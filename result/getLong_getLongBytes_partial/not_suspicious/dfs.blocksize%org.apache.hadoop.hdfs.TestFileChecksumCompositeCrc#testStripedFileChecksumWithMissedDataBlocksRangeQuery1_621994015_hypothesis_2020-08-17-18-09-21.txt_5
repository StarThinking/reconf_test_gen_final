reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1693546808-172.17.0.10-1597687961346:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41684,DS-bd2a4461-2bcb-4cf1-9956-f25aca5ec6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-05894be5-0f2b-4710-ab7b-6e4339c14cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-31b3caef-d90e-4042-bf39-2469864a8c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-6544e2ab-9144-40e4-8a22-b63c4e7e3010,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-b5d19eed-59fd-4c93-8399-001d021ac1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-f193b7c7-87bf-405b-a354-7f1b0ee8ded3,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-476bcd1e-7f50-4309-8d93-36856d2cfa53,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-80c6713e-3907-42fa-84c0-5e0489f5be52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1693546808-172.17.0.10-1597687961346:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41684,DS-bd2a4461-2bcb-4cf1-9956-f25aca5ec6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-05894be5-0f2b-4710-ab7b-6e4339c14cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-31b3caef-d90e-4042-bf39-2469864a8c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-6544e2ab-9144-40e4-8a22-b63c4e7e3010,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-b5d19eed-59fd-4c93-8399-001d021ac1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-f193b7c7-87bf-405b-a354-7f1b0ee8ded3,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-476bcd1e-7f50-4309-8d93-36856d2cfa53,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-80c6713e-3907-42fa-84c0-5e0489f5be52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-786066942-172.17.0.10-1597688060507:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41831,DS-252ae641-0100-448e-ad24-c0034bc382ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-db02ab14-fd8b-4346-85cf-067d63769703,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-1a62cdce-5671-46b8-9f38-e1e6a9136d83,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-a60f4a67-a734-4cc1-8b80-54ac4bd67d62,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-353da325-9457-493c-b3b4-aaea4b3e76ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-ff47766a-f0f4-446a-ae03-d1a0e23568de,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-71561539-d7ed-4d16-a82b-76d13b799c82,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-d03139a7-f0c1-454b-abf6-509a92bbed60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-786066942-172.17.0.10-1597688060507:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41831,DS-252ae641-0100-448e-ad24-c0034bc382ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-db02ab14-fd8b-4346-85cf-067d63769703,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-1a62cdce-5671-46b8-9f38-e1e6a9136d83,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-a60f4a67-a734-4cc1-8b80-54ac4bd67d62,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-353da325-9457-493c-b3b4-aaea4b3e76ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-ff47766a-f0f4-446a-ae03-d1a0e23568de,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-71561539-d7ed-4d16-a82b-76d13b799c82,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-d03139a7-f0c1-454b-abf6-509a92bbed60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-678007157-172.17.0.10-1597688236387:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44203,DS-bd2579e7-9ca9-46eb-9c1b-c3396d74d84a,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-7f3134ec-1213-4053-8cfc-73ed795406df,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-9db2dab0-c1e5-48e3-9ce5-c376dcac308e,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-647ee7d9-7fa2-468a-9f27-d124d130519c,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-fe2a6041-a88a-4f25-b28a-3e763c5acd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-38e569cc-becb-431e-b349-fa04c5128071,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-c44ec2b9-cbb5-4dde-9c61-0f412d1c539d,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-06468551-7c9c-4be1-9e8f-864be4e79aea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-678007157-172.17.0.10-1597688236387:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44203,DS-bd2579e7-9ca9-46eb-9c1b-c3396d74d84a,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-7f3134ec-1213-4053-8cfc-73ed795406df,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-9db2dab0-c1e5-48e3-9ce5-c376dcac308e,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-647ee7d9-7fa2-468a-9f27-d124d130519c,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-fe2a6041-a88a-4f25-b28a-3e763c5acd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-38e569cc-becb-431e-b349-fa04c5128071,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-c44ec2b9-cbb5-4dde-9c61-0f412d1c539d,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-06468551-7c9c-4be1-9e8f-864be4e79aea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337120844-172.17.0.10-1597689852905:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45254,DS-d4fc9370-0e09-4a89-97da-3771cfff8c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-402238ef-4419-4d6e-9bac-7a83d50c0ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-4ee5142a-719a-4461-bd29-7a21a28439cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-962e92b7-0b86-4398-823a-be8d40f3bd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-97020b5f-9abe-4938-8abb-24b52cad6bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-03d5cc59-d222-483f-84c8-8c580eff90e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-0ec19b46-fd6d-4a83-b7dd-cd702890974e,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-d168cea2-a137-43f6-8c7d-13aff9675905,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337120844-172.17.0.10-1597689852905:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45254,DS-d4fc9370-0e09-4a89-97da-3771cfff8c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-402238ef-4419-4d6e-9bac-7a83d50c0ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-4ee5142a-719a-4461-bd29-7a21a28439cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-962e92b7-0b86-4398-823a-be8d40f3bd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-97020b5f-9abe-4938-8abb-24b52cad6bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-03d5cc59-d222-483f-84c8-8c580eff90e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-0ec19b46-fd6d-4a83-b7dd-cd702890974e,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-d168cea2-a137-43f6-8c7d-13aff9675905,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-714570767-172.17.0.10-1597689995112:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34019,DS-1c7c2de3-442c-4a4e-984e-550ea525a993,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-eb851bc1-6a04-4a70-9799-1f08b1677857,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-deeac600-d3ae-434e-ad37-4953f69e19d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-52ff5e30-e9c0-4274-b69b-747767cd8a52,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-5e3e8af8-39b4-4419-a77b-bd22e04243ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-fa0a1957-4dc4-41e8-81f2-c6866be6d93d,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-6f2592c6-8989-4715-bb6b-2c93fb2067bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-30228f88-0e0d-4440-bff5-b8ed4b15a6d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-714570767-172.17.0.10-1597689995112:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34019,DS-1c7c2de3-442c-4a4e-984e-550ea525a993,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-eb851bc1-6a04-4a70-9799-1f08b1677857,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-deeac600-d3ae-434e-ad37-4953f69e19d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-52ff5e30-e9c0-4274-b69b-747767cd8a52,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-5e3e8af8-39b4-4419-a77b-bd22e04243ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-fa0a1957-4dc4-41e8-81f2-c6866be6d93d,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-6f2592c6-8989-4715-bb6b-2c93fb2067bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-30228f88-0e0d-4440-bff5-b8ed4b15a6d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-749973689-172.17.0.10-1597690129549:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40895,DS-7ecf64d1-2f0d-4f75-9349-d3bac06c2fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-1b43e5b1-be7f-4821-b6cd-35b58e9f7206,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-c0512acc-a83f-46ef-b1d5-e14f4a6d4c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-e686f4d4-1a37-43ea-b0b3-3a5d126f6108,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-31c96e07-a974-4e7e-945c-5358993d596b,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-471618cf-365a-4fa4-97c9-224b1a0eb253,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-2d4b7d17-ec90-4c4a-981e-5cfb6a670706,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-d3c8dbf1-e35d-42f3-8eb5-7a57e8d01b97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-749973689-172.17.0.10-1597690129549:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40895,DS-7ecf64d1-2f0d-4f75-9349-d3bac06c2fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-1b43e5b1-be7f-4821-b6cd-35b58e9f7206,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-c0512acc-a83f-46ef-b1d5-e14f4a6d4c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-e686f4d4-1a37-43ea-b0b3-3a5d126f6108,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-31c96e07-a974-4e7e-945c-5358993d596b,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-471618cf-365a-4fa4-97c9-224b1a0eb253,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-2d4b7d17-ec90-4c4a-981e-5cfb6a670706,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-d3c8dbf1-e35d-42f3-8eb5-7a57e8d01b97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618556310-172.17.0.10-1597690234285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33924,DS-abb8f428-ac6f-4108-91e3-43db89b4a590,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-1eeb1130-9db8-42ef-8fff-e90964780c90,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-f7b78786-a575-4bba-83d0-5e21c998e68d,DISK], DatanodeInfoWithStorage[127.0.0.1:42427,DS-574b3880-9462-47a1-b7ad-b1b8bfadf3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-d1732fb4-2be3-4a96-8c51-22ad271860bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-4b75299c-f372-4a64-b932-8a903b5fcefd,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-2d4baa18-0f19-4199-b1fd-727582ca9c40,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-c3b519fa-4729-44bc-ae6b-0733cfbbdb8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618556310-172.17.0.10-1597690234285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33924,DS-abb8f428-ac6f-4108-91e3-43db89b4a590,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-1eeb1130-9db8-42ef-8fff-e90964780c90,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-f7b78786-a575-4bba-83d0-5e21c998e68d,DISK], DatanodeInfoWithStorage[127.0.0.1:42427,DS-574b3880-9462-47a1-b7ad-b1b8bfadf3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-d1732fb4-2be3-4a96-8c51-22ad271860bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-4b75299c-f372-4a64-b932-8a903b5fcefd,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-2d4baa18-0f19-4199-b1fd-727582ca9c40,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-c3b519fa-4729-44bc-ae6b-0733cfbbdb8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-113609754-172.17.0.10-1597690537675:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34617,DS-550900d8-0d0a-4d42-a9b8-da931582fc54,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-4fea5aca-a90c-4132-b4e5-f03934299894,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-d2a69400-8703-476c-b1d8-f26df5ecaefc,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-ac408421-f36b-4376-a33e-f192d37facba,DISK], DatanodeInfoWithStorage[127.0.0.1:42347,DS-28ac2cf5-eb8e-4728-bdf9-8a26ef4dc03d,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-8674998d-92b5-4112-ae76-2a830083a618,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-6be67e91-0c8f-486b-bb41-ff3e982a8790,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-71034d09-56e8-4163-82a0-72be3ce7274a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-113609754-172.17.0.10-1597690537675:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34617,DS-550900d8-0d0a-4d42-a9b8-da931582fc54,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-4fea5aca-a90c-4132-b4e5-f03934299894,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-d2a69400-8703-476c-b1d8-f26df5ecaefc,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-ac408421-f36b-4376-a33e-f192d37facba,DISK], DatanodeInfoWithStorage[127.0.0.1:42347,DS-28ac2cf5-eb8e-4728-bdf9-8a26ef4dc03d,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-8674998d-92b5-4112-ae76-2a830083a618,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-6be67e91-0c8f-486b-bb41-ff3e982a8790,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-71034d09-56e8-4163-82a0-72be3ce7274a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1539640470-172.17.0.10-1597691023584:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44998,DS-1ddc367c-aa1c-4ad8-b294-f7b337065f32,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-9001dd49-c880-44c7-b2af-22c0f08b70f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-70c29fbe-f551-44f3-828f-81a8626a23af,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-7b9df898-78e2-4787-8a2e-aadbe06375ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-8e787e33-86b2-4374-b10c-ea4cd979f7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-318315f3-d130-46dd-a8da-315c6f443755,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-6bfff601-77f3-4329-9bf8-170da755343a,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-8cab959b-146e-49f5-97d6-28a4f9aa1474,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1539640470-172.17.0.10-1597691023584:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44998,DS-1ddc367c-aa1c-4ad8-b294-f7b337065f32,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-9001dd49-c880-44c7-b2af-22c0f08b70f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-70c29fbe-f551-44f3-828f-81a8626a23af,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-7b9df898-78e2-4787-8a2e-aadbe06375ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-8e787e33-86b2-4374-b10c-ea4cd979f7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-318315f3-d130-46dd-a8da-315c6f443755,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-6bfff601-77f3-4329-9bf8-170da755343a,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-8cab959b-146e-49f5-97d6-28a4f9aa1474,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1288166371-172.17.0.10-1597692818573:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46135,DS-e08beba3-0ea7-49b4-aeb5-a72086fa67f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-7cbefeae-84a0-468c-b325-6b6ea4ae0747,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-abd6c8cc-9541-4470-ab56-5e2de6abb15c,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-a59668da-071b-4f97-a73e-1d44a9ceda9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-cb078de7-5b8d-4ceb-8cc2-76e2c81fa93b,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-5ed36a80-f178-453e-a709-d0eb4023718d,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-ace7351f-809b-4f53-b1d2-ba4d8f1dc343,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-d385d94c-029e-4d43-bd8f-9a09ee302f9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1288166371-172.17.0.10-1597692818573:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46135,DS-e08beba3-0ea7-49b4-aeb5-a72086fa67f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-7cbefeae-84a0-468c-b325-6b6ea4ae0747,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-abd6c8cc-9541-4470-ab56-5e2de6abb15c,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-a59668da-071b-4f97-a73e-1d44a9ceda9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-cb078de7-5b8d-4ceb-8cc2-76e2c81fa93b,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-5ed36a80-f178-453e-a709-d0eb4023718d,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-ace7351f-809b-4f53-b1d2-ba4d8f1dc343,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-d385d94c-029e-4d43-bd8f-9a09ee302f9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2043035912-172.17.0.10-1597693315811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36815,DS-6cdab87f-e194-4460-8826-a51892e5f1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-0112aae6-130b-4be7-8e92-eb17c6f0a6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40587,DS-2cc5a03c-02bd-48f9-8f51-d4db66699ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-b6c763b6-9884-4219-8954-4e6f95232642,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-af997245-ef6a-4a04-af71-00d00b06edd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-6da6f574-9e02-4e20-be14-47a14f73e10b,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-57b00bd6-0486-4314-8dfd-ca9069aa2a49,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-270196e5-5213-45cc-a588-46efff10d189,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2043035912-172.17.0.10-1597693315811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36815,DS-6cdab87f-e194-4460-8826-a51892e5f1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-0112aae6-130b-4be7-8e92-eb17c6f0a6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40587,DS-2cc5a03c-02bd-48f9-8f51-d4db66699ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-b6c763b6-9884-4219-8954-4e6f95232642,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-af997245-ef6a-4a04-af71-00d00b06edd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-6da6f574-9e02-4e20-be14-47a14f73e10b,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-57b00bd6-0486-4314-8dfd-ca9069aa2a49,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-270196e5-5213-45cc-a588-46efff10d189,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906353154-172.17.0.10-1597693509797:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34551,DS-5710c2f5-6a6c-44c6-ae54-d24acd65dced,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-210f40b5-f81b-4247-800f-11140c87a92b,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-9aeb61c2-1d0e-4f57-9a09-57d6dba41722,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-780d2815-b474-469b-bc73-a52eb4e391ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-7004f7b4-b7c9-42e3-9faa-d357da5aa757,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-963a467f-ff03-4827-a0bb-a8826907cfbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41130,DS-f5413458-4fa8-499d-b805-c6da45645788,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-4510ebb5-e0db-477c-a4fd-569d6e8e3e94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906353154-172.17.0.10-1597693509797:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34551,DS-5710c2f5-6a6c-44c6-ae54-d24acd65dced,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-210f40b5-f81b-4247-800f-11140c87a92b,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-9aeb61c2-1d0e-4f57-9a09-57d6dba41722,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-780d2815-b474-469b-bc73-a52eb4e391ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-7004f7b4-b7c9-42e3-9faa-d357da5aa757,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-963a467f-ff03-4827-a0bb-a8826907cfbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41130,DS-f5413458-4fa8-499d-b805-c6da45645788,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-4510ebb5-e0db-477c-a4fd-569d6e8e3e94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105046828-172.17.0.10-1597693587637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39540,DS-e44a4201-4840-439a-87a3-3ab0155bb534,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-6fd05746-bb84-4b69-b0fd-a5a94a0d245c,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-6fd5c771-12e5-4872-97a4-bb6023d90aed,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-3b0f65e5-c904-4319-b807-dc1539d62d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-e1825759-78c2-48a4-8a47-2f20476a4728,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-82d1f36c-9391-4e53-b96c-2d0d6aa51156,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-72b0aac0-1098-478f-8bb8-5df51022d329,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-98245bb1-119f-4241-9109-f4c521602b1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105046828-172.17.0.10-1597693587637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39540,DS-e44a4201-4840-439a-87a3-3ab0155bb534,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-6fd05746-bb84-4b69-b0fd-a5a94a0d245c,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-6fd5c771-12e5-4872-97a4-bb6023d90aed,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-3b0f65e5-c904-4319-b807-dc1539d62d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-e1825759-78c2-48a4-8a47-2f20476a4728,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-82d1f36c-9391-4e53-b96c-2d0d6aa51156,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-72b0aac0-1098-478f-8bb8-5df51022d329,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-98245bb1-119f-4241-9109-f4c521602b1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1521988262-172.17.0.10-1597693769048:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33297,DS-f052c33e-121d-45bd-834d-22212c6622af,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-3e860e5b-b729-47eb-9369-3d9533bbd776,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-5699f76b-90b3-4773-81f1-492dc3510919,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-bdd71da5-e90e-46e1-bd92-602d1e3aff48,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-1a2f4637-0f6f-4816-87b7-8d3c4ec9b1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-97902dd5-135c-4e07-9242-ec75cb183567,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-3d2f25c8-cdc3-44ff-b101-895f35da2e31,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-f8c784e9-75f5-445d-839d-6e3556835761,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1521988262-172.17.0.10-1597693769048:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33297,DS-f052c33e-121d-45bd-834d-22212c6622af,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-3e860e5b-b729-47eb-9369-3d9533bbd776,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-5699f76b-90b3-4773-81f1-492dc3510919,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-bdd71da5-e90e-46e1-bd92-602d1e3aff48,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-1a2f4637-0f6f-4816-87b7-8d3c4ec9b1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-97902dd5-135c-4e07-9242-ec75cb183567,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-3d2f25c8-cdc3-44ff-b101-895f35da2e31,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-f8c784e9-75f5-445d-839d-6e3556835761,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1519167613-172.17.0.10-1597693930012:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44496,DS-011b466f-6f21-43c9-bc13-8258b5ea55f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-df222b90-8e56-4179-b16f-2e72286237ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-c48ea382-bb5b-4acc-96c0-d8da32d746c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-e5b78057-af8a-4cf5-9569-ce78d2cde24f,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-34e3d4ae-4292-450c-8e6a-4017d78cd7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-21d03316-dce9-44ce-a071-a34790876d34,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-0a8332e4-fa23-453c-84e7-ec4aebd0e768,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-d347c683-a54b-49ba-9ab7-4b6866a97896,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1519167613-172.17.0.10-1597693930012:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44496,DS-011b466f-6f21-43c9-bc13-8258b5ea55f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-df222b90-8e56-4179-b16f-2e72286237ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-c48ea382-bb5b-4acc-96c0-d8da32d746c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-e5b78057-af8a-4cf5-9569-ce78d2cde24f,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-34e3d4ae-4292-450c-8e6a-4017d78cd7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-21d03316-dce9-44ce-a071-a34790876d34,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-0a8332e4-fa23-453c-84e7-ec4aebd0e768,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-d347c683-a54b-49ba-9ab7-4b6866a97896,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1969535447-172.17.0.10-1597694138522:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43908,DS-b2077d13-139d-4363-89f0-fd4fde020a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-834b233b-323e-42ac-aa48-d6e39c3e48dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-d1b6de64-30c5-42fc-9a83-7835445f6eff,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-adbaa14f-e7e2-48c3-bd0b-889680db71fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-0e99e367-bf3a-430d-abbf-84947b46b6df,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-82b3e376-2235-446a-a903-67116fff8488,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-79088748-833a-4e53-b6d5-15841b625f27,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-3be74d86-c334-42be-a97b-3118d54b92e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1969535447-172.17.0.10-1597694138522:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43908,DS-b2077d13-139d-4363-89f0-fd4fde020a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-834b233b-323e-42ac-aa48-d6e39c3e48dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-d1b6de64-30c5-42fc-9a83-7835445f6eff,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-adbaa14f-e7e2-48c3-bd0b-889680db71fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-0e99e367-bf3a-430d-abbf-84947b46b6df,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-82b3e376-2235-446a-a903-67116fff8488,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-79088748-833a-4e53-b6d5-15841b625f27,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-3be74d86-c334-42be-a97b-3118d54b92e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1001120164-172.17.0.10-1597694309720:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37583,DS-0278d869-1cd7-4701-9b11-f7e47a28f5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-f5fdbec4-e576-460e-8623-588cd06fa12f,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-43586cc8-f2ff-4e7b-824f-4a6ef733fcf5,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-269b30eb-5d28-4253-87de-19dc6e9b8676,DISK], DatanodeInfoWithStorage[127.0.0.1:41658,DS-40f0e23e-1bb0-405e-9106-a90d327194af,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-3afa6005-f95c-4215-a899-040805b1244c,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-af0a0eb6-f31d-4996-877d-63d0d1d35589,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-c9f93c60-b294-4019-9a0e-f95f1b7ac76d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1001120164-172.17.0.10-1597694309720:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37583,DS-0278d869-1cd7-4701-9b11-f7e47a28f5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-f5fdbec4-e576-460e-8623-588cd06fa12f,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-43586cc8-f2ff-4e7b-824f-4a6ef733fcf5,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-269b30eb-5d28-4253-87de-19dc6e9b8676,DISK], DatanodeInfoWithStorage[127.0.0.1:41658,DS-40f0e23e-1bb0-405e-9106-a90d327194af,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-3afa6005-f95c-4215-a899-040805b1244c,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-af0a0eb6-f31d-4996-877d-63d0d1d35589,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-c9f93c60-b294-4019-9a0e-f95f1b7ac76d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: might be true error
Total execution time in seconds : 6913
