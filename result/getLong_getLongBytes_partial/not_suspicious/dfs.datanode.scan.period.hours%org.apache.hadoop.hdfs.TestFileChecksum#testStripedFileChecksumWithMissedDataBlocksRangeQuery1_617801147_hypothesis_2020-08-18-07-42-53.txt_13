reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885103749-172.17.0.14-1597736778355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32792,DS-3dac2958-c4b6-4541-86b1-0791e1670480,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-0067c686-eccb-4ce7-bc03-d9168a64bf58,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-f8a65393-8f48-482c-b0fc-3a59b21837ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-037771d8-d325-4d66-8c34-0f55a660e2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-d7cc6080-8c46-47b9-b2d7-c9352bc028aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35524,DS-011bac39-e69a-41b6-93ec-fe5e1e18a1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-ee4f4f2c-59d0-4b52-8fd6-ac6b468a05bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-c5c07ea9-d133-4465-80c9-d0e5cb7cbf24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885103749-172.17.0.14-1597736778355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32792,DS-3dac2958-c4b6-4541-86b1-0791e1670480,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-0067c686-eccb-4ce7-bc03-d9168a64bf58,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-f8a65393-8f48-482c-b0fc-3a59b21837ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-037771d8-d325-4d66-8c34-0f55a660e2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-d7cc6080-8c46-47b9-b2d7-c9352bc028aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35524,DS-011bac39-e69a-41b6-93ec-fe5e1e18a1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-ee4f4f2c-59d0-4b52-8fd6-ac6b468a05bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-c5c07ea9-d133-4465-80c9-d0e5cb7cbf24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-796225826-172.17.0.14-1597737281989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44893,DS-59e7b54d-49e0-4c12-b632-9f8ce0a975f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-d956f8b9-84c9-414e-a151-00dc3c174460,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-63d1b9de-4e28-4709-a8c2-55520d745919,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-71f25c0f-c458-4b32-9962-cb2f9c988fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-242c9a81-01b2-46be-81da-32dccffac442,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-f05ce187-8d34-47e8-a55d-dced14ef119a,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-cd41f0d4-0fcc-41d6-a1e3-6ef06b1eb93b,DISK], DatanodeInfoWithStorage[127.0.0.1:35789,DS-de090cf0-dae2-4f4c-a4ee-22e32ae7a2c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-796225826-172.17.0.14-1597737281989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44893,DS-59e7b54d-49e0-4c12-b632-9f8ce0a975f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-d956f8b9-84c9-414e-a151-00dc3c174460,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-63d1b9de-4e28-4709-a8c2-55520d745919,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-71f25c0f-c458-4b32-9962-cb2f9c988fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-242c9a81-01b2-46be-81da-32dccffac442,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-f05ce187-8d34-47e8-a55d-dced14ef119a,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-cd41f0d4-0fcc-41d6-a1e3-6ef06b1eb93b,DISK], DatanodeInfoWithStorage[127.0.0.1:35789,DS-de090cf0-dae2-4f4c-a4ee-22e32ae7a2c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800357786-172.17.0.14-1597737574185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42771,DS-ac137dc6-fc14-48b5-a668-63ba55f84e07,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-e084a8ce-ec98-444f-a605-c33effac7b03,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-4936e1f9-35e6-42b2-8d5d-b1a0738d24e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-1cdd5607-9a73-42bc-b860-39078091342c,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-7b571cf0-4ce2-4e35-adbb-0cceb1c914ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-929fb728-7742-4b05-a07b-6ee80c27bdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-56819e9d-c810-49c0-8caf-dd8ff61bf950,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-1d773364-cb81-4ac8-a5c4-3c0a57363ff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800357786-172.17.0.14-1597737574185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42771,DS-ac137dc6-fc14-48b5-a668-63ba55f84e07,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-e084a8ce-ec98-444f-a605-c33effac7b03,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-4936e1f9-35e6-42b2-8d5d-b1a0738d24e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-1cdd5607-9a73-42bc-b860-39078091342c,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-7b571cf0-4ce2-4e35-adbb-0cceb1c914ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-929fb728-7742-4b05-a07b-6ee80c27bdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-56819e9d-c810-49c0-8caf-dd8ff61bf950,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-1d773364-cb81-4ac8-a5c4-3c0a57363ff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752618714-172.17.0.14-1597737930271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38920,DS-c2eef96d-b587-4581-b1eb-39a29c1800d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-dbfd13cb-fdea-49f1-b544-25616f3559cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-309106a0-573e-435a-bd61-acde167ac5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-9b3e0158-4f72-4772-9168-72fd88dd35fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-f86878fd-8bdd-4fcf-8c51-d5e72e40b101,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-90d52c0b-3473-4937-a156-830706385b50,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-35a536a7-edf1-42d4-8ec5-37c914a10e74,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-f0eb90f9-9bdf-457f-b287-c884d6f1b261,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752618714-172.17.0.14-1597737930271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38920,DS-c2eef96d-b587-4581-b1eb-39a29c1800d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-dbfd13cb-fdea-49f1-b544-25616f3559cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-309106a0-573e-435a-bd61-acde167ac5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-9b3e0158-4f72-4772-9168-72fd88dd35fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-f86878fd-8bdd-4fcf-8c51-d5e72e40b101,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-90d52c0b-3473-4937-a156-830706385b50,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-35a536a7-edf1-42d4-8ec5-37c914a10e74,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-f0eb90f9-9bdf-457f-b287-c884d6f1b261,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-300681065-172.17.0.14-1597738177036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35581,DS-8cfb9615-7a55-4a77-bb58-b1dbb10d939f,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-6665ed99-4ab9-4742-8664-681f0bc8d16c,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-bff4809f-18c3-4d6c-8383-7ea84b641711,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-a624482e-3f1f-4904-8d1b-bb6bfdfc2552,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-39de79fd-098a-4014-8cd5-063cf5cbaf18,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-6b13787f-b334-4617-8870-dd87e348974a,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-85815f4e-cf88-40a4-b16c-7d8d8d2e984c,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-e39c4681-0cb7-4e39-9fc7-f5dbe3bf2219,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-300681065-172.17.0.14-1597738177036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35581,DS-8cfb9615-7a55-4a77-bb58-b1dbb10d939f,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-6665ed99-4ab9-4742-8664-681f0bc8d16c,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-bff4809f-18c3-4d6c-8383-7ea84b641711,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-a624482e-3f1f-4904-8d1b-bb6bfdfc2552,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-39de79fd-098a-4014-8cd5-063cf5cbaf18,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-6b13787f-b334-4617-8870-dd87e348974a,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-85815f4e-cf88-40a4-b16c-7d8d8d2e984c,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-e39c4681-0cb7-4e39-9fc7-f5dbe3bf2219,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056467864-172.17.0.14-1597738703836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46497,DS-c466a34f-0c5c-48b4-a6b3-d9050b6c2049,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-1453da86-4207-455b-bd04-194303b338b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-7483be56-2820-46f4-981d-9a04daeb1891,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-6a38a6a3-215f-4a3b-b2ba-b3691679ed8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-5b3d18a6-47ed-4129-8b2c-92eaa7b5d5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-0fd359a6-f8b2-4ffb-b729-61776208e42d,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-93767733-3442-42fc-9adf-980f416d20d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-cdc0bbeb-d13b-4276-bbf6-4450021d93e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056467864-172.17.0.14-1597738703836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46497,DS-c466a34f-0c5c-48b4-a6b3-d9050b6c2049,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-1453da86-4207-455b-bd04-194303b338b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-7483be56-2820-46f4-981d-9a04daeb1891,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-6a38a6a3-215f-4a3b-b2ba-b3691679ed8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-5b3d18a6-47ed-4129-8b2c-92eaa7b5d5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-0fd359a6-f8b2-4ffb-b729-61776208e42d,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-93767733-3442-42fc-9adf-980f416d20d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-cdc0bbeb-d13b-4276-bbf6-4450021d93e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-945966207-172.17.0.14-1597739342927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39471,DS-8171bd37-6fca-404d-9e29-b6228f8eab4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-fc8dac9a-f899-45b8-b68c-1a66dc12d4df,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-55d44ac5-099d-4f96-96bd-5f70a7d6e524,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-c9324507-7e1b-4786-b42a-fc3136a153eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-54334973-766b-43a4-a775-b4e501872cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-9b276548-ff7f-4b59-8c50-f5bff2de3f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-807fd9e9-a674-42d9-b580-48f455a15fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-b625cee9-1252-468d-b3c1-0bc9692fc53a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-945966207-172.17.0.14-1597739342927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39471,DS-8171bd37-6fca-404d-9e29-b6228f8eab4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-fc8dac9a-f899-45b8-b68c-1a66dc12d4df,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-55d44ac5-099d-4f96-96bd-5f70a7d6e524,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-c9324507-7e1b-4786-b42a-fc3136a153eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-54334973-766b-43a4-a775-b4e501872cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-9b276548-ff7f-4b59-8c50-f5bff2de3f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-807fd9e9-a674-42d9-b580-48f455a15fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-b625cee9-1252-468d-b3c1-0bc9692fc53a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-406956478-172.17.0.14-1597740060527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45946,DS-65c88ac8-e3ac-4aad-9ab7-b1eb82c82bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-d78c0519-b59d-4106-ac85-2b9f73b58092,DISK], DatanodeInfoWithStorage[127.0.0.1:36240,DS-6dbc3c7e-eaf4-4d63-9158-15e6a21a86ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-81de4fca-b9e6-4956-8a84-45bce8c2235f,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-7e3ed066-bc85-48ad-9c72-7701c3256360,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-3c9cd4ff-4389-426c-a547-6492be3231f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-7d439886-5514-4209-8835-7eb414f8f838,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-5c31bff9-a8bf-473a-8395-ca46b7439088,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-406956478-172.17.0.14-1597740060527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45946,DS-65c88ac8-e3ac-4aad-9ab7-b1eb82c82bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-d78c0519-b59d-4106-ac85-2b9f73b58092,DISK], DatanodeInfoWithStorage[127.0.0.1:36240,DS-6dbc3c7e-eaf4-4d63-9158-15e6a21a86ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-81de4fca-b9e6-4956-8a84-45bce8c2235f,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-7e3ed066-bc85-48ad-9c72-7701c3256360,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-3c9cd4ff-4389-426c-a547-6492be3231f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-7d439886-5514-4209-8835-7eb414f8f838,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-5c31bff9-a8bf-473a-8395-ca46b7439088,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-519782681-172.17.0.14-1597740398490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44883,DS-0a142d70-ca16-4f09-8bb6-9ed60ef4533b,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-3dbfc1c0-befa-4235-a72d-a2d895ac309b,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-5d4bc07d-942a-4bad-af10-361badff9733,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-e78393fe-814c-4cef-8746-792abd2350db,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-8e27e579-5337-4ad2-bc28-67c9e6d8388b,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-3441dd14-0754-467e-a970-30d05c57e8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-6c62d9b6-5a4f-4843-8f06-78af5f967d28,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-eae5cf85-eed3-465c-adcd-74480400b3fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-519782681-172.17.0.14-1597740398490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44883,DS-0a142d70-ca16-4f09-8bb6-9ed60ef4533b,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-3dbfc1c0-befa-4235-a72d-a2d895ac309b,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-5d4bc07d-942a-4bad-af10-361badff9733,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-e78393fe-814c-4cef-8746-792abd2350db,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-8e27e579-5337-4ad2-bc28-67c9e6d8388b,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-3441dd14-0754-467e-a970-30d05c57e8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-6c62d9b6-5a4f-4843-8f06-78af5f967d28,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-eae5cf85-eed3-465c-adcd-74480400b3fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1478316198-172.17.0.14-1597742017622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42238,DS-73bbcb90-7b3f-46d2-af92-b4ca812140e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-2d9e1713-f46b-4e31-9bf2-d6f25e7363e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-d26e9574-5148-4bd6-8800-26a46bacd302,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-21fadb4c-da3e-4449-be90-c4bf1985799c,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-5748a55c-ad45-49dc-8280-2985c888d22e,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-dacadf90-baa4-4791-b3fc-333819296b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-754a54f1-1019-4099-96d7-50a1306390ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-486dcea5-a1f4-48d1-8ea2-e94c311813d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1478316198-172.17.0.14-1597742017622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42238,DS-73bbcb90-7b3f-46d2-af92-b4ca812140e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-2d9e1713-f46b-4e31-9bf2-d6f25e7363e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-d26e9574-5148-4bd6-8800-26a46bacd302,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-21fadb4c-da3e-4449-be90-c4bf1985799c,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-5748a55c-ad45-49dc-8280-2985c888d22e,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-dacadf90-baa4-4791-b3fc-333819296b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-754a54f1-1019-4099-96d7-50a1306390ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-486dcea5-a1f4-48d1-8ea2-e94c311813d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2099432082-172.17.0.14-1597742148791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46557,DS-be83d416-1694-4334-9cab-29df179a72c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-54c5013d-ee99-4493-8d51-679f1c15c22e,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-e800a31a-0909-4569-a808-3b607f631a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-e9736c4b-d5b0-4097-a659-f6c00d492dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-6082548a-78b3-4089-b0e8-3c5e30cef380,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-64bbf72a-ccdf-4b99-8e81-f5fe7f65d6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-9fde84e1-0b56-48fb-9f54-33df3ac3214c,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-e09b1a4a-5d7e-483f-9f6b-41c62c54e5bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2099432082-172.17.0.14-1597742148791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46557,DS-be83d416-1694-4334-9cab-29df179a72c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-54c5013d-ee99-4493-8d51-679f1c15c22e,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-e800a31a-0909-4569-a808-3b607f631a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-e9736c4b-d5b0-4097-a659-f6c00d492dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-6082548a-78b3-4089-b0e8-3c5e30cef380,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-64bbf72a-ccdf-4b99-8e81-f5fe7f65d6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-9fde84e1-0b56-48fb-9f54-33df3ac3214c,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-e09b1a4a-5d7e-483f-9f6b-41c62c54e5bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1958700129-172.17.0.14-1597743194187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43336,DS-12a9210f-868f-4e86-ab68-b9e64506d24e,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-0520eb72-a972-45af-8101-750dce4fbf77,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-f98a16b2-bb5b-49e9-8385-bbb0ca4af2be,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-81115b60-6969-4e83-8366-2d77809b4110,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-c6793408-795c-4def-b335-20d0ed7e88a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-bb360573-b6c0-4bf2-a2be-c492b04f25bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-8eff2c04-64a8-4710-a301-1a8d65c2b787,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-686d0af1-b41a-456c-86b9-ec8174e7c994,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1958700129-172.17.0.14-1597743194187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43336,DS-12a9210f-868f-4e86-ab68-b9e64506d24e,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-0520eb72-a972-45af-8101-750dce4fbf77,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-f98a16b2-bb5b-49e9-8385-bbb0ca4af2be,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-81115b60-6969-4e83-8366-2d77809b4110,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-c6793408-795c-4def-b335-20d0ed7e88a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-bb360573-b6c0-4bf2-a2be-c492b04f25bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-8eff2c04-64a8-4710-a301-1a8d65c2b787,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-686d0af1-b41a-456c-86b9-ec8174e7c994,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 6930
