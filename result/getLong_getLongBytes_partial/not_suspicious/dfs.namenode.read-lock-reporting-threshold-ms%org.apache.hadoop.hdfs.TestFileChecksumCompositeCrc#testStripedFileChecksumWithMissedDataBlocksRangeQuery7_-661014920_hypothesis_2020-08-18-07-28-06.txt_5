reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1684010253-172.17.0.7-1597735849700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33358,DS-42b6527d-ccb4-4944-bdc1-80468b572390,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-b23bdbed-1868-4932-a41d-78a01caae4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-5c31abcd-1d05-467d-b316-3745a9a510be,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-5c23260e-494c-470a-b96b-ac164c910bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-1bb960ee-d7e3-4755-a986-10bb5845b613,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-5cee2d12-65f1-4788-9bf2-65632d73e55b,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-8b70f045-c6ae-4a7b-9da7-d07ed9295ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-cd266eee-357a-41ea-b0e8-f593759f23de,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1684010253-172.17.0.7-1597735849700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33358,DS-42b6527d-ccb4-4944-bdc1-80468b572390,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-b23bdbed-1868-4932-a41d-78a01caae4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-5c31abcd-1d05-467d-b316-3745a9a510be,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-5c23260e-494c-470a-b96b-ac164c910bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-1bb960ee-d7e3-4755-a986-10bb5845b613,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-5cee2d12-65f1-4788-9bf2-65632d73e55b,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-8b70f045-c6ae-4a7b-9da7-d07ed9295ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-cd266eee-357a-41ea-b0e8-f593759f23de,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-257312738-172.17.0.7-1597735944722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44474,DS-c6fb66cd-e1fd-423f-a8a6-a778c7daf3af,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-4492871d-317d-4064-ba28-99491abbcd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-b6819018-3f84-4fed-a181-c5ff67bc15c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-23409325-0afd-4010-a2fb-00a576e675fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-c3ea0f11-7f68-4a2c-8452-dca9529664d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-3faf815a-6b3e-4358-a340-681a3e6042fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-aa69026f-27a9-4296-8db8-a96b865248ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-83be63b4-51bf-4f0e-ac52-c36952a87fb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-257312738-172.17.0.7-1597735944722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44474,DS-c6fb66cd-e1fd-423f-a8a6-a778c7daf3af,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-4492871d-317d-4064-ba28-99491abbcd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-b6819018-3f84-4fed-a181-c5ff67bc15c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-23409325-0afd-4010-a2fb-00a576e675fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-c3ea0f11-7f68-4a2c-8452-dca9529664d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-3faf815a-6b3e-4358-a340-681a3e6042fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-aa69026f-27a9-4296-8db8-a96b865248ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-83be63b4-51bf-4f0e-ac52-c36952a87fb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20325935-172.17.0.7-1597736077853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44209,DS-0767b6e1-0f05-41e5-b19a-245048d2ea4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-15cde2b2-ee9a-4b0a-aa69-63be39c5a6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-90e90c07-0f52-4acf-92c7-669e2ea69af9,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-f4340994-5d95-4338-a543-fa98c88fb1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-2019c497-7722-4b4f-b307-f5c5bbc77ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-9794e096-0824-4aa0-964c-ed72f0b22886,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-d404f360-72b8-4973-9b21-7086449bdaef,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-ae855168-6a52-42fe-8639-348b99e92b76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20325935-172.17.0.7-1597736077853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44209,DS-0767b6e1-0f05-41e5-b19a-245048d2ea4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-15cde2b2-ee9a-4b0a-aa69-63be39c5a6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-90e90c07-0f52-4acf-92c7-669e2ea69af9,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-f4340994-5d95-4338-a543-fa98c88fb1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-2019c497-7722-4b4f-b307-f5c5bbc77ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-9794e096-0824-4aa0-964c-ed72f0b22886,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-d404f360-72b8-4973-9b21-7086449bdaef,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-ae855168-6a52-42fe-8639-348b99e92b76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-41024837-172.17.0.7-1597736128259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39328,DS-a3535979-a2dc-43ca-9edb-35e3ee2c98f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-cba40ebe-742f-4175-9141-72533e774743,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-d142a69b-41b2-4be6-89eb-6aa212fda9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-59b0c447-8992-4455-9eff-26189e9b557e,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-b29a416b-60d1-428b-9d20-c7b8f91abc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-70482c02-cc26-4bd8-87ac-92b93a5a19ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-da2cab8b-44df-4c59-84b2-ff3943652185,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-ddf794c6-fcf6-465a-82b9-9cef8bef7012,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-41024837-172.17.0.7-1597736128259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39328,DS-a3535979-a2dc-43ca-9edb-35e3ee2c98f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-cba40ebe-742f-4175-9141-72533e774743,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-d142a69b-41b2-4be6-89eb-6aa212fda9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-59b0c447-8992-4455-9eff-26189e9b557e,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-b29a416b-60d1-428b-9d20-c7b8f91abc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-70482c02-cc26-4bd8-87ac-92b93a5a19ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-da2cab8b-44df-4c59-84b2-ff3943652185,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-ddf794c6-fcf6-465a-82b9-9cef8bef7012,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1187517315-172.17.0.7-1597736400527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46346,DS-688d3e38-b417-4657-aeef-a2bd019cb426,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-090eaa6f-be3e-43d3-8dae-1b79749844d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-9e041252-b962-42ce-8da7-8c81a836cfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-40875dea-f43c-4eb1-905c-f7d4d33a2065,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-05a9f4a1-9d48-416c-b360-a4e22732e346,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-4382b8bd-17a5-4c4c-8b20-326c6ccc8fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-79c9ca65-6d30-4b86-ab38-d80c6cebd368,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-afb8c597-8206-4402-b7c5-e2b109a23fed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1187517315-172.17.0.7-1597736400527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46346,DS-688d3e38-b417-4657-aeef-a2bd019cb426,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-090eaa6f-be3e-43d3-8dae-1b79749844d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-9e041252-b962-42ce-8da7-8c81a836cfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-40875dea-f43c-4eb1-905c-f7d4d33a2065,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-05a9f4a1-9d48-416c-b360-a4e22732e346,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-4382b8bd-17a5-4c4c-8b20-326c6ccc8fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-79c9ca65-6d30-4b86-ab38-d80c6cebd368,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-afb8c597-8206-4402-b7c5-e2b109a23fed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-126384506-172.17.0.7-1597736740564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34857,DS-1436349c-2f46-46b1-bec4-114d6a56bc01,DISK], DatanodeInfoWithStorage[127.0.0.1:36804,DS-9044cfa1-1a31-4add-a2de-38b1c2b75914,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-d0c53211-ce36-4598-9c3c-b69c3cd81ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-62d34fd8-1c6c-4ddf-8ead-2e309e7faa95,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-b714424e-573b-4234-b731-ff8a61f0145b,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-5675abaa-68c4-4479-a574-7a575d1cc820,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-65a2abb4-9743-42c9-9862-a2546d730755,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-d5d60100-b4b0-4298-b54d-40dd7a8f4441,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-126384506-172.17.0.7-1597736740564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34857,DS-1436349c-2f46-46b1-bec4-114d6a56bc01,DISK], DatanodeInfoWithStorage[127.0.0.1:36804,DS-9044cfa1-1a31-4add-a2de-38b1c2b75914,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-d0c53211-ce36-4598-9c3c-b69c3cd81ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-62d34fd8-1c6c-4ddf-8ead-2e309e7faa95,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-b714424e-573b-4234-b731-ff8a61f0145b,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-5675abaa-68c4-4479-a574-7a575d1cc820,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-65a2abb4-9743-42c9-9862-a2546d730755,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-d5d60100-b4b0-4298-b54d-40dd7a8f4441,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701295933-172.17.0.7-1597736912993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39956,DS-5cb7a616-8eed-4b18-8fd9-93de3cf1eae0,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-d1c78717-d49e-4a9f-ba3c-b9a3ddf80b99,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-40e78c45-9611-4aab-a297-cef005816406,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-8c06bbb9-e284-4108-9fd1-3f3a54f10f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-fc54eb49-e6cd-4b90-8933-0e72f34ff895,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-db966516-9460-4891-b68f-74128708df69,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-aebde592-a899-4b3b-8a2d-6e1947eedc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-397bb89d-72c6-4644-9b2a-5f0ef074bf20,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701295933-172.17.0.7-1597736912993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39956,DS-5cb7a616-8eed-4b18-8fd9-93de3cf1eae0,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-d1c78717-d49e-4a9f-ba3c-b9a3ddf80b99,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-40e78c45-9611-4aab-a297-cef005816406,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-8c06bbb9-e284-4108-9fd1-3f3a54f10f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-fc54eb49-e6cd-4b90-8933-0e72f34ff895,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-db966516-9460-4891-b68f-74128708df69,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-aebde592-a899-4b3b-8a2d-6e1947eedc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-397bb89d-72c6-4644-9b2a-5f0ef074bf20,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487170992-172.17.0.7-1597737050369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42517,DS-c438291f-5962-45d2-80a3-02e45d8e256c,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-b6302445-3dc1-4420-92d1-cdab5f884181,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-5f1b2e37-600f-4880-b75f-50f5d50e7706,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-993f0e29-ab2e-42a9-9e38-f482980006a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-4948027f-13d8-4959-9f57-c7a7ca077aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-fd02a94f-5377-47f2-aea5-217fc2b7b5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-235087a8-c954-4b48-b6bf-53c00969520c,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-e4dd29bc-7c1c-4f3e-a6db-b8e11d02df79,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487170992-172.17.0.7-1597737050369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42517,DS-c438291f-5962-45d2-80a3-02e45d8e256c,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-b6302445-3dc1-4420-92d1-cdab5f884181,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-5f1b2e37-600f-4880-b75f-50f5d50e7706,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-993f0e29-ab2e-42a9-9e38-f482980006a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-4948027f-13d8-4959-9f57-c7a7ca077aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-fd02a94f-5377-47f2-aea5-217fc2b7b5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-235087a8-c954-4b48-b6bf-53c00969520c,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-e4dd29bc-7c1c-4f3e-a6db-b8e11d02df79,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121622415-172.17.0.7-1597737262423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36821,DS-fa489bf0-6ed8-4308-bc72-1d7b1c788da0,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-d8e98115-a2b2-49a2-86aa-79b604a7ff63,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-2af4acc9-0262-449b-9d42-cf559e0d9416,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-d2f3271f-e172-4bc8-ad8b-f8d2a3c60d76,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-465f0102-5d6e-4c6a-929f-1b765e13c052,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-a38ea72b-57fb-466a-991b-ce7c68cc66c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-48ec44ab-858f-4ee9-a0bc-bd012800ac42,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-41f088b4-147e-453e-b4ed-b963053e773d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121622415-172.17.0.7-1597737262423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36821,DS-fa489bf0-6ed8-4308-bc72-1d7b1c788da0,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-d8e98115-a2b2-49a2-86aa-79b604a7ff63,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-2af4acc9-0262-449b-9d42-cf559e0d9416,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-d2f3271f-e172-4bc8-ad8b-f8d2a3c60d76,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-465f0102-5d6e-4c6a-929f-1b765e13c052,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-a38ea72b-57fb-466a-991b-ce7c68cc66c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-48ec44ab-858f-4ee9-a0bc-bd012800ac42,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-41f088b4-147e-453e-b4ed-b963053e773d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-334960559-172.17.0.7-1597737352012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36648,DS-12f24012-c72a-435f-a10d-282fc80c4c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-eabf36f5-72f6-4320-866a-3be75351b96a,DISK], DatanodeInfoWithStorage[127.0.0.1:42364,DS-baae38fc-617d-4dc4-a824-ee4c7fb0729a,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-67f32173-548c-454e-8216-1f0f1b75934d,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-e16e82c1-543d-4bf4-98eb-0809ebfcfc84,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-431e0a96-b51a-4512-9794-cf676bf79b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-a230235d-f3e9-4297-9142-2d183ca7ba04,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-beee3497-d946-4792-a5c2-8d3929bc6518,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-334960559-172.17.0.7-1597737352012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36648,DS-12f24012-c72a-435f-a10d-282fc80c4c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-eabf36f5-72f6-4320-866a-3be75351b96a,DISK], DatanodeInfoWithStorage[127.0.0.1:42364,DS-baae38fc-617d-4dc4-a824-ee4c7fb0729a,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-67f32173-548c-454e-8216-1f0f1b75934d,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-e16e82c1-543d-4bf4-98eb-0809ebfcfc84,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-431e0a96-b51a-4512-9794-cf676bf79b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-a230235d-f3e9-4297-9142-2d183ca7ba04,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-beee3497-d946-4792-a5c2-8d3929bc6518,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1641415092-172.17.0.7-1597737400099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40499,DS-88079e4f-1ab5-412b-bb41-ee5ab837e604,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-022bbac4-df37-4264-ab55-0a9a032a9d55,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-baa51952-9a12-4227-b5d6-b14d875c8106,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-02c35fea-955f-4a11-b23c-f7592a23c87a,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-96c831e9-222a-432f-8bd9-b342733c7022,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-d983f568-668f-48c0-8620-8672e2368e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-91a6a7f9-15c7-4dfd-9777-f67819906c78,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-02180047-e348-493f-b123-9adb86dc1fa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1641415092-172.17.0.7-1597737400099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40499,DS-88079e4f-1ab5-412b-bb41-ee5ab837e604,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-022bbac4-df37-4264-ab55-0a9a032a9d55,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-baa51952-9a12-4227-b5d6-b14d875c8106,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-02c35fea-955f-4a11-b23c-f7592a23c87a,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-96c831e9-222a-432f-8bd9-b342733c7022,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-d983f568-668f-48c0-8620-8672e2368e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-91a6a7f9-15c7-4dfd-9777-f67819906c78,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-02180047-e348-493f-b123-9adb86dc1fa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1416432281-172.17.0.7-1597737501172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44913,DS-db0d9ca6-b79f-4613-8850-bdf383ddf595,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-c9fa777a-a2ce-4b04-b680-3d7b9c6a0371,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-c380fdab-cf46-43a7-94d9-50709b908d44,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-e97096fd-0087-424d-8d0e-6d31e912d18b,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-3f6aabc8-0acd-4ed9-b2d6-9e4c8bfe0f18,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-403f5d4a-3aec-4c6b-996f-07759989acdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35793,DS-0d45f467-ec11-4ee9-870d-d4dacaa5abac,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-ab5dc0ff-2c32-499c-ba83-be3847301007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1416432281-172.17.0.7-1597737501172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44913,DS-db0d9ca6-b79f-4613-8850-bdf383ddf595,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-c9fa777a-a2ce-4b04-b680-3d7b9c6a0371,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-c380fdab-cf46-43a7-94d9-50709b908d44,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-e97096fd-0087-424d-8d0e-6d31e912d18b,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-3f6aabc8-0acd-4ed9-b2d6-9e4c8bfe0f18,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-403f5d4a-3aec-4c6b-996f-07759989acdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35793,DS-0d45f467-ec11-4ee9-870d-d4dacaa5abac,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-ab5dc0ff-2c32-499c-ba83-be3847301007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1364040702-172.17.0.7-1597737716634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36976,DS-e4067823-75ba-469e-83df-b5409ca6eb68,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-aa516bee-0ec1-4bd4-9cb1-ae886a2887e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-2cf6f261-3ce6-4061-be0b-e2db73063328,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-aa4f9bf5-ef9e-4a61-b74c-9d4b5051c54b,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-65c8a11f-bf94-4513-ac54-25725efb5c31,DISK], DatanodeInfoWithStorage[127.0.0.1:46350,DS-19ca8798-3636-461f-b02a-d9803d8de0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-e2bfc577-90a8-4e74-8b35-98eaba8f81eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-fe277e40-8669-4883-ac25-58022ec0d2d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1364040702-172.17.0.7-1597737716634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36976,DS-e4067823-75ba-469e-83df-b5409ca6eb68,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-aa516bee-0ec1-4bd4-9cb1-ae886a2887e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-2cf6f261-3ce6-4061-be0b-e2db73063328,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-aa4f9bf5-ef9e-4a61-b74c-9d4b5051c54b,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-65c8a11f-bf94-4513-ac54-25725efb5c31,DISK], DatanodeInfoWithStorage[127.0.0.1:46350,DS-19ca8798-3636-461f-b02a-d9803d8de0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-e2bfc577-90a8-4e74-8b35-98eaba8f81eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-fe277e40-8669-4883-ac25-58022ec0d2d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177028754-172.17.0.7-1597737818081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36414,DS-777eb1d2-02f6-42f6-923a-b19ebc6b53ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-0a108160-90fc-4c6d-afe0-880efe918fab,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-45fe3a4b-5712-41fb-b2cd-20af5c14624e,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-8f376468-2f27-457b-8746-0419d440e0df,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-1fcbf657-9b72-455b-b773-af48b6998e74,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-b3156d80-3f5e-4584-ad72-bb663205915b,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-5ebe2c39-790e-403c-8ede-ed710ac79e68,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-91673ccb-6d1c-488c-98c5-8a63d114ffc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177028754-172.17.0.7-1597737818081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36414,DS-777eb1d2-02f6-42f6-923a-b19ebc6b53ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-0a108160-90fc-4c6d-afe0-880efe918fab,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-45fe3a4b-5712-41fb-b2cd-20af5c14624e,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-8f376468-2f27-457b-8746-0419d440e0df,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-1fcbf657-9b72-455b-b773-af48b6998e74,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-b3156d80-3f5e-4584-ad72-bb663205915b,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-5ebe2c39-790e-403c-8ede-ed710ac79e68,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-91673ccb-6d1c-488c-98c5-8a63d114ffc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487180092-172.17.0.7-1597738090110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41740,DS-a76dff7f-560d-4ce4-9d3e-fe249c91a9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-1643adcf-2bdf-4a72-bb70-32d9d403d41a,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-473a4302-c005-4616-ac98-67b7014f7ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-4d712341-a0d9-4073-8690-2e4debbb8327,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-b3a80225-ae13-436c-be4c-b8fb3633319f,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-7ad0f104-d05d-4aa5-8f39-7cd0474a7ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-83eca83e-d0ef-42b7-8d94-938df360fc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-ce0e79ac-a6cd-4646-9854-feda40fd43c4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487180092-172.17.0.7-1597738090110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41740,DS-a76dff7f-560d-4ce4-9d3e-fe249c91a9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-1643adcf-2bdf-4a72-bb70-32d9d403d41a,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-473a4302-c005-4616-ac98-67b7014f7ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-4d712341-a0d9-4073-8690-2e4debbb8327,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-b3a80225-ae13-436c-be4c-b8fb3633319f,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-7ad0f104-d05d-4aa5-8f39-7cd0474a7ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-83eca83e-d0ef-42b7-8d94-938df360fc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-ce0e79ac-a6cd-4646-9854-feda40fd43c4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1443941053-172.17.0.7-1597738622212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45316,DS-866da6b0-1e08-4a62-9cd3-06917914fb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-fc8a4185-3743-4fc1-b7f8-e53a069e93de,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-015e4690-6a5f-4728-be5a-10aa50c846b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-dc9a227a-cb41-4d57-bf64-b4f52a83e2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-ac78dd7f-6e10-4587-a8f4-d370f2fc808f,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-6793cc84-f925-48a2-8b82-770b77c749a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-b21ecbc0-8d26-4af4-95c7-4dfc8739be83,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-391dde87-fa65-4b10-a18a-674b58e468f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1443941053-172.17.0.7-1597738622212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45316,DS-866da6b0-1e08-4a62-9cd3-06917914fb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-fc8a4185-3743-4fc1-b7f8-e53a069e93de,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-015e4690-6a5f-4728-be5a-10aa50c846b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-dc9a227a-cb41-4d57-bf64-b4f52a83e2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-ac78dd7f-6e10-4587-a8f4-d370f2fc808f,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-6793cc84-f925-48a2-8b82-770b77c749a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-b21ecbc0-8d26-4af4-95c7-4dfc8739be83,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-391dde87-fa65-4b10-a18a-674b58e468f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1371651226-172.17.0.7-1597738774462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33307,DS-f65720b4-3608-497a-a99a-66cf0597f270,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-61c081bc-20c0-40f8-af7c-2decec0c9d17,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-410d0b6a-b408-4383-ad29-fce27b2f107c,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-7518f007-10b3-4a6a-b676-1ff05354b8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-e1692d4c-8bfd-4202-b212-c9c7a69f33a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-25e6f9b1-d27b-4867-ae4c-0ea36defeb15,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-54ca359c-22f6-4a21-9e48-d0e04d985ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-d9f7b396-a84e-4366-aa48-964e9acbcec4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1371651226-172.17.0.7-1597738774462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33307,DS-f65720b4-3608-497a-a99a-66cf0597f270,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-61c081bc-20c0-40f8-af7c-2decec0c9d17,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-410d0b6a-b408-4383-ad29-fce27b2f107c,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-7518f007-10b3-4a6a-b676-1ff05354b8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-e1692d4c-8bfd-4202-b212-c9c7a69f33a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-25e6f9b1-d27b-4867-ae4c-0ea36defeb15,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-54ca359c-22f6-4a21-9e48-d0e04d985ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-d9f7b396-a84e-4366-aa48-964e9acbcec4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056863452-172.17.0.7-1597739040276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46514,DS-7a5e259b-f2bb-4058-9a8a-71a99172d904,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-47e3dcea-d9fb-4907-9602-20cb9266b2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-5947f3a1-8264-4ec1-bd0b-a71f0e85c886,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-5a8eff8a-c126-4073-b2bf-6f1cb1197d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-572fb787-dfae-47f0-983f-f300ad8bc02c,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-4994c522-1316-4837-bdfb-beb40e0ea728,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-c28f8058-7702-47d4-a2ae-d0cb61330502,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-766b75b0-6d63-4da6-8f43-1f1cb5fff3bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056863452-172.17.0.7-1597739040276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46514,DS-7a5e259b-f2bb-4058-9a8a-71a99172d904,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-47e3dcea-d9fb-4907-9602-20cb9266b2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-5947f3a1-8264-4ec1-bd0b-a71f0e85c886,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-5a8eff8a-c126-4073-b2bf-6f1cb1197d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-572fb787-dfae-47f0-983f-f300ad8bc02c,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-4994c522-1316-4837-bdfb-beb40e0ea728,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-c28f8058-7702-47d4-a2ae-d0cb61330502,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-766b75b0-6d63-4da6-8f43-1f1cb5fff3bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1526697253-172.17.0.7-1597739121098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40472,DS-387f4523-a73c-4231-a5af-e7f63321f87a,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-1c3e84ad-aaac-44d7-81e6-d3266ecb7536,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-5120b16c-45e7-4539-aa6c-b238ef24650a,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-12b36603-1c00-4740-a403-65559e4455d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-69a7ae6b-f1a5-418d-bf92-4c8ad98d1c35,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-de439730-2fd8-44ea-aa4f-b40029b4c952,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-71096545-c008-4ec6-93b4-9867a2491b69,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-5f7d3fa6-8ef4-4199-a7f2-7473d75c6696,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1526697253-172.17.0.7-1597739121098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40472,DS-387f4523-a73c-4231-a5af-e7f63321f87a,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-1c3e84ad-aaac-44d7-81e6-d3266ecb7536,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-5120b16c-45e7-4539-aa6c-b238ef24650a,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-12b36603-1c00-4740-a403-65559e4455d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-69a7ae6b-f1a5-418d-bf92-4c8ad98d1c35,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-de439730-2fd8-44ea-aa4f-b40029b4c952,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-71096545-c008-4ec6-93b4-9867a2491b69,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-5f7d3fa6-8ef4-4199-a7f2-7473d75c6696,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-83522271-172.17.0.7-1597739157590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39172,DS-6947211c-a5ca-4212-931e-db38bc106e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-1d39419f-7512-4e70-ad40-8c4b4bef9459,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-35376bfc-2a6e-45fc-9e4b-275bf8008c24,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-0c407502-81b9-41fb-8519-44b40b591402,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-cb9c584d-9ab6-45e2-9ea3-72b1fb02858f,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-4128c220-74ff-4d46-8812-4d9dd9e4e58f,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-733269df-7924-4b40-ac7e-c9433e353ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-9c9e67ff-e418-4e34-8a9a-6b5e5ffa1225,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-83522271-172.17.0.7-1597739157590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39172,DS-6947211c-a5ca-4212-931e-db38bc106e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-1d39419f-7512-4e70-ad40-8c4b4bef9459,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-35376bfc-2a6e-45fc-9e4b-275bf8008c24,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-0c407502-81b9-41fb-8519-44b40b591402,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-cb9c584d-9ab6-45e2-9ea3-72b1fb02858f,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-4128c220-74ff-4d46-8812-4d9dd9e4e58f,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-733269df-7924-4b40-ac7e-c9433e353ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-9c9e67ff-e418-4e34-8a9a-6b5e5ffa1225,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-975494792-172.17.0.7-1597739522006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41511,DS-7af17e61-25c3-41b2-ac7e-49582416027c,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-23fdb7d1-452f-4037-889a-9fedb47be634,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-5e603f19-a430-4bfd-a0f9-7fa00da5e56c,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-8ee3b9a7-5ca4-41b6-a183-aa5ece06a622,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-b61452a6-2fe2-4f7b-bf9b-ce7fc5a55c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-9530d6d8-3ace-4d75-97ec-caff88d373d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-e9e35b0b-3a26-44b6-8d81-9bff1dca17e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-1a7a7c42-9ae0-4ce5-ae9b-59b5c13e5e80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-975494792-172.17.0.7-1597739522006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41511,DS-7af17e61-25c3-41b2-ac7e-49582416027c,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-23fdb7d1-452f-4037-889a-9fedb47be634,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-5e603f19-a430-4bfd-a0f9-7fa00da5e56c,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-8ee3b9a7-5ca4-41b6-a183-aa5ece06a622,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-b61452a6-2fe2-4f7b-bf9b-ce7fc5a55c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-9530d6d8-3ace-4d75-97ec-caff88d373d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-e9e35b0b-3a26-44b6-8d81-9bff1dca17e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-1a7a7c42-9ae0-4ce5-ae9b-59b5c13e5e80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2119771815-172.17.0.7-1597739557067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43999,DS-2571a6ea-00ce-431c-a00a-c8f8213b2ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-0ac68d0a-735b-4c5e-aa03-dbb276231cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-cf02d067-8afd-4b41-b5f7-8c73585285c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-16603e57-01b2-412b-b84a-99e5d9189012,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-ce9d490b-2f07-440d-93ec-c44f1702ce19,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-a1794f44-f534-4e8d-817e-db96d5825a88,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-a1ab394b-9519-47f6-9282-3206898d860a,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-be484d87-7e60-46e1-8222-1c830d9f5955,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2119771815-172.17.0.7-1597739557067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43999,DS-2571a6ea-00ce-431c-a00a-c8f8213b2ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-0ac68d0a-735b-4c5e-aa03-dbb276231cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-cf02d067-8afd-4b41-b5f7-8c73585285c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-16603e57-01b2-412b-b84a-99e5d9189012,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-ce9d490b-2f07-440d-93ec-c44f1702ce19,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-a1794f44-f534-4e8d-817e-db96d5825a88,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-a1ab394b-9519-47f6-9282-3206898d860a,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-be484d87-7e60-46e1-8222-1c830d9f5955,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654888358-172.17.0.7-1597739605968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40654,DS-364e28e6-1b81-4d11-8f17-9a518d78a556,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-08b96332-2f9c-4b9f-af3a-310224ce6ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-ef08bd13-95e7-4ac2-ac61-01995653e2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-87810e56-cd08-4104-9605-efcd300db92e,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-2fd40e7f-bc10-474f-b9d4-5c6c3f4f1172,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-158b3af1-d8ae-4d4d-94ed-e45f445ef0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-38b73f95-cfce-4db7-83c9-001c2be062af,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-fc45fa49-8d07-47f4-a937-8d2f425af4fb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654888358-172.17.0.7-1597739605968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40654,DS-364e28e6-1b81-4d11-8f17-9a518d78a556,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-08b96332-2f9c-4b9f-af3a-310224ce6ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-ef08bd13-95e7-4ac2-ac61-01995653e2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-87810e56-cd08-4104-9605-efcd300db92e,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-2fd40e7f-bc10-474f-b9d4-5c6c3f4f1172,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-158b3af1-d8ae-4d4d-94ed-e45f445ef0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-38b73f95-cfce-4db7-83c9-001c2be062af,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-fc45fa49-8d07-47f4-a937-8d2f425af4fb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-412757071-172.17.0.7-1597739683443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44407,DS-8e87c0d2-cfb6-41e2-9965-05e90ebdea2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-6b6c7e8c-6403-4252-9734-3b8ad5958e69,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-c167099d-169f-4b30-aac7-676b329bd040,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-0521f0da-f7a1-4998-a63b-ddc760d92141,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-dc63555d-246b-44fd-8d07-e6c35beb9818,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-d9fb785a-22b5-4529-920d-caaba7b8a2de,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-d4023f0b-d94b-45de-866e-a6d94c1ec997,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-af8f25fb-ce50-4ae0-b69d-63535c87654b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-412757071-172.17.0.7-1597739683443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44407,DS-8e87c0d2-cfb6-41e2-9965-05e90ebdea2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-6b6c7e8c-6403-4252-9734-3b8ad5958e69,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-c167099d-169f-4b30-aac7-676b329bd040,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-0521f0da-f7a1-4998-a63b-ddc760d92141,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-dc63555d-246b-44fd-8d07-e6c35beb9818,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-d9fb785a-22b5-4529-920d-caaba7b8a2de,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-d4023f0b-d94b-45de-866e-a6d94c1ec997,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-af8f25fb-ce50-4ae0-b69d-63535c87654b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-250293036-172.17.0.7-1597740026414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38951,DS-c563f5f4-98a4-4eec-8166-ddfb306fcd85,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-2a500afe-5d4f-4228-8456-0217adbfaaed,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-6e05b9a2-3b93-42b8-b526-93bf93597e69,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-5186e87d-6550-497d-9eb2-4b4ff8ac6051,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-81ec0828-11d5-4fba-a1a8-5d672ebed587,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-fdcb50f1-80ee-4194-b0fe-a42b9ef8d286,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-70402ce0-acc8-413f-8e57-28dbf4543401,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-153d5811-560c-471f-8aaa-d2b5d9d2fcd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-250293036-172.17.0.7-1597740026414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38951,DS-c563f5f4-98a4-4eec-8166-ddfb306fcd85,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-2a500afe-5d4f-4228-8456-0217adbfaaed,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-6e05b9a2-3b93-42b8-b526-93bf93597e69,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-5186e87d-6550-497d-9eb2-4b4ff8ac6051,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-81ec0828-11d5-4fba-a1a8-5d672ebed587,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-fdcb50f1-80ee-4194-b0fe-a42b9ef8d286,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-70402ce0-acc8-413f-8e57-28dbf4543401,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-153d5811-560c-471f-8aaa-d2b5d9d2fcd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-66979017-172.17.0.7-1597740115705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45538,DS-e8917d58-9a0a-44ba-bb39-dfbb225744eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-68a29cda-a401-49fe-b672-f5c1e45bb453,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-054d9fbe-05af-4157-aa99-452b11bd34f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-8ab7e0ef-ab85-475c-86d8-ee930d8409ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-1fa6aa77-a789-4b0d-ab8c-56c98fc734f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-2fb01fe4-697c-43f2-a5f9-e2c6e51e401e,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-59201a42-9a69-4a05-8df7-a3af3749959b,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-19e07109-f448-47e2-84ab-51cb52724cc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-66979017-172.17.0.7-1597740115705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45538,DS-e8917d58-9a0a-44ba-bb39-dfbb225744eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-68a29cda-a401-49fe-b672-f5c1e45bb453,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-054d9fbe-05af-4157-aa99-452b11bd34f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-8ab7e0ef-ab85-475c-86d8-ee930d8409ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-1fa6aa77-a789-4b0d-ab8c-56c98fc734f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-2fb01fe4-697c-43f2-a5f9-e2c6e51e401e,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-59201a42-9a69-4a05-8df7-a3af3749959b,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-19e07109-f448-47e2-84ab-51cb52724cc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-901796816-172.17.0.7-1597740342802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34733,DS-2e92862f-1ae8-4ca3-a8b7-e5ec92b0aeea,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-9c754f2e-625e-4ea0-8130-256defc7f36e,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-e067aaa8-fba5-42e6-b5b9-62260fcbec90,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-d00ae040-6e42-41ba-be92-5d8d8efea27b,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-7fdf27a7-2a84-4bf3-926f-5e1ae206641b,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-080ce87f-86f7-4156-a037-e8d3c78c7405,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-f96a7e90-f743-4579-b2d2-4b594eb04121,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-18ac60c6-5863-4b52-b517-c9f5d873b6aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-901796816-172.17.0.7-1597740342802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34733,DS-2e92862f-1ae8-4ca3-a8b7-e5ec92b0aeea,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-9c754f2e-625e-4ea0-8130-256defc7f36e,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-e067aaa8-fba5-42e6-b5b9-62260fcbec90,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-d00ae040-6e42-41ba-be92-5d8d8efea27b,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-7fdf27a7-2a84-4bf3-926f-5e1ae206641b,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-080ce87f-86f7-4156-a037-e8d3c78c7405,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-f96a7e90-f743-4579-b2d2-4b594eb04121,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-18ac60c6-5863-4b52-b517-c9f5d873b6aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1627455719-172.17.0.7-1597740850338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39471,DS-5c55b9b4-98ef-4aeb-807b-4b6db81f94fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-3c1affa0-2d9a-40f0-9368-1072b2f47e01,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-9fc35935-21f3-42c1-9a71-c74d493ba09e,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-629c6b14-2f16-4eaa-9a91-4fccd3d5e4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-0926bab0-19f2-4292-a916-337095033197,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-36212e92-1989-4eaf-9ca5-f1f00190d7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-130140eb-d2fb-4b7e-b75c-beb2f591519b,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-3f221069-2d7e-41db-87f9-456551c2a24e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1627455719-172.17.0.7-1597740850338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39471,DS-5c55b9b4-98ef-4aeb-807b-4b6db81f94fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-3c1affa0-2d9a-40f0-9368-1072b2f47e01,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-9fc35935-21f3-42c1-9a71-c74d493ba09e,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-629c6b14-2f16-4eaa-9a91-4fccd3d5e4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-0926bab0-19f2-4292-a916-337095033197,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-36212e92-1989-4eaf-9ca5-f1f00190d7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-130140eb-d2fb-4b7e-b75c-beb2f591519b,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-3f221069-2d7e-41db-87f9-456551c2a24e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961979001-172.17.0.7-1597740888478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36671,DS-0a66fec4-4cbd-46a9-a075-b5bab78618b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-89533132-91b9-4836-879d-2d25afad0f24,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-3a7fb25a-2660-42c2-87d2-c8a509f266f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-957d5037-5ae2-49be-a800-aa26e180c43c,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-6baad5c1-6344-413a-ac46-bf4c1dd2f16b,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-720abbed-1a95-40f9-9765-48d090d5a23f,DISK], DatanodeInfoWithStorage[127.0.0.1:38893,DS-a5d78462-4e02-4b43-84b5-9ddb4ee955b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-fe3e4a28-e918-4797-add1-92cb381298ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961979001-172.17.0.7-1597740888478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36671,DS-0a66fec4-4cbd-46a9-a075-b5bab78618b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-89533132-91b9-4836-879d-2d25afad0f24,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-3a7fb25a-2660-42c2-87d2-c8a509f266f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-957d5037-5ae2-49be-a800-aa26e180c43c,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-6baad5c1-6344-413a-ac46-bf4c1dd2f16b,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-720abbed-1a95-40f9-9765-48d090d5a23f,DISK], DatanodeInfoWithStorage[127.0.0.1:38893,DS-a5d78462-4e02-4b43-84b5-9ddb4ee955b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-fe3e4a28-e918-4797-add1-92cb381298ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058124963-172.17.0.7-1597740989161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36770,DS-6d4e15d4-3390-4148-8245-39b62b923278,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-32e12bbb-4265-4c0a-a98b-b845f56cfd09,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-4717ae39-e781-4fd2-bd3f-3333c6db23e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-77486fde-e676-4bc7-93c7-a51e86e64d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-65655972-f0e7-4b56-80f2-1de19672da60,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-4f4d2b1f-3917-4cc3-b232-7bbd2ccfba5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-fd008946-0e97-4aaf-942a-110b4bf80adf,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-d89feeae-a11b-48d8-86d2-afddc73e6faf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058124963-172.17.0.7-1597740989161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36770,DS-6d4e15d4-3390-4148-8245-39b62b923278,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-32e12bbb-4265-4c0a-a98b-b845f56cfd09,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-4717ae39-e781-4fd2-bd3f-3333c6db23e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-77486fde-e676-4bc7-93c7-a51e86e64d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-65655972-f0e7-4b56-80f2-1de19672da60,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-4f4d2b1f-3917-4cc3-b232-7bbd2ccfba5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-fd008946-0e97-4aaf-942a-110b4bf80adf,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-d89feeae-a11b-48d8-86d2-afddc73e6faf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-206310058-172.17.0.7-1597741193519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44201,DS-8becca01-a799-4f91-82f4-3e39bc0cfc45,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-6230a736-365e-4b2d-aa78-f19ce4bcaa87,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-c3c2cbb2-106f-4d48-b3b5-0bd32b165a58,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-0da1fa3d-b211-40cf-a367-bf595f5b420e,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-08b47818-545b-473a-8040-d13485e0f9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-65fa33c0-f8f6-4f2b-afbf-944fa57da381,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-cc53ad9f-f8da-4681-8aed-2ef4fe116672,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-10f90cdc-f5cf-4a0c-8eb6-7130290b7354,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-206310058-172.17.0.7-1597741193519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44201,DS-8becca01-a799-4f91-82f4-3e39bc0cfc45,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-6230a736-365e-4b2d-aa78-f19ce4bcaa87,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-c3c2cbb2-106f-4d48-b3b5-0bd32b165a58,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-0da1fa3d-b211-40cf-a367-bf595f5b420e,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-08b47818-545b-473a-8040-d13485e0f9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-65fa33c0-f8f6-4f2b-afbf-944fa57da381,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-cc53ad9f-f8da-4681-8aed-2ef4fe116672,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-10f90cdc-f5cf-4a0c-8eb6-7130290b7354,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278505716-172.17.0.7-1597741350095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38999,DS-f149ed5a-314f-4e64-af80-11d6b8599f09,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-2f26e63b-337d-4ff0-ad7f-7fa9f2b2d317,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-0a75a98e-12d8-4107-8a9a-5339d4b7ae9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-e7b8d04f-c879-4ba3-a20c-d67165e63d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-3a7161bb-a2e3-48a9-a978-8c7299c6e26f,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-34592dda-4d88-4829-99d7-4ea08a6aeb96,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-4fdd3088-fbcc-405a-95f5-171f931320c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-367e25f1-fd01-4dfc-b77f-bbd8274c1011,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278505716-172.17.0.7-1597741350095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38999,DS-f149ed5a-314f-4e64-af80-11d6b8599f09,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-2f26e63b-337d-4ff0-ad7f-7fa9f2b2d317,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-0a75a98e-12d8-4107-8a9a-5339d4b7ae9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-e7b8d04f-c879-4ba3-a20c-d67165e63d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-3a7161bb-a2e3-48a9-a978-8c7299c6e26f,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-34592dda-4d88-4829-99d7-4ea08a6aeb96,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-4fdd3088-fbcc-405a-95f5-171f931320c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-367e25f1-fd01-4dfc-b77f-bbd8274c1011,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-637387223-172.17.0.7-1597741580481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38411,DS-61200867-a3b7-4b6b-a526-a2dc25526dea,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-fc324021-d36a-4a50-bd4e-cc50e1392dec,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-10ec9c36-6630-428d-bd55-ce8aac85244a,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-c046ebad-0ea4-4cf7-836a-583b226995d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-92249bad-baf4-4392-95ed-e0a76c2d8948,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-7b6fb4af-3f9f-420b-a253-8f9c81aff37e,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-61fa3c86-ba62-412e-a894-30ebe1997e53,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-5526e2e1-a012-4acf-8a45-869c0005eab9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-637387223-172.17.0.7-1597741580481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38411,DS-61200867-a3b7-4b6b-a526-a2dc25526dea,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-fc324021-d36a-4a50-bd4e-cc50e1392dec,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-10ec9c36-6630-428d-bd55-ce8aac85244a,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-c046ebad-0ea4-4cf7-836a-583b226995d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-92249bad-baf4-4392-95ed-e0a76c2d8948,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-7b6fb4af-3f9f-420b-a253-8f9c81aff37e,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-61fa3c86-ba62-412e-a894-30ebe1997e53,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-5526e2e1-a012-4acf-8a45-869c0005eab9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-743673761-172.17.0.7-1597741632308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36352,DS-f61add5f-042a-4f34-85a2-564597c2a6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-66f492e9-dfe5-4f46-98be-a0a8c7979c63,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-e77b2146-aec5-450e-a7d8-14c96aebd484,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-f42878bf-1feb-4c37-9ac4-a50825111ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-21ca0f19-3fb0-449c-bd94-ab5960b75982,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-061f165e-495a-47b9-b86c-793e280131af,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-b9a581f2-3843-48b3-a1cd-460f635d45eb,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-3a3ea60a-e669-4d08-86b2-045019d36eb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-743673761-172.17.0.7-1597741632308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36352,DS-f61add5f-042a-4f34-85a2-564597c2a6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-66f492e9-dfe5-4f46-98be-a0a8c7979c63,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-e77b2146-aec5-450e-a7d8-14c96aebd484,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-f42878bf-1feb-4c37-9ac4-a50825111ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-21ca0f19-3fb0-449c-bd94-ab5960b75982,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-061f165e-495a-47b9-b86c-793e280131af,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-b9a581f2-3843-48b3-a1cd-460f635d45eb,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-3a3ea60a-e669-4d08-86b2-045019d36eb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510034632-172.17.0.7-1597741869168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42302,DS-49611e9f-4153-46a0-b8b8-0e7a69b0fb88,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-e32f39a6-42cf-4cfb-ac0c-f915df58e028,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-dbde3327-2d6e-4146-b380-4e23f341f1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-19f45766-8608-4ddf-b8fa-76c4669377f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-7823401c-9602-452b-ab22-531a33cffef8,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-3a04176c-e0ae-47de-8547-8443caace413,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-7befbc1a-2077-4726-a94e-04a8b1f9694d,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-18462b2a-7ebf-4c15-857b-e5be300d317b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510034632-172.17.0.7-1597741869168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42302,DS-49611e9f-4153-46a0-b8b8-0e7a69b0fb88,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-e32f39a6-42cf-4cfb-ac0c-f915df58e028,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-dbde3327-2d6e-4146-b380-4e23f341f1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-19f45766-8608-4ddf-b8fa-76c4669377f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-7823401c-9602-452b-ab22-531a33cffef8,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-3a04176c-e0ae-47de-8547-8443caace413,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-7befbc1a-2077-4726-a94e-04a8b1f9694d,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-18462b2a-7ebf-4c15-857b-e5be300d317b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1109717926-172.17.0.7-1597741907892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39213,DS-1eced569-c539-4c2e-b6ba-79305f00e47d,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-b4d26c5e-204c-4195-8e7f-d1ca3938884d,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-53c39a39-bcac-4dd7-9a75-21700df56221,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-5cafb0b7-46f8-46de-acd6-0564a038e3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-ae8b7d82-ac2d-4c0d-8204-866fb13c4826,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-0512fcf1-5664-4441-801b-19e89841a43e,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-53cadb85-24fe-420e-86f4-61cff97d11a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-1d0982e3-a831-447b-aaed-83636da71d98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1109717926-172.17.0.7-1597741907892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39213,DS-1eced569-c539-4c2e-b6ba-79305f00e47d,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-b4d26c5e-204c-4195-8e7f-d1ca3938884d,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-53c39a39-bcac-4dd7-9a75-21700df56221,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-5cafb0b7-46f8-46de-acd6-0564a038e3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-ae8b7d82-ac2d-4c0d-8204-866fb13c4826,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-0512fcf1-5664-4441-801b-19e89841a43e,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-53cadb85-24fe-420e-86f4-61cff97d11a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-1d0982e3-a831-447b-aaed-83636da71d98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361762723-172.17.0.7-1597742100567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41197,DS-5211da42-b9e8-44fc-8f30-2831a0a68435,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-99cd98f5-38a7-43db-aaf3-79169797f3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-ff1e47f3-369b-49df-ac2e-04a1dfcdeae3,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-6c36382d-05dd-4efe-97d7-0f75bd82a48c,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-15449fb5-ef25-4a57-9a10-ad1c87d8824d,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-f0a649c6-aeb6-41a9-95b5-87729368fb47,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-1c077475-fbb0-4539-8291-cbf1dc8a28cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-d66d2948-94f8-4796-a70b-c0ff2267522b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361762723-172.17.0.7-1597742100567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41197,DS-5211da42-b9e8-44fc-8f30-2831a0a68435,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-99cd98f5-38a7-43db-aaf3-79169797f3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-ff1e47f3-369b-49df-ac2e-04a1dfcdeae3,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-6c36382d-05dd-4efe-97d7-0f75bd82a48c,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-15449fb5-ef25-4a57-9a10-ad1c87d8824d,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-f0a649c6-aeb6-41a9-95b5-87729368fb47,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-1c077475-fbb0-4539-8291-cbf1dc8a28cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-d66d2948-94f8-4796-a70b-c0ff2267522b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2111594190-172.17.0.7-1597742148982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45731,DS-0dbaa813-f428-4d8c-ba89-f969c21ff10c,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-b0a2e096-c6fd-4ced-8e96-ed433abdfc16,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-eeadd9bc-e6b1-4d87-a93c-d93313fc5d39,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-bc38c85d-d292-4e26-ab41-b0fdc3147ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-3b89925f-3f8a-4ed2-8851-1d2474bcd3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-b270b878-48b5-4e15-a776-6880fe9b56a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-50a663d9-b28a-4460-aca3-7cf0ec6aa01e,DISK], DatanodeInfoWithStorage[127.0.0.1:40127,DS-1e56445a-59cd-4f18-a1af-b1fd9efac6d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2111594190-172.17.0.7-1597742148982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45731,DS-0dbaa813-f428-4d8c-ba89-f969c21ff10c,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-b0a2e096-c6fd-4ced-8e96-ed433abdfc16,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-eeadd9bc-e6b1-4d87-a93c-d93313fc5d39,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-bc38c85d-d292-4e26-ab41-b0fdc3147ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-3b89925f-3f8a-4ed2-8851-1d2474bcd3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-b270b878-48b5-4e15-a776-6880fe9b56a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-50a663d9-b28a-4460-aca3-7cf0ec6aa01e,DISK], DatanodeInfoWithStorage[127.0.0.1:40127,DS-1e56445a-59cd-4f18-a1af-b1fd9efac6d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-712022947-172.17.0.7-1597742281044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41099,DS-11aeddfd-5e22-4411-908e-f28c9998e19d,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-a64da39a-33e3-450c-80fe-b7ccfc13b99b,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-dc19e09f-0e6a-4cd0-a53e-40af91e1c4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-c77a363d-e45d-471c-9c17-f9fcaf5a5742,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-3b7ac160-ef39-4c5c-9510-9892141dc785,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-1dacd104-3d0a-4c92-9c23-2d675b7bf473,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-ee5d2229-3e5c-4e64-aa86-54adeedfdefa,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-17cd15c3-f316-4997-8c1b-207e791cbd62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-712022947-172.17.0.7-1597742281044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41099,DS-11aeddfd-5e22-4411-908e-f28c9998e19d,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-a64da39a-33e3-450c-80fe-b7ccfc13b99b,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-dc19e09f-0e6a-4cd0-a53e-40af91e1c4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-c77a363d-e45d-471c-9c17-f9fcaf5a5742,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-3b7ac160-ef39-4c5c-9510-9892141dc785,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-1dacd104-3d0a-4c92-9c23-2d675b7bf473,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-ee5d2229-3e5c-4e64-aa86-54adeedfdefa,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-17cd15c3-f316-4997-8c1b-207e791cbd62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-256479222-172.17.0.7-1597742426804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43027,DS-7bde067b-6003-49c5-8777-cd89ae65cc26,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-fb8cef3c-0d36-48b6-801d-4a149d83eafe,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-af66dee6-5488-4bc7-9d9f-1effca84211e,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-3c6a359e-caa1-4141-877a-d11040e99c59,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-205e892e-c323-4dbb-868b-10d985e52c26,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-717cd4f6-4dc6-478f-924d-06039885d11f,DISK], DatanodeInfoWithStorage[127.0.0.1:33452,DS-077c284f-668f-40e0-8d02-580b354324aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-7b2db263-9344-4eb0-8dd5-d1558fdb3031,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-256479222-172.17.0.7-1597742426804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43027,DS-7bde067b-6003-49c5-8777-cd89ae65cc26,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-fb8cef3c-0d36-48b6-801d-4a149d83eafe,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-af66dee6-5488-4bc7-9d9f-1effca84211e,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-3c6a359e-caa1-4141-877a-d11040e99c59,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-205e892e-c323-4dbb-868b-10d985e52c26,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-717cd4f6-4dc6-478f-924d-06039885d11f,DISK], DatanodeInfoWithStorage[127.0.0.1:33452,DS-077c284f-668f-40e0-8d02-580b354324aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-7b2db263-9344-4eb0-8dd5-d1558fdb3031,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 15 out of 50
v1v1v2v2 failed with probability 23 out of 50
result: false positive !!!
Total execution time in seconds : 6884
