reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 64
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 64
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-612859044-172.17.0.14-1597479529511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43285,DS-f2bb6cec-7939-4fef-9552-4e0dfb4b06bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-2b2482fb-b2bb-4159-a553-78e81e4185fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-e73fd070-4f6d-45bf-bd25-a15932a88e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-32f80d19-f97e-42af-a744-844d7ab768b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-f938eed4-b3d9-4026-8bf2-cc45a1c124d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-52ec6056-134c-4187-bf82-f4cfd74c1dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-bd48847f-33c7-4af5-ac64-a12cf47f92a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-07624271-45ec-4198-94d1-eeba63291575,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-612859044-172.17.0.14-1597479529511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43285,DS-f2bb6cec-7939-4fef-9552-4e0dfb4b06bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-2b2482fb-b2bb-4159-a553-78e81e4185fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-e73fd070-4f6d-45bf-bd25-a15932a88e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-32f80d19-f97e-42af-a744-844d7ab768b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-f938eed4-b3d9-4026-8bf2-cc45a1c124d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-52ec6056-134c-4187-bf82-f4cfd74c1dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-bd48847f-33c7-4af5-ac64-a12cf47f92a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-07624271-45ec-4198-94d1-eeba63291575,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 64
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1109684069-172.17.0.14-1597479572786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42151,DS-34803e32-c34f-46ce-b6ae-a7b388099192,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-fd41302c-1961-455b-87ef-2aa8f1b28a75,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-aeab98c3-8722-407c-a032-ed26e6c36657,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-8a686c49-81ae-47f4-a322-e69e15526f29,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-b3cd3cc6-c4ff-413c-b638-e182b0cb661f,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-58c79bd7-8b30-4f22-b2d5-0ba98df5405b,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-379868cf-ae84-43cf-b7e1-e03bd62e9d12,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-0dec79cb-04ea-4c8f-9873-c446ed1d1d1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1109684069-172.17.0.14-1597479572786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42151,DS-34803e32-c34f-46ce-b6ae-a7b388099192,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-fd41302c-1961-455b-87ef-2aa8f1b28a75,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-aeab98c3-8722-407c-a032-ed26e6c36657,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-8a686c49-81ae-47f4-a322-e69e15526f29,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-b3cd3cc6-c4ff-413c-b638-e182b0cb661f,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-58c79bd7-8b30-4f22-b2d5-0ba98df5405b,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-379868cf-ae84-43cf-b7e1-e03bd62e9d12,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-0dec79cb-04ea-4c8f-9873-c446ed1d1d1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 64
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1148287426-172.17.0.14-1597479684314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35330,DS-9ffdc279-03ad-49b7-9dd7-eb3c07bb042e,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-5fb888fc-1146-47d5-8f9b-c5896f734e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-04d21858-1e4a-4815-b142-f99704b6243c,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-895e0c11-1ba6-4b94-8621-b9c30d974697,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-20a3f77d-a7f9-45f8-abdc-95f89a16119a,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-bfc79feb-0249-4d2c-bc1f-6cea4c3b0d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-062b17b1-94f9-40c2-98e1-68a4d82b715c,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-b8d9ccd3-a8e6-4fc8-ad9b-f5efdb11fa0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1148287426-172.17.0.14-1597479684314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35330,DS-9ffdc279-03ad-49b7-9dd7-eb3c07bb042e,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-5fb888fc-1146-47d5-8f9b-c5896f734e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-04d21858-1e4a-4815-b142-f99704b6243c,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-895e0c11-1ba6-4b94-8621-b9c30d974697,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-20a3f77d-a7f9-45f8-abdc-95f89a16119a,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-bfc79feb-0249-4d2c-bc1f-6cea4c3b0d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-062b17b1-94f9-40c2-98e1-68a4d82b715c,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-b8d9ccd3-a8e6-4fc8-ad9b-f5efdb11fa0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 64
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1797305071-172.17.0.14-1597480147942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39423,DS-fd151a88-b196-4938-a5e4-7762b6f4086f,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-0939cb1a-c9b9-4d10-8af0-55a129240400,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-ecc1bcb9-3c18-4147-8c5d-b8ad60d026fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-290e86c1-1ebe-4c22-ac44-160d26795209,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-05ca121a-d149-4483-bd22-c51d259fbc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-df63082e-9ad1-438c-9306-232d055145b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-29abd701-e4a5-4933-8785-9eb429c0e560,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-88bb5e38-a186-4e2d-a15c-410c49a9de77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1797305071-172.17.0.14-1597480147942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39423,DS-fd151a88-b196-4938-a5e4-7762b6f4086f,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-0939cb1a-c9b9-4d10-8af0-55a129240400,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-ecc1bcb9-3c18-4147-8c5d-b8ad60d026fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-290e86c1-1ebe-4c22-ac44-160d26795209,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-05ca121a-d149-4483-bd22-c51d259fbc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-df63082e-9ad1-438c-9306-232d055145b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-29abd701-e4a5-4933-8785-9eb429c0e560,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-88bb5e38-a186-4e2d-a15c-410c49a9de77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 64
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1568179079-172.17.0.14-1597480488893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43533,DS-fc869cab-84ea-4e1c-ac3f-f26284c50761,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-ebf985e3-2b3c-4caf-a862-973421b16e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-ff19308f-9b5c-4a15-9bda-30f63ecc0fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-bb554b6b-2d72-4f4e-b2ea-f9db2cb1f586,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-146499c0-e731-4cda-a140-8b017fe03dce,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-7150f4a5-7ee4-444c-9496-7e1c6fdc4b03,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-95842754-c763-47f2-882e-5f741f111b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-c1bbafcf-b4e7-454e-9bed-c1a7b6dd282e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1568179079-172.17.0.14-1597480488893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43533,DS-fc869cab-84ea-4e1c-ac3f-f26284c50761,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-ebf985e3-2b3c-4caf-a862-973421b16e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-ff19308f-9b5c-4a15-9bda-30f63ecc0fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-bb554b6b-2d72-4f4e-b2ea-f9db2cb1f586,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-146499c0-e731-4cda-a140-8b017fe03dce,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-7150f4a5-7ee4-444c-9496-7e1c6fdc4b03,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-95842754-c763-47f2-882e-5f741f111b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-c1bbafcf-b4e7-454e-9bed-c1a7b6dd282e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 64
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-586635695-172.17.0.14-1597480751172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38087,DS-1711ad43-0689-4e5a-b5d1-9040c1a4dffc,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-8f863179-684d-42b5-9f43-0ea22b5e4358,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-c50cbbaf-b275-4f04-af74-8eb2922ccf78,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-4d3e4aac-df72-4d99-aed2-eff555bbd530,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-b3c44e75-f89c-469e-a1cb-fd396c85a2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-9ed8770b-d321-411a-8645-72a407cfb261,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-6a548489-d113-472d-9c25-b042ddc9a743,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-407e813d-1dac-4c7e-977f-efcfa11c6cd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-586635695-172.17.0.14-1597480751172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38087,DS-1711ad43-0689-4e5a-b5d1-9040c1a4dffc,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-8f863179-684d-42b5-9f43-0ea22b5e4358,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-c50cbbaf-b275-4f04-af74-8eb2922ccf78,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-4d3e4aac-df72-4d99-aed2-eff555bbd530,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-b3c44e75-f89c-469e-a1cb-fd396c85a2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-9ed8770b-d321-411a-8645-72a407cfb261,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-6a548489-d113-472d-9c25-b042ddc9a743,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-407e813d-1dac-4c7e-977f-efcfa11c6cd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 64
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1199541853-172.17.0.14-1597480857213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37552,DS-2e2e93d8-1e84-4e09-bf48-85fafcace74d,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-63800b98-6a55-4399-8a6c-18c4f2047a80,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-eddc490f-f83e-463e-b61f-ccc74fdb36c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-d2c628bc-88db-4579-94e1-1180b92ce674,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-54931e47-6e42-4bab-991e-5dae779fcd93,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-70d95a5e-e839-499b-82b0-b3c4ba951bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-f96ac4f2-6b98-41ac-8006-9237db71ac65,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-8999b474-d290-4bad-bb7c-619bb9339533,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1199541853-172.17.0.14-1597480857213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37552,DS-2e2e93d8-1e84-4e09-bf48-85fafcace74d,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-63800b98-6a55-4399-8a6c-18c4f2047a80,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-eddc490f-f83e-463e-b61f-ccc74fdb36c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-d2c628bc-88db-4579-94e1-1180b92ce674,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-54931e47-6e42-4bab-991e-5dae779fcd93,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-70d95a5e-e839-499b-82b0-b3c4ba951bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-f96ac4f2-6b98-41ac-8006-9237db71ac65,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-8999b474-d290-4bad-bb7c-619bb9339533,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 64
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-618869517-172.17.0.14-1597481090422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36011,DS-9162da07-2c5e-4ce7-9d25-7c6c7c5f300d,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-cf5f22a9-68bb-4f5e-bd90-7f0644807a66,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-43dc0a24-a407-425d-afc0-d3718202a0db,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-72c0bec2-9e42-4210-8919-a9f48aa94bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-8da13cfc-e9a3-472c-9ac6-6a9de5253e67,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-a90c192f-b22d-4c30-bc03-29228a2b53d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-18325d79-0b24-4aa7-9e86-8ef8433a63c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-e49112df-a33f-4e64-88ea-b6c285d477c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-618869517-172.17.0.14-1597481090422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36011,DS-9162da07-2c5e-4ce7-9d25-7c6c7c5f300d,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-cf5f22a9-68bb-4f5e-bd90-7f0644807a66,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-43dc0a24-a407-425d-afc0-d3718202a0db,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-72c0bec2-9e42-4210-8919-a9f48aa94bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-8da13cfc-e9a3-472c-9ac6-6a9de5253e67,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-a90c192f-b22d-4c30-bc03-29228a2b53d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-18325d79-0b24-4aa7-9e86-8ef8433a63c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-e49112df-a33f-4e64-88ea-b6c285d477c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 64
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680770969-172.17.0.14-1597481249347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45068,DS-ed0a13a1-a988-4b9b-9a37-159a4b38275c,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-d6392676-35f6-4937-926f-4f5af04ea43f,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-bead3909-ddc9-446f-a4ba-67b5d1b997bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-015da4d3-2488-4a76-af24-7d24c5efdecc,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-89bcfadd-bb84-4269-9ce4-4ac4ac30a73a,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-69ae8416-4fee-4bb4-9e61-a82ee28bd427,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-d68581ab-20c4-4212-a650-a28338076395,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-a716d57d-8cc4-4fb6-90bc-24513884b4c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680770969-172.17.0.14-1597481249347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45068,DS-ed0a13a1-a988-4b9b-9a37-159a4b38275c,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-d6392676-35f6-4937-926f-4f5af04ea43f,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-bead3909-ddc9-446f-a4ba-67b5d1b997bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-015da4d3-2488-4a76-af24-7d24c5efdecc,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-89bcfadd-bb84-4269-9ce4-4ac4ac30a73a,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-69ae8416-4fee-4bb4-9e61-a82ee28bd427,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-d68581ab-20c4-4212-a650-a28338076395,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-a716d57d-8cc4-4fb6-90bc-24513884b4c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 64
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066539616-172.17.0.14-1597481791682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41483,DS-79271bf2-3d49-46d6-9581-e0324f5e4df1,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-ac9d69a2-bfcf-4d3e-8032-a74355109aee,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-0537a9c1-eb03-4f32-8f92-83cef57ce25a,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-84acc671-36a8-46d6-945a-444390b8f14d,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-bcb31455-7021-42c5-b214-0f05249505be,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-fc279bd7-6baa-4551-b12c-a7f41cf41dba,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-cb5ce1dd-e57e-4b94-81cc-25a92278bbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-42964986-93a5-43e2-9972-6b1731afbc72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066539616-172.17.0.14-1597481791682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41483,DS-79271bf2-3d49-46d6-9581-e0324f5e4df1,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-ac9d69a2-bfcf-4d3e-8032-a74355109aee,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-0537a9c1-eb03-4f32-8f92-83cef57ce25a,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-84acc671-36a8-46d6-945a-444390b8f14d,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-bcb31455-7021-42c5-b214-0f05249505be,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-fc279bd7-6baa-4551-b12c-a7f41cf41dba,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-cb5ce1dd-e57e-4b94-81cc-25a92278bbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-42964986-93a5-43e2-9972-6b1731afbc72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 64
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1996821037-172.17.0.14-1597481899430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33315,DS-10e91c6e-6854-45d4-9ab6-2eba54e479a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-491b7d06-5ac3-4381-b9b0-8c9c844ab184,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-dd996e2d-60d4-4aad-ae8e-8af03e3ee149,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-e1cd2d5b-0744-46c5-8654-2cab6900dc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-19ac9d61-0f91-4450-98ad-aed432fb0909,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-05f1aa47-17b2-4d56-949b-0ee7805ff395,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-6963a96d-fa79-4ddf-b019-233b8ead5097,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-a94c1afe-b433-430a-a18c-32a8fe9b66ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1996821037-172.17.0.14-1597481899430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33315,DS-10e91c6e-6854-45d4-9ab6-2eba54e479a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-491b7d06-5ac3-4381-b9b0-8c9c844ab184,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-dd996e2d-60d4-4aad-ae8e-8af03e3ee149,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-e1cd2d5b-0744-46c5-8654-2cab6900dc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-19ac9d61-0f91-4450-98ad-aed432fb0909,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-05f1aa47-17b2-4d56-949b-0ee7805ff395,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-6963a96d-fa79-4ddf-b019-233b8ead5097,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-a94c1afe-b433-430a-a18c-32a8fe9b66ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 64
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1149837286-172.17.0.14-1597482112960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38817,DS-cbb56429-85ec-48ac-9d2e-e6cfb9349fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-d9863ca1-0193-4434-91ac-7a0c13dfe373,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-502841c7-5178-4b01-b41d-d4c73005d8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-7f0f81de-1c14-4946-b2fa-5bc7fa853bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-73dd0d33-47f4-4132-9a41-f931d49d007c,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-369bbba5-30a7-4d59-b22f-d4c6a9f12688,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-4a3b51fe-d852-433e-9378-78eb2866260b,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-b5c004f3-053b-40d6-8474-406f8e7b800e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1149837286-172.17.0.14-1597482112960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38817,DS-cbb56429-85ec-48ac-9d2e-e6cfb9349fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-d9863ca1-0193-4434-91ac-7a0c13dfe373,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-502841c7-5178-4b01-b41d-d4c73005d8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-7f0f81de-1c14-4946-b2fa-5bc7fa853bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-73dd0d33-47f4-4132-9a41-f931d49d007c,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-369bbba5-30a7-4d59-b22f-d4c6a9f12688,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-4a3b51fe-d852-433e-9378-78eb2866260b,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-b5c004f3-053b-40d6-8474-406f8e7b800e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 64
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-567971679-172.17.0.14-1597482345716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35681,DS-92739b89-2390-4bb1-972e-dc23659d3fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-cced7b1b-e491-49f5-a107-d6aaa76397d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-32404cf4-3873-4f63-89a7-47ce75c4a000,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-496d0779-106f-4148-b942-1d962fd1c4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-0d55879e-4b32-438f-a06e-cb091e6bffc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-4a1d1c85-2406-4cf2-98e5-f7c0cb3f7faa,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-7b6a39f7-ee04-40d3-80dd-8ee2401db41f,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-46ddfa0b-ee5b-4fb0-9f39-73e0ef12f03c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-567971679-172.17.0.14-1597482345716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35681,DS-92739b89-2390-4bb1-972e-dc23659d3fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-cced7b1b-e491-49f5-a107-d6aaa76397d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-32404cf4-3873-4f63-89a7-47ce75c4a000,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-496d0779-106f-4148-b942-1d962fd1c4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-0d55879e-4b32-438f-a06e-cb091e6bffc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-4a1d1c85-2406-4cf2-98e5-f7c0cb3f7faa,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-7b6a39f7-ee04-40d3-80dd-8ee2401db41f,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-46ddfa0b-ee5b-4fb0-9f39-73e0ef12f03c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 64
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-345328199-172.17.0.14-1597482492283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36082,DS-9a78ec61-d7ce-45dc-94da-43502dcfd22e,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-f08bb988-9eec-4a2e-a18c-e72ccd08138c,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-1e753e38-c1c0-4886-a39d-a44cfc5c5d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-d9af25e5-15b1-4aec-bf06-2f658e1c2d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-3dc2cfd8-6838-4424-a52f-299a23b9ed1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-dd93efb6-bb8a-48b2-b4b2-0121dc74b269,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-d6042e12-d49c-4aa6-912c-d217ae1c614d,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-a4186188-bce0-487d-9e3b-ada0fe22b509,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-345328199-172.17.0.14-1597482492283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36082,DS-9a78ec61-d7ce-45dc-94da-43502dcfd22e,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-f08bb988-9eec-4a2e-a18c-e72ccd08138c,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-1e753e38-c1c0-4886-a39d-a44cfc5c5d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-d9af25e5-15b1-4aec-bf06-2f658e1c2d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-3dc2cfd8-6838-4424-a52f-299a23b9ed1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-dd93efb6-bb8a-48b2-b4b2-0121dc74b269,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-d6042e12-d49c-4aa6-912c-d217ae1c614d,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-a4186188-bce0-487d-9e3b-ada0fe22b509,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 64
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-165154535-172.17.0.14-1597482787286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45514,DS-d35eae86-b2ff-463a-8662-0c0ead41f47b,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-0e659d31-19e7-463a-ae30-38bd610e90d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-208bfc82-b751-4a7f-9da2-f0c51afc0a98,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-e5ae3834-302d-492d-bce9-04113765ed55,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-37228721-bd41-481b-bf5a-04583d6f1c56,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-9577878b-7d31-48ca-b199-8a9feb7af182,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-1a2c5ea8-a0f2-4cb1-857f-df853e853622,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-7b41df0c-5a0c-4f65-9ecf-7910a110f4d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-165154535-172.17.0.14-1597482787286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45514,DS-d35eae86-b2ff-463a-8662-0c0ead41f47b,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-0e659d31-19e7-463a-ae30-38bd610e90d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-208bfc82-b751-4a7f-9da2-f0c51afc0a98,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-e5ae3834-302d-492d-bce9-04113765ed55,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-37228721-bd41-481b-bf5a-04583d6f1c56,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-9577878b-7d31-48ca-b199-8a9feb7af182,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-1a2c5ea8-a0f2-4cb1-857f-df853e853622,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-7b41df0c-5a0c-4f65-9ecf-7910a110f4d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 64
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1449400614-172.17.0.14-1597483315008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38238,DS-1039ac18-11f9-443a-ac0d-87a5258212fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-2d4d9a4b-02f8-4d5f-b8f6-ce4a14eebd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-4b838921-e56f-48f7-859e-6655b35f0975,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-68e1797d-5c1b-48e7-bce0-fe99d46e7d10,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-57a0e516-358a-44a8-a089-037ee5758af8,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-ca8b2ac6-8a12-439c-b8fb-70df6bf47584,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-e1b1ec7b-93f3-4e54-bb8f-c360d21d4b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-c6c27fdf-9199-40d3-bd9f-69550aab81c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1449400614-172.17.0.14-1597483315008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38238,DS-1039ac18-11f9-443a-ac0d-87a5258212fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-2d4d9a4b-02f8-4d5f-b8f6-ce4a14eebd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-4b838921-e56f-48f7-859e-6655b35f0975,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-68e1797d-5c1b-48e7-bce0-fe99d46e7d10,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-57a0e516-358a-44a8-a089-037ee5758af8,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-ca8b2ac6-8a12-439c-b8fb-70df6bf47584,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-e1b1ec7b-93f3-4e54-bb8f-c360d21d4b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-c6c27fdf-9199-40d3-bd9f-69550aab81c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 64
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-177926926-172.17.0.14-1597483643980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39107,DS-0ac80dfb-b9a9-47f9-8567-e62edb737be8,DISK], DatanodeInfoWithStorage[127.0.0.1:46405,DS-bb2c95d1-c817-4677-8e94-19a822d851f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-7374fa50-eba1-4ac8-bdcf-eff051c7b0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-de49bce3-85a3-4e08-88e4-cf1efd980c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-39643740-543d-4ac9-a12d-e46e8bdfed72,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-d5f561d3-6492-42c1-a5f3-917bae4bbf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-ad6e6cde-0146-4958-9396-1673629925d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-a8cc1268-4c48-44de-a4ca-b34c210c70b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-177926926-172.17.0.14-1597483643980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39107,DS-0ac80dfb-b9a9-47f9-8567-e62edb737be8,DISK], DatanodeInfoWithStorage[127.0.0.1:46405,DS-bb2c95d1-c817-4677-8e94-19a822d851f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-7374fa50-eba1-4ac8-bdcf-eff051c7b0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-de49bce3-85a3-4e08-88e4-cf1efd980c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-39643740-543d-4ac9-a12d-e46e8bdfed72,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-d5f561d3-6492-42c1-a5f3-917bae4bbf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-ad6e6cde-0146-4958-9396-1673629925d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-a8cc1268-4c48-44de-a4ca-b34c210c70b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 64
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-42765271-172.17.0.14-1597483908674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39458,DS-970b6de2-9289-44fc-9dab-749c83419143,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-b17de336-700d-416b-a66d-1c0c3275f0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44306,DS-bb46cc48-92d0-4d34-b0f4-010588f48efb,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-0a53e3e0-9a41-4854-83ac-a0280bbc643d,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-a2c26ff9-b8ad-4d51-ba21-8a867f6aa49e,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-fbed4654-a56a-475b-a712-466627880e36,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-ad2c3ce0-b7da-4bf3-b78e-8bb3056bde4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-1cbc967d-4761-46d2-9928-5b66d02659e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-42765271-172.17.0.14-1597483908674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39458,DS-970b6de2-9289-44fc-9dab-749c83419143,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-b17de336-700d-416b-a66d-1c0c3275f0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44306,DS-bb46cc48-92d0-4d34-b0f4-010588f48efb,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-0a53e3e0-9a41-4854-83ac-a0280bbc643d,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-a2c26ff9-b8ad-4d51-ba21-8a867f6aa49e,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-fbed4654-a56a-475b-a712-466627880e36,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-ad2c3ce0-b7da-4bf3-b78e-8bb3056bde4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-1cbc967d-4761-46d2-9928-5b66d02659e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: might be true error
Total execution time in seconds : 5546
