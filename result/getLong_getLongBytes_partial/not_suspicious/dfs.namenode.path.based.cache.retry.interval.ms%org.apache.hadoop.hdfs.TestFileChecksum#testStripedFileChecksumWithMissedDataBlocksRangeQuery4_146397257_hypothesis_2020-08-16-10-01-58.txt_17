reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-221403799-172.17.0.19-1597572135184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37187,DS-ec10dff2-3067-4604-854b-8b01e5c1395b,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-8de2410f-ab68-407b-b8f9-83e67c57e832,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-e58f55b9-f4d2-409f-8422-248fac0ec136,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-7b2c89e9-66ec-4514-b062-c91b2929bf76,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-b33507fa-6dfb-4a37-86b2-6ae780e50c39,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-feeb77a4-4c0e-4da5-b607-8e13298bf285,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-88397593-dcf3-413c-9479-d6a7fa760385,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-3bb9b615-2e18-4455-9e9a-6b7daab36196,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-221403799-172.17.0.19-1597572135184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37187,DS-ec10dff2-3067-4604-854b-8b01e5c1395b,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-8de2410f-ab68-407b-b8f9-83e67c57e832,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-e58f55b9-f4d2-409f-8422-248fac0ec136,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-7b2c89e9-66ec-4514-b062-c91b2929bf76,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-b33507fa-6dfb-4a37-86b2-6ae780e50c39,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-feeb77a4-4c0e-4da5-b607-8e13298bf285,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-88397593-dcf3-413c-9479-d6a7fa760385,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-3bb9b615-2e18-4455-9e9a-6b7daab36196,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049123851-172.17.0.19-1597572527562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46079,DS-144bcda4-a42d-45ef-bf9f-fb760bcbff38,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-7efd452f-ed3c-4f70-944b-a1e8f7fbcee8,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-c0cbf5bc-ef11-48a9-b14b-aa59fe61ff86,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-3858f12d-9abf-4e41-8ae0-0a87a90d3c81,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-ee092418-c320-47ae-b2af-1ab88e75b4db,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-629bf229-8808-41e2-a7ca-e85cda5297e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-f16ed9c8-f6a3-4177-bb39-25b940cc08a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-e4513210-c860-419d-9de2-61616b0d2f1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049123851-172.17.0.19-1597572527562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46079,DS-144bcda4-a42d-45ef-bf9f-fb760bcbff38,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-7efd452f-ed3c-4f70-944b-a1e8f7fbcee8,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-c0cbf5bc-ef11-48a9-b14b-aa59fe61ff86,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-3858f12d-9abf-4e41-8ae0-0a87a90d3c81,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-ee092418-c320-47ae-b2af-1ab88e75b4db,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-629bf229-8808-41e2-a7ca-e85cda5297e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-f16ed9c8-f6a3-4177-bb39-25b940cc08a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-e4513210-c860-419d-9de2-61616b0d2f1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-500409366-172.17.0.19-1597572646216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45189,DS-c352049f-5875-4bf3-96b1-3b1a228cc55a,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-28b81357-3d18-4a0c-9aee-60b9272366df,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-5cc4cedb-56c5-47c0-bdb3-1c39eb439ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-0f3dac13-928e-4693-bab5-9c9140d6be55,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-d7a36c7e-bb30-40f1-83c8-8a1911b9f603,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-aeec7188-a9c0-4524-a65b-8e1ec68810ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-43b72f2c-fce7-4d94-80dc-1e7f49761e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-07ff8c2b-864d-4082-bc27-c6f897914566,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-500409366-172.17.0.19-1597572646216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45189,DS-c352049f-5875-4bf3-96b1-3b1a228cc55a,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-28b81357-3d18-4a0c-9aee-60b9272366df,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-5cc4cedb-56c5-47c0-bdb3-1c39eb439ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-0f3dac13-928e-4693-bab5-9c9140d6be55,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-d7a36c7e-bb30-40f1-83c8-8a1911b9f603,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-aeec7188-a9c0-4524-a65b-8e1ec68810ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-43b72f2c-fce7-4d94-80dc-1e7f49761e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-07ff8c2b-864d-4082-bc27-c6f897914566,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1228428801-172.17.0.19-1597572887096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45724,DS-a54565df-1d90-43dd-8000-7c613580d2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-3b0a00fe-8298-48c9-b925-2577c4980312,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-1b0d2ad6-b16d-48c2-bf2b-6ef86a2ceff6,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-e5b1cedb-edad-4c19-8cfa-45fc8ed92419,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-92d01df2-cbf6-4d29-80fa-66936d2a4900,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-05a38cd7-0445-4ad7-b2ad-a48b7eafcd62,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-391c210b-3476-48be-8584-0527e95fbd07,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-3ab8ac11-3e3c-4c3b-8590-11587481150f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1228428801-172.17.0.19-1597572887096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45724,DS-a54565df-1d90-43dd-8000-7c613580d2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-3b0a00fe-8298-48c9-b925-2577c4980312,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-1b0d2ad6-b16d-48c2-bf2b-6ef86a2ceff6,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-e5b1cedb-edad-4c19-8cfa-45fc8ed92419,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-92d01df2-cbf6-4d29-80fa-66936d2a4900,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-05a38cd7-0445-4ad7-b2ad-a48b7eafcd62,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-391c210b-3476-48be-8584-0527e95fbd07,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-3ab8ac11-3e3c-4c3b-8590-11587481150f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344755436-172.17.0.19-1597573134950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36793,DS-da007877-96b1-4496-887e-be35ca418675,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-6a270f6b-dd66-4710-a7ea-49a004949a83,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-04bfe41c-eb31-4b2b-9b45-609d2a6dbd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-e57ee245-9e8c-446a-995d-e123fdd0a919,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-4676d131-140e-4a36-973e-73b65afb56e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-8a53b7df-1365-4965-97d2-1d6754b244a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-4dbf245d-d72d-4e2f-b391-5fe4baf0702a,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-1f15f269-cdc4-49c1-a449-1ae6f37c4eb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344755436-172.17.0.19-1597573134950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36793,DS-da007877-96b1-4496-887e-be35ca418675,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-6a270f6b-dd66-4710-a7ea-49a004949a83,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-04bfe41c-eb31-4b2b-9b45-609d2a6dbd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-e57ee245-9e8c-446a-995d-e123fdd0a919,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-4676d131-140e-4a36-973e-73b65afb56e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-8a53b7df-1365-4965-97d2-1d6754b244a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-4dbf245d-d72d-4e2f-b391-5fe4baf0702a,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-1f15f269-cdc4-49c1-a449-1ae6f37c4eb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1379683360-172.17.0.19-1597573547438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33870,DS-88acb49f-07c5-43e1-8b86-3040326a100b,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-8bb6c563-574d-440b-a52e-bc7b151c2bef,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-efa457fa-057c-4beb-9427-bdb5238241c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-343b53bb-1740-495a-a8f3-1d8512094a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-8ad4c696-a926-4a50-b9b4-ab40192b68f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-d3c10c4b-379e-485e-865a-6b724f8e4fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-92848302-b8e3-4d44-8c7e-4ed195c18990,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-c681acb8-8a49-4f00-9eac-eef5cc1b73e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1379683360-172.17.0.19-1597573547438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33870,DS-88acb49f-07c5-43e1-8b86-3040326a100b,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-8bb6c563-574d-440b-a52e-bc7b151c2bef,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-efa457fa-057c-4beb-9427-bdb5238241c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-343b53bb-1740-495a-a8f3-1d8512094a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-8ad4c696-a926-4a50-b9b4-ab40192b68f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-d3c10c4b-379e-485e-865a-6b724f8e4fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-92848302-b8e3-4d44-8c7e-4ed195c18990,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-c681acb8-8a49-4f00-9eac-eef5cc1b73e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211068653-172.17.0.19-1597573826135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34996,DS-58773518-c739-4a5f-a7ac-6f0a7e37618a,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-18014aed-0862-4a29-9cb4-e5d325e7eb45,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-e3b83a88-d8a7-46e4-9702-ab76ca46d776,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-6610867e-be27-44c0-a6d5-fbcfc8a1f8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-8ba15617-37d1-4e9f-817e-6684d391d33c,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-20f9ec57-762d-41d3-994e-8ceb66dc9a42,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-ef7d2fc4-f581-49ea-a369-6bfee078e88f,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-a4862f33-1084-4822-bb89-977654d30c2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211068653-172.17.0.19-1597573826135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34996,DS-58773518-c739-4a5f-a7ac-6f0a7e37618a,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-18014aed-0862-4a29-9cb4-e5d325e7eb45,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-e3b83a88-d8a7-46e4-9702-ab76ca46d776,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-6610867e-be27-44c0-a6d5-fbcfc8a1f8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-8ba15617-37d1-4e9f-817e-6684d391d33c,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-20f9ec57-762d-41d3-994e-8ceb66dc9a42,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-ef7d2fc4-f581-49ea-a369-6bfee078e88f,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-a4862f33-1084-4822-bb89-977654d30c2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165574729-172.17.0.19-1597573859770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41157,DS-35516b69-aae2-46a4-8ad4-2fdbd1914c34,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-83af2182-d7d7-4414-b84d-68ebdb51e529,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-0204cb50-cb5f-47fa-bf1f-d34e23f243eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-a3cd5480-dad4-4582-865b-c95b92f42f54,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-fee8a3c6-1d07-4de6-aa6b-d13d16da856d,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-61b45966-73a4-41c3-8bc1-0749938e55ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-80753c5b-fbdd-4256-998e-0aec73efc31d,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-f9e835a7-b384-48da-8ef6-94d99a418055,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165574729-172.17.0.19-1597573859770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41157,DS-35516b69-aae2-46a4-8ad4-2fdbd1914c34,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-83af2182-d7d7-4414-b84d-68ebdb51e529,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-0204cb50-cb5f-47fa-bf1f-d34e23f243eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-a3cd5480-dad4-4582-865b-c95b92f42f54,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-fee8a3c6-1d07-4de6-aa6b-d13d16da856d,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-61b45966-73a4-41c3-8bc1-0749938e55ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-80753c5b-fbdd-4256-998e-0aec73efc31d,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-f9e835a7-b384-48da-8ef6-94d99a418055,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1080714381-172.17.0.19-1597573999714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36723,DS-f31feab7-41b0-40a7-8d28-c85bc73e3adb,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-f28ae7cc-f20d-4ded-8dbe-c6ca80121cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-ff9e3865-0abf-462d-bb9b-191d58c6e451,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-2e96a082-b525-45b5-b4e6-c64fc19a2957,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-18140d4f-6e4f-40e5-bef6-8aa47c162075,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-ed0ad42e-7582-4d7d-8411-0f923e402f96,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-ccc7d2f8-e94f-4477-bf7a-6a059ef4b587,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-8d79e122-9ccb-4961-a662-c2591c2db7c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1080714381-172.17.0.19-1597573999714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36723,DS-f31feab7-41b0-40a7-8d28-c85bc73e3adb,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-f28ae7cc-f20d-4ded-8dbe-c6ca80121cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-ff9e3865-0abf-462d-bb9b-191d58c6e451,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-2e96a082-b525-45b5-b4e6-c64fc19a2957,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-18140d4f-6e4f-40e5-bef6-8aa47c162075,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-ed0ad42e-7582-4d7d-8411-0f923e402f96,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-ccc7d2f8-e94f-4477-bf7a-6a059ef4b587,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-8d79e122-9ccb-4961-a662-c2591c2db7c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1776674655-172.17.0.19-1597574305059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45254,DS-0c996725-cafb-4c7d-990c-4e0d695f13c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-a2f8ce5b-e261-4686-99f7-ce17eab0fcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-98ac04c3-8e60-4d7a-b111-1c022f550df6,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-38e4278e-ef7c-4fcb-871e-8bc873edbe8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-fe9136ff-af6f-4fdc-ae34-36320ec4bdda,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-02971b3e-5629-4cce-8386-32f0b6c5fef1,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-2c246068-3b7d-4548-b5da-1676ebdd6e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-c6a3ae6f-90b0-4a44-817a-17b9d8a80a7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1776674655-172.17.0.19-1597574305059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45254,DS-0c996725-cafb-4c7d-990c-4e0d695f13c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-a2f8ce5b-e261-4686-99f7-ce17eab0fcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-98ac04c3-8e60-4d7a-b111-1c022f550df6,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-38e4278e-ef7c-4fcb-871e-8bc873edbe8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-fe9136ff-af6f-4fdc-ae34-36320ec4bdda,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-02971b3e-5629-4cce-8386-32f0b6c5fef1,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-2c246068-3b7d-4548-b5da-1676ebdd6e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-c6a3ae6f-90b0-4a44-817a-17b9d8a80a7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954358064-172.17.0.19-1597574383170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46300,DS-1f228e6c-7305-4c0c-883d-a12f06f4253d,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-c07ce572-8804-4aba-8831-bd69852e548c,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-d00e622e-cb04-454f-9693-c606f0200850,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-43dfae9a-ff9d-4f8a-89b8-abfed08542cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-ebb90bc3-440a-4f6a-992a-ee27f2c5b6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-66cce98a-bdea-429b-8575-840fc09b8d21,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-f2d1369c-ad8e-402b-81db-a7d9b7337be2,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-eccde113-7bb4-4026-8981-5a84921536b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954358064-172.17.0.19-1597574383170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46300,DS-1f228e6c-7305-4c0c-883d-a12f06f4253d,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-c07ce572-8804-4aba-8831-bd69852e548c,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-d00e622e-cb04-454f-9693-c606f0200850,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-43dfae9a-ff9d-4f8a-89b8-abfed08542cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-ebb90bc3-440a-4f6a-992a-ee27f2c5b6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-66cce98a-bdea-429b-8575-840fc09b8d21,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-f2d1369c-ad8e-402b-81db-a7d9b7337be2,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-eccde113-7bb4-4026-8981-5a84921536b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1225004691-172.17.0.19-1597574497667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33632,DS-916af5be-7ab2-4415-a865-b28b8a4f11aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-5ba7d770-f657-407b-b547-3963328162db,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-b6d379ab-35ac-4850-ba13-ad963b450a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-360d6d13-b460-4ba1-8d16-0d8743c23345,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-788df8d1-5a9c-4b09-9a9b-60230ffd94e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-a1d5a4f2-1115-404d-b424-012f99357bef,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-2d33dceb-0bea-43ae-9845-2ee881f87e07,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-8f0f55b6-0262-4765-af66-a6e6f6b4ac90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1225004691-172.17.0.19-1597574497667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33632,DS-916af5be-7ab2-4415-a865-b28b8a4f11aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-5ba7d770-f657-407b-b547-3963328162db,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-b6d379ab-35ac-4850-ba13-ad963b450a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-360d6d13-b460-4ba1-8d16-0d8743c23345,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-788df8d1-5a9c-4b09-9a9b-60230ffd94e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-a1d5a4f2-1115-404d-b424-012f99357bef,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-2d33dceb-0bea-43ae-9845-2ee881f87e07,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-8f0f55b6-0262-4765-af66-a6e6f6b4ac90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-880610887-172.17.0.19-1597574943931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45090,DS-97e6e833-b20c-47fb-9155-dbe789339a80,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-5d35092e-0664-4a83-a20f-6827e5f280e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-a45b4d27-5790-4416-aba6-0705e5e0ca40,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-8be72524-1f00-4218-85e8-2ec319dd931a,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-2f6441e0-bf92-41e3-9337-2fd388c9d33f,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-5892cc08-78df-4bc3-ab78-15d0791df1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-a362e953-21a9-49bc-a4b0-eab38f1d8778,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-21dd596b-295e-4394-b7bf-ba19fde122f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-880610887-172.17.0.19-1597574943931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45090,DS-97e6e833-b20c-47fb-9155-dbe789339a80,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-5d35092e-0664-4a83-a20f-6827e5f280e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-a45b4d27-5790-4416-aba6-0705e5e0ca40,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-8be72524-1f00-4218-85e8-2ec319dd931a,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-2f6441e0-bf92-41e3-9337-2fd388c9d33f,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-5892cc08-78df-4bc3-ab78-15d0791df1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-a362e953-21a9-49bc-a4b0-eab38f1d8778,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-21dd596b-295e-4394-b7bf-ba19fde122f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-259207075-172.17.0.19-1597575431429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44084,DS-6c12aced-5250-49a2-8195-b5710be637a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-43135afb-0c34-4734-af0c-bbd3fdb39805,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-6cc0b228-4dae-4234-92e9-7a8448049802,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-4576de59-1dc2-4e0e-b3f5-216af962872d,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-6b353bde-fc25-4a96-b23b-8fa23e521e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-7ae90e05-ff84-400f-b660-f1210500073b,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-01df3627-e3ea-476b-ba1c-50150738957a,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-dfeea2e3-6287-43f7-988a-33c6e46c5714,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-259207075-172.17.0.19-1597575431429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44084,DS-6c12aced-5250-49a2-8195-b5710be637a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43558,DS-43135afb-0c34-4734-af0c-bbd3fdb39805,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-6cc0b228-4dae-4234-92e9-7a8448049802,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-4576de59-1dc2-4e0e-b3f5-216af962872d,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-6b353bde-fc25-4a96-b23b-8fa23e521e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-7ae90e05-ff84-400f-b660-f1210500073b,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-01df3627-e3ea-476b-ba1c-50150738957a,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-dfeea2e3-6287-43f7-988a-33c6e46c5714,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116450530-172.17.0.19-1597575661508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42269,DS-a31d0752-b979-4535-9348-7062e2a9931b,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-124b8f32-8398-4d2b-be2b-d642205282e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-3508025c-0563-4ac1-83ea-cd4d0f1cd153,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-39b0ad1f-ee26-4c09-beb3-58188e99a439,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-296394b9-7899-49a7-a51e-12c5d6168a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-78ba149d-7adb-4c1f-a54e-78b99daac374,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-4000613d-508d-4785-bd68-977893017173,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-52a75666-a857-4635-9854-0e8aa1dd866c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116450530-172.17.0.19-1597575661508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42269,DS-a31d0752-b979-4535-9348-7062e2a9931b,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-124b8f32-8398-4d2b-be2b-d642205282e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-3508025c-0563-4ac1-83ea-cd4d0f1cd153,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-39b0ad1f-ee26-4c09-beb3-58188e99a439,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-296394b9-7899-49a7-a51e-12c5d6168a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-78ba149d-7adb-4c1f-a54e-78b99daac374,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-4000613d-508d-4785-bd68-977893017173,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-52a75666-a857-4635-9854-0e8aa1dd866c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-444642213-172.17.0.19-1597575706733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34251,DS-5703fdaa-4b2c-4646-b2ae-ee1847d5bc82,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-e7a49dec-7aca-4f85-be20-d430dd55865c,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-cb3a68e8-f6ff-456b-95c5-f1f072054ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-a0e8ee27-18e5-4017-b67f-7335146c33d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-a4487219-ac14-4584-aedd-6c967acaca01,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-f449ee26-bd37-47e4-8b78-eeae637329e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-b70f17c5-5bf8-4cca-95be-0273acec8518,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-1c10a11b-d6e2-4393-83fe-211c862571c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-444642213-172.17.0.19-1597575706733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34251,DS-5703fdaa-4b2c-4646-b2ae-ee1847d5bc82,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-e7a49dec-7aca-4f85-be20-d430dd55865c,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-cb3a68e8-f6ff-456b-95c5-f1f072054ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-a0e8ee27-18e5-4017-b67f-7335146c33d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-a4487219-ac14-4584-aedd-6c967acaca01,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-f449ee26-bd37-47e4-8b78-eeae637329e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-b70f17c5-5bf8-4cca-95be-0273acec8518,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-1c10a11b-d6e2-4393-83fe-211c862571c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86453417-172.17.0.19-1597576194220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34578,DS-a0670858-afb0-44e0-951c-f0c475378e26,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-07428ee4-964f-497c-b9e1-2e3f332a219e,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-11449c3a-0bd9-490c-bc31-b1a860a762e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-b1be6361-32f0-4e94-8423-c78192105451,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-c6f19686-19e5-4cf1-82db-c7c2c64ab284,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-63c43175-5d2e-42b5-bcd2-1699e1552d36,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-7a52f8a1-923f-4fe0-945d-d332d1555033,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-3ea7d100-5c58-441e-8d65-3c78ae51943e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86453417-172.17.0.19-1597576194220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34578,DS-a0670858-afb0-44e0-951c-f0c475378e26,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-07428ee4-964f-497c-b9e1-2e3f332a219e,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-11449c3a-0bd9-490c-bc31-b1a860a762e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-b1be6361-32f0-4e94-8423-c78192105451,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-c6f19686-19e5-4cf1-82db-c7c2c64ab284,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-63c43175-5d2e-42b5-bcd2-1699e1552d36,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-7a52f8a1-923f-4fe0-945d-d332d1555033,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-3ea7d100-5c58-441e-8d65-3c78ae51943e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 3000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-787590239-172.17.0.19-1597576585901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37605,DS-b0590638-29b3-44cd-89ed-24376791cd36,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-8443999e-e81a-4857-a866-c30386c264aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-4a6f1f20-ad91-4f4e-811a-a66073a35cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-9c3f9c90-bf0a-430b-bc53-236f6b39dcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-310d5d00-e443-4907-b0cb-d9466cba9eed,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-37da4202-e1cf-470f-a1e5-ff740798e7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-122cfd35-16ea-4c52-ac49-3c20bb58633f,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-ad1a0b2f-3836-4c83-a87a-6ea85cb88f27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-787590239-172.17.0.19-1597576585901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37605,DS-b0590638-29b3-44cd-89ed-24376791cd36,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-8443999e-e81a-4857-a866-c30386c264aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-4a6f1f20-ad91-4f4e-811a-a66073a35cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-9c3f9c90-bf0a-430b-bc53-236f6b39dcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-310d5d00-e443-4907-b0cb-d9466cba9eed,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-37da4202-e1cf-470f-a1e5-ff740798e7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-122cfd35-16ea-4c52-ac49-3c20bb58633f,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-ad1a0b2f-3836-4c83-a87a-6ea85cb88f27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5861
