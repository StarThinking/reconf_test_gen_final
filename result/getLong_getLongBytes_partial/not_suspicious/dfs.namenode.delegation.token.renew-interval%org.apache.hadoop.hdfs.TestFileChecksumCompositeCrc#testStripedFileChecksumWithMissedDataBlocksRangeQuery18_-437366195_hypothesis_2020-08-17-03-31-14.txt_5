reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 100
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 100
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1016597523-172.17.0.18-1597635351613:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37658,DS-79424983-b551-476d-9ed0-d01c8e47006a,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-abbc0a3d-05be-4ac7-af6c-745064686269,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-4e8efb4e-fd1a-410a-a3b0-7a92552a3070,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-ea93c915-1925-4f5b-8b03-89600060d12e,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-e467cc48-fae9-4f21-a4a4-539c0c85997e,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-2111ab60-051f-4fbf-9e17-4d929ff0b2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-85237de3-e7d1-4b65-aaa8-ccb16daba9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-957ac194-91bf-47c5-80d7-c33cefd52970,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1016597523-172.17.0.18-1597635351613:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37658,DS-79424983-b551-476d-9ed0-d01c8e47006a,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-abbc0a3d-05be-4ac7-af6c-745064686269,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-4e8efb4e-fd1a-410a-a3b0-7a92552a3070,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-ea93c915-1925-4f5b-8b03-89600060d12e,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-e467cc48-fae9-4f21-a4a4-539c0c85997e,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-2111ab60-051f-4fbf-9e17-4d929ff0b2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-85237de3-e7d1-4b65-aaa8-ccb16daba9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-957ac194-91bf-47c5-80d7-c33cefd52970,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 100
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1659817829-172.17.0.18-1597635602780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40143,DS-fbe1f318-66c0-41e0-82b1-28b71fbbefa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-c5c4f15f-ad0e-4424-921a-47ec82e04f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41486,DS-a3e67a46-c8f3-47d2-b0cf-5cc32392e4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-991f5d69-a4cf-4846-9718-dd767f5f6447,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-0ba58f42-eb3d-4d8a-8fe2-d55ee517ad4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-68026cb9-6e99-451b-b41a-fb078b25bfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-22470545-29b1-4c53-9de0-9c21d9256e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-49974133-8ee2-4fae-b323-8ecb6c66ca84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1659817829-172.17.0.18-1597635602780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40143,DS-fbe1f318-66c0-41e0-82b1-28b71fbbefa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-c5c4f15f-ad0e-4424-921a-47ec82e04f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41486,DS-a3e67a46-c8f3-47d2-b0cf-5cc32392e4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-991f5d69-a4cf-4846-9718-dd767f5f6447,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-0ba58f42-eb3d-4d8a-8fe2-d55ee517ad4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-68026cb9-6e99-451b-b41a-fb078b25bfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-22470545-29b1-4c53-9de0-9c21d9256e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-49974133-8ee2-4fae-b323-8ecb6c66ca84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 100
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2068631252-172.17.0.18-1597635891914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33810,DS-44d92fda-47a0-426c-8c00-844ac84dfb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-f5cd2c75-e8fb-4e01-b49b-03e38292bb29,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-1bb54e26-5bbf-4656-9957-25e828ffbdd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-777c2693-30e7-47f9-b5d2-c38bc605c98e,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-f995ecae-779d-4241-bbeb-101b5b84e535,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-d67ecd2d-93eb-43f4-b1d7-49d50df78889,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-6734eae2-2951-4d99-9c6b-68e432a5e748,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-b6ec9ed4-b46e-4440-9f96-459a1eb065f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2068631252-172.17.0.18-1597635891914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33810,DS-44d92fda-47a0-426c-8c00-844ac84dfb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-f5cd2c75-e8fb-4e01-b49b-03e38292bb29,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-1bb54e26-5bbf-4656-9957-25e828ffbdd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-777c2693-30e7-47f9-b5d2-c38bc605c98e,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-f995ecae-779d-4241-bbeb-101b5b84e535,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-d67ecd2d-93eb-43f4-b1d7-49d50df78889,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-6734eae2-2951-4d99-9c6b-68e432a5e748,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-b6ec9ed4-b46e-4440-9f96-459a1eb065f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 100
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1934931756-172.17.0.18-1597636574197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42245,DS-2642cdf5-230f-4eaf-a8ee-7ab9dfeaf677,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-b803e04f-412e-4040-a319-dfb014d6af06,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-5553903f-1ae7-4ed2-828f-bd284e5397b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-03ef37eb-6b64-4a5e-bb67-b0c87e1cf640,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-1c73b483-6c74-4c08-90dc-6d0cb8ffb629,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-a007b56a-0c1e-43d1-8a50-a3114e8d3d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-c0241c31-5678-41b7-a524-aae6602cc2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-d326e86a-0eba-4e2c-a8b8-1ee4c4645c5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1934931756-172.17.0.18-1597636574197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42245,DS-2642cdf5-230f-4eaf-a8ee-7ab9dfeaf677,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-b803e04f-412e-4040-a319-dfb014d6af06,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-5553903f-1ae7-4ed2-828f-bd284e5397b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-03ef37eb-6b64-4a5e-bb67-b0c87e1cf640,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-1c73b483-6c74-4c08-90dc-6d0cb8ffb629,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-a007b56a-0c1e-43d1-8a50-a3114e8d3d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-c0241c31-5678-41b7-a524-aae6602cc2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-d326e86a-0eba-4e2c-a8b8-1ee4c4645c5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 100
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1703409046-172.17.0.18-1597636822363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43755,DS-4ed3ba30-d711-4d72-8a94-56647f45a517,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-b15bb7aa-e6e6-481b-b892-aafe0ff642c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-3c5159de-80a4-48fe-bf2d-c9b1a8700f10,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-3087539e-6885-4db4-82ef-1ffb6433b92d,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-a71ba862-e1da-4f4e-a535-5da190da8874,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-8165df12-943b-47cb-8f4f-1850e7cfdce2,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-25df328f-4f0c-4dca-a5c4-6b31b6792947,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-c28027ad-97ce-43e4-b5e5-c02da2061cd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1703409046-172.17.0.18-1597636822363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43755,DS-4ed3ba30-d711-4d72-8a94-56647f45a517,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-b15bb7aa-e6e6-481b-b892-aafe0ff642c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-3c5159de-80a4-48fe-bf2d-c9b1a8700f10,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-3087539e-6885-4db4-82ef-1ffb6433b92d,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-a71ba862-e1da-4f4e-a535-5da190da8874,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-8165df12-943b-47cb-8f4f-1850e7cfdce2,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-25df328f-4f0c-4dca-a5c4-6b31b6792947,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-c28027ad-97ce-43e4-b5e5-c02da2061cd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 100
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-170617977-172.17.0.18-1597637002798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40800,DS-e749e2f5-689e-4619-9182-40cfcf22cfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-f77e388f-d194-4639-a52e-10ad0921b853,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-43069d8b-c681-49de-9ffa-a1d83c61593b,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-b0ddb4d6-74f0-4438-8093-fdc0f2f33284,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-3db870c6-5c0b-44cd-b290-4ba69ad84740,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-6ccfa53c-57f0-473a-bd37-ce416ed0154c,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-2dba0c2c-c3aa-42e1-9b38-5cd056a73304,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-58cd7331-46f7-40c9-8277-2c517018a365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-170617977-172.17.0.18-1597637002798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40800,DS-e749e2f5-689e-4619-9182-40cfcf22cfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-f77e388f-d194-4639-a52e-10ad0921b853,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-43069d8b-c681-49de-9ffa-a1d83c61593b,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-b0ddb4d6-74f0-4438-8093-fdc0f2f33284,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-3db870c6-5c0b-44cd-b290-4ba69ad84740,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-6ccfa53c-57f0-473a-bd37-ce416ed0154c,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-2dba0c2c-c3aa-42e1-9b38-5cd056a73304,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-58cd7331-46f7-40c9-8277-2c517018a365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 100
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1854965468-172.17.0.18-1597637241341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43525,DS-bdb556b2-5602-4697-ae76-aa148bdf3e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-f5d7f115-8e8f-45e0-af86-bd85eb42585b,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-5f7b4995-a497-4b16-a21a-4737e0c28882,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-458c031e-8aa1-4a99-9561-f7fe9dd28853,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-968a56df-fc3c-4b19-ad21-620a9fb23260,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-37223402-6147-4a36-bccc-cd96fe996014,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-a0a28f86-10ad-43bf-9519-a4e63fcaf413,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-ab2c4aa4-3f5d-40ea-85b1-13329fc0c446,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1854965468-172.17.0.18-1597637241341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43525,DS-bdb556b2-5602-4697-ae76-aa148bdf3e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-f5d7f115-8e8f-45e0-af86-bd85eb42585b,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-5f7b4995-a497-4b16-a21a-4737e0c28882,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-458c031e-8aa1-4a99-9561-f7fe9dd28853,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-968a56df-fc3c-4b19-ad21-620a9fb23260,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-37223402-6147-4a36-bccc-cd96fe996014,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-a0a28f86-10ad-43bf-9519-a4e63fcaf413,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-ab2c4aa4-3f5d-40ea-85b1-13329fc0c446,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 100
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-307962366-172.17.0.18-1597637498532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43374,DS-3d1d1a7e-e739-4aa2-b341-af0f0833f437,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-621293e9-ed6b-4b40-bd11-5cfdfb47c836,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-99dbf19f-29d1-4cd0-8541-ac760e1670c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-06db20d5-ca06-4ceb-9936-20574167fff6,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-f509c0c5-43c5-404c-a3b0-2b39c351060c,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-5e4df6d9-8a9e-4a9c-aad6-0139107c37d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-274a5ddf-51fc-4e70-89ef-362e4730572c,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-f860c9e4-390d-44c1-879f-74cda7a3498b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-307962366-172.17.0.18-1597637498532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43374,DS-3d1d1a7e-e739-4aa2-b341-af0f0833f437,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-621293e9-ed6b-4b40-bd11-5cfdfb47c836,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-99dbf19f-29d1-4cd0-8541-ac760e1670c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-06db20d5-ca06-4ceb-9936-20574167fff6,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-f509c0c5-43c5-404c-a3b0-2b39c351060c,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-5e4df6d9-8a9e-4a9c-aad6-0139107c37d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-274a5ddf-51fc-4e70-89ef-362e4730572c,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-f860c9e4-390d-44c1-879f-74cda7a3498b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 100
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1072745335-172.17.0.18-1597638915990:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36482,DS-3a3b98c7-1cc8-434a-8624-cc4eaa0f1076,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-47fc5895-55d5-4342-853d-bcc331bcf547,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-c343f12b-62e7-469e-9e08-96cb9330e10f,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-18e2906f-9aee-4eae-8c58-b76184c2db21,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-69df7f61-5b4d-479b-8faf-73249d688d01,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-6c831adc-2b2f-4edb-bd40-3aa1adc91c68,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-1b770ae3-c0ad-4f01-8ad8-23541c1fc233,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-00f06cc2-3dea-41a5-8bdb-c51fe1f18d48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1072745335-172.17.0.18-1597638915990:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36482,DS-3a3b98c7-1cc8-434a-8624-cc4eaa0f1076,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-47fc5895-55d5-4342-853d-bcc331bcf547,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-c343f12b-62e7-469e-9e08-96cb9330e10f,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-18e2906f-9aee-4eae-8c58-b76184c2db21,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-69df7f61-5b4d-479b-8faf-73249d688d01,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-6c831adc-2b2f-4edb-bd40-3aa1adc91c68,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-1b770ae3-c0ad-4f01-8ad8-23541c1fc233,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-00f06cc2-3dea-41a5-8bdb-c51fe1f18d48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 100
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1473289989-172.17.0.18-1597639060429:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39034,DS-94d5f6e8-8641-43eb-aad3-ac019ba24b80,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-cde8983e-2ef1-4a3e-aa5f-f299ab7b84bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-e42c7c68-638b-40f5-8008-3a2fa5eb1793,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-ac1e91a3-927a-493e-961d-e83c31abec89,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-e2d9849c-e014-4365-86b0-63a61af271de,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-d4303eef-2e68-4f34-b9cf-02974d78827c,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-117e6ee5-5f6e-4fe0-82af-ae89bd1ecad6,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-c08ad76f-3105-4fa0-818c-756eab42baa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1473289989-172.17.0.18-1597639060429:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39034,DS-94d5f6e8-8641-43eb-aad3-ac019ba24b80,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-cde8983e-2ef1-4a3e-aa5f-f299ab7b84bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-e42c7c68-638b-40f5-8008-3a2fa5eb1793,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-ac1e91a3-927a-493e-961d-e83c31abec89,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-e2d9849c-e014-4365-86b0-63a61af271de,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-d4303eef-2e68-4f34-b9cf-02974d78827c,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-117e6ee5-5f6e-4fe0-82af-ae89bd1ecad6,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-c08ad76f-3105-4fa0-818c-756eab42baa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 100
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-838768908-172.17.0.18-1597639676176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34861,DS-81c4df0d-0838-4c2f-8678-96c48f5e80e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-5cb3d806-82fb-40e3-b5c3-258edb793266,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-997a9356-2739-479f-9b29-244a02daeb7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-47b28c77-7465-48c1-827a-579a1b8431a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-402feb2c-2d84-4f33-97cc-e58086378b68,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-de50de12-580a-45f9-9cfa-a1ce1b871dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-056cf5ce-2e10-4a66-bde8-37087973bae0,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-ae8d6d51-40d9-47e0-95b7-631d8bc9b14b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-838768908-172.17.0.18-1597639676176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34861,DS-81c4df0d-0838-4c2f-8678-96c48f5e80e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-5cb3d806-82fb-40e3-b5c3-258edb793266,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-997a9356-2739-479f-9b29-244a02daeb7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-47b28c77-7465-48c1-827a-579a1b8431a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-402feb2c-2d84-4f33-97cc-e58086378b68,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-de50de12-580a-45f9-9cfa-a1ce1b871dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-056cf5ce-2e10-4a66-bde8-37087973bae0,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-ae8d6d51-40d9-47e0-95b7-631d8bc9b14b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 100
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1073083307-172.17.0.18-1597639947660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32811,DS-4730393d-88c4-4f1e-bed9-427a467b1e58,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-24ca5145-edb2-4f14-85a1-347aa46928ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-dddd49ed-061e-4d8c-8a51-c397f84ff5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-bfcd992f-11d8-4b21-8b4a-ff6b6df3e257,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-648fcecf-4991-464e-963b-1d410b3a4cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-2ef24abb-fded-4f47-904f-c56fa684c9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-1f2a6beb-9b50-4dfc-bad6-c7f43184c2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-c286e94a-5548-46d1-abda-7234ec9dc5e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1073083307-172.17.0.18-1597639947660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32811,DS-4730393d-88c4-4f1e-bed9-427a467b1e58,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-24ca5145-edb2-4f14-85a1-347aa46928ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-dddd49ed-061e-4d8c-8a51-c397f84ff5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-bfcd992f-11d8-4b21-8b4a-ff6b6df3e257,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-648fcecf-4991-464e-963b-1d410b3a4cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-2ef24abb-fded-4f47-904f-c56fa684c9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-1f2a6beb-9b50-4dfc-bad6-c7f43184c2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-c286e94a-5548-46d1-abda-7234ec9dc5e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 100
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899121598-172.17.0.18-1597640059150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38011,DS-ca139d83-3d66-478f-a09e-0f90f7859945,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-21359687-8e95-4429-8d67-c5acbd97d562,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-7ccbfcb2-c7d4-45fd-8397-28595b1e7ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-3f4e27ce-26c9-4c15-93d8-825f51c8d9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-930a7102-05d0-4242-b331-654aa9c5ad04,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-339601ea-4c6a-4437-bea9-9df3bce98390,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-6aaad2d6-113b-47f0-b37c-c60c6381c0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-01d8dfd5-5b4b-48aa-b5de-47f0dde4f644,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899121598-172.17.0.18-1597640059150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38011,DS-ca139d83-3d66-478f-a09e-0f90f7859945,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-21359687-8e95-4429-8d67-c5acbd97d562,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-7ccbfcb2-c7d4-45fd-8397-28595b1e7ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-3f4e27ce-26c9-4c15-93d8-825f51c8d9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-930a7102-05d0-4242-b331-654aa9c5ad04,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-339601ea-4c6a-4437-bea9-9df3bce98390,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-6aaad2d6-113b-47f0-b37c-c60c6381c0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-01d8dfd5-5b4b-48aa-b5de-47f0dde4f644,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5438
