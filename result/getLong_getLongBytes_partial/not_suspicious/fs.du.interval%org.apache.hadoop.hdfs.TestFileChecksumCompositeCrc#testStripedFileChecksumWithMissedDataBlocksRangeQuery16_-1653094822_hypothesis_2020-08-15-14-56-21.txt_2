reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-414270865-172.17.0.15-1597503394897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40811,DS-a59414b1-8d1b-4c46-8671-cc20c3d8546d,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-6761ca64-b146-4cf5-bcaf-ee8f285bc47c,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-0973f013-f1c5-43e7-a560-826e35ba90af,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-acd6b177-c642-4165-8afa-a6ac8650c7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-3169daa8-df53-4625-96c9-4ff116fccf45,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-dc0f646f-bc8f-4388-acc0-5915e10933c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-70aeefed-04a5-4128-aadd-d6e6c537c683,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-b7e82aec-26d3-4d34-880f-6c266ccc0bc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-414270865-172.17.0.15-1597503394897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40811,DS-a59414b1-8d1b-4c46-8671-cc20c3d8546d,DISK], DatanodeInfoWithStorage[127.0.0.1:44983,DS-6761ca64-b146-4cf5-bcaf-ee8f285bc47c,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-0973f013-f1c5-43e7-a560-826e35ba90af,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-acd6b177-c642-4165-8afa-a6ac8650c7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-3169daa8-df53-4625-96c9-4ff116fccf45,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-dc0f646f-bc8f-4388-acc0-5915e10933c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-70aeefed-04a5-4128-aadd-d6e6c537c683,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-b7e82aec-26d3-4d34-880f-6c266ccc0bc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-491269985-172.17.0.15-1597503738231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33283,DS-4b37d36e-f0f5-42ad-87f0-b144b5f1a99c,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-1378f50f-7c77-4bf1-b80c-40f85c4ff198,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-6c80f151-5056-4c85-b492-96f2451f4752,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-451c9e40-e943-4cc6-9e6e-24c55a0ba7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-5584f44a-099a-4888-b249-10488ff845fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-de28530e-b11c-4740-987b-f3200921bca3,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-0d2512a2-0132-4862-9d58-12c97a10ebcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-02cd93d6-54fe-4c33-84b1-2487f69f4cf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-491269985-172.17.0.15-1597503738231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33283,DS-4b37d36e-f0f5-42ad-87f0-b144b5f1a99c,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-1378f50f-7c77-4bf1-b80c-40f85c4ff198,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-6c80f151-5056-4c85-b492-96f2451f4752,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-451c9e40-e943-4cc6-9e6e-24c55a0ba7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-5584f44a-099a-4888-b249-10488ff845fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-de28530e-b11c-4740-987b-f3200921bca3,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-0d2512a2-0132-4862-9d58-12c97a10ebcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-02cd93d6-54fe-4c33-84b1-2487f69f4cf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1123439434-172.17.0.15-1597503781671:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45003,DS-a48e3b29-7487-4ae0-bfa9-d5a8f3dea0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-22531c64-101b-47fe-8fa0-152f03d5b338,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-ecc65ff2-e3bd-4a13-87e0-a93f9b337acb,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-98c82495-5cf3-4d0f-8232-64375ac1022e,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-d0790535-099a-433a-be98-ca6d47a75ece,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-f1debcee-bbb2-42c9-8e0d-0ed9f5b80b50,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-16297aa9-bd5a-432c-9e59-a521484e3936,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-f451d40e-4b71-4b89-bb73-c872e36b4ce9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1123439434-172.17.0.15-1597503781671:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45003,DS-a48e3b29-7487-4ae0-bfa9-d5a8f3dea0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-22531c64-101b-47fe-8fa0-152f03d5b338,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-ecc65ff2-e3bd-4a13-87e0-a93f9b337acb,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-98c82495-5cf3-4d0f-8232-64375ac1022e,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-d0790535-099a-433a-be98-ca6d47a75ece,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-f1debcee-bbb2-42c9-8e0d-0ed9f5b80b50,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-16297aa9-bd5a-432c-9e59-a521484e3936,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-f451d40e-4b71-4b89-bb73-c872e36b4ce9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2092671221-172.17.0.15-1597503818120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38662,DS-e3b03848-aa02-4c83-8c1c-13ec1ddab4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-7df01876-1589-46f1-bcff-15c404fcee19,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-be605e8d-84ca-4d3b-b6f8-9024d3c7d68c,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-5681bab6-c216-43ee-9327-8b94c4a5ea87,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-3b6a0018-13f6-401b-9706-842121b2d41b,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-e3d06bfd-eb07-45b5-adfa-8bc90a41c49d,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-81c94073-999c-4cda-91bb-e8dc35c14370,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-17e78332-d3a1-4407-83f5-9f9380e1d49e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2092671221-172.17.0.15-1597503818120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38662,DS-e3b03848-aa02-4c83-8c1c-13ec1ddab4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-7df01876-1589-46f1-bcff-15c404fcee19,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-be605e8d-84ca-4d3b-b6f8-9024d3c7d68c,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-5681bab6-c216-43ee-9327-8b94c4a5ea87,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-3b6a0018-13f6-401b-9706-842121b2d41b,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-e3d06bfd-eb07-45b5-adfa-8bc90a41c49d,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-81c94073-999c-4cda-91bb-e8dc35c14370,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-17e78332-d3a1-4407-83f5-9f9380e1d49e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-237625006-172.17.0.15-1597503956629:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33606,DS-70c3f65d-3d8f-4425-8d12-d9a73ced8e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-b693e39a-9a7c-46e7-932f-eb0fdcbfc63a,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-c32b48b4-9b4d-4549-a668-6d4e635f8558,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-21a9de73-c798-4a28-b68f-60cb40f11e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-88253425-eddb-48a4-abd8-085904765aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-6204f595-f548-47cf-b5bb-dfdf320d0675,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-dda71591-f018-4e7b-b501-f358f1705b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-fdd01a5c-0802-4b8c-a62f-3e7d90f725cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-237625006-172.17.0.15-1597503956629:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33606,DS-70c3f65d-3d8f-4425-8d12-d9a73ced8e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-b693e39a-9a7c-46e7-932f-eb0fdcbfc63a,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-c32b48b4-9b4d-4549-a668-6d4e635f8558,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-21a9de73-c798-4a28-b68f-60cb40f11e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-88253425-eddb-48a4-abd8-085904765aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-6204f595-f548-47cf-b5bb-dfdf320d0675,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-dda71591-f018-4e7b-b501-f358f1705b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-fdd01a5c-0802-4b8c-a62f-3e7d90f725cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-468189478-172.17.0.15-1597504221529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36469,DS-71f31ca7-db87-42fc-a599-bc10bbc7def0,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-8f36a012-e3b6-4d66-9777-62b289fbec37,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-f44594e3-ecc5-4de6-88e2-77e23c90649d,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-082fe2ff-48be-43bc-8f6a-50ae7b741a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-b8847433-3615-413b-9591-f55eb9de8503,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-1d7407cc-2175-49e0-a1a7-7d9f117438d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-186fa708-40e8-4745-932b-7859161cbf17,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-c43b68ea-3c24-4815-95b5-48f6297f1438,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-468189478-172.17.0.15-1597504221529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36469,DS-71f31ca7-db87-42fc-a599-bc10bbc7def0,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-8f36a012-e3b6-4d66-9777-62b289fbec37,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-f44594e3-ecc5-4de6-88e2-77e23c90649d,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-082fe2ff-48be-43bc-8f6a-50ae7b741a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-b8847433-3615-413b-9591-f55eb9de8503,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-1d7407cc-2175-49e0-a1a7-7d9f117438d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-186fa708-40e8-4745-932b-7859161cbf17,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-c43b68ea-3c24-4815-95b5-48f6297f1438,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1580572413-172.17.0.15-1597504259100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38279,DS-0ab54437-b350-4033-8610-2c00a06681b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-8e68d5ba-be88-4a8e-b2db-d3fca8569601,DISK], DatanodeInfoWithStorage[127.0.0.1:34591,DS-6bfe5cf1-c860-4d10-90bf-ab35661990d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-e2d514e2-ddac-4375-bf0c-c3e2201fb82f,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-ec2f02e0-c7a8-4942-9218-72e464ea8ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:39337,DS-f870f738-8953-4e4d-862e-b50743a7a886,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-b1befd45-6845-4850-b1a2-c297cfb2c574,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-e497648c-595b-438a-baa0-c5cc416db241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1580572413-172.17.0.15-1597504259100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38279,DS-0ab54437-b350-4033-8610-2c00a06681b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-8e68d5ba-be88-4a8e-b2db-d3fca8569601,DISK], DatanodeInfoWithStorage[127.0.0.1:34591,DS-6bfe5cf1-c860-4d10-90bf-ab35661990d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-e2d514e2-ddac-4375-bf0c-c3e2201fb82f,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-ec2f02e0-c7a8-4942-9218-72e464ea8ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:39337,DS-f870f738-8953-4e4d-862e-b50743a7a886,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-b1befd45-6845-4850-b1a2-c297cfb2c574,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-e497648c-595b-438a-baa0-c5cc416db241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1168857222-172.17.0.15-1597504621450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45261,DS-66745ca9-ffa3-477a-a0a0-2fc4e2481a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-6a322068-9e13-4025-8340-7645d8af9afd,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-7bec614e-debe-49b5-8cc7-2407c8ea3570,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-af96c237-68e3-4a0e-a675-78ee37e7a990,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-6d0a8aa9-f339-4bf4-84e2-210b5da2276f,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-4632e487-f401-4311-b68a-34f9d6f0b70d,DISK], DatanodeInfoWithStorage[127.0.0.1:42019,DS-c539e716-8bfd-4247-a6c1-0c958b4628fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-d1a6cfd4-b48e-43cd-8f13-393c303bffba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1168857222-172.17.0.15-1597504621450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45261,DS-66745ca9-ffa3-477a-a0a0-2fc4e2481a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-6a322068-9e13-4025-8340-7645d8af9afd,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-7bec614e-debe-49b5-8cc7-2407c8ea3570,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-af96c237-68e3-4a0e-a675-78ee37e7a990,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-6d0a8aa9-f339-4bf4-84e2-210b5da2276f,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-4632e487-f401-4311-b68a-34f9d6f0b70d,DISK], DatanodeInfoWithStorage[127.0.0.1:42019,DS-c539e716-8bfd-4247-a6c1-0c958b4628fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-d1a6cfd4-b48e-43cd-8f13-393c303bffba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2042562229-172.17.0.15-1597504694991:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37136,DS-0b85e75e-c858-4164-ac74-cc3f82c06e00,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-0c025a45-ee13-4d81-b975-fc0e0f58f934,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-42411a20-30b7-4f0d-8829-4824f907b98b,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-7ce23aea-ecb2-45f6-b8a8-6db3d18c0ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-7ae7f392-43ae-4e89-ae77-4f8fde70b26f,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-cd15b051-7f94-4c90-80ed-ec99fdaca587,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-a2ff23fa-3a5b-46d8-b339-b96cebf23e50,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-646bdfa8-7d0a-435f-acf3-5edf4a45afec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2042562229-172.17.0.15-1597504694991:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37136,DS-0b85e75e-c858-4164-ac74-cc3f82c06e00,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-0c025a45-ee13-4d81-b975-fc0e0f58f934,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-42411a20-30b7-4f0d-8829-4824f907b98b,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-7ce23aea-ecb2-45f6-b8a8-6db3d18c0ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-7ae7f392-43ae-4e89-ae77-4f8fde70b26f,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-cd15b051-7f94-4c90-80ed-ec99fdaca587,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-a2ff23fa-3a5b-46d8-b339-b96cebf23e50,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-646bdfa8-7d0a-435f-acf3-5edf4a45afec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2101876090-172.17.0.15-1597504788075:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46066,DS-d710e745-a9ce-494b-90a9-cb95013b6a34,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-5d0c900b-60cd-416e-b69a-ff674dfac93c,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-c6577c1f-3339-485e-a1cf-f4c89dc6d0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-2e9d7851-4be4-4b7c-8088-b02802df1bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-a2576c4d-08f2-4834-ac11-1c2a6a317625,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-3b665fda-3123-4eef-ad81-aefdfda1d507,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-2e951106-9a21-496b-84f2-fab0a8bc95f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-7998fe23-4658-4653-87ab-06cf3d98f5b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2101876090-172.17.0.15-1597504788075:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46066,DS-d710e745-a9ce-494b-90a9-cb95013b6a34,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-5d0c900b-60cd-416e-b69a-ff674dfac93c,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-c6577c1f-3339-485e-a1cf-f4c89dc6d0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-2e9d7851-4be4-4b7c-8088-b02802df1bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-a2576c4d-08f2-4834-ac11-1c2a6a317625,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-3b665fda-3123-4eef-ad81-aefdfda1d507,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-2e951106-9a21-496b-84f2-fab0a8bc95f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-7998fe23-4658-4653-87ab-06cf3d98f5b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1664164320-172.17.0.15-1597505888253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40029,DS-06b5803c-36e9-4616-8aae-4e7283318150,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-55a70dc5-ffc6-421c-a420-d1f9c3ae37c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-40ab086c-0706-4178-a557-b002b5fb0110,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-326cd223-2016-4ff9-bf59-cdcd9ab7cd09,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-4a0e8a0e-ea70-467f-ac72-d31aa1c05120,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-d0ec0cb9-9db7-42cb-918f-e8967a7c78cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-529e1d28-9a75-4f46-abff-f4949fce7841,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-64bee016-4fd2-4037-8096-7a643f5d81bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1664164320-172.17.0.15-1597505888253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40029,DS-06b5803c-36e9-4616-8aae-4e7283318150,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-55a70dc5-ffc6-421c-a420-d1f9c3ae37c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-40ab086c-0706-4178-a557-b002b5fb0110,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-326cd223-2016-4ff9-bf59-cdcd9ab7cd09,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-4a0e8a0e-ea70-467f-ac72-d31aa1c05120,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-d0ec0cb9-9db7-42cb-918f-e8967a7c78cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-529e1d28-9a75-4f46-abff-f4949fce7841,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-64bee016-4fd2-4037-8096-7a643f5d81bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-490486102-172.17.0.15-1597505927505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36176,DS-2b93816f-bde8-4147-a216-b77abb71d20f,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-d5e146a1-3cde-4e8b-8fa6-0e768f17248b,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-262d41ae-45d0-4f23-872b-8d45f5ea3d69,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-96134999-b551-40f5-8fd2-944c57a9d004,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-9f64e612-cc3e-4c1a-a63d-161bbd7e6d44,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-b92328c1-5a13-4ba4-8d33-cd8b17540d45,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-ebc75c9c-e23d-46c2-b07c-d6d0136c6c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-9c832232-1833-4d2a-8476-9db480f0f294,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-490486102-172.17.0.15-1597505927505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36176,DS-2b93816f-bde8-4147-a216-b77abb71d20f,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-d5e146a1-3cde-4e8b-8fa6-0e768f17248b,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-262d41ae-45d0-4f23-872b-8d45f5ea3d69,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-96134999-b551-40f5-8fd2-944c57a9d004,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-9f64e612-cc3e-4c1a-a63d-161bbd7e6d44,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-b92328c1-5a13-4ba4-8d33-cd8b17540d45,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-ebc75c9c-e23d-46c2-b07c-d6d0136c6c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-9c832232-1833-4d2a-8476-9db480f0f294,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-781551926-172.17.0.15-1597505965704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34945,DS-d5b56686-4a5d-4975-95a2-244c5cc03e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-2bbcacec-60d6-460d-b945-f5ef122dabad,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-56640fda-9de2-405e-b30f-ac406f5a3805,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-3808d32c-080c-4133-afae-282a7d8c9b24,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-a6c4b6d1-b0e0-4f6e-ba9b-71107b03a124,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-57aabc3d-0ed7-4881-9b38-9f416e3914c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-03a994ba-9eca-49ea-a811-633b59231ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-eee44805-2eb0-4090-b72f-f56e7d63d0be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-781551926-172.17.0.15-1597505965704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34945,DS-d5b56686-4a5d-4975-95a2-244c5cc03e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-2bbcacec-60d6-460d-b945-f5ef122dabad,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-56640fda-9de2-405e-b30f-ac406f5a3805,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-3808d32c-080c-4133-afae-282a7d8c9b24,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-a6c4b6d1-b0e0-4f6e-ba9b-71107b03a124,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-57aabc3d-0ed7-4881-9b38-9f416e3914c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-03a994ba-9eca-49ea-a811-633b59231ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-eee44805-2eb0-4090-b72f-f56e7d63d0be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1325604101-172.17.0.15-1597506113244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43586,DS-01e2f75c-6a64-4946-bc45-0c51caedc0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-170b3f74-368b-489e-a328-dcd1a96e92c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-4b7bf3e2-5d46-4a45-9e95-8165bcede3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-7c48bd67-e71f-44d7-b211-f3e9413df9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-845fb2d3-e154-47a4-a25f-54520abb3718,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-4aa82c88-cce7-4543-9e58-03fda22cfc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-5b3a1b5a-6c7f-4efb-ba2a-fcd2ebcb19cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-082b67c1-23fc-459a-bdc3-2ddfeda5721c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1325604101-172.17.0.15-1597506113244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43586,DS-01e2f75c-6a64-4946-bc45-0c51caedc0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-170b3f74-368b-489e-a328-dcd1a96e92c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-4b7bf3e2-5d46-4a45-9e95-8165bcede3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-7c48bd67-e71f-44d7-b211-f3e9413df9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-845fb2d3-e154-47a4-a25f-54520abb3718,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-4aa82c88-cce7-4543-9e58-03fda22cfc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-5b3a1b5a-6c7f-4efb-ba2a-fcd2ebcb19cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-082b67c1-23fc-459a-bdc3-2ddfeda5721c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1513627799-172.17.0.15-1597506153164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45129,DS-2b06d95d-5b36-42b8-ac30-8399fbf88815,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-97c3e27b-4428-4b52-9ad1-d7e91f702de0,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-e27f0bd5-1213-4aea-9371-dbc60928f1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-60aa4175-8202-499f-9c93-4c08ed24d9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-9f51ad9a-5c5b-42ea-9079-fc2896b22eff,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-1441416e-8889-4281-a6b3-e31234ecba0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-5b02375c-bebd-4988-b126-ba4293104e82,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-39f7c0dd-580f-450b-8f87-962d290fcb54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1513627799-172.17.0.15-1597506153164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45129,DS-2b06d95d-5b36-42b8-ac30-8399fbf88815,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-97c3e27b-4428-4b52-9ad1-d7e91f702de0,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-e27f0bd5-1213-4aea-9371-dbc60928f1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-60aa4175-8202-499f-9c93-4c08ed24d9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-9f51ad9a-5c5b-42ea-9079-fc2896b22eff,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-1441416e-8889-4281-a6b3-e31234ecba0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-5b02375c-bebd-4988-b126-ba4293104e82,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-39f7c0dd-580f-450b-8f87-962d290fcb54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1294831285-172.17.0.15-1597506193803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34437,DS-7ca85189-a1b8-4cce-a6c7-9bba8515218c,DISK], DatanodeInfoWithStorage[127.0.0.1:33348,DS-98855386-90e3-4c53-b214-f1ce2d4435c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-1bd09723-5280-4c72-8df9-157298e0935c,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-45b79b3c-e310-4a03-9bdf-b5d3fadd8e81,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-d2296662-26bb-4db5-84fd-3246d12f748a,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-2fdd75cc-8e6b-465c-b767-85a23f2c4197,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-9fd765f8-32ad-4acb-b85a-d63147efb15a,DISK], DatanodeInfoWithStorage[127.0.0.1:44674,DS-e5dc2cfd-e338-4cb7-b567-8f9145eb47b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1294831285-172.17.0.15-1597506193803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34437,DS-7ca85189-a1b8-4cce-a6c7-9bba8515218c,DISK], DatanodeInfoWithStorage[127.0.0.1:33348,DS-98855386-90e3-4c53-b214-f1ce2d4435c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-1bd09723-5280-4c72-8df9-157298e0935c,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-45b79b3c-e310-4a03-9bdf-b5d3fadd8e81,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-d2296662-26bb-4db5-84fd-3246d12f748a,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-2fdd75cc-8e6b-465c-b767-85a23f2c4197,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-9fd765f8-32ad-4acb-b85a-d63147efb15a,DISK], DatanodeInfoWithStorage[127.0.0.1:44674,DS-e5dc2cfd-e338-4cb7-b567-8f9145eb47b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1367615416-172.17.0.15-1597506968780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33389,DS-18271f61-4f80-4f58-88d5-2240caa77052,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-e1164416-e585-427b-b416-7efaf374dcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-17057bb9-3429-4581-b99d-38681b74b2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-52fa8150-527a-404b-849b-9804ee4fbac5,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-202ceb3d-8492-4737-a8c3-7f7e6edb4ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-61be6202-00b2-49f5-888d-5128eda97d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-1d34cd78-42fa-41a6-b826-40589148e305,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-6874343d-68f5-465b-9ec2-bec7f039fea2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1367615416-172.17.0.15-1597506968780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33389,DS-18271f61-4f80-4f58-88d5-2240caa77052,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-e1164416-e585-427b-b416-7efaf374dcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-17057bb9-3429-4581-b99d-38681b74b2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-52fa8150-527a-404b-849b-9804ee4fbac5,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-202ceb3d-8492-4737-a8c3-7f7e6edb4ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-61be6202-00b2-49f5-888d-5128eda97d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-1d34cd78-42fa-41a6-b826-40589148e305,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-6874343d-68f5-465b-9ec2-bec7f039fea2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1704030461-172.17.0.15-1597508072610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38641,DS-2a8bace4-e1ab-4822-9f00-66d60c07d770,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-260f2e1c-51dc-4277-9629-591f1a6b3869,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-db540232-1f88-43f5-b825-4816977f9306,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-6b0ce076-7249-415f-a9ed-542e77d138c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-9ff9e321-df1d-4b45-9d30-519f90f8b8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-a38a7c3c-973e-4a80-91d8-d01b5c902e69,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-69dcc3b1-8958-4a48-88af-e6eeed4e6ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-d080bcc8-b2fe-4969-b992-0511ab01d771,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1704030461-172.17.0.15-1597508072610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38641,DS-2a8bace4-e1ab-4822-9f00-66d60c07d770,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-260f2e1c-51dc-4277-9629-591f1a6b3869,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-db540232-1f88-43f5-b825-4816977f9306,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-6b0ce076-7249-415f-a9ed-542e77d138c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-9ff9e321-df1d-4b45-9d30-519f90f8b8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-a38a7c3c-973e-4a80-91d8-d01b5c902e69,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-69dcc3b1-8958-4a48-88af-e6eeed4e6ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-d080bcc8-b2fe-4969-b992-0511ab01d771,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1939541467-172.17.0.15-1597508109029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34437,DS-0772ac6b-4783-43d8-92b6-87b2b5119cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-58e2ce60-a376-4124-a48a-e1cf9900c499,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-c3645656-91fb-48d5-9de3-eda363294486,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-baf596ca-d663-4051-bc62-0766ab2dee9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-a8127454-dd01-47e0-a1b9-753e3de679c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-e217a49b-345a-4d4f-a7e1-442031bc24a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-9d97bfb9-abf3-4566-9db5-935c7e004a19,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-a36f10b8-9ebd-441d-ac60-9b36c2358581,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1939541467-172.17.0.15-1597508109029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34437,DS-0772ac6b-4783-43d8-92b6-87b2b5119cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-58e2ce60-a376-4124-a48a-e1cf9900c499,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-c3645656-91fb-48d5-9de3-eda363294486,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-baf596ca-d663-4051-bc62-0766ab2dee9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-a8127454-dd01-47e0-a1b9-753e3de679c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-e217a49b-345a-4d4f-a7e1-442031bc24a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-9d97bfb9-abf3-4566-9db5-935c7e004a19,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-a36f10b8-9ebd-441d-ac60-9b36c2358581,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1681129944-172.17.0.15-1597508285393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38175,DS-3460cb5c-a5ba-4c20-b203-3e6b18d419f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41774,DS-f656d3e2-b1aa-4d68-a784-9f8beeb2b858,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-21980b52-1293-46d8-a630-2c398f4cc210,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-07c33c52-61dc-4a00-a5ec-434f8c768f02,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-8402bf18-8aeb-4f8d-a191-8cad8e0c74e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-05e55803-2c75-42d6-8f84-a7ff4645e029,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-f5d89b74-5a7a-4c8d-bdfc-0f7f79f1c094,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-3d18ee4f-3071-4582-a4fc-3671d15b4ead,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1681129944-172.17.0.15-1597508285393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38175,DS-3460cb5c-a5ba-4c20-b203-3e6b18d419f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41774,DS-f656d3e2-b1aa-4d68-a784-9f8beeb2b858,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-21980b52-1293-46d8-a630-2c398f4cc210,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-07c33c52-61dc-4a00-a5ec-434f8c768f02,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-8402bf18-8aeb-4f8d-a191-8cad8e0c74e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-05e55803-2c75-42d6-8f84-a7ff4645e029,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-f5d89b74-5a7a-4c8d-bdfc-0f7f79f1c094,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-3d18ee4f-3071-4582-a4fc-3671d15b4ead,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2042844886-172.17.0.15-1597508420247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34767,DS-b867ff6f-fee2-4a93-bc24-6b9b3188120f,DISK], DatanodeInfoWithStorage[127.0.0.1:36700,DS-ea40efa5-2603-4645-9ec7-0d7b4c48e495,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-1d85bd53-7128-4b61-a0e7-91f489aaddc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38630,DS-5427d3ec-d7f7-473f-8959-4439537f587c,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-1279cb4f-5b3e-4a3b-92b6-6fc3d6899855,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-fcfa5b68-fea1-4813-865b-e3b48c0343c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-385d9aea-b12d-4c47-9bfb-fc7fcf60c759,DISK], DatanodeInfoWithStorage[127.0.0.1:34191,DS-a5f1454e-073d-429b-bbc1-d7c4946fb3d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2042844886-172.17.0.15-1597508420247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34767,DS-b867ff6f-fee2-4a93-bc24-6b9b3188120f,DISK], DatanodeInfoWithStorage[127.0.0.1:36700,DS-ea40efa5-2603-4645-9ec7-0d7b4c48e495,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-1d85bd53-7128-4b61-a0e7-91f489aaddc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38630,DS-5427d3ec-d7f7-473f-8959-4439537f587c,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-1279cb4f-5b3e-4a3b-92b6-6fc3d6899855,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-fcfa5b68-fea1-4813-865b-e3b48c0343c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-385d9aea-b12d-4c47-9bfb-fc7fcf60c759,DISK], DatanodeInfoWithStorage[127.0.0.1:34191,DS-a5f1454e-073d-429b-bbc1-d7c4946fb3d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5339
