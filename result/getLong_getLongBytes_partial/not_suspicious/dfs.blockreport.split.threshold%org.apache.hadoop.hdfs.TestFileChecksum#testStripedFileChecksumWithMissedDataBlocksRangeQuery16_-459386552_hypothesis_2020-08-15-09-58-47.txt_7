reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-971963319-172.17.0.17-1597486789295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39980,DS-cc548f90-2c57-4434-8098-195d7ebb6879,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-8c1f7e94-e31a-44d3-806a-d2c10a27dcb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-73134cef-a8e5-410e-8208-f1f77de54f75,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-91fc56ce-0e76-4560-9de2-518e9c1f76f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-f1384715-782d-4412-a501-cfb2dea1ae77,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-efe84754-4e5c-4086-a8cc-83c66acb5e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-ec8fa3a8-f08e-4479-8c49-40c654706d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-c2f86b8c-5b2e-46bd-b3a0-6a67f611110c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-971963319-172.17.0.17-1597486789295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39980,DS-cc548f90-2c57-4434-8098-195d7ebb6879,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-8c1f7e94-e31a-44d3-806a-d2c10a27dcb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-73134cef-a8e5-410e-8208-f1f77de54f75,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-91fc56ce-0e76-4560-9de2-518e9c1f76f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-f1384715-782d-4412-a501-cfb2dea1ae77,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-efe84754-4e5c-4086-a8cc-83c66acb5e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-ec8fa3a8-f08e-4479-8c49-40c654706d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-c2f86b8c-5b2e-46bd-b3a0-6a67f611110c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1507035735-172.17.0.17-1597487039974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36598,DS-4d9b50a9-631a-45ed-803d-4087955c552f,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-126909de-f529-443a-b2d2-42ab80d7cef8,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-947df687-e3f8-4900-97c7-25c4b523a1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-614e76eb-5575-430c-a74c-270bb22222ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-62fd45b3-4257-497f-958d-6e0a86a23a80,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-81b58e5b-7af7-4d55-b3f9-5b12cc9bad2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-8f828a6a-6e78-4b26-9969-7d6e4e9cb21f,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-4a1baffa-ce06-419f-a4b4-41dcb42b08c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1507035735-172.17.0.17-1597487039974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36598,DS-4d9b50a9-631a-45ed-803d-4087955c552f,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-126909de-f529-443a-b2d2-42ab80d7cef8,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-947df687-e3f8-4900-97c7-25c4b523a1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-614e76eb-5575-430c-a74c-270bb22222ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-62fd45b3-4257-497f-958d-6e0a86a23a80,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-81b58e5b-7af7-4d55-b3f9-5b12cc9bad2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-8f828a6a-6e78-4b26-9969-7d6e4e9cb21f,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-4a1baffa-ce06-419f-a4b4-41dcb42b08c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2002968466-172.17.0.17-1597487108881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34128,DS-a3dad556-52a0-4ffc-b352-63e0995ef059,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-fa7d1b84-acce-451d-9b61-949632764490,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-88cfcd0c-876a-47c9-b419-ca976de1c22d,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-713942e5-e5d8-4020-8a33-a92f15cf20e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-d77a748f-6ec8-467a-b6a0-df219fa9a239,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-bb6d17a4-8eca-4105-a6ef-086f4499c73d,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-d2146d7a-4d04-4f18-be1f-2a4a8d34f977,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-d404cc8a-5b0f-4168-875f-99e12785e96c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2002968466-172.17.0.17-1597487108881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34128,DS-a3dad556-52a0-4ffc-b352-63e0995ef059,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-fa7d1b84-acce-451d-9b61-949632764490,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-88cfcd0c-876a-47c9-b419-ca976de1c22d,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-713942e5-e5d8-4020-8a33-a92f15cf20e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-d77a748f-6ec8-467a-b6a0-df219fa9a239,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-bb6d17a4-8eca-4105-a6ef-086f4499c73d,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-d2146d7a-4d04-4f18-be1f-2a4a8d34f977,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-d404cc8a-5b0f-4168-875f-99e12785e96c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1209182351-172.17.0.17-1597487355706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44792,DS-7e3a0c21-5c91-436f-964e-e04fcb43b530,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-87d81ba5-b15e-4131-9fae-726928f43086,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-da139a21-879e-41f8-9b86-0f2096d3047e,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-36451688-e48d-4099-b3c1-ee2aa2f72dee,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-38aa8ab5-99cb-454c-b2c6-f60ca6068b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-9c6123f0-ddc4-4ed9-a39c-ddd669d165e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-c573db6f-f407-4e8b-92c2-6b6edbb4dfbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-f31e354a-b32c-4482-ac4a-64d7e56bb8cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1209182351-172.17.0.17-1597487355706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44792,DS-7e3a0c21-5c91-436f-964e-e04fcb43b530,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-87d81ba5-b15e-4131-9fae-726928f43086,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-da139a21-879e-41f8-9b86-0f2096d3047e,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-36451688-e48d-4099-b3c1-ee2aa2f72dee,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-38aa8ab5-99cb-454c-b2c6-f60ca6068b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-9c6123f0-ddc4-4ed9-a39c-ddd669d165e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-c573db6f-f407-4e8b-92c2-6b6edbb4dfbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-f31e354a-b32c-4482-ac4a-64d7e56bb8cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1153054628-172.17.0.17-1597488154756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35770,DS-07b4fae2-62f7-4f05-b05e-daa6358888e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-35205232-475e-457f-b396-41ad9acc42d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-871a83b6-e61f-48d0-974f-d308cc9596ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-9ac21919-8649-4b4a-a6b4-cbb779351388,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-8e0c6911-e180-4452-b78d-d02fb844e59b,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-70334e30-9a58-4f62-bc12-6b9b91ff1ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-04fb5060-a89c-48bc-b6cf-815112010088,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-36444d8c-dcc6-487c-933a-1b94fbd62471,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1153054628-172.17.0.17-1597488154756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35770,DS-07b4fae2-62f7-4f05-b05e-daa6358888e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-35205232-475e-457f-b396-41ad9acc42d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-871a83b6-e61f-48d0-974f-d308cc9596ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-9ac21919-8649-4b4a-a6b4-cbb779351388,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-8e0c6911-e180-4452-b78d-d02fb844e59b,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-70334e30-9a58-4f62-bc12-6b9b91ff1ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-04fb5060-a89c-48bc-b6cf-815112010088,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-36444d8c-dcc6-487c-933a-1b94fbd62471,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1915820398-172.17.0.17-1597488953086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41078,DS-c377882e-9d55-4a4d-a3d3-01b52811446a,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-972100bb-91c2-43e4-84c5-37c4e23c4dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-801ede28-672a-4c76-a094-22c8ee629414,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-71847c02-d1f6-4dfb-99ce-b12071d14ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-3d6828ff-454e-4e4c-8404-6ce2ddf22512,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-7d7087bd-ce8c-4ba7-9945-3e63c2630379,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-4d449104-7a0e-4530-a3d1-bb099cbb679b,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-2b757ee0-6eee-410c-98eb-72724ed360eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1915820398-172.17.0.17-1597488953086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41078,DS-c377882e-9d55-4a4d-a3d3-01b52811446a,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-972100bb-91c2-43e4-84c5-37c4e23c4dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-801ede28-672a-4c76-a094-22c8ee629414,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-71847c02-d1f6-4dfb-99ce-b12071d14ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-3d6828ff-454e-4e4c-8404-6ce2ddf22512,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-7d7087bd-ce8c-4ba7-9945-3e63c2630379,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-4d449104-7a0e-4530-a3d1-bb099cbb679b,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-2b757ee0-6eee-410c-98eb-72724ed360eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864054985-172.17.0.17-1597488993022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33916,DS-a162189c-d772-46f3-97be-f09f34ad8158,DISK], DatanodeInfoWithStorage[127.0.0.1:39716,DS-790ce209-2764-42af-a70e-79ca73d2a099,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-568f18b5-201e-4f11-8b43-652632270b47,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-ec93c702-0d1d-4f63-8f8a-f8bc588246de,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-7db1b3b0-2dfd-4982-9444-940553a55e21,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-56120c13-6948-4202-8dbe-285f072beb01,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-2c0e38e9-a32f-4e6a-ae5a-10485ef8dd89,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-c8642e59-41d0-48a7-b628-dde64c0e118d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864054985-172.17.0.17-1597488993022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33916,DS-a162189c-d772-46f3-97be-f09f34ad8158,DISK], DatanodeInfoWithStorage[127.0.0.1:39716,DS-790ce209-2764-42af-a70e-79ca73d2a099,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-568f18b5-201e-4f11-8b43-652632270b47,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-ec93c702-0d1d-4f63-8f8a-f8bc588246de,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-7db1b3b0-2dfd-4982-9444-940553a55e21,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-56120c13-6948-4202-8dbe-285f072beb01,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-2c0e38e9-a32f-4e6a-ae5a-10485ef8dd89,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-c8642e59-41d0-48a7-b628-dde64c0e118d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1237114266-172.17.0.17-1597489024490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43703,DS-faf7405e-3d85-4e5a-81b2-e6106e1e22a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-fb95047e-6d7b-40c6-ab12-a79e8f8d6faf,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-beb47521-f257-4d90-96d8-597e1e411cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-366ae5a7-7d71-48a6-82dc-ab02e49ea0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-bd48c05a-f34e-426a-aae9-d251ac86d565,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-68008dc8-21ec-4e2c-8c6b-d58b2421b766,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-234eff91-cc2b-4a62-a47b-0334de07188a,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-7eaa4ff7-2b9d-49e3-b625-e79984cb78ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1237114266-172.17.0.17-1597489024490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43703,DS-faf7405e-3d85-4e5a-81b2-e6106e1e22a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-fb95047e-6d7b-40c6-ab12-a79e8f8d6faf,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-beb47521-f257-4d90-96d8-597e1e411cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-366ae5a7-7d71-48a6-82dc-ab02e49ea0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-bd48c05a-f34e-426a-aae9-d251ac86d565,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-68008dc8-21ec-4e2c-8c6b-d58b2421b766,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-234eff91-cc2b-4a62-a47b-0334de07188a,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-7eaa4ff7-2b9d-49e3-b625-e79984cb78ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1280904862-172.17.0.17-1597489234080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37486,DS-76f0ad92-610b-41a5-8d80-3ea43e909ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-05cc1fd0-54e6-4add-a3d3-39ebf741ce55,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-aada9540-25e2-4b4a-83eb-efedc0ccfddd,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-07b0c8d9-cc3f-4c70-8c26-e0f51570d621,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-8a76b36b-030f-40a5-8d9c-99e688e6f95c,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-777b26ef-f359-464c-bb62-a7826948424b,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-e7963a89-2b10-47e0-8675-32c44adb09e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-550c27a9-d8ae-4b9c-994b-f06bcfe54b7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1280904862-172.17.0.17-1597489234080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37486,DS-76f0ad92-610b-41a5-8d80-3ea43e909ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-05cc1fd0-54e6-4add-a3d3-39ebf741ce55,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-aada9540-25e2-4b4a-83eb-efedc0ccfddd,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-07b0c8d9-cc3f-4c70-8c26-e0f51570d621,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-8a76b36b-030f-40a5-8d9c-99e688e6f95c,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-777b26ef-f359-464c-bb62-a7826948424b,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-e7963a89-2b10-47e0-8675-32c44adb09e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-550c27a9-d8ae-4b9c-994b-f06bcfe54b7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-88690331-172.17.0.17-1597489678592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42402,DS-873c333d-4154-4297-baa8-c59a0d2fc0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-d670ce00-13d9-4f88-99ab-8dc50b1083c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-aa54d5f3-fa7e-4296-ab8f-0cb182eb0fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-5901dc86-d810-4532-9e2a-9b334af3e368,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-cffe69bc-a3c6-425b-9820-67338cfc74f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-3b1276e9-7e60-4ddf-be4e-3e0c4f3887f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-1cf6daea-919f-4da1-bad2-a1a41f7ded5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-0f86e65c-57e3-4624-ae8b-c6bd40def78d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-88690331-172.17.0.17-1597489678592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42402,DS-873c333d-4154-4297-baa8-c59a0d2fc0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-d670ce00-13d9-4f88-99ab-8dc50b1083c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-aa54d5f3-fa7e-4296-ab8f-0cb182eb0fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-5901dc86-d810-4532-9e2a-9b334af3e368,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-cffe69bc-a3c6-425b-9820-67338cfc74f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-3b1276e9-7e60-4ddf-be4e-3e0c4f3887f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-1cf6daea-919f-4da1-bad2-a1a41f7ded5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-0f86e65c-57e3-4624-ae8b-c6bd40def78d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-248609303-172.17.0.17-1597489750605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36682,DS-ee25ca22-ad5b-4ccc-ad23-7142fe2700c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-7d0e8cb7-3f75-4941-af34-41be6497175f,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-687e7b6e-c584-4442-b637-f43db3a33709,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-2b335b18-66d7-44c1-9703-6b65bb9870f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-364db7ce-2bab-4fbe-adc3-5438019b1eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-a37ae5a7-42a6-4d0e-b42d-a02d6fa641d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-026e20b7-6ed0-49f2-9caa-5f1438ecf329,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-65756619-6afa-40a6-8ef6-c53651cbfa63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-248609303-172.17.0.17-1597489750605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36682,DS-ee25ca22-ad5b-4ccc-ad23-7142fe2700c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-7d0e8cb7-3f75-4941-af34-41be6497175f,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-687e7b6e-c584-4442-b637-f43db3a33709,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-2b335b18-66d7-44c1-9703-6b65bb9870f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-364db7ce-2bab-4fbe-adc3-5438019b1eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-a37ae5a7-42a6-4d0e-b42d-a02d6fa641d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-026e20b7-6ed0-49f2-9caa-5f1438ecf329,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-65756619-6afa-40a6-8ef6-c53651cbfa63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-701799109-172.17.0.17-1597489867189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43845,DS-01cc05bc-a2f7-4b18-b8be-c95110a95684,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-224f1cd8-0af7-4ea7-ab25-27609ab64b63,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-1ce5b2e3-1851-41ba-a444-e28e6d23b2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-beba5619-471e-4c6b-89ad-eb189179e1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-879c6bf1-6095-4a60-8af4-4994a5572297,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-b9139743-4cf7-4099-ba1d-a9a54640ba38,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-5d0a6cbb-3b57-4b0d-94cf-dbf2b6799d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-efe4ed60-e3e7-439a-b37c-05db510ce9f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-701799109-172.17.0.17-1597489867189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43845,DS-01cc05bc-a2f7-4b18-b8be-c95110a95684,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-224f1cd8-0af7-4ea7-ab25-27609ab64b63,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-1ce5b2e3-1851-41ba-a444-e28e6d23b2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-beba5619-471e-4c6b-89ad-eb189179e1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-879c6bf1-6095-4a60-8af4-4994a5572297,DISK], DatanodeInfoWithStorage[127.0.0.1:45929,DS-b9139743-4cf7-4099-ba1d-a9a54640ba38,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-5d0a6cbb-3b57-4b0d-94cf-dbf2b6799d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-efe4ed60-e3e7-439a-b37c-05db510ce9f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2105353995-172.17.0.17-1597489934770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42583,DS-70145294-45a0-4006-9729-5fcae33f519f,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-176ab1eb-2ab4-4dff-8609-6f475640bd85,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-5061a1dd-f305-4a31-b2c8-ef973ee077cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-0646c76b-9b90-4144-bbbe-77ff8d8c4cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-f042e171-7d9a-40b9-bb76-903c0f96172a,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-f25294b0-dce5-485b-accc-52390990eded,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-0dad7c61-48ee-4bc9-9afe-e53c3e093f77,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-405bacbb-f784-4862-bd4f-3dedd1e2ef5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2105353995-172.17.0.17-1597489934770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42583,DS-70145294-45a0-4006-9729-5fcae33f519f,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-176ab1eb-2ab4-4dff-8609-6f475640bd85,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-5061a1dd-f305-4a31-b2c8-ef973ee077cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-0646c76b-9b90-4144-bbbe-77ff8d8c4cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-f042e171-7d9a-40b9-bb76-903c0f96172a,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-f25294b0-dce5-485b-accc-52390990eded,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-0dad7c61-48ee-4bc9-9afe-e53c3e093f77,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-405bacbb-f784-4862-bd4f-3dedd1e2ef5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-889373150-172.17.0.17-1597490291625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42880,DS-6ffbd164-d77f-419c-aea8-a5ab936740f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-51fe7f2b-881e-45bc-aada-53a97e1c4de2,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-e9994930-1f6d-459c-a93e-2fcadb29be12,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-4d227a81-877b-4f5e-9170-c9d7abda4465,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-4a8bcb00-4472-4452-9957-16736b87df9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-7cb83f87-111b-4e9a-ba70-ebd094e1b093,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-924ef0cd-a125-4662-a1db-9191f421cc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-474961a8-7f28-4763-a362-fde7b133c9a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-889373150-172.17.0.17-1597490291625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42880,DS-6ffbd164-d77f-419c-aea8-a5ab936740f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-51fe7f2b-881e-45bc-aada-53a97e1c4de2,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-e9994930-1f6d-459c-a93e-2fcadb29be12,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-4d227a81-877b-4f5e-9170-c9d7abda4465,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-4a8bcb00-4472-4452-9957-16736b87df9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-7cb83f87-111b-4e9a-ba70-ebd094e1b093,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-924ef0cd-a125-4662-a1db-9191f421cc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-474961a8-7f28-4763-a362-fde7b133c9a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-314174161-172.17.0.17-1597490360711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37701,DS-de8d0cc3-35c7-4249-8ac2-20fc104d1a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-63d716db-fea7-428e-bd70-9e006ef5689e,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-3a369c83-d800-4854-8c33-89b4fb6118a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-82b28531-3a5a-471b-baf3-faed1c80edb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-8a14cfc5-0176-4049-b22f-ca4966806fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-c7d26ce7-2df5-47d7-876a-1b707c1048d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-75a6866d-ab87-4942-956a-2de8d0208fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-1d56defb-f6bf-45fa-901a-a5f05247bcf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-314174161-172.17.0.17-1597490360711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37701,DS-de8d0cc3-35c7-4249-8ac2-20fc104d1a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-63d716db-fea7-428e-bd70-9e006ef5689e,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-3a369c83-d800-4854-8c33-89b4fb6118a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-82b28531-3a5a-471b-baf3-faed1c80edb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-8a14cfc5-0176-4049-b22f-ca4966806fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-c7d26ce7-2df5-47d7-876a-1b707c1048d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-75a6866d-ab87-4942-956a-2de8d0208fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-1d56defb-f6bf-45fa-901a-a5f05247bcf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1909783206-172.17.0.17-1597490464992:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36244,DS-ea3c5904-a614-417b-8a6c-36113b42bb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-b56a6aac-3805-4a9d-9099-51abee3bef55,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-ad5727c8-3397-40ba-8a63-1f24d5a13801,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-07b181f5-cbce-404f-8a06-7bd81b89ac91,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-851a74e8-2eb5-4e49-a32a-1a936f30a4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-6f1aaf1d-3317-4028-9cb5-22c9186621df,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-f9c90371-fe4c-4d96-9622-e13d31f86b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-28bd6b66-abfb-495f-989c-bd9a68cedfe3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1909783206-172.17.0.17-1597490464992:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36244,DS-ea3c5904-a614-417b-8a6c-36113b42bb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-b56a6aac-3805-4a9d-9099-51abee3bef55,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-ad5727c8-3397-40ba-8a63-1f24d5a13801,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-07b181f5-cbce-404f-8a06-7bd81b89ac91,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-851a74e8-2eb5-4e49-a32a-1a936f30a4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-6f1aaf1d-3317-4028-9cb5-22c9186621df,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-f9c90371-fe4c-4d96-9622-e13d31f86b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-28bd6b66-abfb-495f-989c-bd9a68cedfe3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1882402728-172.17.0.17-1597490493756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35676,DS-dc53470a-9829-44e0-acdc-8547057d019a,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-bc7108ef-7eef-4871-aee9-a01fdb4968c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-f2bcecf9-4439-4e52-855b-15c5dedbebed,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-ba3a718f-fa0b-46f6-bffc-bb72bb62e49c,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-7d5bd8bc-289c-46ce-8b26-9ea7a37de5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-8ac72aac-5e7d-4f6e-b078-31b1cbb39493,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-b3280c00-9808-446c-8176-db9c0bf0fafa,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-892e3bc5-9aa8-4ef6-a772-3f278de21294,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1882402728-172.17.0.17-1597490493756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35676,DS-dc53470a-9829-44e0-acdc-8547057d019a,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-bc7108ef-7eef-4871-aee9-a01fdb4968c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-f2bcecf9-4439-4e52-855b-15c5dedbebed,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-ba3a718f-fa0b-46f6-bffc-bb72bb62e49c,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-7d5bd8bc-289c-46ce-8b26-9ea7a37de5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-8ac72aac-5e7d-4f6e-b078-31b1cbb39493,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-b3280c00-9808-446c-8176-db9c0bf0fafa,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-892e3bc5-9aa8-4ef6-a772-3f278de21294,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-273223614-172.17.0.17-1597490638398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43154,DS-10c50290-10fe-4d0a-b2e7-711cab831fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-4954cf54-684c-4ed1-b0fc-cf2a1544eedc,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-e02f8fbd-0c5b-4856-a4d5-1ff5f447527c,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-ab8a6143-fe42-4939-a138-0f582e52a589,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-ce56c275-6813-488f-a923-c4246af8fae0,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-6c64a91c-97f5-47b6-b6e0-6394cb641b31,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-8e8fc867-379d-482c-8569-7bf5c2388c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34416,DS-d27a2c6e-6c60-4efe-bd94-300cdfb5ebdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-273223614-172.17.0.17-1597490638398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43154,DS-10c50290-10fe-4d0a-b2e7-711cab831fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-4954cf54-684c-4ed1-b0fc-cf2a1544eedc,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-e02f8fbd-0c5b-4856-a4d5-1ff5f447527c,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-ab8a6143-fe42-4939-a138-0f582e52a589,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-ce56c275-6813-488f-a923-c4246af8fae0,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-6c64a91c-97f5-47b6-b6e0-6394cb641b31,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-8e8fc867-379d-482c-8569-7bf5c2388c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34416,DS-d27a2c6e-6c60-4efe-bd94-300cdfb5ebdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5314
