reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-776552685-172.17.0.19-1597556434935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45321,DS-67f13716-eaeb-4a2d-bdf5-d796a1a16f52,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-526ee431-3a85-47c0-88f7-d9fe9984b4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-a3cef0a7-2a06-4575-818a-83e6ea4272a1,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-0383a986-48c5-4a1b-bb00-fb6f8ca87685,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-d1c22b14-2b56-4182-a93c-0b479b1614b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-c4b71492-3a2a-4ec2-aafe-9ac5c0c00755,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-5261caf4-56b2-408e-971a-df40a597ea46,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-d4817fcf-0eb3-4cc0-9baf-3905c9afc04c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-776552685-172.17.0.19-1597556434935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45321,DS-67f13716-eaeb-4a2d-bdf5-d796a1a16f52,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-526ee431-3a85-47c0-88f7-d9fe9984b4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-a3cef0a7-2a06-4575-818a-83e6ea4272a1,DISK], DatanodeInfoWithStorage[127.0.0.1:32974,DS-0383a986-48c5-4a1b-bb00-fb6f8ca87685,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-d1c22b14-2b56-4182-a93c-0b479b1614b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-c4b71492-3a2a-4ec2-aafe-9ac5c0c00755,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-5261caf4-56b2-408e-971a-df40a597ea46,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-d4817fcf-0eb3-4cc0-9baf-3905c9afc04c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629167457-172.17.0.19-1597556628115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39019,DS-3f2ab7eb-87ab-4a88-9b9c-bcdbbee2ad49,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-3765a652-10c7-47a4-8d1e-f13055be0502,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-5143ce9c-9ee8-462a-9905-38c9c394c087,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-cbf0ef60-037b-4462-8f37-1931f00fb54a,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-ea7a5113-7758-4906-a751-e2c5a6e74215,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-40b61aa5-805c-4e43-bcd1-c3e65a70696c,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-2265147a-a342-40b4-a55c-a4c1b809f987,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-9e49b375-89d9-4e7f-a83f-9ecbda0ba2f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629167457-172.17.0.19-1597556628115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39019,DS-3f2ab7eb-87ab-4a88-9b9c-bcdbbee2ad49,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-3765a652-10c7-47a4-8d1e-f13055be0502,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-5143ce9c-9ee8-462a-9905-38c9c394c087,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-cbf0ef60-037b-4462-8f37-1931f00fb54a,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-ea7a5113-7758-4906-a751-e2c5a6e74215,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-40b61aa5-805c-4e43-bcd1-c3e65a70696c,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-2265147a-a342-40b4-a55c-a4c1b809f987,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-9e49b375-89d9-4e7f-a83f-9ecbda0ba2f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-955969948-172.17.0.19-1597556766458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39163,DS-e070220c-912a-4a0c-826d-b8ddd0889840,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-dc25a060-a12d-4153-b5ed-a9e347231b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-8de2c907-9fa0-4100-822b-dbdc6033b0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-859aef67-a0bd-4a77-ab4c-858c34cafaae,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-506f5a73-330d-4127-b254-5c0260d69cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-161e8550-183c-4784-a857-bff88b59d571,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-27a723f1-fab7-4971-89cb-5d4cd21463f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-3fa2e3b2-0590-4362-9db7-431eb510221e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-955969948-172.17.0.19-1597556766458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39163,DS-e070220c-912a-4a0c-826d-b8ddd0889840,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-dc25a060-a12d-4153-b5ed-a9e347231b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-8de2c907-9fa0-4100-822b-dbdc6033b0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-859aef67-a0bd-4a77-ab4c-858c34cafaae,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-506f5a73-330d-4127-b254-5c0260d69cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-161e8550-183c-4784-a857-bff88b59d571,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-27a723f1-fab7-4971-89cb-5d4cd21463f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-3fa2e3b2-0590-4362-9db7-431eb510221e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-139811675-172.17.0.19-1597556806116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43800,DS-74006050-2ec4-4e7f-afd0-aa988c54375b,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-43a96cb7-ae45-49d9-8d35-a0357c755ded,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-475e692a-3474-4867-bb38-e623a551b3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-8d2b41a3-64ab-4637-901e-283f73486aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-88364327-7629-48cd-bbe0-9fde8f0307cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-26e2f407-a693-4139-8f9c-dffeba901840,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-d37ab6a6-3de5-491f-a872-125e36a3a6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-c8f03e47-c6ad-43f1-963b-6584ba9ee72c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-139811675-172.17.0.19-1597556806116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43800,DS-74006050-2ec4-4e7f-afd0-aa988c54375b,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-43a96cb7-ae45-49d9-8d35-a0357c755ded,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-475e692a-3474-4867-bb38-e623a551b3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-8d2b41a3-64ab-4637-901e-283f73486aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-88364327-7629-48cd-bbe0-9fde8f0307cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-26e2f407-a693-4139-8f9c-dffeba901840,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-d37ab6a6-3de5-491f-a872-125e36a3a6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-c8f03e47-c6ad-43f1-963b-6584ba9ee72c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1909908755-172.17.0.19-1597557487425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43477,DS-d552307e-c2e9-4105-863b-4ebcbfb62903,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-8cd17e38-a693-4392-992e-da3f72e50209,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-6edec454-ae88-49c3-90b0-a892955404a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-072c7486-093d-4864-9e86-6392011a3e74,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-06ff5fe3-b10d-4c65-943c-b83d5554b3da,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-8f3efe20-9011-4790-95e6-81d671711be3,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-8a3c30d0-e1c3-4abd-b281-1e5d7b8a1242,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-71b88ed9-b7fb-4fb8-8ad6-f84851f757ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1909908755-172.17.0.19-1597557487425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43477,DS-d552307e-c2e9-4105-863b-4ebcbfb62903,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-8cd17e38-a693-4392-992e-da3f72e50209,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-6edec454-ae88-49c3-90b0-a892955404a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-072c7486-093d-4864-9e86-6392011a3e74,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-06ff5fe3-b10d-4c65-943c-b83d5554b3da,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-8f3efe20-9011-4790-95e6-81d671711be3,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-8a3c30d0-e1c3-4abd-b281-1e5d7b8a1242,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-71b88ed9-b7fb-4fb8-8ad6-f84851f757ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1334070178-172.17.0.19-1597558613526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39398,DS-d8d161d9-610b-4df3-90cc-a9488f2a103d,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-d690cc4f-840d-42b5-892e-2551bdf786f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-f1a90f7c-2ad5-44ca-9de5-f5ff01813b67,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-b291d1e8-9a23-414f-ae05-cf49404cf335,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-2e9ec67f-15a9-41e9-a153-c5d5d18c3bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-1e2507b9-177e-41d6-91dc-3f237962be07,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-16f054c2-cebe-4cb6-957e-fbd1779bed6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-a8667b8e-59b5-4b36-adea-5a5f091a36fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1334070178-172.17.0.19-1597558613526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39398,DS-d8d161d9-610b-4df3-90cc-a9488f2a103d,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-d690cc4f-840d-42b5-892e-2551bdf786f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-f1a90f7c-2ad5-44ca-9de5-f5ff01813b67,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-b291d1e8-9a23-414f-ae05-cf49404cf335,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-2e9ec67f-15a9-41e9-a153-c5d5d18c3bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-1e2507b9-177e-41d6-91dc-3f237962be07,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-16f054c2-cebe-4cb6-957e-fbd1779bed6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-a8667b8e-59b5-4b36-adea-5a5f091a36fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1803339524-172.17.0.19-1597558649820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43565,DS-0fecc4cb-ffec-4ef5-b93a-dd4399f30a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-aac7edeb-442d-4a30-b9ad-2e14348aa0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-ed1b3983-3816-492c-9055-d9e74dcf6850,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-3cea1da0-52c3-4723-b9bc-01ea3c03357f,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-b69176db-1c3c-49c5-be01-6d79d41fbc98,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-120179ff-2de9-4154-a1da-510ba9fbf63d,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-d5137e73-2622-4915-aab7-cce4caf5e6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-c7df127f-278b-44f8-9774-59a689a764cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1803339524-172.17.0.19-1597558649820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43565,DS-0fecc4cb-ffec-4ef5-b93a-dd4399f30a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-aac7edeb-442d-4a30-b9ad-2e14348aa0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-ed1b3983-3816-492c-9055-d9e74dcf6850,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-3cea1da0-52c3-4723-b9bc-01ea3c03357f,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-b69176db-1c3c-49c5-be01-6d79d41fbc98,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-120179ff-2de9-4154-a1da-510ba9fbf63d,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-d5137e73-2622-4915-aab7-cce4caf5e6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-c7df127f-278b-44f8-9774-59a689a764cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1937875966-172.17.0.19-1597558689118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38406,DS-57ee4114-bf05-4701-af44-f277347cccfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-f6d7039b-bfa1-460a-9bdf-655f4c9904cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-29d9e4b2-dee5-47c3-b3a0-e35b131b0ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-a24252d8-f1da-4fa9-85cd-34ea72e312f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-478c8bd3-5cb0-474d-b171-5b11b0af681e,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-994e1c1a-c3f7-4fed-a292-d9313e5d6980,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-1e20e6f1-922b-4269-83aa-32d3a2640bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-c24312d6-6a5e-4542-a0c8-4c46635a2eb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1937875966-172.17.0.19-1597558689118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38406,DS-57ee4114-bf05-4701-af44-f277347cccfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-f6d7039b-bfa1-460a-9bdf-655f4c9904cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-29d9e4b2-dee5-47c3-b3a0-e35b131b0ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-a24252d8-f1da-4fa9-85cd-34ea72e312f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-478c8bd3-5cb0-474d-b171-5b11b0af681e,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-994e1c1a-c3f7-4fed-a292-d9313e5d6980,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-1e20e6f1-922b-4269-83aa-32d3a2640bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-c24312d6-6a5e-4542-a0c8-4c46635a2eb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2018474103-172.17.0.19-1597558730040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45789,DS-35e2c75f-bd9c-4310-a826-f93dfe4f2748,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-6d26792c-1057-49d4-8811-162bf50e442d,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-41431db0-118a-4592-86b8-50790e482885,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-abae87a9-b55c-49b9-926b-623373b787d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-6d79b554-3026-4148-8778-379f5f8b0f30,DISK], DatanodeInfoWithStorage[127.0.0.1:41221,DS-2cd87a0d-e359-4464-91fb-c804e148c9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-9cbb79d7-dbb0-4a35-865a-b29d8d185e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-06b9996e-9a14-4213-b158-c386d42ff021,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2018474103-172.17.0.19-1597558730040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45789,DS-35e2c75f-bd9c-4310-a826-f93dfe4f2748,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-6d26792c-1057-49d4-8811-162bf50e442d,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-41431db0-118a-4592-86b8-50790e482885,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-abae87a9-b55c-49b9-926b-623373b787d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-6d79b554-3026-4148-8778-379f5f8b0f30,DISK], DatanodeInfoWithStorage[127.0.0.1:41221,DS-2cd87a0d-e359-4464-91fb-c804e148c9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-9cbb79d7-dbb0-4a35-865a-b29d8d185e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-06b9996e-9a14-4213-b158-c386d42ff021,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-82574991-172.17.0.19-1597558767350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42627,DS-f542e627-e877-4a56-bec8-b1938a11a270,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-90318760-6d6f-4469-bd7e-596818faa2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-dd60d664-1a99-4566-a22b-b29c8c8c33b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-7c818c9f-5385-4b0f-a8dd-495a303658b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-f9a83979-f4d2-4e2d-a492-51f2e6cfdc97,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-d2284eb5-c5d7-4be3-8429-969b22bfb094,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-7854bcbe-6bfb-47d9-8d38-45b73616f9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-c3f27209-085e-42c5-babc-f33a28887957,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-82574991-172.17.0.19-1597558767350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42627,DS-f542e627-e877-4a56-bec8-b1938a11a270,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-90318760-6d6f-4469-bd7e-596818faa2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-dd60d664-1a99-4566-a22b-b29c8c8c33b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-7c818c9f-5385-4b0f-a8dd-495a303658b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-f9a83979-f4d2-4e2d-a492-51f2e6cfdc97,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-d2284eb5-c5d7-4be3-8429-969b22bfb094,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-7854bcbe-6bfb-47d9-8d38-45b73616f9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-c3f27209-085e-42c5-babc-f33a28887957,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1170225881-172.17.0.19-1597558839175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32999,DS-669b36c5-32ea-41b3-b47e-2f643f52629f,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-96447c5d-08f4-453b-93e8-6cb55f62f38e,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-8ccabdd1-da43-447d-8d59-55823f9a051e,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-78dc9626-befc-432e-9cc0-c68cd5f04ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-d1c1c788-81af-482e-b22b-e1ff43832638,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-5a06494f-8d6c-4da7-a190-9feee5824348,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-dcd308bd-effc-44db-a90e-cf3484bfa0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-9d4df427-531d-41e3-8e57-f1a74d713b37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1170225881-172.17.0.19-1597558839175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32999,DS-669b36c5-32ea-41b3-b47e-2f643f52629f,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-96447c5d-08f4-453b-93e8-6cb55f62f38e,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-8ccabdd1-da43-447d-8d59-55823f9a051e,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-78dc9626-befc-432e-9cc0-c68cd5f04ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-d1c1c788-81af-482e-b22b-e1ff43832638,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-5a06494f-8d6c-4da7-a190-9feee5824348,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-dcd308bd-effc-44db-a90e-cf3484bfa0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-9d4df427-531d-41e3-8e57-f1a74d713b37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81205123-172.17.0.19-1597559621950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36523,DS-92b495db-7cf4-4bda-8476-6238e3e97284,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-bf32ac91-7dcf-4a0f-aa1d-c4e6f5131010,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-dbd9bde7-40a6-4c46-aca9-b03b7dacd91e,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-bcf34f3c-5275-4395-bd06-a3a361c27f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-21a44807-27ec-4309-afd4-df33049439cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-111ff69e-6f10-4070-96a6-297358447756,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-61621195-ec46-4344-82ed-18a1190148ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-e2b4d150-8912-4119-b38b-190461c6302e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81205123-172.17.0.19-1597559621950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36523,DS-92b495db-7cf4-4bda-8476-6238e3e97284,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-bf32ac91-7dcf-4a0f-aa1d-c4e6f5131010,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-dbd9bde7-40a6-4c46-aca9-b03b7dacd91e,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-bcf34f3c-5275-4395-bd06-a3a361c27f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-21a44807-27ec-4309-afd4-df33049439cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-111ff69e-6f10-4070-96a6-297358447756,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-61621195-ec46-4344-82ed-18a1190148ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-e2b4d150-8912-4119-b38b-190461c6302e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430655282-172.17.0.19-1597559929559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46122,DS-e3b8443e-8aa1-4799-a670-7baff05eef6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-60af9226-de86-40e0-a618-60be9d4df7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-aa044c66-753b-4b46-bd46-5c194c6b5ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-545244c8-ee31-4d36-890d-5bb1926beb47,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-7397a8c3-8c5c-4207-96fe-fbafe7ef3015,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-546081b2-356f-4e2f-9c86-62e54a188211,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-e10070d5-d045-48eb-b1fe-c4be0634933d,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-f7d3a736-d688-4efc-9d48-9170e25b0e2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430655282-172.17.0.19-1597559929559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46122,DS-e3b8443e-8aa1-4799-a670-7baff05eef6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-60af9226-de86-40e0-a618-60be9d4df7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-aa044c66-753b-4b46-bd46-5c194c6b5ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-545244c8-ee31-4d36-890d-5bb1926beb47,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-7397a8c3-8c5c-4207-96fe-fbafe7ef3015,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-546081b2-356f-4e2f-9c86-62e54a188211,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-e10070d5-d045-48eb-b1fe-c4be0634933d,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-f7d3a736-d688-4efc-9d48-9170e25b0e2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1552290684-172.17.0.19-1597559966819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42603,DS-9cb75330-8290-4be4-9f49-8f38db99f345,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-cf2e825a-6717-45fc-b679-4ebcf20fc881,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-b4d825bb-c2ec-47fc-bd56-82074fcdff4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45428,DS-a458418e-c1d2-49e8-b6e5-944c13dbb5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-8a4540b2-2e35-4f3d-bf02-9b34956c2398,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-40ee2a6b-eb63-41f9-80ab-88b4cc0f5ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-d04b7e1b-f3d3-4301-aadf-946eb722ab23,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-786733b4-ed5c-4946-a72b-58be99139f8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1552290684-172.17.0.19-1597559966819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42603,DS-9cb75330-8290-4be4-9f49-8f38db99f345,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-cf2e825a-6717-45fc-b679-4ebcf20fc881,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-b4d825bb-c2ec-47fc-bd56-82074fcdff4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45428,DS-a458418e-c1d2-49e8-b6e5-944c13dbb5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-8a4540b2-2e35-4f3d-bf02-9b34956c2398,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-40ee2a6b-eb63-41f9-80ab-88b4cc0f5ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-d04b7e1b-f3d3-4301-aadf-946eb722ab23,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-786733b4-ed5c-4946-a72b-58be99139f8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1910844570-172.17.0.19-1597560296892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38348,DS-c6c4b528-b929-440a-8fe9-1b4d8e8becc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-95054659-7b37-4b09-9438-c3f6525765ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-f8f7289b-f0fd-4d9e-9a12-7ee6260fe3de,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-2cea931b-f40d-4ebc-99bc-b9ab7aa5d01e,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-8a1b8cef-42f4-4c36-9a0b-f3cf356c99d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-c01abca6-ca6a-4db8-b1c0-2493978f2260,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-6584dee1-6031-491b-9353-8ce35ebe32e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-5e7e4820-1d54-44b4-9cdd-4411b450a2ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1910844570-172.17.0.19-1597560296892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38348,DS-c6c4b528-b929-440a-8fe9-1b4d8e8becc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-95054659-7b37-4b09-9438-c3f6525765ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-f8f7289b-f0fd-4d9e-9a12-7ee6260fe3de,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-2cea931b-f40d-4ebc-99bc-b9ab7aa5d01e,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-8a1b8cef-42f4-4c36-9a0b-f3cf356c99d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-c01abca6-ca6a-4db8-b1c0-2493978f2260,DISK], DatanodeInfoWithStorage[127.0.0.1:45585,DS-6584dee1-6031-491b-9353-8ce35ebe32e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-5e7e4820-1d54-44b4-9cdd-4411b450a2ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587561450-172.17.0.19-1597560564072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41499,DS-66570ebd-04df-4fc8-a85a-a862fbb5fb99,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-d0f35ec1-9d4a-48bb-927f-a42a4343b969,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-6debbd3c-9582-4219-a3c9-e41b940e8c68,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-4869d10d-e98d-4e5b-81cb-3d2099422a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-f84d0030-ad4c-422e-99e8-a62a17b2e482,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-8db83933-097c-4eda-ab83-a66fb55c5bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-b1f02d4b-83af-43a4-91a8-b37a603e4503,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-972b44de-7299-4ce8-be09-9272c32eed87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587561450-172.17.0.19-1597560564072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41499,DS-66570ebd-04df-4fc8-a85a-a862fbb5fb99,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-d0f35ec1-9d4a-48bb-927f-a42a4343b969,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-6debbd3c-9582-4219-a3c9-e41b940e8c68,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-4869d10d-e98d-4e5b-81cb-3d2099422a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-f84d0030-ad4c-422e-99e8-a62a17b2e482,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-8db83933-097c-4eda-ab83-a66fb55c5bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-b1f02d4b-83af-43a4-91a8-b37a603e4503,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-972b44de-7299-4ce8-be09-9272c32eed87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1163192256-172.17.0.19-1597560705177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46533,DS-2760678b-956b-44e1-b9e7-825819a1a30e,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-2c3a5793-c5b7-45ed-a494-6f4304fa83db,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-68c5fe88-1918-4cf0-b37a-a5cbaf960ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-df36adaf-559b-44ff-85b3-5484e3de7ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-b392ba6f-f88a-4200-a185-f2fb568143ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-1e1255cc-b7e4-4b58-a9ab-9396347fd150,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-92fd81e3-3c18-492a-a607-126e85ca0cea,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-4416fd87-fc73-41dd-bc0d-aedc8777abb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1163192256-172.17.0.19-1597560705177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46533,DS-2760678b-956b-44e1-b9e7-825819a1a30e,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-2c3a5793-c5b7-45ed-a494-6f4304fa83db,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-68c5fe88-1918-4cf0-b37a-a5cbaf960ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-df36adaf-559b-44ff-85b3-5484e3de7ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-b392ba6f-f88a-4200-a185-f2fb568143ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-1e1255cc-b7e4-4b58-a9ab-9396347fd150,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-92fd81e3-3c18-492a-a607-126e85ca0cea,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-4416fd87-fc73-41dd-bc0d-aedc8777abb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-125503960-172.17.0.19-1597561229111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34229,DS-d01713a7-2321-49e4-b468-0a03622b72ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-53db0df5-f07f-448e-8e3f-3eb6baf77b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-752dd1a0-dfc8-476b-8c8f-debe4352ca86,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-8f14d9cb-8388-4528-addd-4a04e91c22fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-7eb8e0fe-c691-4ad9-96c0-1c96845b9c24,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-91630b52-16f1-4529-a8f1-65f3ddb3a79b,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-085a3401-572e-4047-a114-026518dee1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-2b622209-0e9d-49fb-a632-f1c1b4aed76d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-125503960-172.17.0.19-1597561229111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34229,DS-d01713a7-2321-49e4-b468-0a03622b72ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-53db0df5-f07f-448e-8e3f-3eb6baf77b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-752dd1a0-dfc8-476b-8c8f-debe4352ca86,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-8f14d9cb-8388-4528-addd-4a04e91c22fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-7eb8e0fe-c691-4ad9-96c0-1c96845b9c24,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-91630b52-16f1-4529-a8f1-65f3ddb3a79b,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-085a3401-572e-4047-a114-026518dee1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-2b622209-0e9d-49fb-a632-f1c1b4aed76d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1371932380-172.17.0.19-1597561298589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45902,DS-0021dcd0-6b63-4b00-b3c7-50f462a6c07e,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-4650aed1-d38c-4ca7-9f81-722bf5019358,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-18172933-f5a6-4724-b19b-2ce83f629c47,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-ff245888-946a-4232-94ef-a7832fb3021b,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-f02696a2-b54f-46b8-bbf4-2255a656a68c,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-782d82b2-43e2-4048-bdea-c06cabbe47de,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-a5aca63c-d8c2-4504-a519-b286d97fd755,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-fe75e2fc-9731-40f0-8cdf-2d3ce8d1e538,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1371932380-172.17.0.19-1597561298589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45902,DS-0021dcd0-6b63-4b00-b3c7-50f462a6c07e,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-4650aed1-d38c-4ca7-9f81-722bf5019358,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-18172933-f5a6-4724-b19b-2ce83f629c47,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-ff245888-946a-4232-94ef-a7832fb3021b,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-f02696a2-b54f-46b8-bbf4-2255a656a68c,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-782d82b2-43e2-4048-bdea-c06cabbe47de,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-a5aca63c-d8c2-4504-a519-b286d97fd755,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-fe75e2fc-9731-40f0-8cdf-2d3ce8d1e538,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5746
