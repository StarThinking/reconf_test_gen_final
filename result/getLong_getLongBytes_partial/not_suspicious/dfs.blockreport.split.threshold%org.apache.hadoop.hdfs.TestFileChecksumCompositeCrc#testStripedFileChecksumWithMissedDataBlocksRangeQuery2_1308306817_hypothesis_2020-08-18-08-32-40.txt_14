reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-925334462-172.17.0.2-1597740853142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45586,DS-09dd5c6b-612a-481f-8881-a9182b4741af,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-8c302145-0aed-4068-9fad-024de95f58d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-f3e8502c-b14e-40e3-a349-66c6de56084d,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-6b7769d7-14f8-4f6f-a2b2-4c2fe3615fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-334ee899-9bd0-4fdb-b739-e39485045fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-96ab0896-8282-4fa3-824c-722edaa0503c,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-a3a89396-2970-4f1b-9cf5-8472fb951c36,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-9fa5ee1f-9c1b-4717-9313-7f8b2cd8495c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-925334462-172.17.0.2-1597740853142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45586,DS-09dd5c6b-612a-481f-8881-a9182b4741af,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-8c302145-0aed-4068-9fad-024de95f58d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-f3e8502c-b14e-40e3-a349-66c6de56084d,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-6b7769d7-14f8-4f6f-a2b2-4c2fe3615fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-334ee899-9bd0-4fdb-b739-e39485045fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-96ab0896-8282-4fa3-824c-722edaa0503c,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-a3a89396-2970-4f1b-9cf5-8472fb951c36,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-9fa5ee1f-9c1b-4717-9313-7f8b2cd8495c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1764255953-172.17.0.2-1597740887214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34957,DS-b8c357bf-d3f5-40d2-afff-478eae76a374,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-252f279d-cad9-47a5-b69e-65a0d8b80cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-ec67079b-d62a-4eb9-b06d-d8c3c2897e33,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-e44094bb-b57a-471c-bdc5-9adfaf597aac,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-90e86f06-eb06-4c3d-89a7-b9e35dcfcaca,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-b919b7fb-1c3a-4d3c-9f71-e9b60d54b013,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-9cfde6c2-59b8-47e5-bebf-10bbbe258019,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-656c0a7c-904a-4d0c-adcd-caaccd91c95b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1764255953-172.17.0.2-1597740887214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34957,DS-b8c357bf-d3f5-40d2-afff-478eae76a374,DISK], DatanodeInfoWithStorage[127.0.0.1:45319,DS-252f279d-cad9-47a5-b69e-65a0d8b80cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-ec67079b-d62a-4eb9-b06d-d8c3c2897e33,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-e44094bb-b57a-471c-bdc5-9adfaf597aac,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-90e86f06-eb06-4c3d-89a7-b9e35dcfcaca,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-b919b7fb-1c3a-4d3c-9f71-e9b60d54b013,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-9cfde6c2-59b8-47e5-bebf-10bbbe258019,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-656c0a7c-904a-4d0c-adcd-caaccd91c95b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-658292905-172.17.0.2-1597741012624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45717,DS-5ebc8b15-3016-4020-8d3f-fa0eb7408510,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-c61949bd-e5e0-419f-8797-edbb2a804769,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-758dfdbf-ea02-4769-8d71-431a791b8bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-5b335d9c-ac21-4ebc-b829-ce9b456a459f,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-752a94c9-31bd-489e-b630-defa3e2e3f22,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-50234b43-cf1e-4607-84e2-94029dd81cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-e4ce6efa-117e-4591-98a5-7f63453eaadc,DISK], DatanodeInfoWithStorage[127.0.0.1:33560,DS-f4689c01-379c-4ddd-86b1-51e41183dfef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-658292905-172.17.0.2-1597741012624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45717,DS-5ebc8b15-3016-4020-8d3f-fa0eb7408510,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-c61949bd-e5e0-419f-8797-edbb2a804769,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-758dfdbf-ea02-4769-8d71-431a791b8bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-5b335d9c-ac21-4ebc-b829-ce9b456a459f,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-752a94c9-31bd-489e-b630-defa3e2e3f22,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-50234b43-cf1e-4607-84e2-94029dd81cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-e4ce6efa-117e-4591-98a5-7f63453eaadc,DISK], DatanodeInfoWithStorage[127.0.0.1:33560,DS-f4689c01-379c-4ddd-86b1-51e41183dfef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1565083918-172.17.0.2-1597741459879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45227,DS-4ff2c170-0ee9-453d-8526-df79b6e45bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-b7703aa3-7a3f-4a4f-8f6f-a0677bd3ccf6,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-e88f48e1-8004-4d34-9a82-3005d6b4de24,DISK], DatanodeInfoWithStorage[127.0.0.1:34784,DS-d3f54c1e-bd14-40ee-9345-5b02877bc138,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-5651d677-064d-4bda-a5af-654d671735f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-bf1d55ed-ad11-42a0-a23d-4cebc7f12041,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-5eb3499b-03cd-44f7-b7da-18f244039f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-df14a906-000b-4f09-aa66-ee2c5606c9d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1565083918-172.17.0.2-1597741459879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45227,DS-4ff2c170-0ee9-453d-8526-df79b6e45bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-b7703aa3-7a3f-4a4f-8f6f-a0677bd3ccf6,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-e88f48e1-8004-4d34-9a82-3005d6b4de24,DISK], DatanodeInfoWithStorage[127.0.0.1:34784,DS-d3f54c1e-bd14-40ee-9345-5b02877bc138,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-5651d677-064d-4bda-a5af-654d671735f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-bf1d55ed-ad11-42a0-a23d-4cebc7f12041,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-5eb3499b-03cd-44f7-b7da-18f244039f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-df14a906-000b-4f09-aa66-ee2c5606c9d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2123457340-172.17.0.2-1597741568302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38854,DS-6d379ae5-c0ca-4067-9231-39fb0f53c4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-5b882346-12c9-4ae8-862c-9fe4baf9156a,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-26811e08-6d02-4b7f-a2c0-278aa43e776d,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-ca93b88f-79dc-441e-b56c-40175e9c9e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-93c5b5bc-390c-493c-80c5-07c38ea42df1,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-b8d84b03-2b80-45eb-a576-8183209859cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-e6219780-2af8-4f7d-b1a5-cdea07dd5bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-0be73ba4-3aca-4efc-8864-10f589f5d96b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2123457340-172.17.0.2-1597741568302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38854,DS-6d379ae5-c0ca-4067-9231-39fb0f53c4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-5b882346-12c9-4ae8-862c-9fe4baf9156a,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-26811e08-6d02-4b7f-a2c0-278aa43e776d,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-ca93b88f-79dc-441e-b56c-40175e9c9e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-93c5b5bc-390c-493c-80c5-07c38ea42df1,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-b8d84b03-2b80-45eb-a576-8183209859cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-e6219780-2af8-4f7d-b1a5-cdea07dd5bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-0be73ba4-3aca-4efc-8864-10f589f5d96b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1813391496-172.17.0.2-1597741713384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44738,DS-19db1558-8b6b-4f12-b6e6-5d2ed8d40dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-2d40f556-4104-468c-bb26-41bfadc90f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-d104c426-7811-448a-a82d-16a2e8d77256,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-69c9b5e4-fb25-490a-a8b7-ee2bf7da334c,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-cd91f11b-6bb5-40b6-8fd1-8d6c55ee6e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-9f13ffde-1f04-4a4f-a62c-41ad5e54a9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-54e73471-8571-42ed-a1aa-df1fa7c15aab,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-9c80d76c-7919-4be6-916f-25713ccbd373,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1813391496-172.17.0.2-1597741713384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44738,DS-19db1558-8b6b-4f12-b6e6-5d2ed8d40dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-2d40f556-4104-468c-bb26-41bfadc90f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-d104c426-7811-448a-a82d-16a2e8d77256,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-69c9b5e4-fb25-490a-a8b7-ee2bf7da334c,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-cd91f11b-6bb5-40b6-8fd1-8d6c55ee6e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-9f13ffde-1f04-4a4f-a62c-41ad5e54a9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-54e73471-8571-42ed-a1aa-df1fa7c15aab,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-9c80d76c-7919-4be6-916f-25713ccbd373,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1706921154-172.17.0.2-1597741917845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45751,DS-17802f96-0efb-4fe3-9603-c544684123c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-ac1c032f-e005-495b-bf97-476ea6311498,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-8e3f330d-59d0-4f04-95af-fd2d77252a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-9aa5fbb1-5614-47ae-a6a1-27c172c332e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-c93e3eb8-8137-4270-ac24-66064e2969b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-01a837b2-a60a-4012-9c09-0fb006fdc583,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-47c3abb4-05a6-4c8b-ba0c-07958fe5e604,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-b18d511f-94e2-4422-85ed-722e9c2601bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1706921154-172.17.0.2-1597741917845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45751,DS-17802f96-0efb-4fe3-9603-c544684123c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-ac1c032f-e005-495b-bf97-476ea6311498,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-8e3f330d-59d0-4f04-95af-fd2d77252a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-9aa5fbb1-5614-47ae-a6a1-27c172c332e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-c93e3eb8-8137-4270-ac24-66064e2969b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-01a837b2-a60a-4012-9c09-0fb006fdc583,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-47c3abb4-05a6-4c8b-ba0c-07958fe5e604,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-b18d511f-94e2-4422-85ed-722e9c2601bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-383835192-172.17.0.2-1597741993371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41440,DS-c34f7e6d-82d8-4edb-8139-ec2cfcf715f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-5e57b79e-2ed1-4490-81c7-b957aac0b6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-07a997ac-4511-47ac-b6a2-928b68410730,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-e80952c0-5d7f-4761-9ba8-54c675a95c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-e75dd6c5-4374-4e44-b22a-29014cb06620,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-0a675af3-c268-4edb-a37d-689ba637b33b,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-b396b0d5-2219-42ee-a8fb-ff5e5f2cf6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-f8422ac9-cdc6-4bc8-9195-334ee605d952,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-383835192-172.17.0.2-1597741993371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41440,DS-c34f7e6d-82d8-4edb-8139-ec2cfcf715f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-5e57b79e-2ed1-4490-81c7-b957aac0b6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-07a997ac-4511-47ac-b6a2-928b68410730,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-e80952c0-5d7f-4761-9ba8-54c675a95c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-e75dd6c5-4374-4e44-b22a-29014cb06620,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-0a675af3-c268-4edb-a37d-689ba637b33b,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-b396b0d5-2219-42ee-a8fb-ff5e5f2cf6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-f8422ac9-cdc6-4bc8-9195-334ee605d952,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294856942-172.17.0.2-1597742151192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41055,DS-c732a188-0a7d-49e7-be43-b1a01388f243,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-632d1d26-e6d8-45ea-a3ce-fdbf64912323,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-9f6827ab-8cfc-4d47-bdbf-afd672c7beec,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-44c57d46-14a0-46a4-84d3-c124195c4d16,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-58bfa4dc-ff37-409f-b912-fc3d40f5a1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-e3864e23-a39c-45b0-94a5-742130ed7a61,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-217cc8e0-73bd-43ed-9918-6cf778c7188c,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-0eaf3561-227e-44f2-9960-6e3353740c96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294856942-172.17.0.2-1597742151192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41055,DS-c732a188-0a7d-49e7-be43-b1a01388f243,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-632d1d26-e6d8-45ea-a3ce-fdbf64912323,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-9f6827ab-8cfc-4d47-bdbf-afd672c7beec,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-44c57d46-14a0-46a4-84d3-c124195c4d16,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-58bfa4dc-ff37-409f-b912-fc3d40f5a1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-e3864e23-a39c-45b0-94a5-742130ed7a61,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-217cc8e0-73bd-43ed-9918-6cf778c7188c,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-0eaf3561-227e-44f2-9960-6e3353740c96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202005877-172.17.0.2-1597742331281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43027,DS-26959856-c36a-4747-9a32-ce00154de11c,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-b9d57cbb-b58d-4d41-84af-4f1d9927bdff,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-79250d73-428f-40f3-9add-c2bf57842d34,DISK], DatanodeInfoWithStorage[127.0.0.1:41623,DS-d29ea1e3-575c-40f5-aabf-ed11d8716ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-ae179d06-00be-4ea8-bcbe-6fa0bd44ec0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-505a853c-960b-4e76-bb0d-53e2123839ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-e7de7b2f-86ea-443f-920d-76dbd08bf305,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-cb5b2b0c-cd85-4ad6-bb2b-fe054cbf159f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202005877-172.17.0.2-1597742331281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43027,DS-26959856-c36a-4747-9a32-ce00154de11c,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-b9d57cbb-b58d-4d41-84af-4f1d9927bdff,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-79250d73-428f-40f3-9add-c2bf57842d34,DISK], DatanodeInfoWithStorage[127.0.0.1:41623,DS-d29ea1e3-575c-40f5-aabf-ed11d8716ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-ae179d06-00be-4ea8-bcbe-6fa0bd44ec0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-505a853c-960b-4e76-bb0d-53e2123839ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-e7de7b2f-86ea-443f-920d-76dbd08bf305,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-cb5b2b0c-cd85-4ad6-bb2b-fe054cbf159f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2121301646-172.17.0.2-1597743238782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43110,DS-f1431339-a925-4c99-b3a6-6e1c9386fff8,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-268c0d56-1976-465d-b659-2430a1d93697,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-c42529e8-a073-45af-b22f-1987d3d71cce,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-766808ed-720a-4323-8977-fe5ee215c092,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-ac6219d1-92d0-4955-ab0f-0e3a104f21ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-5097c07a-51db-4949-8226-21143786a024,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-2f1910c6-88c7-4321-99ef-ee18613372f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-a7774736-75f0-4a4a-9273-e73e3b168dfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2121301646-172.17.0.2-1597743238782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43110,DS-f1431339-a925-4c99-b3a6-6e1c9386fff8,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-268c0d56-1976-465d-b659-2430a1d93697,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-c42529e8-a073-45af-b22f-1987d3d71cce,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-766808ed-720a-4323-8977-fe5ee215c092,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-ac6219d1-92d0-4955-ab0f-0e3a104f21ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-5097c07a-51db-4949-8226-21143786a024,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-2f1910c6-88c7-4321-99ef-ee18613372f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-a7774736-75f0-4a4a-9273-e73e3b168dfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249684000-172.17.0.2-1597743731058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39602,DS-ccbf7619-d16d-453b-a95f-833158d736d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-0551ecb9-b9e3-4716-9e35-dbbeae728721,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-c73b7d81-9591-4311-8488-411736b3b988,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-15ac9a16-a8b1-4f5a-8442-cd32044db6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-08b2fc1f-e895-4d3f-9dd8-9e419952915c,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-2fdf70d7-45b2-4ac2-a49d-1f9e07eabeb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-a69028f2-42ec-4c7c-96e8-829e52383dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-2c6b8ffe-f851-4c9a-85f6-66fe5bdbddf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249684000-172.17.0.2-1597743731058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39602,DS-ccbf7619-d16d-453b-a95f-833158d736d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-0551ecb9-b9e3-4716-9e35-dbbeae728721,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-c73b7d81-9591-4311-8488-411736b3b988,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-15ac9a16-a8b1-4f5a-8442-cd32044db6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-08b2fc1f-e895-4d3f-9dd8-9e419952915c,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-2fdf70d7-45b2-4ac2-a49d-1f9e07eabeb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-a69028f2-42ec-4c7c-96e8-829e52383dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-2c6b8ffe-f851-4c9a-85f6-66fe5bdbddf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1935494715-172.17.0.2-1597743838976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39004,DS-52067154-da9c-4680-9961-ed1151df2ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-b1cd791b-0af0-4e44-9b91-46e4e9e4c926,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-7ce9ae39-110e-4913-ace2-ed6b22eebf58,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-71ecab14-d7f6-472e-a4bb-101b0bf29fec,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-72c66d65-7ec5-421c-8c9a-2beae5dee12f,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-df04c6d1-d23f-42d1-9e06-7079dd35da6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-46fa9852-72ef-4646-a647-247ec1f6b236,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-82001a35-27c8-4d13-9027-3e1b87fdd574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1935494715-172.17.0.2-1597743838976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39004,DS-52067154-da9c-4680-9961-ed1151df2ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-b1cd791b-0af0-4e44-9b91-46e4e9e4c926,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-7ce9ae39-110e-4913-ace2-ed6b22eebf58,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-71ecab14-d7f6-472e-a4bb-101b0bf29fec,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-72c66d65-7ec5-421c-8c9a-2beae5dee12f,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-df04c6d1-d23f-42d1-9e06-7079dd35da6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-46fa9852-72ef-4646-a647-247ec1f6b236,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-82001a35-27c8-4d13-9027-3e1b87fdd574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 0
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475337462-172.17.0.2-1597744262422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45064,DS-1bf67fbe-ba65-4320-b2cf-fdc8ed4154ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-bc290334-4e3f-4aed-9853-0b900904a50c,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-2b87bd20-53e0-41e4-a010-09846b8f1f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-1f0e9dd6-98db-48a3-9c1d-7bb93f2766d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-6a38ebf1-b396-4d0e-ab84-7b833b36c5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-668ba8ae-23f0-4f3e-989d-f0195623ac3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-7082a0f9-83ec-4821-a8c0-e85417bdeab4,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-079f2487-58d4-4053-8d22-ceafa80257dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475337462-172.17.0.2-1597744262422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45064,DS-1bf67fbe-ba65-4320-b2cf-fdc8ed4154ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-bc290334-4e3f-4aed-9853-0b900904a50c,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-2b87bd20-53e0-41e4-a010-09846b8f1f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-1f0e9dd6-98db-48a3-9c1d-7bb93f2766d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-6a38ebf1-b396-4d0e-ab84-7b833b36c5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-668ba8ae-23f0-4f3e-989d-f0195623ac3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-7082a0f9-83ec-4821-a8c0-e85417bdeab4,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-079f2487-58d4-4053-8d22-ceafa80257dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5666
