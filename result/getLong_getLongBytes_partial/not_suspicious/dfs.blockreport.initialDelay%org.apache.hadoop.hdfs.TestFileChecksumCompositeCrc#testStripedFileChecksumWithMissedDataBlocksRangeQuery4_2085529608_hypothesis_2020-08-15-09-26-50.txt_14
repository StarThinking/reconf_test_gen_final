reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-457664522-172.17.0.2-1597483627713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46109,DS-9c0d44e8-69a2-4867-b608-c8606a932df9,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-3f87236f-7fdd-49c5-b26d-c7b0f9330e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-8b90e0b2-5fc8-4e0a-af28-612241c61794,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-3ab018a8-68d0-4366-8899-1f35a72298d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-232da617-f68f-40df-9691-c3dea119074c,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-aead7fc3-8d73-424c-b327-30a409669382,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-7d58948a-5a3c-4f5f-bced-44a52397df8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-a20d8e37-2d0c-42c7-afc8-2c18e283b1dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-457664522-172.17.0.2-1597483627713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46109,DS-9c0d44e8-69a2-4867-b608-c8606a932df9,DISK], DatanodeInfoWithStorage[127.0.0.1:42351,DS-3f87236f-7fdd-49c5-b26d-c7b0f9330e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-8b90e0b2-5fc8-4e0a-af28-612241c61794,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-3ab018a8-68d0-4366-8899-1f35a72298d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-232da617-f68f-40df-9691-c3dea119074c,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-aead7fc3-8d73-424c-b327-30a409669382,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-7d58948a-5a3c-4f5f-bced-44a52397df8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-a20d8e37-2d0c-42c7-afc8-2c18e283b1dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1137797939-172.17.0.2-1597483812729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41245,DS-8f6b98fc-bae1-4a70-a425-1bce796d8858,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-fd682753-6aac-4c71-98dc-139677117ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-f1549eb5-2655-4595-8a44-642c8891520a,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-c2298faf-4896-42f8-9290-76337f2418b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-8460452b-3f3f-4953-b706-e14f994940b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-5891060a-20bb-4838-addf-7dbded1e7a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-4c90e28a-32bd-417b-8516-ffb1d2da367d,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-57d54389-a0ac-4caa-888f-685e46fcd5f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1137797939-172.17.0.2-1597483812729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41245,DS-8f6b98fc-bae1-4a70-a425-1bce796d8858,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-fd682753-6aac-4c71-98dc-139677117ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-f1549eb5-2655-4595-8a44-642c8891520a,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-c2298faf-4896-42f8-9290-76337f2418b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-8460452b-3f3f-4953-b706-e14f994940b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-5891060a-20bb-4838-addf-7dbded1e7a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-4c90e28a-32bd-417b-8516-ffb1d2da367d,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-57d54389-a0ac-4caa-888f-685e46fcd5f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599280420-172.17.0.2-1597484094011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35051,DS-ea7132d4-5f72-4007-8b55-ee261d1a83b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-7d0eb86b-9068-474d-a6cf-429717c30cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-222972ef-f2df-4106-bdb6-b6cd5351a244,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-4ec0fc1c-034c-4dad-8d1d-96d0bb613fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-b7dd0692-eb82-4b2c-932f-b2e639f33209,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-6b670a7a-eb3b-4e79-91eb-0919e7fc9ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-ed35f12c-e338-4b2f-9fd5-8b8628f13061,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-209b71d6-fc3c-490f-87bf-92f4d4d38d71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599280420-172.17.0.2-1597484094011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35051,DS-ea7132d4-5f72-4007-8b55-ee261d1a83b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-7d0eb86b-9068-474d-a6cf-429717c30cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-222972ef-f2df-4106-bdb6-b6cd5351a244,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-4ec0fc1c-034c-4dad-8d1d-96d0bb613fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-b7dd0692-eb82-4b2c-932f-b2e639f33209,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-6b670a7a-eb3b-4e79-91eb-0919e7fc9ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-ed35f12c-e338-4b2f-9fd5-8b8628f13061,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-209b71d6-fc3c-490f-87bf-92f4d4d38d71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-238045076-172.17.0.2-1597484693807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39424,DS-e07d6e78-fbfd-4b32-9e04-bba7365411aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-dab78512-e9fe-4038-a8b6-5c0bb203491f,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-83af69a9-feed-4e0e-b468-0d7ce593295d,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-e127663a-b39b-446b-b8ba-4bed27fb6cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-3bc567f2-424c-4c51-9a49-2a523e076a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-52946234-d83e-49c5-a588-0e31732cb122,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-cd924056-2580-4674-b199-0c7b60c926d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-25344426-ec88-4c80-8d0d-0e401d756aec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-238045076-172.17.0.2-1597484693807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39424,DS-e07d6e78-fbfd-4b32-9e04-bba7365411aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-dab78512-e9fe-4038-a8b6-5c0bb203491f,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-83af69a9-feed-4e0e-b468-0d7ce593295d,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-e127663a-b39b-446b-b8ba-4bed27fb6cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-3bc567f2-424c-4c51-9a49-2a523e076a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-52946234-d83e-49c5-a588-0e31732cb122,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-cd924056-2580-4674-b199-0c7b60c926d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-25344426-ec88-4c80-8d0d-0e401d756aec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968614283-172.17.0.2-1597484991348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46821,DS-fd27cb7c-5bbe-4329-9bf4-8fcd82a64fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-de8bd205-f1df-4d6d-a5f4-daf311de553b,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-848d5470-6e1d-47cd-a2cd-a846fa3706a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-87265024-a788-4920-9a19-a53816d65420,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-097251ab-7ad2-47bb-ba55-51a275689fea,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-5d8b9986-8fa9-4e8e-99f1-16f779e9012b,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-a73ad06a-3fe7-4da3-ba32-1712eb1d6895,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-4d936464-9c84-4f10-a678-190fc6172ef2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968614283-172.17.0.2-1597484991348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46821,DS-fd27cb7c-5bbe-4329-9bf4-8fcd82a64fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-de8bd205-f1df-4d6d-a5f4-daf311de553b,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-848d5470-6e1d-47cd-a2cd-a846fa3706a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-87265024-a788-4920-9a19-a53816d65420,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-097251ab-7ad2-47bb-ba55-51a275689fea,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-5d8b9986-8fa9-4e8e-99f1-16f779e9012b,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-a73ad06a-3fe7-4da3-ba32-1712eb1d6895,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-4d936464-9c84-4f10-a678-190fc6172ef2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1859233206-172.17.0.2-1597485028935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35515,DS-9c3cf9f2-317b-4b74-96de-29f627bae19c,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-279bec44-fec5-490c-af6a-1730d482e409,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-c501488f-d99b-443d-9fea-a08b49933cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-27619fb4-3f1c-4882-9d55-45cfe9bab305,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-6fa68b3a-6428-47f6-914d-691640a0c544,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-abd50c29-3519-41ff-aa44-b1fcede1fadc,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-0c455119-2575-48db-99bb-7858c8889081,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-69797d63-771c-489c-abe0-fc54d343054b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1859233206-172.17.0.2-1597485028935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35515,DS-9c3cf9f2-317b-4b74-96de-29f627bae19c,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-279bec44-fec5-490c-af6a-1730d482e409,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-c501488f-d99b-443d-9fea-a08b49933cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-27619fb4-3f1c-4882-9d55-45cfe9bab305,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-6fa68b3a-6428-47f6-914d-691640a0c544,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-abd50c29-3519-41ff-aa44-b1fcede1fadc,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-0c455119-2575-48db-99bb-7858c8889081,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-69797d63-771c-489c-abe0-fc54d343054b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107357643-172.17.0.2-1597485229992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45786,DS-71b36127-c343-46fb-a4f9-a7226776fe7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-0e207186-1f30-4cb6-8da8-cc0ce156256e,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-3c00521d-5cab-4e1c-979f-62cf73c0b07c,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-a403bfcd-407e-4ecc-98be-04980359ab58,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-936cfc73-169f-42a5-a751-0ebff284be75,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-b72360e7-25e3-43f8-9cc0-799788356c58,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-62099499-d9cf-44af-8d39-fd41d83afef8,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-8f8b2358-c1bb-412f-b6f3-d97625ca0a73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107357643-172.17.0.2-1597485229992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45786,DS-71b36127-c343-46fb-a4f9-a7226776fe7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-0e207186-1f30-4cb6-8da8-cc0ce156256e,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-3c00521d-5cab-4e1c-979f-62cf73c0b07c,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-a403bfcd-407e-4ecc-98be-04980359ab58,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-936cfc73-169f-42a5-a751-0ebff284be75,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-b72360e7-25e3-43f8-9cc0-799788356c58,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-62099499-d9cf-44af-8d39-fd41d83afef8,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-8f8b2358-c1bb-412f-b6f3-d97625ca0a73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1882745289-172.17.0.2-1597485701990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42132,DS-0d822b9c-2f0e-46f0-946a-f27260420e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-e2ae6de7-7b71-4ef6-bde0-fb73ce0ed991,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-774f2d4d-048b-4a08-9ff8-e68b45469a28,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-f8f4703f-549c-4962-9f27-813d7f2c5575,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-cd5dc986-6ae4-430d-8d5f-491cdf76cd27,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-dc373231-b4c7-4489-934e-0baa24edec4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-c0b9559a-8a01-470f-923f-7edaf6745c68,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-4cb9be7a-f9fe-4a4c-98bc-87cabd5e7704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1882745289-172.17.0.2-1597485701990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42132,DS-0d822b9c-2f0e-46f0-946a-f27260420e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-e2ae6de7-7b71-4ef6-bde0-fb73ce0ed991,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-774f2d4d-048b-4a08-9ff8-e68b45469a28,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-f8f4703f-549c-4962-9f27-813d7f2c5575,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-cd5dc986-6ae4-430d-8d5f-491cdf76cd27,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-dc373231-b4c7-4489-934e-0baa24edec4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-c0b9559a-8a01-470f-923f-7edaf6745c68,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-4cb9be7a-f9fe-4a4c-98bc-87cabd5e7704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1493829907-172.17.0.2-1597486702238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33873,DS-a153b77e-d0da-4db0-8ad8-b52cc84042c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-3599e363-07a7-4b0e-9201-a3f230818814,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-91c3c18d-c3cf-419c-82c1-2280a493e9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-46cc9a52-1c9a-4f2d-b019-b2d0acebf8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-cb1c71e6-1bdf-465b-942b-61c9cdfd7192,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-ae63fc6a-97dd-4628-b7e6-b248c1599f47,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-a69f8ece-08d0-4af2-a566-980f5277d7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-ac964e5a-88bc-4d99-b327-96e269d0c796,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1493829907-172.17.0.2-1597486702238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33873,DS-a153b77e-d0da-4db0-8ad8-b52cc84042c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-3599e363-07a7-4b0e-9201-a3f230818814,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-91c3c18d-c3cf-419c-82c1-2280a493e9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-46cc9a52-1c9a-4f2d-b019-b2d0acebf8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-cb1c71e6-1bdf-465b-942b-61c9cdfd7192,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-ae63fc6a-97dd-4628-b7e6-b248c1599f47,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-a69f8ece-08d0-4af2-a566-980f5277d7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-ac964e5a-88bc-4d99-b327-96e269d0c796,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609052591-172.17.0.2-1597486862714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40696,DS-f80ec4ed-6a8e-4ab0-bccf-31b8c51826fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-5207d08a-8c65-4d2a-a3cf-0bfe1d8c6cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38142,DS-6f2c8040-98b1-42f3-98fd-6bcd196e9211,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-ea2b4729-92aa-4bfa-987e-dc9033b6121f,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-1f84e28a-a787-40fd-8def-fb8d1766e384,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-7511e942-83fc-428f-bca0-eeef754d61b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-cacf2fae-11d7-4864-b727-3b372c695165,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-d53dab2d-2e09-42ad-aafb-848ff8cab4c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609052591-172.17.0.2-1597486862714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40696,DS-f80ec4ed-6a8e-4ab0-bccf-31b8c51826fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-5207d08a-8c65-4d2a-a3cf-0bfe1d8c6cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38142,DS-6f2c8040-98b1-42f3-98fd-6bcd196e9211,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-ea2b4729-92aa-4bfa-987e-dc9033b6121f,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-1f84e28a-a787-40fd-8def-fb8d1766e384,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-7511e942-83fc-428f-bca0-eeef754d61b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-cacf2fae-11d7-4864-b727-3b372c695165,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-d53dab2d-2e09-42ad-aafb-848ff8cab4c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-511041886-172.17.0.2-1597487302824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34189,DS-cb115d64-6114-4fde-96a3-deb7fb18452a,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-ce55e207-4fef-47b1-95f7-78f75a9324b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-c7c62e98-4095-4ac8-847c-b8d6da6a91de,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-79633789-584b-4ea4-ab96-e95334b62755,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-f4d37cde-5ea0-4495-926c-36a282b3431a,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-96f47867-e12d-4335-bb14-8cbd57c256c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-56af3627-97c7-4463-9a7f-6b081db65251,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-e68cfc26-f3db-438f-8ccc-f140a16081fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-511041886-172.17.0.2-1597487302824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34189,DS-cb115d64-6114-4fde-96a3-deb7fb18452a,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-ce55e207-4fef-47b1-95f7-78f75a9324b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-c7c62e98-4095-4ac8-847c-b8d6da6a91de,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-79633789-584b-4ea4-ab96-e95334b62755,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-f4d37cde-5ea0-4495-926c-36a282b3431a,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-96f47867-e12d-4335-bb14-8cbd57c256c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-56af3627-97c7-4463-9a7f-6b081db65251,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-e68cfc26-f3db-438f-8ccc-f140a16081fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1774754242-172.17.0.2-1597487788690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36537,DS-fc02798e-df71-4d61-9870-66801616792f,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-763af5fd-3a1d-4585-b582-f5a6cd37a218,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-9beec1fb-ad55-4355-aa20-12bfd951f110,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-aee7e236-482e-4fed-81ae-71a1cdf0cf60,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-09163e1e-8fad-4eff-bbf2-e5272adf43f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-5124fe2d-16b0-4a22-a4b7-0e3a5d37a2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-9d6bce98-e9ca-4fbb-a279-098cee6c6c84,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-9a352aa7-fc02-4bca-8111-dbee631912e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1774754242-172.17.0.2-1597487788690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36537,DS-fc02798e-df71-4d61-9870-66801616792f,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-763af5fd-3a1d-4585-b582-f5a6cd37a218,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-9beec1fb-ad55-4355-aa20-12bfd951f110,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-aee7e236-482e-4fed-81ae-71a1cdf0cf60,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-09163e1e-8fad-4eff-bbf2-e5272adf43f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-5124fe2d-16b0-4a22-a4b7-0e3a5d37a2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-9d6bce98-e9ca-4fbb-a279-098cee6c6c84,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-9a352aa7-fc02-4bca-8111-dbee631912e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1292408998-172.17.0.2-1597487824464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46865,DS-caf5e40e-4749-4b90-b981-dc806b178b41,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-0b31e29c-95ce-4768-8d5f-c7ee69239f40,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-b11ac30f-bd17-4a1f-b33d-02888055bf5b,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-3ff8c5b0-fc02-454c-bb90-d8d9cfbbc0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-9c5e1cf9-605a-43c7-8334-18c2cc3629e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-64fa75d1-a654-425b-a097-78ce5a67f5df,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-82a65062-2390-410e-996b-3b99aaa33c26,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-a2cb15c4-9ac2-4255-b5c8-9b112a32e97e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1292408998-172.17.0.2-1597487824464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46865,DS-caf5e40e-4749-4b90-b981-dc806b178b41,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-0b31e29c-95ce-4768-8d5f-c7ee69239f40,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-b11ac30f-bd17-4a1f-b33d-02888055bf5b,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-3ff8c5b0-fc02-454c-bb90-d8d9cfbbc0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-9c5e1cf9-605a-43c7-8334-18c2cc3629e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-64fa75d1-a654-425b-a097-78ce5a67f5df,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-82a65062-2390-410e-996b-3b99aaa33c26,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-a2cb15c4-9ac2-4255-b5c8-9b112a32e97e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612622657-172.17.0.2-1597488625649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39430,DS-c9c48f1d-0325-40b7-9681-42ffabb6dee9,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-8c29f095-3c4a-4ee0-82c8-311749ac2f74,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-32bef36f-ca55-46b2-908c-3d5d45a9121c,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-d2616f7a-f25a-47eb-942e-32e1408f1886,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-008ddbcb-ad03-4f8a-be1e-b49dd4b98de5,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-23ee1e44-199c-47e2-9474-1598366d1775,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-ea0fc08b-aeac-4d06-bc2f-e9248b840552,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-3807712c-3560-45d3-948a-32186db86281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612622657-172.17.0.2-1597488625649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39430,DS-c9c48f1d-0325-40b7-9681-42ffabb6dee9,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-8c29f095-3c4a-4ee0-82c8-311749ac2f74,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-32bef36f-ca55-46b2-908c-3d5d45a9121c,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-d2616f7a-f25a-47eb-942e-32e1408f1886,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-008ddbcb-ad03-4f8a-be1e-b49dd4b98de5,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-23ee1e44-199c-47e2-9474-1598366d1775,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-ea0fc08b-aeac-4d06-bc2f-e9248b840552,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-3807712c-3560-45d3-948a-32186db86281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1637790493-172.17.0.2-1597488672478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38980,DS-b13d2cc2-495b-4cb4-b273-3d6fb1787938,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-64980dea-55eb-4d73-ae23-1fbdaf49b299,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-4174afbb-01bf-4ae1-8ef5-af64f9a43c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-3896042e-0ddf-4da8-a182-dcf2722ddc35,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-c298abc3-e808-4fd4-898c-8074ae82bd84,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-9c8df20e-3c37-4db6-9cf5-1809ed402301,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-9e6ec8c0-3fa9-4de3-8627-87d639a721cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-3038679e-a1f7-4e5a-9ab4-d4b7741b55b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1637790493-172.17.0.2-1597488672478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38980,DS-b13d2cc2-495b-4cb4-b273-3d6fb1787938,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-64980dea-55eb-4d73-ae23-1fbdaf49b299,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-4174afbb-01bf-4ae1-8ef5-af64f9a43c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-3896042e-0ddf-4da8-a182-dcf2722ddc35,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-c298abc3-e808-4fd4-898c-8074ae82bd84,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-9c8df20e-3c37-4db6-9cf5-1809ed402301,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-9e6ec8c0-3fa9-4de3-8627-87d639a721cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-3038679e-a1f7-4e5a-9ab4-d4b7741b55b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-613963879-172.17.0.2-1597488830845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33781,DS-d223673e-bd8d-4eba-84e6-bf62e4467412,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-871f52ca-1135-49da-a8a5-d9beaae9cfea,DISK], DatanodeInfoWithStorage[127.0.0.1:42019,DS-250429f5-d172-46c9-826f-47bae20c79ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-07ff539f-22ba-4918-ba60-47e08c7a2b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-7e0705f4-ec9c-4daa-b08f-6662efbfa65b,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-4901c170-90e8-43d4-b25b-0b0487da5a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-8ccad8c6-a889-489d-af23-164c15946399,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-be4324f4-6003-48c1-b366-952540993931,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-613963879-172.17.0.2-1597488830845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33781,DS-d223673e-bd8d-4eba-84e6-bf62e4467412,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-871f52ca-1135-49da-a8a5-d9beaae9cfea,DISK], DatanodeInfoWithStorage[127.0.0.1:42019,DS-250429f5-d172-46c9-826f-47bae20c79ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-07ff539f-22ba-4918-ba60-47e08c7a2b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-7e0705f4-ec9c-4daa-b08f-6662efbfa65b,DISK], DatanodeInfoWithStorage[127.0.0.1:46358,DS-4901c170-90e8-43d4-b25b-0b0487da5a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-8ccad8c6-a889-489d-af23-164c15946399,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-be4324f4-6003-48c1-b366-952540993931,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 100ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1321494516-172.17.0.2-1597489208703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33454,DS-a3dbc154-98d3-48a3-83c3-670c05648054,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-04350d51-772b-4df7-bb12-77ad145493fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-1c6491f8-3d97-42c9-830c-3a131c1a7ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-fa679d1a-72a9-4fa5-a031-aaaa681ac701,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-6c4053b3-800d-4065-aa92-5faeca9fa7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-9e955461-d068-4da1-bb46-49493ce60ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-eae8733c-8408-4e16-8d15-0aa8a9135b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-1362d07b-7bf3-4fae-b1b3-d57df59f453c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1321494516-172.17.0.2-1597489208703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33454,DS-a3dbc154-98d3-48a3-83c3-670c05648054,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-04350d51-772b-4df7-bb12-77ad145493fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-1c6491f8-3d97-42c9-830c-3a131c1a7ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-fa679d1a-72a9-4fa5-a031-aaaa681ac701,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-6c4053b3-800d-4065-aa92-5faeca9fa7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-9e955461-d068-4da1-bb46-49493ce60ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-eae8733c-8408-4e16-8d15-0aa8a9135b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-1362d07b-7bf3-4fae-b1b3-d57df59f453c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5695
