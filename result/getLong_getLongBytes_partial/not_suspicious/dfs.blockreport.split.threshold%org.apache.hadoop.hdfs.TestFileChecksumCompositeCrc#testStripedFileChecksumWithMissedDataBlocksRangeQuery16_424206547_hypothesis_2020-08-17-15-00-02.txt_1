reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1496044523-172.17.0.6-1597677291127:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38201,DS-a23f7bef-c7de-484f-9ba4-c3ff299a8d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-4543052f-2b15-4a11-83a1-1e42ccceed85,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-e5f925e7-1865-4fe4-8603-d06c3364ad18,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-28e033d8-d751-43d8-9a81-510267e9f491,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-acd67600-0a9c-466d-b6d9-fc322908869a,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-73d93f6e-a49a-49f6-b036-e7870daa5eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-bf639231-1152-4cb3-a7b8-5207cef60f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41658,DS-f09b78fa-7002-4739-9348-09005a456888,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1496044523-172.17.0.6-1597677291127:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38201,DS-a23f7bef-c7de-484f-9ba4-c3ff299a8d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-4543052f-2b15-4a11-83a1-1e42ccceed85,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-e5f925e7-1865-4fe4-8603-d06c3364ad18,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-28e033d8-d751-43d8-9a81-510267e9f491,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-acd67600-0a9c-466d-b6d9-fc322908869a,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-73d93f6e-a49a-49f6-b036-e7870daa5eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-bf639231-1152-4cb3-a7b8-5207cef60f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41658,DS-f09b78fa-7002-4739-9348-09005a456888,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-955151731-172.17.0.6-1597677701380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35410,DS-23f2196b-9238-4a83-94bd-a34c4a5d4382,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-370be5d6-9f33-47d3-8d1b-ec06510899f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38851,DS-6668e06c-1994-4c5d-9939-fb77d8a49992,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-bba9edf3-cd18-4bc2-9e4d-b8b077860bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41265,DS-a0f6c310-f628-4134-b30b-59bab2fc93ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-83ff9536-14fe-4125-a820-91f7beb1eec9,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-f6405e9c-3f78-45bc-9f82-cb5bfb8cd88a,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-f6c7ecf7-8965-4cc0-9ca3-c83130828a5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-955151731-172.17.0.6-1597677701380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35410,DS-23f2196b-9238-4a83-94bd-a34c4a5d4382,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-370be5d6-9f33-47d3-8d1b-ec06510899f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38851,DS-6668e06c-1994-4c5d-9939-fb77d8a49992,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-bba9edf3-cd18-4bc2-9e4d-b8b077860bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41265,DS-a0f6c310-f628-4134-b30b-59bab2fc93ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-83ff9536-14fe-4125-a820-91f7beb1eec9,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-f6405e9c-3f78-45bc-9f82-cb5bfb8cd88a,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-f6c7ecf7-8965-4cc0-9ca3-c83130828a5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2137662133-172.17.0.6-1597677951981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39482,DS-aef8074e-4dd3-429a-8757-61ade33e179e,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-f1026d5b-710e-40d9-974c-dafdf2fb2b83,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-f3f00edb-7486-411b-bb8b-1ebc2462cf02,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-4e6d651f-0264-4dc7-b224-33b099031488,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-53275bf1-d5b8-4875-9817-ce28bc045e12,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-68d3dc09-8238-4483-85b7-5618021941c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-8ffa2712-2088-4915-acb7-be1c2ff8d6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-5598e25f-e4ba-40da-a283-8746fdf591fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2137662133-172.17.0.6-1597677951981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39482,DS-aef8074e-4dd3-429a-8757-61ade33e179e,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-f1026d5b-710e-40d9-974c-dafdf2fb2b83,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-f3f00edb-7486-411b-bb8b-1ebc2462cf02,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-4e6d651f-0264-4dc7-b224-33b099031488,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-53275bf1-d5b8-4875-9817-ce28bc045e12,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-68d3dc09-8238-4483-85b7-5618021941c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-8ffa2712-2088-4915-acb7-be1c2ff8d6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-5598e25f-e4ba-40da-a283-8746fdf591fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1419718116-172.17.0.6-1597678213512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45499,DS-2bfc31eb-52a3-4ca9-8dc7-dac2ae961dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-0dcf56c2-0900-4c7e-83af-6b7b8f164d45,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-ff71a92d-db67-4c43-8d04-09810f56634d,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-718ffd31-607d-4b30-8922-de4e9228c63b,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-9661fe15-86a8-4f28-979d-eafc875a6a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-baa93a96-1f69-44d6-bcff-c428eab4b758,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-1c16ae67-8e20-44cf-9b1a-bcaeda07827e,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-2b4c2173-acfd-45f9-8c81-5bab87a98837,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1419718116-172.17.0.6-1597678213512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45499,DS-2bfc31eb-52a3-4ca9-8dc7-dac2ae961dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-0dcf56c2-0900-4c7e-83af-6b7b8f164d45,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-ff71a92d-db67-4c43-8d04-09810f56634d,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-718ffd31-607d-4b30-8922-de4e9228c63b,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-9661fe15-86a8-4f28-979d-eafc875a6a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-baa93a96-1f69-44d6-bcff-c428eab4b758,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-1c16ae67-8e20-44cf-9b1a-bcaeda07827e,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-2b4c2173-acfd-45f9-8c81-5bab87a98837,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1033994557-172.17.0.6-1597678258545:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38721,DS-fda03a86-8eef-4a69-b8ac-4801e9761b17,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-e1eda3b7-9982-4fbf-91a3-d1306b1dd63c,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-b9f9b211-36ce-467e-b0ee-5c0144c8f548,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-1d936923-eec2-4fcb-942e-1c13dcf6896e,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-4f5e01c0-e43e-4fed-b0fa-6382b179ac47,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-a86be6fc-314c-4c16-96e8-0f719ffd764e,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-788f2425-f7c1-441d-9101-4c8d381d7609,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-5d247727-b697-424a-aee0-14c2bd9d0fbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1033994557-172.17.0.6-1597678258545:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38721,DS-fda03a86-8eef-4a69-b8ac-4801e9761b17,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-e1eda3b7-9982-4fbf-91a3-d1306b1dd63c,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-b9f9b211-36ce-467e-b0ee-5c0144c8f548,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-1d936923-eec2-4fcb-942e-1c13dcf6896e,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-4f5e01c0-e43e-4fed-b0fa-6382b179ac47,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-a86be6fc-314c-4c16-96e8-0f719ffd764e,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-788f2425-f7c1-441d-9101-4c8d381d7609,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-5d247727-b697-424a-aee0-14c2bd9d0fbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-207251347-172.17.0.6-1597678786530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36981,DS-d0f25251-7919-495a-9934-e023407b006a,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-c9e8b5e0-e3f8-40a9-9e99-d9448372df21,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-96900596-113c-4b3a-947c-1ddda7b16d09,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-0aa87b42-26a9-49ec-b994-e10551262774,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-8b2887e1-fc53-4360-92c6-8d39254f7f32,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-ad42d301-5a67-4331-992f-1855888f6ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-24f105c4-0c54-466c-8b81-dab790f5a874,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-f94825a5-8b31-4bdb-8b4b-ebb6398ac36a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-207251347-172.17.0.6-1597678786530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36981,DS-d0f25251-7919-495a-9934-e023407b006a,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-c9e8b5e0-e3f8-40a9-9e99-d9448372df21,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-96900596-113c-4b3a-947c-1ddda7b16d09,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-0aa87b42-26a9-49ec-b994-e10551262774,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-8b2887e1-fc53-4360-92c6-8d39254f7f32,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-ad42d301-5a67-4331-992f-1855888f6ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-24f105c4-0c54-466c-8b81-dab790f5a874,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-f94825a5-8b31-4bdb-8b4b-ebb6398ac36a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-71539991-172.17.0.6-1597678826946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45401,DS-bb4e95e7-72c8-42bb-a2d0-bebf9331f333,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-35502813-a1a2-4d0d-a00a-ddbfc65d7d31,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-99e3a1b0-021d-4c63-b632-7bc589daefdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-399af5e8-005e-405f-898d-102148ddd401,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-e9fc57cf-1089-417c-977e-45775413a1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-b3946708-9c55-4a49-8d34-d8430f1d5559,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-1c85a150-9b27-4e0f-9a41-d3c13ea7f1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-5546a1c5-e593-449f-8cda-8d41c62ad0b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-71539991-172.17.0.6-1597678826946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45401,DS-bb4e95e7-72c8-42bb-a2d0-bebf9331f333,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-35502813-a1a2-4d0d-a00a-ddbfc65d7d31,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-99e3a1b0-021d-4c63-b632-7bc589daefdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-399af5e8-005e-405f-898d-102148ddd401,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-e9fc57cf-1089-417c-977e-45775413a1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-b3946708-9c55-4a49-8d34-d8430f1d5559,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-1c85a150-9b27-4e0f-9a41-d3c13ea7f1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-5546a1c5-e593-449f-8cda-8d41c62ad0b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1493429654-172.17.0.6-1597678936795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38373,DS-c775ccdb-9e8e-4e2e-b0c6-f1987e76cf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-fc2fd06a-f8fa-4270-ad5a-69161e9ac364,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-bd28e4bb-6e78-4e52-abc9-3c34b882c305,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-3f9c5162-e8da-4248-bc5c-79322b6603f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-206afca5-a3d2-4ab6-b9d7-b0f969334cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-7c98b0ac-7a48-4fb5-9a06-012fcfd39383,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-90077f78-515e-4ab0-bb5f-98c8606796ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-fde5989c-899f-43cb-a119-603b5b774b73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1493429654-172.17.0.6-1597678936795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38373,DS-c775ccdb-9e8e-4e2e-b0c6-f1987e76cf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-fc2fd06a-f8fa-4270-ad5a-69161e9ac364,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-bd28e4bb-6e78-4e52-abc9-3c34b882c305,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-3f9c5162-e8da-4248-bc5c-79322b6603f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-206afca5-a3d2-4ab6-b9d7-b0f969334cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-7c98b0ac-7a48-4fb5-9a06-012fcfd39383,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-90077f78-515e-4ab0-bb5f-98c8606796ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-fde5989c-899f-43cb-a119-603b5b774b73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1105969805-172.17.0.6-1597679011411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33438,DS-78edb75d-756f-40c2-89ef-fd3259eb2ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-5b8f1d2a-3cea-4cd2-b16d-470f323a7386,DISK], DatanodeInfoWithStorage[127.0.0.1:33788,DS-2236ff50-6e2c-47c2-8132-b24dec071fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-7de6640e-6ddf-4342-b6ed-c30abaf5a817,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-43af2ea9-ede9-4cf0-a431-f939fb45deab,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-c22e0a78-c027-477d-877d-307be42dfea1,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-f1e2f076-10da-40d6-a676-98e8619080e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-0681ef3a-5aa3-4ea3-8eb3-0c46a17e38d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1105969805-172.17.0.6-1597679011411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33438,DS-78edb75d-756f-40c2-89ef-fd3259eb2ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-5b8f1d2a-3cea-4cd2-b16d-470f323a7386,DISK], DatanodeInfoWithStorage[127.0.0.1:33788,DS-2236ff50-6e2c-47c2-8132-b24dec071fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-7de6640e-6ddf-4342-b6ed-c30abaf5a817,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-43af2ea9-ede9-4cf0-a431-f939fb45deab,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-c22e0a78-c027-477d-877d-307be42dfea1,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-f1e2f076-10da-40d6-a676-98e8619080e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-0681ef3a-5aa3-4ea3-8eb3-0c46a17e38d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1514375961-172.17.0.6-1597679146322:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34503,DS-706cdc94-c3e6-4b07-ab1b-c5874fad3ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-d5a68ec7-8c93-434c-9569-9c7ef597ef30,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-6a9c72fc-5cf5-4bc5-9312-ecde4b299e55,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-66cf77d7-1725-4f4b-bd8e-196075958e63,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-2988a394-5656-4f58-b5c3-0ed25c9bcb79,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-267effa7-6ea5-4901-a089-e0f390282dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-994defa7-3f51-4b26-9c25-4cc847302d31,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-b050f1d4-d8a1-4f40-b419-b18458f9a484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1514375961-172.17.0.6-1597679146322:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34503,DS-706cdc94-c3e6-4b07-ab1b-c5874fad3ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-d5a68ec7-8c93-434c-9569-9c7ef597ef30,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-6a9c72fc-5cf5-4bc5-9312-ecde4b299e55,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-66cf77d7-1725-4f4b-bd8e-196075958e63,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-2988a394-5656-4f58-b5c3-0ed25c9bcb79,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-267effa7-6ea5-4901-a089-e0f390282dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-994defa7-3f51-4b26-9c25-4cc847302d31,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-b050f1d4-d8a1-4f40-b419-b18458f9a484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2100354618-172.17.0.6-1597679288757:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38788,DS-879ef5d6-dfdf-4c83-823d-8dad8fd1444c,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-a1996fc2-e7bf-41c5-bd58-2c714ad8ba65,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-24fd61a4-835f-41a3-be9d-403f716d5837,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-27cf43a4-302e-40a9-975b-6bc4f5807d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-8420822f-8a04-4386-8e3c-ace83e493753,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-735feba1-fd56-44e9-8a6c-d5295e9de825,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-98df114d-337b-468f-92b6-f0c20a1bafbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-f2220c0e-8058-4d33-bd2e-c86785b63fe4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2100354618-172.17.0.6-1597679288757:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38788,DS-879ef5d6-dfdf-4c83-823d-8dad8fd1444c,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-a1996fc2-e7bf-41c5-bd58-2c714ad8ba65,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-24fd61a4-835f-41a3-be9d-403f716d5837,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-27cf43a4-302e-40a9-975b-6bc4f5807d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-8420822f-8a04-4386-8e3c-ace83e493753,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-735feba1-fd56-44e9-8a6c-d5295e9de825,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-98df114d-337b-468f-92b6-f0c20a1bafbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-f2220c0e-8058-4d33-bd2e-c86785b63fe4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-375893142-172.17.0.6-1597679516881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39846,DS-14abfe27-7943-48c1-a2df-3cb68c44bb72,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-1a42c179-c24d-4abe-8588-f56f39e8ffd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-ed7508b2-531e-4a37-a864-1d58f9b9d901,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-2f082bf0-7a22-48fb-8a69-411edb5821b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-b976dd72-dc8b-4aa7-95ab-4919525b002a,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-26fc084d-ab59-4d26-ae05-135879fa877a,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-d02f59e8-766b-46c4-ad99-4c392139027c,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-4c8067a8-61d9-4d20-ae79-9991ae925839,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-375893142-172.17.0.6-1597679516881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39846,DS-14abfe27-7943-48c1-a2df-3cb68c44bb72,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-1a42c179-c24d-4abe-8588-f56f39e8ffd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-ed7508b2-531e-4a37-a864-1d58f9b9d901,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-2f082bf0-7a22-48fb-8a69-411edb5821b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-b976dd72-dc8b-4aa7-95ab-4919525b002a,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-26fc084d-ab59-4d26-ae05-135879fa877a,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-d02f59e8-766b-46c4-ad99-4c392139027c,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-4c8067a8-61d9-4d20-ae79-9991ae925839,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-48268122-172.17.0.6-1597679810766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43718,DS-02cfc4a0-4bd0-4daa-98e8-1b52b81d5ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-0c1f0e71-9f21-45cc-be2a-f68ede8e8d64,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-b27783f0-53f1-4f21-972c-c3fd24f8ff06,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-774be376-d5d7-4b1c-a814-4e351b1fd4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-dab77ef4-4cd8-4a26-b5bb-5a3fea01ad90,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-d20e4532-4ee1-4e04-814c-e7da8edded3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-3fd4330a-791f-4537-bb64-216efc86efe9,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-cfe4d872-1d0d-4ea1-a177-20c9dac6a76f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-48268122-172.17.0.6-1597679810766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43718,DS-02cfc4a0-4bd0-4daa-98e8-1b52b81d5ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-0c1f0e71-9f21-45cc-be2a-f68ede8e8d64,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-b27783f0-53f1-4f21-972c-c3fd24f8ff06,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-774be376-d5d7-4b1c-a814-4e351b1fd4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-dab77ef4-4cd8-4a26-b5bb-5a3fea01ad90,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-d20e4532-4ee1-4e04-814c-e7da8edded3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-3fd4330a-791f-4537-bb64-216efc86efe9,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-cfe4d872-1d0d-4ea1-a177-20c9dac6a76f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1814076333-172.17.0.6-1597679949777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36359,DS-5a8cc95d-399a-4b2e-948d-d5b7bc30b704,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-87838bd1-4423-446e-8faf-ec56203100b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-141c89cf-2b1b-499a-951f-77b41eaf4d91,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-f27b94d2-e6b6-4dcc-aedc-b4aae20d68b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-d65fe745-bf70-4184-9fe0-1f8511a12d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-19898a40-aa8b-4264-9226-f3cc8658936c,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-4dbfdc86-3260-4a88-96a6-d4c5439c7f69,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-2fe00568-b766-4f00-9cf0-18f5aa165ce5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1814076333-172.17.0.6-1597679949777:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36359,DS-5a8cc95d-399a-4b2e-948d-d5b7bc30b704,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-87838bd1-4423-446e-8faf-ec56203100b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-141c89cf-2b1b-499a-951f-77b41eaf4d91,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-f27b94d2-e6b6-4dcc-aedc-b4aae20d68b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-d65fe745-bf70-4184-9fe0-1f8511a12d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-19898a40-aa8b-4264-9226-f3cc8658936c,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-4dbfdc86-3260-4a88-96a6-d4c5439c7f69,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-2fe00568-b766-4f00-9cf0-18f5aa165ce5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-375600183-172.17.0.6-1597680133444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36544,DS-142c1003-e011-4edb-a98d-4081a478f01d,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-1d8b6b33-efca-4d69-bdbd-f65d76ce0260,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-e0deab21-1b2f-41d2-9702-d56af3218a09,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-ec10944b-78b5-4eda-9dbf-bebe0ef56633,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-401b7cb7-29b3-44c0-825e-19603b583930,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-056df4c5-8c8f-4d6c-869a-7c9eb5328756,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-5d47338b-25ba-45c1-ac8a-79bf7cd77feb,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-d204f243-e768-4fc7-8ce9-e26902160507,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-375600183-172.17.0.6-1597680133444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36544,DS-142c1003-e011-4edb-a98d-4081a478f01d,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-1d8b6b33-efca-4d69-bdbd-f65d76ce0260,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-e0deab21-1b2f-41d2-9702-d56af3218a09,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-ec10944b-78b5-4eda-9dbf-bebe0ef56633,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-401b7cb7-29b3-44c0-825e-19603b583930,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-056df4c5-8c8f-4d6c-869a-7c9eb5328756,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-5d47338b-25ba-45c1-ac8a-79bf7cd77feb,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-d204f243-e768-4fc7-8ce9-e26902160507,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-601540119-172.17.0.6-1597680175233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41233,DS-b7ff2287-cfb3-4899-b3b2-12b85090c7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-af1f309d-5d9b-48c3-beba-26394c5d5217,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-76b8dda6-a1df-4eee-8ce7-973860131330,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-ab9b12d6-1680-4eb5-b7bb-f2fe8dd66fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-a752d209-57ab-4f85-b774-6326af03869b,DISK], DatanodeInfoWithStorage[127.0.0.1:43885,DS-ecaf72e9-0f39-40cd-8630-99b9f5848144,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-c74221d9-c617-44f5-b281-d9b8bbd128cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-f9804304-e32a-4a41-b689-b46cec8c513a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-601540119-172.17.0.6-1597680175233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41233,DS-b7ff2287-cfb3-4899-b3b2-12b85090c7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-af1f309d-5d9b-48c3-beba-26394c5d5217,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-76b8dda6-a1df-4eee-8ce7-973860131330,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-ab9b12d6-1680-4eb5-b7bb-f2fe8dd66fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-a752d209-57ab-4f85-b774-6326af03869b,DISK], DatanodeInfoWithStorage[127.0.0.1:43885,DS-ecaf72e9-0f39-40cd-8630-99b9f5848144,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-c74221d9-c617-44f5-b281-d9b8bbd128cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-f9804304-e32a-4a41-b689-b46cec8c513a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274359434-172.17.0.6-1597680502538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41208,DS-4edf2daa-bfb7-4ab2-8d72-2ad7b9e52e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-7eb9fc44-2174-430f-8a1d-cd1bd96bfa9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-75655c54-ef7c-41ac-9f00-81d91f1d8349,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-2c8d6aa4-8027-44e4-b2c4-d53b14501423,DISK], DatanodeInfoWithStorage[127.0.0.1:41905,DS-62943e22-a93e-4c82-8852-d8bea29f1573,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-528d1e48-6d08-4ba2-83f4-5cf0806029c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-df38bf55-4a89-455a-bf49-dac267aee653,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-62d268ee-6701-43c7-bddc-a87e711ff4ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274359434-172.17.0.6-1597680502538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41208,DS-4edf2daa-bfb7-4ab2-8d72-2ad7b9e52e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-7eb9fc44-2174-430f-8a1d-cd1bd96bfa9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-75655c54-ef7c-41ac-9f00-81d91f1d8349,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-2c8d6aa4-8027-44e4-b2c4-d53b14501423,DISK], DatanodeInfoWithStorage[127.0.0.1:41905,DS-62943e22-a93e-4c82-8852-d8bea29f1573,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-528d1e48-6d08-4ba2-83f4-5cf0806029c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-df38bf55-4a89-455a-bf49-dac267aee653,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-62d268ee-6701-43c7-bddc-a87e711ff4ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-466826650-172.17.0.6-1597680645981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33131,DS-98fb799b-ba82-4bd2-b3a5-64bf298df316,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-d3c9dfee-df0d-40f4-af4c-42ee9bd8ecd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-0c187519-f520-48bd-b44f-bea5d481b183,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-fa1a7c5f-f715-4d1e-b80e-1864edb55bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-56300b71-f2eb-46a7-aaff-53bd11c79772,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-098b4fc1-95a7-46fd-bdb5-0c10453a8146,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-95be327d-e875-4da1-833c-dbe4c9062e99,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-18606815-ecf3-4a64-8e9f-d5facc0e3556,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-466826650-172.17.0.6-1597680645981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33131,DS-98fb799b-ba82-4bd2-b3a5-64bf298df316,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-d3c9dfee-df0d-40f4-af4c-42ee9bd8ecd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-0c187519-f520-48bd-b44f-bea5d481b183,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-fa1a7c5f-f715-4d1e-b80e-1864edb55bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-56300b71-f2eb-46a7-aaff-53bd11c79772,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-098b4fc1-95a7-46fd-bdb5-0c10453a8146,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-95be327d-e875-4da1-833c-dbe4c9062e99,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-18606815-ecf3-4a64-8e9f-d5facc0e3556,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-772012826-172.17.0.6-1597680687042:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38068,DS-b40a07c3-1f42-403a-937e-e40c9796c405,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-a3a71f4c-bff7-4b58-a72d-052e74e43d17,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-b61fd214-49bc-46f2-b98c-39d8d6c231d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-daef86f4-883f-48d3-8a94-5560988ef158,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-b552edf5-5a4c-4131-bc17-eddf5393fcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-52f0020b-1e8e-4f2e-9560-bf753ca72a74,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-7cdecfa0-2071-4454-825a-e3cf6e443cab,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-3038c2e7-b560-4df6-955d-216febb99b9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-772012826-172.17.0.6-1597680687042:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38068,DS-b40a07c3-1f42-403a-937e-e40c9796c405,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-a3a71f4c-bff7-4b58-a72d-052e74e43d17,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-b61fd214-49bc-46f2-b98c-39d8d6c231d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-daef86f4-883f-48d3-8a94-5560988ef158,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-b552edf5-5a4c-4131-bc17-eddf5393fcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-52f0020b-1e8e-4f2e-9560-bf753ca72a74,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-7cdecfa0-2071-4454-825a-e3cf6e443cab,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-3038c2e7-b560-4df6-955d-216febb99b9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1170975568-172.17.0.6-1597680865449:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37611,DS-a250252e-8d8b-4645-a1bc-3cbc264da766,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-d2e9a459-ddfb-45f9-b3b9-2705741e876b,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-5e6a8d56-0c89-4c17-b04f-351bba90c3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-3172581f-549c-4e82-9205-7dde39347bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-2fe47be6-9eb3-4fee-a887-b9e92ed758cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-a865b833-8231-4350-bd25-0ffd46841e81,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-7e2dddfd-8d9d-4889-89ae-af0778a10c37,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-ebf5d3c6-91d6-4125-9bde-fd86c53f74e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1170975568-172.17.0.6-1597680865449:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37611,DS-a250252e-8d8b-4645-a1bc-3cbc264da766,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-d2e9a459-ddfb-45f9-b3b9-2705741e876b,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-5e6a8d56-0c89-4c17-b04f-351bba90c3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-3172581f-549c-4e82-9205-7dde39347bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-2fe47be6-9eb3-4fee-a887-b9e92ed758cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-a865b833-8231-4350-bd25-0ffd46841e81,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-7e2dddfd-8d9d-4889-89ae-af0778a10c37,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-ebf5d3c6-91d6-4125-9bde-fd86c53f74e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-363565435-172.17.0.6-1597681366421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35234,DS-4935e931-290e-4dd5-8fec-25d2c56ce002,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-d24b76de-7d23-411d-87d1-36605e61dc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-f84e5c8b-4d89-4131-8f93-35b4bbdd928a,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-b63ecbd9-e305-4eb6-8dec-075f30d47c68,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-0827b86b-b4af-48e6-9014-c5c699c8f4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-33668293-a67d-4ab2-993e-b54e4ca2fa1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-820d0eb1-ebb6-41fa-b8f0-a5a60062bbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-38b6d2ad-f2d1-4f08-8f64-9c944124bb01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-363565435-172.17.0.6-1597681366421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35234,DS-4935e931-290e-4dd5-8fec-25d2c56ce002,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-d24b76de-7d23-411d-87d1-36605e61dc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-f84e5c8b-4d89-4131-8f93-35b4bbdd928a,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-b63ecbd9-e305-4eb6-8dec-075f30d47c68,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-0827b86b-b4af-48e6-9014-c5c699c8f4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-33668293-a67d-4ab2-993e-b54e4ca2fa1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-820d0eb1-ebb6-41fa-b8f0-a5a60062bbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-38b6d2ad-f2d1-4f08-8f64-9c944124bb01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-376921019-172.17.0.6-1597681405831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40146,DS-d91d4198-a683-430b-a2aa-adb4e99946af,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-5a70c339-cedb-40f8-ba76-eee1b0aa21d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-d28cb300-805f-4579-8a60-a3900cb22e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-7aeef523-da95-45f4-8934-239c55b3930d,DISK], DatanodeInfoWithStorage[127.0.0.1:34767,DS-7fdef72d-8e10-49a7-890b-7d6ba9d79749,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-119b9eed-4b4b-4bae-a23b-7b892cc8dd64,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-43bf3320-49c9-405d-83cf-a5782240ef67,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-43126b2d-e8cc-4a24-ab5f-3a42121f7aeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-376921019-172.17.0.6-1597681405831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40146,DS-d91d4198-a683-430b-a2aa-adb4e99946af,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-5a70c339-cedb-40f8-ba76-eee1b0aa21d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-d28cb300-805f-4579-8a60-a3900cb22e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-7aeef523-da95-45f4-8934-239c55b3930d,DISK], DatanodeInfoWithStorage[127.0.0.1:34767,DS-7fdef72d-8e10-49a7-890b-7d6ba9d79749,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-119b9eed-4b4b-4bae-a23b-7b892cc8dd64,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-43bf3320-49c9-405d-83cf-a5782240ef67,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-43126b2d-e8cc-4a24-ab5f-3a42121f7aeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1709356606-172.17.0.6-1597681504213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33471,DS-518a4a80-bbff-48d8-a3c3-bd3e519aedf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-a0d92824-cf5b-4dcf-9241-ea4eb120ad0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-28552484-bfab-4cb2-9b7f-0b20c0042f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-42dd4cab-1f0d-4e83-aa5c-7a371be0f9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-7b630cde-03ca-4ff7-80a2-b739003867c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-8f180141-69e9-449c-831f-b4607466f1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-4fde080f-7fea-4015-9998-2ce1099ce1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-9df51a80-0e4f-44ef-9082-4bfaef89304a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1709356606-172.17.0.6-1597681504213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33471,DS-518a4a80-bbff-48d8-a3c3-bd3e519aedf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-a0d92824-cf5b-4dcf-9241-ea4eb120ad0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-28552484-bfab-4cb2-9b7f-0b20c0042f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-42dd4cab-1f0d-4e83-aa5c-7a371be0f9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-7b630cde-03ca-4ff7-80a2-b739003867c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-8f180141-69e9-449c-831f-b4607466f1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-4fde080f-7fea-4015-9998-2ce1099ce1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-9df51a80-0e4f-44ef-9082-4bfaef89304a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-872107756-172.17.0.6-1597681810743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42989,DS-f3928557-5120-45d6-b22f-0605790f046a,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-d982d44f-5d27-43db-9541-5ed8e4bc8926,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-3eab3454-1cb3-4c8f-b511-34624558df53,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-f3892611-23fd-4c62-8cac-c9cc8e638151,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-f4bbd579-ae8c-47d7-aa3d-4ff742d9f889,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-5136e336-3150-4af7-a562-b683c15504ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-c4b9d256-b83f-41a1-924d-53a458aab468,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-885519b6-3acf-4a63-b26a-50abec701366,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-872107756-172.17.0.6-1597681810743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42989,DS-f3928557-5120-45d6-b22f-0605790f046a,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-d982d44f-5d27-43db-9541-5ed8e4bc8926,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-3eab3454-1cb3-4c8f-b511-34624558df53,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-f3892611-23fd-4c62-8cac-c9cc8e638151,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-f4bbd579-ae8c-47d7-aa3d-4ff742d9f889,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-5136e336-3150-4af7-a562-b683c15504ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-c4b9d256-b83f-41a1-924d-53a458aab468,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-885519b6-3acf-4a63-b26a-50abec701366,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5460
