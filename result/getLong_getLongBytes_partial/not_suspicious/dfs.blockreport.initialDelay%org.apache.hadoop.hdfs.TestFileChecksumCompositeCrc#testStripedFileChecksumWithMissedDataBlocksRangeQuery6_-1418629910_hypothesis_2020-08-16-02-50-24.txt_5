reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-877538750-172.17.0.13-1597546395317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41596,DS-7d2299b4-926b-4663-976e-45cc14b4ca5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-64d830cf-67a7-4d13-a4bd-553e01c28668,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-35e302ce-8582-4a7c-8825-d38a2e6f27d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-e759fe8b-ade5-4c8f-83f0-a260710b844b,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-28be15e2-cb94-49ac-a38f-791826434854,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-2c6f795c-dbdb-40ab-b3fa-85437afd3b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-3bd0afd1-8c5a-4732-9d42-0d18b60e0fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-d590f1c4-0a29-4ad8-89a9-b85f8a7b2153,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-877538750-172.17.0.13-1597546395317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41596,DS-7d2299b4-926b-4663-976e-45cc14b4ca5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-64d830cf-67a7-4d13-a4bd-553e01c28668,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-35e302ce-8582-4a7c-8825-d38a2e6f27d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-e759fe8b-ade5-4c8f-83f0-a260710b844b,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-28be15e2-cb94-49ac-a38f-791826434854,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-2c6f795c-dbdb-40ab-b3fa-85437afd3b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-3bd0afd1-8c5a-4732-9d42-0d18b60e0fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-d590f1c4-0a29-4ad8-89a9-b85f8a7b2153,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-370139650-172.17.0.13-1597546472440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40973,DS-6c294fe9-2719-4a9e-92f1-f77135e1523d,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-cca33e1f-6abf-4a1d-9de8-f1fcbc5696a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-d1bbbef5-fd96-4878-929a-17d8056918b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-8afb9b77-6d3a-4ac5-b756-b4c7e5033f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-4a24f643-29f2-445f-b50b-0ae35a70450e,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-7e95942f-9595-4922-b375-bca65809c15b,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-d541e309-38f4-4363-90c4-8362445f200e,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-6a5c85c1-528c-4d81-846a-15979c4ce765,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-370139650-172.17.0.13-1597546472440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40973,DS-6c294fe9-2719-4a9e-92f1-f77135e1523d,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-cca33e1f-6abf-4a1d-9de8-f1fcbc5696a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-d1bbbef5-fd96-4878-929a-17d8056918b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-8afb9b77-6d3a-4ac5-b756-b4c7e5033f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-4a24f643-29f2-445f-b50b-0ae35a70450e,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-7e95942f-9595-4922-b375-bca65809c15b,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-d541e309-38f4-4363-90c4-8362445f200e,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-6a5c85c1-528c-4d81-846a-15979c4ce765,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274287408-172.17.0.13-1597546512552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36829,DS-3f62cc9e-61aa-48b6-860c-1b5c83d9ce12,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-00849af6-7af9-488c-903d-4be616bf3bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-b0443079-e5d6-42ae-9eef-215ef9c55607,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-70622e75-34ea-4d39-aebd-2ae95d650c89,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-ef02278b-3e0a-4a6e-a574-0656ab85d63f,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-96b879a2-5298-416b-98a2-c29df7d99381,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-9c618f95-aeb7-45c6-b056-a89f13b90b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-871430d8-cb02-4675-b385-9587a60174ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274287408-172.17.0.13-1597546512552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36829,DS-3f62cc9e-61aa-48b6-860c-1b5c83d9ce12,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-00849af6-7af9-488c-903d-4be616bf3bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-b0443079-e5d6-42ae-9eef-215ef9c55607,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-70622e75-34ea-4d39-aebd-2ae95d650c89,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-ef02278b-3e0a-4a6e-a574-0656ab85d63f,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-96b879a2-5298-416b-98a2-c29df7d99381,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-9c618f95-aeb7-45c6-b056-a89f13b90b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-871430d8-cb02-4675-b385-9587a60174ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630953599-172.17.0.13-1597546974552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40293,DS-38fdd93a-d44b-438f-a16e-f680b2f8d94a,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-5755cf2e-9f37-42df-8777-985ca5b5cde5,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-73ae4578-0626-4bcd-93c6-5863f7ac5a30,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-22d23d12-ad34-4f1a-90c6-367628783534,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-8f6a88ba-7ddd-4f07-b005-3f31fe055bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-5c911fa3-7a97-4de6-a5ce-7ce119721099,DISK], DatanodeInfoWithStorage[127.0.0.1:33514,DS-5b92988d-cf02-4634-b458-acd11b0c2fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-f6d749af-6691-448d-ac05-a8159e7ae2ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630953599-172.17.0.13-1597546974552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40293,DS-38fdd93a-d44b-438f-a16e-f680b2f8d94a,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-5755cf2e-9f37-42df-8777-985ca5b5cde5,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-73ae4578-0626-4bcd-93c6-5863f7ac5a30,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-22d23d12-ad34-4f1a-90c6-367628783534,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-8f6a88ba-7ddd-4f07-b005-3f31fe055bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-5c911fa3-7a97-4de6-a5ce-7ce119721099,DISK], DatanodeInfoWithStorage[127.0.0.1:33514,DS-5b92988d-cf02-4634-b458-acd11b0c2fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-f6d749af-6691-448d-ac05-a8159e7ae2ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122925182-172.17.0.13-1597547095633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38066,DS-86cc7435-05e1-466c-8a30-385704c27f08,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-31536799-f4cb-47b4-b58b-f91ea906eab1,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-f2fbb22a-06d2-4d6d-b705-fea27d179034,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-0e88640b-ddbb-4423-9104-77c8afce1daa,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-24210171-4152-45f6-8c3d-d4fc52cc4f97,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-c1daecdb-7146-4f41-b80f-2d8aec39be5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-2e556a02-ea82-4a7b-a37a-7f87a6f3c519,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-208a23a8-5907-4827-a1ba-de30927d4e12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122925182-172.17.0.13-1597547095633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38066,DS-86cc7435-05e1-466c-8a30-385704c27f08,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-31536799-f4cb-47b4-b58b-f91ea906eab1,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-f2fbb22a-06d2-4d6d-b705-fea27d179034,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-0e88640b-ddbb-4423-9104-77c8afce1daa,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-24210171-4152-45f6-8c3d-d4fc52cc4f97,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-c1daecdb-7146-4f41-b80f-2d8aec39be5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-2e556a02-ea82-4a7b-a37a-7f87a6f3c519,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-208a23a8-5907-4827-a1ba-de30927d4e12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145712295-172.17.0.13-1597547282768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44352,DS-7c10f12d-d3c8-49d3-8d67-fd0c2e10868c,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-9f67b151-1aac-45c8-8d60-1871eda212cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-3f8ff394-882f-4b2b-bb92-73939f60a8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-178f5447-02e2-47f9-b0e0-9cb1d032bc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-5eaa2623-4dd0-48a3-a955-22484a439b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-af0ace41-b4cb-42f6-98e6-da297ba7c335,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-72de977b-a50d-4f9b-897b-002270a985e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-612b9019-821b-4b5f-937d-79103ae46f95,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145712295-172.17.0.13-1597547282768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44352,DS-7c10f12d-d3c8-49d3-8d67-fd0c2e10868c,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-9f67b151-1aac-45c8-8d60-1871eda212cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-3f8ff394-882f-4b2b-bb92-73939f60a8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-178f5447-02e2-47f9-b0e0-9cb1d032bc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-5eaa2623-4dd0-48a3-a955-22484a439b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-af0ace41-b4cb-42f6-98e6-da297ba7c335,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-72de977b-a50d-4f9b-897b-002270a985e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-612b9019-821b-4b5f-937d-79103ae46f95,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1733886513-172.17.0.13-1597547562027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39208,DS-b06f8216-5237-4cdd-8997-50988f996213,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-b7938f9d-af44-4ea7-9295-9869effd6b35,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-f11536ea-9f61-4114-9044-d863ee27a3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-97b89860-18a5-4cb4-9371-0095f870f31b,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-95897748-a36b-4c43-8b11-6b3741eb363a,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-a9d2ac23-2325-4c3f-96af-921da046566b,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-b37a649f-141d-49fe-bc27-6233582daed8,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-0ac5b36a-ae99-49fd-87d7-05209ae5e1e3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1733886513-172.17.0.13-1597547562027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39208,DS-b06f8216-5237-4cdd-8997-50988f996213,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-b7938f9d-af44-4ea7-9295-9869effd6b35,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-f11536ea-9f61-4114-9044-d863ee27a3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-97b89860-18a5-4cb4-9371-0095f870f31b,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-95897748-a36b-4c43-8b11-6b3741eb363a,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-a9d2ac23-2325-4c3f-96af-921da046566b,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-b37a649f-141d-49fe-bc27-6233582daed8,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-0ac5b36a-ae99-49fd-87d7-05209ae5e1e3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-5536731-172.17.0.13-1597547795281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40961,DS-d335f1cd-022f-4683-b5f1-8dfbe30dced4,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-fe135022-1b28-4ea8-b917-f72a8471a0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-b7756a1e-740d-4fb1-8342-b4e556bc989c,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-66da28da-0683-401f-918e-7338e11075b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-36ad6b8b-db98-4662-bb4b-394810217c86,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-29da39f7-4df9-44e5-95bb-9a4faa596655,DISK], DatanodeInfoWithStorage[127.0.0.1:35514,DS-4f8c7fb0-7139-4f01-9e56-7c4dbfdbacec,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-a289ad7c-e055-4f69-bd1f-ec94644ecdfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-5536731-172.17.0.13-1597547795281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40961,DS-d335f1cd-022f-4683-b5f1-8dfbe30dced4,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-fe135022-1b28-4ea8-b917-f72a8471a0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-b7756a1e-740d-4fb1-8342-b4e556bc989c,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-66da28da-0683-401f-918e-7338e11075b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-36ad6b8b-db98-4662-bb4b-394810217c86,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-29da39f7-4df9-44e5-95bb-9a4faa596655,DISK], DatanodeInfoWithStorage[127.0.0.1:35514,DS-4f8c7fb0-7139-4f01-9e56-7c4dbfdbacec,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-a289ad7c-e055-4f69-bd1f-ec94644ecdfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487223214-172.17.0.13-1597547866492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35851,DS-f33bb486-c44b-4adf-adf3-29dfc51ac140,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-2d253e7e-137e-4d84-bd5c-033bcb61d0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-189b48f9-393b-4c40-8424-0cc8b14789a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-e63eb158-13a6-43b9-9221-23de47176f84,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-1dbca41d-b390-40f9-81f9-bba06691dcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46025,DS-e735f7d8-6eeb-4401-914e-0580e9f30af8,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-2bb954e1-02d3-4f5e-8003-d21d9aa6a84c,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-a4b89c49-0bfa-4d6c-a878-c5833613f1a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487223214-172.17.0.13-1597547866492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35851,DS-f33bb486-c44b-4adf-adf3-29dfc51ac140,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-2d253e7e-137e-4d84-bd5c-033bcb61d0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-189b48f9-393b-4c40-8424-0cc8b14789a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-e63eb158-13a6-43b9-9221-23de47176f84,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-1dbca41d-b390-40f9-81f9-bba06691dcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46025,DS-e735f7d8-6eeb-4401-914e-0580e9f30af8,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-2bb954e1-02d3-4f5e-8003-d21d9aa6a84c,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-a4b89c49-0bfa-4d6c-a878-c5833613f1a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-657130108-172.17.0.13-1597548203831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33695,DS-8f41c047-c660-4ee6-a50c-d03160e66f33,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-6fdf5c36-711d-41ab-8a75-a782b8d66f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-11dc39f5-b9cb-4eff-9b5a-cc0876b79a98,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-0ce3f8af-c394-4a3f-b3e4-d20d43fa6b98,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-59867d66-34b5-4ad5-90f6-db1a94bbc423,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-44665dcb-f7cc-4a9e-a912-bf9dc8a29027,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-8dc0f1f1-dcd2-42db-87cf-a641f1e8d291,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-21ceea62-5b9c-4dcd-a7ca-4a20d128bc35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-657130108-172.17.0.13-1597548203831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33695,DS-8f41c047-c660-4ee6-a50c-d03160e66f33,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-6fdf5c36-711d-41ab-8a75-a782b8d66f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-11dc39f5-b9cb-4eff-9b5a-cc0876b79a98,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-0ce3f8af-c394-4a3f-b3e4-d20d43fa6b98,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-59867d66-34b5-4ad5-90f6-db1a94bbc423,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-44665dcb-f7cc-4a9e-a912-bf9dc8a29027,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-8dc0f1f1-dcd2-42db-87cf-a641f1e8d291,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-21ceea62-5b9c-4dcd-a7ca-4a20d128bc35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-883058735-172.17.0.13-1597548511210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35719,DS-0dbacfd2-2b1b-45a5-8f7d-d88a15997450,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-6db0ef32-e521-4666-80a9-6c7cf430a68f,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-8341a908-379e-44cd-b86d-6087ea08ce00,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-8ed56a7d-87de-445c-be74-a760edbc541d,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-5070ba7c-6ae8-4fc6-8089-f7ef40cb3723,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-d187810f-ee10-49c8-8eb8-f80ec119cae6,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-66c51998-1771-4474-9774-a3ba0e8e7097,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-e6071610-a52f-47e6-a018-095ba90adac1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-883058735-172.17.0.13-1597548511210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35719,DS-0dbacfd2-2b1b-45a5-8f7d-d88a15997450,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-6db0ef32-e521-4666-80a9-6c7cf430a68f,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-8341a908-379e-44cd-b86d-6087ea08ce00,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-8ed56a7d-87de-445c-be74-a760edbc541d,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-5070ba7c-6ae8-4fc6-8089-f7ef40cb3723,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-d187810f-ee10-49c8-8eb8-f80ec119cae6,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-66c51998-1771-4474-9774-a3ba0e8e7097,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-e6071610-a52f-47e6-a018-095ba90adac1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99749871-172.17.0.13-1597548914427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36736,DS-581508e6-67fd-4fe2-9728-e3eb6fd09a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-a13243bc-0597-4257-b845-0694bfb856bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-9d9a055f-4219-47cb-817f-ae9a4b053401,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-728d50ac-be60-4523-9910-b23fbbe64999,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-65cfe9af-6d6f-4da2-8c4e-5e0489f0744a,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-2553404e-a3ae-496f-884c-659f621e2493,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-31468293-065a-4082-8871-604d2af3af02,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-be83dd74-ad19-48af-8f08-95dbd39413ea,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99749871-172.17.0.13-1597548914427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36736,DS-581508e6-67fd-4fe2-9728-e3eb6fd09a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-a13243bc-0597-4257-b845-0694bfb856bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-9d9a055f-4219-47cb-817f-ae9a4b053401,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-728d50ac-be60-4523-9910-b23fbbe64999,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-65cfe9af-6d6f-4da2-8c4e-5e0489f0744a,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-2553404e-a3ae-496f-884c-659f621e2493,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-31468293-065a-4082-8871-604d2af3af02,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-be83dd74-ad19-48af-8f08-95dbd39413ea,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825740226-172.17.0.13-1597548995203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36368,DS-6365722f-6b57-495e-ae2a-3697ee9b43a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-fecc475d-87d3-44cf-9d4b-8f295d458620,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-fae02f72-0a54-4467-a60e-db9a21c35ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-c867c5c5-856f-4931-b7eb-c7196c1b4a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-add5f140-133a-4065-9b62-42fb18cc0f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-ae51fdfc-553a-47a4-8e4a-fb98139c7f06,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-ed445b1a-88b1-450a-9783-99e1dc7475fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-00d475ba-df06-49d4-8d3a-45dac2302d89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825740226-172.17.0.13-1597548995203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36368,DS-6365722f-6b57-495e-ae2a-3697ee9b43a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-fecc475d-87d3-44cf-9d4b-8f295d458620,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-fae02f72-0a54-4467-a60e-db9a21c35ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-c867c5c5-856f-4931-b7eb-c7196c1b4a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-add5f140-133a-4065-9b62-42fb18cc0f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-ae51fdfc-553a-47a4-8e4a-fb98139c7f06,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-ed445b1a-88b1-450a-9783-99e1dc7475fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-00d475ba-df06-49d4-8d3a-45dac2302d89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2076580215-172.17.0.13-1597549146928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41042,DS-0004b3ab-c413-4a91-9536-f7b640391d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-ea9cdb4d-2221-4e5b-884e-34bcf4e734fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-8903b6ca-6db2-4a2d-b184-d364e33dad5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-846097cb-4b68-434a-8a2e-62c212e4c807,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-84bc3e4f-f347-4c4c-bff7-30c53c534be8,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-b66e1ac9-c7e8-4898-addf-d89f167a8752,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-36868141-7056-463e-8f0d-ca763785a696,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-554cae1a-7d1c-4e70-9dba-d061cf0de3fb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2076580215-172.17.0.13-1597549146928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41042,DS-0004b3ab-c413-4a91-9536-f7b640391d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-ea9cdb4d-2221-4e5b-884e-34bcf4e734fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-8903b6ca-6db2-4a2d-b184-d364e33dad5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-846097cb-4b68-434a-8a2e-62c212e4c807,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-84bc3e4f-f347-4c4c-bff7-30c53c534be8,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-b66e1ac9-c7e8-4898-addf-d89f167a8752,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-36868141-7056-463e-8f0d-ca763785a696,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-554cae1a-7d1c-4e70-9dba-d061cf0de3fb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744211484-172.17.0.13-1597549299615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35420,DS-c1203b67-4572-4567-904c-d02bb9e37999,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-4cd6d9a5-9334-4fa8-bfe7-ba2e4104a28c,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-c6612e14-6852-46de-9f85-b611e68165bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-34b18999-3d41-49f4-80e2-e1a771cabbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-70910bf5-cd70-4ad1-b577-b4d9b153e744,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-d4bc7fd3-2157-4290-a62f-2757c604a1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-f20c4d3d-4127-4706-8820-3aae7b9d8001,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-71a0b1f6-a790-4152-ac40-c1791602b62c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744211484-172.17.0.13-1597549299615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35420,DS-c1203b67-4572-4567-904c-d02bb9e37999,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-4cd6d9a5-9334-4fa8-bfe7-ba2e4104a28c,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-c6612e14-6852-46de-9f85-b611e68165bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-34b18999-3d41-49f4-80e2-e1a771cabbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-70910bf5-cd70-4ad1-b577-b4d9b153e744,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-d4bc7fd3-2157-4290-a62f-2757c604a1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-f20c4d3d-4127-4706-8820-3aae7b9d8001,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-71a0b1f6-a790-4152-ac40-c1791602b62c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-116917821-172.17.0.13-1597549377232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44857,DS-9b1f4e02-074d-4016-b885-a17608009792,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-f886af98-19ef-4288-a582-dcc4391ac4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-8854e804-4da9-4b6e-890f-d4a046160c20,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-43bc82e4-88b5-4f4f-9af7-1afe5b635e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-1d119824-82cf-4195-a548-7d7a4aa31181,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-3b7f2651-8625-49b0-8b88-65e3d5714f10,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-0be9219c-5b41-48b9-8880-77450e58ecee,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-e0c4af93-2a8a-405c-bcb2-e524cd270c98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-116917821-172.17.0.13-1597549377232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44857,DS-9b1f4e02-074d-4016-b885-a17608009792,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-f886af98-19ef-4288-a582-dcc4391ac4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-8854e804-4da9-4b6e-890f-d4a046160c20,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-43bc82e4-88b5-4f4f-9af7-1afe5b635e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-1d119824-82cf-4195-a548-7d7a4aa31181,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-3b7f2651-8625-49b0-8b88-65e3d5714f10,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-0be9219c-5b41-48b9-8880-77450e58ecee,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-e0c4af93-2a8a-405c-bcb2-e524cd270c98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-498459494-172.17.0.13-1597549496273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42909,DS-89cf92ce-f2a0-4f53-86ea-232bfd2d9f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-bc4292bd-31b4-4e39-a90b-5f2539632118,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-a3b7dfb4-4e89-4b0c-81c6-91c0d97119b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-8a35b043-e41b-49e0-bd4c-c489fd498a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-40d456ec-8f8a-40e7-9c8b-1bf0ea243b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-36d85b84-665e-4e1a-9815-e60cd35d7493,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-e0f5b0cc-ceeb-4d67-a0f2-fb97092e5557,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-c5db432a-c0eb-4b10-8139-58a06d376c16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-498459494-172.17.0.13-1597549496273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42909,DS-89cf92ce-f2a0-4f53-86ea-232bfd2d9f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-bc4292bd-31b4-4e39-a90b-5f2539632118,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-a3b7dfb4-4e89-4b0c-81c6-91c0d97119b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-8a35b043-e41b-49e0-bd4c-c489fd498a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-40d456ec-8f8a-40e7-9c8b-1bf0ea243b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-36d85b84-665e-4e1a-9815-e60cd35d7493,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-e0f5b0cc-ceeb-4d67-a0f2-fb97092e5557,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-c5db432a-c0eb-4b10-8139-58a06d376c16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-901360251-172.17.0.13-1597549575683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39054,DS-76f74a31-2ef7-4aa2-9ca7-8c065d85ba40,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-73a8b250-6538-411a-a0ee-0b38676c0bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-82298686-55c0-4328-9b9c-5a56454ed8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-18926d56-0acf-4799-a3b0-480dad59c0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-4737bad2-653c-4892-8de1-ea33c8e010de,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-29ce09c1-576c-48d4-b0a3-a8a921a6f996,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-a2f23f5c-28c0-41c3-a747-63308005c306,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-70cd9d67-e0a7-4616-bdd4-692a9d9e8fea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-901360251-172.17.0.13-1597549575683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39054,DS-76f74a31-2ef7-4aa2-9ca7-8c065d85ba40,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-73a8b250-6538-411a-a0ee-0b38676c0bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-82298686-55c0-4328-9b9c-5a56454ed8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-18926d56-0acf-4799-a3b0-480dad59c0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-4737bad2-653c-4892-8de1-ea33c8e010de,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-29ce09c1-576c-48d4-b0a3-a8a921a6f996,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-a2f23f5c-28c0-41c3-a747-63308005c306,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-70cd9d67-e0a7-4616-bdd4-692a9d9e8fea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1922634594-172.17.0.13-1597549656474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39291,DS-84cc2f4c-c07c-450d-af80-2454510a2ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:33595,DS-156ddd52-750c-45ff-afaf-d51af6a8c7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-a90924bd-5659-4631-9222-07c851e9d94c,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-f54668b6-ac0b-41a7-a373-6f94a92dd56c,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-06983bb7-6aed-4e3e-b421-3654beb7c620,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-c43f3f6d-2cc2-4b8d-b6a5-1a07997672db,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-9c5d8c93-361c-4e7f-9db6-eb56ea1af167,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-db88a1ee-d179-4c13-95f5-f839e88a8535,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1922634594-172.17.0.13-1597549656474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39291,DS-84cc2f4c-c07c-450d-af80-2454510a2ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:33595,DS-156ddd52-750c-45ff-afaf-d51af6a8c7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-a90924bd-5659-4631-9222-07c851e9d94c,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-f54668b6-ac0b-41a7-a373-6f94a92dd56c,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-06983bb7-6aed-4e3e-b421-3654beb7c620,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-c43f3f6d-2cc2-4b8d-b6a5-1a07997672db,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-9c5d8c93-361c-4e7f-9db6-eb56ea1af167,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-db88a1ee-d179-4c13-95f5-f839e88a8535,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2020865515-172.17.0.13-1597549694709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37493,DS-518dac86-823b-431b-bff7-3f1d34c5f02a,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-03a2c13c-8e57-4b2c-96d6-bb4449f54593,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-d9a10dec-d162-44e5-b81d-584d437ff819,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-32c098c7-0fe5-4eef-b776-be2f58f80bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-b7ef4f1d-ee62-4cb6-8241-18228bd117ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-4bf848b0-b1f7-40a1-983d-aca601e23722,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-96aabeca-595e-4031-befd-b55a6cfa42fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-a68b1b14-fa84-4804-accc-7450045e10eb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2020865515-172.17.0.13-1597549694709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37493,DS-518dac86-823b-431b-bff7-3f1d34c5f02a,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-03a2c13c-8e57-4b2c-96d6-bb4449f54593,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-d9a10dec-d162-44e5-b81d-584d437ff819,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-32c098c7-0fe5-4eef-b776-be2f58f80bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-b7ef4f1d-ee62-4cb6-8241-18228bd117ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-4bf848b0-b1f7-40a1-983d-aca601e23722,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-96aabeca-595e-4031-befd-b55a6cfa42fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-a68b1b14-fa84-4804-accc-7450045e10eb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489820633-172.17.0.13-1597549770606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39663,DS-cf9bbbed-3b6b-47c8-b98e-6cb857b146ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-042ff395-8d42-440e-93bc-5aaeec3dd0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-0e09e6d8-a154-41ed-be9d-af90241b7241,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-f760f62c-a8b7-448c-ac72-b64d1d2b93a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-f37c422a-c7db-41f7-8c32-b73d1c351ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-4d1e92e8-20ad-46ba-a465-a2416b11f893,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-5ef7cd2c-a686-48f1-98e3-84bf41dddf33,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-2361f19c-ee18-414d-8975-99b2f4ae9a28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489820633-172.17.0.13-1597549770606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39663,DS-cf9bbbed-3b6b-47c8-b98e-6cb857b146ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-042ff395-8d42-440e-93bc-5aaeec3dd0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-0e09e6d8-a154-41ed-be9d-af90241b7241,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-f760f62c-a8b7-448c-ac72-b64d1d2b93a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-f37c422a-c7db-41f7-8c32-b73d1c351ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-4d1e92e8-20ad-46ba-a465-a2416b11f893,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-5ef7cd2c-a686-48f1-98e3-84bf41dddf33,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-2361f19c-ee18-414d-8975-99b2f4ae9a28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-840401911-172.17.0.13-1597549818717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32867,DS-fb5b2629-4e76-4a0c-9d80-5b135fdec697,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-7ce556fe-2b0b-43af-8723-9fed64d3c91a,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-d272ce3d-5590-49ae-a7fe-50049cbfe290,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-094ff07b-5eff-4bc2-9033-d2640b4fc990,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-666b16c1-f08b-4803-b365-65512d82755e,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-a70415f0-4500-4ccb-8c16-17bc8d1aad22,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-8cba2560-5c2e-4793-8500-ddbb64915c07,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-43de435f-1890-41b5-8996-3c4db4d2bfc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-840401911-172.17.0.13-1597549818717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32867,DS-fb5b2629-4e76-4a0c-9d80-5b135fdec697,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-7ce556fe-2b0b-43af-8723-9fed64d3c91a,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-d272ce3d-5590-49ae-a7fe-50049cbfe290,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-094ff07b-5eff-4bc2-9033-d2640b4fc990,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-666b16c1-f08b-4803-b365-65512d82755e,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-a70415f0-4500-4ccb-8c16-17bc8d1aad22,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-8cba2560-5c2e-4793-8500-ddbb64915c07,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-43de435f-1890-41b5-8996-3c4db4d2bfc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889589887-172.17.0.13-1597549980475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35988,DS-81144237-9366-4404-985b-493faee7f82f,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-22835af2-9de2-48bc-b2de-c4f6f7b17a30,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-224a93a2-c7b4-4aa6-81e7-47ea78cd4526,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-5f5ffe60-cb85-4688-a391-e996157b1e68,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-cb85ace5-82f6-4cfb-9568-f11312508d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-aec25d90-6647-47b1-9d83-f51ead7c7abc,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-474e1fe9-21b7-4d96-9598-62ace27916c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-3a70ad39-b9ed-45e4-b684-f5958431030d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889589887-172.17.0.13-1597549980475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35988,DS-81144237-9366-4404-985b-493faee7f82f,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-22835af2-9de2-48bc-b2de-c4f6f7b17a30,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-224a93a2-c7b4-4aa6-81e7-47ea78cd4526,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-5f5ffe60-cb85-4688-a391-e996157b1e68,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-cb85ace5-82f6-4cfb-9568-f11312508d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-aec25d90-6647-47b1-9d83-f51ead7c7abc,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-474e1fe9-21b7-4d96-9598-62ace27916c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-3a70ad39-b9ed-45e4-b684-f5958431030d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1854067220-172.17.0.13-1597550021036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38282,DS-b82c26ff-4004-4ead-b547-a054f0d9581f,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-dccf6dbe-cf5a-488e-a302-06f13a4c6748,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-a066ad3a-4929-483c-b916-ff11a77e46a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-fd43d7aa-372c-40cf-b911-b808ffef2c83,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-36ee257f-ee1f-4514-921e-7ab6db9bf2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-c926275e-9c27-437b-a377-e172400ec3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-69cdd7d9-bb8f-4601-bc71-021b75c35fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-41666b02-a6a7-48bf-a4ff-00f459754b1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1854067220-172.17.0.13-1597550021036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38282,DS-b82c26ff-4004-4ead-b547-a054f0d9581f,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-dccf6dbe-cf5a-488e-a302-06f13a4c6748,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-a066ad3a-4929-483c-b916-ff11a77e46a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-fd43d7aa-372c-40cf-b911-b808ffef2c83,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-36ee257f-ee1f-4514-921e-7ab6db9bf2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-c926275e-9c27-437b-a377-e172400ec3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-69cdd7d9-bb8f-4601-bc71-021b75c35fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-41666b02-a6a7-48bf-a4ff-00f459754b1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299668833-172.17.0.13-1597550064131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46491,DS-76fe7ce3-f8f8-4d32-b070-f836d693d467,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-618d9af4-2f0f-41c9-ac5f-8e66afb6e595,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-c3ff50a7-3f5c-420a-8d75-b21f9f2d3017,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-7ea9b3ff-3194-40ae-9f52-0432d67804d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-18f13e7f-52e1-45cd-b6d9-b3ca5c3da528,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-ba2fcea1-f6a8-41ec-aea8-6faddd519f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37862,DS-c0232a18-ae88-4cc0-97f2-84dd47481d78,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-8f3381bf-142d-4716-8f31-0924d8da8770,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299668833-172.17.0.13-1597550064131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46491,DS-76fe7ce3-f8f8-4d32-b070-f836d693d467,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-618d9af4-2f0f-41c9-ac5f-8e66afb6e595,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-c3ff50a7-3f5c-420a-8d75-b21f9f2d3017,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-7ea9b3ff-3194-40ae-9f52-0432d67804d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-18f13e7f-52e1-45cd-b6d9-b3ca5c3da528,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-ba2fcea1-f6a8-41ec-aea8-6faddd519f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37862,DS-c0232a18-ae88-4cc0-97f2-84dd47481d78,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-8f3381bf-142d-4716-8f31-0924d8da8770,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1969663407-172.17.0.13-1597550181693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39115,DS-8fca3ecd-f35d-4a0f-b470-6042d27c0e28,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-67291db2-1d54-474f-9cdc-df83b5185345,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-2d5d83f8-c106-4dfb-b28e-80ce24a23cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-a44443df-8f29-48e4-a81f-d34d392c4713,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-81c3cf82-a2e8-4c65-acbd-e9ee5b06a448,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-f5589969-000b-453a-b741-defef009c55b,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-f64dd11f-a4af-4a52-a8be-8123cf46d131,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-2acea9b2-67ee-4647-ae92-76d63d0a9a2c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1969663407-172.17.0.13-1597550181693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39115,DS-8fca3ecd-f35d-4a0f-b470-6042d27c0e28,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-67291db2-1d54-474f-9cdc-df83b5185345,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-2d5d83f8-c106-4dfb-b28e-80ce24a23cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-a44443df-8f29-48e4-a81f-d34d392c4713,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-81c3cf82-a2e8-4c65-acbd-e9ee5b06a448,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-f5589969-000b-453a-b741-defef009c55b,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-f64dd11f-a4af-4a52-a8be-8123cf46d131,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-2acea9b2-67ee-4647-ae92-76d63d0a9a2c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1666802885-172.17.0.13-1597550637923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35383,DS-f87782f6-3192-409a-849e-0e5b4e6a341d,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-93f6a581-fe85-4cf9-8263-487cf67b65de,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-3cc15117-148d-4b4d-86d9-a014176d844b,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-b3a76f51-c27e-4d54-82f4-d5b1729cd1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-27a7df2e-0f18-4353-88d7-95a725e96eff,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-6b1d174f-dbee-4e05-997f-03837bb41bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-a5f0247a-af50-4983-8a8c-0f45464eaffb,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-5ce2e965-7c52-4edf-ae78-568f24429d6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1666802885-172.17.0.13-1597550637923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35383,DS-f87782f6-3192-409a-849e-0e5b4e6a341d,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-93f6a581-fe85-4cf9-8263-487cf67b65de,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-3cc15117-148d-4b4d-86d9-a014176d844b,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-b3a76f51-c27e-4d54-82f4-d5b1729cd1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-27a7df2e-0f18-4353-88d7-95a725e96eff,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-6b1d174f-dbee-4e05-997f-03837bb41bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-a5f0247a-af50-4983-8a8c-0f45464eaffb,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-5ce2e965-7c52-4edf-ae78-568f24429d6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-221330285-172.17.0.13-1597550706702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36493,DS-6a6a4ba5-a234-41c7-a91f-abd7eeaaabe1,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-661b9e4b-1876-4685-abf1-5354ec378e20,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-da29ad66-977d-4c15-9b2a-734656d29269,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-2a626b0b-9848-4d39-a0eb-61fa96dc1155,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-5db6b167-ac84-4394-8255-5d46fc84fca0,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-95f9781e-deea-4cf7-ad1f-d2bbc99f9928,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-95a1f610-41c6-4bd6-a921-3691706672f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-39c46f84-66a6-4259-befd-b9643945a88d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-221330285-172.17.0.13-1597550706702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36493,DS-6a6a4ba5-a234-41c7-a91f-abd7eeaaabe1,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-661b9e4b-1876-4685-abf1-5354ec378e20,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-da29ad66-977d-4c15-9b2a-734656d29269,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-2a626b0b-9848-4d39-a0eb-61fa96dc1155,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-5db6b167-ac84-4394-8255-5d46fc84fca0,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-95f9781e-deea-4cf7-ad1f-d2bbc99f9928,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-95a1f610-41c6-4bd6-a921-3691706672f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-39c46f84-66a6-4259-befd-b9643945a88d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016217276-172.17.0.13-1597550887509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45850,DS-cb407cc5-03e2-420d-8afe-ad05e2851024,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-1656fd94-cbd2-4968-96ed-e4ed46961b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-cdce1bef-a901-496d-a91f-0486ab01e56f,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-1e20058d-8ddc-4ad5-9ca1-c2a29d86725f,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-565844eb-db66-4621-8866-090d192c9b22,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-cf6022dc-c5cb-4325-a0b9-bf7f06f4cbff,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-3c062101-4cc7-48b6-9fa8-3d3008e15e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-34faac96-abf3-44ef-9d63-2752f0e9750c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016217276-172.17.0.13-1597550887509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45850,DS-cb407cc5-03e2-420d-8afe-ad05e2851024,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-1656fd94-cbd2-4968-96ed-e4ed46961b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-cdce1bef-a901-496d-a91f-0486ab01e56f,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-1e20058d-8ddc-4ad5-9ca1-c2a29d86725f,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-565844eb-db66-4621-8866-090d192c9b22,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-cf6022dc-c5cb-4325-a0b9-bf7f06f4cbff,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-3c062101-4cc7-48b6-9fa8-3d3008e15e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-34faac96-abf3-44ef-9d63-2752f0e9750c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-606446224-172.17.0.13-1597550928701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41312,DS-2b67cd0d-4ae9-4dcc-99af-693eaa6f185b,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-d9e8c764-6c79-44bf-8fa4-9898aead26a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-d6bdd857-73b8-4d0e-b8c5-d7958b2c5300,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-027050b6-9cc5-4b0a-ad01-b9b07194250d,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-77047a54-b9de-4d8e-93b9-819a4ba3c910,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-1fe94eda-2685-44db-87eb-dd8fdf1e0613,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-ee7f2813-65d8-4bdf-ba76-333a4399f7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-b3305cee-1b11-4bee-b27b-fdff713642aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-606446224-172.17.0.13-1597550928701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41312,DS-2b67cd0d-4ae9-4dcc-99af-693eaa6f185b,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-d9e8c764-6c79-44bf-8fa4-9898aead26a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-d6bdd857-73b8-4d0e-b8c5-d7958b2c5300,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-027050b6-9cc5-4b0a-ad01-b9b07194250d,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-77047a54-b9de-4d8e-93b9-819a4ba3c910,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-1fe94eda-2685-44db-87eb-dd8fdf1e0613,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-ee7f2813-65d8-4bdf-ba76-333a4399f7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-b3305cee-1b11-4bee-b27b-fdff713642aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-444299657-172.17.0.13-1597550966598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33447,DS-f3cc1b9b-aecb-4617-ae7d-8ad55cc6426e,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-61ecf6e7-6554-471e-87a8-6b59b0f44008,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-0ee4bea3-98e4-4430-80e8-0a65cf94ba24,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-57d12ffb-2efa-495f-99cd-b166807d43d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-b4c6e1f2-2ea5-4ce3-8ba5-fc488ed5524e,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-50ced60c-248f-45e4-a977-58b37d03633f,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-77cf9b0a-9b57-454d-b483-e11decd89518,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-d3fee339-92f0-4cca-a58f-46343e17a942,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-444299657-172.17.0.13-1597550966598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33447,DS-f3cc1b9b-aecb-4617-ae7d-8ad55cc6426e,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-61ecf6e7-6554-471e-87a8-6b59b0f44008,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-0ee4bea3-98e4-4430-80e8-0a65cf94ba24,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-57d12ffb-2efa-495f-99cd-b166807d43d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-b4c6e1f2-2ea5-4ce3-8ba5-fc488ed5524e,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-50ced60c-248f-45e4-a977-58b37d03633f,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-77cf9b0a-9b57-454d-b483-e11decd89518,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-d3fee339-92f0-4cca-a58f-46343e17a942,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-356101340-172.17.0.13-1597551044628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39551,DS-2ca88cd4-5cb0-44cd-9a0b-21699f7a99ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-89b295c8-5a01-40ad-bdcd-90cc5085cb56,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-17a69b67-4b62-4a5b-97c9-55c3efc6b56c,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-37cde390-6b3a-4a98-81a5-1e474d8da778,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-b74132b5-516e-4d9f-926a-ae5ac6d86ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-22e0303b-c9a9-4f20-b5db-57d1533478ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-7fdfb971-16e1-45c2-b878-229159e16753,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-1f017442-8241-46d9-acbe-6c5f7eeb6604,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-356101340-172.17.0.13-1597551044628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39551,DS-2ca88cd4-5cb0-44cd-9a0b-21699f7a99ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-89b295c8-5a01-40ad-bdcd-90cc5085cb56,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-17a69b67-4b62-4a5b-97c9-55c3efc6b56c,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-37cde390-6b3a-4a98-81a5-1e474d8da778,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-b74132b5-516e-4d9f-926a-ae5ac6d86ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-22e0303b-c9a9-4f20-b5db-57d1533478ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-7fdfb971-16e1-45c2-b878-229159e16753,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-1f017442-8241-46d9-acbe-6c5f7eeb6604,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-56091342-172.17.0.13-1597551351258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39206,DS-e30e38e0-4220-43aa-ba1e-45639f275552,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-47d70812-5da0-4584-bbef-fc1af4ae8be0,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-35bef1e5-e864-4e2d-bb0e-d9684c2557b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-f3a9d7ad-e825-44c4-82f9-4ea6b2d8f16b,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-b6e3ed63-5fe7-459e-bdff-80ea4028ca19,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-4760883e-8753-40a8-ad33-23dbfbc2d3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-a294838d-127b-4058-8b8e-5e6446fc83b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-77b3d173-64e3-4524-98c0-018c239b1314,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-56091342-172.17.0.13-1597551351258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39206,DS-e30e38e0-4220-43aa-ba1e-45639f275552,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-47d70812-5da0-4584-bbef-fc1af4ae8be0,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-35bef1e5-e864-4e2d-bb0e-d9684c2557b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-f3a9d7ad-e825-44c4-82f9-4ea6b2d8f16b,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-b6e3ed63-5fe7-459e-bdff-80ea4028ca19,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-4760883e-8753-40a8-ad33-23dbfbc2d3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-a294838d-127b-4058-8b8e-5e6446fc83b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-77b3d173-64e3-4524-98c0-018c239b1314,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-641469519-172.17.0.13-1597551465373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43644,DS-32995de3-cd9b-4731-be9a-c2dce0ab68eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-5c74ec68-3bb8-4fc1-8d13-a7f6975965c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-e59200b1-b61a-497d-b71a-40f132de6156,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-38f4cfb7-ee7d-4958-a158-878938d764e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-bd349037-e45f-4509-9aae-1f7f8cdfe984,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-597bf54e-e92f-476b-8314-16aecd17ad34,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-9edfa9f4-7c51-4c63-9b55-0009b87f73e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-f443ed6b-b639-4c2f-9dfa-446c3863f4fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-641469519-172.17.0.13-1597551465373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43644,DS-32995de3-cd9b-4731-be9a-c2dce0ab68eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-5c74ec68-3bb8-4fc1-8d13-a7f6975965c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-e59200b1-b61a-497d-b71a-40f132de6156,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-38f4cfb7-ee7d-4958-a158-878938d764e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-bd349037-e45f-4509-9aae-1f7f8cdfe984,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-597bf54e-e92f-476b-8314-16aecd17ad34,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-9edfa9f4-7c51-4c63-9b55-0009b87f73e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-f443ed6b-b639-4c2f-9dfa-446c3863f4fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097707649-172.17.0.13-1597551707640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41996,DS-ed61e105-4ad9-4f1b-83ac-05a03aa8c5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-700ad199-48a3-47b1-9da1-b57ec8a222d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-4e097164-532f-4a6a-aab4-cc03ad840f42,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-70cb9206-20ad-4c40-a8a5-de15ac59463d,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-3740e76f-c898-4d23-8fea-acdac7fc23da,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-d948053c-77c5-48cd-bc31-995aa8e0ae3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-00e91d60-22c9-4088-a7c5-33223973e373,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-4d81e48f-578a-44ba-a950-b52090105e9d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097707649-172.17.0.13-1597551707640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41996,DS-ed61e105-4ad9-4f1b-83ac-05a03aa8c5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-700ad199-48a3-47b1-9da1-b57ec8a222d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-4e097164-532f-4a6a-aab4-cc03ad840f42,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-70cb9206-20ad-4c40-a8a5-de15ac59463d,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-3740e76f-c898-4d23-8fea-acdac7fc23da,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-d948053c-77c5-48cd-bc31-995aa8e0ae3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-00e91d60-22c9-4088-a7c5-33223973e373,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-4d81e48f-578a-44ba-a950-b52090105e9d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348197513-172.17.0.13-1597551748242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40348,DS-2c421f52-7b3f-4142-aaae-6392aae4d104,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-1401bdaa-44bc-4829-ac53-5484a6197990,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-0c8b51fb-c867-469b-971f-e8c34144f67e,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-f527c4f2-636b-47d6-b47b-f01c5d53ed46,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-4af70f4b-b363-4ae0-a105-cabdcfa8f476,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-e2c888e2-ddbd-4534-a49c-1389f1437327,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-707346bf-108e-4515-a397-825ef9815771,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-55bc9839-6a2a-4726-8931-5ff680f3465e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348197513-172.17.0.13-1597551748242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40348,DS-2c421f52-7b3f-4142-aaae-6392aae4d104,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-1401bdaa-44bc-4829-ac53-5484a6197990,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-0c8b51fb-c867-469b-971f-e8c34144f67e,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-f527c4f2-636b-47d6-b47b-f01c5d53ed46,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-4af70f4b-b363-4ae0-a105-cabdcfa8f476,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-e2c888e2-ddbd-4534-a49c-1389f1437327,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-707346bf-108e-4515-a397-825ef9815771,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-55bc9839-6a2a-4726-8931-5ff680f3465e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629274025-172.17.0.13-1597551787640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34024,DS-9e35b648-7dd6-492e-8eef-fe88773b7bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-e4da397b-4405-4367-a875-be222ee5d5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-0be82638-5ff1-42e1-9aee-8e2fe140abe6,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-e265798c-96e2-49e2-b7e5-17b808448b10,DISK], DatanodeInfoWithStorage[127.0.0.1:36743,DS-4839fc9e-8af4-42bc-8008-8fdc89a94143,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-8d25ec6b-2ed8-4054-bd2b-b4b00912d33b,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-ce23c950-b2bf-4f95-b395-37d44181dcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-4bbbe046-f86c-48c1-aa20-4d6f9f05b497,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629274025-172.17.0.13-1597551787640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34024,DS-9e35b648-7dd6-492e-8eef-fe88773b7bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-e4da397b-4405-4367-a875-be222ee5d5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-0be82638-5ff1-42e1-9aee-8e2fe140abe6,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-e265798c-96e2-49e2-b7e5-17b808448b10,DISK], DatanodeInfoWithStorage[127.0.0.1:36743,DS-4839fc9e-8af4-42bc-8008-8fdc89a94143,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-8d25ec6b-2ed8-4054-bd2b-b4b00912d33b,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-ce23c950-b2bf-4f95-b395-37d44181dcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-4bbbe046-f86c-48c1-aa20-4d6f9f05b497,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167932198-172.17.0.13-1597551862875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36055,DS-f46ff58e-0f9b-48a7-8004-f7c193ea63b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-ec79ebdd-81c8-4864-8c6b-1974e519f1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-d85f0500-746f-49a0-9cf9-4da6c8250e91,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-c36b747d-9a69-4ff3-9183-00d8695d74ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-fed3b898-1f66-426d-ac0d-8aa3a88f6583,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-cead8642-815b-4e9a-97df-5bfc5aa7d10a,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-743b8949-cdb2-474b-a823-e71a7580c5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-1b75a926-dcdb-4326-a830-e1a26a5a0bc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167932198-172.17.0.13-1597551862875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36055,DS-f46ff58e-0f9b-48a7-8004-f7c193ea63b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-ec79ebdd-81c8-4864-8c6b-1974e519f1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-d85f0500-746f-49a0-9cf9-4da6c8250e91,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-c36b747d-9a69-4ff3-9183-00d8695d74ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-fed3b898-1f66-426d-ac0d-8aa3a88f6583,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-cead8642-815b-4e9a-97df-5bfc5aa7d10a,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-743b8949-cdb2-474b-a823-e71a7580c5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-1b75a926-dcdb-4326-a830-e1a26a5a0bc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749789091-172.17.0.13-1597551899757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40428,DS-562e92a6-32a7-43cb-b90f-01041c077651,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-b5baf575-b9ef-4b35-bece-2056a45fb6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-c210c5fc-af43-4be6-9d29-0d859c02617c,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-10eb0edc-dc17-4767-baec-463db9c11222,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-ea34d8de-26fc-4ef2-9824-97812b61a1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-cc402ba2-6509-40da-a765-1055b8bd9b72,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-ee9aedbf-810e-46f8-8d52-d7251a470ede,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-ef495835-1399-47d8-bd0e-33ddbe5c3c3e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749789091-172.17.0.13-1597551899757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40428,DS-562e92a6-32a7-43cb-b90f-01041c077651,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-b5baf575-b9ef-4b35-bece-2056a45fb6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-c210c5fc-af43-4be6-9d29-0d859c02617c,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-10eb0edc-dc17-4767-baec-463db9c11222,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-ea34d8de-26fc-4ef2-9824-97812b61a1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-cc402ba2-6509-40da-a765-1055b8bd9b72,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-ee9aedbf-810e-46f8-8d52-d7251a470ede,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-ef495835-1399-47d8-bd0e-33ddbe5c3c3e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 14 out of 50
v1v1v2v2 failed with probability 22 out of 50
result: false positive !!!
Total execution time in seconds : 5781
