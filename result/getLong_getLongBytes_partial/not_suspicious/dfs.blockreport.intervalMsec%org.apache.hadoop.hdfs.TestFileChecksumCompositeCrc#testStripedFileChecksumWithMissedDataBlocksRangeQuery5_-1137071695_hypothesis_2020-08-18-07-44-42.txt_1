reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-237912754-172.17.0.19-1597736699649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34536,DS-1ce95bf4-497c-437d-9164-22c4b433cb32,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-88053d79-4e18-4e7f-8272-a7ce0b389f43,DISK], DatanodeInfoWithStorage[127.0.0.1:33998,DS-4a9ce6c9-a87a-454c-b78b-06ddffe68e71,DISK], DatanodeInfoWithStorage[127.0.0.1:45202,DS-e49f4668-d5d5-4faa-bc68-b660ac5606ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-f7ae0953-3bed-474e-b2c7-f5050a3406e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-7e85c984-33a5-49ad-90e6-a47fa17c2703,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-ac5119bc-579d-471a-9c89-cbb11458b853,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-7d57d933-f4ff-4b5f-8a43-b9c4df38b3b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-237912754-172.17.0.19-1597736699649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34536,DS-1ce95bf4-497c-437d-9164-22c4b433cb32,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-88053d79-4e18-4e7f-8272-a7ce0b389f43,DISK], DatanodeInfoWithStorage[127.0.0.1:33998,DS-4a9ce6c9-a87a-454c-b78b-06ddffe68e71,DISK], DatanodeInfoWithStorage[127.0.0.1:45202,DS-e49f4668-d5d5-4faa-bc68-b660ac5606ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-f7ae0953-3bed-474e-b2c7-f5050a3406e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-7e85c984-33a5-49ad-90e6-a47fa17c2703,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-ac5119bc-579d-471a-9c89-cbb11458b853,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-7d57d933-f4ff-4b5f-8a43-b9c4df38b3b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1159884485-172.17.0.19-1597737045252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42256,DS-f97e042d-77ee-47d6-bd04-64ea71a91047,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-048b06fa-aa32-40dc-94c6-41e6209e0145,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-21b2d58e-2e31-465c-a8d1-b0a0630262e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-33c0b877-f1c8-4816-8d94-07d5d9f3caab,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-15bcea05-d3d6-47e6-bbdc-85be9cb8e527,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-aaf646f8-beb9-40e0-9e88-b73dd5f8d787,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-aee1bd2a-71ab-473f-a0a7-0c0bbe1d5bee,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-84495d27-ee09-4756-814b-12e68542178e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1159884485-172.17.0.19-1597737045252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42256,DS-f97e042d-77ee-47d6-bd04-64ea71a91047,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-048b06fa-aa32-40dc-94c6-41e6209e0145,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-21b2d58e-2e31-465c-a8d1-b0a0630262e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-33c0b877-f1c8-4816-8d94-07d5d9f3caab,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-15bcea05-d3d6-47e6-bbdc-85be9cb8e527,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-aaf646f8-beb9-40e0-9e88-b73dd5f8d787,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-aee1bd2a-71ab-473f-a0a7-0c0bbe1d5bee,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-84495d27-ee09-4756-814b-12e68542178e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-450793121-172.17.0.19-1597737486724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33047,DS-7c073be9-42cd-4d82-8132-5fa0c93fab57,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-81095aa3-67d5-4e6f-8f31-d95044518ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-7957b168-aa27-46de-a090-e48ab1531746,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-00b80f96-2bc5-477b-8320-c22f98520cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-7094a4ef-f6af-4180-bbfe-496edfb3fbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-82dcca7c-89a8-4e28-8976-94ceb389c790,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-56c6468e-bbf8-4e4f-bfe3-7e7fa4dee0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-9c0b117a-4ce3-4caf-8dd3-075b2ad40e30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-450793121-172.17.0.19-1597737486724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33047,DS-7c073be9-42cd-4d82-8132-5fa0c93fab57,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-81095aa3-67d5-4e6f-8f31-d95044518ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-7957b168-aa27-46de-a090-e48ab1531746,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-00b80f96-2bc5-477b-8320-c22f98520cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-7094a4ef-f6af-4180-bbfe-496edfb3fbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-82dcca7c-89a8-4e28-8976-94ceb389c790,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-56c6468e-bbf8-4e4f-bfe3-7e7fa4dee0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-9c0b117a-4ce3-4caf-8dd3-075b2ad40e30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1198448142-172.17.0.19-1597737600366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38776,DS-c1d4d312-9ef2-4d6d-bcf0-a6277457d1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-6beff309-6fa3-4cdc-97a3-86b3e4e5f506,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-6e1a1f52-a7fb-45a5-9208-4f52ac4ef616,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-e61b6f36-8d47-464c-aa09-92de62fd49ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-4ede8be8-3ac9-4f9a-98cd-ed37bb2173d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-9c9b60a7-3d34-4955-952a-1f2d88fc2ede,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-418b5440-fba6-43bd-a8d8-4ab534e51b40,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-e23cce32-9bc4-47bd-8a03-18374161aa07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1198448142-172.17.0.19-1597737600366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38776,DS-c1d4d312-9ef2-4d6d-bcf0-a6277457d1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-6beff309-6fa3-4cdc-97a3-86b3e4e5f506,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-6e1a1f52-a7fb-45a5-9208-4f52ac4ef616,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-e61b6f36-8d47-464c-aa09-92de62fd49ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-4ede8be8-3ac9-4f9a-98cd-ed37bb2173d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-9c9b60a7-3d34-4955-952a-1f2d88fc2ede,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-418b5440-fba6-43bd-a8d8-4ab534e51b40,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-e23cce32-9bc4-47bd-8a03-18374161aa07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-620326613-172.17.0.19-1597738039904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45659,DS-f102a65a-69c6-4533-8c1a-f399bf8ad063,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-921509cc-a65b-4c8d-9b60-375381885a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-5346be40-a9a9-4474-b815-525f78fbb9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-c5986c42-a431-4c22-a3fb-01b9592cfc16,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-d80c8ed9-00f9-4b29-adb6-7e33d36f7149,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-4ead3727-204c-4d68-a784-a45ad81cd2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-aaa7c25c-348c-4b6c-9fda-941516eebe2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-d0eaa84f-9860-46c9-a0af-75534951e173,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-620326613-172.17.0.19-1597738039904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45659,DS-f102a65a-69c6-4533-8c1a-f399bf8ad063,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-921509cc-a65b-4c8d-9b60-375381885a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-5346be40-a9a9-4474-b815-525f78fbb9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-c5986c42-a431-4c22-a3fb-01b9592cfc16,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-d80c8ed9-00f9-4b29-adb6-7e33d36f7149,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-4ead3727-204c-4d68-a784-a45ad81cd2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-aaa7c25c-348c-4b6c-9fda-941516eebe2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-d0eaa84f-9860-46c9-a0af-75534951e173,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461398219-172.17.0.19-1597738431354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35389,DS-e60bc6ca-559c-4e85-be0e-fce081d0a682,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-bdcb2c38-f07d-4117-92b3-c41d747c4884,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-3eb4821f-50e5-4c24-b208-0b7da6ff4c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-ec941ed3-3df4-4a30-ab08-9b7e1f42786e,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-fbfeb7b3-e731-4471-a200-afdc8098281f,DISK], DatanodeInfoWithStorage[127.0.0.1:40851,DS-505e7040-2540-40d7-a20b-a7ed7207e6d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-6ac2f209-f02f-46a3-99c9-823b9ba409ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-192670c5-4169-460e-b73c-4e1f8d0538f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461398219-172.17.0.19-1597738431354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35389,DS-e60bc6ca-559c-4e85-be0e-fce081d0a682,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-bdcb2c38-f07d-4117-92b3-c41d747c4884,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-3eb4821f-50e5-4c24-b208-0b7da6ff4c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-ec941ed3-3df4-4a30-ab08-9b7e1f42786e,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-fbfeb7b3-e731-4471-a200-afdc8098281f,DISK], DatanodeInfoWithStorage[127.0.0.1:40851,DS-505e7040-2540-40d7-a20b-a7ed7207e6d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-6ac2f209-f02f-46a3-99c9-823b9ba409ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-192670c5-4169-460e-b73c-4e1f8d0538f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1384274053-172.17.0.19-1597738978529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41337,DS-4c8d9033-9960-4ce4-b3e8-1861f1db6e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-37409407-ea74-44a7-bb95-2ecf253c1064,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-625fec8a-2e72-484d-be5b-309a27432008,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-b1d84223-647a-4d21-bc35-85829dd30f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-b8967985-5e5c-491c-ad17-0aa9deeab84d,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-a9910fcf-8710-49dc-a6ba-1eddd172eb13,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-45886369-813c-47db-bca6-1b6b9e6555c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-77c2a19f-7d09-4814-b58a-5ee01884df31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1384274053-172.17.0.19-1597738978529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41337,DS-4c8d9033-9960-4ce4-b3e8-1861f1db6e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-37409407-ea74-44a7-bb95-2ecf253c1064,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-625fec8a-2e72-484d-be5b-309a27432008,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-b1d84223-647a-4d21-bc35-85829dd30f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-b8967985-5e5c-491c-ad17-0aa9deeab84d,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-a9910fcf-8710-49dc-a6ba-1eddd172eb13,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-45886369-813c-47db-bca6-1b6b9e6555c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-77c2a19f-7d09-4814-b58a-5ee01884df31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1153743063-172.17.0.19-1597739309341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39772,DS-49f7d21e-d757-4530-a73e-e8ea3f40419b,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-732d6b3e-51f1-4413-bb41-c20bf9d6b852,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-6be25ffb-7d6b-4e8e-b99f-60853f24183b,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-fdf28f8b-b586-4e79-b3e5-1a6606dcf728,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-3fc3f9d2-35e0-403b-a370-18b0ad2e1a35,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-144132d8-4105-46a4-92b8-26ff342a4077,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-991edcc7-4cae-4e6e-827a-4e6b35b31e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-5c5ea53e-1cff-4611-9b75-2cbd88e68fdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1153743063-172.17.0.19-1597739309341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39772,DS-49f7d21e-d757-4530-a73e-e8ea3f40419b,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-732d6b3e-51f1-4413-bb41-c20bf9d6b852,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-6be25ffb-7d6b-4e8e-b99f-60853f24183b,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-fdf28f8b-b586-4e79-b3e5-1a6606dcf728,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-3fc3f9d2-35e0-403b-a370-18b0ad2e1a35,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-144132d8-4105-46a4-92b8-26ff342a4077,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-991edcc7-4cae-4e6e-827a-4e6b35b31e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-5c5ea53e-1cff-4611-9b75-2cbd88e68fdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1881111171-172.17.0.19-1597739388664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42013,DS-598b62cf-9b0a-4954-863a-e56ebd4bfc21,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-686947a3-b5d8-481e-8e7c-810638b153a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-7532689e-77a7-499c-84de-ca6433a88dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-06690798-4ec3-49bf-a67f-d4a7f28c5c44,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-229e189f-8e3f-4b9d-9493-895209406cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-0de61b04-071f-4d8b-8523-1204924fb76d,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-6ff88d06-9613-4075-b44e-d6d877609dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-0bffbaaa-e1ff-429f-a0fb-c82d0f1f55a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1881111171-172.17.0.19-1597739388664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42013,DS-598b62cf-9b0a-4954-863a-e56ebd4bfc21,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-686947a3-b5d8-481e-8e7c-810638b153a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-7532689e-77a7-499c-84de-ca6433a88dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-06690798-4ec3-49bf-a67f-d4a7f28c5c44,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-229e189f-8e3f-4b9d-9493-895209406cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-0de61b04-071f-4d8b-8523-1204924fb76d,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-6ff88d06-9613-4075-b44e-d6d877609dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-0bffbaaa-e1ff-429f-a0fb-c82d0f1f55a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1911166982-172.17.0.19-1597739584106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43030,DS-8cf34962-9b84-4cde-9466-24f926a91a42,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-e1f13a62-f941-4a54-862f-5d5047dffc74,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-80572ef7-e5d7-4cf1-9e68-fcc5b5f2f122,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-7aaf9ada-8be6-449f-85cf-7f16efe5a2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-6ea39e4f-820f-4b92-a672-1ea4923c3786,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-49814b12-64e8-4227-bb2c-fa955bcb6d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-94f01b6b-5955-4bed-9eb6-ffbb6dde0805,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-956849f5-333f-4142-ac67-238d4351ea55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1911166982-172.17.0.19-1597739584106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43030,DS-8cf34962-9b84-4cde-9466-24f926a91a42,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-e1f13a62-f941-4a54-862f-5d5047dffc74,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-80572ef7-e5d7-4cf1-9e68-fcc5b5f2f122,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-7aaf9ada-8be6-449f-85cf-7f16efe5a2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-6ea39e4f-820f-4b92-a672-1ea4923c3786,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-49814b12-64e8-4227-bb2c-fa955bcb6d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-94f01b6b-5955-4bed-9eb6-ffbb6dde0805,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-956849f5-333f-4142-ac67-238d4351ea55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1579652924-172.17.0.19-1597739621593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41155,DS-ec822d61-2b75-44f1-872c-e99bef82cf91,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-24e0c151-57d8-44d2-9535-06e32ba373ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-ad32a997-2a8d-46f2-ba27-fce233ce932d,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-a18c3a4f-546f-4fd7-8f20-4d7c519ced53,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-3547dd8f-aefa-4f09-80f2-38b6fc4803c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-cf9fb201-ff40-472e-ac4c-8d5b881a7b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-20d047cb-0843-470e-8bc0-e73d0b07a125,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-cfb24bec-5363-430a-ad20-dc586ad10452,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1579652924-172.17.0.19-1597739621593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41155,DS-ec822d61-2b75-44f1-872c-e99bef82cf91,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-24e0c151-57d8-44d2-9535-06e32ba373ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-ad32a997-2a8d-46f2-ba27-fce233ce932d,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-a18c3a4f-546f-4fd7-8f20-4d7c519ced53,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-3547dd8f-aefa-4f09-80f2-38b6fc4803c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-cf9fb201-ff40-472e-ac4c-8d5b881a7b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-20d047cb-0843-470e-8bc0-e73d0b07a125,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-cfb24bec-5363-430a-ad20-dc586ad10452,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-280543231-172.17.0.19-1597739978522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39698,DS-2fe34324-bc11-4a3c-987a-fc6ad486cc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-322fc26f-cb7a-4b79-87a8-f063c0ef047a,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-dfdca5dd-2b3a-4a74-892c-b376bffd699e,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-e889a6ee-e396-4e16-a369-402deaf75cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-10e0d376-dc7e-458f-8496-aae7af3549d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-cfed0717-42e3-41ab-9bf7-6aa18816790f,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-d6de6bb5-eeb5-46ac-a91a-675361c77e24,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-9a1366ba-f70e-477e-b0b3-f0960776c79d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-280543231-172.17.0.19-1597739978522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39698,DS-2fe34324-bc11-4a3c-987a-fc6ad486cc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-322fc26f-cb7a-4b79-87a8-f063c0ef047a,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-dfdca5dd-2b3a-4a74-892c-b376bffd699e,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-e889a6ee-e396-4e16-a369-402deaf75cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-10e0d376-dc7e-458f-8496-aae7af3549d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-cfed0717-42e3-41ab-9bf7-6aa18816790f,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-d6de6bb5-eeb5-46ac-a91a-675361c77e24,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-9a1366ba-f70e-477e-b0b3-f0960776c79d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-228345062-172.17.0.19-1597740242364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33070,DS-cda62de5-8f7e-4b0d-ab57-2267d44eea13,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-acdb3a10-c125-4db2-b01f-73cbb9d330e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-ff56c4cf-79c2-4333-8006-d7582f210b82,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-95b30dc5-d55e-4c3c-a5b0-57f88e4e0848,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-f39131b0-9513-44d3-84f8-40ca4c24899d,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-f1c51520-cc01-437a-8d9b-08c8906d1294,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-75b3bb46-d60e-49d8-ab5e-9b51dccf2db4,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-334bcc33-7a21-41b6-ae08-b9f3b7a2f765,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-228345062-172.17.0.19-1597740242364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33070,DS-cda62de5-8f7e-4b0d-ab57-2267d44eea13,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-acdb3a10-c125-4db2-b01f-73cbb9d330e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-ff56c4cf-79c2-4333-8006-d7582f210b82,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-95b30dc5-d55e-4c3c-a5b0-57f88e4e0848,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-f39131b0-9513-44d3-84f8-40ca4c24899d,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-f1c51520-cc01-437a-8d9b-08c8906d1294,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-75b3bb46-d60e-49d8-ab5e-9b51dccf2db4,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-334bcc33-7a21-41b6-ae08-b9f3b7a2f765,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567618094-172.17.0.19-1597740452911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33594,DS-8b62f4c2-cc16-407f-bd47-685cf8b19475,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-263d4876-ad61-4d19-acf9-83907d08d2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-79576684-7ff4-4431-a5e2-4745df554b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-8e213e2f-f65f-4a1d-8a59-18520faf70d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-0797326f-f62f-4f55-a657-e05391de0911,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-d2a7bd80-670e-447f-be1c-75b96342ecbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35297,DS-ceccfdf2-ac5f-460a-98d0-edafbb15dc40,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-133bdc10-139a-427a-8516-cac0881c0481,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567618094-172.17.0.19-1597740452911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33594,DS-8b62f4c2-cc16-407f-bd47-685cf8b19475,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-263d4876-ad61-4d19-acf9-83907d08d2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-79576684-7ff4-4431-a5e2-4745df554b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-8e213e2f-f65f-4a1d-8a59-18520faf70d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-0797326f-f62f-4f55-a657-e05391de0911,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-d2a7bd80-670e-447f-be1c-75b96342ecbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35297,DS-ceccfdf2-ac5f-460a-98d0-edafbb15dc40,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-133bdc10-139a-427a-8516-cac0881c0481,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1470667986-172.17.0.19-1597740691866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34624,DS-2bce0595-be0b-49b9-803b-9200e91794df,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-69d85df8-5c0e-4f05-ac9d-ba3d27907fee,DISK], DatanodeInfoWithStorage[127.0.0.1:42012,DS-324a79ae-44e5-4a9f-8794-49c39fe09ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-d84ccbc0-ad5f-4ba3-9a36-4dd248e6e108,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-7115995b-0b73-4c38-8adf-98b8d2ca6c45,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-cfcbc5e3-a420-4ca4-bcb3-554efe647b72,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-d34fb71b-dfaa-4ecf-9a07-c162126ff871,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-c6c54142-0cbe-430c-9e09-ec5e7444de60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1470667986-172.17.0.19-1597740691866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34624,DS-2bce0595-be0b-49b9-803b-9200e91794df,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-69d85df8-5c0e-4f05-ac9d-ba3d27907fee,DISK], DatanodeInfoWithStorage[127.0.0.1:42012,DS-324a79ae-44e5-4a9f-8794-49c39fe09ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-d84ccbc0-ad5f-4ba3-9a36-4dd248e6e108,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-7115995b-0b73-4c38-8adf-98b8d2ca6c45,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-cfcbc5e3-a420-4ca4-bcb3-554efe647b72,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-d34fb71b-dfaa-4ecf-9a07-c162126ff871,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-c6c54142-0cbe-430c-9e09-ec5e7444de60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1711408005-172.17.0.19-1597740733172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34537,DS-8d78baa1-4de5-475b-8eab-e16b7c5afa73,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-f585d037-819e-47e9-b847-8d1a696807a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-14927382-df12-4b03-ac46-8e035f8fcef3,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-212f0aae-e907-4e13-bc95-b24938fa24dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-2cf91d72-5f1b-42c1-8321-d70dcfecd35c,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-8c15dc2b-20f4-471c-b59e-26a194fd4888,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-abba3f81-daf9-403c-9d50-9f8bef84d5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-0f319cf6-2e8e-4cd7-9631-717cee9749e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1711408005-172.17.0.19-1597740733172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34537,DS-8d78baa1-4de5-475b-8eab-e16b7c5afa73,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-f585d037-819e-47e9-b847-8d1a696807a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-14927382-df12-4b03-ac46-8e035f8fcef3,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-212f0aae-e907-4e13-bc95-b24938fa24dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-2cf91d72-5f1b-42c1-8321-d70dcfecd35c,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-8c15dc2b-20f4-471c-b59e-26a194fd4888,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-abba3f81-daf9-403c-9d50-9f8bef84d5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-0f319cf6-2e8e-4cd7-9631-717cee9749e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1920363213-172.17.0.19-1597740839646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41540,DS-5c0234d2-073b-457e-b3dc-0b12e9c98fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-e1652f60-901d-4c93-bc9d-f320c7ed8397,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-c5117c80-8a25-402b-8327-67498ae68092,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-b109b733-cbd0-4f2f-b91a-098a6c2f6d89,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-4963836b-1fe7-4fa1-a02e-df928bc6b5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-91020c38-425a-4386-ba30-022b27c7e4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-3332cc55-2c93-4312-a8a9-163bc7e958f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-de0620c1-9524-4264-a6bd-f31d20288ccb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1920363213-172.17.0.19-1597740839646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41540,DS-5c0234d2-073b-457e-b3dc-0b12e9c98fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-e1652f60-901d-4c93-bc9d-f320c7ed8397,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-c5117c80-8a25-402b-8327-67498ae68092,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-b109b733-cbd0-4f2f-b91a-098a6c2f6d89,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-4963836b-1fe7-4fa1-a02e-df928bc6b5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-91020c38-425a-4386-ba30-022b27c7e4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-3332cc55-2c93-4312-a8a9-163bc7e958f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-de0620c1-9524-4264-a6bd-f31d20288ccb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980418767-172.17.0.19-1597741761487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37719,DS-4046bc04-c4f8-4081-9164-48d8fab899d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-3379ed28-afd9-450a-bb8a-7e10237ef0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-63f44ce6-e5b1-4b5a-a8c7-b3860e6df3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-92526984-8eb3-42e3-a116-da3d8ee72008,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-5a5aa57e-d8b1-4d73-a628-d7bf722549d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-b118d97a-7661-4b2c-ae21-235ab48d64f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-a840073e-71b3-4bfa-b5c7-5df48a3f7b64,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-eb967a5f-0df2-47a7-9723-aaacb7c4c847,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980418767-172.17.0.19-1597741761487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37719,DS-4046bc04-c4f8-4081-9164-48d8fab899d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-3379ed28-afd9-450a-bb8a-7e10237ef0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-63f44ce6-e5b1-4b5a-a8c7-b3860e6df3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-92526984-8eb3-42e3-a116-da3d8ee72008,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-5a5aa57e-d8b1-4d73-a628-d7bf722549d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-b118d97a-7661-4b2c-ae21-235ab48d64f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-a840073e-71b3-4bfa-b5c7-5df48a3f7b64,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-eb967a5f-0df2-47a7-9723-aaacb7c4c847,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1916607442-172.17.0.19-1597742301462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45998,DS-e6a532c4-3c8a-403f-a0da-d578e405c728,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-45adb694-cb90-4322-9b2e-1ce05aad1fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-50dab967-a91e-4764-831f-e1405d706537,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-e9fb1d75-c667-4602-965c-daf6b98df8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-707e71da-2156-4c00-8764-f303ce33d332,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-72de553c-f55f-41fd-be0b-84953fe0d51d,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-28e819be-fb5d-4503-b23b-f0e0711c1909,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-07679a4c-1524-4750-82b0-bc761b61e840,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1916607442-172.17.0.19-1597742301462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45998,DS-e6a532c4-3c8a-403f-a0da-d578e405c728,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-45adb694-cb90-4322-9b2e-1ce05aad1fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-50dab967-a91e-4764-831f-e1405d706537,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-e9fb1d75-c667-4602-965c-daf6b98df8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-707e71da-2156-4c00-8764-f303ce33d332,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-72de553c-f55f-41fd-be0b-84953fe0d51d,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-28e819be-fb5d-4503-b23b-f0e0711c1909,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-07679a4c-1524-4750-82b0-bc761b61e840,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5834
