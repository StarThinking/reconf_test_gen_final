reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1880976839-172.17.0.16-1597739993477:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35603,DS-6161e77d-c501-4d27-9c49-d64d03af8cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-d89dc9a8-a3d8-4c5a-8045-d01f34c608ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-95923ff1-1110-4933-b978-e4d21e76ddcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-528843e8-5a91-47dc-a690-5ec168c11c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-1b8e80c7-ea19-40b2-8b70-7dafb28cecfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-93d1a06a-61e7-4ea9-a5f1-1fbc8a035907,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-8253f203-a623-4f81-b11d-58f24007863d,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-e3e43546-9fec-475c-907e-3cfaa61dbc7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1880976839-172.17.0.16-1597739993477:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35603,DS-6161e77d-c501-4d27-9c49-d64d03af8cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-d89dc9a8-a3d8-4c5a-8045-d01f34c608ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-95923ff1-1110-4933-b978-e4d21e76ddcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-528843e8-5a91-47dc-a690-5ec168c11c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-1b8e80c7-ea19-40b2-8b70-7dafb28cecfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-93d1a06a-61e7-4ea9-a5f1-1fbc8a035907,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-8253f203-a623-4f81-b11d-58f24007863d,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-e3e43546-9fec-475c-907e-3cfaa61dbc7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-503970700-172.17.0.16-1597740053647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39777,DS-3e88f04e-4f2b-4948-b734-cd919b29f33f,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-2d875938-68fb-4771-854b-8fcfb850aafe,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-f40e86d7-4d00-4ec8-b099-5268bc613d52,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-003743bf-976d-449f-ae35-084edf29e258,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-ce749a85-8902-4eb1-abac-927c3f254b93,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-d0834693-8140-4e7b-a155-68d97a97a6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-6dba0383-74d4-4a41-a2bb-d8eecce3f457,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-5e65984e-b453-459f-97c9-2909f5971e6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-503970700-172.17.0.16-1597740053647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39777,DS-3e88f04e-4f2b-4948-b734-cd919b29f33f,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-2d875938-68fb-4771-854b-8fcfb850aafe,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-f40e86d7-4d00-4ec8-b099-5268bc613d52,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-003743bf-976d-449f-ae35-084edf29e258,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-ce749a85-8902-4eb1-abac-927c3f254b93,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-d0834693-8140-4e7b-a155-68d97a97a6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-6dba0383-74d4-4a41-a2bb-d8eecce3f457,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-5e65984e-b453-459f-97c9-2909f5971e6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1691459586-172.17.0.16-1597740088935:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39399,DS-f76192a4-4e2c-464e-81ff-e182962a4877,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-91233500-c0ee-4566-a1c4-d51f40b4d820,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-eea0c25c-ebe1-44ae-89f0-8f6db1466c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-2ea1b31d-8934-4535-9926-50bca405f88c,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-0d3937d4-f397-4efc-af11-e6c73c9f3c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-159dd9f4-2761-4876-9c1d-50f7f06d28ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-118a1787-a95f-4dbb-b705-411f4920ada2,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-7736e7f5-dbb6-493b-9946-2dc4679b2c96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1691459586-172.17.0.16-1597740088935:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39399,DS-f76192a4-4e2c-464e-81ff-e182962a4877,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-91233500-c0ee-4566-a1c4-d51f40b4d820,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-eea0c25c-ebe1-44ae-89f0-8f6db1466c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-2ea1b31d-8934-4535-9926-50bca405f88c,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-0d3937d4-f397-4efc-af11-e6c73c9f3c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-159dd9f4-2761-4876-9c1d-50f7f06d28ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-118a1787-a95f-4dbb-b705-411f4920ada2,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-7736e7f5-dbb6-493b-9946-2dc4679b2c96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1252165712-172.17.0.16-1597740318069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34318,DS-2ee59712-4ed7-4d02-841c-6acfb0f0d712,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-ea46f437-81bd-4a73-a597-1d54a0f5db80,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-d13b1f5a-972f-4ef6-ac2e-b7bed88fa73f,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-f855cae5-146a-4e2f-974c-364619c929d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-3f30d576-113d-4f1b-895c-f70042192176,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-f1a10a67-1f2a-4583-8b55-0d3740aa2cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-f1d0a11b-18a2-4353-b8d4-40f86c223900,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-8faf4614-bb1c-422e-9e87-718fe2a9e1ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1252165712-172.17.0.16-1597740318069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34318,DS-2ee59712-4ed7-4d02-841c-6acfb0f0d712,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-ea46f437-81bd-4a73-a597-1d54a0f5db80,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-d13b1f5a-972f-4ef6-ac2e-b7bed88fa73f,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-f855cae5-146a-4e2f-974c-364619c929d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-3f30d576-113d-4f1b-895c-f70042192176,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-f1a10a67-1f2a-4583-8b55-0d3740aa2cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-f1d0a11b-18a2-4353-b8d4-40f86c223900,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-8faf4614-bb1c-422e-9e87-718fe2a9e1ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-361677118-172.17.0.16-1597740348824:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43725,DS-ecce50da-8c7a-46bb-9898-ee7bf672ac47,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-b2a67b65-2069-4d69-89d6-746c952cd5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-79951391-e775-4c82-adc9-ba814f4809eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-9f89defd-9d0d-4288-a3dc-040aeb1260d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-e22c090b-6d19-4f74-8f2f-13c4f8712f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-3ec86932-e652-4972-b53f-5a4c09757ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-f057ea7e-5cd3-4b08-ad43-7a64cbc2ca14,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-aa289b85-f2d9-400a-930d-e93c8edc1ab7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-361677118-172.17.0.16-1597740348824:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43725,DS-ecce50da-8c7a-46bb-9898-ee7bf672ac47,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-b2a67b65-2069-4d69-89d6-746c952cd5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-79951391-e775-4c82-adc9-ba814f4809eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-9f89defd-9d0d-4288-a3dc-040aeb1260d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-e22c090b-6d19-4f74-8f2f-13c4f8712f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-3ec86932-e652-4972-b53f-5a4c09757ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-f057ea7e-5cd3-4b08-ad43-7a64cbc2ca14,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-aa289b85-f2d9-400a-930d-e93c8edc1ab7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1625657798-172.17.0.16-1597740422544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35857,DS-28e1f5ef-26dd-4994-9071-7dd05cf56f76,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-7b5444b4-d106-4260-9b67-2de4c3b7560a,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-f660dea9-242c-465e-a809-205b0a16281e,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-656d6faa-2ef3-451a-9925-01ca30e6da70,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-843d4e60-986c-474e-9961-a4fb1aae69d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-ebf208c3-3320-453c-af43-6e8f370e721b,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-b47dcacc-6752-43d1-a4d6-1a564fca1e98,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-b87513e8-8dd6-4cb0-b708-9153ba6cb385,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1625657798-172.17.0.16-1597740422544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35857,DS-28e1f5ef-26dd-4994-9071-7dd05cf56f76,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-7b5444b4-d106-4260-9b67-2de4c3b7560a,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-f660dea9-242c-465e-a809-205b0a16281e,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-656d6faa-2ef3-451a-9925-01ca30e6da70,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-843d4e60-986c-474e-9961-a4fb1aae69d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-ebf208c3-3320-453c-af43-6e8f370e721b,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-b47dcacc-6752-43d1-a4d6-1a564fca1e98,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-b87513e8-8dd6-4cb0-b708-9153ba6cb385,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-164210600-172.17.0.16-1597740528576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40658,DS-953bd914-aa61-47cc-a10f-b2f64d7f4562,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-1373feb0-3610-4389-895c-09704666a06f,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-ab9a4f6d-6a86-4b96-8f16-ec20901aa2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-7c1c6d0c-2c8f-442d-93b3-cd2bce48f086,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-6ff6fe62-6726-4ed1-ac3b-e27428344a96,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-0820507d-7473-43a9-9f59-6a4522484bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-d811c9e8-c6c8-4242-a5e9-4f3aab8b559d,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-03550bd1-a25a-4979-8b37-fa28e4832dc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-164210600-172.17.0.16-1597740528576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40658,DS-953bd914-aa61-47cc-a10f-b2f64d7f4562,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-1373feb0-3610-4389-895c-09704666a06f,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-ab9a4f6d-6a86-4b96-8f16-ec20901aa2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-7c1c6d0c-2c8f-442d-93b3-cd2bce48f086,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-6ff6fe62-6726-4ed1-ac3b-e27428344a96,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-0820507d-7473-43a9-9f59-6a4522484bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-d811c9e8-c6c8-4242-a5e9-4f3aab8b559d,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-03550bd1-a25a-4979-8b37-fa28e4832dc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1407485616-172.17.0.16-1597740979232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37175,DS-b167058e-5161-45c7-a0c3-df55c45e0401,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-0ee17240-e891-461e-be96-1b5592300425,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-62f25d2d-f65c-42e4-9e24-16eb94fe356c,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-7cc27c66-6666-40fd-ab68-8d82c30776fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-c8be32e7-d8cf-4513-99cb-c0c9d96fcbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-ea745524-5442-446d-9ef1-b1af52a9ab6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-13da368c-4b10-4fa6-b0eb-612ba1cc05db,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-5df2dea8-5de7-4443-af34-0d1dae608f99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1407485616-172.17.0.16-1597740979232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37175,DS-b167058e-5161-45c7-a0c3-df55c45e0401,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-0ee17240-e891-461e-be96-1b5592300425,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-62f25d2d-f65c-42e4-9e24-16eb94fe356c,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-7cc27c66-6666-40fd-ab68-8d82c30776fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-c8be32e7-d8cf-4513-99cb-c0c9d96fcbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-ea745524-5442-446d-9ef1-b1af52a9ab6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-13da368c-4b10-4fa6-b0eb-612ba1cc05db,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-5df2dea8-5de7-4443-af34-0d1dae608f99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-826495015-172.17.0.16-1597741044884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39751,DS-dbe51b5d-88f7-48bd-827f-fe6a4a68f3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-f4958f9a-6b98-4b0a-9902-a85f15ae1b73,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-c1edda44-c2e7-4c17-a754-fa1a365b5e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-df6cf190-5b39-4a37-94da-b2df82a8e8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-51f05962-b728-4e13-b0d2-99256703831f,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-bc9e76ff-a2b3-45b6-844b-b5dbe7aef7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-32542e86-088f-40cb-8839-37e1d919d4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-cceb7b19-f02b-4590-8119-e0dd48f0a8b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-826495015-172.17.0.16-1597741044884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39751,DS-dbe51b5d-88f7-48bd-827f-fe6a4a68f3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-f4958f9a-6b98-4b0a-9902-a85f15ae1b73,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-c1edda44-c2e7-4c17-a754-fa1a365b5e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-df6cf190-5b39-4a37-94da-b2df82a8e8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-51f05962-b728-4e13-b0d2-99256703831f,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-bc9e76ff-a2b3-45b6-844b-b5dbe7aef7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-32542e86-088f-40cb-8839-37e1d919d4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-cceb7b19-f02b-4590-8119-e0dd48f0a8b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2060045526-172.17.0.16-1597741413601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42904,DS-c486ab85-568e-4454-b880-e43637d930b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42154,DS-aea5e951-39ef-4d13-b350-f12fa63e01ad,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-697c08fc-2fa8-4e82-afb5-e007c7e36459,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-22e6111c-0a7a-44d0-af95-1626a817427e,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-c15a4156-9794-4d12-8105-ae0992e76d18,DISK], DatanodeInfoWithStorage[127.0.0.1:38456,DS-a334675a-1f27-437c-92c3-c1aff0b1088e,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-590c2de3-a765-4020-a14c-535c134c7fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-733e15be-ba61-4e7f-ad14-3bf2ed4df5a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2060045526-172.17.0.16-1597741413601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42904,DS-c486ab85-568e-4454-b880-e43637d930b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42154,DS-aea5e951-39ef-4d13-b350-f12fa63e01ad,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-697c08fc-2fa8-4e82-afb5-e007c7e36459,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-22e6111c-0a7a-44d0-af95-1626a817427e,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-c15a4156-9794-4d12-8105-ae0992e76d18,DISK], DatanodeInfoWithStorage[127.0.0.1:38456,DS-a334675a-1f27-437c-92c3-c1aff0b1088e,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-590c2de3-a765-4020-a14c-535c134c7fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-733e15be-ba61-4e7f-ad14-3bf2ed4df5a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1310771755-172.17.0.16-1597741527560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33856,DS-147553c3-9853-48d9-aa2e-2f501fbbeaf9,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-3a5ad536-983f-46c6-a40a-f4d2aa2c2263,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-8bfbdeab-7e8e-4c2b-b790-516ec6dbc8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-46a4f52a-69f4-4136-a3ad-3773974003ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-bc806396-3bc6-4198-8d60-e07bc6762c92,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-2b98c5e8-d07e-4399-9c4c-75f5c77751db,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-1732fd93-b61a-44a4-a751-239834845b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-1f5fcf62-6eb1-4fcf-a359-487961ff8dbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1310771755-172.17.0.16-1597741527560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33856,DS-147553c3-9853-48d9-aa2e-2f501fbbeaf9,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-3a5ad536-983f-46c6-a40a-f4d2aa2c2263,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-8bfbdeab-7e8e-4c2b-b790-516ec6dbc8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-46a4f52a-69f4-4136-a3ad-3773974003ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-bc806396-3bc6-4198-8d60-e07bc6762c92,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-2b98c5e8-d07e-4399-9c4c-75f5c77751db,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-1732fd93-b61a-44a4-a751-239834845b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-1f5fcf62-6eb1-4fcf-a359-487961ff8dbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-77457623-172.17.0.16-1597741600916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33798,DS-7985855b-5bed-4e22-8d67-6ae52fa135b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35503,DS-661459db-b575-471c-9cb1-7c9316a1492f,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-a3764d33-5597-4b71-9065-ee36b4398678,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-edb88bcb-622e-47ef-948b-5bf13ab86e49,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-4496c8ca-b51b-4366-a76d-09b329ee30d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-2af05cb8-6122-4847-9e9d-760e415e691e,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-8f4f531c-f992-485b-93e6-f897b5442066,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-010ca40f-752e-40c4-8f1a-e923cb127c10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-77457623-172.17.0.16-1597741600916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33798,DS-7985855b-5bed-4e22-8d67-6ae52fa135b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35503,DS-661459db-b575-471c-9cb1-7c9316a1492f,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-a3764d33-5597-4b71-9065-ee36b4398678,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-edb88bcb-622e-47ef-948b-5bf13ab86e49,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-4496c8ca-b51b-4366-a76d-09b329ee30d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-2af05cb8-6122-4847-9e9d-760e415e691e,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-8f4f531c-f992-485b-93e6-f897b5442066,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-010ca40f-752e-40c4-8f1a-e923cb127c10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-818607884-172.17.0.16-1597741991817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33220,DS-4285b6bc-fbf7-48b2-94d2-01499ef9bc4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-11efd562-3466-4b94-a7c2-97fe1500958f,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-973b8126-6ec5-4ba5-a61f-603884ee38e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35994,DS-54aa3b88-7a77-4d91-9c45-fe05c32036ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-c042c0d1-16c7-497a-9487-b61909eb936a,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-f574f8b1-aef8-4396-8755-96f76d4dc691,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-da0569bd-80c5-43a2-b6eb-6b11bae60fba,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-f4ed9639-39cf-43d4-b656-587985af5eaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-818607884-172.17.0.16-1597741991817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33220,DS-4285b6bc-fbf7-48b2-94d2-01499ef9bc4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-11efd562-3466-4b94-a7c2-97fe1500958f,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-973b8126-6ec5-4ba5-a61f-603884ee38e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35994,DS-54aa3b88-7a77-4d91-9c45-fe05c32036ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-c042c0d1-16c7-497a-9487-b61909eb936a,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-f574f8b1-aef8-4396-8755-96f76d4dc691,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-da0569bd-80c5-43a2-b6eb-6b11bae60fba,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-f4ed9639-39cf-43d4-b656-587985af5eaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1868191617-172.17.0.16-1597742347131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46286,DS-b6103a56-9194-4ca2-9327-a21fc57befdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-32cd3fa5-3284-4183-b9a1-819c96df6005,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-6c0f0662-1d3e-4ec0-a86c-880f17c25d76,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-1ab2c146-2629-4a67-974f-90f43b472706,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-14d8104d-8adb-4892-97d4-100ba995e2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-82e4d752-4a38-4d3e-bb81-87b249ac7af3,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-b840bd3d-6007-4c97-883b-331a28112da5,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-ff1a363b-d02c-47f7-9b83-05c3c031a2a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1868191617-172.17.0.16-1597742347131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46286,DS-b6103a56-9194-4ca2-9327-a21fc57befdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-32cd3fa5-3284-4183-b9a1-819c96df6005,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-6c0f0662-1d3e-4ec0-a86c-880f17c25d76,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-1ab2c146-2629-4a67-974f-90f43b472706,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-14d8104d-8adb-4892-97d4-100ba995e2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-82e4d752-4a38-4d3e-bb81-87b249ac7af3,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-b840bd3d-6007-4c97-883b-331a28112da5,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-ff1a363b-d02c-47f7-9b83-05c3c031a2a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1201601022-172.17.0.16-1597742391124:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46358,DS-8b9f36bc-257f-407d-be99-b35db229a1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-18aa79b2-f699-4597-8cc3-b6044aaa62f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-1474dfad-c2dc-4259-8e1b-134898e7d7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35936,DS-02dacf27-913a-4e3d-b1fc-e95cbb8638ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-7bbcbfc8-66bf-418f-9d0a-b56e6fe38d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-b6847027-b3aa-4e0b-95ab-d057a1cbd396,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-48487111-96f9-48b5-bc2b-66bebf0a5b42,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-1906eabe-0710-4e07-98bb-6e6c25e1ab59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1201601022-172.17.0.16-1597742391124:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46358,DS-8b9f36bc-257f-407d-be99-b35db229a1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-18aa79b2-f699-4597-8cc3-b6044aaa62f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-1474dfad-c2dc-4259-8e1b-134898e7d7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35936,DS-02dacf27-913a-4e3d-b1fc-e95cbb8638ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-7bbcbfc8-66bf-418f-9d0a-b56e6fe38d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-b6847027-b3aa-4e0b-95ab-d057a1cbd396,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-48487111-96f9-48b5-bc2b-66bebf0a5b42,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-1906eabe-0710-4e07-98bb-6e6c25e1ab59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1302547946-172.17.0.16-1597742491199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45063,DS-d6d621f8-4989-4a07-9bb5-33b6f589d186,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-6bbf54a6-a8b8-4f22-a327-f93fe530e668,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-77fba2a4-9579-4216-9732-c86be6e8fcd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-0855c982-d0de-4493-815d-3fdea7e3f55b,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-4be97e0d-4c21-4478-938f-8742ac7b1a30,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-62d0fa47-c777-47ad-9f59-d14b9068f050,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-972496fb-aaec-4493-ab2d-9fcd69e633e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-04775eec-7f72-422a-8234-e28447214ae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1302547946-172.17.0.16-1597742491199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45063,DS-d6d621f8-4989-4a07-9bb5-33b6f589d186,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-6bbf54a6-a8b8-4f22-a327-f93fe530e668,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-77fba2a4-9579-4216-9732-c86be6e8fcd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-0855c982-d0de-4493-815d-3fdea7e3f55b,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-4be97e0d-4c21-4478-938f-8742ac7b1a30,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-62d0fa47-c777-47ad-9f59-d14b9068f050,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-972496fb-aaec-4493-ab2d-9fcd69e633e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-04775eec-7f72-422a-8234-e28447214ae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-40867960-172.17.0.16-1597742532640:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34831,DS-f0e69c79-8c2c-4fea-88eb-45b7336abb50,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-09a9f6bb-19fe-45c2-b2ea-7c74022df363,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-7a44bc4b-e615-429b-98c8-4b2c16ebd2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-59250f65-ee16-4503-804b-1fd996110055,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-f2559408-f79d-4627-aeb4-4e2e59474514,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-12c495f7-6c00-4360-b36d-b0825e6d1427,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-2737f7b4-c061-4a92-8dc0-989c325f2391,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-e9b71cf7-23d6-45d1-be1b-d9a761197848,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-40867960-172.17.0.16-1597742532640:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34831,DS-f0e69c79-8c2c-4fea-88eb-45b7336abb50,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-09a9f6bb-19fe-45c2-b2ea-7c74022df363,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-7a44bc4b-e615-429b-98c8-4b2c16ebd2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-59250f65-ee16-4503-804b-1fd996110055,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-f2559408-f79d-4627-aeb4-4e2e59474514,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-12c495f7-6c00-4360-b36d-b0825e6d1427,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-2737f7b4-c061-4a92-8dc0-989c325f2391,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-e9b71cf7-23d6-45d1-be1b-d9a761197848,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-75441011-172.17.0.16-1597742789191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38840,DS-dec8d746-618c-4227-b12c-806a2969e46c,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-22752691-9d27-441f-9291-efde76d8bf9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-8b67b789-1823-4606-a241-6b5ea3fc8059,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-b58d34a5-4370-48da-9b39-083c683bb3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-89ba5434-7463-474e-b8a8-aa939f21979d,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-87eb86f8-15b1-4538-8c5c-0853c84fa9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-0021e05d-e2f7-4f21-b114-0d5189cd0807,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-261f802c-a378-4ef4-afde-542fbd5afbfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-75441011-172.17.0.16-1597742789191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38840,DS-dec8d746-618c-4227-b12c-806a2969e46c,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-22752691-9d27-441f-9291-efde76d8bf9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-8b67b789-1823-4606-a241-6b5ea3fc8059,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-b58d34a5-4370-48da-9b39-083c683bb3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-89ba5434-7463-474e-b8a8-aa939f21979d,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-87eb86f8-15b1-4538-8c5c-0853c84fa9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-0021e05d-e2f7-4f21-b114-0d5189cd0807,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-261f802c-a378-4ef4-afde-542fbd5afbfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1488400866-172.17.0.16-1597743634386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45159,DS-6d477648-fcab-4f46-9df7-702d5548662e,DISK], DatanodeInfoWithStorage[127.0.0.1:38139,DS-4bc2a1b8-4017-47a8-ae6c-c56a8b29e418,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-a10bd460-1807-4e22-adbc-5398e967aa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-aef1e4d3-c93f-4ead-b86d-ce4a3432b3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-d697fc20-26d8-4815-97ea-1f66041d75a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-c9f7d553-a762-45fd-8060-6156d4c94d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35146,DS-34defa73-b909-4bd0-b1fd-8255ca566f08,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-79dc4b30-c7c8-47ab-9353-4d8907e719e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1488400866-172.17.0.16-1597743634386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45159,DS-6d477648-fcab-4f46-9df7-702d5548662e,DISK], DatanodeInfoWithStorage[127.0.0.1:38139,DS-4bc2a1b8-4017-47a8-ae6c-c56a8b29e418,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-a10bd460-1807-4e22-adbc-5398e967aa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-aef1e4d3-c93f-4ead-b86d-ce4a3432b3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-d697fc20-26d8-4815-97ea-1f66041d75a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-c9f7d553-a762-45fd-8060-6156d4c94d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35146,DS-34defa73-b909-4bd0-b1fd-8255ca566f08,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-79dc4b30-c7c8-47ab-9353-4d8907e719e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 30s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-343400527-172.17.0.16-1597743675278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37348,DS-5c86c48d-f209-49e9-ac95-9f795667666a,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-5c62e963-d965-4945-a7e9-011fdf7c2645,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-cb44fba2-079d-44f4-8b2a-a9085783b868,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-923178a4-dfec-4340-9bff-305654628378,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-3dc0916d-e345-4a3a-b8fe-da319b0fae73,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-a922b74e-2e63-49f1-b6d1-f18dbd33aacf,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-6dccb5b8-1a49-4beb-9456-20ae42ae1b54,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-dfbf0c22-bb88-445a-a238-38f678ab89f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-343400527-172.17.0.16-1597743675278:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37348,DS-5c86c48d-f209-49e9-ac95-9f795667666a,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-5c62e963-d965-4945-a7e9-011fdf7c2645,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-cb44fba2-079d-44f4-8b2a-a9085783b868,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-923178a4-dfec-4340-9bff-305654628378,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-3dc0916d-e345-4a3a-b8fe-da319b0fae73,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-a922b74e-2e63-49f1-b6d1-f18dbd33aacf,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-6dccb5b8-1a49-4beb-9456-20ae42ae1b54,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-dfbf0c22-bb88-445a-a238-38f678ab89f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5505
