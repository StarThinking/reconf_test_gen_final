reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523535531-172.17.0.13-1597654335277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39974,DS-462dfba4-a49f-4bbf-9c2c-5401576f1139,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-73860c4d-0785-42f1-8db3-73e09162fb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-7f6a69d4-5f65-4034-b585-a7cf9fd5213d,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-c4daae17-1045-4028-8d71-df03c9cb60f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34640,DS-7c2c90db-22bd-4129-9d46-0b64edea7883,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-63909775-0fb2-4ad8-a5ed-d150ea7dd4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-f190ca79-d959-4a76-836a-706ebe9d2e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-0eaff8b4-8197-4a0d-90b5-032764a95270,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523535531-172.17.0.13-1597654335277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39974,DS-462dfba4-a49f-4bbf-9c2c-5401576f1139,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-73860c4d-0785-42f1-8db3-73e09162fb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-7f6a69d4-5f65-4034-b585-a7cf9fd5213d,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-c4daae17-1045-4028-8d71-df03c9cb60f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34640,DS-7c2c90db-22bd-4129-9d46-0b64edea7883,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-63909775-0fb2-4ad8-a5ed-d150ea7dd4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-f190ca79-d959-4a76-836a-706ebe9d2e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-0eaff8b4-8197-4a0d-90b5-032764a95270,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-25308723-172.17.0.13-1597654375787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34951,DS-21939cfe-221d-44b2-80ea-7f7ef5923c14,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-589f350a-04b5-4743-934a-807ffee79e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-378aa726-dc08-40c4-8524-2a3414221032,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-50a95eba-0560-4c60-afbc-2009c967ea95,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-261f2bad-6214-4f29-8651-07d77093555e,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-b6359b85-8061-4193-b618-5f44a13015ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-b51be59d-0df8-4f33-9cb0-72adcc383ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-a06799a6-8d0f-4a7b-a612-1aa5ec71950b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-25308723-172.17.0.13-1597654375787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34951,DS-21939cfe-221d-44b2-80ea-7f7ef5923c14,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-589f350a-04b5-4743-934a-807ffee79e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-378aa726-dc08-40c4-8524-2a3414221032,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-50a95eba-0560-4c60-afbc-2009c967ea95,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-261f2bad-6214-4f29-8651-07d77093555e,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-b6359b85-8061-4193-b618-5f44a13015ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-b51be59d-0df8-4f33-9cb0-72adcc383ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-a06799a6-8d0f-4a7b-a612-1aa5ec71950b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1981612-172.17.0.13-1597654687473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42063,DS-35f7964b-1235-4032-9678-f12653b277aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-ae93972e-f080-42f3-b174-4ae536e5a8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-e71fb38d-9239-4fb2-9e41-12a96f7db6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-390f2b41-d0d2-4d4e-88bd-b41bace8b9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-93990245-1113-4701-965c-593a20136b96,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-cdc9aff2-06a4-40c3-9b57-eeda7c2b3ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-a868772f-967b-4ed3-b0b2-4961fd8b6aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-c4a0f915-bde2-4d14-991a-cb6a8e3ef63c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1981612-172.17.0.13-1597654687473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42063,DS-35f7964b-1235-4032-9678-f12653b277aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-ae93972e-f080-42f3-b174-4ae536e5a8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-e71fb38d-9239-4fb2-9e41-12a96f7db6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-390f2b41-d0d2-4d4e-88bd-b41bace8b9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-93990245-1113-4701-965c-593a20136b96,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-cdc9aff2-06a4-40c3-9b57-eeda7c2b3ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-a868772f-967b-4ed3-b0b2-4961fd8b6aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-c4a0f915-bde2-4d14-991a-cb6a8e3ef63c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1149569514-172.17.0.13-1597654728126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42616,DS-e6d43d4f-d8ac-43db-a278-f99893c49a69,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-67ea2ea9-11f1-4bf7-a894-bae927649bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-4dae4f47-5478-46d5-930d-9119cb24b4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-29e35b7b-35af-4e30-8c1a-e44cd0030ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-867f2f39-75fb-4b89-9a6a-347936f0f807,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-05d67954-0cf8-4eb8-8c5d-ab52b186fc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-799e74e0-c803-44e8-a26e-5019387f8a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-ffbf06ab-fbde-47a1-8bc4-6efc5f18b5b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1149569514-172.17.0.13-1597654728126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42616,DS-e6d43d4f-d8ac-43db-a278-f99893c49a69,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-67ea2ea9-11f1-4bf7-a894-bae927649bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-4dae4f47-5478-46d5-930d-9119cb24b4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-29e35b7b-35af-4e30-8c1a-e44cd0030ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-867f2f39-75fb-4b89-9a6a-347936f0f807,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-05d67954-0cf8-4eb8-8c5d-ab52b186fc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-799e74e0-c803-44e8-a26e-5019387f8a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-ffbf06ab-fbde-47a1-8bc4-6efc5f18b5b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-335297556-172.17.0.13-1597654828490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33637,DS-7a92cf4d-6d63-4244-9b38-220d82d659cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-2198aaec-1732-4166-b245-3d9010b64bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-9aebe39d-b84c-4f4c-b620-ff92893153ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-5f10a69a-eb92-477f-bf94-c16178b6e1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-dfa08ae1-6331-4f66-afed-faebd92f4294,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-27cb9e89-40fd-4577-9624-4b5c77838100,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-09b615ac-9c1d-458a-be0d-513c0db39323,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-f74878ba-42bc-45e8-a5be-9fc6cfec4a20,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-335297556-172.17.0.13-1597654828490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33637,DS-7a92cf4d-6d63-4244-9b38-220d82d659cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-2198aaec-1732-4166-b245-3d9010b64bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-9aebe39d-b84c-4f4c-b620-ff92893153ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-5f10a69a-eb92-477f-bf94-c16178b6e1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-dfa08ae1-6331-4f66-afed-faebd92f4294,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-27cb9e89-40fd-4577-9624-4b5c77838100,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-09b615ac-9c1d-458a-be0d-513c0db39323,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-f74878ba-42bc-45e8-a5be-9fc6cfec4a20,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1049703495-172.17.0.13-1597655031185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38478,DS-aad52908-cf74-4c26-87b8-1874509d42e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-12f56bc3-027c-4c6b-96cd-ad4a4d8bf018,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-9dadbab6-5fc6-4b86-ba48-e62e41710afc,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-5b07a86f-4404-468b-836c-634c5bceb8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-3e053074-ce15-4c9b-bfe9-62306346d6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-595324d9-54b3-499c-bda1-6abd12a0a651,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-e0e4de60-8089-4a07-aa9d-6dd16e17b91d,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-4b409b7a-c94b-446d-9fbb-a4e2194e9285,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1049703495-172.17.0.13-1597655031185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38478,DS-aad52908-cf74-4c26-87b8-1874509d42e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-12f56bc3-027c-4c6b-96cd-ad4a4d8bf018,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-9dadbab6-5fc6-4b86-ba48-e62e41710afc,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-5b07a86f-4404-468b-836c-634c5bceb8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-3e053074-ce15-4c9b-bfe9-62306346d6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-595324d9-54b3-499c-bda1-6abd12a0a651,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-e0e4de60-8089-4a07-aa9d-6dd16e17b91d,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-4b409b7a-c94b-446d-9fbb-a4e2194e9285,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-517175662-172.17.0.13-1597655223726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33922,DS-25176ae8-956e-4db4-aceb-90d9b1845304,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-b7e51057-3605-411a-a7d0-3912f1b19bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-c57be73a-717a-4a36-8dc8-cf8ace8d10fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-ca72ab6e-e6cd-4bd0-9323-e185158f2778,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-a17a9e7a-0fb1-4cf3-b54f-1b967d2911f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-0ef433fc-6944-41af-8f1f-41cb4c7ae774,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-fec2ce04-7f3e-485f-bee2-b8108edc5289,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-8c9f7b00-d397-4e69-bee8-410c167d5781,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-517175662-172.17.0.13-1597655223726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33922,DS-25176ae8-956e-4db4-aceb-90d9b1845304,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-b7e51057-3605-411a-a7d0-3912f1b19bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-c57be73a-717a-4a36-8dc8-cf8ace8d10fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-ca72ab6e-e6cd-4bd0-9323-e185158f2778,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-a17a9e7a-0fb1-4cf3-b54f-1b967d2911f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-0ef433fc-6944-41af-8f1f-41cb4c7ae774,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-fec2ce04-7f3e-485f-bee2-b8108edc5289,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-8c9f7b00-d397-4e69-bee8-410c167d5781,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-983016885-172.17.0.13-1597655578224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35008,DS-9ef508b2-decf-4ea8-8847-10cb89817397,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-f9089219-b7dc-4c5d-881f-8107d2609b30,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-3f14db0f-78ce-4b16-ab36-d3f8c5677f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-67c9c895-3fd3-43f7-9621-61221ba46822,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-b02e4a35-d5ae-4f34-a659-8dd6cce72681,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-fb333aed-7c50-43d2-87e5-443d9ad59dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-04f1c3b6-a4c1-4ad8-ab78-81efa4b8d7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-33a69716-b893-4fe3-a567-e2739f3e5762,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-983016885-172.17.0.13-1597655578224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35008,DS-9ef508b2-decf-4ea8-8847-10cb89817397,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-f9089219-b7dc-4c5d-881f-8107d2609b30,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-3f14db0f-78ce-4b16-ab36-d3f8c5677f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-67c9c895-3fd3-43f7-9621-61221ba46822,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-b02e4a35-d5ae-4f34-a659-8dd6cce72681,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-fb333aed-7c50-43d2-87e5-443d9ad59dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-04f1c3b6-a4c1-4ad8-ab78-81efa4b8d7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-33a69716-b893-4fe3-a567-e2739f3e5762,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046958766-172.17.0.13-1597655692701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40715,DS-9f4e6405-00cc-4bab-917a-20418981545e,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-66fca6ee-5abe-427d-8038-2f845f42f90b,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-6ce7eb7d-d846-4828-b9ee-32396beade6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-8661da5a-cd4c-4335-8de6-a1249e094f25,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-b773a92f-67f4-47d9-850a-2aa6d6c58b50,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-54f70770-9c92-4392-8aab-959edc2ee8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-ea7eb88b-f521-4c1f-8c53-fa4604d317ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-3fff4f83-a8b4-450d-942a-1f165e13d012,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046958766-172.17.0.13-1597655692701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40715,DS-9f4e6405-00cc-4bab-917a-20418981545e,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-66fca6ee-5abe-427d-8038-2f845f42f90b,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-6ce7eb7d-d846-4828-b9ee-32396beade6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-8661da5a-cd4c-4335-8de6-a1249e094f25,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-b773a92f-67f4-47d9-850a-2aa6d6c58b50,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-54f70770-9c92-4392-8aab-959edc2ee8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-ea7eb88b-f521-4c1f-8c53-fa4604d317ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-3fff4f83-a8b4-450d-942a-1f165e13d012,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-992667990-172.17.0.13-1597655772438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42233,DS-f204568a-0495-4063-887a-caa748a5ca92,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-038304a0-d179-4970-9dab-72456c6922ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-12951505-7fd6-41ec-b1c7-809b9d707eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-97dd7dfb-86a5-42bb-a0fa-3a06bef0f1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-1c501fc9-3963-40fe-b617-c8e2f683374b,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-4c45aefa-d3ad-49ae-9553-a640da90f937,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-1a10c756-1171-4682-a766-650734a78d09,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-22dc93c1-89c0-446f-b82d-81bdc60aebe2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-992667990-172.17.0.13-1597655772438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42233,DS-f204568a-0495-4063-887a-caa748a5ca92,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-038304a0-d179-4970-9dab-72456c6922ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-12951505-7fd6-41ec-b1c7-809b9d707eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-97dd7dfb-86a5-42bb-a0fa-3a06bef0f1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-1c501fc9-3963-40fe-b617-c8e2f683374b,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-4c45aefa-d3ad-49ae-9553-a640da90f937,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-1a10c756-1171-4682-a766-650734a78d09,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-22dc93c1-89c0-446f-b82d-81bdc60aebe2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032894189-172.17.0.13-1597655852773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40992,DS-650e44f5-069b-4634-9b79-6ec5a72556d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-09e8ee14-f5db-49be-8a99-411dd345b391,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-9544bdbb-5aee-4157-a59d-587d6a270492,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-895d77b6-6e5f-4731-9d26-58e8bc58fca5,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-a9dbb99b-dddc-4444-b12c-df0a10e90dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-3131f50d-c020-40ae-9153-2d6e28520d72,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-42fe18af-86a4-4955-a6a4-d0ff30396f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-ede43fc0-5343-4a6e-bcdd-4ac0c29b7778,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032894189-172.17.0.13-1597655852773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40992,DS-650e44f5-069b-4634-9b79-6ec5a72556d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-09e8ee14-f5db-49be-8a99-411dd345b391,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-9544bdbb-5aee-4157-a59d-587d6a270492,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-895d77b6-6e5f-4731-9d26-58e8bc58fca5,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-a9dbb99b-dddc-4444-b12c-df0a10e90dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-3131f50d-c020-40ae-9153-2d6e28520d72,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-42fe18af-86a4-4955-a6a4-d0ff30396f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-ede43fc0-5343-4a6e-bcdd-4ac0c29b7778,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20468234-172.17.0.13-1597655925050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34895,DS-28a3d387-4245-4e87-9743-5c44e3dd23a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-3781bafb-7a29-441f-ace2-c8b2b6f74d74,DISK], DatanodeInfoWithStorage[127.0.0.1:45457,DS-6a541294-72fe-4fc4-aac4-503389fae117,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-7862eb83-5faf-4f12-b18a-d30fcf4ae112,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-7632f804-3fc1-4876-b1b7-f0ef701e25da,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-2a50a289-0a2f-4f2a-bcaa-1c392bd9f708,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-9a65bb89-d6c1-4626-ade8-05ce58a38741,DISK], DatanodeInfoWithStorage[127.0.0.1:43109,DS-6b342e5a-3222-48e3-9b66-4238b904a8fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20468234-172.17.0.13-1597655925050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34895,DS-28a3d387-4245-4e87-9743-5c44e3dd23a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-3781bafb-7a29-441f-ace2-c8b2b6f74d74,DISK], DatanodeInfoWithStorage[127.0.0.1:45457,DS-6a541294-72fe-4fc4-aac4-503389fae117,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-7862eb83-5faf-4f12-b18a-d30fcf4ae112,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-7632f804-3fc1-4876-b1b7-f0ef701e25da,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-2a50a289-0a2f-4f2a-bcaa-1c392bd9f708,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-9a65bb89-d6c1-4626-ade8-05ce58a38741,DISK], DatanodeInfoWithStorage[127.0.0.1:43109,DS-6b342e5a-3222-48e3-9b66-4238b904a8fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-790392957-172.17.0.13-1597656039362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43756,DS-74ffda13-fed3-44e7-bfe5-7be1d19bb57b,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-c6d63bd0-07de-4cda-81b3-91d94d958968,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-d3e5f33b-979a-4999-ba50-51895c4a451a,DISK], DatanodeInfoWithStorage[127.0.0.1:44771,DS-eaee9085-67d1-4eba-8344-3dcc009b2562,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-f382410c-0b30-45b5-b5a4-e6b5148a5d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-1fc84ada-6da9-4b06-96d5-7f303732487a,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-306dddbf-082d-4f88-bfac-ceec2b5e15f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-c6403cf5-1089-4aaf-8d71-6b86f7c60bf0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-790392957-172.17.0.13-1597656039362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43756,DS-74ffda13-fed3-44e7-bfe5-7be1d19bb57b,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-c6d63bd0-07de-4cda-81b3-91d94d958968,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-d3e5f33b-979a-4999-ba50-51895c4a451a,DISK], DatanodeInfoWithStorage[127.0.0.1:44771,DS-eaee9085-67d1-4eba-8344-3dcc009b2562,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-f382410c-0b30-45b5-b5a4-e6b5148a5d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-1fc84ada-6da9-4b06-96d5-7f303732487a,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-306dddbf-082d-4f88-bfac-ceec2b5e15f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-c6403cf5-1089-4aaf-8d71-6b86f7c60bf0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097484219-172.17.0.13-1597656237265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35980,DS-e8489abb-68a4-4996-987f-50ae589fda0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-4e979479-0250-4c45-af77-539a66172ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-c262f2fe-c458-46d5-abeb-61bed22bc135,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-be3bc237-96fb-4e5b-8888-7f633804fde4,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-6fa00ef2-137c-4388-84d7-2d6584a35aac,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-17852619-a487-4e27-8c31-3b5c382e4655,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-908b7488-5a94-4e8c-b243-362f533ba23c,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-13532745-bae2-48cd-b155-f234d0bd526b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097484219-172.17.0.13-1597656237265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35980,DS-e8489abb-68a4-4996-987f-50ae589fda0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-4e979479-0250-4c45-af77-539a66172ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-c262f2fe-c458-46d5-abeb-61bed22bc135,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-be3bc237-96fb-4e5b-8888-7f633804fde4,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-6fa00ef2-137c-4388-84d7-2d6584a35aac,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-17852619-a487-4e27-8c31-3b5c382e4655,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-908b7488-5a94-4e8c-b243-362f533ba23c,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-13532745-bae2-48cd-b155-f234d0bd526b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1358008538-172.17.0.13-1597656372028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46827,DS-27eaca45-0304-4604-889d-47b1029e34db,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-d762a538-819a-47ca-ac5a-1f05fd40ff15,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-1b41aeb3-b311-486c-b54c-c1199c92a44e,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-b1494086-404a-4d72-959a-10b447f3affc,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-a0a757cb-272b-42d2-b00d-f9868e7bca5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-2e849b70-6066-4a4d-8008-a551471d4879,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-c5330fb8-aad5-4e06-a582-4a5d5f76ec77,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-1baee191-6c17-4261-a09d-9cd1faba4f50,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1358008538-172.17.0.13-1597656372028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46827,DS-27eaca45-0304-4604-889d-47b1029e34db,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-d762a538-819a-47ca-ac5a-1f05fd40ff15,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-1b41aeb3-b311-486c-b54c-c1199c92a44e,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-b1494086-404a-4d72-959a-10b447f3affc,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-a0a757cb-272b-42d2-b00d-f9868e7bca5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-2e849b70-6066-4a4d-8008-a551471d4879,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-c5330fb8-aad5-4e06-a582-4a5d5f76ec77,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-1baee191-6c17-4261-a09d-9cd1faba4f50,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-992544843-172.17.0.13-1597656409032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46864,DS-8009be78-8e94-4e5a-96d2-96dc5a61577f,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-a04d0e6c-2fed-4a82-a94b-c4ac838f0b39,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-d616019a-c070-4a03-b412-3854f697b81c,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-c9145eca-3eeb-4af9-ae81-7d93f773240f,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-8ee71966-566b-4b58-b243-64261a415239,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-20c66adc-fc48-4f3c-8b11-8a3425410266,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-77637558-ee7a-4154-ab9d-90a91b13d5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-ce284b9f-9c7a-471c-9be7-1ae296072209,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-992544843-172.17.0.13-1597656409032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46864,DS-8009be78-8e94-4e5a-96d2-96dc5a61577f,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-a04d0e6c-2fed-4a82-a94b-c4ac838f0b39,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-d616019a-c070-4a03-b412-3854f697b81c,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-c9145eca-3eeb-4af9-ae81-7d93f773240f,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-8ee71966-566b-4b58-b243-64261a415239,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-20c66adc-fc48-4f3c-8b11-8a3425410266,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-77637558-ee7a-4154-ab9d-90a91b13d5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-ce284b9f-9c7a-471c-9be7-1ae296072209,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-398346706-172.17.0.13-1597656510446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38542,DS-e8f67580-e040-4770-940d-30575e837f80,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-a44e0f13-aafd-4d8b-8f61-fc005e326a17,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-4e8a3623-7ca4-4a58-bfb6-1e795e85ee5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-d35b1b2b-f921-4181-8d00-265f635ec703,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-f3a5ad05-de88-4ff3-971e-1c8ed2764500,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-96be9ad3-597f-483f-ad2a-f93a3791cc06,DISK], DatanodeInfoWithStorage[127.0.0.1:35651,DS-1d2c3e7e-3e66-4594-9fec-e3fe66afd218,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-8be88b3b-10a9-49f8-b27c-4cce5a558424,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-398346706-172.17.0.13-1597656510446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38542,DS-e8f67580-e040-4770-940d-30575e837f80,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-a44e0f13-aafd-4d8b-8f61-fc005e326a17,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-4e8a3623-7ca4-4a58-bfb6-1e795e85ee5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-d35b1b2b-f921-4181-8d00-265f635ec703,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-f3a5ad05-de88-4ff3-971e-1c8ed2764500,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-96be9ad3-597f-483f-ad2a-f93a3791cc06,DISK], DatanodeInfoWithStorage[127.0.0.1:35651,DS-1d2c3e7e-3e66-4594-9fec-e3fe66afd218,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-8be88b3b-10a9-49f8-b27c-4cce5a558424,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612298296-172.17.0.13-1597656617804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42459,DS-240d06c2-ce5c-4297-9b3a-588232d8a5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37139,DS-512b868e-a0b0-4a28-b7da-7733e7ef762c,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-aaf59243-3cff-42f8-9cee-63ddef25c135,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-4ddcfeba-ef08-4111-9e27-f061cc82e0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-224bc2db-80cb-4124-b8b5-83f6585dc88d,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-98f3eedd-1093-4934-9cd7-396e73e6b5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-f3de99fe-0158-405e-b55d-0b42160e91b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-18f3a800-9f96-490e-9a78-308cfb083e82,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612298296-172.17.0.13-1597656617804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42459,DS-240d06c2-ce5c-4297-9b3a-588232d8a5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37139,DS-512b868e-a0b0-4a28-b7da-7733e7ef762c,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-aaf59243-3cff-42f8-9cee-63ddef25c135,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-4ddcfeba-ef08-4111-9e27-f061cc82e0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-224bc2db-80cb-4124-b8b5-83f6585dc88d,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-98f3eedd-1093-4934-9cd7-396e73e6b5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-f3de99fe-0158-405e-b55d-0b42160e91b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-18f3a800-9f96-490e-9a78-308cfb083e82,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-737297588-172.17.0.13-1597656954524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33383,DS-78ffa630-62a2-4b49-8c9c-203c80d9132e,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-414f7b0f-beb3-4e86-aae3-eb27fee832fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-bb39fa29-edaa-4782-b8df-c5b8ade37aef,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-01cbeb09-29f6-46f5-9b15-ef2c28edcfe6,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-d7d4a902-fede-4c88-8c9f-c556ebb050fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-57b15ed1-056a-4ef8-bb28-54a8ea5a9081,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-2b13db3f-3c6a-4285-8841-d0df751aab9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-52e3686f-6535-4210-b962-df6d34bcc328,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-737297588-172.17.0.13-1597656954524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33383,DS-78ffa630-62a2-4b49-8c9c-203c80d9132e,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-414f7b0f-beb3-4e86-aae3-eb27fee832fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-bb39fa29-edaa-4782-b8df-c5b8ade37aef,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-01cbeb09-29f6-46f5-9b15-ef2c28edcfe6,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-d7d4a902-fede-4c88-8c9f-c556ebb050fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-57b15ed1-056a-4ef8-bb28-54a8ea5a9081,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-2b13db3f-3c6a-4285-8841-d0df751aab9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-52e3686f-6535-4210-b962-df6d34bcc328,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2074446889-172.17.0.13-1597656990915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37209,DS-804a6ccd-20d7-41df-a1fb-a39f2463abe8,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-ac3f35c6-3098-4a1f-bdae-25732baa6ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-233cd0c4-c201-4ec4-8f43-2ad43d413fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-91e3582a-db6c-4b44-9aee-011390830a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-e76e1943-f910-4e97-82d6-d3cd77324968,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-61a18e97-444b-4b57-b274-8c6d7a97c48a,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-83ad670c-1429-4bb6-8f9f-43296398a23a,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-5d305cdd-72bb-4a03-9935-2c8cf086643f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2074446889-172.17.0.13-1597656990915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37209,DS-804a6ccd-20d7-41df-a1fb-a39f2463abe8,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-ac3f35c6-3098-4a1f-bdae-25732baa6ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-233cd0c4-c201-4ec4-8f43-2ad43d413fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-91e3582a-db6c-4b44-9aee-011390830a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-e76e1943-f910-4e97-82d6-d3cd77324968,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-61a18e97-444b-4b57-b274-8c6d7a97c48a,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-83ad670c-1429-4bb6-8f9f-43296398a23a,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-5d305cdd-72bb-4a03-9935-2c8cf086643f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-495518528-172.17.0.13-1597657026391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41726,DS-8b105fd4-d51d-4915-8871-2977cb61258a,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-bddec4a2-253d-4467-a6b6-ce5cfbba362d,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-c23c6511-2af7-4fa5-8c89-fad6f99fd558,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-fc866638-2e2a-4253-9c10-d2a43a38d025,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-b5457ff1-7d18-4403-8262-630165ec6108,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-07e454ee-2694-4472-8b30-486489bbc61d,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-7338dabb-a0d7-4491-88e4-24349f4ebf90,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-c67d2971-985c-46f4-a4d9-e6b9d6bb1e7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-495518528-172.17.0.13-1597657026391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41726,DS-8b105fd4-d51d-4915-8871-2977cb61258a,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-bddec4a2-253d-4467-a6b6-ce5cfbba362d,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-c23c6511-2af7-4fa5-8c89-fad6f99fd558,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-fc866638-2e2a-4253-9c10-d2a43a38d025,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-b5457ff1-7d18-4403-8262-630165ec6108,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-07e454ee-2694-4472-8b30-486489bbc61d,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-7338dabb-a0d7-4491-88e4-24349f4ebf90,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-c67d2971-985c-46f4-a4d9-e6b9d6bb1e7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891208509-172.17.0.13-1597657070132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46693,DS-1c992ba2-fa59-4a1a-824f-07128a805db3,DISK], DatanodeInfoWithStorage[127.0.0.1:46235,DS-a17490cd-e3c5-4afc-a035-7abae83344f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40574,DS-699d2979-18ef-454e-8b39-40d3c0b3016b,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-859545d4-8500-41bd-b195-44e912197e86,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-28375bbb-41b0-4ee4-9923-1c8a4d847dac,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-ddb9de0f-a63c-41d8-ae6a-7d8b340030a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-c2cc3709-c5dd-47b4-aedc-adbf39c6a922,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-e992a613-806a-4ed5-9385-d13cbb2d024f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891208509-172.17.0.13-1597657070132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46693,DS-1c992ba2-fa59-4a1a-824f-07128a805db3,DISK], DatanodeInfoWithStorage[127.0.0.1:46235,DS-a17490cd-e3c5-4afc-a035-7abae83344f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40574,DS-699d2979-18ef-454e-8b39-40d3c0b3016b,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-859545d4-8500-41bd-b195-44e912197e86,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-28375bbb-41b0-4ee4-9923-1c8a4d847dac,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-ddb9de0f-a63c-41d8-ae6a-7d8b340030a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-c2cc3709-c5dd-47b4-aedc-adbf39c6a922,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-e992a613-806a-4ed5-9385-d13cbb2d024f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2066982754-172.17.0.13-1597657328299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44333,DS-0b03abda-df78-4110-a911-327f93541722,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-8a0eace8-4ae3-4247-a5f5-a60e654cea26,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-cccf569e-740f-41f6-904a-e84287855285,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-aa5ae69c-047e-4b6f-86e4-277e882593f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-ce064b50-bda6-4b9b-b948-145a5c8a61f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35823,DS-98a148ae-3840-4f23-a038-3ea7f91708b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-36e33395-4b42-46b1-ada8-8d0df395fc61,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-a110be3c-818f-489e-94f1-175338cb812b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2066982754-172.17.0.13-1597657328299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44333,DS-0b03abda-df78-4110-a911-327f93541722,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-8a0eace8-4ae3-4247-a5f5-a60e654cea26,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-cccf569e-740f-41f6-904a-e84287855285,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-aa5ae69c-047e-4b6f-86e4-277e882593f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-ce064b50-bda6-4b9b-b948-145a5c8a61f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35823,DS-98a148ae-3840-4f23-a038-3ea7f91708b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-36e33395-4b42-46b1-ada8-8d0df395fc61,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-a110be3c-818f-489e-94f1-175338cb812b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1941402122-172.17.0.13-1597657361184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34231,DS-da3a44bb-d8bd-4c37-9dc3-fd5bc8df3f96,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-ac4237cf-58e7-4c95-9820-b958e33b1f80,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-87b54466-1395-4f4d-b366-e89ce9f17a49,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-18d241db-7cc0-4a3d-9a1c-47ef64815542,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-f182b2ab-67b6-49a3-8bfe-656b571cf9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-e32b9f0e-1a10-4fdc-b6c9-67755a24601d,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-954e85cf-6f34-462b-968a-c1785ea191f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-2d4cc7c0-4081-4333-a8d5-c238bb3e743a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1941402122-172.17.0.13-1597657361184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34231,DS-da3a44bb-d8bd-4c37-9dc3-fd5bc8df3f96,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-ac4237cf-58e7-4c95-9820-b958e33b1f80,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-87b54466-1395-4f4d-b366-e89ce9f17a49,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-18d241db-7cc0-4a3d-9a1c-47ef64815542,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-f182b2ab-67b6-49a3-8bfe-656b571cf9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-e32b9f0e-1a10-4fdc-b6c9-67755a24601d,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-954e85cf-6f34-462b-968a-c1785ea191f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-2d4cc7c0-4081-4333-a8d5-c238bb3e743a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1769161320-172.17.0.13-1597657485743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46568,DS-def29aed-70fc-41b2-833d-f6dacd002b53,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-2e872e5d-cc53-4859-84d3-57d89f374038,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-c7f26ef4-998e-451d-b8d5-4d81acaf695c,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-38975221-7342-4a84-ba93-10957b80473e,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-8c177588-d903-45b5-abb5-cd15ce1d4a36,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-0f5facc8-f9cc-4f9f-8069-7c01542c5920,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-faa92631-fd8b-4c7e-8550-1065804293ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-94f6d777-fe93-4932-a90b-90e1215033c1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1769161320-172.17.0.13-1597657485743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46568,DS-def29aed-70fc-41b2-833d-f6dacd002b53,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-2e872e5d-cc53-4859-84d3-57d89f374038,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-c7f26ef4-998e-451d-b8d5-4d81acaf695c,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-38975221-7342-4a84-ba93-10957b80473e,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-8c177588-d903-45b5-abb5-cd15ce1d4a36,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-0f5facc8-f9cc-4f9f-8069-7c01542c5920,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-faa92631-fd8b-4c7e-8550-1065804293ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-94f6d777-fe93-4932-a90b-90e1215033c1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-208105143-172.17.0.13-1597657638741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38166,DS-60df59c9-7602-4463-b82c-efa7da5ef632,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-b35400a7-b74c-462e-a568-7c5528e4b446,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-450dd065-dfb2-4a8b-bfdd-4e8af9dae0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-75b37148-2c2a-42bd-a16d-a609a7618325,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-7f342c91-4137-44ad-b931-e6e30c9f3a38,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-95a4d810-3e53-4086-af28-30188877b095,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-34947fbc-9049-4a30-bdcf-77626e425e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-d940dd2e-7d82-43d0-bfc8-8ab054c5328f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-208105143-172.17.0.13-1597657638741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38166,DS-60df59c9-7602-4463-b82c-efa7da5ef632,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-b35400a7-b74c-462e-a568-7c5528e4b446,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-450dd065-dfb2-4a8b-bfdd-4e8af9dae0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-75b37148-2c2a-42bd-a16d-a609a7618325,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-7f342c91-4137-44ad-b931-e6e30c9f3a38,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-95a4d810-3e53-4086-af28-30188877b095,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-34947fbc-9049-4a30-bdcf-77626e425e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-d940dd2e-7d82-43d0-bfc8-8ab054c5328f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022155174-172.17.0.13-1597657721652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33423,DS-59383b33-b672-4660-8ec6-5d51f8388a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-170002d1-3ddc-4e07-a42e-f5ef60fbff0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-5a680fbd-c107-4eda-b2e4-cc72b667be40,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-250e456f-b056-45f6-961e-a593ae29ac50,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-e81d5c96-f9db-4f92-aee3-10515b33aebb,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-a925d34d-39c4-4b42-801d-a74343cbd040,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-6904e067-8e4d-48eb-8211-3d9c7b20abd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-42b8dc75-f785-4c67-8080-7d42f3f4d930,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022155174-172.17.0.13-1597657721652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33423,DS-59383b33-b672-4660-8ec6-5d51f8388a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-170002d1-3ddc-4e07-a42e-f5ef60fbff0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-5a680fbd-c107-4eda-b2e4-cc72b667be40,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-250e456f-b056-45f6-961e-a593ae29ac50,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-e81d5c96-f9db-4f92-aee3-10515b33aebb,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-a925d34d-39c4-4b42-801d-a74343cbd040,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-6904e067-8e4d-48eb-8211-3d9c7b20abd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-42b8dc75-f785-4c67-8080-7d42f3f4d930,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-907982087-172.17.0.13-1597657920309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34515,DS-4cfaae5a-b27b-46ff-8c13-3ccb9c0b61c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-a0518de1-5fba-41ab-8add-994235501758,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-b707fb30-b63b-499c-b28f-97c7ddb5f50c,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-4447fde6-73f7-4bd3-9240-38e4e71e218f,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-73e83adf-79ae-4a60-b322-3f8663f2f386,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-e7cf7d44-bb40-4e74-905a-b29882b35ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-cd8ea701-2da1-448e-ae33-a2b662c523e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-13e3fc1b-d648-42e6-8fbc-e2681f5a9423,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-907982087-172.17.0.13-1597657920309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34515,DS-4cfaae5a-b27b-46ff-8c13-3ccb9c0b61c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-a0518de1-5fba-41ab-8add-994235501758,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-b707fb30-b63b-499c-b28f-97c7ddb5f50c,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-4447fde6-73f7-4bd3-9240-38e4e71e218f,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-73e83adf-79ae-4a60-b322-3f8663f2f386,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-e7cf7d44-bb40-4e74-905a-b29882b35ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-cd8ea701-2da1-448e-ae33-a2b662c523e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-13e3fc1b-d648-42e6-8fbc-e2681f5a9423,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1497155556-172.17.0.13-1597658105387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36118,DS-d7341377-6df4-4b42-925b-284f43a30a56,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-586a3c8b-819f-4394-80b0-692c9be0ebba,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-c7b83bef-4ce3-402e-8d33-541913d9d3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-2a04c408-cc3b-48c3-9ff0-90d731dfe454,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-774de588-0289-4d23-b4ac-dd91c7b9e2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-72b485c7-363a-4efa-9de6-58c350abb6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-394acabf-27cd-44ff-8c68-b01acf16cfb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-5a1aa9cc-e2d7-4df6-a45c-f834fed6492e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1497155556-172.17.0.13-1597658105387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36118,DS-d7341377-6df4-4b42-925b-284f43a30a56,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-586a3c8b-819f-4394-80b0-692c9be0ebba,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-c7b83bef-4ce3-402e-8d33-541913d9d3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-2a04c408-cc3b-48c3-9ff0-90d731dfe454,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-774de588-0289-4d23-b4ac-dd91c7b9e2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-72b485c7-363a-4efa-9de6-58c350abb6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-394acabf-27cd-44ff-8c68-b01acf16cfb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-5a1aa9cc-e2d7-4df6-a45c-f834fed6492e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1132033529-172.17.0.13-1597658151184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38360,DS-b44727d4-280e-4760-a597-788e366db937,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-894f66dd-8861-401d-9718-8148babefdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-bb97c121-2e0e-48a7-8de3-5dff6d2c507f,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-7eb666d6-8517-4a16-987b-720f1cab8e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-e94d14e6-2dff-4cd2-9077-f923a0013fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-fffb4934-79b1-4829-99f8-46543753a81d,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-d1ebd4f9-c87c-43b4-ab72-cdc299436ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-d75e6bd6-15a1-4748-a50d-5ed6489f30d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1132033529-172.17.0.13-1597658151184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38360,DS-b44727d4-280e-4760-a597-788e366db937,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-894f66dd-8861-401d-9718-8148babefdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-bb97c121-2e0e-48a7-8de3-5dff6d2c507f,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-7eb666d6-8517-4a16-987b-720f1cab8e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-e94d14e6-2dff-4cd2-9077-f923a0013fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-fffb4934-79b1-4829-99f8-46543753a81d,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-d1ebd4f9-c87c-43b4-ab72-cdc299436ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-d75e6bd6-15a1-4748-a50d-5ed6489f30d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1859563010-172.17.0.13-1597658267490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35426,DS-b744634c-d8c0-4d9c-b116-e762a1e73862,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-0dfef7e7-b777-4c0b-933a-efadfd819335,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-d9eb07b4-3893-454e-a148-a5a3d09484ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-22792ef1-5685-4908-a0f4-99438c2861c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-92484290-5291-4503-b83d-1be79573bc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-fd0e731d-93b0-40f3-962f-d281d0fec4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-ebd48c23-0ba6-4b21-a107-f3fb6f4af187,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-f8923a0f-193d-4b7d-a09d-3fa71093a62d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1859563010-172.17.0.13-1597658267490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35426,DS-b744634c-d8c0-4d9c-b116-e762a1e73862,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-0dfef7e7-b777-4c0b-933a-efadfd819335,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-d9eb07b4-3893-454e-a148-a5a3d09484ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-22792ef1-5685-4908-a0f4-99438c2861c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-92484290-5291-4503-b83d-1be79573bc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-fd0e731d-93b0-40f3-962f-d281d0fec4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-ebd48c23-0ba6-4b21-a107-f3fb6f4af187,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-f8923a0f-193d-4b7d-a09d-3fa71093a62d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1271062564-172.17.0.13-1597658429396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42029,DS-2054e61c-854f-42f6-96a3-9670752eb7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-23094f4a-8f8d-453d-83c0-555e02f32530,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-eba9a9b4-5ff3-44f6-9ca9-d2d5f392faf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-e8978ddf-1367-4539-82c0-268dca3a2878,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-b2dada9d-48ef-427a-a15a-4c7293377165,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-8724ae91-02da-4576-90e1-36ea0fae5494,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-b2a14831-58ae-48ec-b5ae-f73abf2a6440,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-a85d3890-d149-44c6-9532-075338b1f95c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1271062564-172.17.0.13-1597658429396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42029,DS-2054e61c-854f-42f6-96a3-9670752eb7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-23094f4a-8f8d-453d-83c0-555e02f32530,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-eba9a9b4-5ff3-44f6-9ca9-d2d5f392faf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-e8978ddf-1367-4539-82c0-268dca3a2878,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-b2dada9d-48ef-427a-a15a-4c7293377165,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-8724ae91-02da-4576-90e1-36ea0fae5494,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-b2a14831-58ae-48ec-b5ae-f73abf2a6440,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-a85d3890-d149-44c6-9532-075338b1f95c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1076048486-172.17.0.13-1597658582921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42685,DS-ae3070e9-1718-4f98-ad77-f73a70eb586a,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-ba5454a8-91fe-42a1-b512-46117c2f54b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-ecc5fe42-ee3c-44f3-bfe9-1e7f075d5425,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-7eea8b88-6b05-494e-ae05-a929f63186f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-6fc231ab-31c8-42be-9a1d-8c612148385d,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-ec7e0675-e1b0-44d0-803d-ced9f2f9af1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-17e65d3a-3788-45f0-bfff-081371c98cde,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-d5bec116-9ade-4d72-9cbc-18f3d5ae6bfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1076048486-172.17.0.13-1597658582921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42685,DS-ae3070e9-1718-4f98-ad77-f73a70eb586a,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-ba5454a8-91fe-42a1-b512-46117c2f54b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-ecc5fe42-ee3c-44f3-bfe9-1e7f075d5425,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-7eea8b88-6b05-494e-ae05-a929f63186f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-6fc231ab-31c8-42be-9a1d-8c612148385d,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-ec7e0675-e1b0-44d0-803d-ced9f2f9af1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-17e65d3a-3788-45f0-bfff-081371c98cde,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-d5bec116-9ade-4d72-9cbc-18f3d5ae6bfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-92522031-172.17.0.13-1597658872848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34137,DS-c7fa64c7-f075-4e09-b7c8-3eeb9826d396,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-cfe65907-036b-47ca-bacd-04e6d792ae54,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-c223663a-7a5a-4f38-a429-7f8d51dc8e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-f0f18b04-ff0b-410a-883c-ce4016b7af8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-d6d47e72-2be0-47e9-a048-58e8206ee7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-6bbba872-647d-4b04-bb46-5cfc2858e18e,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-44e11df3-f5c9-4dbe-af7a-ff176eb0919f,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-135a71a4-163b-4823-8ac0-3a01217112f4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-92522031-172.17.0.13-1597658872848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34137,DS-c7fa64c7-f075-4e09-b7c8-3eeb9826d396,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-cfe65907-036b-47ca-bacd-04e6d792ae54,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-c223663a-7a5a-4f38-a429-7f8d51dc8e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-f0f18b04-ff0b-410a-883c-ce4016b7af8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-d6d47e72-2be0-47e9-a048-58e8206ee7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-6bbba872-647d-4b04-bb46-5cfc2858e18e,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-44e11df3-f5c9-4dbe-af7a-ff176eb0919f,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-135a71a4-163b-4823-8ac0-3a01217112f4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214692179-172.17.0.13-1597659141578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36428,DS-3d9bfe3e-88fd-49f2-ac99-601de14e6530,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-6a504007-4270-489c-acb9-70473a32d683,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-92fb4c92-01c8-4b41-b396-c17d5bc813ca,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-0e33f783-b248-4a25-bfeb-b98e44eebe96,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-097e57f3-beaf-4d17-b1aa-73028f58e7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-66b064e0-694e-4b7f-bee8-976898884980,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-3739a6f0-f7d6-48be-91c1-5ed41a26d462,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-7bb98de3-120b-49be-aeaa-701510136762,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214692179-172.17.0.13-1597659141578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36428,DS-3d9bfe3e-88fd-49f2-ac99-601de14e6530,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-6a504007-4270-489c-acb9-70473a32d683,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-92fb4c92-01c8-4b41-b396-c17d5bc813ca,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-0e33f783-b248-4a25-bfeb-b98e44eebe96,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-097e57f3-beaf-4d17-b1aa-73028f58e7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-66b064e0-694e-4b7f-bee8-976898884980,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-3739a6f0-f7d6-48be-91c1-5ed41a26d462,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-7bb98de3-120b-49be-aeaa-701510136762,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-411658701-172.17.0.13-1597659242752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43964,DS-a8249c59-0d19-422d-bb88-aa2d85c05038,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-0b164e94-41a5-4c74-9bfd-32d643c5b141,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-db87acbc-0957-41de-8263-d5113bd720a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-9724d316-fec5-46a2-89cc-db01abaaacd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-0fb20dbd-5f5c-4f1f-aeeb-5cfacea5b3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-c547f40f-2c63-4cec-a1b3-cab59e8553ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35295,DS-6f430f96-5610-4dd7-ad39-90d5cc965f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-ab371351-ce4c-4cae-97be-9f317b175654,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-411658701-172.17.0.13-1597659242752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43964,DS-a8249c59-0d19-422d-bb88-aa2d85c05038,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-0b164e94-41a5-4c74-9bfd-32d643c5b141,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-db87acbc-0957-41de-8263-d5113bd720a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-9724d316-fec5-46a2-89cc-db01abaaacd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-0fb20dbd-5f5c-4f1f-aeeb-5cfacea5b3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-c547f40f-2c63-4cec-a1b3-cab59e8553ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35295,DS-6f430f96-5610-4dd7-ad39-90d5cc965f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-ab371351-ce4c-4cae-97be-9f317b175654,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851850634-172.17.0.13-1597659387077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44179,DS-aa6dc428-cf8d-4395-b411-62769e95e1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-bffa4997-ffcc-419b-bb1a-f61013408126,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-7ac1bcc8-80e0-4b44-8710-e93ea3980fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-e850eafd-44cf-4bfd-a48d-47a17f2891d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-c1110240-f749-456d-8f9b-217726f25fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-eaa6cab9-b8dd-41ca-b8f8-d9319e672ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-32648ecd-7d99-46e7-8bf4-fd375beaf307,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-7b3788ed-5db2-4376-8852-5ef0655c9754,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851850634-172.17.0.13-1597659387077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44179,DS-aa6dc428-cf8d-4395-b411-62769e95e1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-bffa4997-ffcc-419b-bb1a-f61013408126,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-7ac1bcc8-80e0-4b44-8710-e93ea3980fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-e850eafd-44cf-4bfd-a48d-47a17f2891d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-c1110240-f749-456d-8f9b-217726f25fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-eaa6cab9-b8dd-41ca-b8f8-d9319e672ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-32648ecd-7d99-46e7-8bf4-fd375beaf307,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-7b3788ed-5db2-4376-8852-5ef0655c9754,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-113008718-172.17.0.13-1597659497342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43376,DS-12a8fbc4-c572-4899-b9c3-061f7632a8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-a9954cec-4210-4693-a21d-30dd39ca5630,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-6b3cfcbe-e0a2-4646-a891-7c0892f4b82e,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-9d8c0c67-c521-400c-bbd5-287b77ae464d,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-fb1afccf-7c82-4ba2-b7d0-c27185850ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-331d98a8-9dbc-4df4-87fd-17811552939a,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-e0af8fd4-3d75-4a67-8dfd-98e3c42b9435,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-bf66a960-97d0-4980-b6f9-c488b7e3295a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-113008718-172.17.0.13-1597659497342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43376,DS-12a8fbc4-c572-4899-b9c3-061f7632a8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-a9954cec-4210-4693-a21d-30dd39ca5630,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-6b3cfcbe-e0a2-4646-a891-7c0892f4b82e,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-9d8c0c67-c521-400c-bbd5-287b77ae464d,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-fb1afccf-7c82-4ba2-b7d0-c27185850ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-331d98a8-9dbc-4df4-87fd-17811552939a,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-e0af8fd4-3d75-4a67-8dfd-98e3c42b9435,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-bf66a960-97d0-4980-b6f9-c488b7e3295a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-683036237-172.17.0.13-1597659706907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36535,DS-898153a9-8b84-4471-a9f0-108a823f71d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-20b5afd9-7d12-4f3a-984b-f0e1348e9cff,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-fb2b5caa-b82a-460e-a624-7252a623d02b,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-7c16ea8a-5ef2-43bf-892b-496b2868a227,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-a09f07ea-1b78-4401-b9b1-66e2dc6a9647,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-71af0e37-49a1-473e-88dc-ec2148e5656a,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-d7a0dd3e-3650-4f92-9fc6-e3cb702840b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-fb348269-2a12-4010-b97c-dd08e62a5826,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-683036237-172.17.0.13-1597659706907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36535,DS-898153a9-8b84-4471-a9f0-108a823f71d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-20b5afd9-7d12-4f3a-984b-f0e1348e9cff,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-fb2b5caa-b82a-460e-a624-7252a623d02b,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-7c16ea8a-5ef2-43bf-892b-496b2868a227,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-a09f07ea-1b78-4401-b9b1-66e2dc6a9647,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-71af0e37-49a1-473e-88dc-ec2148e5656a,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-d7a0dd3e-3650-4f92-9fc6-e3cb702840b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-fb348269-2a12-4010-b97c-dd08e62a5826,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-917650143-172.17.0.13-1597659744508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33390,DS-7fa49de4-d708-45ee-bec9-9a871beced41,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-2dfb2027-7e0a-48dd-a901-c9ee75486799,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-160a1539-06fe-4239-9949-bc1e588a7941,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-18692b81-231f-4253-b63c-d30c0e8e0579,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-f521fd0e-e2f1-4818-8610-06ea04536175,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-567f820b-0c13-4363-a622-6f5b78ff1666,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-9c25e101-b28b-4ae0-9029-827cb8d82267,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-926c6de2-8b78-4e4d-9321-8750ee69368c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-917650143-172.17.0.13-1597659744508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33390,DS-7fa49de4-d708-45ee-bec9-9a871beced41,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-2dfb2027-7e0a-48dd-a901-c9ee75486799,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-160a1539-06fe-4239-9949-bc1e588a7941,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-18692b81-231f-4253-b63c-d30c0e8e0579,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-f521fd0e-e2f1-4818-8610-06ea04536175,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-567f820b-0c13-4363-a622-6f5b78ff1666,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-9c25e101-b28b-4ae0-9029-827cb8d82267,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-926c6de2-8b78-4e4d-9321-8750ee69368c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1492206522-172.17.0.13-1597659818129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40795,DS-93f05bc6-dd32-4406-9d0b-5313b3d29879,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-beacf5d2-179a-4c17-844e-b887e99c538c,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-d0ee67a9-ef20-473f-b29a-3ab1684ed7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-afc1cb3c-e5bd-4e26-9dea-c26b1aca896e,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-d94decff-ea3c-432e-a364-b69cd65a72b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-5a0b0da0-80a2-4c06-994d-da3e1e474c21,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-d3ee2693-6a09-47a0-86b5-4387ca90af18,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-b59838e5-8bf3-42d0-8461-e6aa8d5ae8a2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1492206522-172.17.0.13-1597659818129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40795,DS-93f05bc6-dd32-4406-9d0b-5313b3d29879,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-beacf5d2-179a-4c17-844e-b887e99c538c,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-d0ee67a9-ef20-473f-b29a-3ab1684ed7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-afc1cb3c-e5bd-4e26-9dea-c26b1aca896e,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-d94decff-ea3c-432e-a364-b69cd65a72b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-5a0b0da0-80a2-4c06-994d-da3e1e474c21,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-d3ee2693-6a09-47a0-86b5-4387ca90af18,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-b59838e5-8bf3-42d0-8461-e6aa8d5ae8a2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1958232755-172.17.0.13-1597659852582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35764,DS-afec0f82-935c-4a2b-be4c-d13dd22d9280,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-13a8a83f-b672-49f4-8ad5-4de32112efd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-1d362fc7-1007-474b-9653-3e4c8d3a6cca,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-8f5d13c1-8eb6-4f61-98b7-6fd5ce55a6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-fabb44f1-0cbc-4200-8a0a-5aa0c2a43bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-3ff346fa-2f3a-4a6e-b9b9-4d337cb984c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-9649c340-60b6-4f3b-91ac-401a77a9ae7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-d22ea80c-7efa-495c-a632-3bb50b97c975,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1958232755-172.17.0.13-1597659852582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35764,DS-afec0f82-935c-4a2b-be4c-d13dd22d9280,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-13a8a83f-b672-49f4-8ad5-4de32112efd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-1d362fc7-1007-474b-9653-3e4c8d3a6cca,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-8f5d13c1-8eb6-4f61-98b7-6fd5ce55a6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-fabb44f1-0cbc-4200-8a0a-5aa0c2a43bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-3ff346fa-2f3a-4a6e-b9b9-4d337cb984c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-9649c340-60b6-4f3b-91ac-401a77a9ae7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-d22ea80c-7efa-495c-a632-3bb50b97c975,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1702798163-172.17.0.13-1597659885478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45348,DS-13aa2b90-c977-4f2f-af8f-64a5d136c072,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-1378c28d-1682-4e5f-a35a-0b33e3c0fec6,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-1babed6d-4815-4742-962f-84449287da25,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-7febcb0c-9efb-4309-8a46-7b51823f5990,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-3e8fd196-a371-420c-857c-0f73a2a25fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-a1eb7f76-9f1d-4561-885d-3c2b42d7a6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-6cb189aa-8c73-49f5-a56e-6df65198f4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-858a1950-e488-4a5f-8dfd-165fa8f809eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1702798163-172.17.0.13-1597659885478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45348,DS-13aa2b90-c977-4f2f-af8f-64a5d136c072,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-1378c28d-1682-4e5f-a35a-0b33e3c0fec6,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-1babed6d-4815-4742-962f-84449287da25,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-7febcb0c-9efb-4309-8a46-7b51823f5990,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-3e8fd196-a371-420c-857c-0f73a2a25fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-a1eb7f76-9f1d-4561-885d-3c2b42d7a6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-6cb189aa-8c73-49f5-a56e-6df65198f4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-858a1950-e488-4a5f-8dfd-165fa8f809eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 16 out of 50
v1v1v2v2 failed with probability 21 out of 50
result: false positive !!!
Total execution time in seconds : 5709
