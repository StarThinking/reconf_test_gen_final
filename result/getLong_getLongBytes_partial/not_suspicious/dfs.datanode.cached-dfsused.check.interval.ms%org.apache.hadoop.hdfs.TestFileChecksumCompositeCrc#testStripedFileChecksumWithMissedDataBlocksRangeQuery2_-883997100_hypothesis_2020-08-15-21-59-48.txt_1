reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-143980089-172.17.0.21-1597528889987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35749,DS-fc4caa12-080e-4c60-ae9e-1462dbef1624,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-1ae6d7ec-96f4-40e8-81b8-cbb925458c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-82a6c3bf-397e-45c4-8cdd-040cc604b723,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-984e71bb-2a1e-4e0b-b7fb-4c8d09732f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-3be076ef-446a-458d-9c9d-b1450dc5ffe1,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-996a7391-bd32-4117-858b-43d36815ce3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-6adeb49a-f4dd-40b9-bd08-62c419d498bd,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-1e995152-1855-4244-a659-2f7c8994053f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-143980089-172.17.0.21-1597528889987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35749,DS-fc4caa12-080e-4c60-ae9e-1462dbef1624,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-1ae6d7ec-96f4-40e8-81b8-cbb925458c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-82a6c3bf-397e-45c4-8cdd-040cc604b723,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-984e71bb-2a1e-4e0b-b7fb-4c8d09732f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-3be076ef-446a-458d-9c9d-b1450dc5ffe1,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-996a7391-bd32-4117-858b-43d36815ce3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-6adeb49a-f4dd-40b9-bd08-62c419d498bd,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-1e995152-1855-4244-a659-2f7c8994053f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-508002864-172.17.0.21-1597529128982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39698,DS-b854c774-e725-4540-b8f6-bf3a4ba1baaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-5350a809-ccbb-4ed7-a4a0-b68d78fe6524,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-bba3c8da-fc37-44de-8e85-78b952dc4fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-43ec5658-297b-40cc-8585-8e2dd54db93f,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-7ad7ea23-9f0b-4fe9-9937-b637fbef61fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-e801a12c-67cc-49e0-a3aa-6df69f87a89d,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-ff0bff6a-51be-48ed-b42f-71d42d0571b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-34039edf-8c42-4128-a493-57c2c69e71d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-508002864-172.17.0.21-1597529128982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39698,DS-b854c774-e725-4540-b8f6-bf3a4ba1baaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-5350a809-ccbb-4ed7-a4a0-b68d78fe6524,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-bba3c8da-fc37-44de-8e85-78b952dc4fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-43ec5658-297b-40cc-8585-8e2dd54db93f,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-7ad7ea23-9f0b-4fe9-9937-b637fbef61fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-e801a12c-67cc-49e0-a3aa-6df69f87a89d,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-ff0bff6a-51be-48ed-b42f-71d42d0571b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-34039edf-8c42-4128-a493-57c2c69e71d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-972373971-172.17.0.21-1597529164395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39598,DS-c67493f2-1e29-46c5-ad2c-7dd154d2b3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-f13098c6-f042-46a3-8f44-cc865e260310,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-84057db5-c8df-4cb7-b8f4-cf498e189f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-7b1d6255-9a5e-45d5-b69d-6302747230e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-bd68ba2a-b231-418e-9b4e-df7c215b3e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-bb790a01-64ec-48d4-8940-92bb05cde291,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-bb6d7b81-06a7-49a0-8371-d2f8b8521de4,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-04df9b83-2ee0-4162-a27c-1ce4ec7fd388,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-972373971-172.17.0.21-1597529164395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39598,DS-c67493f2-1e29-46c5-ad2c-7dd154d2b3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36634,DS-f13098c6-f042-46a3-8f44-cc865e260310,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-84057db5-c8df-4cb7-b8f4-cf498e189f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-7b1d6255-9a5e-45d5-b69d-6302747230e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-bd68ba2a-b231-418e-9b4e-df7c215b3e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-bb790a01-64ec-48d4-8940-92bb05cde291,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-bb6d7b81-06a7-49a0-8371-d2f8b8521de4,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-04df9b83-2ee0-4162-a27c-1ce4ec7fd388,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-6403288-172.17.0.21-1597529203401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35481,DS-eab1ad0a-a4fe-4c95-9fa7-4f96262adc10,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-a470c7a3-f98c-4786-9629-aba1888ee59a,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-d6755a51-16d7-4a71-ac22-99bf118201a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-e8878519-f76d-4105-865b-e375ab5636d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-d9b51baa-f652-45bf-9055-0eac2fef3097,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-772de0a5-2d65-49fc-80d2-58cf5788f0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-c14eb240-43f7-4e3c-9d20-d0a22a8f9a44,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-77ee5d3b-6b56-4e8f-886a-44d6c091ab41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-6403288-172.17.0.21-1597529203401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35481,DS-eab1ad0a-a4fe-4c95-9fa7-4f96262adc10,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-a470c7a3-f98c-4786-9629-aba1888ee59a,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-d6755a51-16d7-4a71-ac22-99bf118201a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-e8878519-f76d-4105-865b-e375ab5636d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-d9b51baa-f652-45bf-9055-0eac2fef3097,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-772de0a5-2d65-49fc-80d2-58cf5788f0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-c14eb240-43f7-4e3c-9d20-d0a22a8f9a44,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-77ee5d3b-6b56-4e8f-886a-44d6c091ab41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-299714197-172.17.0.21-1597529243309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33379,DS-125e692e-64db-4f4a-aff4-9db06a0590d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-be2acbcb-1089-455f-959e-bdcd7174c9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-ca81db44-f964-4475-bb29-d1825d442519,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-3c28fbf6-7c20-42d9-9367-347252ab8c51,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-6073c13d-a5d3-4800-b056-6a495d8fdd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-7db9c99d-7697-419a-9210-91a1c49af059,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-d140c4fc-2f74-4e06-8ea3-307105373a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-cb139e83-7673-4b2f-a633-97308e384237,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-299714197-172.17.0.21-1597529243309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33379,DS-125e692e-64db-4f4a-aff4-9db06a0590d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-be2acbcb-1089-455f-959e-bdcd7174c9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-ca81db44-f964-4475-bb29-d1825d442519,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-3c28fbf6-7c20-42d9-9367-347252ab8c51,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-6073c13d-a5d3-4800-b056-6a495d8fdd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-7db9c99d-7697-419a-9210-91a1c49af059,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-d140c4fc-2f74-4e06-8ea3-307105373a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-cb139e83-7673-4b2f-a633-97308e384237,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-345857986-172.17.0.21-1597529474404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41314,DS-bec79dd2-2377-4c27-a372-a13ff12341c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-80753787-82ca-4e4e-9fde-27b6e0f04b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-9a8bf0d8-9e42-47c1-a83b-8e1bb37d46db,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-b04bc923-bef5-4db1-98bc-9e7fcab64aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-153166e6-d164-440e-9b1b-3e1140301778,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-bb363526-180e-4407-a869-9d82e1d91c45,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-3942bb81-9bb5-48e1-8d6b-19a0b9f890ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-3fc1b174-1886-46e2-9847-adb82467b6c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-345857986-172.17.0.21-1597529474404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41314,DS-bec79dd2-2377-4c27-a372-a13ff12341c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-80753787-82ca-4e4e-9fde-27b6e0f04b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-9a8bf0d8-9e42-47c1-a83b-8e1bb37d46db,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-b04bc923-bef5-4db1-98bc-9e7fcab64aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-153166e6-d164-440e-9b1b-3e1140301778,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-bb363526-180e-4407-a869-9d82e1d91c45,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-3942bb81-9bb5-48e1-8d6b-19a0b9f890ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-3fc1b174-1886-46e2-9847-adb82467b6c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1026199534-172.17.0.21-1597529922873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34791,DS-fba6b396-354d-4321-aa14-1dce3331e8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-4a35549e-adec-453a-9a7a-a858f76b6d19,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-5e9698a9-4b28-4b84-98aa-b041c337cde5,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-272c43c8-ae56-4a72-b174-8f8f4cfaf613,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-b9a072fe-126c-436f-af9f-eecf05ad4975,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-b90729ba-679f-494d-8793-a67d62ba9889,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-ac319664-8f54-48cc-b3a4-d0024533378a,DISK], DatanodeInfoWithStorage[127.0.0.1:35942,DS-4d936e3a-1ade-4c4f-937e-5105fa35fa9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1026199534-172.17.0.21-1597529922873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34791,DS-fba6b396-354d-4321-aa14-1dce3331e8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-4a35549e-adec-453a-9a7a-a858f76b6d19,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-5e9698a9-4b28-4b84-98aa-b041c337cde5,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-272c43c8-ae56-4a72-b174-8f8f4cfaf613,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-b9a072fe-126c-436f-af9f-eecf05ad4975,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-b90729ba-679f-494d-8793-a67d62ba9889,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-ac319664-8f54-48cc-b3a4-d0024533378a,DISK], DatanodeInfoWithStorage[127.0.0.1:35942,DS-4d936e3a-1ade-4c4f-937e-5105fa35fa9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-676072376-172.17.0.21-1597530429250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41232,DS-f190cd72-a826-40b0-a3eb-68329d4b5ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-c9a5d02d-b221-4591-8699-6c624f520ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-43b0ff46-0e7c-480b-aa44-62ab0d2810f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-9baa64a4-c60c-49cc-8a0c-30cbffc985c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-22032598-c80f-463f-86e0-2832e020c19a,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-6978c888-248b-45a0-a7e1-c92de75f1757,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-888ec5b9-8219-491b-91b9-9ffb31cc1162,DISK], DatanodeInfoWithStorage[127.0.0.1:38340,DS-dc3f1169-8711-4751-b936-aa4c1ea30422,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-676072376-172.17.0.21-1597530429250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41232,DS-f190cd72-a826-40b0-a3eb-68329d4b5ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-c9a5d02d-b221-4591-8699-6c624f520ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-43b0ff46-0e7c-480b-aa44-62ab0d2810f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-9baa64a4-c60c-49cc-8a0c-30cbffc985c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-22032598-c80f-463f-86e0-2832e020c19a,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-6978c888-248b-45a0-a7e1-c92de75f1757,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-888ec5b9-8219-491b-91b9-9ffb31cc1162,DISK], DatanodeInfoWithStorage[127.0.0.1:38340,DS-dc3f1169-8711-4751-b936-aa4c1ea30422,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227231994-172.17.0.21-1597530772374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38332,DS-221b6e62-d8a5-436f-9307-e6862c5b247e,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-22f46db5-8f2c-4ea3-85dd-794b7c1a7f93,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-0b468e1f-ef99-40c5-9ebb-6ff558abba8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-5a3bee5d-b2b4-41f8-a93d-d3d1f9d3530e,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-db9ca8ef-2b2d-4f55-b361-eba856d084ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-715f7f83-5e09-4b23-9639-279131a33d88,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-e88d57b8-de2e-482b-9953-82e92e1255c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-5692185b-b7a5-44b7-a98f-c60ec217d5a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227231994-172.17.0.21-1597530772374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38332,DS-221b6e62-d8a5-436f-9307-e6862c5b247e,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-22f46db5-8f2c-4ea3-85dd-794b7c1a7f93,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-0b468e1f-ef99-40c5-9ebb-6ff558abba8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-5a3bee5d-b2b4-41f8-a93d-d3d1f9d3530e,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-db9ca8ef-2b2d-4f55-b361-eba856d084ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-715f7f83-5e09-4b23-9639-279131a33d88,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-e88d57b8-de2e-482b-9953-82e92e1255c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-5692185b-b7a5-44b7-a98f-c60ec217d5a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102365597-172.17.0.21-1597531033023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34144,DS-937dcfd0-f5b1-47a1-ba1e-e8c3b4e3b6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-55b2d617-3919-4e43-8850-96e5ef634f51,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-303861e8-6934-4654-b1a1-b78e13d977da,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-a27ba5ec-3a33-44d7-8a77-09e6b2e77abe,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-30033a4b-6796-428b-ab47-25be14c4ab31,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-b6d4dec0-37fb-426c-925a-4baf54478441,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-37dda8e8-59a2-4c1a-bc2d-2e5458e919c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-6456f82f-0ebb-48fe-8687-fd5cdcb20386,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102365597-172.17.0.21-1597531033023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34144,DS-937dcfd0-f5b1-47a1-ba1e-e8c3b4e3b6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-55b2d617-3919-4e43-8850-96e5ef634f51,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-303861e8-6934-4654-b1a1-b78e13d977da,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-a27ba5ec-3a33-44d7-8a77-09e6b2e77abe,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-30033a4b-6796-428b-ab47-25be14c4ab31,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-b6d4dec0-37fb-426c-925a-4baf54478441,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-37dda8e8-59a2-4c1a-bc2d-2e5458e919c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-6456f82f-0ebb-48fe-8687-fd5cdcb20386,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535345013-172.17.0.21-1597531140740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43757,DS-e2118732-41c5-43df-b9e3-734d49b7c553,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-ab8cbce0-faa2-4da3-bf81-7500334ff8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-d69c9d5a-4fa7-49b0-aad2-cac3d993d6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-62d48d34-4ab2-4ecd-aca7-09671b04f88e,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-e6f172d2-3bb9-40b2-937b-1d793fb399ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-8adb5252-7791-4edb-be64-6834d53b2095,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-5da8dee6-a289-40fe-b99e-13bd8e5264b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-25a7543e-bc1e-4ac6-9057-8cc7618d9ea4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535345013-172.17.0.21-1597531140740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43757,DS-e2118732-41c5-43df-b9e3-734d49b7c553,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-ab8cbce0-faa2-4da3-bf81-7500334ff8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-d69c9d5a-4fa7-49b0-aad2-cac3d993d6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-62d48d34-4ab2-4ecd-aca7-09671b04f88e,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-e6f172d2-3bb9-40b2-937b-1d793fb399ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-8adb5252-7791-4edb-be64-6834d53b2095,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-5da8dee6-a289-40fe-b99e-13bd8e5264b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-25a7543e-bc1e-4ac6-9057-8cc7618d9ea4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-525627556-172.17.0.21-1597531762785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34768,DS-c4d3e3cb-8c39-4899-bff7-088471d1d432,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-bb46c80e-b3f4-4d54-8e0b-d6e3b80a482f,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-aec92d2c-1258-477a-aa6f-eff69fe51c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-dca74787-bfd3-484f-8b6c-9c4c84f93104,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-528f1688-4147-4246-865e-e22b8686c14f,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-e314f902-5790-4cef-9f73-bfcb905c3bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-73d48dcc-0203-479e-bcd8-737a47f3d1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-6359c1a5-2d71-4188-95b0-b0c813c10e79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-525627556-172.17.0.21-1597531762785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34768,DS-c4d3e3cb-8c39-4899-bff7-088471d1d432,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-bb46c80e-b3f4-4d54-8e0b-d6e3b80a482f,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-aec92d2c-1258-477a-aa6f-eff69fe51c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-dca74787-bfd3-484f-8b6c-9c4c84f93104,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-528f1688-4147-4246-865e-e22b8686c14f,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-e314f902-5790-4cef-9f73-bfcb905c3bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-73d48dcc-0203-479e-bcd8-737a47f3d1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-6359c1a5-2d71-4188-95b0-b0c813c10e79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1899801956-172.17.0.21-1597531845690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37069,DS-1aadbe47-700c-4329-8702-58ff7f96eadc,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-cbc8c9fc-ae98-4efa-b91a-7922ae89fd95,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-1f48fb9d-a1ab-486d-9553-f7ed28bd0603,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-d1e686b9-bb57-4642-8350-2aadbaa66218,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-8ae1deaa-2f1c-46df-a086-3e7953bb64e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-f88e5511-90b7-4c14-a0dd-f31e9fb69282,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-a1fe5c9d-4673-4712-b60e-b41f69c17f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-1f919d5d-c56e-4d22-b656-6b04aad863cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1899801956-172.17.0.21-1597531845690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37069,DS-1aadbe47-700c-4329-8702-58ff7f96eadc,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-cbc8c9fc-ae98-4efa-b91a-7922ae89fd95,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-1f48fb9d-a1ab-486d-9553-f7ed28bd0603,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-d1e686b9-bb57-4642-8350-2aadbaa66218,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-8ae1deaa-2f1c-46df-a086-3e7953bb64e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-f88e5511-90b7-4c14-a0dd-f31e9fb69282,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-a1fe5c9d-4673-4712-b60e-b41f69c17f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-1f919d5d-c56e-4d22-b656-6b04aad863cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-173158794-172.17.0.21-1597532591158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38868,DS-38a2177a-d6cd-4424-ba91-f02d0bde4769,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-e133973a-ca92-4b2b-9dc2-4805d7d4f4de,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-568f8818-b9a0-4c36-9db6-4a754427fd43,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-2c70a333-502a-4df0-9b20-c4114081f160,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-d5e248d1-d376-404b-acf8-c48caab751ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-6e35139e-89a5-43c6-93fa-48a259a7cf61,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-b02b6895-b6dc-433b-9796-46d81e2baa4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-53019d5d-bef5-4a84-ad98-1391c4666640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-173158794-172.17.0.21-1597532591158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38868,DS-38a2177a-d6cd-4424-ba91-f02d0bde4769,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-e133973a-ca92-4b2b-9dc2-4805d7d4f4de,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-568f8818-b9a0-4c36-9db6-4a754427fd43,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-2c70a333-502a-4df0-9b20-c4114081f160,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-d5e248d1-d376-404b-acf8-c48caab751ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-6e35139e-89a5-43c6-93fa-48a259a7cf61,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-b02b6895-b6dc-433b-9796-46d81e2baa4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-53019d5d-bef5-4a84-ad98-1391c4666640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306596586-172.17.0.21-1597533561425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34982,DS-5ce6e11d-5699-4122-a51d-7adccddd2e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-2f126853-4b94-442a-90a7-f05da3054a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-3e85553d-26c9-43ae-b672-09c5231901c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-caccc28d-c016-4aac-9dd5-00c83a294622,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-3a31bdec-f72c-435a-b334-e5c3b520d0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-6e503b45-4a0c-4cc8-83c4-d088986bfd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-86945570-9f93-45e3-9fab-0ab2aeaa2423,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-e0c8da26-50d1-47a3-bee1-7be3962d0355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306596586-172.17.0.21-1597533561425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34982,DS-5ce6e11d-5699-4122-a51d-7adccddd2e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-2f126853-4b94-442a-90a7-f05da3054a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-3e85553d-26c9-43ae-b672-09c5231901c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-caccc28d-c016-4aac-9dd5-00c83a294622,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-3a31bdec-f72c-435a-b334-e5c3b520d0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-6e503b45-4a0c-4cc8-83c4-d088986bfd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-86945570-9f93-45e3-9fab-0ab2aeaa2423,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-e0c8da26-50d1-47a3-bee1-7be3962d0355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650097200-172.17.0.21-1597533682832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44923,DS-b5a52550-8f3d-46a4-b5b9-7070acb24a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-8417d66e-bab8-4853-8bc7-4c798c7c14ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-05555a8e-c585-4816-ad9d-6f3d7b3a7d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-6c68c202-e20d-4ca0-995b-7c9a27ea9a48,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-f160e8c9-7f6f-4221-8c9c-f46a870cc69b,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-2aef21ca-3f07-4761-b8c3-6371329ecaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41455,DS-47cf5f91-6d8d-4a9c-be23-9f82829d1dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-6c805ff8-e0b2-47ea-a46f-158ee1a2626c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650097200-172.17.0.21-1597533682832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44923,DS-b5a52550-8f3d-46a4-b5b9-7070acb24a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-8417d66e-bab8-4853-8bc7-4c798c7c14ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-05555a8e-c585-4816-ad9d-6f3d7b3a7d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-6c68c202-e20d-4ca0-995b-7c9a27ea9a48,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-f160e8c9-7f6f-4221-8c9c-f46a870cc69b,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-2aef21ca-3f07-4761-b8c3-6371329ecaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41455,DS-47cf5f91-6d8d-4a9c-be23-9f82829d1dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-6c805ff8-e0b2-47ea-a46f-158ee1a2626c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1083476500-172.17.0.21-1597534053259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33168,DS-298e5a9a-9ce1-4759-b80b-892c350bd7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-18ac885f-19c1-4834-a902-6a19c408d445,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-93aa86be-6245-445c-8a80-6a219e75ec6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-9ed3a007-83f6-4ad1-b50a-d3e783ed1808,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-9fa3f592-6107-4291-babf-537f20aeef25,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-8e48639b-4dfa-4259-adbe-ecf2b356c233,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-e1bd5ce3-ae95-4476-83a8-25af62ef8467,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-fc5cd478-9ceb-4de2-aba3-f1d009e0ffdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1083476500-172.17.0.21-1597534053259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33168,DS-298e5a9a-9ce1-4759-b80b-892c350bd7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-18ac885f-19c1-4834-a902-6a19c408d445,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-93aa86be-6245-445c-8a80-6a219e75ec6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-9ed3a007-83f6-4ad1-b50a-d3e783ed1808,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-9fa3f592-6107-4291-babf-537f20aeef25,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-8e48639b-4dfa-4259-adbe-ecf2b356c233,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-e1bd5ce3-ae95-4476-83a8-25af62ef8467,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-fc5cd478-9ceb-4de2-aba3-f1d009e0ffdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1926626079-172.17.0.21-1597534197587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42722,DS-1260026a-00b3-4c48-819e-f1b5ebd929ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-0e2a70d3-16ff-4942-8a99-68be4da8ffad,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-1053dda5-750a-426a-b0f6-2aa598fde667,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-ebf59004-3514-49d8-ad6c-ee048edb7805,DISK], DatanodeInfoWithStorage[127.0.0.1:41964,DS-3b90a4fe-e39e-4286-96f8-5d0d41af7c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-14d3e879-af28-4ef7-ba3b-e0c3351ad084,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-c1d41497-9f17-42ae-891f-57e08624f9de,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-3532be91-8dec-4242-8905-7b0e3982e75a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1926626079-172.17.0.21-1597534197587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42722,DS-1260026a-00b3-4c48-819e-f1b5ebd929ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-0e2a70d3-16ff-4942-8a99-68be4da8ffad,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-1053dda5-750a-426a-b0f6-2aa598fde667,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-ebf59004-3514-49d8-ad6c-ee048edb7805,DISK], DatanodeInfoWithStorage[127.0.0.1:41964,DS-3b90a4fe-e39e-4286-96f8-5d0d41af7c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-14d3e879-af28-4ef7-ba3b-e0c3351ad084,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-c1d41497-9f17-42ae-891f-57e08624f9de,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-3532be91-8dec-4242-8905-7b0e3982e75a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1607718219-172.17.0.21-1597534241748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36990,DS-54d9244f-1094-49a0-a57d-80a95e27a765,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-ff8d1463-9094-4154-a75f-e60d05c64958,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-8289910b-a595-4d88-9d0e-071c2831a0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-6a98f9bd-4aae-4112-974b-027b03248bae,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-9caab484-429b-472a-a1bc-a488475e4668,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-a7c88dcb-af92-433c-950b-4645705bee35,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-f1dbf81d-7e5c-47c9-9d0d-2a04ccccc772,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-e959ac2a-74ff-485d-a3ed-f2a634ddf44f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1607718219-172.17.0.21-1597534241748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36990,DS-54d9244f-1094-49a0-a57d-80a95e27a765,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-ff8d1463-9094-4154-a75f-e60d05c64958,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-8289910b-a595-4d88-9d0e-071c2831a0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-6a98f9bd-4aae-4112-974b-027b03248bae,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-9caab484-429b-472a-a1bc-a488475e4668,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-a7c88dcb-af92-433c-950b-4645705bee35,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-f1dbf81d-7e5c-47c9-9d0d-2a04ccccc772,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-e959ac2a-74ff-485d-a3ed-f2a634ddf44f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1432306516-172.17.0.21-1597534354366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43061,DS-ac2f3ef0-ed26-4621-a874-a97a2bf50ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-12132b6c-e800-42d6-9aa8-3f568e5a6d85,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-da9dd9a6-4dc1-4713-bbe6-c208d25dd1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-d85f5f47-0f66-4c04-877d-0b75f57521c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-65438d59-c45f-4f23-b874-b75e1ba50b84,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-d7adad1e-c4eb-411d-a5f9-471520268038,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-2c25c857-e7aa-45fa-b710-aa647c302e76,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-15fb030f-fdc1-4c28-b402-be872efb4a53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1432306516-172.17.0.21-1597534354366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43061,DS-ac2f3ef0-ed26-4621-a874-a97a2bf50ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-12132b6c-e800-42d6-9aa8-3f568e5a6d85,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-da9dd9a6-4dc1-4713-bbe6-c208d25dd1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-d85f5f47-0f66-4c04-877d-0b75f57521c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-65438d59-c45f-4f23-b874-b75e1ba50b84,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-d7adad1e-c4eb-411d-a5f9-471520268038,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-2c25c857-e7aa-45fa-b710-aa647c302e76,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-15fb030f-fdc1-4c28-b402-be872efb4a53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5839
