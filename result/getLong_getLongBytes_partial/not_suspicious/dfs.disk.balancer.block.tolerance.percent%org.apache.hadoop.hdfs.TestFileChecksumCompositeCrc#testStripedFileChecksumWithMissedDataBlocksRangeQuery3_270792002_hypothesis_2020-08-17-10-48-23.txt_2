reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-752181395-172.17.0.12-1597661318302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37147,DS-8420d68b-0581-4d8c-9f4e-19929df0c8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-97652934-aae3-4965-833c-9142a2ef089a,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-34745303-1d8b-441f-a68f-8e3101076ead,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-af981e03-5097-487e-a216-fbeb340bf2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-3d50493e-999d-42d7-87c7-a9ce61d7446d,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-864138ac-c878-42fb-96c2-5569ac94a69f,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-ad4d8a5c-10be-4077-a773-d7cd691510dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-dc3534d7-3579-459b-b7b9-74b1821f7e31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-752181395-172.17.0.12-1597661318302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37147,DS-8420d68b-0581-4d8c-9f4e-19929df0c8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-97652934-aae3-4965-833c-9142a2ef089a,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-34745303-1d8b-441f-a68f-8e3101076ead,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-af981e03-5097-487e-a216-fbeb340bf2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-3d50493e-999d-42d7-87c7-a9ce61d7446d,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-864138ac-c878-42fb-96c2-5569ac94a69f,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-ad4d8a5c-10be-4077-a773-d7cd691510dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-dc3534d7-3579-459b-b7b9-74b1821f7e31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1621879297-172.17.0.12-1597662152494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39992,DS-8ba0d615-49f7-474c-baad-19e3295c8447,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-179bbab1-7abe-464b-a853-b080023cd515,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-49bd2e05-acb9-4767-af5a-ab1e98111ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-c92fde2e-98ff-4975-8abd-929f5b6863ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-e7a9196f-5932-466d-ad75-6bb430b35f89,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-fc1c8a65-5448-4a10-bdbc-18d87beeb6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-afb4018b-6135-4c3a-a6cd-18701c7c9e85,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-a078ec08-66fb-47dc-a00f-a3fc2a71f44c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1621879297-172.17.0.12-1597662152494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39992,DS-8ba0d615-49f7-474c-baad-19e3295c8447,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-179bbab1-7abe-464b-a853-b080023cd515,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-49bd2e05-acb9-4767-af5a-ab1e98111ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-c92fde2e-98ff-4975-8abd-929f5b6863ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-e7a9196f-5932-466d-ad75-6bb430b35f89,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-fc1c8a65-5448-4a10-bdbc-18d87beeb6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-afb4018b-6135-4c3a-a6cd-18701c7c9e85,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-a078ec08-66fb-47dc-a00f-a3fc2a71f44c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273234300-172.17.0.12-1597662341568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34846,DS-63b2f238-79a9-4bf5-b368-71254e23db92,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-fd9237dd-aa47-4e84-822b-8fa0610ec437,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-b14ca0db-e2bb-422a-aab9-67aed61eb013,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-4e0e7514-ee69-4504-8148-0b44c674d205,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-a78b841f-a661-40e1-a1a6-b3e15afb9795,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-858e7f27-4b3c-443f-851c-d74dcb1afcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-d81f21c6-35d2-4fae-bcf2-87290653c666,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-4d9a1fdd-8c35-4675-9bd3-ae8e9b7173df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273234300-172.17.0.12-1597662341568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34846,DS-63b2f238-79a9-4bf5-b368-71254e23db92,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-fd9237dd-aa47-4e84-822b-8fa0610ec437,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-b14ca0db-e2bb-422a-aab9-67aed61eb013,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-4e0e7514-ee69-4504-8148-0b44c674d205,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-a78b841f-a661-40e1-a1a6-b3e15afb9795,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-858e7f27-4b3c-443f-851c-d74dcb1afcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-d81f21c6-35d2-4fae-bcf2-87290653c666,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-4d9a1fdd-8c35-4675-9bd3-ae8e9b7173df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-552477578-172.17.0.12-1597662458030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44684,DS-59c0eecc-6165-40c4-8c47-56fa996229b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-5c0445f6-9221-477a-ac2f-667b2f784162,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-1d96a029-2d8b-4a72-a956-8de5bf999daa,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-f9589cbc-0758-4026-9968-39b67494da00,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-6cc239ff-6682-426e-b127-06398434f862,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-cf19ef2f-a19a-4032-b0fa-a3991dd79031,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-9e798e42-f469-4e59-b063-8ed6195c10d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-ad1faa53-eb6f-405a-b3ef-63e2a96913bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-552477578-172.17.0.12-1597662458030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44684,DS-59c0eecc-6165-40c4-8c47-56fa996229b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-5c0445f6-9221-477a-ac2f-667b2f784162,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-1d96a029-2d8b-4a72-a956-8de5bf999daa,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-f9589cbc-0758-4026-9968-39b67494da00,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-6cc239ff-6682-426e-b127-06398434f862,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-cf19ef2f-a19a-4032-b0fa-a3991dd79031,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-9e798e42-f469-4e59-b063-8ed6195c10d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-ad1faa53-eb6f-405a-b3ef-63e2a96913bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994417449-172.17.0.12-1597662505982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33227,DS-a52b057d-31ec-47b3-aa96-401505f93201,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-83bf1399-99c4-4faa-8ddd-d4df299055d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-63a249e5-c4dd-43fa-bdf0-238607d235f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-b541c387-c2f2-4415-b894-696c1ca14d56,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-ec403924-effa-4cc5-aca4-4a399f1782a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-b8f48202-3c6b-426b-babd-a587f4b0f23f,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-b508ba58-0b3d-43cb-ab53-6a9abf15a3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-31be9033-3c64-4e88-b2e5-0e1b6e2399fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994417449-172.17.0.12-1597662505982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33227,DS-a52b057d-31ec-47b3-aa96-401505f93201,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-83bf1399-99c4-4faa-8ddd-d4df299055d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-63a249e5-c4dd-43fa-bdf0-238607d235f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-b541c387-c2f2-4415-b894-696c1ca14d56,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-ec403924-effa-4cc5-aca4-4a399f1782a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-b8f48202-3c6b-426b-babd-a587f4b0f23f,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-b508ba58-0b3d-43cb-ab53-6a9abf15a3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-31be9033-3c64-4e88-b2e5-0e1b6e2399fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1093156887-172.17.0.12-1597662922551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43662,DS-7d101f0b-2d6b-47e5-ab49-3b4bb9e80cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-f34955a9-8ec6-435e-9baa-9f5a6d10e460,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-98527504-f02c-4168-857e-cfc1f513dbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:39487,DS-296e98b6-0507-4490-b8f2-24a4f1067d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-f94a1a8b-76af-4ef1-9cba-2f75ec91d61d,DISK], DatanodeInfoWithStorage[127.0.0.1:46106,DS-63d59a6f-e0f5-4ba2-a62c-68be47b1241c,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-62f8c64f-68b4-4f57-b362-369ad8e8fe93,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-25492eaa-490c-45b2-95d3-23dbe3ee11d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1093156887-172.17.0.12-1597662922551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43662,DS-7d101f0b-2d6b-47e5-ab49-3b4bb9e80cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-f34955a9-8ec6-435e-9baa-9f5a6d10e460,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-98527504-f02c-4168-857e-cfc1f513dbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:39487,DS-296e98b6-0507-4490-b8f2-24a4f1067d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-f94a1a8b-76af-4ef1-9cba-2f75ec91d61d,DISK], DatanodeInfoWithStorage[127.0.0.1:46106,DS-63d59a6f-e0f5-4ba2-a62c-68be47b1241c,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-62f8c64f-68b4-4f57-b362-369ad8e8fe93,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-25492eaa-490c-45b2-95d3-23dbe3ee11d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267002074-172.17.0.12-1597663399796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42645,DS-9040e2e6-dea6-4dea-8655-7a2a6a110a19,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-e8be82f2-9910-4e82-9420-ad9932538f08,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-94090f89-4400-4328-b978-fd67517d8f00,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-584cc7f2-df4c-422b-9bfe-c488ecea616f,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-611715e6-110f-4a2f-86b5-c377d54c73bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-920cf13f-e69a-43eb-bb52-61442b363408,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-53dbb769-d907-40fb-bf89-ccb022f62bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-1cf740e3-463c-46f5-81ee-5709a6f3a358,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267002074-172.17.0.12-1597663399796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42645,DS-9040e2e6-dea6-4dea-8655-7a2a6a110a19,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-e8be82f2-9910-4e82-9420-ad9932538f08,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-94090f89-4400-4328-b978-fd67517d8f00,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-584cc7f2-df4c-422b-9bfe-c488ecea616f,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-611715e6-110f-4a2f-86b5-c377d54c73bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-920cf13f-e69a-43eb-bb52-61442b363408,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-53dbb769-d907-40fb-bf89-ccb022f62bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-1cf740e3-463c-46f5-81ee-5709a6f3a358,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-104282901-172.17.0.12-1597663681862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33175,DS-5f802c8b-cedf-4299-8aa0-2ff4011f463f,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-75c4b201-3d5b-48a0-8387-63998cd43f06,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-97658e45-dcc0-41ec-938f-a18bdb75708c,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-db3bdbab-fc56-4ad4-998f-e1c0b44d11ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-be32970a-81c9-4bb7-8e01-e79fe4aba173,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-57047a48-2bc2-486d-aa6b-51e249244081,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-7cb50e4b-e58b-4183-9460-2266aa28b322,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-0abc0c8a-961a-4601-add9-33a037682d45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-104282901-172.17.0.12-1597663681862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33175,DS-5f802c8b-cedf-4299-8aa0-2ff4011f463f,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-75c4b201-3d5b-48a0-8387-63998cd43f06,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-97658e45-dcc0-41ec-938f-a18bdb75708c,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-db3bdbab-fc56-4ad4-998f-e1c0b44d11ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-be32970a-81c9-4bb7-8e01-e79fe4aba173,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-57047a48-2bc2-486d-aa6b-51e249244081,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-7cb50e4b-e58b-4183-9460-2266aa28b322,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-0abc0c8a-961a-4601-add9-33a037682d45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1336070201-172.17.0.12-1597663907707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42203,DS-be973cba-428a-4763-a4b5-36c453f7d761,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-e3220acd-2ab8-47e3-a00e-c8c07e1595c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-d40d4d92-2795-4629-9878-eab9928cace0,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-4b5e57cb-3bd9-4d7c-9fda-076d55e4680e,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-1c515f27-9c91-4b1f-b549-6ca7d4b71dda,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-c415f15a-b934-4872-ab7f-620ebac5768b,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-a0897228-ebce-4a51-b4f2-445f0c9915db,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-6d02d6c5-bac3-41ae-9f89-0ea1e0a60f0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1336070201-172.17.0.12-1597663907707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42203,DS-be973cba-428a-4763-a4b5-36c453f7d761,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-e3220acd-2ab8-47e3-a00e-c8c07e1595c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-d40d4d92-2795-4629-9878-eab9928cace0,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-4b5e57cb-3bd9-4d7c-9fda-076d55e4680e,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-1c515f27-9c91-4b1f-b549-6ca7d4b71dda,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-c415f15a-b934-4872-ab7f-620ebac5768b,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-a0897228-ebce-4a51-b4f2-445f0c9915db,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-6d02d6c5-bac3-41ae-9f89-0ea1e0a60f0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391536848-172.17.0.12-1597663987408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40417,DS-85e79a3b-7111-43ae-b493-c546a9342d53,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-2e299dad-a418-4b07-b077-e83dbb6dd6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-38d8bb53-94f6-40f3-a307-1143b7c5dfb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-645255cc-99ca-47fa-abf8-acd99953869f,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-1cd89cdd-588e-4867-83f1-3a0bc6f7fcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-2461eac9-0642-4b0b-bde9-674aeec2d01d,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-86fb9dbd-3cc5-4428-960a-f55ce904e22f,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-b501652d-b65a-4979-a343-ec8b179f6aff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391536848-172.17.0.12-1597663987408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40417,DS-85e79a3b-7111-43ae-b493-c546a9342d53,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-2e299dad-a418-4b07-b077-e83dbb6dd6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-38d8bb53-94f6-40f3-a307-1143b7c5dfb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-645255cc-99ca-47fa-abf8-acd99953869f,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-1cd89cdd-588e-4867-83f1-3a0bc6f7fcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-2461eac9-0642-4b0b-bde9-674aeec2d01d,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-86fb9dbd-3cc5-4428-960a-f55ce904e22f,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-b501652d-b65a-4979-a343-ec8b179f6aff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-531052179-172.17.0.12-1597664404751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35715,DS-792a1786-16c1-4542-92e0-c4372aaa50cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-63a8eee1-f00d-4d47-b6f8-01e37e321f14,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-79c4f382-08d2-4c79-bfc8-e6831bb9faa8,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-cc365f2b-70a9-4f2f-bcbf-31d9e2afa21f,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-b066b14b-6d67-484e-ace0-a4053abb722c,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-e1e0e353-c86c-48aa-bbea-d63180af98fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-cd97615d-41c3-4547-b5ab-93579f62b5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-8f25f6e5-2b19-43af-8511-037eb23ef19d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-531052179-172.17.0.12-1597664404751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35715,DS-792a1786-16c1-4542-92e0-c4372aaa50cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-63a8eee1-f00d-4d47-b6f8-01e37e321f14,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-79c4f382-08d2-4c79-bfc8-e6831bb9faa8,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-cc365f2b-70a9-4f2f-bcbf-31d9e2afa21f,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-b066b14b-6d67-484e-ace0-a4053abb722c,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-e1e0e353-c86c-48aa-bbea-d63180af98fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-cd97615d-41c3-4547-b5ab-93579f62b5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-8f25f6e5-2b19-43af-8511-037eb23ef19d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2118893096-172.17.0.12-1597665691621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42938,DS-367c0684-c00a-4828-9715-1e3d8c3bcbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-045d1614-f4ad-4ed5-9804-13a22b260b14,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-c6950dbd-8748-4b26-9b13-16cca5c425db,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-989b6df2-8dbd-4da0-8752-f7a786524526,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-cd490ac5-72c1-4d52-9cbe-117520d47bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-89416952-bf66-4f96-99ac-33d195c3497e,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-f13305ca-3d52-4ac8-9e73-87c0be2a9338,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-08683c0c-1c4a-43d5-9983-9113c3bf943f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2118893096-172.17.0.12-1597665691621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42938,DS-367c0684-c00a-4828-9715-1e3d8c3bcbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-045d1614-f4ad-4ed5-9804-13a22b260b14,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-c6950dbd-8748-4b26-9b13-16cca5c425db,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-989b6df2-8dbd-4da0-8752-f7a786524526,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-cd490ac5-72c1-4d52-9cbe-117520d47bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-89416952-bf66-4f96-99ac-33d195c3497e,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-f13305ca-3d52-4ac8-9e73-87c0be2a9338,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-08683c0c-1c4a-43d5-9983-9113c3bf943f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5611
