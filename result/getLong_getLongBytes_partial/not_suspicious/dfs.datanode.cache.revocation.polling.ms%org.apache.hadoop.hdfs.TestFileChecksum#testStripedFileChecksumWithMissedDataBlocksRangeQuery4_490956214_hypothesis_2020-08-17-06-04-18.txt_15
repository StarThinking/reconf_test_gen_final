reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772410323-172.17.0.5-1597645886735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37759,DS-506495c6-a4e9-4d91-a5c1-3e4f34bb040e,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-3ee62bb6-4a3d-4be0-89fc-832a71e8f0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-38eab259-e121-4d89-927e-24945c91a6af,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-34a35428-9859-463b-a20a-a3d0e0be9694,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-102fb93a-8580-49d5-8893-f29a41b9dabb,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-3ea5b594-04ae-4353-a0d8-bc32e50278e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-f07fb727-18e9-45c6-ae4d-a9b6c193f8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-89c041ba-df8f-4fc1-9364-ead29082b176,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772410323-172.17.0.5-1597645886735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37759,DS-506495c6-a4e9-4d91-a5c1-3e4f34bb040e,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-3ee62bb6-4a3d-4be0-89fc-832a71e8f0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-38eab259-e121-4d89-927e-24945c91a6af,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-34a35428-9859-463b-a20a-a3d0e0be9694,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-102fb93a-8580-49d5-8893-f29a41b9dabb,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-3ea5b594-04ae-4353-a0d8-bc32e50278e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-f07fb727-18e9-45c6-ae4d-a9b6c193f8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-89c041ba-df8f-4fc1-9364-ead29082b176,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1032878148-172.17.0.5-1597645931982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46273,DS-bfc591fc-fd5e-4b56-b207-658574608fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-37ae8e91-5028-4698-94df-9e9fc0cbb00d,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-e1b16b20-8018-4483-b43f-1e0d572eea23,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-978e2033-bdb8-433b-af1c-fa43a2262c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-339d8e8f-1eb4-48a7-a034-acf8e348ccb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-601ece42-0d4c-4edb-91b7-5411222ee45f,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-ce7edae3-6350-45b9-9b6a-99cf99209692,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-d5b5d266-7b16-46a5-b175-27a49baaa7f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1032878148-172.17.0.5-1597645931982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46273,DS-bfc591fc-fd5e-4b56-b207-658574608fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-37ae8e91-5028-4698-94df-9e9fc0cbb00d,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-e1b16b20-8018-4483-b43f-1e0d572eea23,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-978e2033-bdb8-433b-af1c-fa43a2262c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-339d8e8f-1eb4-48a7-a034-acf8e348ccb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-601ece42-0d4c-4edb-91b7-5411222ee45f,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-ce7edae3-6350-45b9-9b6a-99cf99209692,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-d5b5d266-7b16-46a5-b175-27a49baaa7f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246163331-172.17.0.5-1597646826581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45078,DS-884f6756-f0ea-41a7-a25f-943d9c6843a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-9de63701-745d-4c49-b61f-a23d532929c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-3a093445-2114-4ec4-a403-31725c1012de,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-3dd8368b-99d6-4ee7-bfb3-df403d73f5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-85dd2b24-64ef-4a74-a12b-2ba63a1e6d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-eff186df-4ee4-4eac-8580-f843165e5632,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-d390f7c0-bf3e-4aed-88b0-de59b2b64cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-77a2c870-3dea-467f-b5e6-611b06087e7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246163331-172.17.0.5-1597646826581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45078,DS-884f6756-f0ea-41a7-a25f-943d9c6843a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-9de63701-745d-4c49-b61f-a23d532929c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-3a093445-2114-4ec4-a403-31725c1012de,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-3dd8368b-99d6-4ee7-bfb3-df403d73f5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-85dd2b24-64ef-4a74-a12b-2ba63a1e6d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-eff186df-4ee4-4eac-8580-f843165e5632,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-d390f7c0-bf3e-4aed-88b0-de59b2b64cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-77a2c870-3dea-467f-b5e6-611b06087e7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1414307050-172.17.0.5-1597646904114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37803,DS-ad671a28-74fc-4246-aa15-e4651ab2fbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36514,DS-c2802970-32e7-4ee6-a725-9a8253a512e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-41283622-a355-4017-8847-eeef43163f27,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-53427397-390f-480a-8bd6-b325f80520e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-9065f700-e967-4970-95b9-1b628f6bba3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-2cde5857-1a68-4ea3-8b01-af4187ac3e95,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-486c5537-6f1e-4b7c-8fab-92687a370c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-0d28c852-7748-4ab3-a9c8-09075f262150,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1414307050-172.17.0.5-1597646904114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37803,DS-ad671a28-74fc-4246-aa15-e4651ab2fbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36514,DS-c2802970-32e7-4ee6-a725-9a8253a512e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-41283622-a355-4017-8847-eeef43163f27,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-53427397-390f-480a-8bd6-b325f80520e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-9065f700-e967-4970-95b9-1b628f6bba3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-2cde5857-1a68-4ea3-8b01-af4187ac3e95,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-486c5537-6f1e-4b7c-8fab-92687a370c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-0d28c852-7748-4ab3-a9c8-09075f262150,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1444855786-172.17.0.5-1597647781553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36638,DS-6a747575-1805-4aba-ac19-b15424132a50,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-44a2074d-aa7d-486b-8039-70ec50ee24cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-874fe742-3e26-476e-9700-9d3390197862,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-b1fd6502-d607-4817-91e2-6541df616c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-d1da9514-79bb-49f9-afa4-72b81f7505d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-212cbcf1-64eb-4876-9689-04a3f523fc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-c3e50f0b-3098-41ab-bf46-335e77391dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-87d3fd83-d77e-40ed-a28c-513599e556e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1444855786-172.17.0.5-1597647781553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36638,DS-6a747575-1805-4aba-ac19-b15424132a50,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-44a2074d-aa7d-486b-8039-70ec50ee24cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-874fe742-3e26-476e-9700-9d3390197862,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-b1fd6502-d607-4817-91e2-6541df616c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-d1da9514-79bb-49f9-afa4-72b81f7505d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-212cbcf1-64eb-4876-9689-04a3f523fc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-c3e50f0b-3098-41ab-bf46-335e77391dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-87d3fd83-d77e-40ed-a28c-513599e556e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700993546-172.17.0.5-1597648008110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33419,DS-ef05c50b-6ee2-48a7-a75a-a627bfee7c67,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-8fab01ff-9a62-4ac4-a740-42db1d118b48,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-9a822366-8d82-4368-b14a-3e0bf050a5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-30ebb882-0ab3-47ad-af9f-d45e78971c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-ebb89b25-6e97-4e23-97b6-a0522a828985,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-f45644a2-fdc9-4e00-8de0-97b157856d89,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-9219904a-a649-4b17-8226-124fa64bcf65,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-dd0949c9-72ce-4914-9b85-0560a08f867b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700993546-172.17.0.5-1597648008110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33419,DS-ef05c50b-6ee2-48a7-a75a-a627bfee7c67,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-8fab01ff-9a62-4ac4-a740-42db1d118b48,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-9a822366-8d82-4368-b14a-3e0bf050a5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-30ebb882-0ab3-47ad-af9f-d45e78971c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-ebb89b25-6e97-4e23-97b6-a0522a828985,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-f45644a2-fdc9-4e00-8de0-97b157856d89,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-9219904a-a649-4b17-8226-124fa64bcf65,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-dd0949c9-72ce-4914-9b85-0560a08f867b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-807579104-172.17.0.5-1597648059450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40251,DS-97976932-83b0-46e8-838e-6a9d45d442b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-3c280d87-603c-4d3a-a9e2-d48c34ced436,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-5bdda31c-9e48-476a-af65-632432db8637,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-9a0874c3-0dd2-46aa-8219-be9ce99bcff0,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-49b32746-af42-421b-8e03-e15137e75a12,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-923a83af-1e4f-4028-a54c-41c5011fd049,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-96f8d556-830d-42ba-afc9-a814b7299a66,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-63707d9a-44c1-4753-9a23-b13610ac652c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-807579104-172.17.0.5-1597648059450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40251,DS-97976932-83b0-46e8-838e-6a9d45d442b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-3c280d87-603c-4d3a-a9e2-d48c34ced436,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-5bdda31c-9e48-476a-af65-632432db8637,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-9a0874c3-0dd2-46aa-8219-be9ce99bcff0,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-49b32746-af42-421b-8e03-e15137e75a12,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-923a83af-1e4f-4028-a54c-41c5011fd049,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-96f8d556-830d-42ba-afc9-a814b7299a66,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-63707d9a-44c1-4753-9a23-b13610ac652c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1927180816-172.17.0.5-1597648410777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44624,DS-61b2a541-3691-4cc7-a0af-b01376da79e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-07388eef-94f1-408d-9581-97e8948be079,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-da442c9d-7006-4ed4-b308-7ce7e5379844,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-3387ad66-2a69-4ec1-8278-82bad86b7978,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-0ce41c7f-ce74-4368-80be-cd4d3ea63b92,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-6d19aa34-3f10-49a2-b495-a2cc7cdecdea,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-e5a52115-3695-43c0-acd1-00140eb77684,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-d8262b95-c0c6-4b3f-8df7-f88a2ed8da4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1927180816-172.17.0.5-1597648410777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44624,DS-61b2a541-3691-4cc7-a0af-b01376da79e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-07388eef-94f1-408d-9581-97e8948be079,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-da442c9d-7006-4ed4-b308-7ce7e5379844,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-3387ad66-2a69-4ec1-8278-82bad86b7978,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-0ce41c7f-ce74-4368-80be-cd4d3ea63b92,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-6d19aa34-3f10-49a2-b495-a2cc7cdecdea,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-e5a52115-3695-43c0-acd1-00140eb77684,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-d8262b95-c0c6-4b3f-8df7-f88a2ed8da4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1326569395-172.17.0.5-1597648457402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39179,DS-0b91a7fe-b353-4b29-8dc6-3516f09c4d03,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-b0d6fa4d-de5a-48a0-b573-2da3af685315,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-66155015-8e17-4c06-83b1-848d68099615,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-7da6d95d-b61d-4a43-bf75-c2c89ab084f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-6c7697df-8a9f-4ee5-9f89-2b865cbb3873,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-ddece46a-50df-403e-ae1c-767144574a59,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-002f607f-5006-47e7-a611-cad19ae311e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-55dbba50-83ec-4e2c-b621-80d461e83656,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1326569395-172.17.0.5-1597648457402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39179,DS-0b91a7fe-b353-4b29-8dc6-3516f09c4d03,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-b0d6fa4d-de5a-48a0-b573-2da3af685315,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-66155015-8e17-4c06-83b1-848d68099615,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-7da6d95d-b61d-4a43-bf75-c2c89ab084f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-6c7697df-8a9f-4ee5-9f89-2b865cbb3873,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-ddece46a-50df-403e-ae1c-767144574a59,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-002f607f-5006-47e7-a611-cad19ae311e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-55dbba50-83ec-4e2c-b621-80d461e83656,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-25041133-172.17.0.5-1597648614268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33144,DS-d6f686ac-2b74-49b4-9874-b5d2d88ea36e,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-88676ea2-1064-49eb-995d-94786864addb,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-655b4fc6-4010-44f9-911b-5e8b4a21982b,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-5586cec8-77d8-49c5-b177-5acc5dc75b35,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-c5e667f5-daf7-44ad-9a09-11d6bfd7abd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-8fc55d22-49c6-44f7-a626-c99f52372232,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-46e01f01-59ac-49a3-bb23-0035aaa29039,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-cf850f85-e8a6-410f-8e64-ae71a7d4d3eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-25041133-172.17.0.5-1597648614268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33144,DS-d6f686ac-2b74-49b4-9874-b5d2d88ea36e,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-88676ea2-1064-49eb-995d-94786864addb,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-655b4fc6-4010-44f9-911b-5e8b4a21982b,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-5586cec8-77d8-49c5-b177-5acc5dc75b35,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-c5e667f5-daf7-44ad-9a09-11d6bfd7abd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-8fc55d22-49c6-44f7-a626-c99f52372232,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-46e01f01-59ac-49a3-bb23-0035aaa29039,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-cf850f85-e8a6-410f-8e64-ae71a7d4d3eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-422059105-172.17.0.5-1597650040235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38297,DS-ae880473-432f-42da-9c96-8983b1c337c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-7b604e3c-98eb-4ff7-90d5-21061a6ae4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-06682a80-f845-4873-abe4-a6f21ab951bd,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-33af5a11-eaa1-4cf4-8b64-d49d76f722a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-6d63c5fd-5f73-4963-86a5-4d17abe8ba14,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-441aa2a9-d451-41a8-b359-ae753380d7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-494ec5fc-83d7-4cf0-b0d9-7d4761f56df8,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-19ec1ed6-4541-419d-a6b7-01afe6711c09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-422059105-172.17.0.5-1597650040235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38297,DS-ae880473-432f-42da-9c96-8983b1c337c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-7b604e3c-98eb-4ff7-90d5-21061a6ae4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-06682a80-f845-4873-abe4-a6f21ab951bd,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-33af5a11-eaa1-4cf4-8b64-d49d76f722a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-6d63c5fd-5f73-4963-86a5-4d17abe8ba14,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-441aa2a9-d451-41a8-b359-ae753380d7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-494ec5fc-83d7-4cf0-b0d9-7d4761f56df8,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-19ec1ed6-4541-419d-a6b7-01afe6711c09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1393070221-172.17.0.5-1597650136382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33267,DS-4597bf1c-f1db-4ed1-a85e-930079719b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-6454472e-ef1a-4205-ba13-b26136901b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-21a749e4-16aa-4e1a-a829-5afc1a1b1ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-735e3946-0d69-49ed-8389-0282d4e73090,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-4634686b-f11c-4875-be51-5a6e0f25bd19,DISK], DatanodeInfoWithStorage[127.0.0.1:35051,DS-b22c77b4-5d9e-4376-9834-98be06aeccac,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-8e11415c-2fd1-43d5-aeb7-4d0cebd65587,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-1c30acd2-de96-47f7-8c37-9fd80f5dbbe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1393070221-172.17.0.5-1597650136382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33267,DS-4597bf1c-f1db-4ed1-a85e-930079719b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-6454472e-ef1a-4205-ba13-b26136901b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-21a749e4-16aa-4e1a-a829-5afc1a1b1ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-735e3946-0d69-49ed-8389-0282d4e73090,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-4634686b-f11c-4875-be51-5a6e0f25bd19,DISK], DatanodeInfoWithStorage[127.0.0.1:35051,DS-b22c77b4-5d9e-4376-9834-98be06aeccac,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-8e11415c-2fd1-43d5-aeb7-4d0cebd65587,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-1c30acd2-de96-47f7-8c37-9fd80f5dbbe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-380286304-172.17.0.5-1597650843168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38688,DS-5235d523-68fd-4a55-8284-fd79f5510a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-83557f8b-9bce-443a-be08-6b09a36f5e58,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-87cc3cb8-4e86-40f4-9bf2-9bd5407e3e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-7671cf95-e2e5-4d0c-b5ea-4bdb08f079a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-ca6ca336-1b04-4566-a6a6-d251fcbb7bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-5a5f8945-575f-4f67-a1c6-b47465a1d009,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-dc94b11c-64b1-4e52-95fc-77b997ec903a,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-ac2cb95f-7f3a-4390-a3a0-74f0d1775e6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-380286304-172.17.0.5-1597650843168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38688,DS-5235d523-68fd-4a55-8284-fd79f5510a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-83557f8b-9bce-443a-be08-6b09a36f5e58,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-87cc3cb8-4e86-40f4-9bf2-9bd5407e3e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-7671cf95-e2e5-4d0c-b5ea-4bdb08f079a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-ca6ca336-1b04-4566-a6a6-d251fcbb7bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-5a5f8945-575f-4f67-a1c6-b47465a1d009,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-dc94b11c-64b1-4e52-95fc-77b997ec903a,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-ac2cb95f-7f3a-4390-a3a0-74f0d1775e6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383263140-172.17.0.5-1597651034554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36193,DS-adfda9a2-2ef1-4c29-94ae-592cbc68efc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-cdf3c372-73d7-4a51-b785-a6c373eeae58,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-91d7fd0f-ab2b-4743-8816-743f084e023d,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-bb92852b-a505-4121-afba-8dc32ceaafb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-2eaa4b4d-15cd-4d50-bde6-8e87d22c5021,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-c625fbc5-3c68-4ea2-ad97-2da62b0da618,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-c2afa15a-0a12-4a3b-9900-73bd3aea8e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-fcca06e6-b39d-47c0-b57b-9648f0505557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383263140-172.17.0.5-1597651034554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36193,DS-adfda9a2-2ef1-4c29-94ae-592cbc68efc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-cdf3c372-73d7-4a51-b785-a6c373eeae58,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-91d7fd0f-ab2b-4743-8816-743f084e023d,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-bb92852b-a505-4121-afba-8dc32ceaafb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-2eaa4b4d-15cd-4d50-bde6-8e87d22c5021,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-c625fbc5-3c68-4ea2-ad97-2da62b0da618,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-c2afa15a-0a12-4a3b-9900-73bd3aea8e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-fcca06e6-b39d-47c0-b57b-9648f0505557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 7006
