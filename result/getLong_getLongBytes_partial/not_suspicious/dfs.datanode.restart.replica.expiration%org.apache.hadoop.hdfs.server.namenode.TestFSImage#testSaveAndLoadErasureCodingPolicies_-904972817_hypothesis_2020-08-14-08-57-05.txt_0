reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestFSImage#testSaveAndLoadErasureCodingPolicies
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestFSImage#testSaveAndLoadErasureCodingPolicies
reconfPoint: -2
result: -1
failureMessage: 3 missing blocks, the stripe is: AlignedStripe(Offset=0, length=1048576, fetchedChunksNum=0, missingChunksNum=3); locatedBlocks is: LocatedBlocks{;  fileLength=50331648;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1046246524-172.17.0.14-1597398804776:blk_-9223372036854775760_1003; getBlockSize()=50331648; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38899,DS-46f7b6b0-70f3-48a3-bdb6-3f9620a55ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-c6ea52b4-b491-4686-9d20-ab6aa24ad726,DISK]]; indices=[3, 4]}];  lastLocatedBlock=LocatedStripedBlock{BP-1046246524-172.17.0.14-1597398804776:blk_-9223372036854775760_1003; getBlockSize()=50331648; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38899,DS-46f7b6b0-70f3-48a3-bdb6-3f9620a55ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-c6ea52b4-b491-4686-9d20-ab6aa24ad726,DISK]]; indices=[3, 4]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-3-2-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=3, numParityUnits=2]], CellSize=1048576, Id=2]}
stackTrace: java.io.IOException: 3 missing blocks, the stripe is: AlignedStripe(Offset=0, length=1048576, fetchedChunksNum=0, missingChunksNum=3); locatedBlocks is: LocatedBlocks{;  fileLength=50331648;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1046246524-172.17.0.14-1597398804776:blk_-9223372036854775760_1003; getBlockSize()=50331648; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38899,DS-46f7b6b0-70f3-48a3-bdb6-3f9620a55ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-c6ea52b4-b491-4686-9d20-ab6aa24ad726,DISK]]; indices=[3, 4]}];  lastLocatedBlock=LocatedStripedBlock{BP-1046246524-172.17.0.14-1597398804776:blk_-9223372036854775760_1003; getBlockSize()=50331648; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38899,DS-46f7b6b0-70f3-48a3-bdb6-3f9620a55ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-c6ea52b4-b491-4686-9d20-ab6aa24ad726,DISK]]; indices=[3, 4]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-3-2-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=3, numParityUnits=2]], CellSize=1048576, Id=2]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:338)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:326)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:419)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:829)
	at java.io.DataInputStream.read(DataInputStream.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:94)
	at org.apache.hadoop.hdfs.DFSTestUtil.readFileAsBytes(DFSTestUtil.java:372)
	at org.apache.hadoop.hdfs.server.namenode.TestFSImage.testChangeErasureCodingPolicyState(TestFSImage.java:960)
	at org.apache.hadoop.hdfs.server.namenode.TestFSImage.testSaveAndLoadErasureCodingPolicies(TestFSImage.java:892)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestFSImage#testSaveAndLoadErasureCodingPolicies
reconfPoint: -2
result: -1
failureMessage: 3 missing blocks, the stripe is: AlignedStripe(Offset=0, length=1048576, fetchedChunksNum=0, missingChunksNum=3); locatedBlocks is: LocatedBlocks{;  fileLength=50331648;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-936254935-172.17.0.14-1597398911017:blk_-9223372036854775760_1003; getBlockSize()=50331648; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46456,DS-3a34337d-a721-42ab-b79f-0ae4e6bc0e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-ba8cd1e2-b911-40db-bd28-6c06a012e0cc,DISK]]; indices=[0, 1]}];  lastLocatedBlock=LocatedStripedBlock{BP-936254935-172.17.0.14-1597398911017:blk_-9223372036854775760_1003; getBlockSize()=50331648; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46456,DS-3a34337d-a721-42ab-b79f-0ae4e6bc0e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-ba8cd1e2-b911-40db-bd28-6c06a012e0cc,DISK]]; indices=[0, 1]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-3-2-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=3, numParityUnits=2]], CellSize=1048576, Id=2]}
stackTrace: java.io.IOException: 3 missing blocks, the stripe is: AlignedStripe(Offset=0, length=1048576, fetchedChunksNum=0, missingChunksNum=3); locatedBlocks is: LocatedBlocks{;  fileLength=50331648;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-936254935-172.17.0.14-1597398911017:blk_-9223372036854775760_1003; getBlockSize()=50331648; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46456,DS-3a34337d-a721-42ab-b79f-0ae4e6bc0e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-ba8cd1e2-b911-40db-bd28-6c06a012e0cc,DISK]]; indices=[0, 1]}];  lastLocatedBlock=LocatedStripedBlock{BP-936254935-172.17.0.14-1597398911017:blk_-9223372036854775760_1003; getBlockSize()=50331648; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46456,DS-3a34337d-a721-42ab-b79f-0ae4e6bc0e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-ba8cd1e2-b911-40db-bd28-6c06a012e0cc,DISK]]; indices=[0, 1]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-3-2-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=3, numParityUnits=2]], CellSize=1048576, Id=2]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:326)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:419)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:829)
	at java.io.DataInputStream.read(DataInputStream.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:94)
	at org.apache.hadoop.hdfs.DFSTestUtil.readFileAsBytes(DFSTestUtil.java:372)
	at org.apache.hadoop.hdfs.server.namenode.TestFSImage.testChangeErasureCodingPolicyState(TestFSImage.java:932)
	at org.apache.hadoop.hdfs.server.namenode.TestFSImage.testSaveAndLoadErasureCodingPolicies(TestFSImage.java:892)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestFSImage#testSaveAndLoadErasureCodingPolicies
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=1048576, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=100663296;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-936528450-172.17.0.14-1597399239293:blk_-9223372036854775776_1002; getBlockSize()=100663296; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37192,DS-1b2484b7-032b-44ad-b145-8996598f7e79,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-ddd17801-6d07-4b85-848d-c044d76e0da1,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-214b3377-f159-4d55-922b-1e7582d1308b,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-f0e25ddd-c396-4115-818d-5fa20de92570,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-998af77b-08a7-47ca-a4f1-c76ed11ad847,DISK]]; indices=[1, 2, 3, 6, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-936528450-172.17.0.14-1597399239293:blk_-9223372036854775776_1002; getBlockSize()=100663296; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37192,DS-1b2484b7-032b-44ad-b145-8996598f7e79,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-ddd17801-6d07-4b85-848d-c044d76e0da1,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-214b3377-f159-4d55-922b-1e7582d1308b,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-f0e25ddd-c396-4115-818d-5fa20de92570,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-998af77b-08a7-47ca-a4f1-c76ed11ad847,DISK]]; indices=[1, 2, 3, 6, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=1048576, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=100663296;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-936528450-172.17.0.14-1597399239293:blk_-9223372036854775776_1002; getBlockSize()=100663296; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37192,DS-1b2484b7-032b-44ad-b145-8996598f7e79,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-ddd17801-6d07-4b85-848d-c044d76e0da1,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-214b3377-f159-4d55-922b-1e7582d1308b,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-f0e25ddd-c396-4115-818d-5fa20de92570,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-998af77b-08a7-47ca-a4f1-c76ed11ad847,DISK]]; indices=[1, 2, 3, 6, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-936528450-172.17.0.14-1597399239293:blk_-9223372036854775776_1002; getBlockSize()=100663296; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37192,DS-1b2484b7-032b-44ad-b145-8996598f7e79,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-ddd17801-6d07-4b85-848d-c044d76e0da1,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-214b3377-f159-4d55-922b-1e7582d1308b,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-f0e25ddd-c396-4115-818d-5fa20de92570,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-998af77b-08a7-47ca-a4f1-c76ed11ad847,DISK]]; indices=[1, 2, 3, 6, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:326)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:419)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:829)
	at java.io.DataInputStream.read(DataInputStream.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:94)
	at org.apache.hadoop.hdfs.DFSTestUtil.readFileAsBytes(DFSTestUtil.java:372)
	at org.apache.hadoop.hdfs.server.namenode.TestFSImage.testChangeErasureCodingPolicyState(TestFSImage.java:960)
	at org.apache.hadoop.hdfs.server.namenode.TestFSImage.testSaveAndLoadErasureCodingPolicies(TestFSImage.java:889)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestFSImage#testSaveAndLoadErasureCodingPolicies
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=1048576, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=100663296;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-347845399-172.17.0.14-1597399671769:blk_-9223372036854775776_1002; getBlockSize()=100663296; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38931,DS-4dd48b11-cffa-4640-82d3-bcb392fa8b36,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-1a2b920c-9b67-4a49-b252-7c62f21076a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-9312e098-2ea8-4be1-9053-1c82c0549e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-42563857-7c1e-4b84-aed5-a5d5b657ac87,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-e4fefd8f-7ee9-4bae-b67e-4809cff60fbe,DISK]]; indices=[2, 3, 4, 5, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-347845399-172.17.0.14-1597399671769:blk_-9223372036854775776_1002; getBlockSize()=100663296; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38931,DS-4dd48b11-cffa-4640-82d3-bcb392fa8b36,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-1a2b920c-9b67-4a49-b252-7c62f21076a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-9312e098-2ea8-4be1-9053-1c82c0549e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-42563857-7c1e-4b84-aed5-a5d5b657ac87,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-e4fefd8f-7ee9-4bae-b67e-4809cff60fbe,DISK]]; indices=[2, 3, 4, 5, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=1048576, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=100663296;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-347845399-172.17.0.14-1597399671769:blk_-9223372036854775776_1002; getBlockSize()=100663296; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38931,DS-4dd48b11-cffa-4640-82d3-bcb392fa8b36,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-1a2b920c-9b67-4a49-b252-7c62f21076a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-9312e098-2ea8-4be1-9053-1c82c0549e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-42563857-7c1e-4b84-aed5-a5d5b657ac87,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-e4fefd8f-7ee9-4bae-b67e-4809cff60fbe,DISK]]; indices=[2, 3, 4, 5, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-347845399-172.17.0.14-1597399671769:blk_-9223372036854775776_1002; getBlockSize()=100663296; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38931,DS-4dd48b11-cffa-4640-82d3-bcb392fa8b36,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-1a2b920c-9b67-4a49-b252-7c62f21076a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-9312e098-2ea8-4be1-9053-1c82c0549e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-42563857-7c1e-4b84-aed5-a5d5b657ac87,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-e4fefd8f-7ee9-4bae-b67e-4809cff60fbe,DISK]]; indices=[2, 3, 4, 5, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:326)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:419)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:829)
	at java.io.DataInputStream.read(DataInputStream.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:94)
	at org.apache.hadoop.hdfs.DFSTestUtil.readFileAsBytes(DFSTestUtil.java:372)
	at org.apache.hadoop.hdfs.server.namenode.TestFSImage.testChangeErasureCodingPolicyState(TestFSImage.java:932)
	at org.apache.hadoop.hdfs.server.namenode.TestFSImage.testSaveAndLoadErasureCodingPolicies(TestFSImage.java:889)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestFSImage#testSaveAndLoadErasureCodingPolicies
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=1048576, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=100663296;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-806246105-172.17.0.14-1597400081752:blk_-9223372036854775776_1002; getBlockSize()=100663296; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45885,DS-7d2c67a7-e821-4046-a7ef-982a7b7b87e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-40de7369-5bae-492e-848f-ca9d7fb1d10f,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-83f82614-a809-4a8e-ae4d-cebae66ba346,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-f49cded8-c3d2-48bd-8891-316666bac5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-5397bfeb-02b2-4ae7-bc11-1b6480ea964d,DISK]]; indices=[0, 3, 5, 6, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-806246105-172.17.0.14-1597400081752:blk_-9223372036854775776_1002; getBlockSize()=100663296; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45885,DS-7d2c67a7-e821-4046-a7ef-982a7b7b87e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-40de7369-5bae-492e-848f-ca9d7fb1d10f,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-83f82614-a809-4a8e-ae4d-cebae66ba346,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-f49cded8-c3d2-48bd-8891-316666bac5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-5397bfeb-02b2-4ae7-bc11-1b6480ea964d,DISK]]; indices=[0, 3, 5, 6, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=1048576, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=100663296;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-806246105-172.17.0.14-1597400081752:blk_-9223372036854775776_1002; getBlockSize()=100663296; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45885,DS-7d2c67a7-e821-4046-a7ef-982a7b7b87e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-40de7369-5bae-492e-848f-ca9d7fb1d10f,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-83f82614-a809-4a8e-ae4d-cebae66ba346,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-f49cded8-c3d2-48bd-8891-316666bac5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-5397bfeb-02b2-4ae7-bc11-1b6480ea964d,DISK]]; indices=[0, 3, 5, 6, 8]}];  lastLocatedBlock=LocatedStripedBlock{BP-806246105-172.17.0.14-1597400081752:blk_-9223372036854775776_1002; getBlockSize()=100663296; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45885,DS-7d2c67a7-e821-4046-a7ef-982a7b7b87e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-40de7369-5bae-492e-848f-ca9d7fb1d10f,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-83f82614-a809-4a8e-ae4d-cebae66ba346,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-f49cded8-c3d2-48bd-8891-316666bac5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-5397bfeb-02b2-4ae7-bc11-1b6480ea964d,DISK]]; indices=[0, 3, 5, 6, 8]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:326)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:419)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:829)
	at java.io.DataInputStream.read(DataInputStream.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:94)
	at org.apache.hadoop.hdfs.DFSTestUtil.readFileAsBytes(DFSTestUtil.java:372)
	at org.apache.hadoop.hdfs.server.namenode.TestFSImage.testChangeErasureCodingPolicyState(TestFSImage.java:960)
	at org.apache.hadoop.hdfs.server.namenode.TestFSImage.testSaveAndLoadErasureCodingPolicies(TestFSImage.java:889)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestFSImage#testSaveAndLoadErasureCodingPolicies
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=1048576, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=100663296;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-914553953-172.17.0.14-1597402983177:blk_-9223372036854775776_1002; getBlockSize()=100663296; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43116,DS-2bc44dc8-8a6f-4c6c-837c-99e556b02697,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-95d3247d-267b-423a-8da9-e29efaf3eed7,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-b249dab6-eff3-40a3-bdcc-098edf891195,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-591bba8d-529e-4e0e-9c00-5d6e2d55e6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-810c1e3a-954b-4433-86df-7b9f2e3f9192,DISK]]; indices=[0, 2, 4, 5, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-914553953-172.17.0.14-1597402983177:blk_-9223372036854775776_1002; getBlockSize()=100663296; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43116,DS-2bc44dc8-8a6f-4c6c-837c-99e556b02697,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-95d3247d-267b-423a-8da9-e29efaf3eed7,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-b249dab6-eff3-40a3-bdcc-098edf891195,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-591bba8d-529e-4e0e-9c00-5d6e2d55e6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-810c1e3a-954b-4433-86df-7b9f2e3f9192,DISK]]; indices=[0, 2, 4, 5, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=1048576, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=100663296;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-914553953-172.17.0.14-1597402983177:blk_-9223372036854775776_1002; getBlockSize()=100663296; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43116,DS-2bc44dc8-8a6f-4c6c-837c-99e556b02697,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-95d3247d-267b-423a-8da9-e29efaf3eed7,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-b249dab6-eff3-40a3-bdcc-098edf891195,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-591bba8d-529e-4e0e-9c00-5d6e2d55e6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-810c1e3a-954b-4433-86df-7b9f2e3f9192,DISK]]; indices=[0, 2, 4, 5, 7]}];  lastLocatedBlock=LocatedStripedBlock{BP-914553953-172.17.0.14-1597402983177:blk_-9223372036854775776_1002; getBlockSize()=100663296; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43116,DS-2bc44dc8-8a6f-4c6c-837c-99e556b02697,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-95d3247d-267b-423a-8da9-e29efaf3eed7,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-b249dab6-eff3-40a3-bdcc-098edf891195,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-591bba8d-529e-4e0e-9c00-5d6e2d55e6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-810c1e3a-954b-4433-86df-7b9f2e3f9192,DISK]]; indices=[0, 2, 4, 5, 7]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:326)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:419)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:829)
	at java.io.DataInputStream.read(DataInputStream.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:94)
	at org.apache.hadoop.hdfs.DFSTestUtil.readFileAsBytes(DFSTestUtil.java:372)
	at org.apache.hadoop.hdfs.server.namenode.TestFSImage.testChangeErasureCodingPolicyState(TestFSImage.java:960)
	at org.apache.hadoop.hdfs.server.namenode.TestFSImage.testSaveAndLoadErasureCodingPolicies(TestFSImage.java:889)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestFSImage#testSaveAndLoadErasureCodingPolicies
reconfPoint: -2
result: -1
failureMessage: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=1048576, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=50331648;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1061242134-172.17.0.14-1597407530931:blk_-9223372036854775760_1003; getBlockSize()=50331648; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44652,DS-b462f269-5ed2-45ee-887d-d99599dd109d,DISK]]; indices=[2]}];  lastLocatedBlock=LocatedStripedBlock{BP-1061242134-172.17.0.14-1597407530931:blk_-9223372036854775760_1003; getBlockSize()=50331648; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44652,DS-b462f269-5ed2-45ee-887d-d99599dd109d,DISK]]; indices=[2]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-3-2-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=3, numParityUnits=2]], CellSize=1048576, Id=2]}
stackTrace: java.io.IOException: 4 missing blocks, the stripe is: AlignedStripe(Offset=0, length=1048576, fetchedChunksNum=0, missingChunksNum=4); locatedBlocks is: LocatedBlocks{;  fileLength=50331648;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-1061242134-172.17.0.14-1597407530931:blk_-9223372036854775760_1003; getBlockSize()=50331648; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44652,DS-b462f269-5ed2-45ee-887d-d99599dd109d,DISK]]; indices=[2]}];  lastLocatedBlock=LocatedStripedBlock{BP-1061242134-172.17.0.14-1597407530931:blk_-9223372036854775760_1003; getBlockSize()=50331648; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44652,DS-b462f269-5ed2-45ee-887d-d99599dd109d,DISK]]; indices=[2]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-3-2-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=3, numParityUnits=2]], CellSize=1048576, Id=2]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:326)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:419)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:829)
	at java.io.DataInputStream.read(DataInputStream.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:94)
	at org.apache.hadoop.hdfs.DFSTestUtil.readFileAsBytes(DFSTestUtil.java:372)
	at org.apache.hadoop.hdfs.server.namenode.TestFSImage.testChangeErasureCodingPolicyState(TestFSImage.java:932)
	at org.apache.hadoop.hdfs.server.namenode.TestFSImage.testSaveAndLoadErasureCodingPolicies(TestFSImage.java:892)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestFSImage#testSaveAndLoadErasureCodingPolicies
reconfPoint: -2
result: -1
failureMessage: 3 missing blocks, the stripe is: AlignedStripe(Offset=0, length=1048576, fetchedChunksNum=0, missingChunksNum=3); locatedBlocks is: LocatedBlocks{;  fileLength=50331648;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-915746693-172.17.0.14-1597409925230:blk_-9223372036854775760_1003; getBlockSize()=50331648; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46418,DS-91fbee67-f533-4a07-8552-622950484980,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-b98c22b6-b776-449d-a52d-7c119cb85b6d,DISK]]; indices=[1, 4]}];  lastLocatedBlock=LocatedStripedBlock{BP-915746693-172.17.0.14-1597409925230:blk_-9223372036854775760_1003; getBlockSize()=50331648; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46418,DS-91fbee67-f533-4a07-8552-622950484980,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-b98c22b6-b776-449d-a52d-7c119cb85b6d,DISK]]; indices=[1, 4]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-3-2-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=3, numParityUnits=2]], CellSize=1048576, Id=2]}
stackTrace: java.io.IOException: 3 missing blocks, the stripe is: AlignedStripe(Offset=0, length=1048576, fetchedChunksNum=0, missingChunksNum=3); locatedBlocks is: LocatedBlocks{;  fileLength=50331648;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-915746693-172.17.0.14-1597409925230:blk_-9223372036854775760_1003; getBlockSize()=50331648; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46418,DS-91fbee67-f533-4a07-8552-622950484980,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-b98c22b6-b776-449d-a52d-7c119cb85b6d,DISK]]; indices=[1, 4]}];  lastLocatedBlock=LocatedStripedBlock{BP-915746693-172.17.0.14-1597409925230:blk_-9223372036854775760_1003; getBlockSize()=50331648; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46418,DS-91fbee67-f533-4a07-8552-622950484980,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-b98c22b6-b776-449d-a52d-7c119cb85b6d,DISK]]; indices=[1, 4]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-3-2-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=3, numParityUnits=2]], CellSize=1048576, Id=2]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:326)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:419)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:829)
	at java.io.DataInputStream.read(DataInputStream.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:94)
	at org.apache.hadoop.hdfs.DFSTestUtil.readFileAsBytes(DFSTestUtil.java:372)
	at org.apache.hadoop.hdfs.server.namenode.TestFSImage.testChangeErasureCodingPolicyState(TestFSImage.java:932)
	at org.apache.hadoop.hdfs.server.namenode.TestFSImage.testSaveAndLoadErasureCodingPolicies(TestFSImage.java:892)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.server.namenode.TestFSImage#testSaveAndLoadErasureCodingPolicies
reconfPoint: -2
result: -1
failureMessage: 3 missing blocks, the stripe is: AlignedStripe(Offset=0, length=1048576, fetchedChunksNum=0, missingChunksNum=3); locatedBlocks is: LocatedBlocks{;  fileLength=50331648;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-263607306-172.17.0.14-1597410986037:blk_-9223372036854775760_1003; getBlockSize()=50331648; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43762,DS-9ae666ac-80fa-4ef8-bbe1-39dc5d193991,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-2d10db2d-c0cb-4eec-80b6-c6271c24cdab,DISK]]; indices=[0, 3]}];  lastLocatedBlock=LocatedStripedBlock{BP-263607306-172.17.0.14-1597410986037:blk_-9223372036854775760_1003; getBlockSize()=50331648; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43762,DS-9ae666ac-80fa-4ef8-bbe1-39dc5d193991,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-2d10db2d-c0cb-4eec-80b6-c6271c24cdab,DISK]]; indices=[0, 3]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-3-2-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=3, numParityUnits=2]], CellSize=1048576, Id=2]}
stackTrace: java.io.IOException: 3 missing blocks, the stripe is: AlignedStripe(Offset=0, length=1048576, fetchedChunksNum=0, missingChunksNum=3); locatedBlocks is: LocatedBlocks{;  fileLength=50331648;  underConstruction=false;  blocks=[LocatedStripedBlock{BP-263607306-172.17.0.14-1597410986037:blk_-9223372036854775760_1003; getBlockSize()=50331648; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43762,DS-9ae666ac-80fa-4ef8-bbe1-39dc5d193991,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-2d10db2d-c0cb-4eec-80b6-c6271c24cdab,DISK]]; indices=[0, 3]}];  lastLocatedBlock=LocatedStripedBlock{BP-263607306-172.17.0.14-1597410986037:blk_-9223372036854775760_1003; getBlockSize()=50331648; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43762,DS-9ae666ac-80fa-4ef8-bbe1-39dc5d193991,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-2d10db2d-c0cb-4eec-80b6-c6271c24cdab,DISK]]; indices=[0, 3]};  isLastBlockComplete=true;  ecPolicy=ErasureCodingPolicy=[Name=RS-3-2-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=3, numParityUnits=2]], CellSize=1048576, Id=2]}
	at org.apache.hadoop.hdfs.StripeReader.checkMissingBlocks(StripeReader.java:179)
	at org.apache.hadoop.hdfs.StripeReader.readParityChunks(StripeReader.java:211)
	at org.apache.hadoop.hdfs.StripeReader.readStripe(StripeReader.java:341)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readOneStripe(DFSStripedInputStream.java:326)
	at org.apache.hadoop.hdfs.DFSStripedInputStream.readWithStrategy(DFSStripedInputStream.java:419)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:829)
	at java.io.DataInputStream.read(DataInputStream.java:100)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:94)
	at org.apache.hadoop.hdfs.DFSTestUtil.readFileAsBytes(DFSTestUtil.java:372)
	at org.apache.hadoop.hdfs.server.namenode.TestFSImage.testChangeErasureCodingPolicyState(TestFSImage.java:932)
	at org.apache.hadoop.hdfs.server.namenode.TestFSImage.testSaveAndLoadErasureCodingPolicies(TestFSImage.java:892)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 15965
