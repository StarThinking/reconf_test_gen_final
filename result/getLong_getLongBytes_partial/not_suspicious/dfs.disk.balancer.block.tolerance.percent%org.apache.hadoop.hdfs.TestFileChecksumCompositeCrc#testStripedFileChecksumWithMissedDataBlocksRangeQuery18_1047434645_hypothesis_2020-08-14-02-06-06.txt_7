reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1613617694-172.17.0.20-1597372085303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46363,DS-d56e99c5-1582-42da-9926-25a62b6e00dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-cc29b393-71de-4d81-9073-eb6ac6063a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-3db67d3a-f9e3-4306-b82f-bed6a4e14603,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-14594951-1941-441a-b062-fd46fa7c0b89,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-21a5ee43-90d7-4033-9b63-b77a0c9e015b,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-5319df27-634f-4f41-9dbd-fd4849d71a79,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-2c4c8be2-0d76-4691-8432-b9d2e1b94504,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-250f6cbc-3432-42b9-ada0-f6941be39f49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1613617694-172.17.0.20-1597372085303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46363,DS-d56e99c5-1582-42da-9926-25a62b6e00dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-cc29b393-71de-4d81-9073-eb6ac6063a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-3db67d3a-f9e3-4306-b82f-bed6a4e14603,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-14594951-1941-441a-b062-fd46fa7c0b89,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-21a5ee43-90d7-4033-9b63-b77a0c9e015b,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-5319df27-634f-4f41-9dbd-fd4849d71a79,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-2c4c8be2-0d76-4691-8432-b9d2e1b94504,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-250f6cbc-3432-42b9-ada0-f6941be39f49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-710373294-172.17.0.20-1597372119655:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42191,DS-11d45970-4d76-493d-bbdc-d1a50a425c58,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-63642421-2d1b-4c85-95b0-f88b1a91ac00,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-e5b4ce38-b7f5-42a0-a4b4-c2faed81e400,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-5339fec7-ee9d-424d-a081-5e9d35e89779,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-bd383ba3-6177-4e1a-9ef5-ab7259fce7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-e73e7aa0-0691-4ebd-baa9-97c8ce596b99,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-48f2a830-c613-4cb4-a8bb-f6cfcf8461ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-34ef7647-4846-4d56-8df5-2109e31e8f2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-710373294-172.17.0.20-1597372119655:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42191,DS-11d45970-4d76-493d-bbdc-d1a50a425c58,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-63642421-2d1b-4c85-95b0-f88b1a91ac00,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-e5b4ce38-b7f5-42a0-a4b4-c2faed81e400,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-5339fec7-ee9d-424d-a081-5e9d35e89779,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-bd383ba3-6177-4e1a-9ef5-ab7259fce7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-e73e7aa0-0691-4ebd-baa9-97c8ce596b99,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-48f2a830-c613-4cb4-a8bb-f6cfcf8461ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-34ef7647-4846-4d56-8df5-2109e31e8f2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2079189997-172.17.0.20-1597372183380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44569,DS-e6fdab27-5486-47bb-8606-3c91708a7915,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-c3069008-5359-48a9-9110-e174ad2af677,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-58117a5c-b6d3-4dba-a73c-7cce73ef5026,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-1a7e8b6a-bdaa-4a59-8f44-f4f83eff25e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-e02f3c32-41fc-4f1d-a2ef-427a2c09614f,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-8406503f-94a6-43ec-b367-054253bbc052,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-b9636b38-7090-429a-81ce-91002dd154b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-c07f4ee8-1a8b-4404-9f55-78161bba5e1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2079189997-172.17.0.20-1597372183380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44569,DS-e6fdab27-5486-47bb-8606-3c91708a7915,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-c3069008-5359-48a9-9110-e174ad2af677,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-58117a5c-b6d3-4dba-a73c-7cce73ef5026,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-1a7e8b6a-bdaa-4a59-8f44-f4f83eff25e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-e02f3c32-41fc-4f1d-a2ef-427a2c09614f,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-8406503f-94a6-43ec-b367-054253bbc052,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-b9636b38-7090-429a-81ce-91002dd154b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-c07f4ee8-1a8b-4404-9f55-78161bba5e1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1951668187-172.17.0.20-1597372809349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45364,DS-d9a621a7-c5de-44ee-b5d4-0515c4cfb9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-991d4c8f-e680-4b64-8729-66ca0443ce2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-9711265e-2445-46ad-a148-128f17f0290c,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-8144b2be-9445-4c7a-bcc3-b32d449daebc,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-34c051a8-bd30-4da3-ae0b-3691fb4071c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-34bfe192-6b0b-45f4-a574-1f560a8f7df7,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-787fb716-c7af-49aa-a6c1-9b45683bd5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-7d281f31-1c58-4795-95ec-3967fab29f66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1951668187-172.17.0.20-1597372809349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45364,DS-d9a621a7-c5de-44ee-b5d4-0515c4cfb9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-991d4c8f-e680-4b64-8729-66ca0443ce2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-9711265e-2445-46ad-a148-128f17f0290c,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-8144b2be-9445-4c7a-bcc3-b32d449daebc,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-34c051a8-bd30-4da3-ae0b-3691fb4071c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-34bfe192-6b0b-45f4-a574-1f560a8f7df7,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-787fb716-c7af-49aa-a6c1-9b45683bd5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-7d281f31-1c58-4795-95ec-3967fab29f66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1718291758-172.17.0.20-1597372841206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41977,DS-7be69d4c-7bc5-443b-a89b-a9e925fb3992,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-6e2cd8cb-337a-4798-9a09-b9046ab03313,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-edcc80e8-a54e-489b-9e6e-90c015fd5806,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-1e3d9f13-14b3-4962-a4e4-f7e572db4324,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-fcd0e681-65a3-4e69-9f01-fa2cbfc465ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-b32d5ada-1200-4606-85a0-7181158d3a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-7b3b07ec-9644-4e1d-a39a-e2fce14b730a,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-ad893187-a9fb-4ba3-b3c8-845508f467ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1718291758-172.17.0.20-1597372841206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41977,DS-7be69d4c-7bc5-443b-a89b-a9e925fb3992,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-6e2cd8cb-337a-4798-9a09-b9046ab03313,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-edcc80e8-a54e-489b-9e6e-90c015fd5806,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-1e3d9f13-14b3-4962-a4e4-f7e572db4324,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-fcd0e681-65a3-4e69-9f01-fa2cbfc465ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-b32d5ada-1200-4606-85a0-7181158d3a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-7b3b07ec-9644-4e1d-a39a-e2fce14b730a,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-ad893187-a9fb-4ba3-b3c8-845508f467ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-573757774-172.17.0.20-1597372941334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38891,DS-5afa5497-bb41-48c5-9298-1ed8c407724c,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-1ee3bda6-b362-4ee9-8db7-16bfa07f7168,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-cf9841ea-337d-4a13-a71f-3eb436db124e,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-d03df60d-8a22-4548-ad9f-e5cfeb0ded1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-33a479ef-ed5a-4279-93cc-8806fb7e1b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-d5bfcf2f-a89e-4f97-bbb5-9430386bfd90,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-f599b2b3-118b-435e-b8e8-3482130e6696,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-3b1bf2de-826e-4705-8b6b-f2135ebe8bfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-573757774-172.17.0.20-1597372941334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38891,DS-5afa5497-bb41-48c5-9298-1ed8c407724c,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-1ee3bda6-b362-4ee9-8db7-16bfa07f7168,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-cf9841ea-337d-4a13-a71f-3eb436db124e,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-d03df60d-8a22-4548-ad9f-e5cfeb0ded1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-33a479ef-ed5a-4279-93cc-8806fb7e1b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-d5bfcf2f-a89e-4f97-bbb5-9430386bfd90,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-f599b2b3-118b-435e-b8e8-3482130e6696,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-3b1bf2de-826e-4705-8b6b-f2135ebe8bfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-28388043-172.17.0.20-1597373401336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37028,DS-b7d174b2-b7bf-4b4a-a70b-629ff6a35798,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-2441e300-1ff5-4617-9dad-ddb0b45a3425,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-aad469d9-7908-4395-a8c7-672d16d7bd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-7ccf929a-95b8-4954-aa5a-b3621bd56a40,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-db6a77b0-bbe5-4060-a265-f6598fcd7d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-e92d7728-95a1-4ec6-a793-c4489ebc26dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-e049ba32-4cb8-45f0-8004-c2f2a9978b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-6c36cd8d-36cf-44ce-a151-0f0d6ccf5696,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-28388043-172.17.0.20-1597373401336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37028,DS-b7d174b2-b7bf-4b4a-a70b-629ff6a35798,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-2441e300-1ff5-4617-9dad-ddb0b45a3425,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-aad469d9-7908-4395-a8c7-672d16d7bd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-7ccf929a-95b8-4954-aa5a-b3621bd56a40,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-db6a77b0-bbe5-4060-a265-f6598fcd7d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-e92d7728-95a1-4ec6-a793-c4489ebc26dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-e049ba32-4cb8-45f0-8004-c2f2a9978b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-6c36cd8d-36cf-44ce-a151-0f0d6ccf5696,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2122921908-172.17.0.20-1597373481272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42940,DS-f5f0f252-9cea-449b-b726-3c78eee4b504,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-8c0d864d-9e40-4e42-ac06-9f4c1fe63f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-1c64f79c-fcc1-4e11-a607-f22a12780917,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-17ab3107-e83f-434e-93f4-0c01db15e4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-9567d0fc-27e1-4099-bea7-9210da5a74ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-b3883748-d07f-4c2f-9004-0944115c777c,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-1e932737-2f53-4569-8010-259a676f48f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-ec0dd2c2-657d-4c6b-bd04-2b40552350dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2122921908-172.17.0.20-1597373481272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42940,DS-f5f0f252-9cea-449b-b726-3c78eee4b504,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-8c0d864d-9e40-4e42-ac06-9f4c1fe63f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-1c64f79c-fcc1-4e11-a607-f22a12780917,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-17ab3107-e83f-434e-93f4-0c01db15e4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-9567d0fc-27e1-4099-bea7-9210da5a74ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-b3883748-d07f-4c2f-9004-0944115c777c,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-1e932737-2f53-4569-8010-259a676f48f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-ec0dd2c2-657d-4c6b-bd04-2b40552350dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-129252763-172.17.0.20-1597373802093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40830,DS-587d22a7-f246-47e6-8e74-c285f4a7577a,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-e7dadcd6-56be-4a28-ba7c-ec32158f45d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-5a31bc1f-df67-4d85-8bf1-705489c52373,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-fe81bf50-c305-487f-8102-5a98050a21a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-e0e41373-2f40-470c-b4f1-bf1cf10f845a,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-d58cdfa3-05d1-4450-a45d-1770acc8dc97,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-bf94b28d-078b-45c9-a730-9a4ecd1e4464,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-4f4d0165-f179-418c-b1c6-a2355f9cb99f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-129252763-172.17.0.20-1597373802093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40830,DS-587d22a7-f246-47e6-8e74-c285f4a7577a,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-e7dadcd6-56be-4a28-ba7c-ec32158f45d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-5a31bc1f-df67-4d85-8bf1-705489c52373,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-fe81bf50-c305-487f-8102-5a98050a21a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-e0e41373-2f40-470c-b4f1-bf1cf10f845a,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-d58cdfa3-05d1-4450-a45d-1770acc8dc97,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-bf94b28d-078b-45c9-a730-9a4ecd1e4464,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-4f4d0165-f179-418c-b1c6-a2355f9cb99f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1121409366-172.17.0.20-1597374706543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43233,DS-cb1db0a0-fe00-40f1-a42d-9ffa16ccf7af,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-c5c5388d-9cc8-4cf3-9d3d-6fc04e36dbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-42642b4d-9ad0-45a6-9741-443e04352770,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-67fcfc2f-9d3b-4653-b3b1-32f86e8953c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-6b614aca-8015-40a6-9e05-99a8117ea58e,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-fcd6e64d-bba1-4ae7-85dc-7572375c7770,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-e6cebbf7-66c9-4083-b435-d64d5ce69440,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-77ac37d4-b908-4ca8-8eec-70988f5faafe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1121409366-172.17.0.20-1597374706543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43233,DS-cb1db0a0-fe00-40f1-a42d-9ffa16ccf7af,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-c5c5388d-9cc8-4cf3-9d3d-6fc04e36dbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-42642b4d-9ad0-45a6-9741-443e04352770,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-67fcfc2f-9d3b-4653-b3b1-32f86e8953c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-6b614aca-8015-40a6-9e05-99a8117ea58e,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-fcd6e64d-bba1-4ae7-85dc-7572375c7770,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-e6cebbf7-66c9-4083-b435-d64d5ce69440,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-77ac37d4-b908-4ca8-8eec-70988f5faafe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-708878651-172.17.0.20-1597374870812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43453,DS-afe3a942-92a9-4ba7-8cae-85c283840390,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-0e26940f-242d-4035-916b-d23eb3de48cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-ba10506f-27ec-4b23-9b77-0ecedfde7c11,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-0f3ae247-7eed-4ff3-8618-bfee272ca00b,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-6c7a1791-5b59-45ec-9583-5a69d051f87a,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-d5510dcf-d4b5-4c9a-8747-acd0ad0532b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-b84fe8f3-b9a1-461c-9f5c-7f040ac5c2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-ecef16a8-0dde-4374-af9c-e09432df0f4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-708878651-172.17.0.20-1597374870812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43453,DS-afe3a942-92a9-4ba7-8cae-85c283840390,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-0e26940f-242d-4035-916b-d23eb3de48cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-ba10506f-27ec-4b23-9b77-0ecedfde7c11,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-0f3ae247-7eed-4ff3-8618-bfee272ca00b,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-6c7a1791-5b59-45ec-9583-5a69d051f87a,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-d5510dcf-d4b5-4c9a-8747-acd0ad0532b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-b84fe8f3-b9a1-461c-9f5c-7f040ac5c2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-ecef16a8-0dde-4374-af9c-e09432df0f4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-574734256-172.17.0.20-1597375003323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44558,DS-24385ffa-41d7-4efe-adf2-bea9ac93ac64,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-8877b609-5bf5-4a4b-a8d5-8e1a0d392c79,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-fca9a6da-9361-47a1-80c5-be54fc2d4ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-7ce620f6-9a52-464a-964a-2ec7576af3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-bcf7e54b-aa55-477a-a70c-68e6127c5ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-5e8bd58b-ff1c-4ddb-99e2-a2bf81459e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-6b57c5d6-75c7-4319-b33b-5b6b528baab2,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-e029cd26-8593-451a-87de-535d5c77d150,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-574734256-172.17.0.20-1597375003323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44558,DS-24385ffa-41d7-4efe-adf2-bea9ac93ac64,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-8877b609-5bf5-4a4b-a8d5-8e1a0d392c79,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-fca9a6da-9361-47a1-80c5-be54fc2d4ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-7ce620f6-9a52-464a-964a-2ec7576af3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-bcf7e54b-aa55-477a-a70c-68e6127c5ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-5e8bd58b-ff1c-4ddb-99e2-a2bf81459e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-6b57c5d6-75c7-4319-b33b-5b6b528baab2,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-e029cd26-8593-451a-87de-535d5c77d150,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-789306288-172.17.0.20-1597375038996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43525,DS-be3f2e54-c41f-405b-9f64-0f6e4ed162b5,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-a97d1ebc-809d-48e8-aa6f-48f6fb4e6c41,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-d76436ac-f1b8-466e-911b-4b37c2668359,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-12226123-7d53-4d1d-a339-6f4f6d0c45a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-c082a6ee-f2a9-4186-a704-f031031280d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-db000613-a3be-43a1-a189-a4b5daefd178,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-d5bd4773-602c-47a3-b4ef-44c839547d32,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-5f3ed32c-cf97-44a5-81aa-3d73154a0238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-789306288-172.17.0.20-1597375038996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43525,DS-be3f2e54-c41f-405b-9f64-0f6e4ed162b5,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-a97d1ebc-809d-48e8-aa6f-48f6fb4e6c41,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-d76436ac-f1b8-466e-911b-4b37c2668359,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-12226123-7d53-4d1d-a339-6f4f6d0c45a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-c082a6ee-f2a9-4186-a704-f031031280d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-db000613-a3be-43a1-a189-a4b5daefd178,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-d5bd4773-602c-47a3-b4ef-44c839547d32,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-5f3ed32c-cf97-44a5-81aa-3d73154a0238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 99
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899600939-172.17.0.20-1597375310905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44251,DS-7203605f-e5f5-4d12-b9a7-ed755eddb44b,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-e47c6e90-71e1-4bd8-83e8-2639f57b8d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-ee388bf3-c975-472f-9259-3fd01f540bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-0762d646-86c7-4d1e-9882-fb468a5a92c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-bf5096b0-bd77-4038-97c1-b7464a87421e,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-f8c930e9-90cf-4026-afa3-fd79ae38fb36,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-2f79cc4e-f1b8-47f8-a0b5-fcfa7ed4dde7,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-7a9cf6c2-acb4-4640-a874-7feb69ada75c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899600939-172.17.0.20-1597375310905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44251,DS-7203605f-e5f5-4d12-b9a7-ed755eddb44b,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-e47c6e90-71e1-4bd8-83e8-2639f57b8d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-ee388bf3-c975-472f-9259-3fd01f540bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-0762d646-86c7-4d1e-9882-fb468a5a92c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-bf5096b0-bd77-4038-97c1-b7464a87421e,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-f8c930e9-90cf-4026-afa3-fd79ae38fb36,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-2f79cc4e-f1b8-47f8-a0b5-fcfa7ed4dde7,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-7a9cf6c2-acb4-4640-a874-7feb69ada75c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5200
