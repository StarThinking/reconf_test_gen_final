reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1694637497-172.17.0.19-1597696516682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40010,DS-3ba6e054-2b8a-4e72-922a-379ec11ca292,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-7d2f06d8-bbd6-4e2e-b689-2a4be84a1700,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-9ffefe1b-d3fb-4d08-ba04-a1efba78396d,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-123dc0c6-8b08-42c9-8468-72e2191d305e,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-5060a80f-caa6-4ee0-a32a-ece26928f58a,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-46128cfe-8afc-461d-8a7b-7792efb23311,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-86ae5f37-783b-42ae-8a90-a39a712b3c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-eefaa48f-3436-4e5a-b141-c20e794a3f86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1694637497-172.17.0.19-1597696516682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40010,DS-3ba6e054-2b8a-4e72-922a-379ec11ca292,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-7d2f06d8-bbd6-4e2e-b689-2a4be84a1700,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-9ffefe1b-d3fb-4d08-ba04-a1efba78396d,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-123dc0c6-8b08-42c9-8468-72e2191d305e,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-5060a80f-caa6-4ee0-a32a-ece26928f58a,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-46128cfe-8afc-461d-8a7b-7792efb23311,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-86ae5f37-783b-42ae-8a90-a39a712b3c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-eefaa48f-3436-4e5a-b141-c20e794a3f86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457541602-172.17.0.19-1597696918911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44731,DS-9fab5de8-09ec-4d81-9aea-9c631431aa5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-42c97896-0358-4798-89c3-da7c45420e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36694,DS-1da1b6b8-1d68-46de-a4e1-b3c07ef57e85,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-be9feb13-3889-4f2f-a3ae-710c5990eed2,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-87d95c8a-3724-4fa1-992c-3c104067a030,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-31b7ba5b-0249-4f7b-a805-767cb6673770,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-38d2a148-1909-4bae-8523-ee502ba705a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42752,DS-75bc885d-8e47-4479-9f51-a60e0858e17d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457541602-172.17.0.19-1597696918911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44731,DS-9fab5de8-09ec-4d81-9aea-9c631431aa5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-42c97896-0358-4798-89c3-da7c45420e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36694,DS-1da1b6b8-1d68-46de-a4e1-b3c07ef57e85,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-be9feb13-3889-4f2f-a3ae-710c5990eed2,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-87d95c8a-3724-4fa1-992c-3c104067a030,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-31b7ba5b-0249-4f7b-a805-767cb6673770,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-38d2a148-1909-4bae-8523-ee502ba705a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42752,DS-75bc885d-8e47-4479-9f51-a60e0858e17d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2101217001-172.17.0.19-1597696964665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45316,DS-b3f4c524-e9ec-4b82-8bd4-c4bb97ab5743,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-3967db61-22dd-497a-9f95-95da0bcf66e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-5a062031-251a-471e-b1f7-a05c38a9f081,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-6e8b4a37-9ad5-4b5a-b66b-619561dfff0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-223b3a2a-20f7-4a06-a7c8-a3b0367e6ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-52bef3b4-542e-40f7-85c9-c707aeaf9759,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-666711a5-f2d1-47d4-b54d-d78056178e29,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-59932bea-b1dd-4955-9915-e468c4bd98c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2101217001-172.17.0.19-1597696964665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45316,DS-b3f4c524-e9ec-4b82-8bd4-c4bb97ab5743,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-3967db61-22dd-497a-9f95-95da0bcf66e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-5a062031-251a-471e-b1f7-a05c38a9f081,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-6e8b4a37-9ad5-4b5a-b66b-619561dfff0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-223b3a2a-20f7-4a06-a7c8-a3b0367e6ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-52bef3b4-542e-40f7-85c9-c707aeaf9759,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-666711a5-f2d1-47d4-b54d-d78056178e29,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-59932bea-b1dd-4955-9915-e468c4bd98c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-630796859-172.17.0.19-1597697368675:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39618,DS-00766eec-a72f-4373-b08b-e8c0e42fedaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-03d73072-2c86-4722-9e21-3a1d686f35d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-789c7ad8-07f4-4a7a-b94d-04018937737e,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-dc2e7e00-708c-48be-b26c-96060091b88d,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-a4d6ae7a-2604-401e-8d65-b79f03010d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-02d953ba-925b-419e-adb0-9f7ff2c65ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-ba485e02-51dd-4477-b1c5-ed3255b1c692,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-dcef507f-f801-4061-946a-838c02efc73b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-630796859-172.17.0.19-1597697368675:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39618,DS-00766eec-a72f-4373-b08b-e8c0e42fedaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-03d73072-2c86-4722-9e21-3a1d686f35d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-789c7ad8-07f4-4a7a-b94d-04018937737e,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-dc2e7e00-708c-48be-b26c-96060091b88d,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-a4d6ae7a-2604-401e-8d65-b79f03010d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-02d953ba-925b-419e-adb0-9f7ff2c65ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-ba485e02-51dd-4477-b1c5-ed3255b1c692,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-dcef507f-f801-4061-946a-838c02efc73b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1219254716-172.17.0.19-1597697499873:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38468,DS-a96bcc3d-d455-4fa5-ad91-6757739a7fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-bff50516-4fd2-47ec-9347-29563108bc86,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-67af2c68-663d-4c2e-b0cd-3cb7cb258a71,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-dc3c0202-c863-4efc-a4cb-675ef007e114,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-65042e52-9ed4-49f9-b61d-c947c2ca1259,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-8e884136-f05a-497d-a459-de4a3bb0bba1,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-fe1c3ba3-74c0-444e-b49f-c17ec726424e,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-0e5528a8-354b-44fd-b7be-56ed6965d40b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1219254716-172.17.0.19-1597697499873:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38468,DS-a96bcc3d-d455-4fa5-ad91-6757739a7fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-bff50516-4fd2-47ec-9347-29563108bc86,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-67af2c68-663d-4c2e-b0cd-3cb7cb258a71,DISK], DatanodeInfoWithStorage[127.0.0.1:43009,DS-dc3c0202-c863-4efc-a4cb-675ef007e114,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-65042e52-9ed4-49f9-b61d-c947c2ca1259,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-8e884136-f05a-497d-a459-de4a3bb0bba1,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-fe1c3ba3-74c0-444e-b49f-c17ec726424e,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-0e5528a8-354b-44fd-b7be-56ed6965d40b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1012082157-172.17.0.19-1597697843186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45177,DS-dc7a89b0-d92b-41d6-af92-9e06f5698655,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-d6772bbf-ea36-4a24-adfc-98522801c838,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-f051a5cc-ddb5-4382-bd9a-a43227afc328,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-6d4547e7-a51e-450f-a870-4ffadcf9c63f,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-2e255058-2aa2-4aba-95c1-13a758ee3d53,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-3774d280-2c31-4369-8af2-a0d96f025afd,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-3f3cd0a6-86b8-433e-9a30-14d76e3b37e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-67f6424b-0d18-4cd7-878b-531d73c576ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1012082157-172.17.0.19-1597697843186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45177,DS-dc7a89b0-d92b-41d6-af92-9e06f5698655,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-d6772bbf-ea36-4a24-adfc-98522801c838,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-f051a5cc-ddb5-4382-bd9a-a43227afc328,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-6d4547e7-a51e-450f-a870-4ffadcf9c63f,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-2e255058-2aa2-4aba-95c1-13a758ee3d53,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-3774d280-2c31-4369-8af2-a0d96f025afd,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-3f3cd0a6-86b8-433e-9a30-14d76e3b37e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-67f6424b-0d18-4cd7-878b-531d73c576ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-838129927-172.17.0.19-1597698453974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35568,DS-f6494cf5-6ad5-40ed-ad93-4a02d9cb2917,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-5641af5e-f362-434d-af7b-69baba13ad8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-6c036886-76d0-4aab-bea2-b5c227ea4cde,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-f1936868-2ca6-4a9c-8a92-bbd0adffe069,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-fd7ce85d-d101-4da8-a814-20eaa4b47c85,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-9a3bbe57-0d0a-47c0-80ae-45d6309a71ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-034139cf-0284-4e53-a21e-9c9ffbcdf68d,DISK], DatanodeInfoWithStorage[127.0.0.1:45669,DS-982052c1-622e-4a74-9f79-4c17a05665f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-838129927-172.17.0.19-1597698453974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35568,DS-f6494cf5-6ad5-40ed-ad93-4a02d9cb2917,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-5641af5e-f362-434d-af7b-69baba13ad8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-6c036886-76d0-4aab-bea2-b5c227ea4cde,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-f1936868-2ca6-4a9c-8a92-bbd0adffe069,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-fd7ce85d-d101-4da8-a814-20eaa4b47c85,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-9a3bbe57-0d0a-47c0-80ae-45d6309a71ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-034139cf-0284-4e53-a21e-9c9ffbcdf68d,DISK], DatanodeInfoWithStorage[127.0.0.1:45669,DS-982052c1-622e-4a74-9f79-4c17a05665f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-117979491-172.17.0.19-1597699135382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41766,DS-e20c7332-88d0-4992-b69e-0cc306f79e79,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-a28b26f0-1629-4878-a175-4d91e670f154,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-15e284b6-edaf-4215-b098-32c6e18ce801,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-cf31538d-fc2f-4ce1-97a8-6338ca605df5,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-6db1a146-e8e4-48e7-9340-ae57fd3d3ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-65cbf3d0-3500-415e-a02c-95270e69fa45,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-69d9518a-fdf0-4eb4-9574-64644a3b3da9,DISK], DatanodeInfoWithStorage[127.0.0.1:45640,DS-52ab6ae7-ab40-472a-9356-149865dedcc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-117979491-172.17.0.19-1597699135382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41766,DS-e20c7332-88d0-4992-b69e-0cc306f79e79,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-a28b26f0-1629-4878-a175-4d91e670f154,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-15e284b6-edaf-4215-b098-32c6e18ce801,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-cf31538d-fc2f-4ce1-97a8-6338ca605df5,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-6db1a146-e8e4-48e7-9340-ae57fd3d3ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-65cbf3d0-3500-415e-a02c-95270e69fa45,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-69d9518a-fdf0-4eb4-9574-64644a3b3da9,DISK], DatanodeInfoWithStorage[127.0.0.1:45640,DS-52ab6ae7-ab40-472a-9356-149865dedcc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-95538973-172.17.0.19-1597699414222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37213,DS-31b5ebd0-1609-4e50-93d5-226a8e5470fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-41bf0fd9-e065-4329-b8a8-f9989d588293,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-468f7602-4f95-46ff-a391-d87fded18098,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-4178cf1d-fafb-48a2-8a6d-61ca3e4cf87d,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-0947ce1d-87b5-41c2-b112-212967b305a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-966cf4bb-3335-4c97-badd-f6dbbde51743,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-190fcc96-28ec-4a87-8750-8923796722d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-eb1f2500-5861-40f6-83ef-6f72b033c29c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-95538973-172.17.0.19-1597699414222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37213,DS-31b5ebd0-1609-4e50-93d5-226a8e5470fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-41bf0fd9-e065-4329-b8a8-f9989d588293,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-468f7602-4f95-46ff-a391-d87fded18098,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-4178cf1d-fafb-48a2-8a6d-61ca3e4cf87d,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-0947ce1d-87b5-41c2-b112-212967b305a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-966cf4bb-3335-4c97-badd-f6dbbde51743,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-190fcc96-28ec-4a87-8750-8923796722d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-eb1f2500-5861-40f6-83ef-6f72b033c29c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2060229731-172.17.0.19-1597700015103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45851,DS-0db6fe78-32b9-44be-a0f0-d719596d9ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-d6303c55-3276-41be-b2d5-a9fb7a4d023e,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-01b751b3-1e7b-4ece-9686-74e5cb6a7bad,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-61cdbd1c-cc6e-4047-ba1a-a1df0302811c,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-0370ea45-7bac-4933-8179-5314602a0321,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-cae55ca4-fd31-4d3b-a72a-f4109db570f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-8a4a27ed-9d0a-40c5-8acc-6eb876ecf978,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-ce2524f3-9812-4539-988e-1fa6a6792104,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2060229731-172.17.0.19-1597700015103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45851,DS-0db6fe78-32b9-44be-a0f0-d719596d9ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-d6303c55-3276-41be-b2d5-a9fb7a4d023e,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-01b751b3-1e7b-4ece-9686-74e5cb6a7bad,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-61cdbd1c-cc6e-4047-ba1a-a1df0302811c,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-0370ea45-7bac-4933-8179-5314602a0321,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-cae55ca4-fd31-4d3b-a72a-f4109db570f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-8a4a27ed-9d0a-40c5-8acc-6eb876ecf978,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-ce2524f3-9812-4539-988e-1fa6a6792104,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-705763157-172.17.0.19-1597700726405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33712,DS-42ad4cfc-7ba6-4ee4-8190-4b6e03540a14,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-85496a2b-85c1-44f9-8d18-c5b1a1888954,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-47fa151f-74a6-417f-a0f3-27fc55153bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-997ea763-2502-4517-8e79-f0e152a3c097,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-2e9ef906-08d5-40f3-8aa7-8d1243e6e0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-1a7ea261-bc7b-409f-a489-1f8de72621be,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-ced77fa4-fb90-49dc-9034-8a9064291f93,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-3562bdb6-448d-4650-a5d1-c471161d4153,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-705763157-172.17.0.19-1597700726405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33712,DS-42ad4cfc-7ba6-4ee4-8190-4b6e03540a14,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-85496a2b-85c1-44f9-8d18-c5b1a1888954,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-47fa151f-74a6-417f-a0f3-27fc55153bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-997ea763-2502-4517-8e79-f0e152a3c097,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-2e9ef906-08d5-40f3-8aa7-8d1243e6e0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-1a7ea261-bc7b-409f-a489-1f8de72621be,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-ced77fa4-fb90-49dc-9034-8a9064291f93,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-3562bdb6-448d-4650-a5d1-c471161d4153,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1048310880-172.17.0.19-1597701861384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40683,DS-a38ac9d7-d171-41af-85aa-247076918637,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-d426c625-d4b3-4511-a51a-2425c76e53d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-b78cba80-a28b-431f-adc3-bd3427b50d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36858,DS-f8552ff8-7be9-4b0c-906d-74bb598120a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-f5fa6b29-4cd9-44a4-82a5-ac633f6db4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-27ab6db6-fd1f-4894-b6fc-0f684c9671dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-66ebca3a-0b7c-4c43-bbeb-1900f41225aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-17d75ee5-90af-433d-a824-14efe62fb9f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1048310880-172.17.0.19-1597701861384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40683,DS-a38ac9d7-d171-41af-85aa-247076918637,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-d426c625-d4b3-4511-a51a-2425c76e53d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-b78cba80-a28b-431f-adc3-bd3427b50d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36858,DS-f8552ff8-7be9-4b0c-906d-74bb598120a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-f5fa6b29-4cd9-44a4-82a5-ac633f6db4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-27ab6db6-fd1f-4894-b6fc-0f684c9671dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-66ebca3a-0b7c-4c43-bbeb-1900f41225aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-17d75ee5-90af-433d-a824-14efe62fb9f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2020398806-172.17.0.19-1597702239441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35097,DS-0bdc9b93-8ab9-4945-b39a-5b6d23fb672f,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-2e9fc787-9a25-4f94-ac57-0cff9e7380d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-2c56b9be-bc9c-48fd-8636-bf4534280511,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-e0ce1f1a-8ff7-421d-9930-1ac688c73105,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-9043055f-c152-4a2d-a5a6-8b170cf0505b,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-f99962bb-98e5-4fe9-9d9e-e6e39d502375,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-f9f4612a-0771-44a5-bbef-d028580964ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-5c3d1198-5994-4f63-ab6e-fbaa73c7b1a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2020398806-172.17.0.19-1597702239441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35097,DS-0bdc9b93-8ab9-4945-b39a-5b6d23fb672f,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-2e9fc787-9a25-4f94-ac57-0cff9e7380d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-2c56b9be-bc9c-48fd-8636-bf4534280511,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-e0ce1f1a-8ff7-421d-9930-1ac688c73105,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-9043055f-c152-4a2d-a5a6-8b170cf0505b,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-f99962bb-98e5-4fe9-9d9e-e6e39d502375,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-f9f4612a-0771-44a5-bbef-d028580964ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-5c3d1198-5994-4f63-ab6e-fbaa73c7b1a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-387264964-172.17.0.19-1597702439636:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42129,DS-2bb6638f-bb1f-4498-b804-877709b532a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-755f4c21-9b46-45ec-8a09-6e93b58aee4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-473f3238-5e71-49b2-a8d9-2856043003f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-34f66fe7-7c8a-4381-8f66-83c33fe79bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-96be6a90-3d7b-47c1-b0be-3c6ddcc06858,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-d5d80b9f-6c20-4658-b72c-5b9c0aa7a9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-6e9ee2ca-318f-4860-a203-4156e763dcad,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-8b45ac95-b6df-48b4-ade8-93dc72566277,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-387264964-172.17.0.19-1597702439636:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42129,DS-2bb6638f-bb1f-4498-b804-877709b532a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-755f4c21-9b46-45ec-8a09-6e93b58aee4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-473f3238-5e71-49b2-a8d9-2856043003f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-34f66fe7-7c8a-4381-8f66-83c33fe79bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-96be6a90-3d7b-47c1-b0be-3c6ddcc06858,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-d5d80b9f-6c20-4658-b72c-5b9c0aa7a9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-6e9ee2ca-318f-4860-a203-4156e763dcad,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-8b45ac95-b6df-48b4-ade8-93dc72566277,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1003447155-172.17.0.19-1597702665419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33505,DS-c5690f15-a259-41a0-888c-5a3b7d1b5ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-64c7fbc1-d772-4d92-9533-ec4aaf341481,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-19889570-3658-4531-9e77-1496d5643e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-737e22c0-c2d9-4ac7-aeaa-41217977e256,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-69dd0423-216a-48f5-9d7f-90c296d633d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-b530a72b-5c71-4690-b191-9db86f49e8da,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-52d5f8be-e593-44ec-95a0-72184b260e00,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-fd10263e-464a-4cbb-9dcd-9f05cd6e5913,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1003447155-172.17.0.19-1597702665419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33505,DS-c5690f15-a259-41a0-888c-5a3b7d1b5ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-64c7fbc1-d772-4d92-9533-ec4aaf341481,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-19889570-3658-4531-9e77-1496d5643e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-737e22c0-c2d9-4ac7-aeaa-41217977e256,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-69dd0423-216a-48f5-9d7f-90c296d633d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-b530a72b-5c71-4690-b191-9db86f49e8da,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-52d5f8be-e593-44ec-95a0-72184b260e00,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-fd10263e-464a-4cbb-9dcd-9f05cd6e5913,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1690170879-172.17.0.19-1597703194372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44614,DS-31bbc861-3ede-4754-9bfe-467c82002b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-e9709204-636d-4849-a3ed-41f760ab5c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-8121de40-16e2-4fe1-bfd3-85518c6f502e,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-715cae1b-0ced-4321-8481-6e36ac5c1f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-4f18fffc-f9b0-4e5c-82de-92a9baab0459,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-5b1b09a2-09fe-4cda-90cb-511d1fec6916,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-afef8eb2-c00c-4e01-82fc-6bb5d72028a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-fae19cfa-e013-4770-9191-82fdea9ae0aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1690170879-172.17.0.19-1597703194372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44614,DS-31bbc861-3ede-4754-9bfe-467c82002b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-e9709204-636d-4849-a3ed-41f760ab5c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-8121de40-16e2-4fe1-bfd3-85518c6f502e,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-715cae1b-0ced-4321-8481-6e36ac5c1f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-4f18fffc-f9b0-4e5c-82de-92a9baab0459,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-5b1b09a2-09fe-4cda-90cb-511d1fec6916,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-afef8eb2-c00c-4e01-82fc-6bb5d72028a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-fae19cfa-e013-4770-9191-82fdea9ae0aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 7074
