reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085296786-172.17.0.11-1597273900973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36926,DS-18032250-2026-4913-963b-fe9e6c9fe51e,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-ecfc0438-7f8c-4ee3-82e2-14fd6f9d2d07,DISK], DatanodeInfoWithStorage[127.0.0.1:35051,DS-acd407da-1e49-44f9-9e71-d06bb04a3ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-5b08b356-1f75-4168-a538-b5548877fc16,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-368435d2-e5e6-4639-bb0c-b9e0c1c65448,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-25ccab1d-e066-4b7b-8868-1bf32207ac4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-ebc68c9a-a798-4450-b415-9f5e809e77b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-94cae332-dd7c-4015-a058-addc45a8551b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085296786-172.17.0.11-1597273900973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36926,DS-18032250-2026-4913-963b-fe9e6c9fe51e,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-ecfc0438-7f8c-4ee3-82e2-14fd6f9d2d07,DISK], DatanodeInfoWithStorage[127.0.0.1:35051,DS-acd407da-1e49-44f9-9e71-d06bb04a3ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-5b08b356-1f75-4168-a538-b5548877fc16,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-368435d2-e5e6-4639-bb0c-b9e0c1c65448,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-25ccab1d-e066-4b7b-8868-1bf32207ac4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-ebc68c9a-a798-4450-b415-9f5e809e77b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-94cae332-dd7c-4015-a058-addc45a8551b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1666882568-172.17.0.11-1597274115883:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40422,DS-eadf1572-9591-4d17-b21c-94e0493862f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-bcabf80c-4748-4438-84c0-6a8beda4519b,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-e485fb1c-7874-463b-8ff4-2207dcad323d,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-9d9932bd-17c1-4c7d-a41f-ca2a83a91c95,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-2d8e531f-ef81-4619-a14b-dfe96815d68e,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-f1d16e3c-4e04-4f80-a9a8-4342826eebbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-5cd739d4-0420-4ef5-9549-0379a926c6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-b290ea7d-a6c7-4496-8663-194e94c59fc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1666882568-172.17.0.11-1597274115883:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40422,DS-eadf1572-9591-4d17-b21c-94e0493862f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-bcabf80c-4748-4438-84c0-6a8beda4519b,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-e485fb1c-7874-463b-8ff4-2207dcad323d,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-9d9932bd-17c1-4c7d-a41f-ca2a83a91c95,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-2d8e531f-ef81-4619-a14b-dfe96815d68e,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-f1d16e3c-4e04-4f80-a9a8-4342826eebbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-5cd739d4-0420-4ef5-9549-0379a926c6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-b290ea7d-a6c7-4496-8663-194e94c59fc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1771916678-172.17.0.11-1597274822287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40851,DS-9b9621de-81cf-441b-8a82-708fcda134ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-098b55ec-55bd-43a4-869a-2fc092e7ad15,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-f2be2909-1a58-494e-985e-a25844ed633b,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-fc297811-08e8-4d1a-b691-ba70961a8dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-4c1ed3b0-bee0-4ed4-9034-30a75e13d251,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-13682763-741e-4074-883f-924d90220745,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-0bc4d040-d21e-4e95-835f-f62b2845cbea,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-b4ae0dd2-1354-49c9-9562-145286e97162,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1771916678-172.17.0.11-1597274822287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40851,DS-9b9621de-81cf-441b-8a82-708fcda134ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-098b55ec-55bd-43a4-869a-2fc092e7ad15,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-f2be2909-1a58-494e-985e-a25844ed633b,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-fc297811-08e8-4d1a-b691-ba70961a8dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-4c1ed3b0-bee0-4ed4-9034-30a75e13d251,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-13682763-741e-4074-883f-924d90220745,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-0bc4d040-d21e-4e95-835f-f62b2845cbea,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-b4ae0dd2-1354-49c9-9562-145286e97162,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1015352630-172.17.0.11-1597275044988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33493,DS-24e09177-aa49-4d29-a10f-648f1f09c6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-88d345e2-06b7-40eb-bfe9-ed9cbaf6a401,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-2c5b33b1-63eb-4587-ad07-c5ec7cc78921,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-5030664c-7df7-422e-ac75-9175e48b8e47,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-d1b045c3-12d8-43d8-bb00-849de2d4015e,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-b2d8996c-974b-4565-8054-102dae5f8cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-27e97a92-a4c9-4887-9427-c477c91586f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-af790fa6-d991-42f9-bd1c-901ab2557a19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1015352630-172.17.0.11-1597275044988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33493,DS-24e09177-aa49-4d29-a10f-648f1f09c6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-88d345e2-06b7-40eb-bfe9-ed9cbaf6a401,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-2c5b33b1-63eb-4587-ad07-c5ec7cc78921,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-5030664c-7df7-422e-ac75-9175e48b8e47,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-d1b045c3-12d8-43d8-bb00-849de2d4015e,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-b2d8996c-974b-4565-8054-102dae5f8cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-27e97a92-a4c9-4887-9427-c477c91586f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-af790fa6-d991-42f9-bd1c-901ab2557a19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-191027232-172.17.0.11-1597275314192:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44192,DS-bed650a4-b35f-4366-97ca-167a7e4dfcf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-a319a3fc-41a9-42d8-8003-6a0a6f7fe668,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-27c1d295-37c6-438c-b451-d87516a636ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-55ba6ba3-a549-496e-bd72-34ab0e5cf857,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-77a8c66c-9c0b-4908-9f41-514663d406c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-87b036ee-1922-47af-a037-4bc4917bc623,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-0c34c21e-fcce-414d-9666-85f67d96d5db,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-5b75f9db-342d-4597-8348-d5fb0da84bf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-191027232-172.17.0.11-1597275314192:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44192,DS-bed650a4-b35f-4366-97ca-167a7e4dfcf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-a319a3fc-41a9-42d8-8003-6a0a6f7fe668,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-27c1d295-37c6-438c-b451-d87516a636ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-55ba6ba3-a549-496e-bd72-34ab0e5cf857,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-77a8c66c-9c0b-4908-9f41-514663d406c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-87b036ee-1922-47af-a037-4bc4917bc623,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-0c34c21e-fcce-414d-9666-85f67d96d5db,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-5b75f9db-342d-4597-8348-d5fb0da84bf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-658863721-172.17.0.11-1597276062194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34693,DS-ce16a954-be93-4297-a8d8-37aa14d5fd22,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-777711d9-5a1a-4a05-a092-660a3d2683ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-c10761ed-b9ad-440c-885f-a9e067626187,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-22704891-b819-4988-a225-6d89459597ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-d9b5d248-1219-4780-8e58-79d7fe224cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-8526f856-47c6-4df5-9687-295fe940b477,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-78b1ba05-46f8-4121-bda1-9bef7cb176d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-e721c8f7-2f53-4989-bed8-a594e76c25f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-658863721-172.17.0.11-1597276062194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34693,DS-ce16a954-be93-4297-a8d8-37aa14d5fd22,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-777711d9-5a1a-4a05-a092-660a3d2683ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-c10761ed-b9ad-440c-885f-a9e067626187,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-22704891-b819-4988-a225-6d89459597ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-d9b5d248-1219-4780-8e58-79d7fe224cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-8526f856-47c6-4df5-9687-295fe940b477,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-78b1ba05-46f8-4121-bda1-9bef7cb176d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-e721c8f7-2f53-4989-bed8-a594e76c25f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-426763967-172.17.0.11-1597276275402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44601,DS-f061f3de-28e9-4d6b-a515-b34924e817b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-d5f3c12e-b68a-482c-9561-42093a15be48,DISK], DatanodeInfoWithStorage[127.0.0.1:46636,DS-479e5d7e-ac94-4b4d-8a60-76f7e01a40ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-f1f35cc8-b140-49d9-8416-9e0fba68e55d,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-89e56838-c0ab-47f4-a244-4e255389fccb,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-591aa342-94ca-4ee8-bde2-d1f11390dcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-aa548cc1-0fd4-440c-81a9-1c61849a93ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-69773e1f-70ae-4076-bdb4-e79b6bfa9cec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-426763967-172.17.0.11-1597276275402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44601,DS-f061f3de-28e9-4d6b-a515-b34924e817b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-d5f3c12e-b68a-482c-9561-42093a15be48,DISK], DatanodeInfoWithStorage[127.0.0.1:46636,DS-479e5d7e-ac94-4b4d-8a60-76f7e01a40ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-f1f35cc8-b140-49d9-8416-9e0fba68e55d,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-89e56838-c0ab-47f4-a244-4e255389fccb,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-591aa342-94ca-4ee8-bde2-d1f11390dcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-aa548cc1-0fd4-440c-81a9-1c61849a93ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-69773e1f-70ae-4076-bdb4-e79b6bfa9cec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-706264624-172.17.0.11-1597276536030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39084,DS-e10a28ae-bdbb-4ee2-84ef-6332087cd35b,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-ba3a95ab-d32a-45c7-ab15-6d30d9006296,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-7093ebf9-a88b-41a9-87b4-4feac0d88244,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-bcbeb9de-ec2d-42b4-95a6-58d0d3fd6fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-46b439e5-bc3c-4af7-912c-84baea61b737,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-a6dfcb8a-6c80-4d11-8ca5-2ca8e5cc4207,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-39d82d72-e97b-4e1a-adb2-096acfc0994e,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-95b87f27-c78e-43c7-8642-3ee5391aa996,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-706264624-172.17.0.11-1597276536030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39084,DS-e10a28ae-bdbb-4ee2-84ef-6332087cd35b,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-ba3a95ab-d32a-45c7-ab15-6d30d9006296,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-7093ebf9-a88b-41a9-87b4-4feac0d88244,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-bcbeb9de-ec2d-42b4-95a6-58d0d3fd6fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-46b439e5-bc3c-4af7-912c-84baea61b737,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-a6dfcb8a-6c80-4d11-8ca5-2ca8e5cc4207,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-39d82d72-e97b-4e1a-adb2-096acfc0994e,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-95b87f27-c78e-43c7-8642-3ee5391aa996,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1297583974-172.17.0.11-1597276797816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37598,DS-59014b98-9226-4289-9a3d-631e963b5e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-8f569350-60f5-4723-bab4-168a5e948713,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-1d911b95-cf53-4dab-bf6a-c0e62adae2db,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-3b61459a-45f2-4eee-b4ce-84943f3fa323,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-12497432-f9fe-4126-8b66-cf3257d320d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44674,DS-17fe3c0c-7b89-43bb-b533-382c45ac390c,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-29b3c4e0-a095-4440-9cb1-fd2a09a73a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-77bc6856-f00d-4ae6-9d3b-ba4c8a976e6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1297583974-172.17.0.11-1597276797816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37598,DS-59014b98-9226-4289-9a3d-631e963b5e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-8f569350-60f5-4723-bab4-168a5e948713,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-1d911b95-cf53-4dab-bf6a-c0e62adae2db,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-3b61459a-45f2-4eee-b4ce-84943f3fa323,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-12497432-f9fe-4126-8b66-cf3257d320d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44674,DS-17fe3c0c-7b89-43bb-b533-382c45ac390c,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-29b3c4e0-a095-4440-9cb1-fd2a09a73a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-77bc6856-f00d-4ae6-9d3b-ba4c8a976e6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-312425101-172.17.0.11-1597276883167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46341,DS-c7e73322-7a81-4b5f-883f-c67262af21c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-dc817a40-2046-4625-b4bf-e1942afbe168,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-534c2e20-4062-4f1e-91c9-5188727509d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-4bf8ada9-897e-44bd-a5ff-6cef809d31b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-f2f37a1b-aa27-4728-8382-aa9fb8e0b63a,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-58567faa-beab-49f9-9458-0dec1c0f3085,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-bddf201d-3ea6-4274-aa62-f51a18e78e63,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-dbeafc35-e8ea-4ac1-97d3-8ac8d9c79143,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-312425101-172.17.0.11-1597276883167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46341,DS-c7e73322-7a81-4b5f-883f-c67262af21c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-dc817a40-2046-4625-b4bf-e1942afbe168,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-534c2e20-4062-4f1e-91c9-5188727509d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-4bf8ada9-897e-44bd-a5ff-6cef809d31b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-f2f37a1b-aa27-4728-8382-aa9fb8e0b63a,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-58567faa-beab-49f9-9458-0dec1c0f3085,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-bddf201d-3ea6-4274-aa62-f51a18e78e63,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-dbeafc35-e8ea-4ac1-97d3-8ac8d9c79143,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1903054419-172.17.0.11-1597277292827:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45577,DS-06feae2b-db8e-45bd-ad9b-2d91ebb4f7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-12f99d44-f5f5-4ce7-b609-428cb053e60f,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-a554194b-506e-4c29-ac70-e43eeab83a87,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-e7d53962-c6dc-4e74-91f3-93fe7fe5d904,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-3427a75a-f261-4d93-a0bf-84dfd6fb6b62,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-ca0cc6a3-6ce3-44ad-9057-fbdbdc72dc39,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-758a6faf-b1f5-4142-9ee1-25a2f3173929,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-fdda1c9c-3c6e-4a9b-bb58-d03dcc078689,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1903054419-172.17.0.11-1597277292827:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45577,DS-06feae2b-db8e-45bd-ad9b-2d91ebb4f7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-12f99d44-f5f5-4ce7-b609-428cb053e60f,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-a554194b-506e-4c29-ac70-e43eeab83a87,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-e7d53962-c6dc-4e74-91f3-93fe7fe5d904,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-3427a75a-f261-4d93-a0bf-84dfd6fb6b62,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-ca0cc6a3-6ce3-44ad-9057-fbdbdc72dc39,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-758a6faf-b1f5-4142-9ee1-25a2f3173929,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-fdda1c9c-3c6e-4a9b-bb58-d03dcc078689,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1138440797-172.17.0.11-1597277375474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37690,DS-1f062187-7f4e-449e-92a6-7a6c8261d1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-4503309b-65dc-4b5f-9866-e865a26f8920,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-59fc5583-be71-40b0-804b-0bcaa31ce984,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-bda9eca7-13a3-45c2-92a1-a32d6b998227,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-9377d13c-dd5c-4b94-91e5-81335fb73787,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-e9a064e4-b1f6-4603-8e19-080394ab75fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-830591c2-691c-4696-8ab5-5dfd59cd5322,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-79e87825-ea5a-46db-a281-1449299e1f6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1138440797-172.17.0.11-1597277375474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37690,DS-1f062187-7f4e-449e-92a6-7a6c8261d1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-4503309b-65dc-4b5f-9866-e865a26f8920,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-59fc5583-be71-40b0-804b-0bcaa31ce984,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-bda9eca7-13a3-45c2-92a1-a32d6b998227,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-9377d13c-dd5c-4b94-91e5-81335fb73787,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-e9a064e4-b1f6-4603-8e19-080394ab75fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-830591c2-691c-4696-8ab5-5dfd59cd5322,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-79e87825-ea5a-46db-a281-1449299e1f6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-763250559-172.17.0.11-1597277427185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35832,DS-a8a8f601-4b6c-4e12-b3d4-370de4cdad1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-e9c8a7dd-6ecf-4f70-b9b1-87a83b3707bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-3c4ec081-9dd8-4a18-a1bf-8080a4d65bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-014e20d7-10a4-433e-8363-b5e166a64c16,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-86ff17e4-481f-4b45-b1f3-4166e18e95cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-0d19e8f6-940e-4b68-8de7-c740a7f9e658,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-27f92591-d19d-4195-b49f-6afba0260693,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-27bd10cf-f59d-4ce8-9fc1-e47b2a988861,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-763250559-172.17.0.11-1597277427185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35832,DS-a8a8f601-4b6c-4e12-b3d4-370de4cdad1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-e9c8a7dd-6ecf-4f70-b9b1-87a83b3707bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-3c4ec081-9dd8-4a18-a1bf-8080a4d65bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-014e20d7-10a4-433e-8363-b5e166a64c16,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-86ff17e4-481f-4b45-b1f3-4166e18e95cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-0d19e8f6-940e-4b68-8de7-c740a7f9e658,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-27f92591-d19d-4195-b49f-6afba0260693,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-27bd10cf-f59d-4ce8-9fc1-e47b2a988861,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2126332286-172.17.0.11-1597278345492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41275,DS-3306846f-a082-4a27-b8fa-6ea7c5f96b76,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-5f9c90b2-be0a-4b59-9a3f-c54a7607fa9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-e17550cf-a84f-4ea4-a5fd-72075dc729fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-fe07902e-0bea-44e8-b286-7df0be22beaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-c0794550-c92d-46fb-bbcf-29e421f1fcc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-7f4b1cf7-5f37-439f-bac6-46df8ec482ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-596fbc75-7b44-4359-9d69-65b941eaed9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-405c97bb-89e7-46a6-ba31-cd6f1eb90bc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2126332286-172.17.0.11-1597278345492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41275,DS-3306846f-a082-4a27-b8fa-6ea7c5f96b76,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-5f9c90b2-be0a-4b59-9a3f-c54a7607fa9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-e17550cf-a84f-4ea4-a5fd-72075dc729fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-fe07902e-0bea-44e8-b286-7df0be22beaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-c0794550-c92d-46fb-bbcf-29e421f1fcc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-7f4b1cf7-5f37-439f-bac6-46df8ec482ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-596fbc75-7b44-4359-9d69-65b941eaed9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-405c97bb-89e7-46a6-ba31-cd6f1eb90bc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1922541906-172.17.0.11-1597278513103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42774,DS-c0caac2c-0863-4cfc-8c09-bd8b8866dd53,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-618e6fea-243a-4e31-8ec7-3789c265af47,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-5377b104-2f58-4a04-ae0f-c8d6e07282f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44774,DS-b309a130-b8a3-43b3-b7ae-841f9e91dcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-378cfb61-317d-4cfd-b4ef-f55a1c4fd258,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-d25d4eba-3fbe-4c4f-a3a4-cae56f2916db,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-688ec10a-b346-4acc-8566-dcfa7c85d0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-dc8423e9-e8cf-4e7f-aa24-eb123dba0811,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1922541906-172.17.0.11-1597278513103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42774,DS-c0caac2c-0863-4cfc-8c09-bd8b8866dd53,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-618e6fea-243a-4e31-8ec7-3789c265af47,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-5377b104-2f58-4a04-ae0f-c8d6e07282f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44774,DS-b309a130-b8a3-43b3-b7ae-841f9e91dcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-378cfb61-317d-4cfd-b4ef-f55a1c4fd258,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-d25d4eba-3fbe-4c4f-a3a4-cae56f2916db,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-688ec10a-b346-4acc-8566-dcfa7c85d0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-dc8423e9-e8cf-4e7f-aa24-eb123dba0811,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-185318099-172.17.0.11-1597279174994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44712,DS-b9b091eb-9e17-42c8-9146-5d256438ee8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-616e2010-e356-4ce8-99ba-b021b4805acc,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-6da6a35d-e506-4752-af71-060732de9005,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-72b2d2af-77c5-4a77-ac85-5575086612f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-186faffe-e653-4554-a1a9-573dfcb75d77,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-65f102e6-4ef6-467c-a1cd-5bd0b59ace44,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-7121e324-eb3c-4249-b28f-2d4520f913f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38360,DS-d6275c38-67fd-4ebd-b68b-4d100f8de10a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-185318099-172.17.0.11-1597279174994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44712,DS-b9b091eb-9e17-42c8-9146-5d256438ee8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-616e2010-e356-4ce8-99ba-b021b4805acc,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-6da6a35d-e506-4752-af71-060732de9005,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-72b2d2af-77c5-4a77-ac85-5575086612f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-186faffe-e653-4554-a1a9-573dfcb75d77,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-65f102e6-4ef6-467c-a1cd-5bd0b59ace44,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-7121e324-eb3c-4249-b28f-2d4520f913f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38360,DS-d6275c38-67fd-4ebd-b68b-4d100f8de10a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-177276588-172.17.0.11-1597279302619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37364,DS-8703eca3-8d58-44ee-a018-256e309ef0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-26a04040-b519-4bd4-8564-813de5d3503d,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-a94fdf4c-bb72-43e0-b2bc-a1bcfd74db41,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-2bcf5d55-33e0-459d-b329-751067172eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-ac08c5b5-53e2-4a12-8f43-ea782d7d7325,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-01e841a7-e3d6-4252-944e-2cb825fafecd,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-31353e1c-1f06-41ed-9fdb-181ee97428d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-e3cb21a6-2c35-41a5-aef6-c35462dceb9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-177276588-172.17.0.11-1597279302619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37364,DS-8703eca3-8d58-44ee-a018-256e309ef0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-26a04040-b519-4bd4-8564-813de5d3503d,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-a94fdf4c-bb72-43e0-b2bc-a1bcfd74db41,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-2bcf5d55-33e0-459d-b329-751067172eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-ac08c5b5-53e2-4a12-8f43-ea782d7d7325,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-01e841a7-e3d6-4252-944e-2cb825fafecd,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-31353e1c-1f06-41ed-9fdb-181ee97428d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-e3cb21a6-2c35-41a5-aef6-c35462dceb9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2003859532-172.17.0.11-1597279476298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37910,DS-1a20cb6a-800d-4979-9cb7-78fc4afdc4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-ea3229e0-1617-4667-98f6-affe018eb0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-f0b35d5a-ddb0-40ec-8126-595ab4403789,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-717fa130-6630-4889-96ec-5f2dfc5e7785,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-064f4cd5-340c-409f-9069-1dbc3270ae01,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-8601dca1-5051-4995-8ffe-9c572b41b3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-d1779276-9ea8-4cb4-94dd-ad789185e14e,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-712cf246-1da8-4de3-ab72-8263aba57989,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2003859532-172.17.0.11-1597279476298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37910,DS-1a20cb6a-800d-4979-9cb7-78fc4afdc4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-ea3229e0-1617-4667-98f6-affe018eb0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-f0b35d5a-ddb0-40ec-8126-595ab4403789,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-717fa130-6630-4889-96ec-5f2dfc5e7785,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-064f4cd5-340c-409f-9069-1dbc3270ae01,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-8601dca1-5051-4995-8ffe-9c572b41b3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-d1779276-9ea8-4cb4-94dd-ad789185e14e,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-712cf246-1da8-4de3-ab72-8263aba57989,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6611
