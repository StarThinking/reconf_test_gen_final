reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-265173523-172.17.0.6-1597578562765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44108,DS-0a3a6997-8168-4184-b29b-4964eb43576a,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-7d3a0515-caf8-4075-8785-5418d1a493af,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-44329cfa-8639-4a34-8cc2-763739ac6ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-0d643ccf-327f-4a18-b39c-582643e21f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-cff78c24-837b-4763-8688-197930ae2f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-109be173-e220-4aa4-98c5-34031062c9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-db20ea4e-b35d-4ef7-b042-a9f47b9843ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-8713be6b-468c-4b77-b27a-7c711eefb3b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-265173523-172.17.0.6-1597578562765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44108,DS-0a3a6997-8168-4184-b29b-4964eb43576a,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-7d3a0515-caf8-4075-8785-5418d1a493af,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-44329cfa-8639-4a34-8cc2-763739ac6ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-0d643ccf-327f-4a18-b39c-582643e21f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-cff78c24-837b-4763-8688-197930ae2f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-109be173-e220-4aa4-98c5-34031062c9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-db20ea4e-b35d-4ef7-b042-a9f47b9843ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-8713be6b-468c-4b77-b27a-7c711eefb3b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-323043296-172.17.0.6-1597578642001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35404,DS-8a204968-1068-41c7-8332-3085c94fa393,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-a6cb43c2-752b-46dd-9b6e-890b98bfbbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-5aae4315-0e29-44a3-b790-1123ea3f2d57,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-c0b1b31a-359b-4f7b-bb50-156e14c9fb20,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-d5321b73-3918-424b-8717-6f74035cbe14,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-763d965f-236d-4600-ba4d-9e981946c287,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-32992afb-8d38-46b1-99f4-5d6a250f29cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-81901463-2ed7-4d9f-a6ae-79313b3d7f62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-323043296-172.17.0.6-1597578642001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35404,DS-8a204968-1068-41c7-8332-3085c94fa393,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-a6cb43c2-752b-46dd-9b6e-890b98bfbbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-5aae4315-0e29-44a3-b790-1123ea3f2d57,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-c0b1b31a-359b-4f7b-bb50-156e14c9fb20,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-d5321b73-3918-424b-8717-6f74035cbe14,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-763d965f-236d-4600-ba4d-9e981946c287,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-32992afb-8d38-46b1-99f4-5d6a250f29cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-81901463-2ed7-4d9f-a6ae-79313b3d7f62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1965634885-172.17.0.6-1597579101393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40127,DS-2b421acf-12d9-4e10-b1bf-833dcad0b029,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-b8242184-8a0f-4536-a0b7-76b86bd118ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-7987c997-f13a-4e4b-bc09-f84db32d022b,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-b81548b3-d116-4670-a190-88191b5df3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-9e74d417-4620-4ba4-b777-fa02ea9a147b,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-242feb1d-38ff-4196-bb7b-da77f14829ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-4641c2da-4734-47e5-8890-d4b5b51f63f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-68020a10-a77e-4676-8d7d-fc9d19780538,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1965634885-172.17.0.6-1597579101393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40127,DS-2b421acf-12d9-4e10-b1bf-833dcad0b029,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-b8242184-8a0f-4536-a0b7-76b86bd118ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-7987c997-f13a-4e4b-bc09-f84db32d022b,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-b81548b3-d116-4670-a190-88191b5df3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-9e74d417-4620-4ba4-b777-fa02ea9a147b,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-242feb1d-38ff-4196-bb7b-da77f14829ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-4641c2da-4734-47e5-8890-d4b5b51f63f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-68020a10-a77e-4676-8d7d-fc9d19780538,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-982904603-172.17.0.6-1597579137000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41177,DS-62857786-2983-49db-9fca-421e61cf7f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-2436fba4-9141-4497-a950-297a5389460e,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-1bb34160-c295-4e98-afe1-b79598a29ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-da1a52ac-a6b8-4e31-ace6-72e1136b6bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-cbc39a8b-d7c5-4bea-a1a6-0366460bb7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-4b4a9fe0-efe6-4cc5-8108-3018c9a34158,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-b6a89c05-16e7-44b2-a782-ab730732ddb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-08d66da0-eb9b-4937-99dd-dc3a02365023,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-982904603-172.17.0.6-1597579137000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41177,DS-62857786-2983-49db-9fca-421e61cf7f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-2436fba4-9141-4497-a950-297a5389460e,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-1bb34160-c295-4e98-afe1-b79598a29ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-da1a52ac-a6b8-4e31-ace6-72e1136b6bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-cbc39a8b-d7c5-4bea-a1a6-0366460bb7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-4b4a9fe0-efe6-4cc5-8108-3018c9a34158,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-b6a89c05-16e7-44b2-a782-ab730732ddb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-08d66da0-eb9b-4937-99dd-dc3a02365023,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2078109213-172.17.0.6-1597579350637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38772,DS-70b0bf96-c096-4869-b373-f85cdb58c55d,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-52bfdbd8-e600-40aa-842f-c4d1a9f54516,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-1bebb78c-d209-4b10-b883-08c394da145d,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-a7e26c1c-7cdf-492e-ad65-2efbf0ce368d,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-2e9e113e-70c2-4622-8c10-501c52c87f87,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-fdb5573f-e206-4cdd-9a6b-2bae9cc5426c,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-0c144465-99d1-4303-a933-357652881755,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-4a2daaf7-6f65-4211-afbd-d19284ab1143,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2078109213-172.17.0.6-1597579350637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38772,DS-70b0bf96-c096-4869-b373-f85cdb58c55d,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-52bfdbd8-e600-40aa-842f-c4d1a9f54516,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-1bebb78c-d209-4b10-b883-08c394da145d,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-a7e26c1c-7cdf-492e-ad65-2efbf0ce368d,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-2e9e113e-70c2-4622-8c10-501c52c87f87,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-fdb5573f-e206-4cdd-9a6b-2bae9cc5426c,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-0c144465-99d1-4303-a933-357652881755,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-4a2daaf7-6f65-4211-afbd-d19284ab1143,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1100018997-172.17.0.6-1597579597334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46862,DS-a79109fc-7eb0-4eb2-8220-f603a5066362,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-2e340ab3-4feb-4d0a-a76d-f3a37ff9a2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-fed18830-22d9-41e2-b078-e039cea6a5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-9e869a5d-a5d1-4aa8-8593-fc86bc05d12b,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-109ad6f0-fc91-46ae-87ee-a006cc531722,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-edcc83a9-f551-4760-af3e-8e70bd3ee458,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-12e6e6d0-a982-4845-906f-e896a5b6ec79,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-6ab5e064-7b24-49f1-8ebd-b8007a652421,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1100018997-172.17.0.6-1597579597334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46862,DS-a79109fc-7eb0-4eb2-8220-f603a5066362,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-2e340ab3-4feb-4d0a-a76d-f3a37ff9a2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-fed18830-22d9-41e2-b078-e039cea6a5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-9e869a5d-a5d1-4aa8-8593-fc86bc05d12b,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-109ad6f0-fc91-46ae-87ee-a006cc531722,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-edcc83a9-f551-4760-af3e-8e70bd3ee458,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-12e6e6d0-a982-4845-906f-e896a5b6ec79,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-6ab5e064-7b24-49f1-8ebd-b8007a652421,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-528968845-172.17.0.6-1597580947353:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40953,DS-b71fd6f4-7764-4269-b5e7-90b27259fb81,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-548dfb72-ad0b-40ff-8b78-607856cededd,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-303fa8f4-c85b-4399-afce-10f081a8c52a,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-07f495d2-8847-470a-aaff-d06b37ea0201,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-64d29812-0b38-4137-bef6-7135c6f426e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-9129fb03-714f-499d-9f94-bb54771d3b78,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-2f6215d5-1da7-496d-a86c-1bfaa488e39e,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-1fb35ebb-3002-4a1f-ab9d-e659bd97eaa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-528968845-172.17.0.6-1597580947353:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40953,DS-b71fd6f4-7764-4269-b5e7-90b27259fb81,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-548dfb72-ad0b-40ff-8b78-607856cededd,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-303fa8f4-c85b-4399-afce-10f081a8c52a,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-07f495d2-8847-470a-aaff-d06b37ea0201,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-64d29812-0b38-4137-bef6-7135c6f426e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-9129fb03-714f-499d-9f94-bb54771d3b78,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-2f6215d5-1da7-496d-a86c-1bfaa488e39e,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-1fb35ebb-3002-4a1f-ab9d-e659bd97eaa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2018372197-172.17.0.6-1597580997120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41414,DS-d002f5fb-e44c-4d8b-a3f4-b314271747b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-4933123a-f497-4579-a485-ca56a3b5a861,DISK], DatanodeInfoWithStorage[127.0.0.1:42347,DS-649f1480-9c9b-4d9d-b86f-cedcb60c395d,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-5f8ef6d6-0f04-4f84-aa77-5d9bef5e74bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-6a48fe29-9ad1-4f84-9d0c-b5c8cd3eed61,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-2c4d851a-e84f-479c-8ec8-7924f4835c27,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-a5d646a9-43b5-4ea8-8365-386459f1c512,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-2a663bad-33bd-4581-aede-1b9d35ddb8d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2018372197-172.17.0.6-1597580997120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41414,DS-d002f5fb-e44c-4d8b-a3f4-b314271747b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-4933123a-f497-4579-a485-ca56a3b5a861,DISK], DatanodeInfoWithStorage[127.0.0.1:42347,DS-649f1480-9c9b-4d9d-b86f-cedcb60c395d,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-5f8ef6d6-0f04-4f84-aa77-5d9bef5e74bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-6a48fe29-9ad1-4f84-9d0c-b5c8cd3eed61,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-2c4d851a-e84f-479c-8ec8-7924f4835c27,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-a5d646a9-43b5-4ea8-8365-386459f1c512,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-2a663bad-33bd-4581-aede-1b9d35ddb8d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-367249452-172.17.0.6-1597581276242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42713,DS-238ff167-b0d8-4c6a-8291-6c16db057cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-c106afe7-60b8-4793-9158-b2bfe3b8dc77,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-f004e6e5-d3c1-4a35-95a5-5d21a50dd41c,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-eaa87b07-3d5c-4d1b-a852-e8689625d755,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-2b94c0c0-d792-4393-a564-c797ae35a018,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-8f491e04-e0ce-4660-b230-77b141615874,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-c1194045-94e0-4c45-824e-07aa0491b147,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-d7b4b35e-569b-4ce4-841a-32263ff12f01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-367249452-172.17.0.6-1597581276242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42713,DS-238ff167-b0d8-4c6a-8291-6c16db057cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-c106afe7-60b8-4793-9158-b2bfe3b8dc77,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-f004e6e5-d3c1-4a35-95a5-5d21a50dd41c,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-eaa87b07-3d5c-4d1b-a852-e8689625d755,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-2b94c0c0-d792-4393-a564-c797ae35a018,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-8f491e04-e0ce-4660-b230-77b141615874,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-c1194045-94e0-4c45-824e-07aa0491b147,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-d7b4b35e-569b-4ce4-841a-32263ff12f01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1504849767-172.17.0.6-1597581505708:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33081,DS-bca67c9a-13b4-436d-922a-ed9f88ab0f03,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-9c2263d2-45fd-4737-b73a-61ce9c78461a,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-956aaf15-0b80-4dfc-8df6-669df448a738,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-7570aa60-b912-41d4-a192-281bbcd65581,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-20bd0785-aa48-4669-802d-020679684c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-721d4443-2ca8-403a-a9e6-18ae8b646322,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-50ca18f6-72cb-46dd-b2b6-6c519223f78c,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-bc478d21-6c5c-4341-ae91-ea5aac678d66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1504849767-172.17.0.6-1597581505708:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33081,DS-bca67c9a-13b4-436d-922a-ed9f88ab0f03,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-9c2263d2-45fd-4737-b73a-61ce9c78461a,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-956aaf15-0b80-4dfc-8df6-669df448a738,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-7570aa60-b912-41d4-a192-281bbcd65581,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-20bd0785-aa48-4669-802d-020679684c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-721d4443-2ca8-403a-a9e6-18ae8b646322,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-50ca18f6-72cb-46dd-b2b6-6c519223f78c,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-bc478d21-6c5c-4341-ae91-ea5aac678d66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-6139114-172.17.0.6-1597581539326:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33140,DS-d6455e04-a737-40d0-87b9-73ce61f63bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-5e12ce4e-15d7-4c50-bb02-4cd1f8415edb,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-a23c5b74-ff1b-4b06-922b-e47e89f07adf,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-e939ec90-b9a7-4a17-8836-65940fbc20b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-572f0013-d97f-4ab6-8230-0003ecda5783,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-ce8a0835-47f5-44e6-87d4-74c88bdb5ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-3aa42769-c498-4956-baf4-6a399c21ebbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-5b5a37d2-9af7-4e8c-b894-beac7e4e8857,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-6139114-172.17.0.6-1597581539326:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33140,DS-d6455e04-a737-40d0-87b9-73ce61f63bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-5e12ce4e-15d7-4c50-bb02-4cd1f8415edb,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-a23c5b74-ff1b-4b06-922b-e47e89f07adf,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-e939ec90-b9a7-4a17-8836-65940fbc20b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-572f0013-d97f-4ab6-8230-0003ecda5783,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-ce8a0835-47f5-44e6-87d4-74c88bdb5ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-3aa42769-c498-4956-baf4-6a399c21ebbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-5b5a37d2-9af7-4e8c-b894-beac7e4e8857,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-90261696-172.17.0.6-1597581799667:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34243,DS-168a2183-cb27-468c-a53c-a4804a71c798,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-4dfe286e-8285-4f05-a8ee-77c3b38bec30,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-5ba810c5-b2c2-47d1-b2b1-83a37f5d8dee,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-be29f248-df9d-4eb5-a9c4-64a67ec0a75e,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-7b86d3b3-3f47-4b07-8abf-a8c29709ff66,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-3d66a976-06e8-4c44-a743-01db6198fe53,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-c3a9ebc7-3ca9-4f7c-9ef8-1115658675df,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-176bd971-7022-4b1a-a587-fedc6fc0ad2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-90261696-172.17.0.6-1597581799667:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34243,DS-168a2183-cb27-468c-a53c-a4804a71c798,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-4dfe286e-8285-4f05-a8ee-77c3b38bec30,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-5ba810c5-b2c2-47d1-b2b1-83a37f5d8dee,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-be29f248-df9d-4eb5-a9c4-64a67ec0a75e,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-7b86d3b3-3f47-4b07-8abf-a8c29709ff66,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-3d66a976-06e8-4c44-a743-01db6198fe53,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-c3a9ebc7-3ca9-4f7c-9ef8-1115658675df,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-176bd971-7022-4b1a-a587-fedc6fc0ad2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 32768
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1771793073-172.17.0.6-1597581995906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34055,DS-391e9061-ed0c-4d40-a7e1-c4a047c4822b,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-c300e01f-9909-4a5f-a374-e66c95bb7585,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-4add187a-2f73-4bf1-b5f7-46a063b462e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-fe5a3dad-29b3-4f61-906b-36c386864791,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-0e7cc2d6-cd28-464a-9d6d-69f715d35333,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-ab041d6d-7c22-4a51-a427-2a542579e9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-f4e58fe2-0d47-476a-a28d-cd613b30545f,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-f374eb93-d043-4dbd-95c9-164f12acf1db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1771793073-172.17.0.6-1597581995906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34055,DS-391e9061-ed0c-4d40-a7e1-c4a047c4822b,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-c300e01f-9909-4a5f-a374-e66c95bb7585,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-4add187a-2f73-4bf1-b5f7-46a063b462e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-fe5a3dad-29b3-4f61-906b-36c386864791,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-0e7cc2d6-cd28-464a-9d6d-69f715d35333,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-ab041d6d-7c22-4a51-a427-2a542579e9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-f4e58fe2-0d47-476a-a28d-cd613b30545f,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-f374eb93-d043-4dbd-95c9-164f12acf1db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 3609
