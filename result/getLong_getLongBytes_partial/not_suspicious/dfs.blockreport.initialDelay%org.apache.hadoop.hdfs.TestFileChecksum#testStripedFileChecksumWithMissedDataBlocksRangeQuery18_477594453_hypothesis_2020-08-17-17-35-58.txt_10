reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1717231083-172.17.0.4-1597686163421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35497,DS-8bd55cf7-b80b-4c44-9963-16b4afd96b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-cbde7b08-f952-46c0-bee3-efec63bb08f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-fa4aef83-08a4-4659-becf-d6cab0590c17,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-5505ad5c-ddc6-435b-bfad-1161600b5ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-8d606a6b-f259-42f7-9a31-8b8fccb6feef,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-4298e215-9016-442a-a0e3-3f757b5ced11,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-94c16fea-462b-46b8-982e-7d2d6679561e,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-6e8e901f-4d6b-4ef5-9d1c-1e38cab84bd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1717231083-172.17.0.4-1597686163421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35497,DS-8bd55cf7-b80b-4c44-9963-16b4afd96b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-cbde7b08-f952-46c0-bee3-efec63bb08f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-fa4aef83-08a4-4659-becf-d6cab0590c17,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-5505ad5c-ddc6-435b-bfad-1161600b5ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-8d606a6b-f259-42f7-9a31-8b8fccb6feef,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-4298e215-9016-442a-a0e3-3f757b5ced11,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-94c16fea-462b-46b8-982e-7d2d6679561e,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-6e8e901f-4d6b-4ef5-9d1c-1e38cab84bd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-644724303-172.17.0.4-1597686395253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33400,DS-e615d749-1985-49da-b232-3e75b01f999a,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-ede0275e-c970-4527-9270-3a24bb985750,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-99f902e3-e46f-4a3a-a1a6-df6be92ac83a,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-3b53d7a7-e91e-4dca-b21f-0b3242c58aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-200ccbf7-623c-435b-95c2-baead142c46d,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-ba0fce92-7416-4382-86f8-803b30ecd65c,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-3c9a1049-efcd-43be-a105-31176b7b979f,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-e9e954f4-dc5a-4529-94e1-623ceedb16ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-644724303-172.17.0.4-1597686395253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33400,DS-e615d749-1985-49da-b232-3e75b01f999a,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-ede0275e-c970-4527-9270-3a24bb985750,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-99f902e3-e46f-4a3a-a1a6-df6be92ac83a,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-3b53d7a7-e91e-4dca-b21f-0b3242c58aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-200ccbf7-623c-435b-95c2-baead142c46d,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-ba0fce92-7416-4382-86f8-803b30ecd65c,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-3c9a1049-efcd-43be-a105-31176b7b979f,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-e9e954f4-dc5a-4529-94e1-623ceedb16ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-577629085-172.17.0.4-1597686972782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46760,DS-9097a94e-d5c4-4cb7-8138-c95b4577aab6,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-c284d943-2add-4a5a-aad5-367804ade64b,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-4ea6c404-daca-4cc4-9054-2348d424d844,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-5a367ac2-b952-42ac-b6ed-27c46bbd4a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-9a7ab541-f040-4d82-a5e3-f01979e4ba3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-041c034c-3df2-4853-85e1-6f2f5ca8f6af,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-87a75620-0037-4024-a014-59ae358d65f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-58c17457-d1b8-4a2d-9dc9-bf1441164681,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-577629085-172.17.0.4-1597686972782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46760,DS-9097a94e-d5c4-4cb7-8138-c95b4577aab6,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-c284d943-2add-4a5a-aad5-367804ade64b,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-4ea6c404-daca-4cc4-9054-2348d424d844,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-5a367ac2-b952-42ac-b6ed-27c46bbd4a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-9a7ab541-f040-4d82-a5e3-f01979e4ba3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-041c034c-3df2-4853-85e1-6f2f5ca8f6af,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-87a75620-0037-4024-a014-59ae358d65f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-58c17457-d1b8-4a2d-9dc9-bf1441164681,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1204435164-172.17.0.4-1597687004808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33633,DS-0953a793-ab59-467f-8b6e-741ef6fac84c,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-c0c4d149-f70b-4910-818d-a2a1d34ffb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-be03f2b9-13b8-41dc-a3b5-bcbb0692b503,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-0337dbbc-670f-47ca-8150-fab61f7784a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-55c7897b-595f-4e19-ad00-eab3265ad76e,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-e8a4581d-32ac-4e44-aa78-6e4d7497f50b,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-1a8a3487-df9a-49e8-bdc9-2f12df2df746,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-710a4f62-3ae7-4daf-bae0-b86f4045c99b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1204435164-172.17.0.4-1597687004808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33633,DS-0953a793-ab59-467f-8b6e-741ef6fac84c,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-c0c4d149-f70b-4910-818d-a2a1d34ffb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-be03f2b9-13b8-41dc-a3b5-bcbb0692b503,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-0337dbbc-670f-47ca-8150-fab61f7784a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-55c7897b-595f-4e19-ad00-eab3265ad76e,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-e8a4581d-32ac-4e44-aa78-6e4d7497f50b,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-1a8a3487-df9a-49e8-bdc9-2f12df2df746,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-710a4f62-3ae7-4daf-bae0-b86f4045c99b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-986712863-172.17.0.4-1597687080933:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34699,DS-ec0e404d-8b68-4c68-b258-d9bf8451e368,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-5f19efa6-9ed5-4157-8d87-35c905e72938,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-7104a823-5c82-4e7a-b84e-382fb349c4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-2817ba47-8a88-47e1-acef-cd035e123201,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-f846bc0d-8433-489b-853f-167d355dd706,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-4484fb0b-8ee1-475f-a073-ce475159ed2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-e1d3514f-4d9c-41fe-a219-8d5130a7219a,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-d8c3c909-cbc2-43ba-b43c-565c93d2bab7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-986712863-172.17.0.4-1597687080933:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34699,DS-ec0e404d-8b68-4c68-b258-d9bf8451e368,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-5f19efa6-9ed5-4157-8d87-35c905e72938,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-7104a823-5c82-4e7a-b84e-382fb349c4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-2817ba47-8a88-47e1-acef-cd035e123201,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-f846bc0d-8433-489b-853f-167d355dd706,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-4484fb0b-8ee1-475f-a073-ce475159ed2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-e1d3514f-4d9c-41fe-a219-8d5130a7219a,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-d8c3c909-cbc2-43ba-b43c-565c93d2bab7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1965253157-172.17.0.4-1597687204002:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42662,DS-82526cbf-1f9d-4293-85a2-443a827c8073,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-9849a83b-b304-4a19-ab0f-63ad1b52c89e,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-cfda1f99-7748-4a07-aa92-b0bf8d54eb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-24d6f3ae-1f41-42d7-b06b-61c5e69acbe7,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-a77aa185-fbdd-477d-b2d1-b2c773c08b52,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-1ff45527-d9a8-4d61-9a0e-a0d9ecc3f038,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-52131b65-8783-4e47-9ed9-09f8bc410fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-91eac55e-91f5-44c7-bcac-01ee0065ded9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1965253157-172.17.0.4-1597687204002:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42662,DS-82526cbf-1f9d-4293-85a2-443a827c8073,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-9849a83b-b304-4a19-ab0f-63ad1b52c89e,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-cfda1f99-7748-4a07-aa92-b0bf8d54eb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-24d6f3ae-1f41-42d7-b06b-61c5e69acbe7,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-a77aa185-fbdd-477d-b2d1-b2c773c08b52,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-1ff45527-d9a8-4d61-9a0e-a0d9ecc3f038,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-52131b65-8783-4e47-9ed9-09f8bc410fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-91eac55e-91f5-44c7-bcac-01ee0065ded9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1370739014-172.17.0.4-1597687798795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43559,DS-cb7fff43-e4c3-4f16-b5d2-31f21fd5c16f,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-64c08ac0-b5dc-4f25-aad5-71764443878c,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-e1bb6c91-a128-4806-819e-2a81dbcb4d79,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-9c8db43c-36c7-48e9-b999-3c9f101b5f06,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-3c5d9826-cc4a-4881-b9e0-bda5b29aa5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-38577faa-1ce5-46f5-b9af-fc3d75716e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-694630b0-0a2b-46a8-b72d-6d8dd11fee4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-73b1a948-13f7-4962-87a0-cb631cede63f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1370739014-172.17.0.4-1597687798795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43559,DS-cb7fff43-e4c3-4f16-b5d2-31f21fd5c16f,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-64c08ac0-b5dc-4f25-aad5-71764443878c,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-e1bb6c91-a128-4806-819e-2a81dbcb4d79,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-9c8db43c-36c7-48e9-b999-3c9f101b5f06,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-3c5d9826-cc4a-4881-b9e0-bda5b29aa5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-38577faa-1ce5-46f5-b9af-fc3d75716e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-694630b0-0a2b-46a8-b72d-6d8dd11fee4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-73b1a948-13f7-4962-87a0-cb631cede63f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2028974244-172.17.0.4-1597687875338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39873,DS-bcdbd64e-599c-42a5-baf2-9c5babe69b53,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-65fc135d-310e-42ef-bc16-3abea830f6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-62c17b6d-7be2-4ea0-b490-9fb9cb4a45d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-1cede20d-4bc0-48c0-a13b-1b2c8f92d131,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-bd159b5f-9be4-4f03-b88c-4db7ed6fdc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-e34e4892-a7da-4e17-b674-da98fd7fb54b,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-606cb2c0-98b3-4d73-ac72-cbdfaf8ca352,DISK], DatanodeInfoWithStorage[127.0.0.1:35738,DS-5be01ae2-9ace-44f0-bcf9-61efb4650e23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2028974244-172.17.0.4-1597687875338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39873,DS-bcdbd64e-599c-42a5-baf2-9c5babe69b53,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-65fc135d-310e-42ef-bc16-3abea830f6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-62c17b6d-7be2-4ea0-b490-9fb9cb4a45d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-1cede20d-4bc0-48c0-a13b-1b2c8f92d131,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-bd159b5f-9be4-4f03-b88c-4db7ed6fdc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-e34e4892-a7da-4e17-b674-da98fd7fb54b,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-606cb2c0-98b3-4d73-ac72-cbdfaf8ca352,DISK], DatanodeInfoWithStorage[127.0.0.1:35738,DS-5be01ae2-9ace-44f0-bcf9-61efb4650e23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1356981036-172.17.0.4-1597688147303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36087,DS-a5decbc1-2c4e-4ee3-ad4d-e7b0d7f2ed8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-525f42f9-46f3-478d-9397-a236c7555cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-d8fd4737-5a85-4182-acf0-f6ac5139d57a,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-1dd023db-3435-4864-8425-cfc1831af5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-7ae8d64a-39f1-4a8d-9cc5-103998735405,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-76464c45-8d35-406e-9e16-2a061c2ef9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-0a6eb1f2-7652-4331-ae06-19ba2066e036,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-3358f366-1c54-4961-a8ac-f5680a017007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1356981036-172.17.0.4-1597688147303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36087,DS-a5decbc1-2c4e-4ee3-ad4d-e7b0d7f2ed8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-525f42f9-46f3-478d-9397-a236c7555cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-d8fd4737-5a85-4182-acf0-f6ac5139d57a,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-1dd023db-3435-4864-8425-cfc1831af5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-7ae8d64a-39f1-4a8d-9cc5-103998735405,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-76464c45-8d35-406e-9e16-2a061c2ef9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-0a6eb1f2-7652-4331-ae06-19ba2066e036,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-3358f366-1c54-4961-a8ac-f5680a017007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-682494342-172.17.0.4-1597688445447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32832,DS-d3e8ba3d-940c-456a-99b4-b4843639b5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-856e7278-e76c-42d6-890b-6b84aff4dbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-b699474c-439d-4cc9-8b49-2019ff4dcf6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-00e660a4-9077-41e8-b30c-76fde42e7a85,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-43ba87ad-079d-42c1-ab05-9eb07a7106b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-fdb4cf37-f122-4e3c-892d-e77259e5f993,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-9435547e-0811-44d8-924a-1a018f8305ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-27e2c26b-8c98-4ad5-b930-ece9dafaafbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-682494342-172.17.0.4-1597688445447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32832,DS-d3e8ba3d-940c-456a-99b4-b4843639b5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-856e7278-e76c-42d6-890b-6b84aff4dbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-b699474c-439d-4cc9-8b49-2019ff4dcf6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-00e660a4-9077-41e8-b30c-76fde42e7a85,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-43ba87ad-079d-42c1-ab05-9eb07a7106b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-fdb4cf37-f122-4e3c-892d-e77259e5f993,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-9435547e-0811-44d8-924a-1a018f8305ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-27e2c26b-8c98-4ad5-b930-ece9dafaafbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1222125025-172.17.0.4-1597688934974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37303,DS-67a26c55-3b77-4463-ace1-646350bdb654,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-cb34a5cd-4a54-43f4-be43-f3879fc6368f,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-426bcf26-9cd8-4ca5-92f4-f97c7210c190,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-3437aba0-644f-45fb-b126-5644f9fb518b,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-5a041674-0182-407a-be6c-b53003594316,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-33a8d9c9-9c34-416b-ae2c-a2f35d74ffe2,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-2089f415-8c87-4857-9cda-6c9a2728683b,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-400fd364-72b4-4537-9e5f-a34b17dcf8e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1222125025-172.17.0.4-1597688934974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37303,DS-67a26c55-3b77-4463-ace1-646350bdb654,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-cb34a5cd-4a54-43f4-be43-f3879fc6368f,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-426bcf26-9cd8-4ca5-92f4-f97c7210c190,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-3437aba0-644f-45fb-b126-5644f9fb518b,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-5a041674-0182-407a-be6c-b53003594316,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-33a8d9c9-9c34-416b-ae2c-a2f35d74ffe2,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-2089f415-8c87-4857-9cda-6c9a2728683b,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-400fd364-72b4-4537-9e5f-a34b17dcf8e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057013905-172.17.0.4-1597689046914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45833,DS-33ea770e-d11b-40c2-8cc5-4fd1bab59f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-0eb288c8-c971-41a4-bd76-7e8840bdca2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-105d2369-2101-4304-b6b4-87e5283bd478,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-cdcb89cc-4d84-4795-acda-8a4a7c3aa98f,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-f90fe839-da43-4bab-9d63-3555284d15a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-6d4238d9-27d8-4b56-b6e0-5b2b9ccc209a,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-36f40672-d39d-4c6d-aadd-81e996807767,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-a3a3100a-34b0-4fb5-a7c6-598d65bc84e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057013905-172.17.0.4-1597689046914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45833,DS-33ea770e-d11b-40c2-8cc5-4fd1bab59f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-0eb288c8-c971-41a4-bd76-7e8840bdca2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-105d2369-2101-4304-b6b4-87e5283bd478,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-cdcb89cc-4d84-4795-acda-8a4a7c3aa98f,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-f90fe839-da43-4bab-9d63-3555284d15a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-6d4238d9-27d8-4b56-b6e0-5b2b9ccc209a,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-36f40672-d39d-4c6d-aadd-81e996807767,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-a3a3100a-34b0-4fb5-a7c6-598d65bc84e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1094401384-172.17.0.4-1597689556496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35992,DS-d33b3be6-a21c-4e18-ab32-cd35b9deb78f,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-da001232-fd17-4bf6-82db-12c490d7bce5,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-c161bebe-3e14-480b-9def-084cf52780a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-1ab6cccb-7404-478d-89e2-72a0820069bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-e63e883c-4f15-49a4-8099-c962dd2f5d22,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-6caf30a0-8db3-4322-8ccb-7a89ad03610e,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-8b222c53-5ab6-4de0-b1f7-7f8cabdf9b66,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-bcc4ea19-8420-4029-8bbe-29b2ef52d28b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1094401384-172.17.0.4-1597689556496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35992,DS-d33b3be6-a21c-4e18-ab32-cd35b9deb78f,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-da001232-fd17-4bf6-82db-12c490d7bce5,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-c161bebe-3e14-480b-9def-084cf52780a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-1ab6cccb-7404-478d-89e2-72a0820069bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-e63e883c-4f15-49a4-8099-c962dd2f5d22,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-6caf30a0-8db3-4322-8ccb-7a89ad03610e,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-8b222c53-5ab6-4de0-b1f7-7f8cabdf9b66,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-bcc4ea19-8420-4029-8bbe-29b2ef52d28b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1003177482-172.17.0.4-1597690125137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44548,DS-0e021147-7247-434f-9cc4-345af8b99c74,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-a67cd147-ce0e-4716-9a94-80c9e8313378,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-3ceae079-efe5-49cd-8f2d-ec21c6bb7f92,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-e98d5bbd-81d9-4050-a2f3-670760842d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-11b78396-ead3-4a74-bfe5-c484edc86413,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-5853a945-01a6-4231-aa9e-68acce0b8a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-9d50cd9a-c6bb-4c6d-bc20-71aa64cd0ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-5deb42c9-80c4-4b40-a72c-f47a792ec607,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1003177482-172.17.0.4-1597690125137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44548,DS-0e021147-7247-434f-9cc4-345af8b99c74,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-a67cd147-ce0e-4716-9a94-80c9e8313378,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-3ceae079-efe5-49cd-8f2d-ec21c6bb7f92,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-e98d5bbd-81d9-4050-a2f3-670760842d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-11b78396-ead3-4a74-bfe5-c484edc86413,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-5853a945-01a6-4231-aa9e-68acce0b8a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-9d50cd9a-c6bb-4c6d-bc20-71aa64cd0ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-5deb42c9-80c4-4b40-a72c-f47a792ec607,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-683917871-172.17.0.4-1597690911818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39163,DS-224b87a4-1ed9-484f-a192-aa4161a6e226,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-b62d3605-a7cf-4369-9394-fded4cef48bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-ac38d1a3-3aa5-475e-85be-e6d4132f4580,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-44cd7e5d-8208-47f3-ad4e-ae37be285fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-1078ffb3-32f6-4dbb-a980-b222ebcdb145,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-d0aae68c-23e1-4093-bf80-05dcd6ac8327,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-23ae5abe-7f6a-4232-bff7-c8c61d049071,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-1cffc1ed-ec05-4344-9bf2-5a47953f9742,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-683917871-172.17.0.4-1597690911818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39163,DS-224b87a4-1ed9-484f-a192-aa4161a6e226,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-b62d3605-a7cf-4369-9394-fded4cef48bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-ac38d1a3-3aa5-475e-85be-e6d4132f4580,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-44cd7e5d-8208-47f3-ad4e-ae37be285fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-1078ffb3-32f6-4dbb-a980-b222ebcdb145,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-d0aae68c-23e1-4093-bf80-05dcd6ac8327,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-23ae5abe-7f6a-4232-bff7-c8c61d049071,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-1cffc1ed-ec05-4344-9bf2-5a47953f9742,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-150146862-172.17.0.4-1597691227650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42606,DS-4b20a720-9eca-4ffa-ac49-726e8fcfd348,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-57918016-5210-4273-b8fb-6f09b52acfd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-7d41b3b5-19db-408d-bbbd-7967ff2d34c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-cbcd2080-0e2a-4a0c-830c-20574bbe8954,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-0a5bb6e1-671e-4c49-a0f6-a41967a80494,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-b105eb5b-d987-4b11-84c6-dffabda0c314,DISK], DatanodeInfoWithStorage[127.0.0.1:33835,DS-617c7a3a-6a99-4c53-a2f5-deea568a4b40,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-f3fa4d57-2c0a-4ca5-9456-de83422f2823,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-150146862-172.17.0.4-1597691227650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42606,DS-4b20a720-9eca-4ffa-ac49-726e8fcfd348,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-57918016-5210-4273-b8fb-6f09b52acfd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-7d41b3b5-19db-408d-bbbd-7967ff2d34c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-cbcd2080-0e2a-4a0c-830c-20574bbe8954,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-0a5bb6e1-671e-4c49-a0f6-a41967a80494,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-b105eb5b-d987-4b11-84c6-dffabda0c314,DISK], DatanodeInfoWithStorage[127.0.0.1:33835,DS-617c7a3a-6a99-4c53-a2f5-deea568a4b40,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-f3fa4d57-2c0a-4ca5-9456-de83422f2823,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5705
