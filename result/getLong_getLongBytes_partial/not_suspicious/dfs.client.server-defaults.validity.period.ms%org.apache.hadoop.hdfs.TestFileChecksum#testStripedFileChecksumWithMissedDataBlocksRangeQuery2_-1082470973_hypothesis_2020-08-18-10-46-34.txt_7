reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204383417-172.17.0.8-1597748139966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34801,DS-01c5bdbe-5aec-4ffe-82c7-57c6b8efea28,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-7800b50e-c612-4185-aca7-6b0443b5464b,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-de23ced9-e73a-4e25-98d8-89e698e576b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-789d51ff-8861-4a1c-88a1-abcda56b2ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-2babb8c1-9e00-4e4a-9bb8-0442d1ed1864,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-310e36b4-3fa1-44fb-aed3-2fca6ba59d09,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-83d19260-597a-4bea-b964-f79411a09968,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-0784cedd-2641-436e-a345-112f367a7ef0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204383417-172.17.0.8-1597748139966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34801,DS-01c5bdbe-5aec-4ffe-82c7-57c6b8efea28,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-7800b50e-c612-4185-aca7-6b0443b5464b,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-de23ced9-e73a-4e25-98d8-89e698e576b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-789d51ff-8861-4a1c-88a1-abcda56b2ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-2babb8c1-9e00-4e4a-9bb8-0442d1ed1864,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-310e36b4-3fa1-44fb-aed3-2fca6ba59d09,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-83d19260-597a-4bea-b964-f79411a09968,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-0784cedd-2641-436e-a345-112f367a7ef0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1489569205-172.17.0.8-1597748848969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33263,DS-0e547b69-1f6e-4fef-b802-606cfdb4287b,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-739e12af-1276-4b3c-b027-2dcec02b029b,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-85cf590a-1b96-4fcd-bd54-1ca832f8d052,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-af94f7ec-b067-4659-a3d9-8cf3daf90a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-4b89cbda-f75d-4e89-b0ec-d0b5f16012c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-ae153188-9af1-4803-84df-815d51908196,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-25c0e4de-21fd-40cd-a1d1-1944b5adf20f,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-88426576-49c3-4a15-a533-4352c075a0af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1489569205-172.17.0.8-1597748848969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33263,DS-0e547b69-1f6e-4fef-b802-606cfdb4287b,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-739e12af-1276-4b3c-b027-2dcec02b029b,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-85cf590a-1b96-4fcd-bd54-1ca832f8d052,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-af94f7ec-b067-4659-a3d9-8cf3daf90a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-4b89cbda-f75d-4e89-b0ec-d0b5f16012c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-ae153188-9af1-4803-84df-815d51908196,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-25c0e4de-21fd-40cd-a1d1-1944b5adf20f,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-88426576-49c3-4a15-a533-4352c075a0af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773176802-172.17.0.8-1597749091719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35846,DS-406c7978-be45-42bd-b86f-cf23d55bcaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-b24b99ff-869c-422f-898a-65cc9027ca59,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-b1b353c3-a654-449d-adfb-c0b23f30d19f,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-5c499486-c028-4d03-ae59-48d3df8f7a63,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-fb45ee70-bb99-4407-b6be-735ad1bb040a,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-03e035fe-5517-4312-a669-72f9a0ebc18e,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-f53fff13-acd9-4de7-b535-9c5f09b7fec9,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-8dcdbf8b-561b-4866-b6a7-9f3bbf1190c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773176802-172.17.0.8-1597749091719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35846,DS-406c7978-be45-42bd-b86f-cf23d55bcaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-b24b99ff-869c-422f-898a-65cc9027ca59,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-b1b353c3-a654-449d-adfb-c0b23f30d19f,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-5c499486-c028-4d03-ae59-48d3df8f7a63,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-fb45ee70-bb99-4407-b6be-735ad1bb040a,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-03e035fe-5517-4312-a669-72f9a0ebc18e,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-f53fff13-acd9-4de7-b535-9c5f09b7fec9,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-8dcdbf8b-561b-4866-b6a7-9f3bbf1190c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896007910-172.17.0.8-1597749571974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33691,DS-9822c3f2-78aa-4163-b005-bd9981aacf42,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-c7f459a5-7aaa-4375-b592-f358a36b05b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-5a0db001-8c90-4fcf-9414-e41fd14dc87e,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-4681bd3c-cb9a-40bc-ae62-b2205e1d1763,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-dc03d032-5b43-41b4-bf85-68a559057fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-adc67162-97ee-414e-afe3-7036578f96eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-59aab17a-9710-48f1-9149-e87c2142f610,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-e176ae36-30c5-45f5-b33c-a235a51d214c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896007910-172.17.0.8-1597749571974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33691,DS-9822c3f2-78aa-4163-b005-bd9981aacf42,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-c7f459a5-7aaa-4375-b592-f358a36b05b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-5a0db001-8c90-4fcf-9414-e41fd14dc87e,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-4681bd3c-cb9a-40bc-ae62-b2205e1d1763,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-dc03d032-5b43-41b4-bf85-68a559057fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-adc67162-97ee-414e-afe3-7036578f96eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-59aab17a-9710-48f1-9149-e87c2142f610,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-e176ae36-30c5-45f5-b33c-a235a51d214c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1511635485-172.17.0.8-1597749678250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38294,DS-5f973376-1b62-4fe1-a455-47af4c6d239f,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-5edc513b-a95b-4dd9-847e-ab8db6c1a7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-f94dc16c-0bb5-43c5-9f1f-cb7f5fecd490,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-ce060483-bf5a-4283-9c9b-2945f3f3361e,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-efbaeecf-ae50-41be-876e-97ee13672834,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-056fa478-0b94-4913-b470-bb9c055e58e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-22612ec1-fd44-4ad3-b14e-c9d23ff1d9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-b43f9665-9ce3-4392-8b18-634bdc87aed0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1511635485-172.17.0.8-1597749678250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38294,DS-5f973376-1b62-4fe1-a455-47af4c6d239f,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-5edc513b-a95b-4dd9-847e-ab8db6c1a7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-f94dc16c-0bb5-43c5-9f1f-cb7f5fecd490,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-ce060483-bf5a-4283-9c9b-2945f3f3361e,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-efbaeecf-ae50-41be-876e-97ee13672834,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-056fa478-0b94-4913-b470-bb9c055e58e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-22612ec1-fd44-4ad3-b14e-c9d23ff1d9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-b43f9665-9ce3-4392-8b18-634bdc87aed0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430389474-172.17.0.8-1597749718903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38755,DS-d0ee7f3a-8850-46ec-a37c-e47e39a5b17e,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-78cb13d3-2776-4929-a3b9-81e28e21220b,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-eb833039-4363-429c-ad70-5315d88572b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-3ce5c023-5de8-4fc8-ae89-5e3518c83f33,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-7f463f39-32bc-4ef4-a759-a18e1f46ffd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-58082fc3-c3b1-4186-966c-e10b7ddfa064,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-413b230e-e1ff-4683-ba83-30e314727e80,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-89b6df2a-4042-4375-9bcf-f5726bb32429,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430389474-172.17.0.8-1597749718903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38755,DS-d0ee7f3a-8850-46ec-a37c-e47e39a5b17e,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-78cb13d3-2776-4929-a3b9-81e28e21220b,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-eb833039-4363-429c-ad70-5315d88572b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-3ce5c023-5de8-4fc8-ae89-5e3518c83f33,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-7f463f39-32bc-4ef4-a759-a18e1f46ffd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-58082fc3-c3b1-4186-966c-e10b7ddfa064,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-413b230e-e1ff-4683-ba83-30e314727e80,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-89b6df2a-4042-4375-9bcf-f5726bb32429,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156549071-172.17.0.8-1597749789835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46726,DS-a49f244f-d746-4562-898a-4660e520e60e,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-77fb5969-f124-4839-b81a-1421ab671b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-3bb52295-d24b-481f-a59e-3eb3ad918e84,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-23a92ee4-55c2-43c0-8574-399b2e16cc46,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-4fff4476-959f-4106-9c56-b97abc40158b,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-22c4810b-baa3-4228-996a-6e89ffa180b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-912634ae-e276-4d16-acbc-03b2e14a9a35,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-2ed99975-923a-4ec2-a907-e8c4a291723d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156549071-172.17.0.8-1597749789835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46726,DS-a49f244f-d746-4562-898a-4660e520e60e,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-77fb5969-f124-4839-b81a-1421ab671b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-3bb52295-d24b-481f-a59e-3eb3ad918e84,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-23a92ee4-55c2-43c0-8574-399b2e16cc46,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-4fff4476-959f-4106-9c56-b97abc40158b,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-22c4810b-baa3-4228-996a-6e89ffa180b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-912634ae-e276-4d16-acbc-03b2e14a9a35,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-2ed99975-923a-4ec2-a907-e8c4a291723d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1044298024-172.17.0.8-1597750074915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33469,DS-b6f7a2fb-5ab8-48dd-a8b9-27d0ef335fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-8242b65c-ade3-400c-9a8d-eda915a70d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-b7f79e9d-7481-4c96-b87b-a2f0cb24cb44,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-270e218c-f648-4771-af7b-cc328de4f3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-504d1642-353d-429f-82f6-e9675126f6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-5e5a1ffa-faf5-4e9e-8f58-b80fffe712f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-603a6ff1-7987-43b2-8b60-f2475828f0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-5e518252-c8d2-4910-bf95-48d3b9de5142,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1044298024-172.17.0.8-1597750074915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33469,DS-b6f7a2fb-5ab8-48dd-a8b9-27d0ef335fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-8242b65c-ade3-400c-9a8d-eda915a70d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-b7f79e9d-7481-4c96-b87b-a2f0cb24cb44,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-270e218c-f648-4771-af7b-cc328de4f3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-504d1642-353d-429f-82f6-e9675126f6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-5e5a1ffa-faf5-4e9e-8f58-b80fffe712f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-603a6ff1-7987-43b2-8b60-f2475828f0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-5e518252-c8d2-4910-bf95-48d3b9de5142,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-127749901-172.17.0.8-1597750114044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43527,DS-39084e01-970b-45bb-bad2-4f60587978bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41019,DS-5c3840cb-f0c2-4f62-8968-fa84dfd34fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-289c90bf-4f69-43a7-b9bd-9509abe1bdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-3202e70d-96df-4a5c-8b1f-96fa068147ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-719f76ac-bbeb-4796-aa3c-08f74bc0c3de,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-3dbefa40-6f04-4dd4-b9f8-496174fe5591,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-eaaf56d9-6db9-48d7-bcca-381c3bee2745,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-e0ab7210-9540-4809-b051-51874a6df9ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-127749901-172.17.0.8-1597750114044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43527,DS-39084e01-970b-45bb-bad2-4f60587978bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41019,DS-5c3840cb-f0c2-4f62-8968-fa84dfd34fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-289c90bf-4f69-43a7-b9bd-9509abe1bdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-3202e70d-96df-4a5c-8b1f-96fa068147ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-719f76ac-bbeb-4796-aa3c-08f74bc0c3de,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-3dbefa40-6f04-4dd4-b9f8-496174fe5591,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-eaaf56d9-6db9-48d7-bcca-381c3bee2745,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-e0ab7210-9540-4809-b051-51874a6df9ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-795920452-172.17.0.8-1597750233558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37595,DS-0b03f58c-7e90-4cf1-bab4-973ab658ebc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-25722a77-74ae-4383-8491-c17a3ca4cad2,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-cacb0d27-0e46-4f7a-a291-2ff438940afd,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-95f5e432-d1f8-42d4-b894-c31038c3dccd,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-a71fcac8-319a-4fa1-9d45-f90a0d45b449,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-669507e6-3978-40f1-a3f2-872a7153eff9,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-2c7da7d3-90f3-493f-a0c4-409d5de56a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-17561435-4bb0-449f-a2d0-d2229b54c659,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-795920452-172.17.0.8-1597750233558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37595,DS-0b03f58c-7e90-4cf1-bab4-973ab658ebc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-25722a77-74ae-4383-8491-c17a3ca4cad2,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-cacb0d27-0e46-4f7a-a291-2ff438940afd,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-95f5e432-d1f8-42d4-b894-c31038c3dccd,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-a71fcac8-319a-4fa1-9d45-f90a0d45b449,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-669507e6-3978-40f1-a3f2-872a7153eff9,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-2c7da7d3-90f3-493f-a0c4-409d5de56a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-17561435-4bb0-449f-a2d0-d2229b54c659,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-303335403-172.17.0.8-1597750914179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35317,DS-1194af8b-b2ee-463a-bd64-ae2323a2b142,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-c92b5d3b-5391-4e4e-9bd3-59954cca9e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-50d8f7d4-069e-4f3b-b57a-fdda3ee8800d,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-91d3de40-5beb-403f-a060-74d298ee0000,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-ca82ad87-8a71-4d11-8fec-6ef868602b86,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-a1cf6529-2cb1-4c5c-ba76-c62e612d46ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-3ffda12f-51f8-4760-bdb0-3d0a189876b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-8283c010-041c-41f2-868b-d9e068d280b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-303335403-172.17.0.8-1597750914179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35317,DS-1194af8b-b2ee-463a-bd64-ae2323a2b142,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-c92b5d3b-5391-4e4e-9bd3-59954cca9e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-50d8f7d4-069e-4f3b-b57a-fdda3ee8800d,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-91d3de40-5beb-403f-a060-74d298ee0000,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-ca82ad87-8a71-4d11-8fec-6ef868602b86,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-a1cf6529-2cb1-4c5c-ba76-c62e612d46ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-3ffda12f-51f8-4760-bdb0-3d0a189876b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-8283c010-041c-41f2-868b-d9e068d280b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-591633135-172.17.0.8-1597751065804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39354,DS-eb3372bf-4a84-4876-81ec-8551a17f213e,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-0ec1e2bb-9f24-4ad3-9f86-245ae5812bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-cd80585f-265b-4e6c-96d0-01aabb93fabb,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-72f4558d-e77c-4bda-83c7-8f1ef703eb18,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-ea7011cb-0aa2-454d-a7ee-48df0f511d34,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-e7bbe6ab-7f0d-4065-9234-187cb2911f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-6b6f7217-a9d9-4e8e-b8c6-42f87b54bbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-25491ffd-b294-44aa-87ce-256de93993b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-591633135-172.17.0.8-1597751065804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39354,DS-eb3372bf-4a84-4876-81ec-8551a17f213e,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-0ec1e2bb-9f24-4ad3-9f86-245ae5812bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-cd80585f-265b-4e6c-96d0-01aabb93fabb,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-72f4558d-e77c-4bda-83c7-8f1ef703eb18,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-ea7011cb-0aa2-454d-a7ee-48df0f511d34,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-e7bbe6ab-7f0d-4065-9234-187cb2911f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-6b6f7217-a9d9-4e8e-b8c6-42f87b54bbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-25491ffd-b294-44aa-87ce-256de93993b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130270883-172.17.0.8-1597751218567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43721,DS-427e2b32-1e90-4936-9f8a-6f030712f1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-a49cb837-10e4-4aa8-a1da-fe3003445ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-9a4f99cb-8ebd-45aa-8800-c1b107d7716d,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-a63555e9-6b09-4c84-b905-f64b8b2d90c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-dfa1ebb5-38a3-4528-806b-c66c32348db9,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-73b82fe3-264f-4c0b-a979-7212a868b400,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-c0bd0474-68a2-45a5-9f30-c223717983de,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-cff58268-a14a-42f3-961d-647620bea269,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130270883-172.17.0.8-1597751218567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43721,DS-427e2b32-1e90-4936-9f8a-6f030712f1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-a49cb837-10e4-4aa8-a1da-fe3003445ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-9a4f99cb-8ebd-45aa-8800-c1b107d7716d,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-a63555e9-6b09-4c84-b905-f64b8b2d90c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-dfa1ebb5-38a3-4528-806b-c66c32348db9,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-73b82fe3-264f-4c0b-a979-7212a868b400,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-c0bd0474-68a2-45a5-9f30-c223717983de,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-cff58268-a14a-42f3-961d-647620bea269,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545318272-172.17.0.8-1597751525378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33527,DS-88ab2a49-40be-4077-8f5f-1d1851d50c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-076366e5-f85f-43ea-a42c-d39b9c919b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-aa278d76-4b70-480b-ac50-ea2e16643c52,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-e4fd224a-a541-44c5-a6fe-fcdb3fe04b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-282d60ae-51ad-4e08-9825-ca293627ee8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-236f351d-956c-460a-8165-6bdb66969b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-e7052c32-1b7c-425d-bbac-535c377f8a44,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-dad8e7d9-bdb1-4807-8a76-920902d01336,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545318272-172.17.0.8-1597751525378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33527,DS-88ab2a49-40be-4077-8f5f-1d1851d50c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-076366e5-f85f-43ea-a42c-d39b9c919b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-aa278d76-4b70-480b-ac50-ea2e16643c52,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-e4fd224a-a541-44c5-a6fe-fcdb3fe04b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-282d60ae-51ad-4e08-9825-ca293627ee8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-236f351d-956c-460a-8165-6bdb66969b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-e7052c32-1b7c-425d-bbac-535c377f8a44,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-dad8e7d9-bdb1-4807-8a76-920902d01336,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405825071-172.17.0.8-1597751645652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36091,DS-ca51f5c8-efcb-4e1c-9958-44b7ec81ba42,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-19c1a1d0-58aa-4c4c-bbae-a12ef14f94ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-b4befbb8-8356-466b-a4aa-becd3a952345,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-9d30e2be-f18f-49a4-bfb5-98017c61f7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-7d1329d5-9f5a-4051-b364-c7969e694bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-1fac0cd6-bc4b-4bc3-8aaa-663711bb986c,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-85da65f6-2788-434a-96b5-dbc01f9d3ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-b8b41e54-8d40-4fad-addc-656b6fd4b54d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405825071-172.17.0.8-1597751645652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36091,DS-ca51f5c8-efcb-4e1c-9958-44b7ec81ba42,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-19c1a1d0-58aa-4c4c-bbae-a12ef14f94ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-b4befbb8-8356-466b-a4aa-becd3a952345,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-9d30e2be-f18f-49a4-bfb5-98017c61f7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-7d1329d5-9f5a-4051-b364-c7969e694bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-1fac0cd6-bc4b-4bc3-8aaa-663711bb986c,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-85da65f6-2788-434a-96b5-dbc01f9d3ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-b8b41e54-8d40-4fad-addc-656b6fd4b54d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75978362-172.17.0.8-1597752134391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39902,DS-5aae94eb-4434-42e9-8576-1c8726413e57,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-e8ba6127-c156-4f83-8ccc-6df0751943bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-c95f2f03-2e6c-4ee1-95d1-c50ed3aaad32,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-af2a6c57-977c-4b9c-9120-d03669a6b7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-93a37fdc-0bef-4e0d-b41a-38733e82aae8,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-d8785228-5e54-4462-9660-8bec8abaefcb,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-c5060f6a-5b91-4bfb-9913-9811f1d7ea49,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-51a0837e-96e4-4d0b-bee2-b673efed27b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75978362-172.17.0.8-1597752134391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39902,DS-5aae94eb-4434-42e9-8576-1c8726413e57,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-e8ba6127-c156-4f83-8ccc-6df0751943bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-c95f2f03-2e6c-4ee1-95d1-c50ed3aaad32,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-af2a6c57-977c-4b9c-9120-d03669a6b7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-93a37fdc-0bef-4e0d-b41a-38733e82aae8,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-d8785228-5e54-4462-9660-8bec8abaefcb,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-c5060f6a-5b91-4bfb-9913-9811f1d7ea49,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-51a0837e-96e4-4d0b-bee2-b673efed27b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-387081756-172.17.0.8-1597752561008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45599,DS-cc379a82-9cc8-46e3-969b-1f666b63cff3,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-6ad88c09-525e-48cd-830a-021c8136ea0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-2f453910-7b13-4606-93a4-1b99969dde49,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-d80b6210-fc9b-487b-89e6-28adcba4178c,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-501d8f12-da0c-4575-832b-ec939069f773,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-69f70efc-c983-4c3e-a57e-12df11e4e0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-7fb13b36-e966-4728-9326-942636d20e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-731b3fbb-c609-4891-91a1-5d370482977d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-387081756-172.17.0.8-1597752561008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45599,DS-cc379a82-9cc8-46e3-969b-1f666b63cff3,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-6ad88c09-525e-48cd-830a-021c8136ea0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-2f453910-7b13-4606-93a4-1b99969dde49,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-d80b6210-fc9b-487b-89e6-28adcba4178c,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-501d8f12-da0c-4575-832b-ec939069f773,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-69f70efc-c983-4c3e-a57e-12df11e4e0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-7fb13b36-e966-4728-9326-942636d20e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-731b3fbb-c609-4891-91a1-5d370482977d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-305583582-172.17.0.8-1597752708977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44780,DS-c3ffe9a1-8162-4d33-bc91-46a5aa97f1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-e51142c0-fe93-4c64-be9a-a8b98cc9f953,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-ac0fb436-6d86-431a-8a35-0b9149b2eeb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-b07a76ee-a329-42ce-baaf-211800ad3728,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-f1554717-ebc1-427f-861c-14e8acf1fa83,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-062c0b23-d057-42ea-8cc3-b2e8b3c51c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-5055c22a-80f5-4c88-b99f-fce448d0b1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-e325a7dc-3dc2-45fd-90e0-abcd17ba0859,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-305583582-172.17.0.8-1597752708977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44780,DS-c3ffe9a1-8162-4d33-bc91-46a5aa97f1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-e51142c0-fe93-4c64-be9a-a8b98cc9f953,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-ac0fb436-6d86-431a-8a35-0b9149b2eeb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-b07a76ee-a329-42ce-baaf-211800ad3728,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-f1554717-ebc1-427f-861c-14e8acf1fa83,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-062c0b23-d057-42ea-8cc3-b2e8b3c51c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-5055c22a-80f5-4c88-b99f-fce448d0b1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-e325a7dc-3dc2-45fd-90e0-abcd17ba0859,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668012738-172.17.0.8-1597752786837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41068,DS-601cffe3-b324-464a-b988-7c9d236a059e,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-12c44c6c-5e01-4222-8ac5-79edb889568d,DISK], DatanodeInfoWithStorage[127.0.0.1:42149,DS-ed481a62-0ca0-4e86-8225-11da96290b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-fa2270cd-b773-49e3-b237-a306b223a3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-03139d9d-3f0c-46e7-87db-36372fc100cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-63668bfa-6c51-4e7b-8145-a003d34443cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-4bc2e7cd-1271-4381-ac4b-99740e535b25,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-2b337fc0-b25b-41e7-8210-598933da2faa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668012738-172.17.0.8-1597752786837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41068,DS-601cffe3-b324-464a-b988-7c9d236a059e,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-12c44c6c-5e01-4222-8ac5-79edb889568d,DISK], DatanodeInfoWithStorage[127.0.0.1:42149,DS-ed481a62-0ca0-4e86-8225-11da96290b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-fa2270cd-b773-49e3-b237-a306b223a3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-03139d9d-3f0c-46e7-87db-36372fc100cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-63668bfa-6c51-4e7b-8145-a003d34443cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-4bc2e7cd-1271-4381-ac4b-99740e535b25,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-2b337fc0-b25b-41e7-8210-598933da2faa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 3600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046630396-172.17.0.8-1597753197720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39337,DS-1a6f9401-7591-421f-8311-7e99a9ddb036,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-56c06f37-dfad-4126-8542-8e18dfa5222a,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-dfc905c4-f519-4c39-a774-76edd76a2499,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-c9168216-dd8c-4480-99e6-0b251a297783,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-8626ea38-cea6-43d0-8353-409f8276d2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-074f6301-fe05-4e53-af7f-d70401f917a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-e246a61c-e5b6-4fbf-8e0f-98b915764de2,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-0ced821f-29d1-42d6-9b5d-91767761a96d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046630396-172.17.0.8-1597753197720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39337,DS-1a6f9401-7591-421f-8311-7e99a9ddb036,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-56c06f37-dfad-4126-8542-8e18dfa5222a,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-dfc905c4-f519-4c39-a774-76edd76a2499,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-c9168216-dd8c-4480-99e6-0b251a297783,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-8626ea38-cea6-43d0-8353-409f8276d2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-074f6301-fe05-4e53-af7f-d70401f917a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-e246a61c-e5b6-4fbf-8e0f-98b915764de2,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-0ced821f-29d1-42d6-9b5d-91767761a96d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5620
