reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929914653-172.17.0.4-1597339959461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46401,DS-025c692a-9762-4551-bec4-cf19669caec0,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-1e0d71a3-46b6-4670-a749-1514a4444f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-2012f651-bd21-4431-bfbf-f4433d9f00d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-49a0532a-a54f-460e-af2f-aa6fadd21f42,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-c54c8a51-d5d7-4cc0-977e-c0fc64d79337,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-214c3750-bffa-4553-9321-0129e9701905,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-ba99bb11-14f9-4687-9c21-3d46c3f19c27,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-4e10f3ba-be00-4a37-b627-dfeffead8314,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929914653-172.17.0.4-1597339959461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46401,DS-025c692a-9762-4551-bec4-cf19669caec0,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-1e0d71a3-46b6-4670-a749-1514a4444f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-2012f651-bd21-4431-bfbf-f4433d9f00d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-49a0532a-a54f-460e-af2f-aa6fadd21f42,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-c54c8a51-d5d7-4cc0-977e-c0fc64d79337,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-214c3750-bffa-4553-9321-0129e9701905,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-ba99bb11-14f9-4687-9c21-3d46c3f19c27,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-4e10f3ba-be00-4a37-b627-dfeffead8314,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-635179626-172.17.0.4-1597340076742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42401,DS-89392bf0-2b6c-4ffe-8f9b-619a680b15e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-3e74e5cc-f00b-46d4-bd05-48f7327288d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-9792e659-4a04-412d-b752-ea9845b43805,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-24651036-1511-4c94-886f-7ebcdff607e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-8d063822-365d-4af6-94f4-7d9eb4017f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-dc8208da-f7f6-4b5f-a82f-a2951f17149c,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-f92fd6e6-4583-4d74-bc9e-e0fb86788c86,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-3ff4c3a7-269f-4172-b178-c070a30b54b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-635179626-172.17.0.4-1597340076742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42401,DS-89392bf0-2b6c-4ffe-8f9b-619a680b15e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-3e74e5cc-f00b-46d4-bd05-48f7327288d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-9792e659-4a04-412d-b752-ea9845b43805,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-24651036-1511-4c94-886f-7ebcdff607e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-8d063822-365d-4af6-94f4-7d9eb4017f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-dc8208da-f7f6-4b5f-a82f-a2951f17149c,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-f92fd6e6-4583-4d74-bc9e-e0fb86788c86,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-3ff4c3a7-269f-4172-b178-c070a30b54b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1021138354-172.17.0.4-1597340724805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36091,DS-b60cf93c-3de3-4abf-a0a6-ac0b11448b51,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-6423f608-9ab8-4b61-831c-833962c2f9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-67260cee-2025-46e1-b5ce-82a506f423ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-19ad240a-8c74-49d8-8fee-f79cb3ae47b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-6defede9-febb-484d-aab3-d777d237a7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-e6a8c642-bedd-4e2e-bb8f-1c5c2d5e609a,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-6a16a4f1-cbcd-417e-a011-022cfac83de2,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-2004778a-d14f-446c-af0c-dfc85dd130df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1021138354-172.17.0.4-1597340724805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36091,DS-b60cf93c-3de3-4abf-a0a6-ac0b11448b51,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-6423f608-9ab8-4b61-831c-833962c2f9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-67260cee-2025-46e1-b5ce-82a506f423ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-19ad240a-8c74-49d8-8fee-f79cb3ae47b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-6defede9-febb-484d-aab3-d777d237a7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-e6a8c642-bedd-4e2e-bb8f-1c5c2d5e609a,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-6a16a4f1-cbcd-417e-a011-022cfac83de2,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-2004778a-d14f-446c-af0c-dfc85dd130df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488812483-172.17.0.4-1597340793005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44412,DS-857a7191-e111-4823-ad5d-95d6162ae04c,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-cddd1fff-d421-4f37-ba74-8ecdbb6c9211,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-c9a4de20-d1a5-445a-a226-f266e9223d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-87784baf-a7e0-4a1a-b712-7e7cf26902a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-d8c01336-05f7-4937-8410-94d5c68e97b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-3aef1e35-e258-46a1-b3ec-4ae3ce700792,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-c16340a5-d1bc-4456-aeca-b0be0f5ff1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-98ca959e-1ac3-49fd-8cd4-ba25d5c6e4ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488812483-172.17.0.4-1597340793005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44412,DS-857a7191-e111-4823-ad5d-95d6162ae04c,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-cddd1fff-d421-4f37-ba74-8ecdbb6c9211,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-c9a4de20-d1a5-445a-a226-f266e9223d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-87784baf-a7e0-4a1a-b712-7e7cf26902a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-d8c01336-05f7-4937-8410-94d5c68e97b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-3aef1e35-e258-46a1-b3ec-4ae3ce700792,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-c16340a5-d1bc-4456-aeca-b0be0f5ff1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-98ca959e-1ac3-49fd-8cd4-ba25d5c6e4ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-407235402-172.17.0.4-1597340974033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40717,DS-27873b86-cec2-449e-992b-2b423d17181a,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-f50f1cb2-21f2-434f-b901-a73e916d6225,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-c6ced58c-43e5-4319-9eba-eb20c53e0642,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-642fc191-e598-4358-a507-6b36fd0b626f,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-0fa51f86-b7c1-4287-9ffb-0eace3e358f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-b487e35e-08c6-4fbc-8f56-1ab506e0f038,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-9a5d10fb-d13d-43dd-9f12-0af9becff75e,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-e250a5c8-d43d-42d9-b9d6-afce70941d97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-407235402-172.17.0.4-1597340974033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40717,DS-27873b86-cec2-449e-992b-2b423d17181a,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-f50f1cb2-21f2-434f-b901-a73e916d6225,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-c6ced58c-43e5-4319-9eba-eb20c53e0642,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-642fc191-e598-4358-a507-6b36fd0b626f,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-0fa51f86-b7c1-4287-9ffb-0eace3e358f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-b487e35e-08c6-4fbc-8f56-1ab506e0f038,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-9a5d10fb-d13d-43dd-9f12-0af9becff75e,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-e250a5c8-d43d-42d9-b9d6-afce70941d97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598947973-172.17.0.4-1597341975228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39541,DS-ba43ff2c-4ed3-4071-b15f-cc19430c0b66,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-1144d683-8935-499f-99c3-6e52d9792988,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-19edaadd-e1b7-4d71-88fb-1f09c84182c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-8ce5daa6-6568-4f9b-9f56-e473c066f27f,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-b3e0ebea-5c32-47ad-ab93-3e6aec4a373a,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-d0d76f4d-0642-4caf-ae93-e412a1e488dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-c4fefb7d-3b6b-45e7-b429-6afcf3abb736,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-19db32ba-f1f5-4d42-b32a-589b2b22606a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598947973-172.17.0.4-1597341975228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39541,DS-ba43ff2c-4ed3-4071-b15f-cc19430c0b66,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-1144d683-8935-499f-99c3-6e52d9792988,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-19edaadd-e1b7-4d71-88fb-1f09c84182c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-8ce5daa6-6568-4f9b-9f56-e473c066f27f,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-b3e0ebea-5c32-47ad-ab93-3e6aec4a373a,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-d0d76f4d-0642-4caf-ae93-e412a1e488dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-c4fefb7d-3b6b-45e7-b429-6afcf3abb736,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-19db32ba-f1f5-4d42-b32a-589b2b22606a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315008860-172.17.0.4-1597342224323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33529,DS-c80a4b5c-ef62-45da-b397-2c331a676ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-47143ee2-fe65-4376-8f4f-1b492ccf8aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-eedade7e-f0e1-43f9-96ea-eb66a91a2020,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-588a4c27-17e5-4039-945e-e5ee83f4a399,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-9a03a13e-748b-43ef-8b9a-dec41e012c12,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-e129111a-15e0-4b12-8aa2-ee507f4f3c35,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-ef0a7d11-f544-4ed2-9c8f-24b5765e798b,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-a701f35b-c68c-4fb5-a62c-316555b53a7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315008860-172.17.0.4-1597342224323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33529,DS-c80a4b5c-ef62-45da-b397-2c331a676ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-47143ee2-fe65-4376-8f4f-1b492ccf8aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-eedade7e-f0e1-43f9-96ea-eb66a91a2020,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-588a4c27-17e5-4039-945e-e5ee83f4a399,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-9a03a13e-748b-43ef-8b9a-dec41e012c12,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-e129111a-15e0-4b12-8aa2-ee507f4f3c35,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-ef0a7d11-f544-4ed2-9c8f-24b5765e798b,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-a701f35b-c68c-4fb5-a62c-316555b53a7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-339565395-172.17.0.4-1597342598867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41000,DS-7364cbf7-e69c-4642-979b-e05788afc1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-6e74a5e0-ca68-4ef8-9624-a6cb79fed11b,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-3a9644fa-3eda-43b5-a7fd-2a9bb2800c71,DISK], DatanodeInfoWithStorage[127.0.0.1:34382,DS-388595bb-0c70-4da9-adf9-4fe016cb8fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-dda1f8a1-5894-4985-845b-8fde91ed7ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-7c4cbcae-4100-4137-b051-764d7e97d644,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-ca9ea0b8-2a81-405d-b750-444a7ec2dd65,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-056d8547-ec6b-4f72-ab6e-a6f058c6e2b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-339565395-172.17.0.4-1597342598867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41000,DS-7364cbf7-e69c-4642-979b-e05788afc1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-6e74a5e0-ca68-4ef8-9624-a6cb79fed11b,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-3a9644fa-3eda-43b5-a7fd-2a9bb2800c71,DISK], DatanodeInfoWithStorage[127.0.0.1:34382,DS-388595bb-0c70-4da9-adf9-4fe016cb8fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-dda1f8a1-5894-4985-845b-8fde91ed7ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-7c4cbcae-4100-4137-b051-764d7e97d644,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-ca9ea0b8-2a81-405d-b750-444a7ec2dd65,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-056d8547-ec6b-4f72-ab6e-a6f058c6e2b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85793857-172.17.0.4-1597343055104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43034,DS-35751d2f-b30d-4c4d-9a78-fe5f1529c141,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-0f1d7be8-7a5a-4d74-b322-3eada52e52ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-6b5ad43d-130f-4684-90ed-90ed390c5746,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-d50063d3-f076-4275-b91f-e28b7d6bdb46,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-4af8fc9c-f632-4fa0-8147-321a832b68d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-a2d94c47-3ecb-4f7e-b56d-80e06e50af77,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-d6d5bcbf-a312-4dce-94b4-a27a86262f11,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-31db410a-7595-42c3-879f-f9e4e1dc9c4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85793857-172.17.0.4-1597343055104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43034,DS-35751d2f-b30d-4c4d-9a78-fe5f1529c141,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-0f1d7be8-7a5a-4d74-b322-3eada52e52ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-6b5ad43d-130f-4684-90ed-90ed390c5746,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-d50063d3-f076-4275-b91f-e28b7d6bdb46,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-4af8fc9c-f632-4fa0-8147-321a832b68d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-a2d94c47-3ecb-4f7e-b56d-80e06e50af77,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-d6d5bcbf-a312-4dce-94b4-a27a86262f11,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-31db410a-7595-42c3-879f-f9e4e1dc9c4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1302306526-172.17.0.4-1597343126018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38668,DS-d389a7cf-bc8f-4c15-a1ae-aa46a996fcb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-bb597e7d-a348-40e4-b817-91b345ea54ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-86bf4b81-a042-4919-8353-c257884947d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-290e22a7-f850-4152-b542-fc0459dfc498,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-693b5467-07e4-4eb8-9e33-da45b0b3dbab,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-31a851ac-f59c-4864-b4dd-443c7f9fd9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-7802c0c1-277a-458c-8cda-b95f077dbf23,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-5d8ded70-0a37-43e1-931e-106ca6a6fbd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1302306526-172.17.0.4-1597343126018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38668,DS-d389a7cf-bc8f-4c15-a1ae-aa46a996fcb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-bb597e7d-a348-40e4-b817-91b345ea54ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-86bf4b81-a042-4919-8353-c257884947d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-290e22a7-f850-4152-b542-fc0459dfc498,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-693b5467-07e4-4eb8-9e33-da45b0b3dbab,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-31a851ac-f59c-4864-b4dd-443c7f9fd9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-7802c0c1-277a-458c-8cda-b95f077dbf23,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-5d8ded70-0a37-43e1-931e-106ca6a6fbd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-312404014-172.17.0.4-1597343372734:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38669,DS-27cd590e-1d73-41ae-baae-0a70a6b0f4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-f09a6ddb-c26d-4fd8-94d9-fb00849b98b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-e8f83352-2827-45c5-aef9-633d6603d0be,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-302ceff6-e29f-4388-aed3-bf4c49af9691,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-419fa868-35a3-458b-a42b-c7338e4a73d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-d11c7674-df17-451d-be02-1e370c7a5fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-af6144de-f02e-4d26-aa7e-df208d427753,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-22ae0737-3081-47ad-a218-4ae9cd652074,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-312404014-172.17.0.4-1597343372734:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38669,DS-27cd590e-1d73-41ae-baae-0a70a6b0f4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-f09a6ddb-c26d-4fd8-94d9-fb00849b98b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-e8f83352-2827-45c5-aef9-633d6603d0be,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-302ceff6-e29f-4388-aed3-bf4c49af9691,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-419fa868-35a3-458b-a42b-c7338e4a73d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-d11c7674-df17-451d-be02-1e370c7a5fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-af6144de-f02e-4d26-aa7e-df208d427753,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-22ae0737-3081-47ad-a218-4ae9cd652074,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124510990-172.17.0.4-1597343408183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38546,DS-e1879861-0367-4935-9f99-9a434bfdc1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-648ac2a5-b96f-486a-aaeb-7becbba89f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-413d14b5-210d-4d79-9e1f-9a2f6f57df97,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-d7b5e4e8-9419-4dc7-aa7e-3e151d9774e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-6cfc7b45-ea3c-427e-8093-0f088a38467d,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-f97d5ec9-5989-4cc3-802d-eda9fbf574cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-16dabd4e-b19c-42b8-8105-8fa0596d1219,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-cdcbca00-ca81-45a8-9b77-95fb2208d19c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124510990-172.17.0.4-1597343408183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38546,DS-e1879861-0367-4935-9f99-9a434bfdc1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-648ac2a5-b96f-486a-aaeb-7becbba89f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-413d14b5-210d-4d79-9e1f-9a2f6f57df97,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-d7b5e4e8-9419-4dc7-aa7e-3e151d9774e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-6cfc7b45-ea3c-427e-8093-0f088a38467d,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-f97d5ec9-5989-4cc3-802d-eda9fbf574cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-16dabd4e-b19c-42b8-8105-8fa0596d1219,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-cdcbca00-ca81-45a8-9b77-95fb2208d19c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1863853248-172.17.0.4-1597343800173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41278,DS-2dd8b9b1-1055-4590-9ed7-3fdaed2ed237,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-626a233e-b526-48c6-84f4-7dc48ce313ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-5cd0ff51-222c-47ab-b0fa-e8f8cb16c585,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-1a1f6d8f-c2be-4656-b269-78cbfe4a3feb,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-c27daa76-fd4a-4211-9457-4c048e5bfb7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-9f76cd5c-ca84-49db-b893-800058021cee,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-d77edccd-e17e-4884-85b4-79a122db3825,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-1f129b2b-00b6-4e36-b3c1-1c7da040a8f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1863853248-172.17.0.4-1597343800173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41278,DS-2dd8b9b1-1055-4590-9ed7-3fdaed2ed237,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-626a233e-b526-48c6-84f4-7dc48ce313ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-5cd0ff51-222c-47ab-b0fa-e8f8cb16c585,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-1a1f6d8f-c2be-4656-b269-78cbfe4a3feb,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-c27daa76-fd4a-4211-9457-4c048e5bfb7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-9f76cd5c-ca84-49db-b893-800058021cee,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-d77edccd-e17e-4884-85b4-79a122db3825,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-1f129b2b-00b6-4e36-b3c1-1c7da040a8f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1867510935-172.17.0.4-1597344055656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40610,DS-93dc8387-f649-4a3b-8080-69b20c64038f,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-2ecb792a-790d-46c0-94b4-3776fb3ab004,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-1fb9465d-9d9a-4d39-950e-c78e4e0160af,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-85bc0517-f9b3-41ae-8e2e-0d12dfb4887c,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-7190ae28-7345-4c49-bc02-c9faf184e169,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-81f9e2a0-b0c0-4446-9974-8ce839723071,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-96d1773f-b3a6-402d-ac88-6fef98c1532c,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-d81ed6fc-0938-49fd-8866-3d3ff2423c34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1867510935-172.17.0.4-1597344055656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40610,DS-93dc8387-f649-4a3b-8080-69b20c64038f,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-2ecb792a-790d-46c0-94b4-3776fb3ab004,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-1fb9465d-9d9a-4d39-950e-c78e4e0160af,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-85bc0517-f9b3-41ae-8e2e-0d12dfb4887c,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-7190ae28-7345-4c49-bc02-c9faf184e169,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-81f9e2a0-b0c0-4446-9974-8ce839723071,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-96d1773f-b3a6-402d-ac88-6fef98c1532c,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-d81ed6fc-0938-49fd-8866-3d3ff2423c34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1334646559-172.17.0.4-1597344170087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46271,DS-30557c0d-1edc-4498-981b-d16e0ac04d44,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-c464ed08-a7ac-4ce2-8753-e05c30645f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-cf559a7c-8727-404d-bf54-e8f841784d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-e033036d-03f1-4068-9060-325a09286007,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-b495c106-e2b9-44aa-ba82-ee8be6eafb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-ebc37d55-4db2-4f58-a415-44decbeca54d,DISK], DatanodeInfoWithStorage[127.0.0.1:36888,DS-8f0d61c8-45c4-4173-855b-221d8582cb84,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-3debe5f1-b608-4876-a248-e7683f73ea0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1334646559-172.17.0.4-1597344170087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46271,DS-30557c0d-1edc-4498-981b-d16e0ac04d44,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-c464ed08-a7ac-4ce2-8753-e05c30645f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-cf559a7c-8727-404d-bf54-e8f841784d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-e033036d-03f1-4068-9060-325a09286007,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-b495c106-e2b9-44aa-ba82-ee8be6eafb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-ebc37d55-4db2-4f58-a415-44decbeca54d,DISK], DatanodeInfoWithStorage[127.0.0.1:36888,DS-8f0d61c8-45c4-4173-855b-221d8582cb84,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-3debe5f1-b608-4876-a248-e7683f73ea0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1394826632-172.17.0.4-1597344243037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46469,DS-64706f28-a014-4fa7-8be6-8a2b61adbfa4,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-1af3bfe6-6492-4e60-997f-cd181770cb51,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-3d1d6b76-4add-4009-9bbb-4e67d61511ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-035d4c73-a12e-446d-9a75-cb098999ba88,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-b509d92e-dd7c-4b4c-a461-b76d8edc1725,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-307e5356-673b-4e63-9196-ee45b4939a32,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-81262189-73de-4727-a9cf-20d6400a3599,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-87a07f60-6b81-4fab-a06c-62d5a9aa0761,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1394826632-172.17.0.4-1597344243037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46469,DS-64706f28-a014-4fa7-8be6-8a2b61adbfa4,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-1af3bfe6-6492-4e60-997f-cd181770cb51,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-3d1d6b76-4add-4009-9bbb-4e67d61511ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-035d4c73-a12e-446d-9a75-cb098999ba88,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-b509d92e-dd7c-4b4c-a461-b76d8edc1725,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-307e5356-673b-4e63-9196-ee45b4939a32,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-81262189-73de-4727-a9cf-20d6400a3599,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-87a07f60-6b81-4fab-a06c-62d5a9aa0761,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5418
