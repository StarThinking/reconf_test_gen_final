reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-341286472-172.17.0.8-1597334651887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39611,DS-8212cf70-1f9a-465d-a8c7-759416548aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-aef0e68e-8907-4728-ac18-54bd7a24407e,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-e6a74353-d630-45dd-92b8-ee2975ab1784,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-a4f5466b-06aa-44a2-ac45-0191f29fbe10,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-dd3d9445-416a-4fc5-b422-7d6f64e637c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-8b6689fb-2623-4f9f-929f-58c5c9188516,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-0f9a9151-ec0f-4e89-93db-585c5a97eafe,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-2851d26a-8ba6-4ebe-b9ba-d090ee4be174,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-341286472-172.17.0.8-1597334651887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39611,DS-8212cf70-1f9a-465d-a8c7-759416548aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-aef0e68e-8907-4728-ac18-54bd7a24407e,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-e6a74353-d630-45dd-92b8-ee2975ab1784,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-a4f5466b-06aa-44a2-ac45-0191f29fbe10,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-dd3d9445-416a-4fc5-b422-7d6f64e637c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-8b6689fb-2623-4f9f-929f-58c5c9188516,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-0f9a9151-ec0f-4e89-93db-585c5a97eafe,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-2851d26a-8ba6-4ebe-b9ba-d090ee4be174,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015132189-172.17.0.8-1597334890250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45180,DS-f024641d-7c2e-48f0-b713-f133f35d75f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-dc86ff1c-4e3a-4398-9713-1e562dda8b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-d643deb7-10d1-4990-b00e-79738bafe050,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-ee25779c-b29d-48c4-a65c-9f87cda0f6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-43ac442c-357c-4d9e-9160-ccb6844f135a,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-aac50e35-5f15-480e-9650-0a2e8d004a03,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-0194cf35-deeb-4781-b061-7448c57f0942,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-9609b6d4-9abd-4ea0-92b1-c55409ed0002,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015132189-172.17.0.8-1597334890250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45180,DS-f024641d-7c2e-48f0-b713-f133f35d75f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-dc86ff1c-4e3a-4398-9713-1e562dda8b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-d643deb7-10d1-4990-b00e-79738bafe050,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-ee25779c-b29d-48c4-a65c-9f87cda0f6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-43ac442c-357c-4d9e-9160-ccb6844f135a,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-aac50e35-5f15-480e-9650-0a2e8d004a03,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-0194cf35-deeb-4781-b061-7448c57f0942,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-9609b6d4-9abd-4ea0-92b1-c55409ed0002,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294854794-172.17.0.8-1597335004584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33463,DS-d3634f63-ab3d-447c-8ae1-23664b83677d,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-96b8baef-6c3b-434b-b466-b05b5036b5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-f4a3daab-872a-455a-b5ee-791b2b12781c,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-102ed88a-93f1-4adb-acf4-a6d2b2cfd84a,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-aba24596-1423-4ed0-b749-08689100882c,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-68bca073-adb3-484a-ae93-58cb4befbbec,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-48a4bcdd-cd4a-4fab-9381-59b95152bdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-b1e8c73a-5baf-48ea-b7d8-a8d905406df7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294854794-172.17.0.8-1597335004584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33463,DS-d3634f63-ab3d-447c-8ae1-23664b83677d,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-96b8baef-6c3b-434b-b466-b05b5036b5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-f4a3daab-872a-455a-b5ee-791b2b12781c,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-102ed88a-93f1-4adb-acf4-a6d2b2cfd84a,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-aba24596-1423-4ed0-b749-08689100882c,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-68bca073-adb3-484a-ae93-58cb4befbbec,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-48a4bcdd-cd4a-4fab-9381-59b95152bdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-b1e8c73a-5baf-48ea-b7d8-a8d905406df7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-359638116-172.17.0.8-1597335091997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33005,DS-e150cfdf-ae5e-43e4-92bb-53b13f14b94c,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-2f145ba0-3763-4f89-b1a9-bfa581b4ba17,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-ae44195d-ab9a-468d-bfcb-457fe7429d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-01046d5a-84ad-463f-93e6-bcab0a26f484,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-e7936662-ef2a-47e6-b7da-14d186281669,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-f7712260-2176-4e8a-944f-ae31ab0e99cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-0fb2569a-6084-4b1c-a746-b523eb7bf9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-3b126680-00e0-4450-9155-37e0801d95b8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-359638116-172.17.0.8-1597335091997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33005,DS-e150cfdf-ae5e-43e4-92bb-53b13f14b94c,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-2f145ba0-3763-4f89-b1a9-bfa581b4ba17,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-ae44195d-ab9a-468d-bfcb-457fe7429d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-01046d5a-84ad-463f-93e6-bcab0a26f484,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-e7936662-ef2a-47e6-b7da-14d186281669,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-f7712260-2176-4e8a-944f-ae31ab0e99cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-0fb2569a-6084-4b1c-a746-b523eb7bf9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-3b126680-00e0-4450-9155-37e0801d95b8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1500245539-172.17.0.8-1597335248273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39849,DS-162cc195-4b3c-4112-9c81-618ad142fe6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-848984d6-ba74-4fd9-bd33-1d57f5829e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-7cff53f0-9ca9-441c-8189-75e2e46233e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-0c303149-95b4-4c4d-9fa0-71c4dc7fe7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-8bcc4890-c9a1-45df-a85b-fe32e79a3d70,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-c2e04373-f2f3-41a7-af14-6cc03d5c9b91,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-1db6f9d3-f19d-4c32-b6a5-04bee62a7b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-8e3099da-3551-44f5-b5f8-530b31b52104,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1500245539-172.17.0.8-1597335248273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39849,DS-162cc195-4b3c-4112-9c81-618ad142fe6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-848984d6-ba74-4fd9-bd33-1d57f5829e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-7cff53f0-9ca9-441c-8189-75e2e46233e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-0c303149-95b4-4c4d-9fa0-71c4dc7fe7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-8bcc4890-c9a1-45df-a85b-fe32e79a3d70,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-c2e04373-f2f3-41a7-af14-6cc03d5c9b91,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-1db6f9d3-f19d-4c32-b6a5-04bee62a7b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-8e3099da-3551-44f5-b5f8-530b31b52104,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408761740-172.17.0.8-1597335289832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33905,DS-37cf94e2-fbeb-4c82-ad89-d1ec572b150f,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-09945e89-514c-4188-9ef9-5c1776d9c1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-e2d80f5d-46f6-4536-b2ab-7ad26c7938ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-683f42c0-eafe-48e1-84f8-9fb68877eee9,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-24c2b734-2c60-482a-b9ef-ca3f74de3bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-8bb42226-a619-436e-af63-8beb312fed3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-344f7e69-af6f-4416-b450-c88c22460807,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-8dac3f8f-58b7-42e2-99de-32e34ef78e6e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408761740-172.17.0.8-1597335289832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33905,DS-37cf94e2-fbeb-4c82-ad89-d1ec572b150f,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-09945e89-514c-4188-9ef9-5c1776d9c1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-e2d80f5d-46f6-4536-b2ab-7ad26c7938ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-683f42c0-eafe-48e1-84f8-9fb68877eee9,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-24c2b734-2c60-482a-b9ef-ca3f74de3bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-8bb42226-a619-436e-af63-8beb312fed3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-344f7e69-af6f-4416-b450-c88c22460807,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-8dac3f8f-58b7-42e2-99de-32e34ef78e6e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-416527251-172.17.0.8-1597335373085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33482,DS-e241d565-553f-48db-98bd-31a9710b1bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-489e9c95-99f2-41de-929d-eccf466d8a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-739ee8bd-a67f-4131-9ae7-66795befc9da,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-e72f7be7-c220-45b5-8e86-4a9a816c224b,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-6c2e67ee-fa2a-49db-bd4b-7c25c405bdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-89104337-25f6-488f-a0a4-4fb685a79357,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-3705ef72-a827-4cd2-b247-65a0bdf96c24,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-07c67ff6-82c7-4b39-a809-3649452cf2ea,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-416527251-172.17.0.8-1597335373085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33482,DS-e241d565-553f-48db-98bd-31a9710b1bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-489e9c95-99f2-41de-929d-eccf466d8a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-739ee8bd-a67f-4131-9ae7-66795befc9da,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-e72f7be7-c220-45b5-8e86-4a9a816c224b,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-6c2e67ee-fa2a-49db-bd4b-7c25c405bdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-89104337-25f6-488f-a0a4-4fb685a79357,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-3705ef72-a827-4cd2-b247-65a0bdf96c24,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-07c67ff6-82c7-4b39-a809-3649452cf2ea,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487449243-172.17.0.8-1597335633907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41753,DS-088c2344-e206-4e94-a5cb-b7babc276588,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-5e45430e-c63d-4719-bb1f-4c98c64c046a,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-553073e4-b34f-431e-b418-0ba9109cb1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-55f4b6d6-c8f4-4eec-92c3-89ab321e86db,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-5bfd83a8-15bb-4cf1-b77b-fcbd6e8b1ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-ad951416-3b23-4004-9b7c-c468c829f7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-d26b91a1-7f68-479a-aac6-e6f8be321766,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-81aaebb4-daca-4a5a-8d0f-acb3fc719af0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487449243-172.17.0.8-1597335633907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41753,DS-088c2344-e206-4e94-a5cb-b7babc276588,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-5e45430e-c63d-4719-bb1f-4c98c64c046a,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-553073e4-b34f-431e-b418-0ba9109cb1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-55f4b6d6-c8f4-4eec-92c3-89ab321e86db,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-5bfd83a8-15bb-4cf1-b77b-fcbd6e8b1ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-ad951416-3b23-4004-9b7c-c468c829f7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-d26b91a1-7f68-479a-aac6-e6f8be321766,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-81aaebb4-daca-4a5a-8d0f-acb3fc719af0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611819506-172.17.0.8-1597335712407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46459,DS-7bf3ed3d-6f7e-4e49-92d1-d62c6750c1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-0f1ccb10-88b5-45be-8ee1-3a70bcaf24a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-2705e622-913d-4eb3-9f6e-ed486c0283d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-6e918cd7-8f37-4bae-b6e4-2a8e51e1c781,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-4beebda6-837d-4bfe-aff2-eed88d76ab55,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-bb358122-a3df-4147-b87c-b28166d736b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-626f1ce3-b2ba-4e2d-b7ef-946c8275dc57,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-a8bb088a-d317-4fd9-99a3-dd5a10f6e607,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611819506-172.17.0.8-1597335712407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46459,DS-7bf3ed3d-6f7e-4e49-92d1-d62c6750c1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-0f1ccb10-88b5-45be-8ee1-3a70bcaf24a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-2705e622-913d-4eb3-9f6e-ed486c0283d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-6e918cd7-8f37-4bae-b6e4-2a8e51e1c781,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-4beebda6-837d-4bfe-aff2-eed88d76ab55,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-bb358122-a3df-4147-b87c-b28166d736b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-626f1ce3-b2ba-4e2d-b7ef-946c8275dc57,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-a8bb088a-d317-4fd9-99a3-dd5a10f6e607,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218723826-172.17.0.8-1597335751387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36136,DS-ce47975b-8ebc-4693-bcda-78db23231296,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-5c8f397a-2bf8-476a-82ff-c0216acb3e09,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-78eec54a-4c30-47bc-9557-41cb59543160,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-4223de03-69b7-4401-8e6e-38f615f218b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-7f958947-2ab3-4591-aa3b-3798bfebb5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-d772b84c-d717-4af1-8e18-6bd3a1b2dbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-e2ee61bb-7043-4183-aa9c-b5fff83c1b61,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-fb8607e2-2946-4428-ba40-879535789e15,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218723826-172.17.0.8-1597335751387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36136,DS-ce47975b-8ebc-4693-bcda-78db23231296,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-5c8f397a-2bf8-476a-82ff-c0216acb3e09,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-78eec54a-4c30-47bc-9557-41cb59543160,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-4223de03-69b7-4401-8e6e-38f615f218b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-7f958947-2ab3-4591-aa3b-3798bfebb5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-d772b84c-d717-4af1-8e18-6bd3a1b2dbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-e2ee61bb-7043-4183-aa9c-b5fff83c1b61,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-fb8607e2-2946-4428-ba40-879535789e15,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1398036123-172.17.0.8-1597335785791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39863,DS-7200a1ea-7e99-4869-b3cc-044a119f4b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-179e273f-9d70-4365-bc85-8384d8488fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-f4deada0-74c0-442d-ace7-9d470fcb9d75,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-52471472-e2fc-4180-8c3e-aa963d530861,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-6d9370aa-08fa-4155-be8f-466a236e291b,DISK], DatanodeInfoWithStorage[127.0.0.1:37533,DS-f2d47801-77aa-4588-8f33-4b61d25ac3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-6837b363-84fe-460d-964d-2dafd75d4f26,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-b48d8918-b130-4da3-8223-36035145b49c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1398036123-172.17.0.8-1597335785791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39863,DS-7200a1ea-7e99-4869-b3cc-044a119f4b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-179e273f-9d70-4365-bc85-8384d8488fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-f4deada0-74c0-442d-ace7-9d470fcb9d75,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-52471472-e2fc-4180-8c3e-aa963d530861,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-6d9370aa-08fa-4155-be8f-466a236e291b,DISK], DatanodeInfoWithStorage[127.0.0.1:37533,DS-f2d47801-77aa-4588-8f33-4b61d25ac3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-6837b363-84fe-460d-964d-2dafd75d4f26,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-b48d8918-b130-4da3-8223-36035145b49c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1480299135-172.17.0.8-1597336214410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37584,DS-61d294df-c5b8-4252-bfa5-8216b118b0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-c6118b7b-bb1b-4ba4-a4a8-9cd6d926a142,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-756b18cd-772a-436b-b1f0-98ed59ae0261,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-1de4ef1a-0d2e-4bb7-9ab8-34279f559826,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-d7757cec-32ca-446e-aa56-b8c72c53c1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-0ccfb985-b7a1-4398-99ab-adbb8881a480,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-b37d7cf0-e73d-48e5-bdac-6e546b5c73d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-eb16c15e-9630-45df-a886-10cebe09f782,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1480299135-172.17.0.8-1597336214410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37584,DS-61d294df-c5b8-4252-bfa5-8216b118b0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-c6118b7b-bb1b-4ba4-a4a8-9cd6d926a142,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-756b18cd-772a-436b-b1f0-98ed59ae0261,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-1de4ef1a-0d2e-4bb7-9ab8-34279f559826,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-d7757cec-32ca-446e-aa56-b8c72c53c1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-0ccfb985-b7a1-4398-99ab-adbb8881a480,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-b37d7cf0-e73d-48e5-bdac-6e546b5c73d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-eb16c15e-9630-45df-a886-10cebe09f782,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-967080327-172.17.0.8-1597336503401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45058,DS-f0c1cb02-dec0-49c2-ab15-934571925dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-f3068f2a-27d1-45bd-a845-117c959285e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-6d90bba3-2e06-4ea6-a3e8-a4ae3507b9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-c2978dda-99e7-4878-9f6f-00fe61e99786,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-b9bc155a-b5f3-44ba-8826-c819eea5105c,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-2005dd65-6d27-41aa-9cd5-682471f0a0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-4f9fd3c4-502d-461b-ab2a-2ef3ed493ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-249517aa-3ee4-4068-a4a0-796e3062fe84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-967080327-172.17.0.8-1597336503401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45058,DS-f0c1cb02-dec0-49c2-ab15-934571925dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-f3068f2a-27d1-45bd-a845-117c959285e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-6d90bba3-2e06-4ea6-a3e8-a4ae3507b9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-c2978dda-99e7-4878-9f6f-00fe61e99786,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-b9bc155a-b5f3-44ba-8826-c819eea5105c,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-2005dd65-6d27-41aa-9cd5-682471f0a0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-4f9fd3c4-502d-461b-ab2a-2ef3ed493ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-249517aa-3ee4-4068-a4a0-796e3062fe84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-76379281-172.17.0.8-1597336538530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35830,DS-a1767678-fdb8-4798-bc1e-806207cdcd76,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-319e4773-5ba8-4b2c-adb6-e3b53bee2aea,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-0b17ff15-6ef9-43b8-bc1b-b4dc1e3350da,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-bbcf3f5f-0e4e-4691-8d98-6055a8dc67c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-64e9a883-349d-4d5f-a49c-80a86ec4408b,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-7d168eb2-60ff-46f1-9013-250cea4a4ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-ae2488fb-1a5f-4c8d-92e4-1e19da2e4141,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-8e6d8dfa-d6bb-42a5-9420-b0510a514c31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-76379281-172.17.0.8-1597336538530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35830,DS-a1767678-fdb8-4798-bc1e-806207cdcd76,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-319e4773-5ba8-4b2c-adb6-e3b53bee2aea,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-0b17ff15-6ef9-43b8-bc1b-b4dc1e3350da,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-bbcf3f5f-0e4e-4691-8d98-6055a8dc67c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-64e9a883-349d-4d5f-a49c-80a86ec4408b,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-7d168eb2-60ff-46f1-9013-250cea4a4ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-ae2488fb-1a5f-4c8d-92e4-1e19da2e4141,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-8e6d8dfa-d6bb-42a5-9420-b0510a514c31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-491108147-172.17.0.8-1597336651709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45669,DS-447b29a3-6950-4825-80bf-3a7fd742aac9,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-84e6a8b1-1fe3-49ae-93ed-c803f21733e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-b0b7147f-df93-47ef-90c2-6aa2f7307d25,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-63ffd759-1153-4f02-9deb-84ef4b9da350,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-4a44b1b2-069e-4e17-a654-9967ecbb1484,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-fcfe51ba-a58f-4df1-a0c5-e5ffc87f5859,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-b4dba534-90c2-461f-ba76-58b83e9d1af4,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-47523e7e-7f8e-42d2-8077-77e019485493,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-491108147-172.17.0.8-1597336651709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45669,DS-447b29a3-6950-4825-80bf-3a7fd742aac9,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-84e6a8b1-1fe3-49ae-93ed-c803f21733e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-b0b7147f-df93-47ef-90c2-6aa2f7307d25,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-63ffd759-1153-4f02-9deb-84ef4b9da350,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-4a44b1b2-069e-4e17-a654-9967ecbb1484,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-fcfe51ba-a58f-4df1-a0c5-e5ffc87f5859,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-b4dba534-90c2-461f-ba76-58b83e9d1af4,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-47523e7e-7f8e-42d2-8077-77e019485493,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-413776484-172.17.0.8-1597336689604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38653,DS-feade3e9-27e3-4eb4-8833-a3339f17cbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-10c6c8d6-b3db-4bb3-88b6-39b7b9c9f9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37356,DS-b0d07c6c-7c42-464d-bfa7-ad0a7572fdbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-b6b57d38-8cc9-4281-9c65-aac4716c6b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-c3184fb6-89dd-4c77-b652-386a3fd6a40f,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-eb6d8279-c200-4d96-89df-1a594e8e54d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-25d64024-8af1-4564-a346-d491bdb35661,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-8f5c5131-3d5e-42ab-ad36-d2ca71fce93d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-413776484-172.17.0.8-1597336689604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38653,DS-feade3e9-27e3-4eb4-8833-a3339f17cbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-10c6c8d6-b3db-4bb3-88b6-39b7b9c9f9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37356,DS-b0d07c6c-7c42-464d-bfa7-ad0a7572fdbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-b6b57d38-8cc9-4281-9c65-aac4716c6b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-c3184fb6-89dd-4c77-b652-386a3fd6a40f,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-eb6d8279-c200-4d96-89df-1a594e8e54d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-25d64024-8af1-4564-a346-d491bdb35661,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-8f5c5131-3d5e-42ab-ad36-d2ca71fce93d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097209491-172.17.0.8-1597336863398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36636,DS-3f213828-3884-4b96-b51a-9cd3ea20b838,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-c689555d-1d97-4cd3-8c69-bb449b87d33b,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-d1132175-1be9-45a5-82b2-380bb160da69,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-ec68b30b-27ba-455a-8f99-8ea7273e7d72,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-ea668d7e-ddad-4b81-9ee5-68bf87311425,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-3be61d79-e258-47ca-9f2d-e4c423cabdb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-8fa15c7b-df6b-46a9-8221-efc891fe1616,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-52212f6c-1f55-48ab-9884-011a10bc4673,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097209491-172.17.0.8-1597336863398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36636,DS-3f213828-3884-4b96-b51a-9cd3ea20b838,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-c689555d-1d97-4cd3-8c69-bb449b87d33b,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-d1132175-1be9-45a5-82b2-380bb160da69,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-ec68b30b-27ba-455a-8f99-8ea7273e7d72,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-ea668d7e-ddad-4b81-9ee5-68bf87311425,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-3be61d79-e258-47ca-9f2d-e4c423cabdb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-8fa15c7b-df6b-46a9-8221-efc891fe1616,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-52212f6c-1f55-48ab-9884-011a10bc4673,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931663586-172.17.0.8-1597337012988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38194,DS-5ccf5409-cbab-4114-9cdc-120b22a177c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-92c94fe7-7efb-4d99-8f05-393b750bdd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-b701b050-5616-4df0-bc81-e311d95a2d97,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-969b6f18-0dec-4641-90ac-9e8539b82a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-bd9cb9a4-b862-4c53-bae9-5e3d6b4a3f57,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-44c74faf-f986-4460-953a-3cb62e771776,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-d58ac90a-2571-46aa-a6bf-8926dc34f3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-4fcfa23a-f942-46b9-836f-1635add6d9d4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931663586-172.17.0.8-1597337012988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38194,DS-5ccf5409-cbab-4114-9cdc-120b22a177c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-92c94fe7-7efb-4d99-8f05-393b750bdd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-b701b050-5616-4df0-bc81-e311d95a2d97,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-969b6f18-0dec-4641-90ac-9e8539b82a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-bd9cb9a4-b862-4c53-bae9-5e3d6b4a3f57,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-44c74faf-f986-4460-953a-3cb62e771776,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-d58ac90a-2571-46aa-a6bf-8926dc34f3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-4fcfa23a-f942-46b9-836f-1635add6d9d4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-479157501-172.17.0.8-1597337124590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35894,DS-9cd728b8-d93b-4ff7-a592-9140086caea3,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-ec2d2922-9d12-4a23-918b-19e1f111584e,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-78ca97d9-283e-4b16-b081-d0e5436f2b35,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-bd8662ed-b59d-448b-8c19-5606c64b764d,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-16ee3611-34a4-4cd2-8a6a-7f7d32bce912,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-52054f3f-2758-45fa-ada5-8a7b0f4b7bed,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-f6fbcb35-27d7-4167-b0ae-3cd913c7125b,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-106ee80b-dd32-4c41-8cb3-14379075098e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-479157501-172.17.0.8-1597337124590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35894,DS-9cd728b8-d93b-4ff7-a592-9140086caea3,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-ec2d2922-9d12-4a23-918b-19e1f111584e,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-78ca97d9-283e-4b16-b081-d0e5436f2b35,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-bd8662ed-b59d-448b-8c19-5606c64b764d,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-16ee3611-34a4-4cd2-8a6a-7f7d32bce912,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-52054f3f-2758-45fa-ada5-8a7b0f4b7bed,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-f6fbcb35-27d7-4167-b0ae-3cd913c7125b,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-106ee80b-dd32-4c41-8cb3-14379075098e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1730159950-172.17.0.8-1597337213699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40386,DS-e9249f1a-dfad-4784-9f78-ee2ea7f21129,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-12ed2895-2eae-4abb-881f-581610cb399a,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-01ddb964-1eed-4b60-a90e-f20f2ba5ae62,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-65fc3842-249d-46d3-8d51-f794932c3895,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-bf10a304-b30d-4821-a0c4-4ff8cbf2d43f,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-2c9064d4-12d7-4e71-87c1-41f478202a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-c497b524-5690-4382-a348-9be56bdb29df,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-044d20c3-58fe-4a54-a099-754b982291e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1730159950-172.17.0.8-1597337213699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40386,DS-e9249f1a-dfad-4784-9f78-ee2ea7f21129,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-12ed2895-2eae-4abb-881f-581610cb399a,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-01ddb964-1eed-4b60-a90e-f20f2ba5ae62,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-65fc3842-249d-46d3-8d51-f794932c3895,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-bf10a304-b30d-4821-a0c4-4ff8cbf2d43f,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-2c9064d4-12d7-4e71-87c1-41f478202a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-c497b524-5690-4382-a348-9be56bdb29df,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-044d20c3-58fe-4a54-a099-754b982291e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052815399-172.17.0.8-1597337257292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41917,DS-538ff8b5-93c4-4d0d-85fd-5125af17ddb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-1e65854d-d263-494d-b0c5-a5f1ff9c654c,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-9544fb84-8ca6-4010-9210-b7ddfb0a340f,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-ff7ff7be-2a40-4d81-9d23-16fb7a5d4947,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-a7fd3223-e5a7-42d3-898d-ff512e26c545,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-50bdb5b7-e203-4010-ac9a-6a9666a4c12a,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-90dc4981-7846-4ac2-82b4-bdf88ed5fbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-ef29dca1-3a5b-494d-a774-b205c68d1c3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052815399-172.17.0.8-1597337257292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41917,DS-538ff8b5-93c4-4d0d-85fd-5125af17ddb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-1e65854d-d263-494d-b0c5-a5f1ff9c654c,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-9544fb84-8ca6-4010-9210-b7ddfb0a340f,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-ff7ff7be-2a40-4d81-9d23-16fb7a5d4947,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-a7fd3223-e5a7-42d3-898d-ff512e26c545,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-50bdb5b7-e203-4010-ac9a-6a9666a4c12a,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-90dc4981-7846-4ac2-82b4-bdf88ed5fbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-ef29dca1-3a5b-494d-a774-b205c68d1c3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-827825703-172.17.0.8-1597337439821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46170,DS-d78aa825-9bd6-481d-93ac-278a55b66a96,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-7f922d38-8a05-4150-b35e-8197023781ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-719b641b-d2ad-4c5e-9fe6-cad4499f62e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-f185d977-8ad2-40b2-8c29-ce335421285a,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-2c03b50b-a533-445c-b3f1-b33d59424e90,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-7e36b5fb-4eb1-4ab7-84c4-06ab31ec4d23,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-9cf4ab19-3efd-43b5-8df9-943dde28c3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-060396bf-818e-4c91-ac9d-a80de8cc64e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-827825703-172.17.0.8-1597337439821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46170,DS-d78aa825-9bd6-481d-93ac-278a55b66a96,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-7f922d38-8a05-4150-b35e-8197023781ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-719b641b-d2ad-4c5e-9fe6-cad4499f62e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-f185d977-8ad2-40b2-8c29-ce335421285a,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-2c03b50b-a533-445c-b3f1-b33d59424e90,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-7e36b5fb-4eb1-4ab7-84c4-06ab31ec4d23,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-9cf4ab19-3efd-43b5-8df9-943dde28c3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-060396bf-818e-4c91-ac9d-a80de8cc64e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-690165248-172.17.0.8-1597337602230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43130,DS-c03741b9-b602-4fde-9654-b54e243b0bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-2cdc5f09-7d6e-4f69-a862-d451d40b62f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-bfa468a8-2c99-42e4-8f14-8da9a08fa14e,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-f8b3748b-1f74-49a5-ae4b-9921f6f89bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-a66c47b8-9f09-41fe-8c62-881981c2146b,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-76159ff8-de08-4776-807a-daaef2567222,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-649473d3-fd91-411b-9286-3da6211e76fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-faf02040-90eb-47cc-a6a1-f749e914a867,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-690165248-172.17.0.8-1597337602230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43130,DS-c03741b9-b602-4fde-9654-b54e243b0bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-2cdc5f09-7d6e-4f69-a862-d451d40b62f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-bfa468a8-2c99-42e4-8f14-8da9a08fa14e,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-f8b3748b-1f74-49a5-ae4b-9921f6f89bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-a66c47b8-9f09-41fe-8c62-881981c2146b,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-76159ff8-de08-4776-807a-daaef2567222,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-649473d3-fd91-411b-9286-3da6211e76fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-faf02040-90eb-47cc-a6a1-f749e914a867,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1502418422-172.17.0.8-1597337824282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37865,DS-ddf70b23-3182-4ac4-9076-720d3253bcde,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-f72ccd20-587c-478d-8961-4ed4690c7262,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-9f637d67-5aca-4aa7-881a-c0b2f5116a71,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-b3e091fd-4387-4fdd-b596-ddfcf69a6140,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-5e975c1f-c3cd-463c-b169-4463fc9f032a,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-f2581c75-ca2a-4403-bf42-b8e63ee9d839,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-17e0e17c-b17c-46b8-9ed4-69accbfaab25,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-63c19964-5450-465f-bf40-8870a534e32c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1502418422-172.17.0.8-1597337824282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37865,DS-ddf70b23-3182-4ac4-9076-720d3253bcde,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-f72ccd20-587c-478d-8961-4ed4690c7262,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-9f637d67-5aca-4aa7-881a-c0b2f5116a71,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-b3e091fd-4387-4fdd-b596-ddfcf69a6140,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-5e975c1f-c3cd-463c-b169-4463fc9f032a,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-f2581c75-ca2a-4403-bf42-b8e63ee9d839,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-17e0e17c-b17c-46b8-9ed4-69accbfaab25,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-63c19964-5450-465f-bf40-8870a534e32c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-714227678-172.17.0.8-1597337889575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35224,DS-031c0b39-8ce3-49d2-a74c-67897f3819af,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-51a1ac24-d24e-445c-8695-cb712f6c9f79,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-c213f667-0656-46ff-bd16-4754655f5010,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-d17fcdf4-0dd3-47b6-8f77-3c298ae452ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-394fcc0f-6e6a-40ea-bdd5-5ff9370cca23,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-f2ad1bd9-c386-4f3b-b530-49ebbcd69a35,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-b1546a95-17ef-4ba5-9082-72480118eb28,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-4ce806d3-e0e9-4088-a572-1f319da93cce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-714227678-172.17.0.8-1597337889575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35224,DS-031c0b39-8ce3-49d2-a74c-67897f3819af,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-51a1ac24-d24e-445c-8695-cb712f6c9f79,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-c213f667-0656-46ff-bd16-4754655f5010,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-d17fcdf4-0dd3-47b6-8f77-3c298ae452ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-394fcc0f-6e6a-40ea-bdd5-5ff9370cca23,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-f2ad1bd9-c386-4f3b-b530-49ebbcd69a35,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-b1546a95-17ef-4ba5-9082-72480118eb28,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-4ce806d3-e0e9-4088-a572-1f319da93cce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408304885-172.17.0.8-1597337927563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37165,DS-6d4e618d-bc3a-4733-bab1-fb1be77fab86,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-ba55b523-8d36-4c0b-9ade-29c5f7fcc8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-a344f109-202a-4f98-946c-ab8a19aafe62,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-f591a80e-77d3-414d-babd-b405fbc0c651,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-6c266376-446d-4379-9a4f-43301eb85281,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-a5d5ae4a-26ce-4ef1-8576-a1721337dd61,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-73398b1f-cfc2-4a7a-be9d-1830931fa424,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-f6c6b2a8-36f8-466b-8b4b-119f62222e07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408304885-172.17.0.8-1597337927563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37165,DS-6d4e618d-bc3a-4733-bab1-fb1be77fab86,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-ba55b523-8d36-4c0b-9ade-29c5f7fcc8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-a344f109-202a-4f98-946c-ab8a19aafe62,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-f591a80e-77d3-414d-babd-b405fbc0c651,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-6c266376-446d-4379-9a4f-43301eb85281,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-a5d5ae4a-26ce-4ef1-8576-a1721337dd61,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-73398b1f-cfc2-4a7a-be9d-1830931fa424,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-f6c6b2a8-36f8-466b-8b4b-119f62222e07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1386767689-172.17.0.8-1597338098876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45241,DS-b2b4aa4b-1352-4726-9ea0-08be3d77bf0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-f5d918a3-8b6b-4c6e-b028-108077ba3df6,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-58bb28f2-136a-426e-a426-3921112c9192,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-5e167038-a656-4d05-9821-970609cea57d,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-97cf7517-de9b-4fd8-b093-4e5e6532fc95,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-8cea7e2d-9bf4-45bf-9305-7bbaac171a30,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-431b10a7-bb9e-436b-a1d8-00e219776a23,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-2d21f0c5-1b10-4957-b828-c2b91ff27307,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1386767689-172.17.0.8-1597338098876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45241,DS-b2b4aa4b-1352-4726-9ea0-08be3d77bf0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-f5d918a3-8b6b-4c6e-b028-108077ba3df6,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-58bb28f2-136a-426e-a426-3921112c9192,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-5e167038-a656-4d05-9821-970609cea57d,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-97cf7517-de9b-4fd8-b093-4e5e6532fc95,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-8cea7e2d-9bf4-45bf-9305-7bbaac171a30,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-431b10a7-bb9e-436b-a1d8-00e219776a23,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-2d21f0c5-1b10-4957-b828-c2b91ff27307,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-316072582-172.17.0.8-1597338170562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43656,DS-d195c64d-07a5-4ada-88f7-ac872b288f16,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-e6d5e7bc-b8a6-4602-add9-223f3982ab50,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-83409fa0-fc44-407b-9b70-10d9f73e96f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44240,DS-ce6f6728-2ece-4637-a160-8bead98904f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-52aea6c5-df65-43b6-ba20-fb8f6ddf38df,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-173ec138-17c3-4235-a222-1d0d57daf713,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-f4c6d6f0-cb88-4d5b-98d8-9dba8535334e,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-b283c87a-b66f-4f8c-b539-d8fee0f27a6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-316072582-172.17.0.8-1597338170562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43656,DS-d195c64d-07a5-4ada-88f7-ac872b288f16,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-e6d5e7bc-b8a6-4602-add9-223f3982ab50,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-83409fa0-fc44-407b-9b70-10d9f73e96f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44240,DS-ce6f6728-2ece-4637-a160-8bead98904f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-52aea6c5-df65-43b6-ba20-fb8f6ddf38df,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-173ec138-17c3-4235-a222-1d0d57daf713,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-f4c6d6f0-cb88-4d5b-98d8-9dba8535334e,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-b283c87a-b66f-4f8c-b539-d8fee0f27a6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-679141522-172.17.0.8-1597338205249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34570,DS-b5e620ad-4276-4f11-95ef-1d52cdba5eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-5e5a3f64-bb5b-4b10-9779-31981700bd33,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-96f795d6-5970-474d-8bb7-ae0ac09787ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-ceb7c52e-7569-4529-bcc7-ec5f5b1755d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-48913adc-a207-4688-b993-238d9179a80d,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-a91af803-e030-4b5c-80d7-a8e8d8ab19a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-ccdcffc7-46bd-4a79-af56-f8b6dea660a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-cae5b6de-d0ed-40d1-9ac6-501cfe7625ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-679141522-172.17.0.8-1597338205249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34570,DS-b5e620ad-4276-4f11-95ef-1d52cdba5eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-5e5a3f64-bb5b-4b10-9779-31981700bd33,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-96f795d6-5970-474d-8bb7-ae0ac09787ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-ceb7c52e-7569-4529-bcc7-ec5f5b1755d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-48913adc-a207-4688-b993-238d9179a80d,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-a91af803-e030-4b5c-80d7-a8e8d8ab19a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-ccdcffc7-46bd-4a79-af56-f8b6dea660a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-cae5b6de-d0ed-40d1-9ac6-501cfe7625ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-46424966-172.17.0.8-1597338667786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43861,DS-8a3d0bde-89d8-4bed-a12c-2f4b62d4c766,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-5fff01a4-b6c9-4fce-b2a1-2670489b5817,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-d4a3252a-b4b9-491e-9725-1060d6c07ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-9bf5cea7-d26a-4ec6-ba65-dd8c70014731,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-64dbf050-0431-4050-80ad-89cf6797f251,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-f0a7ec15-322d-41f0-8573-09a4e74350c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-c2c189b0-0a6f-4584-aab8-33344a22c65f,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-e1c38e67-a53b-41b9-a7d8-53bd040fc165,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-46424966-172.17.0.8-1597338667786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43861,DS-8a3d0bde-89d8-4bed-a12c-2f4b62d4c766,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-5fff01a4-b6c9-4fce-b2a1-2670489b5817,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-d4a3252a-b4b9-491e-9725-1060d6c07ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-9bf5cea7-d26a-4ec6-ba65-dd8c70014731,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-64dbf050-0431-4050-80ad-89cf6797f251,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-f0a7ec15-322d-41f0-8573-09a4e74350c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-c2c189b0-0a6f-4584-aab8-33344a22c65f,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-e1c38e67-a53b-41b9-a7d8-53bd040fc165,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024372015-172.17.0.8-1597338739953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35377,DS-ca87ed49-e57d-49cd-9ef2-86b799d8e03f,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-729e1cc8-0714-41e6-b92d-5e26326b50c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-02c89b60-42b2-4b65-9c50-204f30913d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-6545c5b3-50d6-4609-a739-3c95de34a168,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-1bde643b-dddb-4045-b7a3-01781b648a52,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-025413d9-c1f6-4c19-956e-972e9cea254b,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-144e7bed-8f8e-4b1e-b3f1-a2b6cc8068ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-ca3cb0c7-8312-4fed-91f8-68ea83e7760d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024372015-172.17.0.8-1597338739953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35377,DS-ca87ed49-e57d-49cd-9ef2-86b799d8e03f,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-729e1cc8-0714-41e6-b92d-5e26326b50c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-02c89b60-42b2-4b65-9c50-204f30913d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-6545c5b3-50d6-4609-a739-3c95de34a168,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-1bde643b-dddb-4045-b7a3-01781b648a52,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-025413d9-c1f6-4c19-956e-972e9cea254b,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-144e7bed-8f8e-4b1e-b3f1-a2b6cc8068ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-ca3cb0c7-8312-4fed-91f8-68ea83e7760d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1279664503-172.17.0.8-1597339038893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42153,DS-8f2e28d7-822b-4181-88d0-4306c813ef34,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-de73235e-b411-4fa1-9467-89cc6ff1abcc,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-53cdb88d-cabf-4b35-a3c4-6ce1e01e1536,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-31ac4ff6-b3f6-413e-918c-cafcd4b1dea6,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-46c73691-d023-4a47-82ea-924b54b55fde,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-341890f3-7487-4c62-97d5-ff15b5d9b408,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-25415b79-4644-476b-9c9f-e1edb1c15eed,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-a89d2c40-c1b9-4932-86a0-ad327eb741a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1279664503-172.17.0.8-1597339038893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42153,DS-8f2e28d7-822b-4181-88d0-4306c813ef34,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-de73235e-b411-4fa1-9467-89cc6ff1abcc,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-53cdb88d-cabf-4b35-a3c4-6ce1e01e1536,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-31ac4ff6-b3f6-413e-918c-cafcd4b1dea6,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-46c73691-d023-4a47-82ea-924b54b55fde,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-341890f3-7487-4c62-97d5-ff15b5d9b408,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-25415b79-4644-476b-9c9f-e1edb1c15eed,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-a89d2c40-c1b9-4932-86a0-ad327eb741a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1212818294-172.17.0.8-1597339303341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42303,DS-bbe63fef-102f-4e8d-9d6f-f6ec43435b51,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-a6322238-47b8-4fb6-8dbd-7ec151d8d261,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-049bfbb8-c452-4963-b199-58c164366d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-d31468dd-2c47-40b3-9cba-c51017555890,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-638623aa-024f-42cd-a056-b8944dc3bbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-d88bd813-8954-4651-a3f5-46e6bc5b7e38,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-bdf79435-528d-4631-8e63-da7940d08a52,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-bae42980-44da-43e9-b98d-72d94d80bfe8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1212818294-172.17.0.8-1597339303341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42303,DS-bbe63fef-102f-4e8d-9d6f-f6ec43435b51,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-a6322238-47b8-4fb6-8dbd-7ec151d8d261,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-049bfbb8-c452-4963-b199-58c164366d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-d31468dd-2c47-40b3-9cba-c51017555890,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-638623aa-024f-42cd-a056-b8944dc3bbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-d88bd813-8954-4651-a3f5-46e6bc5b7e38,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-bdf79435-528d-4631-8e63-da7940d08a52,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-bae42980-44da-43e9-b98d-72d94d80bfe8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-598154619-172.17.0.8-1597339498158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35625,DS-31d70ba8-8264-4a40-a8c3-6c2f739d9f29,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-5d61fe36-86ea-4b3f-b4a1-8a102ba58312,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-d50d7deb-f3ac-4a14-af85-320af81cdc71,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-083c6927-2571-4f4c-9fcc-8e0c2e6a85cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-1557a2c9-31ff-4c4f-a4c1-11ae94113f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-ad88b49f-2422-49b1-a0eb-483b66f84891,DISK], DatanodeInfoWithStorage[127.0.0.1:34590,DS-d2fb6fbc-6151-42e8-80a7-c2cfd08ccaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-cbd92a39-2baf-4775-9c29-92896a969bfa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-598154619-172.17.0.8-1597339498158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35625,DS-31d70ba8-8264-4a40-a8c3-6c2f739d9f29,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-5d61fe36-86ea-4b3f-b4a1-8a102ba58312,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-d50d7deb-f3ac-4a14-af85-320af81cdc71,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-083c6927-2571-4f4c-9fcc-8e0c2e6a85cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-1557a2c9-31ff-4c4f-a4c1-11ae94113f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-ad88b49f-2422-49b1-a0eb-483b66f84891,DISK], DatanodeInfoWithStorage[127.0.0.1:34590,DS-d2fb6fbc-6151-42e8-80a7-c2cfd08ccaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-cbd92a39-2baf-4775-9c29-92896a969bfa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2010977029-172.17.0.8-1597339613829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36705,DS-524b4e10-030a-4249-a271-34f4c00ffdab,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-e3d8265b-354d-4e0e-8e5f-314e6a50ad28,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-ce4dc60a-0679-48fd-8e25-86c09c613164,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-d9d5569d-5ac2-483e-be9d-3d063a18093c,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-155f28c9-d890-4d79-92d5-02f9db09681f,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-8941f1e6-dcc4-4340-8251-c25005db0c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-991548cb-7418-4526-b3f2-5ade89a2b4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-1cf87288-a7e6-4fb4-90f2-480aef092530,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2010977029-172.17.0.8-1597339613829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36705,DS-524b4e10-030a-4249-a271-34f4c00ffdab,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-e3d8265b-354d-4e0e-8e5f-314e6a50ad28,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-ce4dc60a-0679-48fd-8e25-86c09c613164,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-d9d5569d-5ac2-483e-be9d-3d063a18093c,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-155f28c9-d890-4d79-92d5-02f9db09681f,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-8941f1e6-dcc4-4340-8251-c25005db0c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-991548cb-7418-4526-b3f2-5ade89a2b4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-1cf87288-a7e6-4fb4-90f2-480aef092530,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-100418860-172.17.0.8-1597339737792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45906,DS-f82883b9-a836-4dc3-a447-9b7771ecb18d,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-9678ab50-a137-478e-bd2e-c69a281866ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-416f1e94-0fe9-46f2-81b3-515f5e0470a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-1e700cd1-154e-47b2-956f-e5eac8c78f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-b613cb88-9b0f-444d-baa2-a162417e4dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-b4e4f92f-058d-41fc-9b2d-d9f7ce47b993,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-1a296136-3863-423a-92a7-417b3232b852,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-aa296065-23a7-4f4d-a7ce-484a0988a87a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-100418860-172.17.0.8-1597339737792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45906,DS-f82883b9-a836-4dc3-a447-9b7771ecb18d,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-9678ab50-a137-478e-bd2e-c69a281866ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-416f1e94-0fe9-46f2-81b3-515f5e0470a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-1e700cd1-154e-47b2-956f-e5eac8c78f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-b613cb88-9b0f-444d-baa2-a162417e4dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-b4e4f92f-058d-41fc-9b2d-d9f7ce47b993,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-1a296136-3863-423a-92a7-417b3232b852,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-aa296065-23a7-4f4d-a7ce-484a0988a87a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-266269589-172.17.0.8-1597340011242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37747,DS-59dfb919-9cb0-4bda-a3a5-3a2afa993f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-30350876-b490-4069-a898-22827c91e127,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-c14467e4-0501-4d01-abb6-a2fda84ac706,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-86237b51-7ed1-43fd-8083-67d5d7e18cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-3934f03e-3f9c-4cc1-b224-cdfc0cb69d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-3e66a3f8-1127-460b-ad8c-87e1977211d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-33535d81-4334-4a4a-ad9f-826a8f560255,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-3a439c83-21d2-4fbd-a66b-db1a5c5f8ad1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-266269589-172.17.0.8-1597340011242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37747,DS-59dfb919-9cb0-4bda-a3a5-3a2afa993f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-30350876-b490-4069-a898-22827c91e127,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-c14467e4-0501-4d01-abb6-a2fda84ac706,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-86237b51-7ed1-43fd-8083-67d5d7e18cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-3934f03e-3f9c-4cc1-b224-cdfc0cb69d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-3e66a3f8-1127-460b-ad8c-87e1977211d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-33535d81-4334-4a4a-ad9f-826a8f560255,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-3a439c83-21d2-4fbd-a66b-db1a5c5f8ad1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1559102762-172.17.0.8-1597340057296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36745,DS-fd616883-6c47-4acb-8880-fe16c9e1a9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-421d8480-12c5-4a08-aadb-d9f826435777,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-c86bfbe5-0466-41fd-bda2-d00a6888995b,DISK], DatanodeInfoWithStorage[127.0.0.1:34032,DS-06c753b9-4124-4c20-8dff-fe1e6e5c81fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-7b3e17fc-c680-46e1-a4ca-c410cdc47095,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-50be66db-269c-4838-96cc-e2d6b0a7c7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-9539a1cd-6edf-42c4-a615-7f23bc276404,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-cbce0ab0-da01-42c8-8f84-63c336304a76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1559102762-172.17.0.8-1597340057296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36745,DS-fd616883-6c47-4acb-8880-fe16c9e1a9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-421d8480-12c5-4a08-aadb-d9f826435777,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-c86bfbe5-0466-41fd-bda2-d00a6888995b,DISK], DatanodeInfoWithStorage[127.0.0.1:34032,DS-06c753b9-4124-4c20-8dff-fe1e6e5c81fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-7b3e17fc-c680-46e1-a4ca-c410cdc47095,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-50be66db-269c-4838-96cc-e2d6b0a7c7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-9539a1cd-6edf-42c4-a615-7f23bc276404,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-cbce0ab0-da01-42c8-8f84-63c336304a76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437807342-172.17.0.8-1597340342241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45934,DS-d67c2a66-4172-48e6-8895-deb1b871c05a,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-77d9394e-7c48-4360-83ea-93c9990b5aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-b173e3c8-6e1d-47e1-bcfb-bfaeb008e5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-b3ac55b5-6a2b-4760-b404-61f7a7418542,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-d6b43e73-8208-4151-ac17-43a19861bba9,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-9c2060ef-a233-41c3-af03-e331f521c2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-ad6a98a4-fdb8-4194-9a93-a2c903aaae28,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-6514dc7a-d383-489d-8edc-ea2792ddd18a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437807342-172.17.0.8-1597340342241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45934,DS-d67c2a66-4172-48e6-8895-deb1b871c05a,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-77d9394e-7c48-4360-83ea-93c9990b5aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-b173e3c8-6e1d-47e1-bcfb-bfaeb008e5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-b3ac55b5-6a2b-4760-b404-61f7a7418542,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-d6b43e73-8208-4151-ac17-43a19861bba9,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-9c2060ef-a233-41c3-af03-e331f521c2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-ad6a98a4-fdb8-4194-9a93-a2c903aaae28,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-6514dc7a-d383-489d-8edc-ea2792ddd18a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 27 out of 50
result: false positive !!!
Total execution time in seconds : 5806
