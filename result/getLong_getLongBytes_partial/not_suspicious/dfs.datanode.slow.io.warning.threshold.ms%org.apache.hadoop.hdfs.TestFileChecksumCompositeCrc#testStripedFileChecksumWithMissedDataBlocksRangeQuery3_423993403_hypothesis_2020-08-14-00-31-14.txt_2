reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1763514675-172.17.0.19-1597365486159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41419,DS-215a50dc-a066-4f66-8608-d4e71171e7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-72a19d59-09fa-432f-88e8-93c48ec8544f,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-9974995e-69f9-44f7-a069-f23494f52c19,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-854af6d8-c17b-4b1f-9460-c83ad1b9ec53,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-99795609-f647-49a1-989d-1d549c59be25,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-bf1b95e5-4524-47f1-8877-86b029eeacf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-2cacf49b-5e94-403e-b1a2-263b7ed60544,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-d66d9ad8-40ac-4309-9a17-af2d05e337df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1763514675-172.17.0.19-1597365486159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41419,DS-215a50dc-a066-4f66-8608-d4e71171e7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-72a19d59-09fa-432f-88e8-93c48ec8544f,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-9974995e-69f9-44f7-a069-f23494f52c19,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-854af6d8-c17b-4b1f-9460-c83ad1b9ec53,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-99795609-f647-49a1-989d-1d549c59be25,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-bf1b95e5-4524-47f1-8877-86b029eeacf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-2cacf49b-5e94-403e-b1a2-263b7ed60544,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-d66d9ad8-40ac-4309-9a17-af2d05e337df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486397081-172.17.0.19-1597365539262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41869,DS-241b1729-9561-4f9f-b2da-c4a52c69eb82,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-04958d8f-144a-477c-8698-6ca230d42a94,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-8aa38c97-2746-4bfb-b5c2-f8f5bd298e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-9b125023-9719-4e5d-8e74-caa95ea1a527,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-3cb631e8-5504-41d5-b5c3-b72043edbda3,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-9bf0346f-1e86-4deb-bb18-92e7723e2461,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-31019aa3-f33a-4e4d-8088-03592f7c4d91,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-c200c906-b581-45fd-9a48-afd19b538c31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486397081-172.17.0.19-1597365539262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41869,DS-241b1729-9561-4f9f-b2da-c4a52c69eb82,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-04958d8f-144a-477c-8698-6ca230d42a94,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-8aa38c97-2746-4bfb-b5c2-f8f5bd298e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-9b125023-9719-4e5d-8e74-caa95ea1a527,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-3cb631e8-5504-41d5-b5c3-b72043edbda3,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-9bf0346f-1e86-4deb-bb18-92e7723e2461,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-31019aa3-f33a-4e4d-8088-03592f7c4d91,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-c200c906-b581-45fd-9a48-afd19b538c31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-917205938-172.17.0.19-1597366569881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38601,DS-9a991ed6-4ed6-4c81-9bc4-9ed5c74e52b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-9d49aeeb-a4e7-4ce2-a31f-7f62c13b64f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-ab6eda47-1c7c-47e5-b757-252de0b6637a,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-bdefdf8a-e9a3-42a6-bcab-7e7487cce678,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-1e471967-8d69-4c69-8b40-0e3169bbda79,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-79df116a-0c98-454b-bb55-bfcd44468fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-fc12d731-90d8-49c9-91c6-c9ffdbe4e159,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-653fa42e-6d94-4c30-ade4-46db7f4877a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-917205938-172.17.0.19-1597366569881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38601,DS-9a991ed6-4ed6-4c81-9bc4-9ed5c74e52b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-9d49aeeb-a4e7-4ce2-a31f-7f62c13b64f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-ab6eda47-1c7c-47e5-b757-252de0b6637a,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-bdefdf8a-e9a3-42a6-bcab-7e7487cce678,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-1e471967-8d69-4c69-8b40-0e3169bbda79,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-79df116a-0c98-454b-bb55-bfcd44468fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-fc12d731-90d8-49c9-91c6-c9ffdbe4e159,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-653fa42e-6d94-4c30-ade4-46db7f4877a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1288105749-172.17.0.19-1597366756745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37870,DS-e1878956-443a-4e7a-98df-2f8ff79ff505,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-47a83164-f019-47f5-bb92-5b11ba8f6eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-8e064e82-5b12-45e9-82a4-d10209685f15,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-01c50a66-9118-4cbf-84a4-74c2cf17a54a,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-04f2179c-3da9-4258-813d-5cc66a5610fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-c1da7616-01f6-453a-a233-4fc406a2a119,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-795fc12b-650b-4ce7-b175-4b13ae0be1df,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-b2414bda-8a66-4baa-8950-dbc90057ccb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1288105749-172.17.0.19-1597366756745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37870,DS-e1878956-443a-4e7a-98df-2f8ff79ff505,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-47a83164-f019-47f5-bb92-5b11ba8f6eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-8e064e82-5b12-45e9-82a4-d10209685f15,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-01c50a66-9118-4cbf-84a4-74c2cf17a54a,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-04f2179c-3da9-4258-813d-5cc66a5610fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-c1da7616-01f6-453a-a233-4fc406a2a119,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-795fc12b-650b-4ce7-b175-4b13ae0be1df,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-b2414bda-8a66-4baa-8950-dbc90057ccb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117083344-172.17.0.19-1597366929086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46720,DS-e4f36f72-2703-4e6f-86fd-7f327ec09e62,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-23045982-c188-4141-b564-0c6aaafac3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-98678e3c-af94-437d-8b8f-3da725e0cf47,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-d9ecb1e2-7322-4d4d-902a-ae347337ac59,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-062e7537-eb5b-4e1f-8610-8242971e7979,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-625b1847-746b-41ef-b766-1e2c281a70b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-b13a649f-132d-40f0-908c-c62256bdcdc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-117c0bdc-6413-45f2-bc1c-669d797af02d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117083344-172.17.0.19-1597366929086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46720,DS-e4f36f72-2703-4e6f-86fd-7f327ec09e62,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-23045982-c188-4141-b564-0c6aaafac3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-98678e3c-af94-437d-8b8f-3da725e0cf47,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-d9ecb1e2-7322-4d4d-902a-ae347337ac59,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-062e7537-eb5b-4e1f-8610-8242971e7979,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-625b1847-746b-41ef-b766-1e2c281a70b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-b13a649f-132d-40f0-908c-c62256bdcdc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-117c0bdc-6413-45f2-bc1c-669d797af02d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-495060338-172.17.0.19-1597367050473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34498,DS-44f2bf92-5e65-42db-8c8e-9369b918b228,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-e73e5689-a0fb-48f7-90a4-d5fcae702193,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-072735da-2349-47b3-a320-1072b5aa7af2,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-a6b9e318-697f-48fa-9c05-8748ab44243b,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-2965d1d7-8d78-4f39-8734-250b10328205,DISK], DatanodeInfoWithStorage[127.0.0.1:38851,DS-fddfc4bb-3515-499e-810c-bb3df36df815,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-4c0acf66-7a0f-42f0-8dfd-350ea0ff500b,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-f6956c4e-b1a6-4e58-9e82-c7235da8c3e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-495060338-172.17.0.19-1597367050473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34498,DS-44f2bf92-5e65-42db-8c8e-9369b918b228,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-e73e5689-a0fb-48f7-90a4-d5fcae702193,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-072735da-2349-47b3-a320-1072b5aa7af2,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-a6b9e318-697f-48fa-9c05-8748ab44243b,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-2965d1d7-8d78-4f39-8734-250b10328205,DISK], DatanodeInfoWithStorage[127.0.0.1:38851,DS-fddfc4bb-3515-499e-810c-bb3df36df815,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-4c0acf66-7a0f-42f0-8dfd-350ea0ff500b,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-f6956c4e-b1a6-4e58-9e82-c7235da8c3e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-973351286-172.17.0.19-1597367089603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38539,DS-a947b2aa-8179-4030-9891-b1d6163dafc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-684e4cb3-27d0-4e7d-b127-dee9f46ccb23,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-82c7a822-b680-4fb1-ad76-3e59d8c7fef5,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-f5ed5b06-2c7f-47c1-a886-4a78e1def9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-f7bff5f2-4b17-495a-aaab-74bcf66d96de,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-d921c704-5290-4156-9ce1-d02ec5d3f717,DISK], DatanodeInfoWithStorage[127.0.0.1:39248,DS-ce641a5b-7a1e-4cd5-84a0-177379598678,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-0aca1a6b-8d0d-4f65-b88c-60a7221fa090,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-973351286-172.17.0.19-1597367089603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38539,DS-a947b2aa-8179-4030-9891-b1d6163dafc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-684e4cb3-27d0-4e7d-b127-dee9f46ccb23,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-82c7a822-b680-4fb1-ad76-3e59d8c7fef5,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-f5ed5b06-2c7f-47c1-a886-4a78e1def9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-f7bff5f2-4b17-495a-aaab-74bcf66d96de,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-d921c704-5290-4156-9ce1-d02ec5d3f717,DISK], DatanodeInfoWithStorage[127.0.0.1:39248,DS-ce641a5b-7a1e-4cd5-84a0-177379598678,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-0aca1a6b-8d0d-4f65-b88c-60a7221fa090,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1413640100-172.17.0.19-1597367973286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37639,DS-fedb57bf-87c3-4423-acf0-90b3d1165e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-dac70305-78df-46fd-a4a2-06574ee902a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-f8cfe811-447f-48c6-b99c-eafc2edce030,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-2fc3c4df-8ae9-4fd4-b1ec-592234ad3517,DISK], DatanodeInfoWithStorage[127.0.0.1:46350,DS-eee34ed8-4fe0-42c4-aef9-3ec5ec009a62,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-b38999c7-6287-4661-9e1b-7064c4840b92,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-875a50ad-7509-4abd-b7d5-12c8eaba25ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-b3a6f7b4-8294-4fe5-9622-84e906c7430a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1413640100-172.17.0.19-1597367973286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37639,DS-fedb57bf-87c3-4423-acf0-90b3d1165e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-dac70305-78df-46fd-a4a2-06574ee902a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-f8cfe811-447f-48c6-b99c-eafc2edce030,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-2fc3c4df-8ae9-4fd4-b1ec-592234ad3517,DISK], DatanodeInfoWithStorage[127.0.0.1:46350,DS-eee34ed8-4fe0-42c4-aef9-3ec5ec009a62,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-b38999c7-6287-4661-9e1b-7064c4840b92,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-875a50ad-7509-4abd-b7d5-12c8eaba25ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-b3a6f7b4-8294-4fe5-9622-84e906c7430a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062835087-172.17.0.19-1597368051491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34203,DS-d404a3ed-b49c-4392-ae68-02b79b9e6ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-de6c7207-919c-4cfe-886b-98d4ac34e528,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-c20ee323-dc17-4279-9546-b034edf7e3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-f7c602aa-50af-455a-82e7-4e67c24683b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-f6d4d813-f99a-4d2e-be43-cd5c98bb8523,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-738230b9-5db7-405c-8036-ac4a1a3ab94a,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-4b5baeda-783e-46aa-b206-487c90ff581d,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-d3c09c86-f7f5-45b0-a0fb-79d7bf6127de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062835087-172.17.0.19-1597368051491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34203,DS-d404a3ed-b49c-4392-ae68-02b79b9e6ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-de6c7207-919c-4cfe-886b-98d4ac34e528,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-c20ee323-dc17-4279-9546-b034edf7e3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-f7c602aa-50af-455a-82e7-4e67c24683b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-f6d4d813-f99a-4d2e-be43-cd5c98bb8523,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-738230b9-5db7-405c-8036-ac4a1a3ab94a,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-4b5baeda-783e-46aa-b206-487c90ff581d,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-d3c09c86-f7f5-45b0-a0fb-79d7bf6127de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-667990775-172.17.0.19-1597368754839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41739,DS-66471343-1131-4f03-a4dd-2bedab6f6e15,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-c90a8c07-acbd-47eb-990d-3249c704730b,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-7eeff0f2-047d-4f41-9677-3d1e0fb97d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-ab086e88-6ccd-45fa-8819-7ae0ef68731a,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-a143c393-8b67-459c-af37-56f77957e575,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-a422bd52-8f1d-415c-bed9-80746a0a3ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-d291f363-4140-49da-8124-d4938006910c,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-c0c69ce1-03d3-40b7-829b-ec7f9ee29ee1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-667990775-172.17.0.19-1597368754839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41739,DS-66471343-1131-4f03-a4dd-2bedab6f6e15,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-c90a8c07-acbd-47eb-990d-3249c704730b,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-7eeff0f2-047d-4f41-9677-3d1e0fb97d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-ab086e88-6ccd-45fa-8819-7ae0ef68731a,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-a143c393-8b67-459c-af37-56f77957e575,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-a422bd52-8f1d-415c-bed9-80746a0a3ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-d291f363-4140-49da-8124-d4938006910c,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-c0c69ce1-03d3-40b7-829b-ec7f9ee29ee1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1845060332-172.17.0.19-1597369098189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43562,DS-f3eeb471-99f1-4dcd-9b83-ebd23e87109a,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-a3b7330a-53c0-4f9a-bea6-b6287af5ff74,DISK], DatanodeInfoWithStorage[127.0.0.1:35026,DS-7f550e16-9722-4287-a783-48ff1c19e732,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-cdeb8e69-c71c-47af-b6e9-de26149f3e09,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-a6a66a62-13b9-42a4-8adb-0f569b002797,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-e895d924-73e0-48f4-87fe-e1b03cf9956a,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-36ce73e3-fac5-4835-9250-114c5eedb2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-45f76c69-7693-409d-84bf-08d9c3e9da33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1845060332-172.17.0.19-1597369098189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43562,DS-f3eeb471-99f1-4dcd-9b83-ebd23e87109a,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-a3b7330a-53c0-4f9a-bea6-b6287af5ff74,DISK], DatanodeInfoWithStorage[127.0.0.1:35026,DS-7f550e16-9722-4287-a783-48ff1c19e732,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-cdeb8e69-c71c-47af-b6e9-de26149f3e09,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-a6a66a62-13b9-42a4-8adb-0f569b002797,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-e895d924-73e0-48f4-87fe-e1b03cf9956a,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-36ce73e3-fac5-4835-9250-114c5eedb2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-45f76c69-7693-409d-84bf-08d9c3e9da33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-139249384-172.17.0.19-1597369796739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37178,DS-4d4f8ed2-a5f2-4e8a-9171-8af633047bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-872e685d-7c8e-4bd3-900d-906750d2c2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-098e9ff4-596b-4411-9955-1350ee9eb145,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-3ce3a403-da37-4344-a5e1-304a0cc01048,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-12080584-2149-4d21-92a0-193dc933cac0,DISK], DatanodeInfoWithStorage[127.0.0.1:34465,DS-c078a28b-0580-488d-ae58-76fd8d073d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-0267f642-a85f-4615-9c51-3dfe431eadf8,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-cac153b9-6acd-41f8-ac83-60886177848e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-139249384-172.17.0.19-1597369796739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37178,DS-4d4f8ed2-a5f2-4e8a-9171-8af633047bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-872e685d-7c8e-4bd3-900d-906750d2c2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-098e9ff4-596b-4411-9955-1350ee9eb145,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-3ce3a403-da37-4344-a5e1-304a0cc01048,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-12080584-2149-4d21-92a0-193dc933cac0,DISK], DatanodeInfoWithStorage[127.0.0.1:34465,DS-c078a28b-0580-488d-ae58-76fd8d073d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-0267f642-a85f-4615-9c51-3dfe431eadf8,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-cac153b9-6acd-41f8-ac83-60886177848e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 30
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-836884955-172.17.0.19-1597370236668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44443,DS-15dc1be4-85db-47f7-9b52-8205747b5690,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-25b1e6f5-86b5-4811-b79e-ed2581da9bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-0e0c2b94-f511-4a0f-befe-d0c27aa14ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-d2077960-2480-4405-8e45-bf21e124a725,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-00a27472-09e6-44a5-9e2b-ee0a17b6e822,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-c382b14c-719b-4334-8423-bf556a78bbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-9dd34c93-141f-4ea4-acf4-e4ae3b132a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-74ef61c4-5d39-43b4-a887-b6d7fd6d770d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-836884955-172.17.0.19-1597370236668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44443,DS-15dc1be4-85db-47f7-9b52-8205747b5690,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-25b1e6f5-86b5-4811-b79e-ed2581da9bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-0e0c2b94-f511-4a0f-befe-d0c27aa14ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-d2077960-2480-4405-8e45-bf21e124a725,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-00a27472-09e6-44a5-9e2b-ee0a17b6e822,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-c382b14c-719b-4334-8423-bf556a78bbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-9dd34c93-141f-4ea4-acf4-e4ae3b132a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-74ef61c4-5d39-43b4-a887-b6d7fd6d770d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5634
