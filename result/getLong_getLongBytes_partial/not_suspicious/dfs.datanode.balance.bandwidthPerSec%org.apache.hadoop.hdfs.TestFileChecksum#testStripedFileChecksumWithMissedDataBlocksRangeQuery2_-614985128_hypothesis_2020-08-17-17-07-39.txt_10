reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-843781409-172.17.0.5-1597684487144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41940,DS-8f73256b-d184-43a0-a22b-1ad95dcc046c,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-3d4e210b-3fa2-47ff-98c9-aa9018966e43,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-a95b45b1-4286-4478-920a-ec21ced3d0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-cb762540-f695-4bd2-a9a1-9978d636965e,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-79e1d07c-319c-4eb3-a32c-c245d3e12ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-d2affdbc-2c62-4f7f-8666-ac993215ff87,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-31cc448d-449c-46a6-9800-893db1c6ca50,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-e15286ad-9e75-4df6-8df6-5865e5e9eb0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-843781409-172.17.0.5-1597684487144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41940,DS-8f73256b-d184-43a0-a22b-1ad95dcc046c,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-3d4e210b-3fa2-47ff-98c9-aa9018966e43,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-a95b45b1-4286-4478-920a-ec21ced3d0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-cb762540-f695-4bd2-a9a1-9978d636965e,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-79e1d07c-319c-4eb3-a32c-c245d3e12ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-d2affdbc-2c62-4f7f-8666-ac993215ff87,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-31cc448d-449c-46a6-9800-893db1c6ca50,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-e15286ad-9e75-4df6-8df6-5865e5e9eb0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638053866-172.17.0.5-1597685039450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42645,DS-85a9fe1d-f2df-499d-a176-fbcaf4752cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-e77ce091-a375-47a4-a1b9-49846458359c,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-6ddeba4e-e466-4f80-85ea-ed84d2d6e898,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-94285b0f-a518-4e99-ba4c-b650a795fa05,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-a8602908-da4c-4e6c-9d3d-d2ed8ca96f35,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-629d8707-33fb-40dc-b900-fea28995dcad,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-f2430dd8-1c37-4ef0-b0cc-d832b946e4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-c88ca92c-c3c4-4270-a455-0ffb4fe257bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638053866-172.17.0.5-1597685039450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42645,DS-85a9fe1d-f2df-499d-a176-fbcaf4752cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-e77ce091-a375-47a4-a1b9-49846458359c,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-6ddeba4e-e466-4f80-85ea-ed84d2d6e898,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-94285b0f-a518-4e99-ba4c-b650a795fa05,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-a8602908-da4c-4e6c-9d3d-d2ed8ca96f35,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-629d8707-33fb-40dc-b900-fea28995dcad,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-f2430dd8-1c37-4ef0-b0cc-d832b946e4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-c88ca92c-c3c4-4270-a455-0ffb4fe257bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-282025769-172.17.0.5-1597685239986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36407,DS-fe08eaa7-5c0f-4d0b-84f5-f39354ea9688,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-59eb2d1a-fb69-4a74-a5b5-ec2ed8356710,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-db04f647-a556-432e-88a5-01cbb97f70a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-5ae18cd4-cdbc-4863-b363-00ded5002eef,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-6f01e3f1-6c71-40c1-8826-e1d20f573cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-69059187-ecf2-4594-bcee-a8a4a5fd222e,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-916155ec-df8c-4a4a-a37d-ca5010859dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-8d108f90-105d-48b5-aea8-3a897730f3d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-282025769-172.17.0.5-1597685239986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36407,DS-fe08eaa7-5c0f-4d0b-84f5-f39354ea9688,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-59eb2d1a-fb69-4a74-a5b5-ec2ed8356710,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-db04f647-a556-432e-88a5-01cbb97f70a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-5ae18cd4-cdbc-4863-b363-00ded5002eef,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-6f01e3f1-6c71-40c1-8826-e1d20f573cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-69059187-ecf2-4594-bcee-a8a4a5fd222e,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-916155ec-df8c-4a4a-a37d-ca5010859dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-8d108f90-105d-48b5-aea8-3a897730f3d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2002013551-172.17.0.5-1597685356196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36500,DS-7f5794ad-ea0a-45c2-b434-58577f3fb79d,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-0b5d2b3e-e020-4251-86c9-1dc0ad7e8171,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-d344b1b6-4645-4119-88aa-b90ca0c534bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-6118e602-6dae-47ae-90c9-54f3e74d94b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-361da046-83ec-4f3f-a664-80041f768410,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-5f7b84ba-879b-4a31-9c72-8322c629376f,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-49fc549a-d86c-4871-9237-11b67b60937e,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-dad74eee-e81d-4142-9c71-6e7b47593fb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2002013551-172.17.0.5-1597685356196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36500,DS-7f5794ad-ea0a-45c2-b434-58577f3fb79d,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-0b5d2b3e-e020-4251-86c9-1dc0ad7e8171,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-d344b1b6-4645-4119-88aa-b90ca0c534bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-6118e602-6dae-47ae-90c9-54f3e74d94b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-361da046-83ec-4f3f-a664-80041f768410,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-5f7b84ba-879b-4a31-9c72-8322c629376f,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-49fc549a-d86c-4871-9237-11b67b60937e,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-dad74eee-e81d-4142-9c71-6e7b47593fb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596725221-172.17.0.5-1597686119506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40237,DS-a7ba38f3-2952-4d0f-a5fc-b0ba65aab586,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-9f33b093-5102-43e4-b09d-b6278bbdb8de,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-07ff47a0-1800-463a-9880-99e5faaaec37,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-b594b679-cb4e-451b-b196-9c6191ac479f,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-dcdb9105-eeb9-4c78-8180-ac4fbac6614c,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-7becdc23-cb94-4970-a322-6540ad0dcf90,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-0cc7ad93-a661-46e4-a5a9-44d6c39267f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-0bbe05fa-3f12-4d8d-9271-d334d6c86cba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596725221-172.17.0.5-1597686119506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40237,DS-a7ba38f3-2952-4d0f-a5fc-b0ba65aab586,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-9f33b093-5102-43e4-b09d-b6278bbdb8de,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-07ff47a0-1800-463a-9880-99e5faaaec37,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-b594b679-cb4e-451b-b196-9c6191ac479f,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-dcdb9105-eeb9-4c78-8180-ac4fbac6614c,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-7becdc23-cb94-4970-a322-6540ad0dcf90,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-0cc7ad93-a661-46e4-a5a9-44d6c39267f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-0bbe05fa-3f12-4d8d-9271-d334d6c86cba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1955146049-172.17.0.5-1597686478398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40916,DS-89877577-c2bb-4b77-a486-e779f16fe87d,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-8e452453-75a9-4c53-826c-589220240a23,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-77ecaa60-6e0b-4d76-a9c3-01b29084303d,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-160d8767-6a1b-448c-84c2-2bb832474894,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-427260a6-48b8-412d-bdc7-b33c9fc0f9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-afcb542b-b825-4c58-952b-37de0b6cdd37,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-ab01a11d-e821-4551-b2b3-23b5bea347f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-f985b5a7-e077-406e-8281-91c8a1142f78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1955146049-172.17.0.5-1597686478398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40916,DS-89877577-c2bb-4b77-a486-e779f16fe87d,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-8e452453-75a9-4c53-826c-589220240a23,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-77ecaa60-6e0b-4d76-a9c3-01b29084303d,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-160d8767-6a1b-448c-84c2-2bb832474894,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-427260a6-48b8-412d-bdc7-b33c9fc0f9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-afcb542b-b825-4c58-952b-37de0b6cdd37,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-ab01a11d-e821-4551-b2b3-23b5bea347f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-f985b5a7-e077-406e-8281-91c8a1142f78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-893104385-172.17.0.5-1597686639539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42189,DS-d7efac0b-1aff-4ce2-aca2-6d2b7f8c0626,DISK], DatanodeInfoWithStorage[127.0.0.1:36258,DS-c5804724-cd47-4185-8813-2dcf34729703,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-3fb22402-b27d-4933-822d-386f2e94ab46,DISK], DatanodeInfoWithStorage[127.0.0.1:35463,DS-635cb8cb-60c2-458c-8a17-4861c57dc062,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-94cde6f0-84d1-4e96-a3e0-ec7ccc633a25,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-cf467df9-3245-4f46-ba8f-de7fb146e89e,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-bfeb4d89-993c-40a1-ae1f-83c38ea1b903,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-692e5b94-09cc-47cb-8aef-aca50c5efc47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-893104385-172.17.0.5-1597686639539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42189,DS-d7efac0b-1aff-4ce2-aca2-6d2b7f8c0626,DISK], DatanodeInfoWithStorage[127.0.0.1:36258,DS-c5804724-cd47-4185-8813-2dcf34729703,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-3fb22402-b27d-4933-822d-386f2e94ab46,DISK], DatanodeInfoWithStorage[127.0.0.1:35463,DS-635cb8cb-60c2-458c-8a17-4861c57dc062,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-94cde6f0-84d1-4e96-a3e0-ec7ccc633a25,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-cf467df9-3245-4f46-ba8f-de7fb146e89e,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-bfeb4d89-993c-40a1-ae1f-83c38ea1b903,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-692e5b94-09cc-47cb-8aef-aca50c5efc47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1992592522-172.17.0.5-1597687387342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41212,DS-61dd32ad-ada6-4058-bc81-5df6e5ae78f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-f47f51e2-4d07-4741-8da4-d3a51887f258,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-5fa69f48-e753-4ef1-8095-d43148a677dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-fc89d890-1fc2-4617-9935-26d0e65dd72c,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-f4e4f0f4-b2c3-4a68-a292-293389262dae,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-46128945-9ca9-4cb7-9868-6f8f40ea7b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-ce0008c1-b1c7-4d5b-9c7c-4e0b8f31e458,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-154f30d1-cfb5-40bf-8218-9fdb0919da4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1992592522-172.17.0.5-1597687387342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41212,DS-61dd32ad-ada6-4058-bc81-5df6e5ae78f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-f47f51e2-4d07-4741-8da4-d3a51887f258,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-5fa69f48-e753-4ef1-8095-d43148a677dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-fc89d890-1fc2-4617-9935-26d0e65dd72c,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-f4e4f0f4-b2c3-4a68-a292-293389262dae,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-46128945-9ca9-4cb7-9868-6f8f40ea7b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-ce0008c1-b1c7-4d5b-9c7c-4e0b8f31e458,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-154f30d1-cfb5-40bf-8218-9fdb0919da4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467946729-172.17.0.5-1597687613577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42096,DS-5ebb44ea-1a87-46ca-9820-7bc03ea22c13,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-41d0af4e-58ab-4685-aadd-bbaf64310c94,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-cc715cc2-f9fc-42bd-b628-8e0b30b9bb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-3b314f6d-faaf-4322-a401-8b15c2cf6572,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-ac809576-eece-4a18-8086-9d9ea83baacb,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-9c1d5f86-b3d9-4acf-b1ca-f5558041a160,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-f02ec43e-e7c4-48de-84e9-6f0043625dad,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-77ed69e2-3559-4fea-bbec-aaa93017b386,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467946729-172.17.0.5-1597687613577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42096,DS-5ebb44ea-1a87-46ca-9820-7bc03ea22c13,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-41d0af4e-58ab-4685-aadd-bbaf64310c94,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-cc715cc2-f9fc-42bd-b628-8e0b30b9bb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-3b314f6d-faaf-4322-a401-8b15c2cf6572,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-ac809576-eece-4a18-8086-9d9ea83baacb,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-9c1d5f86-b3d9-4acf-b1ca-f5558041a160,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-f02ec43e-e7c4-48de-84e9-6f0043625dad,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-77ed69e2-3559-4fea-bbec-aaa93017b386,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1774571591-172.17.0.5-1597687723594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40080,DS-d8922442-4094-4731-9d4f-ac201ef9f79f,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-33317f74-4b45-45b4-a20e-2cd9a72179d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-9ecaa021-9977-485a-a3bf-21bb548cb294,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-fdedde93-25e4-4ab3-bd5a-ff1dede5571b,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-147d9c41-7777-423c-a9d1-a4028da30aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-cde50bfd-27bf-44d2-a251-dcce33d46d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-614363fb-647b-4244-be76-d98b45e64fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-64368344-e2d0-4e73-a52f-67d8af40d774,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1774571591-172.17.0.5-1597687723594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40080,DS-d8922442-4094-4731-9d4f-ac201ef9f79f,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-33317f74-4b45-45b4-a20e-2cd9a72179d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-9ecaa021-9977-485a-a3bf-21bb548cb294,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-fdedde93-25e4-4ab3-bd5a-ff1dede5571b,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-147d9c41-7777-423c-a9d1-a4028da30aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-cde50bfd-27bf-44d2-a251-dcce33d46d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-614363fb-647b-4244-be76-d98b45e64fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-64368344-e2d0-4e73-a52f-67d8af40d774,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124494066-172.17.0.5-1597687762800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38597,DS-520d1317-3199-41f2-9260-2923d0c55569,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-e1b3bcfc-cf72-4cbf-887b-9d079f11774b,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-3d2eb936-a4ed-4b05-8901-f16a533e6e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-f64ace0b-cd07-4bbd-9ae0-5b8ae82b9c76,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-3bf9f98a-7c6c-43e6-9aa7-e6f86a510075,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-c1f18fbc-ac83-45c5-9094-99495217e3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-c201ef59-5491-4cde-93a9-166cda25d1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-1d492d99-6459-4e21-b908-0e15daf536ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124494066-172.17.0.5-1597687762800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38597,DS-520d1317-3199-41f2-9260-2923d0c55569,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-e1b3bcfc-cf72-4cbf-887b-9d079f11774b,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-3d2eb936-a4ed-4b05-8901-f16a533e6e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-f64ace0b-cd07-4bbd-9ae0-5b8ae82b9c76,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-3bf9f98a-7c6c-43e6-9aa7-e6f86a510075,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-c1f18fbc-ac83-45c5-9094-99495217e3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-c201ef59-5491-4cde-93a9-166cda25d1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-1d492d99-6459-4e21-b908-0e15daf536ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1910446157-172.17.0.5-1597688159900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35352,DS-882f5f81-0f82-4fa7-9f5e-ff122522bef0,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-5aa6393d-e881-4865-9660-32b61f1273dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-f902a837-a9bc-4fb6-b79a-671bf3e5d8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-db60eb82-56ac-41fd-8cc6-651f89abe1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42251,DS-12f71449-09c2-41df-8ac6-849ca48913bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-9bf7c8f7-a09c-4627-aa5f-f4c6e32a18e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-0113a135-a603-40f8-9e0f-a7fe9644cfc0,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-3935b049-730a-4a93-9662-947e2e42ae8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1910446157-172.17.0.5-1597688159900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35352,DS-882f5f81-0f82-4fa7-9f5e-ff122522bef0,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-5aa6393d-e881-4865-9660-32b61f1273dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-f902a837-a9bc-4fb6-b79a-671bf3e5d8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-db60eb82-56ac-41fd-8cc6-651f89abe1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42251,DS-12f71449-09c2-41df-8ac6-849ca48913bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-9bf7c8f7-a09c-4627-aa5f-f4c6e32a18e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-0113a135-a603-40f8-9e0f-a7fe9644cfc0,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-3935b049-730a-4a93-9662-947e2e42ae8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-16316984-172.17.0.5-1597688513530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43374,DS-2b229a5e-365d-4342-be3f-12b1ca6cdbf4,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-ede08f33-31e5-453d-8334-b5eef2fcefa2,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-02657490-cdc4-40aa-9a5c-f9ab5e7c731b,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-14d4f47a-7f1e-4699-aec9-0946fb14b04f,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-e2b6039b-2321-410d-84ca-f7bbc2254c65,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-81fe599f-ba3d-4254-af31-80dc35fd94a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-1bed4dcd-1dc9-49c9-8c4c-caa052416429,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-40091c65-e6b9-4fce-82e1-899f1cd89dfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-16316984-172.17.0.5-1597688513530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43374,DS-2b229a5e-365d-4342-be3f-12b1ca6cdbf4,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-ede08f33-31e5-453d-8334-b5eef2fcefa2,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-02657490-cdc4-40aa-9a5c-f9ab5e7c731b,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-14d4f47a-7f1e-4699-aec9-0946fb14b04f,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-e2b6039b-2321-410d-84ca-f7bbc2254c65,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-81fe599f-ba3d-4254-af31-80dc35fd94a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-1bed4dcd-1dc9-49c9-8c4c-caa052416429,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-40091c65-e6b9-4fce-82e1-899f1cd89dfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-236052274-172.17.0.5-1597688662214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37492,DS-59e7647e-d397-4025-a44c-a22a597641ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-6b322744-a516-46c8-9e99-b851cd8736bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-43f8cd5e-f94c-49a4-937a-b6b0f136531b,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-6b19f490-cbde-401d-9394-1d3ffb44e41b,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-46de360e-cd79-4607-b6c0-9eb6ca791918,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-5d307821-754a-427d-83de-de2fea8e6fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-53bafb75-c6f2-4192-92ea-bb8b5a63f094,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-c2528db3-f07c-438c-a938-1fe75ae337aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-236052274-172.17.0.5-1597688662214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37492,DS-59e7647e-d397-4025-a44c-a22a597641ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-6b322744-a516-46c8-9e99-b851cd8736bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-43f8cd5e-f94c-49a4-937a-b6b0f136531b,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-6b19f490-cbde-401d-9394-1d3ffb44e41b,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-46de360e-cd79-4607-b6c0-9eb6ca791918,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-5d307821-754a-427d-83de-de2fea8e6fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-53bafb75-c6f2-4192-92ea-bb8b5a63f094,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-c2528db3-f07c-438c-a938-1fe75ae337aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-734348046-172.17.0.5-1597688725666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37395,DS-2c72da34-50b5-4e92-824f-7b3db852000b,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-c5fd7b12-93e1-43bd-b738-14b7ae8ee80c,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-61d7030b-e755-4ee8-9bb7-dac59825f8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-99d11d66-418e-4dfa-8e4e-b65ea27c5919,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-a820b9d3-39aa-4e77-8375-9197b00df2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-3d2a39b6-b1b0-4917-aa85-04a2556d612d,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-26f75821-fe1f-4dce-84fe-b676334f10b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-629653e6-7baf-4019-9af4-644575ff7afb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-734348046-172.17.0.5-1597688725666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37395,DS-2c72da34-50b5-4e92-824f-7b3db852000b,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-c5fd7b12-93e1-43bd-b738-14b7ae8ee80c,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-61d7030b-e755-4ee8-9bb7-dac59825f8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-99d11d66-418e-4dfa-8e4e-b65ea27c5919,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-a820b9d3-39aa-4e77-8375-9197b00df2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-3d2a39b6-b1b0-4917-aa85-04a2556d612d,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-26f75821-fe1f-4dce-84fe-b676334f10b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-629653e6-7baf-4019-9af4-644575ff7afb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1866140548-172.17.0.5-1597689311213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36821,DS-c9d0b16c-0a76-4f07-9c14-1cee51061c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-b95906ee-0ecd-4d63-affa-f291f3419816,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-d574e5cd-e889-4235-a087-018f49c6e2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-58e3bd5f-6074-43de-8cc7-179b653ed1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-db8675c8-6590-4079-9186-2609e156f902,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-ee6e135c-2008-46db-9591-001d0f921290,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-b71513f7-45e2-438f-b0d3-3d2154927c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-3fb8a73f-441e-4aa6-a983-ed1baf508a84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1866140548-172.17.0.5-1597689311213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36821,DS-c9d0b16c-0a76-4f07-9c14-1cee51061c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-b95906ee-0ecd-4d63-affa-f291f3419816,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-d574e5cd-e889-4235-a087-018f49c6e2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-58e3bd5f-6074-43de-8cc7-179b653ed1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-db8675c8-6590-4079-9186-2609e156f902,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-ee6e135c-2008-46db-9591-001d0f921290,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-b71513f7-45e2-438f-b0d3-3d2154927c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-3fb8a73f-441e-4aa6-a983-ed1baf508a84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-758661537-172.17.0.5-1597689480440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46511,DS-9962f9c5-cc59-4f29-8113-ea9a7e2d9538,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-791bda42-1e3a-433f-bca7-e5bf070cdcab,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-dbf8e050-7130-45b3-bff8-02491d0e33b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-e6d87817-10a7-4174-91ab-6178f414507e,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-28f80e4f-fa3b-4c4c-a22a-9bf59e3bd3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-8cc0a242-e1f9-4513-a3f2-6a9d5bb80228,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-b10d2d06-109f-43ef-8b44-e68de836245b,DISK], DatanodeInfoWithStorage[127.0.0.1:45029,DS-afc793cd-c208-45b4-a3cc-26b96f8544b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-758661537-172.17.0.5-1597689480440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46511,DS-9962f9c5-cc59-4f29-8113-ea9a7e2d9538,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-791bda42-1e3a-433f-bca7-e5bf070cdcab,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-dbf8e050-7130-45b3-bff8-02491d0e33b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-e6d87817-10a7-4174-91ab-6178f414507e,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-28f80e4f-fa3b-4c4c-a22a-9bf59e3bd3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-8cc0a242-e1f9-4513-a3f2-6a9d5bb80228,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-b10d2d06-109f-43ef-8b44-e68de836245b,DISK], DatanodeInfoWithStorage[127.0.0.1:45029,DS-afc793cd-c208-45b4-a3cc-26b96f8544b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107950978-172.17.0.5-1597689666929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35871,DS-86fe3164-4021-4fe3-98d2-4e0d7a567774,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-75fa8504-3fab-41c3-8a51-2f736697999a,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-b878663c-d213-4b27-b693-2bd9a20efea2,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-b1b8111a-c2bf-42f6-bed8-1203157f17ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-cf036fb5-b377-4916-892a-65e92e48016f,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-111b800d-2834-4b9e-b98f-00782e70754b,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-431a3ed7-cb45-42e3-ac17-66934b647763,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-b86860f3-a4e6-433f-a6e2-6eec743d4faf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107950978-172.17.0.5-1597689666929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35871,DS-86fe3164-4021-4fe3-98d2-4e0d7a567774,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-75fa8504-3fab-41c3-8a51-2f736697999a,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-b878663c-d213-4b27-b693-2bd9a20efea2,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-b1b8111a-c2bf-42f6-bed8-1203157f17ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-cf036fb5-b377-4916-892a-65e92e48016f,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-111b800d-2834-4b9e-b98f-00782e70754b,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-431a3ed7-cb45-42e3-ac17-66934b647763,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-b86860f3-a4e6-433f-a6e2-6eec743d4faf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1659564277-172.17.0.5-1597689707266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46801,DS-7156f030-86a0-405c-95b7-4051188d5629,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-1782b73e-913e-4f2c-96d1-46651588213f,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-874f69a1-629c-478e-bcbd-ac2aacc89b10,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-63ab33e2-cd06-496e-b786-77a9c2973db8,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-58f8a31c-4fc0-4627-9034-3e59d8271f85,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-f81d63de-f0a0-4fec-b589-90aec6613920,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-55b64ad5-bcfb-4a03-a290-bd7b4da08ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-10cb6ab7-149e-47b4-90b3-84e168863fe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1659564277-172.17.0.5-1597689707266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46801,DS-7156f030-86a0-405c-95b7-4051188d5629,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-1782b73e-913e-4f2c-96d1-46651588213f,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-874f69a1-629c-478e-bcbd-ac2aacc89b10,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-63ab33e2-cd06-496e-b786-77a9c2973db8,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-58f8a31c-4fc0-4627-9034-3e59d8271f85,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-f81d63de-f0a0-4fec-b589-90aec6613920,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-55b64ad5-bcfb-4a03-a290-bd7b4da08ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-10cb6ab7-149e-47b4-90b3-84e168863fe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5873
