reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1956908119-172.17.0.6-1597296438067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44426,DS-b0d93041-0205-4faa-825e-74c607abbbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-df23bc26-e930-4cf2-9694-8d438bd69b11,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-49ddb51a-a990-4b3b-a73e-5c4afdf5defd,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-6178ecd4-2fa1-4887-8c72-7e42685bf3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-d0df4b2f-c9fb-4541-b709-d6df7b1b6fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-746a7687-e37a-4485-bc86-4dd27ea407f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-61daa0fc-dee6-46cc-9727-c445a5c4bd34,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-9574457d-795d-43b9-8501-3e8d0dec8751,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1956908119-172.17.0.6-1597296438067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44426,DS-b0d93041-0205-4faa-825e-74c607abbbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-df23bc26-e930-4cf2-9694-8d438bd69b11,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-49ddb51a-a990-4b3b-a73e-5c4afdf5defd,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-6178ecd4-2fa1-4887-8c72-7e42685bf3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-d0df4b2f-c9fb-4541-b709-d6df7b1b6fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-746a7687-e37a-4485-bc86-4dd27ea407f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-61daa0fc-dee6-46cc-9727-c445a5c4bd34,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-9574457d-795d-43b9-8501-3e8d0dec8751,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317461299-172.17.0.6-1597296682049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41203,DS-81908143-0658-4135-84a5-3e5091fed34b,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-20a69613-3f21-4fa3-9b22-70a7117438db,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-67186f4e-488c-4238-9f3e-4a08dcd371ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-3eaa08bd-e9c5-47e7-b99e-efefac89def6,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-b828327e-e40e-44c2-9b28-3f0bd4f64286,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-496d3381-a3bd-4acf-86bd-593bdb57025d,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-2e81ee2e-dcc0-4832-9019-9e938d26d781,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-3e5e2606-6480-40b5-bd4f-ef970c512361,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317461299-172.17.0.6-1597296682049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41203,DS-81908143-0658-4135-84a5-3e5091fed34b,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-20a69613-3f21-4fa3-9b22-70a7117438db,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-67186f4e-488c-4238-9f3e-4a08dcd371ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-3eaa08bd-e9c5-47e7-b99e-efefac89def6,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-b828327e-e40e-44c2-9b28-3f0bd4f64286,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-496d3381-a3bd-4acf-86bd-593bdb57025d,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-2e81ee2e-dcc0-4832-9019-9e938d26d781,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-3e5e2606-6480-40b5-bd4f-ef970c512361,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81429001-172.17.0.6-1597296718382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42078,DS-5238b67b-75a4-4b44-997e-5f0196d0693f,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-4420c5f0-1d58-4d07-be85-a58d76d32cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-fce4306f-89a0-412b-a08f-4e1bc5ec13d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-362ffefb-8555-4615-8b41-2bf65fbb0105,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-ecdccabb-22d5-4355-b88a-4b29438fd0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-bc52f851-e36b-49b7-92e5-3d5efb1504ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-23161e76-7be9-4349-8b49-ffb2b7894af0,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-4002ab0c-a3f3-476e-b10e-4f9e86843467,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81429001-172.17.0.6-1597296718382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42078,DS-5238b67b-75a4-4b44-997e-5f0196d0693f,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-4420c5f0-1d58-4d07-be85-a58d76d32cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-fce4306f-89a0-412b-a08f-4e1bc5ec13d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-362ffefb-8555-4615-8b41-2bf65fbb0105,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-ecdccabb-22d5-4355-b88a-4b29438fd0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-bc52f851-e36b-49b7-92e5-3d5efb1504ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-23161e76-7be9-4349-8b49-ffb2b7894af0,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-4002ab0c-a3f3-476e-b10e-4f9e86843467,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-260324325-172.17.0.6-1597296874260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43636,DS-8c8a852f-a537-4379-8dc4-d6eeafad6301,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-19e3de07-6d82-4305-80a7-76330aaca2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-f1a73547-f3bf-4d20-81c3-ae73571a845a,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-0d39da2c-cd69-4b6c-8713-2d1f19723a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-abd5b220-8d6f-4e0c-a255-aa7f019c4281,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-ae32eb7e-8e26-4aff-99e1-66c359cdb291,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-74dd7e63-98af-4995-b556-dc276fe48371,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-fcaae902-c11b-4402-a9cd-67961a0bb653,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-260324325-172.17.0.6-1597296874260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43636,DS-8c8a852f-a537-4379-8dc4-d6eeafad6301,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-19e3de07-6d82-4305-80a7-76330aaca2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-f1a73547-f3bf-4d20-81c3-ae73571a845a,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-0d39da2c-cd69-4b6c-8713-2d1f19723a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-abd5b220-8d6f-4e0c-a255-aa7f019c4281,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-ae32eb7e-8e26-4aff-99e1-66c359cdb291,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-74dd7e63-98af-4995-b556-dc276fe48371,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-fcaae902-c11b-4402-a9cd-67961a0bb653,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-307239717-172.17.0.6-1597296985783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44184,DS-65e3abb8-bcc1-47b3-bea9-b4b9903d7a18,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-7ed92b08-63ac-491c-99a7-1dbcd08764dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-4ba70320-16a0-4d17-91b3-1179e2b1142a,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-e225eb38-3ff6-440d-a245-1ad907d9a3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-3e1b605e-182d-4b04-a535-5dcc0c352098,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-21ff9463-a843-45c0-9255-95281b3aa3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-90dd8ca8-1750-4beb-a9ec-e6652a959180,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-f91c7292-1d7f-41da-9aa3-89c42ac07110,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-307239717-172.17.0.6-1597296985783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44184,DS-65e3abb8-bcc1-47b3-bea9-b4b9903d7a18,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-7ed92b08-63ac-491c-99a7-1dbcd08764dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-4ba70320-16a0-4d17-91b3-1179e2b1142a,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-e225eb38-3ff6-440d-a245-1ad907d9a3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-3e1b605e-182d-4b04-a535-5dcc0c352098,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-21ff9463-a843-45c0-9255-95281b3aa3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-90dd8ca8-1750-4beb-a9ec-e6652a959180,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-f91c7292-1d7f-41da-9aa3-89c42ac07110,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424008041-172.17.0.6-1597297022985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44566,DS-c8c740fd-d6c3-4690-9a4f-66b3394df62f,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-44295e27-c29f-43ee-ae4f-3116be087ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-6b07498d-a891-4198-b98d-11c9f65f041a,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-b05d4181-7647-4909-8c25-10c0d64e0d25,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-634061bf-94c1-48ca-a684-67319c959e28,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-8a9f3d6b-e10a-4877-80dd-f552bb5f10e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-eb81a000-020a-45d1-bd6a-b167e82d6639,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-10cc999e-4fff-436f-b46a-448ae53e69b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424008041-172.17.0.6-1597297022985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44566,DS-c8c740fd-d6c3-4690-9a4f-66b3394df62f,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-44295e27-c29f-43ee-ae4f-3116be087ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-6b07498d-a891-4198-b98d-11c9f65f041a,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-b05d4181-7647-4909-8c25-10c0d64e0d25,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-634061bf-94c1-48ca-a684-67319c959e28,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-8a9f3d6b-e10a-4877-80dd-f552bb5f10e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-eb81a000-020a-45d1-bd6a-b167e82d6639,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-10cc999e-4fff-436f-b46a-448ae53e69b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245215613-172.17.0.6-1597297556189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34185,DS-10035762-ccd5-4fe1-8f84-4cf49afdb6af,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-961e3c84-1894-4c18-aa40-18bae9e9cad3,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-c0f0ad96-6b8e-41f8-9782-ef7e571d0727,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-da85afe2-4712-492a-9cee-9c84d78a2ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-66197f2e-cea2-4ae2-88fe-44a985a65570,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-729189dd-958d-463a-a567-8fe6c7ab3468,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-b21d0b5b-6e04-441a-a009-8283fe58487e,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-b50cd708-cf3f-402f-8e3f-3bef37739401,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245215613-172.17.0.6-1597297556189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34185,DS-10035762-ccd5-4fe1-8f84-4cf49afdb6af,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-961e3c84-1894-4c18-aa40-18bae9e9cad3,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-c0f0ad96-6b8e-41f8-9782-ef7e571d0727,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-da85afe2-4712-492a-9cee-9c84d78a2ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-66197f2e-cea2-4ae2-88fe-44a985a65570,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-729189dd-958d-463a-a567-8fe6c7ab3468,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-b21d0b5b-6e04-441a-a009-8283fe58487e,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-b50cd708-cf3f-402f-8e3f-3bef37739401,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1307117377-172.17.0.6-1597297868603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46417,DS-66b9b9bb-fe97-42d9-9b2d-7be5c92a88bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-262639cf-ed76-4665-b6f3-84c9b18d33b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-b9e9da2e-b220-4b52-b3e5-9102496a04bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-f37a9ce9-e7e3-4c7f-8665-45a86edd8860,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-51c77b2f-c16a-4835-bd6f-8f5292e2d589,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-07988e5e-b6a3-4fb2-9b95-74d3680adc8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-d9c79c77-7a97-496c-b2b5-788e5a56e6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-336348ac-76c8-4596-85ff-f3672f67f4b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1307117377-172.17.0.6-1597297868603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46417,DS-66b9b9bb-fe97-42d9-9b2d-7be5c92a88bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-262639cf-ed76-4665-b6f3-84c9b18d33b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-b9e9da2e-b220-4b52-b3e5-9102496a04bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-f37a9ce9-e7e3-4c7f-8665-45a86edd8860,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-51c77b2f-c16a-4835-bd6f-8f5292e2d589,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-07988e5e-b6a3-4fb2-9b95-74d3680adc8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-d9c79c77-7a97-496c-b2b5-788e5a56e6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-336348ac-76c8-4596-85ff-f3672f67f4b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1624850718-172.17.0.6-1597297989283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37809,DS-c483763c-1ef9-4828-8535-049488f9c599,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-38b2516b-f05e-4bed-92ac-cfea0d95d906,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-cd99784d-beeb-45cf-ad95-c9f87781768b,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-5ea39d18-1cef-4ca5-aa6c-8453c6f7f6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-f721a7bd-5081-40e5-b18a-b3e0f359360a,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-a0f46a75-e7b0-4b54-9f3d-ea7c8b10f455,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-b0d2dc4c-ed6b-4a02-85fe-a8ec28381620,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-11c4ab90-ff4a-49cd-84d0-3ff8c5716391,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1624850718-172.17.0.6-1597297989283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37809,DS-c483763c-1ef9-4828-8535-049488f9c599,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-38b2516b-f05e-4bed-92ac-cfea0d95d906,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-cd99784d-beeb-45cf-ad95-c9f87781768b,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-5ea39d18-1cef-4ca5-aa6c-8453c6f7f6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-f721a7bd-5081-40e5-b18a-b3e0f359360a,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-a0f46a75-e7b0-4b54-9f3d-ea7c8b10f455,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-b0d2dc4c-ed6b-4a02-85fe-a8ec28381620,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-11c4ab90-ff4a-49cd-84d0-3ff8c5716391,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1835217736-172.17.0.6-1597298663698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41028,DS-323d4053-f335-4ab7-a9ae-d6ceb1e517a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-269b9746-2887-46c1-9aba-075aa33df954,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-294a56d0-8b26-4fab-b79b-921be2bd2a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-26118edf-5f3a-4921-a62c-a8f610c6f01b,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-c519b044-5bd9-47bc-945f-9ba68f87be75,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-8a577335-b34c-49a7-a26e-c16c22ae2d39,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-20773cc8-229f-4bbd-845a-2de5be10065f,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-338747ea-a308-4045-9ef8-25864d890008,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1835217736-172.17.0.6-1597298663698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41028,DS-323d4053-f335-4ab7-a9ae-d6ceb1e517a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-269b9746-2887-46c1-9aba-075aa33df954,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-294a56d0-8b26-4fab-b79b-921be2bd2a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-26118edf-5f3a-4921-a62c-a8f610c6f01b,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-c519b044-5bd9-47bc-945f-9ba68f87be75,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-8a577335-b34c-49a7-a26e-c16c22ae2d39,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-20773cc8-229f-4bbd-845a-2de5be10065f,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-338747ea-a308-4045-9ef8-25864d890008,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510355757-172.17.0.6-1597298695532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36847,DS-854eea72-318c-4f90-8482-6eab4d88b598,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-453d79dc-9344-4a12-bd90-f736fe25adcc,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-6df662ab-8836-4f5c-ac05-9c4c6b96420e,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-ac8b0b99-4665-4bda-bb37-d2b73f571e02,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-1a25171d-dc41-4c8e-bdb2-1d9eda2d1970,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-e0648c7b-1bfc-4a9b-adfc-a79ec50f2a37,DISK], DatanodeInfoWithStorage[127.0.0.1:35823,DS-7799bcb6-fb9b-4d29-8c5a-827c5a21f334,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-b432fdcf-49e6-4912-808a-692ed7f4e0d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510355757-172.17.0.6-1597298695532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36847,DS-854eea72-318c-4f90-8482-6eab4d88b598,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-453d79dc-9344-4a12-bd90-f736fe25adcc,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-6df662ab-8836-4f5c-ac05-9c4c6b96420e,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-ac8b0b99-4665-4bda-bb37-d2b73f571e02,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-1a25171d-dc41-4c8e-bdb2-1d9eda2d1970,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-e0648c7b-1bfc-4a9b-adfc-a79ec50f2a37,DISK], DatanodeInfoWithStorage[127.0.0.1:35823,DS-7799bcb6-fb9b-4d29-8c5a-827c5a21f334,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-b432fdcf-49e6-4912-808a-692ed7f4e0d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344996792-172.17.0.6-1597299322838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42142,DS-75f8abfa-2988-444f-ad1a-6e4f44fc47e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-22045808-c934-47de-9672-ca94aa4c8a78,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-210ed47f-c0bb-4d63-acb0-eb9d33356ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-7bd13274-5a14-4f25-83fc-fb6a0f96ca54,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-f637d9ed-b0cf-47e7-8cae-465591757696,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-9443eacf-a192-406d-89ff-062c8bf64640,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-7a530ee7-4d13-4443-82fd-674a75b854c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-efaea512-e6d4-4c37-8db0-71d58cf75e01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344996792-172.17.0.6-1597299322838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42142,DS-75f8abfa-2988-444f-ad1a-6e4f44fc47e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-22045808-c934-47de-9672-ca94aa4c8a78,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-210ed47f-c0bb-4d63-acb0-eb9d33356ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-7bd13274-5a14-4f25-83fc-fb6a0f96ca54,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-f637d9ed-b0cf-47e7-8cae-465591757696,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-9443eacf-a192-406d-89ff-062c8bf64640,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-7a530ee7-4d13-4443-82fd-674a75b854c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-efaea512-e6d4-4c37-8db0-71d58cf75e01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328354917-172.17.0.6-1597299478401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44316,DS-d6f58b8a-e328-4252-b44d-a1be6583a895,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-3c7bb34c-af27-49bd-9e1e-545a8f793d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-fc7edbf9-d4fe-4700-975b-3b8aff2ea8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-5a88cf3e-7c12-4742-9893-573038cd9124,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-6fcc883b-4a70-42e0-89a9-09a1f2051fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-7bc4fe9b-8abb-4786-8256-b8b64d64ca8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-00e4c0c9-5cf3-470a-bd16-92e22c5daa01,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-389eeaa2-e728-435c-b6c4-638c4aff6dab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328354917-172.17.0.6-1597299478401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44316,DS-d6f58b8a-e328-4252-b44d-a1be6583a895,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-3c7bb34c-af27-49bd-9e1e-545a8f793d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-fc7edbf9-d4fe-4700-975b-3b8aff2ea8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-5a88cf3e-7c12-4742-9893-573038cd9124,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-6fcc883b-4a70-42e0-89a9-09a1f2051fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-7bc4fe9b-8abb-4786-8256-b8b64d64ca8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-00e4c0c9-5cf3-470a-bd16-92e22c5daa01,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-389eeaa2-e728-435c-b6c4-638c4aff6dab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258650326-172.17.0.6-1597299672967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40448,DS-97c42d8a-6015-4ad5-9220-bef2e16a6658,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-26ab0ddb-f7aa-48fa-938d-68b1ce518fac,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-34866447-10f4-4a0e-9031-238bcb4bf2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-3831dd92-6cc3-4e3d-9f02-700d3e582029,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-34ed3fec-590b-4753-95cc-d697b3f73a64,DISK], DatanodeInfoWithStorage[127.0.0.1:44299,DS-ec169890-5583-4df0-9ee5-d00b8c400248,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-b3252a6c-03de-4e7f-b257-08a57d1761c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-bb52831e-c11b-4c11-af4c-c8e81feb8d2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258650326-172.17.0.6-1597299672967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40448,DS-97c42d8a-6015-4ad5-9220-bef2e16a6658,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-26ab0ddb-f7aa-48fa-938d-68b1ce518fac,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-34866447-10f4-4a0e-9031-238bcb4bf2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-3831dd92-6cc3-4e3d-9f02-700d3e582029,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-34ed3fec-590b-4753-95cc-d697b3f73a64,DISK], DatanodeInfoWithStorage[127.0.0.1:44299,DS-ec169890-5583-4df0-9ee5-d00b8c400248,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-b3252a6c-03de-4e7f-b257-08a57d1761c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-bb52831e-c11b-4c11-af4c-c8e81feb8d2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2128041303-172.17.0.6-1597300060741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46167,DS-5a4258cd-6500-4456-aaae-c29e0cca44a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-33e8b137-8889-4905-ba00-9e7d3180e35d,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-62f3ebcc-b210-4a1b-881d-8d6dfc259dda,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-a8de0eca-ddac-451f-bec0-3d8ab19dbb92,DISK], DatanodeInfoWithStorage[127.0.0.1:40388,DS-1fc2ba44-5cc6-46ef-82e5-2f3ab7ae81ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-3dce6ab1-9ae8-4f18-9f85-dbeaab0c4509,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-b94c8e63-a1a8-4393-9024-59788802774f,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-84e9dce1-96f9-42ac-9bb8-1ea5e27e04f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2128041303-172.17.0.6-1597300060741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46167,DS-5a4258cd-6500-4456-aaae-c29e0cca44a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-33e8b137-8889-4905-ba00-9e7d3180e35d,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-62f3ebcc-b210-4a1b-881d-8d6dfc259dda,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-a8de0eca-ddac-451f-bec0-3d8ab19dbb92,DISK], DatanodeInfoWithStorage[127.0.0.1:40388,DS-1fc2ba44-5cc6-46ef-82e5-2f3ab7ae81ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-3dce6ab1-9ae8-4f18-9f85-dbeaab0c4509,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-b94c8e63-a1a8-4393-9024-59788802774f,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-84e9dce1-96f9-42ac-9bb8-1ea5e27e04f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167948772-172.17.0.6-1597300097574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46014,DS-6498b287-52c4-4621-904a-5ae2bdb03df6,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-1b63ff75-7bf5-49c3-aac3-256ee974cd15,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-fa62ec46-50bc-4e97-a311-3a358bf03302,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-4182bf05-49c8-4000-9648-c1c1a7984ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-2fb84b7c-8a7a-498d-aa71-e3e662e116c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-d230a6dc-d99e-4ecd-9826-8e61f11311f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-964a71f7-f8d8-4d11-b491-372613b65dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-27bc51c2-3bfd-4c81-b6c2-edecb72cac35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167948772-172.17.0.6-1597300097574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46014,DS-6498b287-52c4-4621-904a-5ae2bdb03df6,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-1b63ff75-7bf5-49c3-aac3-256ee974cd15,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-fa62ec46-50bc-4e97-a311-3a358bf03302,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-4182bf05-49c8-4000-9648-c1c1a7984ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-2fb84b7c-8a7a-498d-aa71-e3e662e116c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-d230a6dc-d99e-4ecd-9826-8e61f11311f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-964a71f7-f8d8-4d11-b491-372613b65dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-27bc51c2-3bfd-4c81-b6c2-edecb72cac35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517824967-172.17.0.6-1597300212355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34671,DS-41c6f969-1aa7-477e-86b9-030afa1b61c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-2355f304-28a7-491b-8714-f6877a536a50,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-ea1f624a-087f-4fde-852f-20dfd9b1ee82,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-7f2bcea5-6e41-4d53-ab3d-1db31583caaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-85859dee-dc29-44a7-9297-299f4742df95,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-fefd058b-87f4-4a35-93ae-768fa2eaddb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-2261bc15-f681-4b89-8623-5134d102f26c,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-d9bb390a-e6b9-4766-8508-506f7bb98df3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517824967-172.17.0.6-1597300212355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34671,DS-41c6f969-1aa7-477e-86b9-030afa1b61c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-2355f304-28a7-491b-8714-f6877a536a50,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-ea1f624a-087f-4fde-852f-20dfd9b1ee82,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-7f2bcea5-6e41-4d53-ab3d-1db31583caaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-85859dee-dc29-44a7-9297-299f4742df95,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-fefd058b-87f4-4a35-93ae-768fa2eaddb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-2261bc15-f681-4b89-8623-5134d102f26c,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-d9bb390a-e6b9-4766-8508-506f7bb98df3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1171169924-172.17.0.6-1597300254179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38171,DS-f370a9f6-8ce2-451d-a3f7-0badf836c59d,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-9d2c9766-3ca6-4680-bc4a-0807726d9664,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-591bf268-bbfe-408d-b9f7-384f734b320e,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-e9d77f1f-9626-49ab-92fb-191423220645,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-8d564a8e-6a4d-4562-b3fb-2dc1a73c3e91,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-fb7456d3-3ff9-4634-a481-8fafd996cdfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-705ec9a0-5df4-40de-8561-8e7c7a1fb420,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-d11b627c-7d5f-43a0-be00-74aec570e162,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1171169924-172.17.0.6-1597300254179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38171,DS-f370a9f6-8ce2-451d-a3f7-0badf836c59d,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-9d2c9766-3ca6-4680-bc4a-0807726d9664,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-591bf268-bbfe-408d-b9f7-384f734b320e,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-e9d77f1f-9626-49ab-92fb-191423220645,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-8d564a8e-6a4d-4562-b3fb-2dc1a73c3e91,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-fb7456d3-3ff9-4634-a481-8fafd996cdfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-705ec9a0-5df4-40de-8561-8e7c7a1fb420,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-d11b627c-7d5f-43a0-be00-74aec570e162,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1559359912-172.17.0.6-1597301035031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36992,DS-f8e3ac09-d23f-47e0-abd3-5c5966537eff,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-0e7ba0ac-670e-4ea2-8e36-ca3b0b3dbbed,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-b6ebff0a-7272-4c79-b36a-3829f3a1ffc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-014e7fb7-ce5b-49ab-a4f4-cc760c4f1ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-0da4ce4c-2ecd-456a-9c6a-e359d4703cca,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-d1c4cdb8-cb67-4380-b41c-0219c7d082f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-6ff6ddb6-778a-4544-ab70-7246526ce236,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-f1905004-0481-4c03-bdc3-2519a9dbb279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1559359912-172.17.0.6-1597301035031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36992,DS-f8e3ac09-d23f-47e0-abd3-5c5966537eff,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-0e7ba0ac-670e-4ea2-8e36-ca3b0b3dbbed,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-b6ebff0a-7272-4c79-b36a-3829f3a1ffc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-014e7fb7-ce5b-49ab-a4f4-cc760c4f1ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-0da4ce4c-2ecd-456a-9c6a-e359d4703cca,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-d1c4cdb8-cb67-4380-b41c-0219c7d082f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-6ff6ddb6-778a-4544-ab70-7246526ce236,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-f1905004-0481-4c03-bdc3-2519a9dbb279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1279949414-172.17.0.6-1597301216131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36329,DS-1eaab5fa-0933-40c9-9548-1bfdfdf77d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-0a3f7198-6fa5-4fbf-b283-042527c2ba04,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-1f95e389-bf77-4298-8c51-7183397304f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-35c472cf-a29f-4ad7-a576-b924822d2a40,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-7bfef37b-8264-4f4f-ab8a-13ff55833df6,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-05d403a8-b515-4888-a5f4-4aca84f2c9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-ef6a5e83-5ad3-47e8-a471-034703061e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-11babe22-c3c1-4d83-a6cc-b708e95d0f15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1279949414-172.17.0.6-1597301216131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36329,DS-1eaab5fa-0933-40c9-9548-1bfdfdf77d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-0a3f7198-6fa5-4fbf-b283-042527c2ba04,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-1f95e389-bf77-4298-8c51-7183397304f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-35c472cf-a29f-4ad7-a576-b924822d2a40,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-7bfef37b-8264-4f4f-ab8a-13ff55833df6,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-05d403a8-b515-4888-a5f4-4aca84f2c9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-ef6a5e83-5ad3-47e8-a471-034703061e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-11babe22-c3c1-4d83-a6cc-b708e95d0f15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486035744-172.17.0.6-1597301345213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34535,DS-44ed9839-5680-436b-ade7-109078332d79,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-54a3e853-c24a-4b38-8fe5-99de7892e6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-333a234e-53c4-46c8-a7a7-aef05452bf46,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-8b56de73-69cf-4f3e-a20f-771a5f37bc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-916a1ab6-85e5-44de-a269-9b31429a4252,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-fac1b736-da7c-4a4f-b51b-7a42c7b03dff,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-62b7ab59-aff0-4f03-8c17-46c8db4238a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-f71aaf1d-e815-42d1-8ed2-e54ad4de62e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486035744-172.17.0.6-1597301345213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34535,DS-44ed9839-5680-436b-ade7-109078332d79,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-54a3e853-c24a-4b38-8fe5-99de7892e6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-333a234e-53c4-46c8-a7a7-aef05452bf46,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-8b56de73-69cf-4f3e-a20f-771a5f37bc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-916a1ab6-85e5-44de-a269-9b31429a4252,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-fac1b736-da7c-4a4f-b51b-7a42c7b03dff,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-62b7ab59-aff0-4f03-8c17-46c8db4238a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-f71aaf1d-e815-42d1-8ed2-e54ad4de62e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1540218747-172.17.0.6-1597301563855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45994,DS-26e084c8-7290-4c78-b16d-4276fa46d308,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-737eb341-9ae2-497a-a3fa-3b4b5d477550,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-a0dc9f07-bc92-4e1b-9f29-47784da4b842,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-6d6822d8-b921-4dd3-af52-bd45803c4bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-511aa31a-e757-4d12-abef-5e401a752700,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-91042524-bbf7-4fe8-bf65-52f5378a7465,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-53cbc727-d4b1-4b55-84d8-bb2c11c657d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-eac1e164-d501-4482-b111-9dc203758bee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1540218747-172.17.0.6-1597301563855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45994,DS-26e084c8-7290-4c78-b16d-4276fa46d308,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-737eb341-9ae2-497a-a3fa-3b4b5d477550,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-a0dc9f07-bc92-4e1b-9f29-47784da4b842,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-6d6822d8-b921-4dd3-af52-bd45803c4bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-511aa31a-e757-4d12-abef-5e401a752700,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-91042524-bbf7-4fe8-bf65-52f5378a7465,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-53cbc727-d4b1-4b55-84d8-bb2c11c657d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-eac1e164-d501-4482-b111-9dc203758bee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5828
