reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144967765-172.17.0.10-1597743917430:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36792,DS-5b17423d-f2e4-4e8f-b8dc-c57329e9e9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-bea6d763-8ed7-4a02-9b0a-dc36f97f595a,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-25de7abc-b0c8-4e62-9f56-39a6728619b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-b69df203-b91e-4ab1-9aca-c260657507a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-1e8bdef9-e234-40e2-ab50-1c0631920475,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-10f1a54a-e34b-4fff-a267-4285cde9e919,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-d0b48fb6-c12a-4aaf-97e2-79713a092569,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-457a007d-80d7-4bf9-ac0a-0b88433aa5fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144967765-172.17.0.10-1597743917430:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36792,DS-5b17423d-f2e4-4e8f-b8dc-c57329e9e9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-bea6d763-8ed7-4a02-9b0a-dc36f97f595a,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-25de7abc-b0c8-4e62-9f56-39a6728619b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-b69df203-b91e-4ab1-9aca-c260657507a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-1e8bdef9-e234-40e2-ab50-1c0631920475,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-10f1a54a-e34b-4fff-a267-4285cde9e919,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-d0b48fb6-c12a-4aaf-97e2-79713a092569,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-457a007d-80d7-4bf9-ac0a-0b88433aa5fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144202689-172.17.0.10-1597743996942:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37357,DS-219dea1a-78a5-4224-8287-831c92187109,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-cda7b0b1-5247-4c6a-a35e-6375b5770ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-e253479b-d66b-4afb-82db-80917da2759b,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-48236744-ddc1-4d93-be01-54a58f76c4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-1a9938f5-4cc9-43dd-a61d-61092ab6fc65,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-e18d0492-533b-4b1a-ac31-6565a3f58f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-3cda5f62-fa3f-4285-858e-66b635d88528,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-94a348d2-5397-4c37-bd1f-8b45ee7dd7de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144202689-172.17.0.10-1597743996942:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37357,DS-219dea1a-78a5-4224-8287-831c92187109,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-cda7b0b1-5247-4c6a-a35e-6375b5770ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-e253479b-d66b-4afb-82db-80917da2759b,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-48236744-ddc1-4d93-be01-54a58f76c4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-1a9938f5-4cc9-43dd-a61d-61092ab6fc65,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-e18d0492-533b-4b1a-ac31-6565a3f58f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-3cda5f62-fa3f-4285-858e-66b635d88528,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-94a348d2-5397-4c37-bd1f-8b45ee7dd7de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-207356940-172.17.0.10-1597744437752:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44282,DS-c2a0b373-e5ac-44ba-ad5b-12301278e4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-14043c43-0e0d-4278-b0ca-e0369894b4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-7161287a-60fb-4626-8c39-08e0cd9a49ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-575477da-ab44-49cd-9e9c-17c1379cfc18,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-3c387297-0dd5-46e1-bcb7-cfecf3a4985e,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-07fe1603-a199-4549-9c68-1997bbf86df4,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-9ada46e7-f351-44ec-9cff-838f8f667893,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-7f960eca-899b-4def-9d0a-75bf2919c04e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-207356940-172.17.0.10-1597744437752:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44282,DS-c2a0b373-e5ac-44ba-ad5b-12301278e4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-14043c43-0e0d-4278-b0ca-e0369894b4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-7161287a-60fb-4626-8c39-08e0cd9a49ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-575477da-ab44-49cd-9e9c-17c1379cfc18,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-3c387297-0dd5-46e1-bcb7-cfecf3a4985e,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-07fe1603-a199-4549-9c68-1997bbf86df4,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-9ada46e7-f351-44ec-9cff-838f8f667893,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-7f960eca-899b-4def-9d0a-75bf2919c04e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1454321500-172.17.0.10-1597744560538:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42437,DS-14655b13-1636-43ad-994e-555b9daeaebc,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-9c2ff7a6-969d-433a-91fc-fac93312d8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-0a784148-2518-4546-9d0e-05900b785744,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-865e46d4-93a5-4fa5-bd4b-aca6940d59a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-16f96085-1445-4322-a67b-ebce9e7a3b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-892406d7-6105-41cd-94b5-bbb9f654aa6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-5196a87f-830b-4f01-9e51-0e227528142c,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-aa170430-6e89-43cb-9318-90c62878b644,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1454321500-172.17.0.10-1597744560538:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42437,DS-14655b13-1636-43ad-994e-555b9daeaebc,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-9c2ff7a6-969d-433a-91fc-fac93312d8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-0a784148-2518-4546-9d0e-05900b785744,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-865e46d4-93a5-4fa5-bd4b-aca6940d59a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-16f96085-1445-4322-a67b-ebce9e7a3b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-892406d7-6105-41cd-94b5-bbb9f654aa6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-5196a87f-830b-4f01-9e51-0e227528142c,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-aa170430-6e89-43cb-9318-90c62878b644,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258839628-172.17.0.10-1597744916177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33275,DS-711bbf14-e580-436a-8dda-839954896f90,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-f32f1b82-4236-441f-b87b-b9e699e536a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-2b39a8ef-10fc-45ad-95c1-c2be04ea380c,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-873cf588-dd69-452c-9825-ea6a503ca7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-ca990aea-da8d-415e-8ac9-3560ab29e5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-5dfe0a5d-21a6-4814-be78-64875b3dfad8,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-b8198913-a925-4ddf-9a4c-038385273d35,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-457072ea-946e-47f6-bcc2-480f28125d2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258839628-172.17.0.10-1597744916177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33275,DS-711bbf14-e580-436a-8dda-839954896f90,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-f32f1b82-4236-441f-b87b-b9e699e536a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-2b39a8ef-10fc-45ad-95c1-c2be04ea380c,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-873cf588-dd69-452c-9825-ea6a503ca7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-ca990aea-da8d-415e-8ac9-3560ab29e5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-5dfe0a5d-21a6-4814-be78-64875b3dfad8,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-b8198913-a925-4ddf-9a4c-038385273d35,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-457072ea-946e-47f6-bcc2-480f28125d2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841614586-172.17.0.10-1597745193012:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38383,DS-dc093d5d-a003-483d-9983-66cba258b682,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-1f7690d2-3aca-4838-a08f-3155d3f1ef1e,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-675b6d0b-0816-4a97-aa9a-294ca0fbe452,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-5fc9e7ba-7525-4d9c-be1b-3da153af4223,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-1d5d1acb-e714-4896-bbcd-e4797e7d8bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-3b112423-99c7-4c2b-836f-d736c05dbdc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-f599ae6a-45c2-4bfe-b3c9-9dab4dcfab36,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-cd38fe06-3e06-4cc6-b10c-5811e9054232,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841614586-172.17.0.10-1597745193012:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38383,DS-dc093d5d-a003-483d-9983-66cba258b682,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-1f7690d2-3aca-4838-a08f-3155d3f1ef1e,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-675b6d0b-0816-4a97-aa9a-294ca0fbe452,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-5fc9e7ba-7525-4d9c-be1b-3da153af4223,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-1d5d1acb-e714-4896-bbcd-e4797e7d8bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-3b112423-99c7-4c2b-836f-d736c05dbdc5,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-f599ae6a-45c2-4bfe-b3c9-9dab4dcfab36,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-cd38fe06-3e06-4cc6-b10c-5811e9054232,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558672140-172.17.0.10-1597746135296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33153,DS-eecbe73c-e154-4088-93c9-c3c883476801,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-355023fe-625f-451b-a758-47935f661a04,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-f7f1bc2e-df03-4781-a243-74a66643cd03,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-dfc86d48-18f7-4f83-a740-f24fe0589cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-1dc0b913-4461-4b49-9446-27614d80cb98,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-1d585784-6e3b-4abb-83b3-c64ae0475a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-5bb69ef6-d97a-4afc-9c97-d074e86a6e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-475b0cb5-2361-4cf5-8e7a-ecc7a6a42750,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558672140-172.17.0.10-1597746135296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33153,DS-eecbe73c-e154-4088-93c9-c3c883476801,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-355023fe-625f-451b-a758-47935f661a04,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-f7f1bc2e-df03-4781-a243-74a66643cd03,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-dfc86d48-18f7-4f83-a740-f24fe0589cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-1dc0b913-4461-4b49-9446-27614d80cb98,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-1d585784-6e3b-4abb-83b3-c64ae0475a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-5bb69ef6-d97a-4afc-9c97-d074e86a6e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-475b0cb5-2361-4cf5-8e7a-ecc7a6a42750,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638259086-172.17.0.10-1597746692220:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45400,DS-dc870760-aedb-4009-84a1-b5de3d3b6c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-e181e363-5ac5-44d1-a889-ed93836513d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-7732a23f-6b03-446d-96a8-bddc8fa3919a,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-5060f743-fc0b-4d7d-b163-8aa4b219a971,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-5b9eaaac-9573-4617-a37e-80acdcc59125,DISK], DatanodeInfoWithStorage[127.0.0.1:35309,DS-01f46e50-8aff-41ba-a04c-2c3e5d3e787c,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-3d21a518-8d99-4477-99c9-20ab68f09776,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-5746c2ba-5b99-47df-9afb-fb58c1ea73d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638259086-172.17.0.10-1597746692220:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45400,DS-dc870760-aedb-4009-84a1-b5de3d3b6c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-e181e363-5ac5-44d1-a889-ed93836513d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-7732a23f-6b03-446d-96a8-bddc8fa3919a,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-5060f743-fc0b-4d7d-b163-8aa4b219a971,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-5b9eaaac-9573-4617-a37e-80acdcc59125,DISK], DatanodeInfoWithStorage[127.0.0.1:35309,DS-01f46e50-8aff-41ba-a04c-2c3e5d3e787c,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-3d21a518-8d99-4477-99c9-20ab68f09776,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-5746c2ba-5b99-47df-9afb-fb58c1ea73d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-228376146-172.17.0.10-1597746732588:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44335,DS-139f9400-67af-44a0-83fe-4ad85d4e20c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-16845c06-3c97-4618-a4f8-42a9d92a04ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-efbcc35c-7512-48d2-8ce1-ec63c0af894e,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-0b43e0b8-c30f-440a-b742-a77cd9389a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-282e41a9-d97d-4318-9fd2-33ea80672b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-1e15c4f9-070d-424e-b47a-9a8a5dcf0988,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-4ce62d29-b8c5-4e5b-81fc-89f62292073e,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-47c1bf13-bb18-449f-a37f-af271c9e8044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-228376146-172.17.0.10-1597746732588:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44335,DS-139f9400-67af-44a0-83fe-4ad85d4e20c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-16845c06-3c97-4618-a4f8-42a9d92a04ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-efbcc35c-7512-48d2-8ce1-ec63c0af894e,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-0b43e0b8-c30f-440a-b742-a77cd9389a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-282e41a9-d97d-4318-9fd2-33ea80672b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-1e15c4f9-070d-424e-b47a-9a8a5dcf0988,DISK], DatanodeInfoWithStorage[127.0.0.1:41876,DS-4ce62d29-b8c5-4e5b-81fc-89f62292073e,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-47c1bf13-bb18-449f-a37f-af271c9e8044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124591258-172.17.0.10-1597747807548:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33913,DS-4bf28c8f-9075-4d7a-9b77-27c2eec00f25,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-dbc365d7-ba09-48d8-a0f7-219ff8a1bb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-738e774f-5f8d-46ae-a565-6a1524e5514b,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-387d96fd-e676-409d-b02e-71e0ebcb5b55,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-49dc105c-af78-47f7-a0d9-11e4708e73db,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-a0c33500-23ef-4b13-9c07-64f05334dfc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-f193c65c-85eb-49ee-b033-7b0f654181a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-424c9858-eede-4116-a3f7-3b649449f942,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124591258-172.17.0.10-1597747807548:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33913,DS-4bf28c8f-9075-4d7a-9b77-27c2eec00f25,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-dbc365d7-ba09-48d8-a0f7-219ff8a1bb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-738e774f-5f8d-46ae-a565-6a1524e5514b,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-387d96fd-e676-409d-b02e-71e0ebcb5b55,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-49dc105c-af78-47f7-a0d9-11e4708e73db,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-a0c33500-23ef-4b13-9c07-64f05334dfc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-f193c65c-85eb-49ee-b033-7b0f654181a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-424c9858-eede-4116-a3f7-3b649449f942,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-735371627-172.17.0.10-1597747875757:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39981,DS-510d5615-e791-4d91-ac5f-0cc0c49fe0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39652,DS-7f4bb8aa-a515-41fe-ab33-24b78520d0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-4e6d290a-62f4-44b1-91d3-ab736a2133e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-9df3fc81-5be1-45c4-a12c-9a60cb56cbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-c1577355-3105-4e2b-bb9d-b44ed0c72814,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-389e3c0c-c6ab-44b0-9acd-31263ae21a75,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-cccc6320-0f06-4ea8-afef-87583ab402f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-63ffa7d2-4bd5-48a0-8949-0f3e4b694a8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-735371627-172.17.0.10-1597747875757:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39981,DS-510d5615-e791-4d91-ac5f-0cc0c49fe0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39652,DS-7f4bb8aa-a515-41fe-ab33-24b78520d0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-4e6d290a-62f4-44b1-91d3-ab736a2133e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-9df3fc81-5be1-45c4-a12c-9a60cb56cbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-c1577355-3105-4e2b-bb9d-b44ed0c72814,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-389e3c0c-c6ab-44b0-9acd-31263ae21a75,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-cccc6320-0f06-4ea8-afef-87583ab402f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-63ffa7d2-4bd5-48a0-8949-0f3e4b694a8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701461238-172.17.0.10-1597748012073:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39568,DS-18f1858b-a911-44f2-9949-20dad52d6076,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-51063cce-33c5-4f4a-a2f8-19f6daf15bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-bacf3b3e-e16f-4e1d-96af-e7ea940bae91,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-aa99fe99-9803-466c-822a-f0b234e28c06,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-0778f1e5-fbfa-47e4-913d-b733cb9978e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-8ff274b5-2ded-445e-9940-fc56084c335c,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-01388653-7530-40fc-9466-844dd12ccb19,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-935258ae-11b6-4500-85f1-ad6ceb25b678,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701461238-172.17.0.10-1597748012073:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39568,DS-18f1858b-a911-44f2-9949-20dad52d6076,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-51063cce-33c5-4f4a-a2f8-19f6daf15bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-bacf3b3e-e16f-4e1d-96af-e7ea940bae91,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-aa99fe99-9803-466c-822a-f0b234e28c06,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-0778f1e5-fbfa-47e4-913d-b733cb9978e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-8ff274b5-2ded-445e-9940-fc56084c335c,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-01388653-7530-40fc-9466-844dd12ccb19,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-935258ae-11b6-4500-85f1-ad6ceb25b678,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-494846616-172.17.0.10-1597748274609:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33336,DS-bad5a745-09af-45ab-83f9-311267dba287,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-53cf1de2-9b60-4b1e-adc6-f9738596aa36,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-a43e1c60-ea65-4602-b581-2234e7a41690,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-d990ed25-5659-4e52-9506-3e9f8ed851bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-5e552ded-f2e5-4722-83a5-13a8954c898f,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-c029647e-43cf-4746-8376-f5ac71d17f68,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-9aaec9db-984b-4c3d-8862-6ba6d909db33,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-9d6e6e27-aa9d-434f-8706-8f1a05502afe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-494846616-172.17.0.10-1597748274609:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33336,DS-bad5a745-09af-45ab-83f9-311267dba287,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-53cf1de2-9b60-4b1e-adc6-f9738596aa36,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-a43e1c60-ea65-4602-b581-2234e7a41690,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-d990ed25-5659-4e52-9506-3e9f8ed851bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-5e552ded-f2e5-4722-83a5-13a8954c898f,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-c029647e-43cf-4746-8376-f5ac71d17f68,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-9aaec9db-984b-4c3d-8862-6ba6d909db33,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-9d6e6e27-aa9d-434f-8706-8f1a05502afe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 5232
