reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1379424971-172.17.0.12-1597332526854:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39659,DS-ea7a8898-c33b-4ea4-9757-384f0a49cd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-a3f608cb-2c11-4c68-9a76-294a48110324,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-9c24643d-cd92-48e2-b24d-89a380c8f54e,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-e34b94ed-052a-4514-85d5-1dbf6766f067,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-3baa979d-c660-4d16-a0ac-c0d932925fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-2dda7e2a-e232-4df7-aabf-77ec3ed7d7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-82cd6d98-5f11-474c-bbea-e67b2245edca,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-36b71710-0c8c-459e-b332-690391f30fa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1379424971-172.17.0.12-1597332526854:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39659,DS-ea7a8898-c33b-4ea4-9757-384f0a49cd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-a3f608cb-2c11-4c68-9a76-294a48110324,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-9c24643d-cd92-48e2-b24d-89a380c8f54e,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-e34b94ed-052a-4514-85d5-1dbf6766f067,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-3baa979d-c660-4d16-a0ac-c0d932925fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-2dda7e2a-e232-4df7-aabf-77ec3ed7d7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-82cd6d98-5f11-474c-bbea-e67b2245edca,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-36b71710-0c8c-459e-b332-690391f30fa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1709299792-172.17.0.12-1597332663780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33468,DS-6f3b93e7-516f-4fdc-bf62-c65439ad4e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-75d25dcb-9d99-44d6-8e82-78ebec4c0bae,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-99106c9e-5906-4860-8816-bf76d6dbf213,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-46df3b71-f944-406d-add7-c612209b4fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-a0d0828c-0a69-4e12-a9de-9a5675c8d51a,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-12935f6c-d6d8-459b-9f7d-47b2c48f9da0,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-1ff94c4f-cbbf-4a5a-b0d0-964ef9ea5a31,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-6f840c2a-3d9a-45d6-b464-4305b01fcfef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1709299792-172.17.0.12-1597332663780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33468,DS-6f3b93e7-516f-4fdc-bf62-c65439ad4e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-75d25dcb-9d99-44d6-8e82-78ebec4c0bae,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-99106c9e-5906-4860-8816-bf76d6dbf213,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-46df3b71-f944-406d-add7-c612209b4fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-a0d0828c-0a69-4e12-a9de-9a5675c8d51a,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-12935f6c-d6d8-459b-9f7d-47b2c48f9da0,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-1ff94c4f-cbbf-4a5a-b0d0-964ef9ea5a31,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-6f840c2a-3d9a-45d6-b464-4305b01fcfef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-767976777-172.17.0.12-1597332771931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39265,DS-d537ebe0-9753-4faf-841a-cc140cc42e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-406a8319-d5c9-46a2-876d-441b296f3e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-45099745-2b5f-49ec-b6f5-7d5802fa2a57,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-ad5329d8-09bf-40dc-aa7a-d45b2b59ef95,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-71f8df04-66d0-4791-876a-4fd7012d544a,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-85384632-f570-468f-8700-2c7c5e448d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36700,DS-4cf56ac8-1eea-4b2d-8311-98a73d43ce42,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-5cc859d8-4924-4d3f-8b0a-5bb7e81dd467,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-767976777-172.17.0.12-1597332771931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39265,DS-d537ebe0-9753-4faf-841a-cc140cc42e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-406a8319-d5c9-46a2-876d-441b296f3e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-45099745-2b5f-49ec-b6f5-7d5802fa2a57,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-ad5329d8-09bf-40dc-aa7a-d45b2b59ef95,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-71f8df04-66d0-4791-876a-4fd7012d544a,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-85384632-f570-468f-8700-2c7c5e448d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36700,DS-4cf56ac8-1eea-4b2d-8311-98a73d43ce42,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-5cc859d8-4924-4d3f-8b0a-5bb7e81dd467,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1935678655-172.17.0.12-1597332913927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45971,DS-02f11c71-80bf-487e-a6c3-b28180b3ef8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-8252a6ec-b926-4647-ab71-128dd8e3f9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-665f1768-42f8-4589-94dd-4a83fee24b30,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-6510dd16-fa46-4c3a-b692-8e25c143dae8,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-26613aa0-a6ef-40a9-9f28-e6ffbeac21d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-9f450b29-c783-462f-8dbf-898a50269c76,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-b5c6e6dc-4a10-4fc7-a50a-e24a134496d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-aeb24e09-a5e6-42d6-96c7-a1aea9581b65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1935678655-172.17.0.12-1597332913927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45971,DS-02f11c71-80bf-487e-a6c3-b28180b3ef8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-8252a6ec-b926-4647-ab71-128dd8e3f9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-665f1768-42f8-4589-94dd-4a83fee24b30,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-6510dd16-fa46-4c3a-b692-8e25c143dae8,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-26613aa0-a6ef-40a9-9f28-e6ffbeac21d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-9f450b29-c783-462f-8dbf-898a50269c76,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-b5c6e6dc-4a10-4fc7-a50a-e24a134496d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-aeb24e09-a5e6-42d6-96c7-a1aea9581b65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1088555580-172.17.0.12-1597333113299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39599,DS-73806b66-8f1f-4ec3-89c4-c56db347c381,DISK], DatanodeInfoWithStorage[127.0.0.1:37321,DS-b569f5a8-5937-4222-b20a-4a3099846b92,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-19edda0a-83a3-44a3-8873-8803c8b34ade,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-eb4cb892-b3c1-4c64-aca2-6a3e1ca7b8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-79edaf26-b330-400b-bc2b-054bce046d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-8c2ba7e8-3b04-413f-b842-39588c767188,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-8221f404-8843-4e1d-8f8b-47f065bf151f,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-4acde3a7-19ae-4f3a-827f-321e2ede296b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1088555580-172.17.0.12-1597333113299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39599,DS-73806b66-8f1f-4ec3-89c4-c56db347c381,DISK], DatanodeInfoWithStorage[127.0.0.1:37321,DS-b569f5a8-5937-4222-b20a-4a3099846b92,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-19edda0a-83a3-44a3-8873-8803c8b34ade,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-eb4cb892-b3c1-4c64-aca2-6a3e1ca7b8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-79edaf26-b330-400b-bc2b-054bce046d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-8c2ba7e8-3b04-413f-b842-39588c767188,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-8221f404-8843-4e1d-8f8b-47f065bf151f,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-4acde3a7-19ae-4f3a-827f-321e2ede296b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-724926384-172.17.0.12-1597333214527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41870,DS-544c6f69-f825-4ae3-88e5-858bd9a3321c,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-b8a2ce8a-b0a8-4b1c-a17d-3697308133c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-eb67cf00-9900-4ca1-83ab-dcd1ddd3cf1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-767c7503-de90-4ef3-87f9-39043791ee5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-bfe92c12-79a9-4f40-8069-12cddd68fd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-88dbc50b-825f-4a2e-a189-30acfe448f14,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-021da4d9-ac11-457b-be6c-5ba4984465b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-ea51ec7e-cf4c-42c3-b6f2-ef645f8e7908,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-724926384-172.17.0.12-1597333214527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41870,DS-544c6f69-f825-4ae3-88e5-858bd9a3321c,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-b8a2ce8a-b0a8-4b1c-a17d-3697308133c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-eb67cf00-9900-4ca1-83ab-dcd1ddd3cf1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-767c7503-de90-4ef3-87f9-39043791ee5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-bfe92c12-79a9-4f40-8069-12cddd68fd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-88dbc50b-825f-4a2e-a189-30acfe448f14,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-021da4d9-ac11-457b-be6c-5ba4984465b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-ea51ec7e-cf4c-42c3-b6f2-ef645f8e7908,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1606772871-172.17.0.12-1597333327729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44321,DS-dcbf73b4-aeff-41b8-9874-46b3efed5b62,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-6b122a11-8825-4251-abf7-39a6c5e77295,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-bb7f03a3-0638-40a0-a0aa-879e8e5c2304,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-82c5ccf1-81a9-40b7-a248-900266d71eae,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-2e82d1e6-128c-4911-bbe4-bf3a117355fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-df47eb61-23f4-4b71-a1ed-59336bf3da3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-4264e1cf-c9b7-47d6-89d3-21992c71216f,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-6c820e13-0f15-4e5a-ad50-316735e0ba67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1606772871-172.17.0.12-1597333327729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44321,DS-dcbf73b4-aeff-41b8-9874-46b3efed5b62,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-6b122a11-8825-4251-abf7-39a6c5e77295,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-bb7f03a3-0638-40a0-a0aa-879e8e5c2304,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-82c5ccf1-81a9-40b7-a248-900266d71eae,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-2e82d1e6-128c-4911-bbe4-bf3a117355fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-df47eb61-23f4-4b71-a1ed-59336bf3da3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-4264e1cf-c9b7-47d6-89d3-21992c71216f,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-6c820e13-0f15-4e5a-ad50-316735e0ba67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2009430864-172.17.0.12-1597333697817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45935,DS-1cd2bd1c-e92e-42b8-983b-a64fd973f787,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-d4247c48-366e-4591-bc9c-1502fe83f03b,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-263a39d0-11e0-4683-804b-94627a5608a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-9aa7ba45-0b26-45dc-8a7e-a93177fe4085,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-249d1eeb-8a55-4299-a2e6-07c13407480c,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-7f0c68ab-9714-44f2-8632-bc60155edb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-00f839cb-f5c2-4208-8509-e8d6b8e1c519,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-8e1e2840-d171-424e-8880-b8ee5127a044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2009430864-172.17.0.12-1597333697817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45935,DS-1cd2bd1c-e92e-42b8-983b-a64fd973f787,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-d4247c48-366e-4591-bc9c-1502fe83f03b,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-263a39d0-11e0-4683-804b-94627a5608a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-9aa7ba45-0b26-45dc-8a7e-a93177fe4085,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-249d1eeb-8a55-4299-a2e6-07c13407480c,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-7f0c68ab-9714-44f2-8632-bc60155edb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-00f839cb-f5c2-4208-8509-e8d6b8e1c519,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-8e1e2840-d171-424e-8880-b8ee5127a044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-158039097-172.17.0.12-1597334525036:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35071,DS-133b729c-48ca-4e30-8b8e-82dc9c1d5a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-e0a87c37-49f0-4e71-b217-778caba8285b,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-bdbef375-87ac-4c96-b968-56b43e49ef94,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-242cd612-b36d-4cbf-8075-36afc2eb8577,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-98e92bb5-b6f4-4e10-91af-906f5952463e,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-2a483723-a2f3-423d-bffc-0a60b6bfa376,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-4345a4e0-d9a9-48c9-a12f-35997900a39f,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-83556e47-4165-4f49-838e-370d6ae0f709,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-158039097-172.17.0.12-1597334525036:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35071,DS-133b729c-48ca-4e30-8b8e-82dc9c1d5a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-e0a87c37-49f0-4e71-b217-778caba8285b,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-bdbef375-87ac-4c96-b968-56b43e49ef94,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-242cd612-b36d-4cbf-8075-36afc2eb8577,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-98e92bb5-b6f4-4e10-91af-906f5952463e,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-2a483723-a2f3-423d-bffc-0a60b6bfa376,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-4345a4e0-d9a9-48c9-a12f-35997900a39f,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-83556e47-4165-4f49-838e-370d6ae0f709,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-53294677-172.17.0.12-1597335966116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33702,DS-7d03ccc0-4e1e-4522-99e3-88cc756804fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-67bedd11-9d06-4c9a-8c0f-5cd15af5d695,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-92fdc15e-6032-407d-bf8a-84bac5740b30,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-322a855f-1242-472f-aa32-f754b7155cac,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-7dfd01ac-e797-4828-ae2d-a0063195e9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-a521360f-b927-434d-9294-d11a5fa2a364,DISK], DatanodeInfoWithStorage[127.0.0.1:43498,DS-04c61586-c589-4200-9d60-6d216228b289,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-a7153a24-7727-4c8e-81ea-4bf2c6140ad5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-53294677-172.17.0.12-1597335966116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33702,DS-7d03ccc0-4e1e-4522-99e3-88cc756804fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-67bedd11-9d06-4c9a-8c0f-5cd15af5d695,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-92fdc15e-6032-407d-bf8a-84bac5740b30,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-322a855f-1242-472f-aa32-f754b7155cac,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-7dfd01ac-e797-4828-ae2d-a0063195e9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-a521360f-b927-434d-9294-d11a5fa2a364,DISK], DatanodeInfoWithStorage[127.0.0.1:43498,DS-04c61586-c589-4200-9d60-6d216228b289,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-a7153a24-7727-4c8e-81ea-4bf2c6140ad5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-701067479-172.17.0.12-1597336359391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38135,DS-a3246ba2-1525-474d-b32e-824a411f0764,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-195568d9-e30d-4da4-84b3-963b871bd9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-624d9230-7d08-4995-ab9a-c843c49de7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-1051dfdb-fc59-48e8-bf0c-7865a40b0942,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-0bbf0e80-0ffd-4778-8f41-72d58368971b,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-fd8413e3-979f-4fea-9c5a-12108f306f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-a20b0909-27e0-4a56-829f-73d7151ccf75,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-eb849dbd-d336-4af5-84a3-ce8be373d58f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-701067479-172.17.0.12-1597336359391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38135,DS-a3246ba2-1525-474d-b32e-824a411f0764,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-195568d9-e30d-4da4-84b3-963b871bd9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-624d9230-7d08-4995-ab9a-c843c49de7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-1051dfdb-fc59-48e8-bf0c-7865a40b0942,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-0bbf0e80-0ffd-4778-8f41-72d58368971b,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-fd8413e3-979f-4fea-9c5a-12108f306f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-a20b0909-27e0-4a56-829f-73d7151ccf75,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-eb849dbd-d336-4af5-84a3-ce8be373d58f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2023029426-172.17.0.12-1597336780663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46125,DS-f756f6b3-e2de-4c87-b107-03163c299e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-07d2e179-c355-412a-8669-e82ccccc5844,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-b76ea672-d676-42d0-9209-c32ec61dac10,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-6c4e425b-6803-475d-b9e6-7f6b77541fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-36864327-8f81-45d3-9eed-7b6e08c97866,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-7a7fec77-c504-43e9-9acd-194e453c8a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-9943ba55-35d6-4fda-81bf-1f35b77273b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-7a59cd26-6fcf-40b3-aa1f-dd1cd2bc7dc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2023029426-172.17.0.12-1597336780663:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46125,DS-f756f6b3-e2de-4c87-b107-03163c299e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-07d2e179-c355-412a-8669-e82ccccc5844,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-b76ea672-d676-42d0-9209-c32ec61dac10,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-6c4e425b-6803-475d-b9e6-7f6b77541fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-36864327-8f81-45d3-9eed-7b6e08c97866,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-7a7fec77-c504-43e9-9acd-194e453c8a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-9943ba55-35d6-4fda-81bf-1f35b77273b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-7a59cd26-6fcf-40b3-aa1f-dd1cd2bc7dc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 10000
v2: 9000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-467184561-172.17.0.12-1597337023600:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43402,DS-a1f43b92-787c-4648-9eed-df647ac37a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-e68dfe6a-aa54-4792-9bcf-85ddc2d85be7,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-09a6c780-679b-4683-b7b6-5579a4d98c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-eb50785b-7282-487b-bf04-0b84e67cdd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-4caa3236-16e9-4a21-971c-d1dda686c2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-7d24b1f5-32aa-46e9-9a3a-fe5a7484cc64,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-19167277-5936-4b25-8d8f-fd479bc1a352,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-0a044554-f8fb-4be9-9077-b47ba9e17068,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-467184561-172.17.0.12-1597337023600:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43402,DS-a1f43b92-787c-4648-9eed-df647ac37a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-e68dfe6a-aa54-4792-9bcf-85ddc2d85be7,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-09a6c780-679b-4683-b7b6-5579a4d98c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-eb50785b-7282-487b-bf04-0b84e67cdd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-4caa3236-16e9-4a21-971c-d1dda686c2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-7d24b1f5-32aa-46e9-9a3a-fe5a7484cc64,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-19167277-5936-4b25-8d8f-fd479bc1a352,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-0a044554-f8fb-4be9-9077-b47ba9e17068,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5173
