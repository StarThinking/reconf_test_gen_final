reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-299605631-172.17.0.3-1597342207792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45549,DS-4a2fba07-3521-4b4b-81a2-2f11dbcdf74a,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-547d9a90-eb80-4bcb-87ca-6b4f4cf26f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-69329124-2425-4017-9e2b-d4f7fd2fe497,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-4c98210f-9b17-452f-b84f-9999c5ec287a,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-d4e62e42-b9d0-4d11-bffd-f209d0efc1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-d7d3ec91-0bf9-4f0c-ad2c-aec08ff1f9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-88ef7397-0d85-433d-9ca5-c5260fddb7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-c01274b4-a000-415c-bb9a-64d8914d2426,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-299605631-172.17.0.3-1597342207792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45549,DS-4a2fba07-3521-4b4b-81a2-2f11dbcdf74a,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-547d9a90-eb80-4bcb-87ca-6b4f4cf26f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-69329124-2425-4017-9e2b-d4f7fd2fe497,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-4c98210f-9b17-452f-b84f-9999c5ec287a,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-d4e62e42-b9d0-4d11-bffd-f209d0efc1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-d7d3ec91-0bf9-4f0c-ad2c-aec08ff1f9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-88ef7397-0d85-433d-9ca5-c5260fddb7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-c01274b4-a000-415c-bb9a-64d8914d2426,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1614317659-172.17.0.3-1597342574962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40882,DS-76ff2f27-e5fe-46b5-abc5-2612ae9e330f,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-27de0a1d-bf7b-4849-9b46-91bbe6cce5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-d0b27d06-352c-4c2b-94aa-cc87e31f3d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-459cae10-9d12-4c13-afdf-7e7aca550154,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-be614ceb-c5f6-4675-b456-5a791bbcca9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-9e9a5eec-cfcd-48f4-84f5-e949257aaaec,DISK], DatanodeInfoWithStorage[127.0.0.1:33900,DS-98529662-5e59-4c7a-9cda-d107590e659d,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-5735668f-11e8-48c4-8002-83d5c0656222,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1614317659-172.17.0.3-1597342574962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40882,DS-76ff2f27-e5fe-46b5-abc5-2612ae9e330f,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-27de0a1d-bf7b-4849-9b46-91bbe6cce5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-d0b27d06-352c-4c2b-94aa-cc87e31f3d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-459cae10-9d12-4c13-afdf-7e7aca550154,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-be614ceb-c5f6-4675-b456-5a791bbcca9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-9e9a5eec-cfcd-48f4-84f5-e949257aaaec,DISK], DatanodeInfoWithStorage[127.0.0.1:33900,DS-98529662-5e59-4c7a-9cda-d107590e659d,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-5735668f-11e8-48c4-8002-83d5c0656222,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1743111580-172.17.0.3-1597343447672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32966,DS-2c1d20c6-33c6-4035-9421-451d335e27f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-102fb53d-d703-4768-ae5c-c8cef615e541,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-7b0b71a2-bcc5-49db-b0a1-378e281ec4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-619e550b-1224-4c5d-b865-c798d78f9124,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-7cee586e-031f-4ce5-994b-4c8a4961dbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-e1bb6c7e-b6b1-44fd-9b7f-1173c1cdb0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-e78c76f6-2f1c-4c67-9cb3-8003b8f1ae2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-59f617e8-4f9b-4073-b76d-a5626d3467ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1743111580-172.17.0.3-1597343447672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32966,DS-2c1d20c6-33c6-4035-9421-451d335e27f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-102fb53d-d703-4768-ae5c-c8cef615e541,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-7b0b71a2-bcc5-49db-b0a1-378e281ec4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-619e550b-1224-4c5d-b865-c798d78f9124,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-7cee586e-031f-4ce5-994b-4c8a4961dbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-e1bb6c7e-b6b1-44fd-9b7f-1173c1cdb0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-e78c76f6-2f1c-4c67-9cb3-8003b8f1ae2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-59f617e8-4f9b-4073-b76d-a5626d3467ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1343310683-172.17.0.3-1597343898726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44485,DS-c3ff0fcc-876f-4149-b342-d1aeb742f22c,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-a94ca259-080d-4833-b352-4ba4687d4361,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-8aaf8775-a20b-4e79-93c5-381de051e2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-ccb6cfac-0031-40a4-8d19-cad786d7b477,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-e973dd84-8368-4f1e-8f94-1ee01b5262ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-255c7415-c3b4-498c-b519-d6db35cdeed4,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-6067563f-82f6-4253-8ba9-081c05150d63,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-cbd8c9b8-45e4-43bd-b446-e30314d7694c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1343310683-172.17.0.3-1597343898726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44485,DS-c3ff0fcc-876f-4149-b342-d1aeb742f22c,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-a94ca259-080d-4833-b352-4ba4687d4361,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-8aaf8775-a20b-4e79-93c5-381de051e2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-ccb6cfac-0031-40a4-8d19-cad786d7b477,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-e973dd84-8368-4f1e-8f94-1ee01b5262ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-255c7415-c3b4-498c-b519-d6db35cdeed4,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-6067563f-82f6-4253-8ba9-081c05150d63,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-cbd8c9b8-45e4-43bd-b446-e30314d7694c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049569196-172.17.0.3-1597344235605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45653,DS-04d0741f-0051-4889-b65e-cef96a4e2e43,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-704faed2-72cf-4b49-a605-7baa89a6347f,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-666cf4fc-a4c9-48e6-8030-a4e9b57c0118,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-949c1154-c457-4217-904f-45feacb2edea,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-e9947800-88e4-4397-a184-887941588c61,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-309b4186-5b86-41da-9eae-f858604c6ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-99ee9b53-a043-4e9f-8b4b-e1ff05821f74,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-f06ffd48-c18f-4003-a554-79ee4e17e8b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049569196-172.17.0.3-1597344235605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45653,DS-04d0741f-0051-4889-b65e-cef96a4e2e43,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-704faed2-72cf-4b49-a605-7baa89a6347f,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-666cf4fc-a4c9-48e6-8030-a4e9b57c0118,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-949c1154-c457-4217-904f-45feacb2edea,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-e9947800-88e4-4397-a184-887941588c61,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-309b4186-5b86-41da-9eae-f858604c6ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-99ee9b53-a043-4e9f-8b4b-e1ff05821f74,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-f06ffd48-c18f-4003-a554-79ee4e17e8b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-613612816-172.17.0.3-1597344506942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39317,DS-423b6246-6846-432c-a5e2-ef5570cea14c,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-19a37c1a-cc84-491e-a353-66585a6f6c85,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-deb2180b-e3c5-46ac-8de3-135f81810e10,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-cb31ef3d-ee75-4155-9436-f62c1780f8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-aa5e9279-9b90-41d7-9273-4e917dc6a661,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-33a6e155-d6a0-4d3e-9d61-9b12d5bd30fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-503dc110-c2bd-4e1e-8d8a-62cf3227fe92,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-e350bec3-2347-4b1e-9655-3724eccf0571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-613612816-172.17.0.3-1597344506942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39317,DS-423b6246-6846-432c-a5e2-ef5570cea14c,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-19a37c1a-cc84-491e-a353-66585a6f6c85,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-deb2180b-e3c5-46ac-8de3-135f81810e10,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-cb31ef3d-ee75-4155-9436-f62c1780f8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-aa5e9279-9b90-41d7-9273-4e917dc6a661,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-33a6e155-d6a0-4d3e-9d61-9b12d5bd30fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-503dc110-c2bd-4e1e-8d8a-62cf3227fe92,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-e350bec3-2347-4b1e-9655-3724eccf0571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838396944-172.17.0.3-1597344673431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43231,DS-7b637fe3-2750-4e1d-8458-c7a54d580902,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-0096c37d-5a58-4c2d-9342-ad22ef657fda,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-9fa7d478-ddd0-4ed9-8dae-0de92f50a839,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-1697044a-0c79-48f8-97b1-7399e53e6be1,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-9cd26327-e57c-4428-abf5-5ca19f9fa65e,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-1534417d-c90a-4e03-9d0d-94164b3471be,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-b4c9cafb-4192-400a-ad7b-0c5e34cb8d23,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-00db8726-feab-490c-905f-a8f0e3ae46bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838396944-172.17.0.3-1597344673431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43231,DS-7b637fe3-2750-4e1d-8458-c7a54d580902,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-0096c37d-5a58-4c2d-9342-ad22ef657fda,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-9fa7d478-ddd0-4ed9-8dae-0de92f50a839,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-1697044a-0c79-48f8-97b1-7399e53e6be1,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-9cd26327-e57c-4428-abf5-5ca19f9fa65e,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-1534417d-c90a-4e03-9d0d-94164b3471be,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-b4c9cafb-4192-400a-ad7b-0c5e34cb8d23,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-00db8726-feab-490c-905f-a8f0e3ae46bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2080000972-172.17.0.3-1597345128837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45073,DS-50d168be-0076-4480-be9f-0494bdbf2df8,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-fcd3603c-00b2-4d7c-a82e-3d1957cd0865,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-4e8ddec7-284f-49a7-bfe2-65c0a6a1e050,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-57480f83-0a96-46fa-b857-24796ff598e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-20fa2d6c-b54e-4fcb-8fe4-29d1d495c838,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-f4bb9ae6-7596-4b88-94f7-ce386883e2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-5d615109-9d5f-4c5b-aace-85735c0b2172,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-1b43b9bf-f32a-4a2d-bdd9-cfcc047c1e6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2080000972-172.17.0.3-1597345128837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45073,DS-50d168be-0076-4480-be9f-0494bdbf2df8,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-fcd3603c-00b2-4d7c-a82e-3d1957cd0865,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-4e8ddec7-284f-49a7-bfe2-65c0a6a1e050,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-57480f83-0a96-46fa-b857-24796ff598e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-20fa2d6c-b54e-4fcb-8fe4-29d1d495c838,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-f4bb9ae6-7596-4b88-94f7-ce386883e2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-5d615109-9d5f-4c5b-aace-85735c0b2172,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-1b43b9bf-f32a-4a2d-bdd9-cfcc047c1e6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058584539-172.17.0.3-1597346112747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39745,DS-2197b253-7756-495d-a0a4-c584c8c76744,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-5dbcedfc-532f-42eb-926a-ee33d22afff6,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-67acdedf-f79a-4d34-96bf-6176f9acdf80,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-4a1a1f93-7b3a-41c5-a3aa-081eaca509c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-8f340334-c5be-4230-b9e9-0479df2688df,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-80d0fa00-4bdd-4ba1-a707-e46d97212e29,DISK], DatanodeInfoWithStorage[127.0.0.1:34747,DS-7f865f83-3486-4c2f-bc98-a6bf86d805d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-5201bc28-6089-4bdd-9bcf-6f40483223e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058584539-172.17.0.3-1597346112747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39745,DS-2197b253-7756-495d-a0a4-c584c8c76744,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-5dbcedfc-532f-42eb-926a-ee33d22afff6,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-67acdedf-f79a-4d34-96bf-6176f9acdf80,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-4a1a1f93-7b3a-41c5-a3aa-081eaca509c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-8f340334-c5be-4230-b9e9-0479df2688df,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-80d0fa00-4bdd-4ba1-a707-e46d97212e29,DISK], DatanodeInfoWithStorage[127.0.0.1:34747,DS-7f865f83-3486-4c2f-bc98-a6bf86d805d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-5201bc28-6089-4bdd-9bcf-6f40483223e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-649245425-172.17.0.3-1597346156707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38327,DS-d31e375f-079f-465d-bc51-7e1df8b4582a,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-66c5e813-bb7a-4b81-acf1-2d301c7b6c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-654a1317-b7dc-49d9-98f6-68d11a1b09b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-0487b5fa-1486-4236-abff-b53a843c39d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-6e70ed70-e767-4e8f-a9e6-c623e92899d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-393ea36c-f7a3-4343-90b7-1cc405d2e764,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-a232c0d2-287a-4f83-a4b1-6eaa9d3c6cea,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-22aa2f8c-1b46-4349-9eb7-c6386b0a6d8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-649245425-172.17.0.3-1597346156707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38327,DS-d31e375f-079f-465d-bc51-7e1df8b4582a,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-66c5e813-bb7a-4b81-acf1-2d301c7b6c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-654a1317-b7dc-49d9-98f6-68d11a1b09b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-0487b5fa-1486-4236-abff-b53a843c39d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-6e70ed70-e767-4e8f-a9e6-c623e92899d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-393ea36c-f7a3-4343-90b7-1cc405d2e764,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-a232c0d2-287a-4f83-a4b1-6eaa9d3c6cea,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-22aa2f8c-1b46-4349-9eb7-c6386b0a6d8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-94550766-172.17.0.3-1597346240032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42900,DS-5e2b38b7-03b0-4895-b852-f329942a4981,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-2055b58d-5d2a-4610-bcaa-99c58dc1ecbf,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-9ba2d10e-151d-473e-a4ac-fe4b027239d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-39b3034c-8d61-4cc7-9b94-90ff18bafde5,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-8663ce5e-ccd6-4398-9764-9c6789880269,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-86c686c6-0171-461f-8e7e-c31bfe477744,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-a3b9b0b0-5a72-4525-9cbd-5f5bb6b8981f,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-27bc2368-3830-46ba-b3eb-8169dd368245,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-94550766-172.17.0.3-1597346240032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42900,DS-5e2b38b7-03b0-4895-b852-f329942a4981,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-2055b58d-5d2a-4610-bcaa-99c58dc1ecbf,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-9ba2d10e-151d-473e-a4ac-fe4b027239d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-39b3034c-8d61-4cc7-9b94-90ff18bafde5,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-8663ce5e-ccd6-4398-9764-9c6789880269,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-86c686c6-0171-461f-8e7e-c31bfe477744,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-a3b9b0b0-5a72-4525-9cbd-5f5bb6b8981f,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-27bc2368-3830-46ba-b3eb-8169dd368245,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931386131-172.17.0.3-1597346995952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43913,DS-8c6cd476-a03a-4bdb-be4f-7ca0cdba4b02,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-a4e3daab-1e79-47f9-b11a-a7e7908e5428,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-85928265-b880-48b7-baad-b7983c47e490,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-1ac880cf-0f10-44ad-bb0b-7c079d9979e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-66f8d935-fa9d-4435-bf76-0652da831116,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-205163a6-c14a-4d89-8947-455c5fc49e73,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-d5984b00-704c-4a9f-a543-2704cb5eb125,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-eafda5ff-58f5-441a-a766-94dbad3f20ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931386131-172.17.0.3-1597346995952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43913,DS-8c6cd476-a03a-4bdb-be4f-7ca0cdba4b02,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-a4e3daab-1e79-47f9-b11a-a7e7908e5428,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-85928265-b880-48b7-baad-b7983c47e490,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-1ac880cf-0f10-44ad-bb0b-7c079d9979e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-66f8d935-fa9d-4435-bf76-0652da831116,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-205163a6-c14a-4d89-8947-455c5fc49e73,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-d5984b00-704c-4a9f-a543-2704cb5eb125,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-eafda5ff-58f5-441a-a766-94dbad3f20ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1919959330-172.17.0.3-1597347046495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39289,DS-4e4a44f0-6acc-4990-b3db-02ade0cbb7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-1a89c92b-d20a-47a1-a460-48f92dd2f0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-9e4813c8-6a39-42a0-98ba-4988f481a1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-29e34114-3cf8-44ad-b3af-e5ba5ba1298a,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-b86b3b55-e565-44e4-a45f-cb8eb2c55f06,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-60517dc7-d2d6-4c08-aff5-0e76583a67b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-3cde46f8-ccb0-4d08-b1ab-ad2f768b0649,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-72aceda2-9bf2-4e2f-a06f-29b86c49f00b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1919959330-172.17.0.3-1597347046495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39289,DS-4e4a44f0-6acc-4990-b3db-02ade0cbb7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-1a89c92b-d20a-47a1-a460-48f92dd2f0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-9e4813c8-6a39-42a0-98ba-4988f481a1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-29e34114-3cf8-44ad-b3af-e5ba5ba1298a,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-b86b3b55-e565-44e4-a45f-cb8eb2c55f06,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-60517dc7-d2d6-4c08-aff5-0e76583a67b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-3cde46f8-ccb0-4d08-b1ab-ad2f768b0649,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-72aceda2-9bf2-4e2f-a06f-29b86c49f00b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-265064664-172.17.0.3-1597347414036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38127,DS-2ee63338-4caa-4a5d-8061-5d4e2aabfdc3,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-8d241a95-9d4c-4d87-b74d-826e6fd55a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-4704a54f-cfe4-4856-ade0-722e6fb4d071,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-a0ecaa26-9cba-489d-86f5-f058dbdde86d,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-304c9ae3-33fb-41b2-8c32-191c4e51390c,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-12bef8bd-0be8-409c-b996-e3a1f3558043,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-51f57d23-fa1b-42de-a964-7b5c4c024dad,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-a17f790e-f00b-4df3-881f-7b9e0bc968c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-265064664-172.17.0.3-1597347414036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38127,DS-2ee63338-4caa-4a5d-8061-5d4e2aabfdc3,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-8d241a95-9d4c-4d87-b74d-826e6fd55a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-4704a54f-cfe4-4856-ade0-722e6fb4d071,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-a0ecaa26-9cba-489d-86f5-f058dbdde86d,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-304c9ae3-33fb-41b2-8c32-191c4e51390c,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-12bef8bd-0be8-409c-b996-e3a1f3558043,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-51f57d23-fa1b-42de-a964-7b5c4c024dad,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-a17f790e-f00b-4df3-881f-7b9e0bc968c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059454651-172.17.0.3-1597347770446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41252,DS-16b88c7c-3ce7-4480-87f6-c43f1b2cd3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-c2cbbee9-f2c0-4c82-8302-5d67db84ad2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-72e6152e-d020-4dc2-bf44-9b654209e5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-8a2476c6-da4a-4924-b36b-891aceed452d,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-8b471957-a92a-49cb-af11-c725c7201a93,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-3ac7154c-5f10-4715-86f1-f2ff27620bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-fa81e583-06ed-4124-8cc5-6877bcf41d34,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-345afb2d-8ff3-47ab-85d8-6a0876366bb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059454651-172.17.0.3-1597347770446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41252,DS-16b88c7c-3ce7-4480-87f6-c43f1b2cd3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-c2cbbee9-f2c0-4c82-8302-5d67db84ad2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-72e6152e-d020-4dc2-bf44-9b654209e5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-8a2476c6-da4a-4924-b36b-891aceed452d,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-8b471957-a92a-49cb-af11-c725c7201a93,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-3ac7154c-5f10-4715-86f1-f2ff27620bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-fa81e583-06ed-4124-8cc5-6877bcf41d34,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-345afb2d-8ff3-47ab-85d8-6a0876366bb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 360
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-419833557-172.17.0.3-1597348193319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45280,DS-2afc5432-3d07-499e-94ea-fed7313bf125,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-d6f3f68f-e77f-400f-bf7b-00e3523d8636,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-9e35e718-1df0-4c2f-9cb1-9397690bcd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-cbe717b5-fc40-4837-90e9-cfd846790658,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-c9d5fa4b-ee19-4e64-81a5-998791acf0da,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-1669ef07-ae89-498e-aa4b-b2b4847d289c,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-f5d672b9-9e61-41af-9381-e951daeef75f,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-5c2a57b7-7e4c-49a0-9e20-c25396818e28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-419833557-172.17.0.3-1597348193319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45280,DS-2afc5432-3d07-499e-94ea-fed7313bf125,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-d6f3f68f-e77f-400f-bf7b-00e3523d8636,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-9e35e718-1df0-4c2f-9cb1-9397690bcd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-cbe717b5-fc40-4837-90e9-cfd846790658,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-c9d5fa4b-ee19-4e64-81a5-998791acf0da,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-1669ef07-ae89-498e-aa4b-b2b4847d289c,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-f5d672b9-9e61-41af-9381-e951daeef75f,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-5c2a57b7-7e4c-49a0-9e20-c25396818e28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6915
