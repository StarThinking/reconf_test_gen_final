reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 1s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 1s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1136470046-172.17.0.4-1597541275846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37420,DS-a09aa6bf-c1af-4e41-b867-598c80331a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-f3b89b2c-59d1-4a98-99a1-0f33ac7111b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-d63e49fa-158a-4949-b986-d18a168cfe17,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-4c346e77-6d5b-4ee0-85be-15ffa5eb26ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-978285bc-8a84-4613-be5a-d7605cb6cca1,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-6ff709ea-1c52-4a4b-b43b-04d250c1a423,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-d22a8fd4-6a31-4eac-9ac2-60830635a3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-35a403e2-91b3-4a44-be20-45becd84719b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1136470046-172.17.0.4-1597541275846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37420,DS-a09aa6bf-c1af-4e41-b867-598c80331a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-f3b89b2c-59d1-4a98-99a1-0f33ac7111b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-d63e49fa-158a-4949-b986-d18a168cfe17,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-4c346e77-6d5b-4ee0-85be-15ffa5eb26ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-978285bc-8a84-4613-be5a-d7605cb6cca1,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-6ff709ea-1c52-4a4b-b43b-04d250c1a423,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-d22a8fd4-6a31-4eac-9ac2-60830635a3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-35a403e2-91b3-4a44-be20-45becd84719b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 1s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1903437286-172.17.0.4-1597541326960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41204,DS-7f5f71b3-d07a-417d-b9c6-cb26f3d2db1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-2ee2b646-97ae-4e5d-a2c3-7c2ece08811a,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-fa4691b1-5d50-43f8-8629-2faf5a7e4855,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-2b1e1f38-32c2-4fff-ab9e-00a3551fde59,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-1f9dfe1d-e6d3-4fd5-83f4-c367522c96af,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-2090231e-ee9f-4f30-8d5e-154256139e60,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-2985285e-b2f8-411b-b408-c4fa30e2e56a,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-32841dc0-8efb-473b-9bfe-5b075cbc6371,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1903437286-172.17.0.4-1597541326960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41204,DS-7f5f71b3-d07a-417d-b9c6-cb26f3d2db1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-2ee2b646-97ae-4e5d-a2c3-7c2ece08811a,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-fa4691b1-5d50-43f8-8629-2faf5a7e4855,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-2b1e1f38-32c2-4fff-ab9e-00a3551fde59,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-1f9dfe1d-e6d3-4fd5-83f4-c367522c96af,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-2090231e-ee9f-4f30-8d5e-154256139e60,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-2985285e-b2f8-411b-b408-c4fa30e2e56a,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-32841dc0-8efb-473b-9bfe-5b075cbc6371,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 1s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008323692-172.17.0.4-1597541896417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41079,DS-b6bbc104-9ca3-481f-bc6b-b587d2e6c66a,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-ebc59d43-c85d-4f56-83f9-ba52649b80af,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-ab949474-a2ea-42cb-bcac-364748d84696,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-5348a7df-0f87-4ae3-a9f8-ff03ea2b0794,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-e3be3a81-c226-4f5b-b782-824c681485cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-39930030-8bc5-4770-a901-472c582966b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-b6442438-8c6f-4a67-9bab-d4af3bd53035,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-36b01e6f-0cd5-4ed9-b4b4-e0085c564556,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008323692-172.17.0.4-1597541896417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41079,DS-b6bbc104-9ca3-481f-bc6b-b587d2e6c66a,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-ebc59d43-c85d-4f56-83f9-ba52649b80af,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-ab949474-a2ea-42cb-bcac-364748d84696,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-5348a7df-0f87-4ae3-a9f8-ff03ea2b0794,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-e3be3a81-c226-4f5b-b782-824c681485cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-39930030-8bc5-4770-a901-472c582966b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-b6442438-8c6f-4a67-9bab-d4af3bd53035,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-36b01e6f-0cd5-4ed9-b4b4-e0085c564556,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 1s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1783184482-172.17.0.4-1597543037016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44058,DS-ce537741-04d4-47c2-a12a-15e6334d85ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-24e7f7ba-5039-43cc-85dc-268642dc8bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-294c2b7e-18fd-40cb-8f6e-6e1058ae189a,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-d43f5045-4ed7-42d0-9ef5-86acf700f7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-c25e29c2-abc5-4243-b291-e85039556e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-28c8c696-d007-4337-8322-2a9151b84d76,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-aaa89923-efa5-452a-9aa2-3b53336b6519,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-9f55d7aa-aef9-4ee5-bd02-0c9e9908b6dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1783184482-172.17.0.4-1597543037016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44058,DS-ce537741-04d4-47c2-a12a-15e6334d85ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-24e7f7ba-5039-43cc-85dc-268642dc8bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-294c2b7e-18fd-40cb-8f6e-6e1058ae189a,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-d43f5045-4ed7-42d0-9ef5-86acf700f7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-c25e29c2-abc5-4243-b291-e85039556e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-28c8c696-d007-4337-8322-2a9151b84d76,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-aaa89923-efa5-452a-9aa2-3b53336b6519,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-9f55d7aa-aef9-4ee5-bd02-0c9e9908b6dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 1s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-98416448-172.17.0.4-1597543160953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42062,DS-acb8cbf5-1478-4d3f-b22d-ab16f4b312e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-1ac11648-e7b9-4011-b628-16649e6decd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-5ac99aec-32ea-4b55-8c51-fbd58df0b926,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-c3606e7d-a1b8-4b65-83a9-53188785077d,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-45a52443-df8d-4c20-bf58-66c78250804f,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-7710411e-a8ba-4a9b-bf24-0408494b07b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-8c159903-940a-4265-aa14-4525821087cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-27e63fba-592a-473c-8b82-29a46b7e6392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-98416448-172.17.0.4-1597543160953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42062,DS-acb8cbf5-1478-4d3f-b22d-ab16f4b312e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-1ac11648-e7b9-4011-b628-16649e6decd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-5ac99aec-32ea-4b55-8c51-fbd58df0b926,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-c3606e7d-a1b8-4b65-83a9-53188785077d,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-45a52443-df8d-4c20-bf58-66c78250804f,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-7710411e-a8ba-4a9b-bf24-0408494b07b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-8c159903-940a-4265-aa14-4525821087cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-27e63fba-592a-473c-8b82-29a46b7e6392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 1s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1291073432-172.17.0.4-1597543206586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41563,DS-004c2b66-435a-4282-83a2-7ce077d12ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-d2fe8bfe-6814-4c00-977a-f6a0dd9fb3da,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-9694ee23-4681-4e71-a8d3-9a43d219a6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-47a82a2d-59f4-4e94-aea7-24910fd7eabb,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-f5ec41a7-14f2-4ac1-964b-f2903d5bcbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-72c0e04a-7646-458d-ba9e-4eda3408f48d,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-d6090a6c-59cf-48e6-b0f7-bee9a3c510e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-0f2e962f-61fe-49fa-ad9e-b97ab8e914e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1291073432-172.17.0.4-1597543206586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41563,DS-004c2b66-435a-4282-83a2-7ce077d12ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-d2fe8bfe-6814-4c00-977a-f6a0dd9fb3da,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-9694ee23-4681-4e71-a8d3-9a43d219a6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-47a82a2d-59f4-4e94-aea7-24910fd7eabb,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-f5ec41a7-14f2-4ac1-964b-f2903d5bcbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-72c0e04a-7646-458d-ba9e-4eda3408f48d,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-d6090a6c-59cf-48e6-b0f7-bee9a3c510e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-0f2e962f-61fe-49fa-ad9e-b97ab8e914e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 1s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102249461-172.17.0.4-1597543412514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34303,DS-5cc4b63a-1bce-441b-b400-d93d0de97691,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-2e73ef06-56e2-40f9-bf12-477b179430ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-14525633-c154-4b92-b86d-b7a19be3ae09,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-5c220a92-5361-42ec-8d2b-5f666c7c0e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-fa034f05-ffce-484c-9ffd-2a29e297f093,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-b33cda9b-bad8-494a-ab58-68ad689070e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-47ed4603-e334-4fd8-b3fa-8dde01075a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-a36ba13b-8e6b-476f-994d-6f532269eb41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102249461-172.17.0.4-1597543412514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34303,DS-5cc4b63a-1bce-441b-b400-d93d0de97691,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-2e73ef06-56e2-40f9-bf12-477b179430ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-14525633-c154-4b92-b86d-b7a19be3ae09,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-5c220a92-5361-42ec-8d2b-5f666c7c0e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-fa034f05-ffce-484c-9ffd-2a29e297f093,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-b33cda9b-bad8-494a-ab58-68ad689070e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-47ed4603-e334-4fd8-b3fa-8dde01075a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-a36ba13b-8e6b-476f-994d-6f532269eb41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 1s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278554099-172.17.0.4-1597544332863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42942,DS-0ec6ccf8-cde3-40c4-8aec-ae4fac017bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-53ccaced-e946-48d0-99b0-21f3e0957695,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-5762636e-da22-46b9-b43b-5e0830790efb,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-dc8b1c5b-c1b2-4d23-acfa-15cedecf1322,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-74b29b8b-7fa4-43d2-b5e5-8886711d732b,DISK], DatanodeInfoWithStorage[127.0.0.1:40388,DS-f8981939-2a1b-487f-ab5b-1d29bca4ea29,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-ed506e41-6f6c-4221-8146-cf48eb115e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-b99b4262-99af-4052-97f0-731a7d55e871,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278554099-172.17.0.4-1597544332863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42942,DS-0ec6ccf8-cde3-40c4-8aec-ae4fac017bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-53ccaced-e946-48d0-99b0-21f3e0957695,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-5762636e-da22-46b9-b43b-5e0830790efb,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-dc8b1c5b-c1b2-4d23-acfa-15cedecf1322,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-74b29b8b-7fa4-43d2-b5e5-8886711d732b,DISK], DatanodeInfoWithStorage[127.0.0.1:40388,DS-f8981939-2a1b-487f-ab5b-1d29bca4ea29,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-ed506e41-6f6c-4221-8146-cf48eb115e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-b99b4262-99af-4052-97f0-731a7d55e871,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 1s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-242852791-172.17.0.4-1597544670690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40936,DS-8b3c9994-1940-4dc4-8d50-912c05b8aa99,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-9d769014-63b1-493f-adbc-14f5a167b98e,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-1f3a33c3-d549-409c-a1d5-d4cfa0925b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-1dec0a15-ad30-4464-a45c-1437b94da15d,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-732cd88d-1866-4761-b547-3b2f8442fc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-5465abab-53f4-4124-9ccd-d36694358f31,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-31c47524-e471-4fdd-9e8c-b774238c5185,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-673aa0bd-54f6-4d99-ba8a-4cf2cc362828,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-242852791-172.17.0.4-1597544670690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40936,DS-8b3c9994-1940-4dc4-8d50-912c05b8aa99,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-9d769014-63b1-493f-adbc-14f5a167b98e,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-1f3a33c3-d549-409c-a1d5-d4cfa0925b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-1dec0a15-ad30-4464-a45c-1437b94da15d,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-732cd88d-1866-4761-b547-3b2f8442fc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-5465abab-53f4-4124-9ccd-d36694358f31,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-31c47524-e471-4fdd-9e8c-b774238c5185,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-673aa0bd-54f6-4d99-ba8a-4cf2cc362828,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 1s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045450355-172.17.0.4-1597544942256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44225,DS-ec281c2e-94d6-4e23-a30c-21d3041e1989,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-e85a3f1f-7afb-4de8-8d0e-e9cc4a624d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-38fb2143-0c5b-4b30-a05a-8c48c4db1565,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-06a92f34-e0d9-41cc-90be-db68392c8ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-3ba407df-248e-4f5a-9f62-48b09deb890c,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-67a7ccb2-2ca7-488d-9630-7409ed062377,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-e6e0d479-bcef-4cd0-9a68-d4a75eb1f95a,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-146febf2-9433-4db6-af4f-089656cdc09f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045450355-172.17.0.4-1597544942256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44225,DS-ec281c2e-94d6-4e23-a30c-21d3041e1989,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-e85a3f1f-7afb-4de8-8d0e-e9cc4a624d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-38fb2143-0c5b-4b30-a05a-8c48c4db1565,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-06a92f34-e0d9-41cc-90be-db68392c8ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-3ba407df-248e-4f5a-9f62-48b09deb890c,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-67a7ccb2-2ca7-488d-9630-7409ed062377,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-e6e0d479-bcef-4cd0-9a68-d4a75eb1f95a,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-146febf2-9433-4db6-af4f-089656cdc09f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 1s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-918484774-172.17.0.4-1597545278851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36405,DS-f7a2f591-b63f-4a8e-a4ab-9211566b01f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-b6ac1d1c-987c-4e22-a294-f022da1a74b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-275d3328-bdee-4b59-aca5-6eb748e52fee,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-345bf9c1-7274-48b4-9c5a-69bf4ad18e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-8c8b9934-2c53-4494-a013-db8fff50c118,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-0bd0d638-0937-4c85-b122-a86a7f4d037c,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-14e3f2c5-6676-49f1-8c53-9b9ec8a0b234,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-496fdfaf-c004-46ae-81e7-ca1c7f77df42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-918484774-172.17.0.4-1597545278851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36405,DS-f7a2f591-b63f-4a8e-a4ab-9211566b01f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-b6ac1d1c-987c-4e22-a294-f022da1a74b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-275d3328-bdee-4b59-aca5-6eb748e52fee,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-345bf9c1-7274-48b4-9c5a-69bf4ad18e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-8c8b9934-2c53-4494-a013-db8fff50c118,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-0bd0d638-0937-4c85-b122-a86a7f4d037c,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-14e3f2c5-6676-49f1-8c53-9b9ec8a0b234,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-496fdfaf-c004-46ae-81e7-ca1c7f77df42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 1s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931437819-172.17.0.4-1597545761382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36811,DS-446da8d9-3857-44c5-9853-8ca967633ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-e24cd56d-8c6d-4ea7-a1a2-35c23e3b925d,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-c44641a2-acad-4076-82b9-f85c6337878c,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-aa4dc0a3-a295-439b-83fb-e87d64e418f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-6b8e4bcd-3ace-4d49-bdae-d921abe61aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-c3684698-a8bf-401b-8eb5-c6014905d48f,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-b632f35b-6d50-48df-baff-a10575a9d258,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-8f9f7b6f-6ec9-44f2-974b-55e5c5461b69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931437819-172.17.0.4-1597545761382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36811,DS-446da8d9-3857-44c5-9853-8ca967633ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-e24cd56d-8c6d-4ea7-a1a2-35c23e3b925d,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-c44641a2-acad-4076-82b9-f85c6337878c,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-aa4dc0a3-a295-439b-83fb-e87d64e418f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-6b8e4bcd-3ace-4d49-bdae-d921abe61aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-c3684698-a8bf-401b-8eb5-c6014905d48f,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-b632f35b-6d50-48df-baff-a10575a9d258,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-8f9f7b6f-6ec9-44f2-974b-55e5c5461b69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 1s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1775352158-172.17.0.4-1597546219636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41654,DS-af74e532-d106-4656-91bc-85c78af077d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-f7c500bb-cdd0-4d44-803b-775f2d68c1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-02ab944f-5a11-49ee-b2ad-6c7001aeac9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35793,DS-2d882ad3-d1ba-4472-85ab-c967eb8bfc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-cbc2e9b2-e26f-4b28-ba01-13d98336dd42,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-13356a06-8d76-4ec4-ba1b-d6222c5603c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-1537903c-fb98-4b31-879d-3100a72ce3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-2fbb2772-1964-4ac3-aae4-e789c55e7277,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1775352158-172.17.0.4-1597546219636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41654,DS-af74e532-d106-4656-91bc-85c78af077d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-f7c500bb-cdd0-4d44-803b-775f2d68c1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-02ab944f-5a11-49ee-b2ad-6c7001aeac9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35793,DS-2d882ad3-d1ba-4472-85ab-c967eb8bfc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-cbc2e9b2-e26f-4b28-ba01-13d98336dd42,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-13356a06-8d76-4ec4-ba1b-d6222c5603c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-1537903c-fb98-4b31-879d-3100a72ce3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-2fbb2772-1964-4ac3-aae4-e789c55e7277,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 1s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-327836697-172.17.0.4-1597546254490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35970,DS-c780354d-0237-4480-8b59-76f70e1c4905,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-59771f29-600b-4116-99b7-b825d0dda9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-3ab05f90-5206-4650-b8cb-81224686f658,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-1ed6a38b-2f0d-4556-9d15-e81c423e2878,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-22933914-213f-4b12-81e5-1562921434fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-5a79a90b-518c-46dd-8427-553d1332693f,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-9164acc1-f9e2-43c3-8671-2f1da18725c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-092a406d-e24a-4384-ab6a-277865533ece,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-327836697-172.17.0.4-1597546254490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35970,DS-c780354d-0237-4480-8b59-76f70e1c4905,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-59771f29-600b-4116-99b7-b825d0dda9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-3ab05f90-5206-4650-b8cb-81224686f658,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-1ed6a38b-2f0d-4556-9d15-e81c423e2878,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-22933914-213f-4b12-81e5-1562921434fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-5a79a90b-518c-46dd-8427-553d1332693f,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-9164acc1-f9e2-43c3-8671-2f1da18725c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-092a406d-e24a-4384-ab6a-277865533ece,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 1s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1543548677-172.17.0.4-1597546635230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35945,DS-e3d77692-f839-4eb2-b296-b55a2b99d1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-a4c66dd7-9f77-4f37-941d-34b1e881107c,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-c9ab1c98-0003-4de2-851c-f7fc8e4deeb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-ec9e79f9-4439-420b-9413-59f9e2dc7276,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-ede639c4-e4bb-4d35-b44a-8fde05ba148b,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-99f130f4-2acc-4d05-aeb5-d17b51b95dca,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-9f8906c6-bf6e-4218-b582-5f8909775d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-d4da7234-2a72-4bf1-83c7-c2eac863394c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1543548677-172.17.0.4-1597546635230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35945,DS-e3d77692-f839-4eb2-b296-b55a2b99d1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-a4c66dd7-9f77-4f37-941d-34b1e881107c,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-c9ab1c98-0003-4de2-851c-f7fc8e4deeb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-ec9e79f9-4439-420b-9413-59f9e2dc7276,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-ede639c4-e4bb-4d35-b44a-8fde05ba148b,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-99f130f4-2acc-4d05-aeb5-d17b51b95dca,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-9f8906c6-bf6e-4218-b582-5f8909775d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-d4da7234-2a72-4bf1-83c7-c2eac863394c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 1s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950990886-172.17.0.4-1597546739428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44877,DS-055692c4-94a4-46e9-a3d3-6fbfc559b4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-0cbd3bb5-f936-478c-b0fc-38102b9f67a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-e3d61302-aedf-4d59-9def-63d17e74f825,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-d1aea9ee-2bfb-4134-8ba2-d893507d595d,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-955c32f0-9308-4f19-86d0-7a45542aa772,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-c9ee648a-5416-4c5f-8881-30c8f5ea9050,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-d169679c-a79c-49e7-b116-aa1c044cc2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-d7dcbe7e-ff89-4549-864c-642eb4d0fd0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950990886-172.17.0.4-1597546739428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44877,DS-055692c4-94a4-46e9-a3d3-6fbfc559b4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-0cbd3bb5-f936-478c-b0fc-38102b9f67a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-e3d61302-aedf-4d59-9def-63d17e74f825,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-d1aea9ee-2bfb-4134-8ba2-d893507d595d,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-955c32f0-9308-4f19-86d0-7a45542aa772,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-c9ee648a-5416-4c5f-8881-30c8f5ea9050,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-d169679c-a79c-49e7-b116-aa1c044cc2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-d7dcbe7e-ff89-4549-864c-642eb4d0fd0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 1s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-691258719-172.17.0.4-1597546792778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34915,DS-db5e21e7-b66f-42cb-82da-3cb2c31f7fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-b5873e81-df12-4105-8cce-6c96f1626c68,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-df5ef28d-ac92-437d-a586-bc2afd1f922c,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-51869d99-caed-4f04-b336-d9967ca47e42,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-303862cc-3d14-4691-9d15-f1a467bb0fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-3c900857-c958-43c7-8724-2213ed1c0d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-bc4d94a6-bd88-4567-b6ff-fabcf30fa346,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-4f45c07b-0a01-438f-bf08-f4ec471f91b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-691258719-172.17.0.4-1597546792778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34915,DS-db5e21e7-b66f-42cb-82da-3cb2c31f7fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-b5873e81-df12-4105-8cce-6c96f1626c68,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-df5ef28d-ac92-437d-a586-bc2afd1f922c,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-51869d99-caed-4f04-b336-d9967ca47e42,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-303862cc-3d14-4691-9d15-f1a467bb0fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-3c900857-c958-43c7-8724-2213ed1c0d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-bc4d94a6-bd88-4567-b6ff-fabcf30fa346,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-4f45c07b-0a01-438f-bf08-f4ec471f91b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 1s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1196329149-172.17.0.4-1597547048654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37363,DS-61a588e0-eb01-46cc-8448-73158f170e00,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-1d086a52-c8e6-423b-8094-c3421fdffb93,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-af25b380-2a85-4303-a9d9-e3e714eafac8,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-4f782f90-4c5f-443a-8f54-a1cb95366034,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-43e72a7a-1843-4c0b-95de-ae9316cd3f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-aae4c00f-d6a0-484b-a09b-d5c0502946f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-642a9761-0a00-4526-987c-8c587629017f,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-7d591edd-b724-44fa-9e36-ecd2bbe68f17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1196329149-172.17.0.4-1597547048654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37363,DS-61a588e0-eb01-46cc-8448-73158f170e00,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-1d086a52-c8e6-423b-8094-c3421fdffb93,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-af25b380-2a85-4303-a9d9-e3e714eafac8,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-4f782f90-4c5f-443a-8f54-a1cb95366034,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-43e72a7a-1843-4c0b-95de-ae9316cd3f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-aae4c00f-d6a0-484b-a09b-d5c0502946f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-642a9761-0a00-4526-987c-8c587629017f,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-7d591edd-b724-44fa-9e36-ecd2bbe68f17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 1s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1495416495-172.17.0.4-1597547286988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42236,DS-ef16e124-db7a-4b97-bb1d-2c28451bff89,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-98c93948-de6f-4b74-918d-2edf0d08c89f,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-0fcd4b13-a4aa-43ac-a684-34a07599fe18,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-00cad22b-dd70-42b4-8202-24ed4458605f,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-32594c3a-6c0c-4ccb-b7da-faeb15d025a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-bfe3a7d0-3def-42fc-900f-ece261290eac,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-daa8dbdf-66ba-4738-8ded-3e6d65b121ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-31f2a6be-d1e4-42d0-8fb2-d9998a24d3f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1495416495-172.17.0.4-1597547286988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42236,DS-ef16e124-db7a-4b97-bb1d-2c28451bff89,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-98c93948-de6f-4b74-918d-2edf0d08c89f,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-0fcd4b13-a4aa-43ac-a684-34a07599fe18,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-00cad22b-dd70-42b4-8202-24ed4458605f,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-32594c3a-6c0c-4ccb-b7da-faeb15d025a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-bfe3a7d0-3def-42fc-900f-ece261290eac,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-daa8dbdf-66ba-4738-8ded-3e6d65b121ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-31f2a6be-d1e4-42d0-8fb2-d9998a24d3f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 1s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1070381880-172.17.0.4-1597547550616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34677,DS-cf9c257a-4ee5-4b5a-91ec-fe9e76489612,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-85b87246-2757-4edd-ac4e-5e8c2647eefb,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-2752cff1-94fd-4c45-914a-595712721558,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-4b6a8473-1dfd-4f1c-a5fd-c7f2b67fa7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-7b188230-3ac0-41a7-aaa2-46604099ba0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-fa22c28c-7f59-4618-84eb-6535ef1cd08b,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-d1651716-ec77-410c-b811-7132bdce356c,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-c2c70335-68ea-4833-bff1-1b8c430b3fdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1070381880-172.17.0.4-1597547550616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34677,DS-cf9c257a-4ee5-4b5a-91ec-fe9e76489612,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-85b87246-2757-4edd-ac4e-5e8c2647eefb,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-2752cff1-94fd-4c45-914a-595712721558,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-4b6a8473-1dfd-4f1c-a5fd-c7f2b67fa7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-7b188230-3ac0-41a7-aaa2-46604099ba0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-fa22c28c-7f59-4618-84eb-6535ef1cd08b,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-d1651716-ec77-410c-b811-7132bdce356c,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-c2c70335-68ea-4833-bff1-1b8c430b3fdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 1s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869881055-172.17.0.4-1597548080916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33302,DS-7fe77369-d937-4597-9b03-bc1bcf1c0062,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-89a06578-f8c7-43f6-8578-9d286c3ab710,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-172ead91-0800-4dc5-92b6-15f564e217d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-d408699a-7eb4-4252-9865-145d79927187,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-521ee7e1-bf5f-46eb-867b-34739d1e8bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-004f854f-d981-4d4b-8711-4895637757bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-55f029b5-7b63-470b-994a-cb6e4359cd26,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-2d651c94-1779-4405-a9bb-74faa21f6c1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869881055-172.17.0.4-1597548080916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33302,DS-7fe77369-d937-4597-9b03-bc1bcf1c0062,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-89a06578-f8c7-43f6-8578-9d286c3ab710,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-172ead91-0800-4dc5-92b6-15f564e217d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-d408699a-7eb4-4252-9865-145d79927187,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-521ee7e1-bf5f-46eb-867b-34739d1e8bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-004f854f-d981-4d4b-8711-4895637757bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-55f029b5-7b63-470b-994a-cb6e4359cd26,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-2d651c94-1779-4405-a9bb-74faa21f6c1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 7087
