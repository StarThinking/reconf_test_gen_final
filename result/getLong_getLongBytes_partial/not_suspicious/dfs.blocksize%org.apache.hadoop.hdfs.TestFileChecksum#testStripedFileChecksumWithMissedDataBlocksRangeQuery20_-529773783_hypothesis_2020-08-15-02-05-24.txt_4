reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-132282670-172.17.0.20-1597457136927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43482,DS-52de450c-afc6-4f34-b6ff-e24e8aacf98a,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-0495ac0a-dd93-41c2-b315-b6ac021c86d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-d36741a2-ee1d-4178-ba40-28f269b4f576,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-bb6d3d98-aa18-45ed-8317-bb35944c0661,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-751f3f46-7d84-4886-922f-1f73125e4916,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-4215c4f7-dd19-4617-bcb6-c7bac3069e53,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-1043f86d-63b3-4619-a381-37031aa73de0,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-42d4f90f-03d0-479b-922a-685123fd66b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-132282670-172.17.0.20-1597457136927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43482,DS-52de450c-afc6-4f34-b6ff-e24e8aacf98a,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-0495ac0a-dd93-41c2-b315-b6ac021c86d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-d36741a2-ee1d-4178-ba40-28f269b4f576,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-bb6d3d98-aa18-45ed-8317-bb35944c0661,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-751f3f46-7d84-4886-922f-1f73125e4916,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-4215c4f7-dd19-4617-bcb6-c7bac3069e53,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-1043f86d-63b3-4619-a381-37031aa73de0,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-42d4f90f-03d0-479b-922a-685123fd66b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-64350357-172.17.0.20-1597457314464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43660,DS-4d21fe81-bbba-4115-bbb0-fa43aa2c2b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-637ac6d5-6949-4393-948c-9fb8da42ec50,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-dd1bb8f2-6d84-45a7-a692-1f607f218327,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-b5ddf9ec-0af3-4210-9b2f-1c9ecbef7316,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-1b09176e-dc59-4bec-891c-73a289a1b1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-176978b3-62b4-44f8-a752-18bb8692b118,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-653c50cf-93cf-402a-a606-5b3911889929,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-c018fb80-3920-403a-bb17-a094507e36d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-64350357-172.17.0.20-1597457314464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43660,DS-4d21fe81-bbba-4115-bbb0-fa43aa2c2b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-637ac6d5-6949-4393-948c-9fb8da42ec50,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-dd1bb8f2-6d84-45a7-a692-1f607f218327,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-b5ddf9ec-0af3-4210-9b2f-1c9ecbef7316,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-1b09176e-dc59-4bec-891c-73a289a1b1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-176978b3-62b4-44f8-a752-18bb8692b118,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-653c50cf-93cf-402a-a606-5b3911889929,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-c018fb80-3920-403a-bb17-a094507e36d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-600507746-172.17.0.20-1597457667518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33177,DS-2024d36c-22e6-4cb6-abce-f8743c97bed2,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-f2625235-ced7-497d-8470-e8eb35cb3d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-53fb8edc-5574-4d72-b61f-c4766a2ee6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-9dcdbb68-6644-44bd-9d89-778779727ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:40851,DS-341efe8c-69ce-4b35-af02-541b03d6289f,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-eb961e8e-e2c8-4aae-8dab-953b945d70e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-bade41a5-a77d-414b-9eca-dbe0fa17850d,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-b9e94841-1d9f-4fd7-8c07-985f86dd07bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-600507746-172.17.0.20-1597457667518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33177,DS-2024d36c-22e6-4cb6-abce-f8743c97bed2,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-f2625235-ced7-497d-8470-e8eb35cb3d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-53fb8edc-5574-4d72-b61f-c4766a2ee6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-9dcdbb68-6644-44bd-9d89-778779727ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:40851,DS-341efe8c-69ce-4b35-af02-541b03d6289f,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-eb961e8e-e2c8-4aae-8dab-953b945d70e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-bade41a5-a77d-414b-9eca-dbe0fa17850d,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-b9e94841-1d9f-4fd7-8c07-985f86dd07bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-38722035-172.17.0.20-1597458655998:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37646,DS-4ed7e353-c247-453f-9aab-d0e03f85ede9,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-c5e0bd3d-7686-4e66-b960-a19f2a6e9457,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-8f10676c-4d15-4f8a-a5c6-d5b2c2811b53,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-c572d1a4-01c7-4bd5-aba7-b268e7d65c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-8141db6f-533d-4d25-a7da-177f39907ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-d7687e78-184b-4256-af93-06a673513b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-52d141f7-8bdc-43bc-8177-5bdb5dbb9704,DISK], DatanodeInfoWithStorage[127.0.0.1:40995,DS-475942a0-a6e6-4511-9e01-5834e0a26c3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-38722035-172.17.0.20-1597458655998:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37646,DS-4ed7e353-c247-453f-9aab-d0e03f85ede9,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-c5e0bd3d-7686-4e66-b960-a19f2a6e9457,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-8f10676c-4d15-4f8a-a5c6-d5b2c2811b53,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-c572d1a4-01c7-4bd5-aba7-b268e7d65c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-8141db6f-533d-4d25-a7da-177f39907ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-d7687e78-184b-4256-af93-06a673513b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-52d141f7-8bdc-43bc-8177-5bdb5dbb9704,DISK], DatanodeInfoWithStorage[127.0.0.1:40995,DS-475942a0-a6e6-4511-9e01-5834e0a26c3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-425063590-172.17.0.20-1597458792411:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46691,DS-e7083a57-18fd-44f6-85bb-8cc9a600fe46,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-d2737e14-3daf-4159-9690-9a40c4cc98e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-82b98201-0d72-4c88-8041-e6a2fb4f28d7,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-e2aba149-c0ce-403f-a32a-a778469bdce4,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-3cbbb93b-d45f-4b41-bed5-2dfb5772e7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-7852097f-660d-496d-9e4a-46f3603b05e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-0a888d40-927c-4d03-94cd-42fd2cc7be8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-36320123-ac01-4284-8a65-408803fd2520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-425063590-172.17.0.20-1597458792411:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46691,DS-e7083a57-18fd-44f6-85bb-8cc9a600fe46,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-d2737e14-3daf-4159-9690-9a40c4cc98e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-82b98201-0d72-4c88-8041-e6a2fb4f28d7,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-e2aba149-c0ce-403f-a32a-a778469bdce4,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-3cbbb93b-d45f-4b41-bed5-2dfb5772e7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-7852097f-660d-496d-9e4a-46f3603b05e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-0a888d40-927c-4d03-94cd-42fd2cc7be8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-36320123-ac01-4284-8a65-408803fd2520,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-503539288-172.17.0.20-1597459174883:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45743,DS-90581937-1813-490a-9c4d-3b2f10fd06ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36816,DS-555096bb-b9ab-4ddd-87e8-6bd49e8c08bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-d26f4e57-5989-4422-b2e0-2492a90f014d,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-bf4c39f0-642b-4f65-b0ab-7354ee76c624,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-d713e41f-b056-469d-af17-30143de86694,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-9e2bf6e0-61ee-45d2-a4ee-78ad05663278,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-21f8c9ef-300f-47fc-ba91-b6a74f91b283,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-8c01b3b1-a2e5-4893-9c05-5155bb099912,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-503539288-172.17.0.20-1597459174883:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45743,DS-90581937-1813-490a-9c4d-3b2f10fd06ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36816,DS-555096bb-b9ab-4ddd-87e8-6bd49e8c08bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-d26f4e57-5989-4422-b2e0-2492a90f014d,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-bf4c39f0-642b-4f65-b0ab-7354ee76c624,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-d713e41f-b056-469d-af17-30143de86694,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-9e2bf6e0-61ee-45d2-a4ee-78ad05663278,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-21f8c9ef-300f-47fc-ba91-b6a74f91b283,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-8c01b3b1-a2e5-4893-9c05-5155bb099912,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-390546132-172.17.0.20-1597459523029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39850,DS-49e7d7b2-1074-4d99-bd07-7237e9ea853d,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-d6cab443-7496-487d-9507-33f1090e77ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-3a47b3dc-c2c4-4a1b-b236-6e0d4ffb9536,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-14925344-9233-45d9-94e1-8670f976d0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-d9c7a37b-e224-4f23-bd5c-67ad226b0d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-ecf17fcf-54f0-4b4a-80d1-499ab4815f36,DISK], DatanodeInfoWithStorage[127.0.0.1:36902,DS-0a10b54a-d643-432a-95cc-fefe316477cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-36e5dc7f-2b5b-4086-b49c-feefdac54b39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-390546132-172.17.0.20-1597459523029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39850,DS-49e7d7b2-1074-4d99-bd07-7237e9ea853d,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-d6cab443-7496-487d-9507-33f1090e77ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-3a47b3dc-c2c4-4a1b-b236-6e0d4ffb9536,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-14925344-9233-45d9-94e1-8670f976d0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-d9c7a37b-e224-4f23-bd5c-67ad226b0d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-ecf17fcf-54f0-4b4a-80d1-499ab4815f36,DISK], DatanodeInfoWithStorage[127.0.0.1:36902,DS-0a10b54a-d643-432a-95cc-fefe316477cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-36e5dc7f-2b5b-4086-b49c-feefdac54b39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-146069905-172.17.0.20-1597459651748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34845,DS-e490abb1-e48d-424c-9def-18cf92ac718b,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-461e5ca9-ed4a-4242-98a3-f194247d6f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-bd24a2cc-caf2-42a7-afc9-82ada1b65fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-25e45d2b-cf0c-4162-abc7-b6558395ab04,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-13c50a2b-5815-4104-b9e1-0a8569e7dbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-5a2f14af-3d5b-4a42-91ff-949058f6c996,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-0cf76979-3d81-4fb5-90f0-90f8fc8c002b,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-9b8ac787-8fa3-4dce-9683-af127cb87954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-146069905-172.17.0.20-1597459651748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34845,DS-e490abb1-e48d-424c-9def-18cf92ac718b,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-461e5ca9-ed4a-4242-98a3-f194247d6f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-bd24a2cc-caf2-42a7-afc9-82ada1b65fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-25e45d2b-cf0c-4162-abc7-b6558395ab04,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-13c50a2b-5815-4104-b9e1-0a8569e7dbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-5a2f14af-3d5b-4a42-91ff-949058f6c996,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-0cf76979-3d81-4fb5-90f0-90f8fc8c002b,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-9b8ac787-8fa3-4dce-9683-af127cb87954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-304113309-172.17.0.20-1597460112083:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43700,DS-ddb49aaf-d8fe-4fa0-a9c8-f81664885342,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-63fefb3d-6ec6-449a-baaa-5c0a16ba0f18,DISK], DatanodeInfoWithStorage[127.0.0.1:39618,DS-c17aa6fe-70a2-40e1-92af-fbf740aeb31b,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-eca0058a-7742-41e9-aa37-0c688d80c690,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-97f127ad-7f95-40a0-affc-bf076dd9bc59,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-e87b7cdd-bc29-453b-a154-ff098f903c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-898143e0-3dfa-4068-8f0c-147fbfd1e00c,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-e4497948-7993-46a0-820c-95f448acf984,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-304113309-172.17.0.20-1597460112083:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43700,DS-ddb49aaf-d8fe-4fa0-a9c8-f81664885342,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-63fefb3d-6ec6-449a-baaa-5c0a16ba0f18,DISK], DatanodeInfoWithStorage[127.0.0.1:39618,DS-c17aa6fe-70a2-40e1-92af-fbf740aeb31b,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-eca0058a-7742-41e9-aa37-0c688d80c690,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-97f127ad-7f95-40a0-affc-bf076dd9bc59,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-e87b7cdd-bc29-453b-a154-ff098f903c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-898143e0-3dfa-4068-8f0c-147fbfd1e00c,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-e4497948-7993-46a0-820c-95f448acf984,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-93688736-172.17.0.20-1597460331496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33177,DS-d0e94daf-fbd1-48c6-8e55-1f8707a29241,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-07e0dbfd-f7f5-43d7-b945-e9c12ae63291,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-c22c34f4-8af8-442e-b8d0-14c6bdce80c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-48fabf7a-58e4-48d4-b174-1637c7661e38,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-8fbb460a-3b35-4297-9b17-90e25245436a,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-92189fe1-2aaa-4136-bdee-2ed49fb94510,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-64592805-b7d0-400f-b747-727792d48e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-817da4c9-7e64-4978-b9b5-ca444973285c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-93688736-172.17.0.20-1597460331496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33177,DS-d0e94daf-fbd1-48c6-8e55-1f8707a29241,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-07e0dbfd-f7f5-43d7-b945-e9c12ae63291,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-c22c34f4-8af8-442e-b8d0-14c6bdce80c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-48fabf7a-58e4-48d4-b174-1637c7661e38,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-8fbb460a-3b35-4297-9b17-90e25245436a,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-92189fe1-2aaa-4136-bdee-2ed49fb94510,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-64592805-b7d0-400f-b747-727792d48e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-817da4c9-7e64-4978-b9b5-ca444973285c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-103784963-172.17.0.20-1597460480737:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36290,DS-07e93116-dda5-427e-a630-c00a6f16c551,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-6c9f77b0-a76f-4348-a4fa-d59be4106d43,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-b0228672-e124-4053-84a2-fbe2c5408ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-fa4582b1-7f81-4739-93aa-4a9f73e85837,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-a03861dc-8514-4089-910c-03b4fe7b3795,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-f1d6e076-55d6-44ee-a0c4-1371dbf860fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-a8563219-7475-47da-8187-039b85ca703d,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-7f1009ed-8ad5-4496-bb47-a95bdb5dd61f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-103784963-172.17.0.20-1597460480737:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36290,DS-07e93116-dda5-427e-a630-c00a6f16c551,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-6c9f77b0-a76f-4348-a4fa-d59be4106d43,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-b0228672-e124-4053-84a2-fbe2c5408ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-fa4582b1-7f81-4739-93aa-4a9f73e85837,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-a03861dc-8514-4089-910c-03b4fe7b3795,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-f1d6e076-55d6-44ee-a0c4-1371dbf860fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-a8563219-7475-47da-8187-039b85ca703d,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-7f1009ed-8ad5-4496-bb47-a95bdb5dd61f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1449612682-172.17.0.20-1597460544580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40971,DS-c2b91286-1e90-4ee6-bd65-6d966f09143a,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-bf421f49-212d-43d4-8028-968cc60c4814,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-3f8b6bde-39de-41f4-b121-c4e66e237321,DISK], DatanodeInfoWithStorage[127.0.0.1:38137,DS-201b4808-b87c-4c9d-918b-bda4822efd58,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-e4ae1bf3-2a14-47ea-817a-bd490bd37e35,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-e3203fea-68af-4ec1-9667-f201b55def61,DISK], DatanodeInfoWithStorage[127.0.0.1:38183,DS-06176e6e-a1a1-452d-b574-a80e5d2c9af7,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-87cee6e0-df41-48cf-b7c2-723ff9ed0110,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1449612682-172.17.0.20-1597460544580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40971,DS-c2b91286-1e90-4ee6-bd65-6d966f09143a,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-bf421f49-212d-43d4-8028-968cc60c4814,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-3f8b6bde-39de-41f4-b121-c4e66e237321,DISK], DatanodeInfoWithStorage[127.0.0.1:38137,DS-201b4808-b87c-4c9d-918b-bda4822efd58,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-e4ae1bf3-2a14-47ea-817a-bd490bd37e35,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-e3203fea-68af-4ec1-9667-f201b55def61,DISK], DatanodeInfoWithStorage[127.0.0.1:38183,DS-06176e6e-a1a1-452d-b574-a80e5d2c9af7,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-87cee6e0-df41-48cf-b7c2-723ff9ed0110,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1859745433-172.17.0.20-1597460686529:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35290,DS-5488e2ab-e60b-4e27-8af0-25a27b164c89,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-92d372d9-2028-4347-9eb4-fa5399339799,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-452395f6-bc5e-4295-bdc2-d6003dfda44d,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-28be02bf-3c63-4dd5-81c4-52a339faf5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-9a8df94d-185e-4ee9-98b2-684cf3b4493f,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-a7d69393-72e5-42a8-85f3-895351db21cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-baec2aa2-5a1d-4ec4-b1b4-cfbfc89204a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-25ff6afd-8f65-42c5-a28b-7209aeabf2cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1859745433-172.17.0.20-1597460686529:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35290,DS-5488e2ab-e60b-4e27-8af0-25a27b164c89,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-92d372d9-2028-4347-9eb4-fa5399339799,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-452395f6-bc5e-4295-bdc2-d6003dfda44d,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-28be02bf-3c63-4dd5-81c4-52a339faf5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-9a8df94d-185e-4ee9-98b2-684cf3b4493f,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-a7d69393-72e5-42a8-85f3-895351db21cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-baec2aa2-5a1d-4ec4-b1b4-cfbfc89204a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-25ff6afd-8f65-42c5-a28b-7209aeabf2cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-922098956-172.17.0.20-1597461156700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38490,DS-9e9a7592-3e2a-4487-adf8-e8689b315506,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-04bcafeb-4cf0-47b7-a8be-3550106d0ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-4986d11f-5b28-4f71-95c3-fe2a6d51e72a,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-f941ba21-3b22-4578-9b9d-788ee8fccdad,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-aacc3adf-e556-4366-84d7-c104791781d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-14e9e456-f007-4d56-a0bb-aa4ffb6db009,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-51669b2e-e3c2-4601-9f77-ecdb4efef276,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-36ff711a-9810-4263-8f3d-0fe682740b46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-922098956-172.17.0.20-1597461156700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38490,DS-9e9a7592-3e2a-4487-adf8-e8689b315506,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-04bcafeb-4cf0-47b7-a8be-3550106d0ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-4986d11f-5b28-4f71-95c3-fe2a6d51e72a,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-f941ba21-3b22-4578-9b9d-788ee8fccdad,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-aacc3adf-e556-4366-84d7-c104791781d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-14e9e456-f007-4d56-a0bb-aa4ffb6db009,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-51669b2e-e3c2-4601-9f77-ecdb4efef276,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-36ff711a-9810-4263-8f3d-0fe682740b46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1860242789-172.17.0.20-1597461196872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32971,DS-3a749aee-993d-4fbe-aaa6-498a97bd63c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-871c8217-bca8-40bf-9a18-1069546ea9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-bbe7370d-b2a8-47d7-9eb3-3077e95d1da9,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-a4548ed6-b453-474d-a95d-90ec39faf62e,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-2027358d-8201-4e31-9d0a-23b7f1f165fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-5679ce46-e47f-4631-afc0-9aa169bf3e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-a5b1a862-28f2-4d3a-a3b6-9e81bf0b634b,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-6f0d96a2-c748-4c3c-ab1d-6a6bfb27e01a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1860242789-172.17.0.20-1597461196872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32971,DS-3a749aee-993d-4fbe-aaa6-498a97bd63c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-871c8217-bca8-40bf-9a18-1069546ea9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-bbe7370d-b2a8-47d7-9eb3-3077e95d1da9,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-a4548ed6-b453-474d-a95d-90ec39faf62e,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-2027358d-8201-4e31-9d0a-23b7f1f165fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-5679ce46-e47f-4631-afc0-9aa169bf3e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-a5b1a862-28f2-4d3a-a3b6-9e81bf0b634b,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-6f0d96a2-c748-4c3c-ab1d-6a6bfb27e01a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-83985516-172.17.0.20-1597461539089:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36483,DS-2ba9f2af-d0dc-4add-a132-9a91438dcf74,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-858d9be7-13a4-44cd-a41c-a964df032f44,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-a3fd87df-0f03-4a65-af8d-4dbc975146f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-8f6f4544-16a3-4efb-a83d-508fb6648897,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-8f3bb2d0-8b3e-4bf3-980b-b553491461e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-14e92003-c4ec-4842-943f-6db68d797c68,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-473417a1-739a-4097-9083-0b42fe7655f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-80ae1bc5-0591-4ca2-98f2-deb97c0c974b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-83985516-172.17.0.20-1597461539089:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36483,DS-2ba9f2af-d0dc-4add-a132-9a91438dcf74,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-858d9be7-13a4-44cd-a41c-a964df032f44,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-a3fd87df-0f03-4a65-af8d-4dbc975146f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-8f6f4544-16a3-4efb-a83d-508fb6648897,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-8f3bb2d0-8b3e-4bf3-980b-b553491461e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-14e92003-c4ec-4842-943f-6db68d797c68,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-473417a1-739a-4097-9083-0b42fe7655f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-80ae1bc5-0591-4ca2-98f2-deb97c0c974b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-752767874-172.17.0.20-1597461856384:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44391,DS-3bbc7683-613d-43bd-8749-1a50fff3f212,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-488426c6-e69c-4f87-9030-20d4faf3fbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-9eb8043f-a891-4ecc-ab61-249b5b65c751,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-66dae902-e5e4-4c49-9ef1-5204cabb829c,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-3cfec3f9-25f4-48e0-ae19-8d743a1906e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-a3b6d6c0-e7bc-4415-b622-287d1a5045f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-b5a08764-c773-49fb-bb70-fd0a04c5f297,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-7887bb01-a5c8-4bc4-a44e-72db5d863e96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-752767874-172.17.0.20-1597461856384:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44391,DS-3bbc7683-613d-43bd-8749-1a50fff3f212,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-488426c6-e69c-4f87-9030-20d4faf3fbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-9eb8043f-a891-4ecc-ab61-249b5b65c751,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-66dae902-e5e4-4c49-9ef1-5204cabb829c,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-3cfec3f9-25f4-48e0-ae19-8d743a1906e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-a3b6d6c0-e7bc-4415-b622-287d1a5045f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-b5a08764-c773-49fb-bb70-fd0a04c5f297,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-7887bb01-a5c8-4bc4-a44e-72db5d863e96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1231600417-172.17.0.20-1597462003319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38933,DS-adbee9eb-394d-4910-bef7-f10d000307af,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-250ddb46-eb88-4ec3-8f37-d1a171c1cc50,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-c3a6142b-958c-466d-9da7-05c9e18cd31f,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-03369942-3d63-4784-a3d9-9ba75289f715,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-70426120-d6d5-4bb2-be37-f6c361503d35,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-99de4c91-0410-4f6d-b2e5-5431d4c666d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-09f3be4b-f437-405e-9e5a-1e608a0cfa59,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-339a39ac-ce26-412e-8c11-047a685e2c67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1231600417-172.17.0.20-1597462003319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38933,DS-adbee9eb-394d-4910-bef7-f10d000307af,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-250ddb46-eb88-4ec3-8f37-d1a171c1cc50,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-c3a6142b-958c-466d-9da7-05c9e18cd31f,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-03369942-3d63-4784-a3d9-9ba75289f715,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-70426120-d6d5-4bb2-be37-f6c361503d35,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-99de4c91-0410-4f6d-b2e5-5431d4c666d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-09f3be4b-f437-405e-9e5a-1e608a0cfa59,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-339a39ac-ce26-412e-8c11-047a685e2c67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1424506114-172.17.0.20-1597462180835:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45865,DS-b8f54819-d2ee-4691-92b0-f0075f7d7059,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-dd378dfc-1853-4a89-8d70-2e33767c493d,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-6df8aff7-5a92-47a1-9dbc-9825012597d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-f42b8f13-56fd-42e5-915f-9f0e551a4717,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-84839397-e0cf-4935-9efc-7bfeaf10bdae,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-15220f11-596c-4787-aa90-9c76a3a51fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-43f24b69-b0e5-4549-bcc0-e7fe328eba8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-051b6077-8eb4-42b9-ab16-9391fbbe931a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1424506114-172.17.0.20-1597462180835:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45865,DS-b8f54819-d2ee-4691-92b0-f0075f7d7059,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-dd378dfc-1853-4a89-8d70-2e33767c493d,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-6df8aff7-5a92-47a1-9dbc-9825012597d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-f42b8f13-56fd-42e5-915f-9f0e551a4717,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-84839397-e0cf-4935-9efc-7bfeaf10bdae,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-15220f11-596c-4787-aa90-9c76a3a51fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-43f24b69-b0e5-4549-bcc0-e7fe328eba8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-051b6077-8eb4-42b9-ab16-9391fbbe931a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1774948314-172.17.0.20-1597462396529:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37210,DS-cab81c05-b9d3-47d0-ae56-20c6fb152340,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-9551599e-2078-4f04-89b5-459daee9c2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-8d347a68-f617-4e56-8c4f-90f870f2b83f,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-016223de-9d57-430f-999e-2a72e79ffd14,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-09a92199-dc11-46bb-a5ea-420a5bc09f38,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-136887b5-d9b0-46e7-83ef-849ab73030b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-3f4a405b-272d-4baa-8000-88ba09e26dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-16a2a1c8-a6da-44b5-a71f-48885bd56e7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1774948314-172.17.0.20-1597462396529:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37210,DS-cab81c05-b9d3-47d0-ae56-20c6fb152340,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-9551599e-2078-4f04-89b5-459daee9c2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-8d347a68-f617-4e56-8c4f-90f870f2b83f,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-016223de-9d57-430f-999e-2a72e79ffd14,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-09a92199-dc11-46bb-a5ea-420a5bc09f38,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-136887b5-d9b0-46e7-83ef-849ab73030b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-3f4a405b-272d-4baa-8000-88ba09e26dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-16a2a1c8-a6da-44b5-a71f-48885bd56e7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1376830261-172.17.0.20-1597462478848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44368,DS-d35ad07e-e446-4601-96da-afc553892b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-0151c6c2-4e55-479e-ba6f-4cd5e7c24e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-994bd406-015e-44db-bcad-5759a534fbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-03b84254-d96d-4c2c-89dc-233b7d2e5b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-28fbd834-77ba-4150-ae6e-035722f690dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-46547972-6676-491f-9339-83098e6985e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-e21d7c8d-50ad-4dc9-864b-09e3ec818903,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-73e58067-72ef-426a-b33e-7cf77c54c5d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1376830261-172.17.0.20-1597462478848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44368,DS-d35ad07e-e446-4601-96da-afc553892b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-0151c6c2-4e55-479e-ba6f-4cd5e7c24e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36545,DS-994bd406-015e-44db-bcad-5759a534fbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-03b84254-d96d-4c2c-89dc-233b7d2e5b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-28fbd834-77ba-4150-ae6e-035722f690dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-46547972-6676-491f-9339-83098e6985e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-e21d7c8d-50ad-4dc9-864b-09e3ec818903,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-73e58067-72ef-426a-b33e-7cf77c54c5d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5453
