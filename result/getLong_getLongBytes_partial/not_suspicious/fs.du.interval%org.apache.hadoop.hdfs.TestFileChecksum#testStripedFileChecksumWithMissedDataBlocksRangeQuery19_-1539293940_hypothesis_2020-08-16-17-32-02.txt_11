reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-868729470-172.17.0.16-1597599908590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39119,DS-1fe86023-ae66-4408-a69e-01dde9160edf,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-ba6e1545-d246-4437-be3b-988f7b5db07f,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-2061103b-8f21-4387-bc5a-021feac21b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-5274d5f9-a30d-4aa5-8222-5f3f59f8dc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-8f730ca0-18df-4025-abe1-494a3414f1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-106d185a-5ca3-48d1-b26c-87625bc68ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-b1c07c8a-2fbf-4969-903a-dbd061c0c0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-e1a16cf3-8cdf-4be6-b70e-5ddea870f660,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-868729470-172.17.0.16-1597599908590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39119,DS-1fe86023-ae66-4408-a69e-01dde9160edf,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-ba6e1545-d246-4437-be3b-988f7b5db07f,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-2061103b-8f21-4387-bc5a-021feac21b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-5274d5f9-a30d-4aa5-8222-5f3f59f8dc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-8f730ca0-18df-4025-abe1-494a3414f1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-106d185a-5ca3-48d1-b26c-87625bc68ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-b1c07c8a-2fbf-4969-903a-dbd061c0c0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-e1a16cf3-8cdf-4be6-b70e-5ddea870f660,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-694296582-172.17.0.16-1597600013739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40500,DS-836473be-bf57-4514-bfe6-e3fa4751afd1,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-8ed3da06-3fb5-4b84-9dd9-7cab64505529,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-55e58e33-82fc-40df-b8e8-fdb229fe40b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-156d3263-8ff8-4677-af4b-1321bb5d2468,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-7eb29f47-c63d-457b-83a3-958080b97ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-7d96ccfd-746c-4229-8603-edddf86512e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-df8d830b-f38e-4f23-8a2e-adeec7bce0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-3d2f538c-63b2-4a47-8445-b4b1f111068c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-694296582-172.17.0.16-1597600013739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40500,DS-836473be-bf57-4514-bfe6-e3fa4751afd1,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-8ed3da06-3fb5-4b84-9dd9-7cab64505529,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-55e58e33-82fc-40df-b8e8-fdb229fe40b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-156d3263-8ff8-4677-af4b-1321bb5d2468,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-7eb29f47-c63d-457b-83a3-958080b97ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-7d96ccfd-746c-4229-8603-edddf86512e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-df8d830b-f38e-4f23-8a2e-adeec7bce0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-3d2f538c-63b2-4a47-8445-b4b1f111068c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1436226791-172.17.0.16-1597600148822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44893,DS-fc02f1a7-13da-4477-b558-4d2ca1e189ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-3d56463a-a4fa-43a4-ab58-49b5b146a7df,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-5a04da30-c434-4db7-a613-47737dd429e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-3c04b149-49a1-4682-8dec-0431c8555fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-1719e2cf-6a15-4169-933f-94f75477c4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-40951db3-f26a-482d-b86f-f0aab255ba95,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-4014f86b-b4d0-495b-bcaa-f020c6f0af37,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-1cbc42a0-c3ee-4428-8b31-7905c9074db7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1436226791-172.17.0.16-1597600148822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44893,DS-fc02f1a7-13da-4477-b558-4d2ca1e189ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-3d56463a-a4fa-43a4-ab58-49b5b146a7df,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-5a04da30-c434-4db7-a613-47737dd429e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-3c04b149-49a1-4682-8dec-0431c8555fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-1719e2cf-6a15-4169-933f-94f75477c4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-40951db3-f26a-482d-b86f-f0aab255ba95,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-4014f86b-b4d0-495b-bcaa-f020c6f0af37,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-1cbc42a0-c3ee-4428-8b31-7905c9074db7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-126354448-172.17.0.16-1597600376059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38924,DS-35d76871-a80c-4b98-8145-248b96b233a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-5c20ca82-561a-46b7-bcb2-b9b29031a6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-4057dc31-a492-48fa-8c2e-1ba45306af0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-c358d356-feb9-4a7e-89fa-dbc500b92590,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-3015bfb7-8dd8-457f-93fd-52944eda2da2,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-26bc9656-2291-4ee8-acb0-127d9bbfff19,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-2835c208-d513-44bb-b04e-3010922d67af,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-b845a073-988b-4e6b-b685-35ba7667e6b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-126354448-172.17.0.16-1597600376059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38924,DS-35d76871-a80c-4b98-8145-248b96b233a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-5c20ca82-561a-46b7-bcb2-b9b29031a6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-4057dc31-a492-48fa-8c2e-1ba45306af0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-c358d356-feb9-4a7e-89fa-dbc500b92590,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-3015bfb7-8dd8-457f-93fd-52944eda2da2,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-26bc9656-2291-4ee8-acb0-127d9bbfff19,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-2835c208-d513-44bb-b04e-3010922d67af,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-b845a073-988b-4e6b-b685-35ba7667e6b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1408068148-172.17.0.16-1597601479272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42294,DS-99ef84b8-c279-41df-ac8a-c2da4f52832b,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-fc4048c1-e83f-4441-814e-984f0a246f24,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-4510e4fb-64bb-4e0c-86c9-1f4fc164444d,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-b1eb1125-bc84-4e24-911d-6eba98f8115e,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-83128d9e-6b51-4261-a969-a9c3ab69809f,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-1c1842d1-1994-48a6-b929-43f90baf705b,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-aeb99b32-5228-4393-a617-e708480206d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-52b4f903-9d46-4f10-b7ae-df3c2b1ebe69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1408068148-172.17.0.16-1597601479272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42294,DS-99ef84b8-c279-41df-ac8a-c2da4f52832b,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-fc4048c1-e83f-4441-814e-984f0a246f24,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-4510e4fb-64bb-4e0c-86c9-1f4fc164444d,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-b1eb1125-bc84-4e24-911d-6eba98f8115e,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-83128d9e-6b51-4261-a969-a9c3ab69809f,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-1c1842d1-1994-48a6-b929-43f90baf705b,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-aeb99b32-5228-4393-a617-e708480206d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-52b4f903-9d46-4f10-b7ae-df3c2b1ebe69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1158570104-172.17.0.16-1597601627581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36000,DS-cab25efd-309f-49ee-9090-13bebaff9e79,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-f4ff3c25-1a80-4f2a-882e-57f8dc8202f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-ed791d08-8de6-4963-8328-c75e1728d556,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-3b0fb7c3-8bc0-40ab-9831-976d4ecede76,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-677fe189-9cac-42d7-ac56-8fba8e40ac2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-37d0155d-53b2-4a6a-9c32-8496a93c6cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-d6a8f3c0-ca0d-4c60-a340-a6b5fa03dbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-e0f03c67-963e-48ed-a5ff-84833f28aff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1158570104-172.17.0.16-1597601627581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36000,DS-cab25efd-309f-49ee-9090-13bebaff9e79,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-f4ff3c25-1a80-4f2a-882e-57f8dc8202f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-ed791d08-8de6-4963-8328-c75e1728d556,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-3b0fb7c3-8bc0-40ab-9831-976d4ecede76,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-677fe189-9cac-42d7-ac56-8fba8e40ac2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-37d0155d-53b2-4a6a-9c32-8496a93c6cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-d6a8f3c0-ca0d-4c60-a340-a6b5fa03dbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-e0f03c67-963e-48ed-a5ff-84833f28aff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1498945600-172.17.0.16-1597601720708:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43090,DS-625a26bf-95f3-49e4-a7f2-e47ad05b3fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-ede78edd-beda-421f-84bc-25bdae846ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:41711,DS-257202c8-52b6-403b-99a5-eb43c3312ced,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-84fe3bc1-ab2a-4ad0-9d09-6374f1bf4494,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-46df0003-4460-42fd-b913-f5eff79190a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-bd9135f7-9666-45cf-97a2-f639cf14f23b,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-100e0834-8239-4d49-91b6-43e392d1d4df,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-eaa40ca5-2a9d-4002-acb4-c2d8b9b781bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1498945600-172.17.0.16-1597601720708:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43090,DS-625a26bf-95f3-49e4-a7f2-e47ad05b3fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-ede78edd-beda-421f-84bc-25bdae846ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:41711,DS-257202c8-52b6-403b-99a5-eb43c3312ced,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-84fe3bc1-ab2a-4ad0-9d09-6374f1bf4494,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-46df0003-4460-42fd-b913-f5eff79190a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-bd9135f7-9666-45cf-97a2-f639cf14f23b,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-100e0834-8239-4d49-91b6-43e392d1d4df,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-eaa40ca5-2a9d-4002-acb4-c2d8b9b781bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-97359562-172.17.0.16-1597602202303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38359,DS-4f534aa9-00a3-4c51-8a6a-a5d3f6a1ff98,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-bedffe30-8557-49bf-9561-e4629bd4295d,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-355409e7-1d30-4865-b973-4ac0bdb6785a,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-58663fb9-d15a-414e-afdd-753cee38e544,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-b40eef27-fa33-4de2-ad80-efe0996ef33e,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-1776bb70-04fa-4525-95e7-fb20f80606c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-cb3310f2-c953-4cbd-9502-564bab89d100,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-0583e5e7-f2e6-4e30-b9de-576ba99da930,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-97359562-172.17.0.16-1597602202303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38359,DS-4f534aa9-00a3-4c51-8a6a-a5d3f6a1ff98,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-bedffe30-8557-49bf-9561-e4629bd4295d,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-355409e7-1d30-4865-b973-4ac0bdb6785a,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-58663fb9-d15a-414e-afdd-753cee38e544,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-b40eef27-fa33-4de2-ad80-efe0996ef33e,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-1776bb70-04fa-4525-95e7-fb20f80606c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-cb3310f2-c953-4cbd-9502-564bab89d100,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-0583e5e7-f2e6-4e30-b9de-576ba99da930,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131107930-172.17.0.16-1597604109556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45836,DS-cbee49b7-7e8d-4279-8346-e93bae0fd184,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-7da5cc33-dc84-4170-a62b-7791453ba389,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-84f68950-e5df-478b-b72a-0f4a5677a681,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-e8cee581-5211-424b-aa57-99c6e8630225,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-17c59962-ce5b-41cd-a774-66a907b7d3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-6135d6d8-9785-4de3-90c4-6c7357c3c0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-304fba3b-aafc-4ea2-8b97-a14439f2a668,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-edf269fe-f754-4c14-aa6b-ff7d4c889917,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131107930-172.17.0.16-1597604109556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45836,DS-cbee49b7-7e8d-4279-8346-e93bae0fd184,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-7da5cc33-dc84-4170-a62b-7791453ba389,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-84f68950-e5df-478b-b72a-0f4a5677a681,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-e8cee581-5211-424b-aa57-99c6e8630225,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-17c59962-ce5b-41cd-a774-66a907b7d3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-6135d6d8-9785-4de3-90c4-6c7357c3c0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-304fba3b-aafc-4ea2-8b97-a14439f2a668,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-edf269fe-f754-4c14-aa6b-ff7d4c889917,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-995062053-172.17.0.16-1597604514734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35628,DS-4cf271bd-262f-49dc-b807-af8b8d47a6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-4cb43c08-0105-4875-a479-9906ab3a89c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-d887af5c-3e7c-421e-b1c2-26e9305bc097,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-53e689b7-cc1b-4ae6-a2e1-df3e558d1404,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-39ac9ec8-4e7c-4e12-942c-060a3edd2955,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-2d797563-a192-4111-a833-cecfa3f084d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-490cd3be-e146-4799-8cf4-581724d098bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-406abab9-e187-4698-82fd-1714d8844f90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-995062053-172.17.0.16-1597604514734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35628,DS-4cf271bd-262f-49dc-b807-af8b8d47a6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-4cb43c08-0105-4875-a479-9906ab3a89c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-d887af5c-3e7c-421e-b1c2-26e9305bc097,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-53e689b7-cc1b-4ae6-a2e1-df3e558d1404,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-39ac9ec8-4e7c-4e12-942c-060a3edd2955,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-2d797563-a192-4111-a833-cecfa3f084d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-490cd3be-e146-4799-8cf4-581724d098bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-406abab9-e187-4698-82fd-1714d8844f90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-926601268-172.17.0.16-1597604810776:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40539,DS-d17d8cb3-f227-4fe4-9051-9c3f401073cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-aa9083fd-df49-412c-b688-e159602fff9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-0828674e-956a-4c11-adb5-940917e3c20d,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-c5895648-c9e3-418a-bb52-9469ca0feb71,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-142b8348-5d8f-4433-99b6-a7a58dd27089,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-1568fa44-18aa-4719-bee4-1b8f69dbe52e,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-7144cfe4-6332-4cbb-b609-09bfb3506bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-151e1cae-710a-4aab-a9b1-f444f964f187,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-926601268-172.17.0.16-1597604810776:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40539,DS-d17d8cb3-f227-4fe4-9051-9c3f401073cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-aa9083fd-df49-412c-b688-e159602fff9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-0828674e-956a-4c11-adb5-940917e3c20d,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-c5895648-c9e3-418a-bb52-9469ca0feb71,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-142b8348-5d8f-4433-99b6-a7a58dd27089,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-1568fa44-18aa-4719-bee4-1b8f69dbe52e,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-7144cfe4-6332-4cbb-b609-09bfb3506bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-151e1cae-710a-4aab-a9b1-f444f964f187,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-837502927-172.17.0.16-1597605099373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34338,DS-8fc03895-2031-4819-a123-9f8243a4505c,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-a38f03c8-f1b2-4f69-bb62-d12945502231,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-3d7f9a09-d803-4189-9570-1f391a6a5a67,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-d8dd3ee6-d83b-481c-a669-35962a4f0ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-84e606f3-6a45-4084-9f03-0f5d5d0974d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-86cdf6f1-066e-4741-86a3-54d4f8147dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-964fdca5-9ab5-4265-af8a-9d938b70e158,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-3fc7ca28-a46b-43f4-b7b0-287c1de31801,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-837502927-172.17.0.16-1597605099373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34338,DS-8fc03895-2031-4819-a123-9f8243a4505c,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-a38f03c8-f1b2-4f69-bb62-d12945502231,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-3d7f9a09-d803-4189-9570-1f391a6a5a67,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-d8dd3ee6-d83b-481c-a669-35962a4f0ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-84e606f3-6a45-4084-9f03-0f5d5d0974d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-86cdf6f1-066e-4741-86a3-54d4f8147dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-964fdca5-9ab5-4265-af8a-9d938b70e158,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-3fc7ca28-a46b-43f4-b7b0-287c1de31801,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-318170772-172.17.0.16-1597605154545:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42878,DS-4c72a948-d522-4857-8743-a7635b64fa74,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-61510a6e-e8e7-40eb-baf7-ee2de3e45d09,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-e27beed5-1c6b-4ac9-a822-223561129b38,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-3c48a401-3909-406c-ae77-118115230e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-4b17f910-5c91-4e7a-8c3e-48ee77dae5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-5db67316-391e-40ac-ba88-f4af27a8322e,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-5dcb38b1-faf3-4b22-8d86-b7a673e13347,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-ec0399fb-0f55-4a60-9f06-9158a4265eda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-318170772-172.17.0.16-1597605154545:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42878,DS-4c72a948-d522-4857-8743-a7635b64fa74,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-61510a6e-e8e7-40eb-baf7-ee2de3e45d09,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-e27beed5-1c6b-4ac9-a822-223561129b38,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-3c48a401-3909-406c-ae77-118115230e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-4b17f910-5c91-4e7a-8c3e-48ee77dae5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-5db67316-391e-40ac-ba88-f4af27a8322e,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-5dcb38b1-faf3-4b22-8d86-b7a673e13347,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-ec0399fb-0f55-4a60-9f06-9158a4265eda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680706221-172.17.0.16-1597605537768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32999,DS-aa036e30-b159-4576-96fc-d7c23ac7561c,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-5a060ef1-043c-457c-8fd6-750f61e19708,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-2bd43a12-a64c-40e3-94d5-81db7e781cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-08a9af18-4662-453a-aeb6-23971ea062ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-ea60adb5-b626-4172-9f3d-a1569951b4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-bffb6ed6-3571-4d23-8cd9-c0faaed2c009,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-a25629ca-71ce-4dfa-a65d-53f44276ebc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-bd42e61f-0083-4106-8b9c-e0d2aa49e33c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680706221-172.17.0.16-1597605537768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32999,DS-aa036e30-b159-4576-96fc-d7c23ac7561c,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-5a060ef1-043c-457c-8fd6-750f61e19708,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-2bd43a12-a64c-40e3-94d5-81db7e781cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-08a9af18-4662-453a-aeb6-23971ea062ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-ea60adb5-b626-4172-9f3d-a1569951b4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-bffb6ed6-3571-4d23-8cd9-c0faaed2c009,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-a25629ca-71ce-4dfa-a65d-53f44276ebc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-bd42e61f-0083-4106-8b9c-e0d2aa49e33c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1699308171-172.17.0.16-1597605635217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33951,DS-277528dc-55cd-4d49-93cb-4b4a5d24e724,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-02b257ef-30e2-46bf-bee9-5cb07e7e8310,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-f6c30b9d-18d1-44ce-a672-3164924b186f,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-8ff5deb3-69c1-4c2f-aeac-06c386986fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-e1b634e7-94fd-4b54-b64f-6cafcb7ee36d,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-2789acbf-72fc-4540-8356-f80f047cc3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-fbecf2f9-efbe-442f-a9d0-2f519ce22260,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-01f9f0c0-f258-487e-84a4-7167cf1524d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1699308171-172.17.0.16-1597605635217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33951,DS-277528dc-55cd-4d49-93cb-4b4a5d24e724,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-02b257ef-30e2-46bf-bee9-5cb07e7e8310,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-f6c30b9d-18d1-44ce-a672-3164924b186f,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-8ff5deb3-69c1-4c2f-aeac-06c386986fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-e1b634e7-94fd-4b54-b64f-6cafcb7ee36d,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-2789acbf-72fc-4540-8356-f80f047cc3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-fbecf2f9-efbe-442f-a9d0-2f519ce22260,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-01f9f0c0-f258-487e-84a4-7167cf1524d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-912661437-172.17.0.16-1597605779775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45755,DS-e450119d-a1c8-492a-ad6b-1275912afed8,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-26abfb67-f4ae-44df-87db-41f37294f561,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-e5e6df5f-564d-4cd6-86e3-a633a11f4c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-c1e45259-1f08-4830-a6db-fb951b84024c,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-e6616392-c961-4dcf-a6fa-87322572faae,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-b5e4ab4b-cdc0-48d7-a552-f02d1b63615b,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-a2721d2b-d0c3-4b0e-8529-7b0de7a67ead,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-9155aa57-af3f-4b80-a8b0-b89ee82c0181,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-912661437-172.17.0.16-1597605779775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45755,DS-e450119d-a1c8-492a-ad6b-1275912afed8,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-26abfb67-f4ae-44df-87db-41f37294f561,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-e5e6df5f-564d-4cd6-86e3-a633a11f4c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-c1e45259-1f08-4830-a6db-fb951b84024c,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-e6616392-c961-4dcf-a6fa-87322572faae,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-b5e4ab4b-cdc0-48d7-a552-f02d1b63615b,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-a2721d2b-d0c3-4b0e-8529-7b0de7a67ead,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-9155aa57-af3f-4b80-a8b0-b89ee82c0181,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-793494007-172.17.0.16-1597605912810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44371,DS-3cabdcf4-f925-4910-8fa0-f937ad3bfbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-7fd30091-984e-424a-8b9d-6e2e13f395c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-514e1f91-770e-41bb-8559-f0c0795b6512,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-21f27930-cee6-494e-bdec-111ee9b64442,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-8d4f213d-467b-4421-ae01-d205aaef7dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-d3e21691-c865-4c9f-8770-dc506e537b75,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-2bb7b1d0-7126-4d5d-bf18-bc6d022e7716,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-eabc9d6c-c8db-4aef-95b5-3b462a90994a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-793494007-172.17.0.16-1597605912810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44371,DS-3cabdcf4-f925-4910-8fa0-f937ad3bfbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-7fd30091-984e-424a-8b9d-6e2e13f395c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-514e1f91-770e-41bb-8559-f0c0795b6512,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-21f27930-cee6-494e-bdec-111ee9b64442,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-8d4f213d-467b-4421-ae01-d205aaef7dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-d3e21691-c865-4c9f-8770-dc506e537b75,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-2bb7b1d0-7126-4d5d-bf18-bc6d022e7716,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-eabc9d6c-c8db-4aef-95b5-3b462a90994a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-540559436-172.17.0.16-1597606050073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44778,DS-8d0be526-8e2d-47b9-a4c3-7ed9cfe54b42,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-82c2ff88-916c-45c1-8979-1c29c5f0fcfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-8c1cc714-da3a-4b02-bd5d-96904b2ff341,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-5f2145c7-7727-46c5-a564-5c4f219e9503,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-7d6040e8-8eee-42e0-a939-86242fe4af10,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-eb4d8a5d-4b50-434e-b160-80e0c3952324,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-62481200-0691-408c-ba7b-58bbb54bce74,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-f59cb706-6c64-4f55-a7ff-e7bdd9d95b4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-540559436-172.17.0.16-1597606050073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44778,DS-8d0be526-8e2d-47b9-a4c3-7ed9cfe54b42,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-82c2ff88-916c-45c1-8979-1c29c5f0fcfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-8c1cc714-da3a-4b02-bd5d-96904b2ff341,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-5f2145c7-7727-46c5-a564-5c4f219e9503,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-7d6040e8-8eee-42e0-a939-86242fe4af10,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-eb4d8a5d-4b50-434e-b160-80e0c3952324,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-62481200-0691-408c-ba7b-58bbb54bce74,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-f59cb706-6c64-4f55-a7ff-e7bdd9d95b4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 7228
