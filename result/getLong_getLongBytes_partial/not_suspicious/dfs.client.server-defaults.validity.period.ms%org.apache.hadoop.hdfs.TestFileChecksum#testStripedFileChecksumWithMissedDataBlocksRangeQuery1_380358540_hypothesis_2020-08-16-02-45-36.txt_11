reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-837483329-172.17.0.17-1597546237948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45351,DS-3e706632-6046-482b-b0d1-c3e786ce810e,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-01fd3150-b2ff-408f-81aa-3330032f0e85,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-d9f70a9b-2c1f-45fb-a2ea-abfbcc468f39,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-f003c824-a9fb-4198-9f41-2399f7762b74,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-60f3ae57-1b65-4fe3-9d01-5b5cc4bf90c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-becdfbdf-f00d-4a01-a7cd-0c5b948c5ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-bf9ad9be-7a12-4207-9e81-3b9714ea059d,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-67db9b99-db1a-4d04-b2a1-d049b9ceb175,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-837483329-172.17.0.17-1597546237948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45351,DS-3e706632-6046-482b-b0d1-c3e786ce810e,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-01fd3150-b2ff-408f-81aa-3330032f0e85,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-d9f70a9b-2c1f-45fb-a2ea-abfbcc468f39,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-f003c824-a9fb-4198-9f41-2399f7762b74,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-60f3ae57-1b65-4fe3-9d01-5b5cc4bf90c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-becdfbdf-f00d-4a01-a7cd-0c5b948c5ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-bf9ad9be-7a12-4207-9e81-3b9714ea059d,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-67db9b99-db1a-4d04-b2a1-d049b9ceb175,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2043788798-172.17.0.17-1597546348783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41572,DS-bea29c46-95c7-4418-a2aa-42d2f729cf15,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-a0977135-888d-4c3f-a989-b3aa56ed3616,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-fd538e9c-6805-4dcb-868f-db2e01f61a14,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-43b2d834-ec91-4be4-87ea-bb5102a806fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-06f57749-37f6-4bad-88c0-79ffd7d9269a,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-d0b49a80-f1f4-4a87-acb1-c12c158cd9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-25a499fb-ef5f-4dac-9df8-e590e097ad3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-3d283a18-9250-4098-bc74-d9d0b3f7ab11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2043788798-172.17.0.17-1597546348783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41572,DS-bea29c46-95c7-4418-a2aa-42d2f729cf15,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-a0977135-888d-4c3f-a989-b3aa56ed3616,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-fd538e9c-6805-4dcb-868f-db2e01f61a14,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-43b2d834-ec91-4be4-87ea-bb5102a806fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-06f57749-37f6-4bad-88c0-79ffd7d9269a,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-d0b49a80-f1f4-4a87-acb1-c12c158cd9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-25a499fb-ef5f-4dac-9df8-e590e097ad3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-3d283a18-9250-4098-bc74-d9d0b3f7ab11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1048000323-172.17.0.17-1597546650304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35731,DS-e8270eac-f864-4405-aecb-42eff4e38d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-522591a8-06fa-4aff-be8c-2d63d0a20d73,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-704c3f31-f123-4cc7-a14f-654306a46d00,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-f33cc8d3-97bb-4c39-8459-429a58449dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-081acfe8-55d4-452a-a858-01939d3df281,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-60aa18cc-d750-4966-99c9-6480ddcd92ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-10018940-67f5-4633-afb1-9b36b7bd3505,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-f726a4d2-2169-4530-b77b-4150f48c57d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1048000323-172.17.0.17-1597546650304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35731,DS-e8270eac-f864-4405-aecb-42eff4e38d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-522591a8-06fa-4aff-be8c-2d63d0a20d73,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-704c3f31-f123-4cc7-a14f-654306a46d00,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-f33cc8d3-97bb-4c39-8459-429a58449dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-081acfe8-55d4-452a-a858-01939d3df281,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-60aa18cc-d750-4966-99c9-6480ddcd92ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-10018940-67f5-4633-afb1-9b36b7bd3505,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-f726a4d2-2169-4530-b77b-4150f48c57d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1650868691-172.17.0.17-1597547109296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35841,DS-7ccf81ef-5ac3-4bf0-8a22-f78116e14da9,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-df28138c-b59b-4b43-a217-c04e1311f94e,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-2eaf8d9b-89f4-42ca-86b9-2657617a5aee,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-56e1c0c3-cff8-4d45-82c5-c23b51899485,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-52d08ff5-0163-4b3e-a170-8377169e94cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-02b944bf-dcd8-48de-a4bf-b8df3f3a1094,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-d8b29a83-954f-4ff0-b91a-a894aa983ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-7eaf3b39-942c-4eae-8b97-ed38f9a0bd9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1650868691-172.17.0.17-1597547109296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35841,DS-7ccf81ef-5ac3-4bf0-8a22-f78116e14da9,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-df28138c-b59b-4b43-a217-c04e1311f94e,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-2eaf8d9b-89f4-42ca-86b9-2657617a5aee,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-56e1c0c3-cff8-4d45-82c5-c23b51899485,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-52d08ff5-0163-4b3e-a170-8377169e94cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-02b944bf-dcd8-48de-a4bf-b8df3f3a1094,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-d8b29a83-954f-4ff0-b91a-a894aa983ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-7eaf3b39-942c-4eae-8b97-ed38f9a0bd9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1287167945-172.17.0.17-1597547174602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42019,DS-2e5818f5-887f-49df-a16b-36a6f63a8187,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-caa75de9-373e-4e12-89c8-11029df2fd93,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-44d95874-8d5d-4189-8bf3-21a0b11b7123,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-a205eca7-7ee8-4712-b3b6-523ce73fa5da,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-39cacc4a-1851-4414-bdef-9aefd79ccffb,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-d3420820-fe05-4e96-b7b0-c9d91e753590,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-c834a7ef-4f2a-471e-854b-3370d61b13e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-cc17fd21-128b-4dff-aebc-3699932f3e38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1287167945-172.17.0.17-1597547174602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42019,DS-2e5818f5-887f-49df-a16b-36a6f63a8187,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-caa75de9-373e-4e12-89c8-11029df2fd93,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-44d95874-8d5d-4189-8bf3-21a0b11b7123,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-a205eca7-7ee8-4712-b3b6-523ce73fa5da,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-39cacc4a-1851-4414-bdef-9aefd79ccffb,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-d3420820-fe05-4e96-b7b0-c9d91e753590,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-c834a7ef-4f2a-471e-854b-3370d61b13e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-cc17fd21-128b-4dff-aebc-3699932f3e38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1583657049-172.17.0.17-1597547378076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38975,DS-869aff62-6182-46f7-9323-aa47005dac0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-816027b1-8105-4fc2-a65f-64c16a682c95,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-9f308484-042c-4f8f-9d0a-8b9cadd8824d,DISK], DatanodeInfoWithStorage[127.0.0.1:42610,DS-5916986d-05bb-488c-8835-ea1d4a244194,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-6e66bae4-25a7-4ae6-b383-e19702dcce5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-7b4feef8-4a39-4270-8351-f51cb640bd22,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-b3906327-c612-420b-9f6c-5db6abe3fc84,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-114aa059-28d2-40d5-a346-9d452df97b33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1583657049-172.17.0.17-1597547378076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38975,DS-869aff62-6182-46f7-9323-aa47005dac0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-816027b1-8105-4fc2-a65f-64c16a682c95,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-9f308484-042c-4f8f-9d0a-8b9cadd8824d,DISK], DatanodeInfoWithStorage[127.0.0.1:42610,DS-5916986d-05bb-488c-8835-ea1d4a244194,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-6e66bae4-25a7-4ae6-b383-e19702dcce5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-7b4feef8-4a39-4270-8351-f51cb640bd22,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-b3906327-c612-420b-9f6c-5db6abe3fc84,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-114aa059-28d2-40d5-a346-9d452df97b33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-914297760-172.17.0.17-1597547447396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44754,DS-fb37abd6-60e6-43aa-a347-1ec62883bc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-03f2cfb9-9f43-4a56-aa61-df39f7bcabf7,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-ac1c74ec-6d35-419f-9b65-41e152bcf7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-db02f350-8714-4be0-8fca-bce21ed96b06,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-31bfd4c5-5f93-4772-91f2-09a5edf14ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-d2b4c299-0f01-4413-b248-43fe5cd2476a,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-812a59fd-b1f8-4836-bbdb-051ede565a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-d06fb590-7225-4524-8933-788c50c4500b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-914297760-172.17.0.17-1597547447396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44754,DS-fb37abd6-60e6-43aa-a347-1ec62883bc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-03f2cfb9-9f43-4a56-aa61-df39f7bcabf7,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-ac1c74ec-6d35-419f-9b65-41e152bcf7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-db02f350-8714-4be0-8fca-bce21ed96b06,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-31bfd4c5-5f93-4772-91f2-09a5edf14ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-d2b4c299-0f01-4413-b248-43fe5cd2476a,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-812a59fd-b1f8-4836-bbdb-051ede565a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-d06fb590-7225-4524-8933-788c50c4500b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061561159-172.17.0.17-1597547578332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36677,DS-585dc3e6-4569-4637-a5d6-4e060f4050c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-43aed80e-43e8-4005-831b-5e3ca9ff510e,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-e09f2cfe-a860-473b-9b0b-c6b467886d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-f7879920-2cb3-4142-a509-66bf83c66b67,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-9d7888cc-8437-422c-8abb-e071d8e8cf28,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-9deba4b2-5406-45c5-871e-42aa967cb675,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-46ca8149-a7e8-49b4-9d7c-c38ffa012f00,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-eb44b7f6-696a-4040-ba4e-a3a48729dde1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061561159-172.17.0.17-1597547578332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36677,DS-585dc3e6-4569-4637-a5d6-4e060f4050c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-43aed80e-43e8-4005-831b-5e3ca9ff510e,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-e09f2cfe-a860-473b-9b0b-c6b467886d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-f7879920-2cb3-4142-a509-66bf83c66b67,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-9d7888cc-8437-422c-8abb-e071d8e8cf28,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-9deba4b2-5406-45c5-871e-42aa967cb675,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-46ca8149-a7e8-49b4-9d7c-c38ffa012f00,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-eb44b7f6-696a-4040-ba4e-a3a48729dde1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-451877899-172.17.0.17-1597548159913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40264,DS-bbe414eb-9ba3-4482-8b8b-42168d1ff13d,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-4ff946bc-dfdd-484d-9133-36c0d7ecb20b,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-df0d3927-62e9-4e46-b088-e800b1781dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-6e8bb432-74f5-444b-bd16-64faff72249f,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-b826c24a-413f-4b32-92e0-bf34b38e79b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44265,DS-6490ba20-507b-4778-aeff-be57402d998e,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-3f527fa6-e073-4511-9208-14cc93c52fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-5f763b15-bc1f-48ce-9178-7f3c6e86c1c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-451877899-172.17.0.17-1597548159913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40264,DS-bbe414eb-9ba3-4482-8b8b-42168d1ff13d,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-4ff946bc-dfdd-484d-9133-36c0d7ecb20b,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-df0d3927-62e9-4e46-b088-e800b1781dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-6e8bb432-74f5-444b-bd16-64faff72249f,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-b826c24a-413f-4b32-92e0-bf34b38e79b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44265,DS-6490ba20-507b-4778-aeff-be57402d998e,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-3f527fa6-e073-4511-9208-14cc93c52fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-5f763b15-bc1f-48ce-9178-7f3c6e86c1c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1677505406-172.17.0.17-1597548402389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39246,DS-3898a07f-1d5e-4f8d-adf7-1ed861f3778e,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-be7aca2f-411e-4ab1-9716-b167da647967,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-90e0038f-b8d6-441c-b986-9ddd45c3d153,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-9c302365-14a2-4d79-a58c-26d7de71e21b,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-16295b83-1474-4908-8100-f9d93167e0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-91159640-e305-437c-8b3f-f10b61b8912a,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-d5916849-0255-4b74-964d-59d7dac32dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-aa6f50a9-ce09-4172-8d94-3400f2466026,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1677505406-172.17.0.17-1597548402389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39246,DS-3898a07f-1d5e-4f8d-adf7-1ed861f3778e,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-be7aca2f-411e-4ab1-9716-b167da647967,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-90e0038f-b8d6-441c-b986-9ddd45c3d153,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-9c302365-14a2-4d79-a58c-26d7de71e21b,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-16295b83-1474-4908-8100-f9d93167e0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-91159640-e305-437c-8b3f-f10b61b8912a,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-d5916849-0255-4b74-964d-59d7dac32dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-aa6f50a9-ce09-4172-8d94-3400f2466026,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216522369-172.17.0.17-1597548554717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35666,DS-4846522c-ee44-4bdf-bf8a-20a8ab5b903b,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-6eb4d7de-9593-4da6-855c-1e62990a389e,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-c366e7db-4ddd-4472-8a5c-d756519d987c,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-de56a424-078f-4f50-9860-703fab3d0ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-e0400d1c-48cc-4ac8-9f3c-c9e21789158d,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-689f5a7b-cf8e-42af-a8bd-59d78f0cf220,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-66efb7a8-9e20-4669-ad4e-2434bd257d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-cfd6bbfe-cfad-4c25-8038-dd0bf04d2f51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216522369-172.17.0.17-1597548554717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35666,DS-4846522c-ee44-4bdf-bf8a-20a8ab5b903b,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-6eb4d7de-9593-4da6-855c-1e62990a389e,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-c366e7db-4ddd-4472-8a5c-d756519d987c,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-de56a424-078f-4f50-9860-703fab3d0ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-e0400d1c-48cc-4ac8-9f3c-c9e21789158d,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-689f5a7b-cf8e-42af-a8bd-59d78f0cf220,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-66efb7a8-9e20-4669-ad4e-2434bd257d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-cfd6bbfe-cfad-4c25-8038-dd0bf04d2f51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-190567546-172.17.0.17-1597548662983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33171,DS-757b63bf-7155-4ead-a235-fa51a5a1d6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-c6d0175a-74e9-4bcd-92ed-475c9fbe443e,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-af437b41-aafb-4f05-9dd0-85d4049dbd42,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-debd3cf3-fd16-4e88-a4ea-bb88452f5d69,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-eb18d843-b07b-49d3-aac4-948e64d4da75,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-77b43617-ad1c-4ffc-bb67-173952f5551c,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-72534765-ea01-4afb-9f5d-0893ec5e21f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-8d81a16b-53bb-4b1d-bce5-86230f9ed83b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-190567546-172.17.0.17-1597548662983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33171,DS-757b63bf-7155-4ead-a235-fa51a5a1d6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-c6d0175a-74e9-4bcd-92ed-475c9fbe443e,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-af437b41-aafb-4f05-9dd0-85d4049dbd42,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-debd3cf3-fd16-4e88-a4ea-bb88452f5d69,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-eb18d843-b07b-49d3-aac4-948e64d4da75,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-77b43617-ad1c-4ffc-bb67-173952f5551c,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-72534765-ea01-4afb-9f5d-0893ec5e21f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-8d81a16b-53bb-4b1d-bce5-86230f9ed83b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1991821364-172.17.0.17-1597549633911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37504,DS-21bfe964-47c2-4cb6-b996-06e03ed34f56,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-333e82f8-da87-48f9-899f-cdaa5c43096d,DISK], DatanodeInfoWithStorage[127.0.0.1:45029,DS-94912a62-3fb2-42f1-8620-84540ddb3730,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-57956b3a-eb90-4064-a545-bc89db400198,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-c4e3bc57-78a2-412b-8573-fbb84eec14e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-be52af56-e0fc-40ef-a160-81a9f6418917,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-883ecd52-4b49-4c69-a0e0-998110861f72,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-77ea68c0-d930-497e-8c06-482f1e3b4e38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1991821364-172.17.0.17-1597549633911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37504,DS-21bfe964-47c2-4cb6-b996-06e03ed34f56,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-333e82f8-da87-48f9-899f-cdaa5c43096d,DISK], DatanodeInfoWithStorage[127.0.0.1:45029,DS-94912a62-3fb2-42f1-8620-84540ddb3730,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-57956b3a-eb90-4064-a545-bc89db400198,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-c4e3bc57-78a2-412b-8573-fbb84eec14e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-be52af56-e0fc-40ef-a160-81a9f6418917,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-883ecd52-4b49-4c69-a0e0-998110861f72,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-77ea68c0-d930-497e-8c06-482f1e3b4e38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631455726-172.17.0.17-1597549759309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42275,DS-1c9bec20-d55e-4505-9c31-76ac899bb062,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-ce78f028-21fe-424b-9f43-8b371f91326f,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-4305d14c-8f07-4e95-959f-0ec5fab75da8,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-b1240eac-ddf1-4cfb-8677-30251a63dcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-2b252160-6665-4752-8c17-3c39e835cda6,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-f18fc84f-d951-4090-9c3a-7c3f962d240b,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-cb94ad00-212a-442d-83ab-91b4a075c838,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-0741241a-723e-4ebb-ab22-d01b1b1a51b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631455726-172.17.0.17-1597549759309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42275,DS-1c9bec20-d55e-4505-9c31-76ac899bb062,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-ce78f028-21fe-424b-9f43-8b371f91326f,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-4305d14c-8f07-4e95-959f-0ec5fab75da8,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-b1240eac-ddf1-4cfb-8677-30251a63dcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-2b252160-6665-4752-8c17-3c39e835cda6,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-f18fc84f-d951-4090-9c3a-7c3f962d240b,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-cb94ad00-212a-442d-83ab-91b4a075c838,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-0741241a-723e-4ebb-ab22-d01b1b1a51b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-98178865-172.17.0.17-1597549840669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36253,DS-3787790a-55eb-4926-979a-ba932b7bb000,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-a52e9ebe-6283-4af3-9142-2e7c3e6218bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-4679cf02-ad64-4eb5-b776-9477730ba889,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-f105148b-7694-4e9e-8a4b-1ad7b8cbf57b,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-cb3eae43-e44b-424b-aafb-2bb1b1cfe394,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-605a1a8b-0625-4f31-9e6b-b2cbe83a222d,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-e8645902-a9d9-49af-bdff-ce1713422e81,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-43244d28-b9ec-449a-ba0c-8dc6ab4a0c37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-98178865-172.17.0.17-1597549840669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36253,DS-3787790a-55eb-4926-979a-ba932b7bb000,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-a52e9ebe-6283-4af3-9142-2e7c3e6218bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-4679cf02-ad64-4eb5-b776-9477730ba889,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-f105148b-7694-4e9e-8a4b-1ad7b8cbf57b,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-cb3eae43-e44b-424b-aafb-2bb1b1cfe394,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-605a1a8b-0625-4f31-9e6b-b2cbe83a222d,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-e8645902-a9d9-49af-bdff-ce1713422e81,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-43244d28-b9ec-449a-ba0c-8dc6ab4a0c37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1522594087-172.17.0.17-1597550561746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43892,DS-24c5d9c8-9947-49df-a6d0-c6aa6e2d5daf,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-fd72c009-65d7-480c-8e44-861af1112fff,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-ff1a9469-b802-4642-9ab5-01a3264724c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-bce7fb51-dd80-4e6f-aecd-901223e092e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-78bf9dd5-e9b3-49ca-ba4e-6080d9c72217,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-dd47c1e6-a87d-4154-b574-ebda70842988,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-2ce2fbfa-d653-4e35-b9ed-4de94f6a3f89,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-98df0740-c0d9-4b13-837f-1c9348f68b75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1522594087-172.17.0.17-1597550561746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43892,DS-24c5d9c8-9947-49df-a6d0-c6aa6e2d5daf,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-fd72c009-65d7-480c-8e44-861af1112fff,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-ff1a9469-b802-4642-9ab5-01a3264724c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-bce7fb51-dd80-4e6f-aecd-901223e092e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-78bf9dd5-e9b3-49ca-ba4e-6080d9c72217,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-dd47c1e6-a87d-4154-b574-ebda70842988,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-2ce2fbfa-d653-4e35-b9ed-4de94f6a3f89,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-98df0740-c0d9-4b13-837f-1c9348f68b75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-316177889-172.17.0.17-1597550830310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36758,DS-f02173f2-2365-437e-bd80-13c781334d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-c05b7ade-4dbd-4923-ac4e-942966e8a854,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-2a0b37b7-94e7-4b43-8146-1bc0a2f410ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-765f967b-b5d7-4a1e-bef9-942da6eb7dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-b29a0608-f011-4faf-92ba-6a5ac2200913,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-dfe18b87-88b1-40f2-b7cf-60c292033166,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-72f7eb08-8942-411e-b519-673eb2bed7df,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-46d8ffd3-30f1-43d2-b49e-65a4024a3ba1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-316177889-172.17.0.17-1597550830310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36758,DS-f02173f2-2365-437e-bd80-13c781334d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-c05b7ade-4dbd-4923-ac4e-942966e8a854,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-2a0b37b7-94e7-4b43-8146-1bc0a2f410ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-765f967b-b5d7-4a1e-bef9-942da6eb7dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-b29a0608-f011-4faf-92ba-6a5ac2200913,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-dfe18b87-88b1-40f2-b7cf-60c292033166,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-72f7eb08-8942-411e-b519-673eb2bed7df,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-46d8ffd3-30f1-43d2-b49e-65a4024a3ba1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-357066808-172.17.0.17-1597551152549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42858,DS-b9bb3d50-2400-42eb-a50e-ba58ef5c5af0,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-0056daf3-9acb-443e-a4a9-025456ddec51,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-60bccfe2-d47a-484f-b0f3-093a94f9cca7,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-317d3475-f8a5-41b7-86c3-b15a80c727af,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-5bfbf964-e29e-462c-9788-8360c33a02bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-85df7aa0-39df-4b97-96d8-8ae30a915f86,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-aad163a2-dbdb-4ac8-9aa3-daa75be13ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:33531,DS-525398b4-37da-4538-8818-8a6acb0e8bfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-357066808-172.17.0.17-1597551152549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42858,DS-b9bb3d50-2400-42eb-a50e-ba58ef5c5af0,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-0056daf3-9acb-443e-a4a9-025456ddec51,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-60bccfe2-d47a-484f-b0f3-093a94f9cca7,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-317d3475-f8a5-41b7-86c3-b15a80c727af,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-5bfbf964-e29e-462c-9788-8360c33a02bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-85df7aa0-39df-4b97-96d8-8ae30a915f86,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-aad163a2-dbdb-4ac8-9aa3-daa75be13ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:33531,DS-525398b4-37da-4538-8818-8a6acb0e8bfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-125228073-172.17.0.17-1597551606110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33244,DS-03f79ade-fac6-48c2-99b6-ab584db5928e,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-9e95f46e-c36d-4bfd-a824-95d49aad5c25,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-78b02eaa-f2aa-4ac6-bcf4-728599a9109a,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-25c64c4f-b67a-4ac6-975f-196fd42ecc28,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-37e16ae9-4c92-4edf-996e-8473577ce0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-9d74e83a-efe8-41f5-9cc0-2624949b13c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-0e0a230a-abc0-427e-85ac-a436ed291fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-16b8120f-ad8d-4dd8-beba-7028e14c9b4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-125228073-172.17.0.17-1597551606110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33244,DS-03f79ade-fac6-48c2-99b6-ab584db5928e,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-9e95f46e-c36d-4bfd-a824-95d49aad5c25,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-78b02eaa-f2aa-4ac6-bcf4-728599a9109a,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-25c64c4f-b67a-4ac6-975f-196fd42ecc28,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-37e16ae9-4c92-4edf-996e-8473577ce0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-9d74e83a-efe8-41f5-9cc0-2624949b13c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-0e0a230a-abc0-427e-85ac-a436ed291fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-16b8120f-ad8d-4dd8-beba-7028e14c9b4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1134476776-172.17.0.17-1597551688019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39762,DS-5e5df282-f223-4c37-b330-ec1bc3cb1351,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-eb73db3f-6924-4564-928b-6694b9c42e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-27f2f3a2-d2c1-4516-8ed6-6d2265476ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-0f4c5851-66e4-43d9-bcd9-84bfd541aaea,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-2d064dff-c755-4b41-82c6-a7cc50ba6071,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-ad7a5b6b-8f76-445a-a372-6ae2283da50e,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-9a8ff0be-8c49-4e7d-aba2-c68bcb15b203,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-de9b01ff-1577-40f7-8c73-430c23d5f234,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1134476776-172.17.0.17-1597551688019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39762,DS-5e5df282-f223-4c37-b330-ec1bc3cb1351,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-eb73db3f-6924-4564-928b-6694b9c42e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-27f2f3a2-d2c1-4516-8ed6-6d2265476ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-0f4c5851-66e4-43d9-bcd9-84bfd541aaea,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-2d064dff-c755-4b41-82c6-a7cc50ba6071,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-ad7a5b6b-8f76-445a-a372-6ae2283da50e,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-9a8ff0be-8c49-4e7d-aba2-c68bcb15b203,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-de9b01ff-1577-40f7-8c73-430c23d5f234,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5774
