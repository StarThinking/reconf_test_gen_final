reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1738157375-172.17.0.19-1597536056866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33145,DS-751a7955-e99b-49bc-afa9-647f8677d971,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-7543869d-9da6-4388-b770-02b9a21a6d97,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-92909351-4721-41f6-8c22-4ca5107254d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-0535bbc1-e584-44a7-929d-cc986f8d5d92,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-70f4f3d0-c19b-41b3-ba3f-bec4cb677bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-8159de50-ea7e-4715-83bd-764bbcc1f08d,DISK], DatanodeInfoWithStorage[127.0.0.1:43109,DS-c0b171ce-ef08-4f9c-b46f-319104698b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-c5c6dc6c-f18a-4444-9c74-5aed1c62b82c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1738157375-172.17.0.19-1597536056866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33145,DS-751a7955-e99b-49bc-afa9-647f8677d971,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-7543869d-9da6-4388-b770-02b9a21a6d97,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-92909351-4721-41f6-8c22-4ca5107254d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-0535bbc1-e584-44a7-929d-cc986f8d5d92,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-70f4f3d0-c19b-41b3-ba3f-bec4cb677bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-8159de50-ea7e-4715-83bd-764bbcc1f08d,DISK], DatanodeInfoWithStorage[127.0.0.1:43109,DS-c0b171ce-ef08-4f9c-b46f-319104698b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-c5c6dc6c-f18a-4444-9c74-5aed1c62b82c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-236390769-172.17.0.19-1597536239566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39761,DS-9d0ad8fe-b332-44b1-9b7a-813653bc0a17,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-471f52b2-45c2-4d5f-af44-f0a4023eab01,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-73527ff4-3f60-4b3f-a924-ecb9101fab15,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-5a7ff6a2-680c-4f32-a740-08d4b58a91d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-2c39a32e-2f06-4980-85f5-61b2840b8904,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-b5250b6c-edb8-4470-8795-9fda39b3a512,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-9705b265-98ce-4753-8010-4c80c82d85ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-adae0e30-8f5b-49f3-94ff-1c50d3f88a1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-236390769-172.17.0.19-1597536239566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39761,DS-9d0ad8fe-b332-44b1-9b7a-813653bc0a17,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-471f52b2-45c2-4d5f-af44-f0a4023eab01,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-73527ff4-3f60-4b3f-a924-ecb9101fab15,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-5a7ff6a2-680c-4f32-a740-08d4b58a91d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-2c39a32e-2f06-4980-85f5-61b2840b8904,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-b5250b6c-edb8-4470-8795-9fda39b3a512,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-9705b265-98ce-4753-8010-4c80c82d85ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-adae0e30-8f5b-49f3-94ff-1c50d3f88a1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1711885250-172.17.0.19-1597536382161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35514,DS-bfea730e-0005-410a-be96-881399932971,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-3140016a-89c1-4661-8503-61d0b8d05086,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-3cc7133b-af50-4c63-a989-a32184be2fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-829bf052-43f9-4745-8368-434287089cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-e250ffc0-bf2b-42e2-b457-d4c0a2701825,DISK], DatanodeInfoWithStorage[127.0.0.1:40077,DS-32a6017d-4e18-4c12-bc63-49cbb0883aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-c1590e02-4840-4a3f-80d9-a570f6c304d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-4abad298-9612-47c8-81f8-3937ac3f52ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1711885250-172.17.0.19-1597536382161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35514,DS-bfea730e-0005-410a-be96-881399932971,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-3140016a-89c1-4661-8503-61d0b8d05086,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-3cc7133b-af50-4c63-a989-a32184be2fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-829bf052-43f9-4745-8368-434287089cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-e250ffc0-bf2b-42e2-b457-d4c0a2701825,DISK], DatanodeInfoWithStorage[127.0.0.1:40077,DS-32a6017d-4e18-4c12-bc63-49cbb0883aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-c1590e02-4840-4a3f-80d9-a570f6c304d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-4abad298-9612-47c8-81f8-3937ac3f52ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1151169258-172.17.0.19-1597536646480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43068,DS-cc5c04e8-1064-43dd-98cc-2cfa7a148570,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-760b8311-a3cc-406c-a2f5-6bdc8c5cfa56,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-3d9779ae-88f7-4a4a-9459-21e17c9902c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-9f0876a2-cc9e-41cb-a48e-aa7eed1182b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-531575ba-454f-44ad-b360-296e85b0207e,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-ede74a0b-986c-4a4f-9ec2-e7c588c74987,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-0b0e12d9-960c-4b08-ad89-d124e61bcc4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-51740657-97c5-49e5-84c8-aacbd31260fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1151169258-172.17.0.19-1597536646480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43068,DS-cc5c04e8-1064-43dd-98cc-2cfa7a148570,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-760b8311-a3cc-406c-a2f5-6bdc8c5cfa56,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-3d9779ae-88f7-4a4a-9459-21e17c9902c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-9f0876a2-cc9e-41cb-a48e-aa7eed1182b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-531575ba-454f-44ad-b360-296e85b0207e,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-ede74a0b-986c-4a4f-9ec2-e7c588c74987,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-0b0e12d9-960c-4b08-ad89-d124e61bcc4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-51740657-97c5-49e5-84c8-aacbd31260fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1768894935-172.17.0.19-1597536682226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41775,DS-fb3d6cdd-b919-4e11-a8a8-81a9ed83b63c,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-da66a264-fe4d-434d-9224-0ae929d30c84,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-a1516e2e-d82c-4c17-8e1b-08f45b45e723,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-dfd5f369-d0a9-4017-9ae2-10594483800c,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-4735f214-719b-472e-a409-439cc6b0b128,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-6af0b255-6e25-41ab-af4b-71f450d1b3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-634224ad-2ee6-47bf-9df9-437eca73a900,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-e1e86996-3784-4197-b0f0-d78e2f74d55c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1768894935-172.17.0.19-1597536682226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41775,DS-fb3d6cdd-b919-4e11-a8a8-81a9ed83b63c,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-da66a264-fe4d-434d-9224-0ae929d30c84,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-a1516e2e-d82c-4c17-8e1b-08f45b45e723,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-dfd5f369-d0a9-4017-9ae2-10594483800c,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-4735f214-719b-472e-a409-439cc6b0b128,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-6af0b255-6e25-41ab-af4b-71f450d1b3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-634224ad-2ee6-47bf-9df9-437eca73a900,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-e1e86996-3784-4197-b0f0-d78e2f74d55c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1148221047-172.17.0.19-1597536798679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37271,DS-f9e2470e-72c4-48e8-951f-5b79a630906f,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-71c520f3-4dec-499c-b899-1b922a0a58f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-48e1606d-fcaf-4b65-9efb-a06079ea3606,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-e06ca462-5e42-4054-adb3-e3b4b09baebc,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-8b83db36-0c07-43c8-b614-79b3a48b62a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-cf5c2289-7a5e-4bf5-a52f-853edcaa2023,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-dbcd03f9-f8fc-4ca7-806d-ded7daa96441,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-b2fbf8ad-6876-4abc-badf-34096f1bd1fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1148221047-172.17.0.19-1597536798679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37271,DS-f9e2470e-72c4-48e8-951f-5b79a630906f,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-71c520f3-4dec-499c-b899-1b922a0a58f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-48e1606d-fcaf-4b65-9efb-a06079ea3606,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-e06ca462-5e42-4054-adb3-e3b4b09baebc,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-8b83db36-0c07-43c8-b614-79b3a48b62a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-cf5c2289-7a5e-4bf5-a52f-853edcaa2023,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-dbcd03f9-f8fc-4ca7-806d-ded7daa96441,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-b2fbf8ad-6876-4abc-badf-34096f1bd1fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-198052014-172.17.0.19-1597537783682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44830,DS-db6f2bbc-da5f-4285-b4be-7780be2cb6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-d568b05a-a1d1-4f73-8185-9edda4a9adc8,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-006bba62-25e2-4146-8325-a85e52829ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-509fe126-511d-4b74-9026-ef407a0a1a60,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-f915b523-77f1-482a-afab-364c723f64f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-498da7c5-d232-4949-b88d-c6644187ebea,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-2e5662f0-f71a-4776-b718-9e00fe43ccd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-6fbc6021-a140-47c1-8d8d-519a5c37269f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-198052014-172.17.0.19-1597537783682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44830,DS-db6f2bbc-da5f-4285-b4be-7780be2cb6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-d568b05a-a1d1-4f73-8185-9edda4a9adc8,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-006bba62-25e2-4146-8325-a85e52829ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-509fe126-511d-4b74-9026-ef407a0a1a60,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-f915b523-77f1-482a-afab-364c723f64f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-498da7c5-d232-4949-b88d-c6644187ebea,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-2e5662f0-f71a-4776-b718-9e00fe43ccd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-6fbc6021-a140-47c1-8d8d-519a5c37269f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361503696-172.17.0.19-1597537854390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43064,DS-c1258033-4399-4f54-afc3-c80cfd5f4906,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-7877f9db-ba92-4bed-ab32-0ae0b599a107,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-6b417ebb-48d3-4f65-b00e-23154c279d20,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-ff07bf7c-fb67-4501-81e3-b65c16106083,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-fcee9708-3bf5-4133-a5fb-9a9667ce2234,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-6f0d5544-3f90-499c-aac0-208ec97613b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-b6ee6605-f849-437f-adbd-cf49f205d243,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-6fc11876-10dc-4e5d-8b5b-19a0fa68fb67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361503696-172.17.0.19-1597537854390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43064,DS-c1258033-4399-4f54-afc3-c80cfd5f4906,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-7877f9db-ba92-4bed-ab32-0ae0b599a107,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-6b417ebb-48d3-4f65-b00e-23154c279d20,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-ff07bf7c-fb67-4501-81e3-b65c16106083,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-fcee9708-3bf5-4133-a5fb-9a9667ce2234,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-6f0d5544-3f90-499c-aac0-208ec97613b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-b6ee6605-f849-437f-adbd-cf49f205d243,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-6fc11876-10dc-4e5d-8b5b-19a0fa68fb67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-882126413-172.17.0.19-1597538124570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38723,DS-479ce2b4-4d64-4f4c-9b19-154846239bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-a8cab18b-f039-4de2-a843-8ade3e2812cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-14177596-3780-444f-ab2a-3217e38b506e,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-bf9e79fa-e373-4092-a369-4d0e88aae4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-f102b8c5-a540-4e06-9c5b-d1e2d5bf562c,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-27767606-290f-4dc4-ac03-c4ae5e324e12,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-191ea149-e312-4f1d-a4ac-9ad82b810d54,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-ee2fae21-965d-444c-823e-d6e03619a915,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-882126413-172.17.0.19-1597538124570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38723,DS-479ce2b4-4d64-4f4c-9b19-154846239bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-a8cab18b-f039-4de2-a843-8ade3e2812cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-14177596-3780-444f-ab2a-3217e38b506e,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-bf9e79fa-e373-4092-a369-4d0e88aae4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-f102b8c5-a540-4e06-9c5b-d1e2d5bf562c,DISK], DatanodeInfoWithStorage[127.0.0.1:38375,DS-27767606-290f-4dc4-ac03-c4ae5e324e12,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-191ea149-e312-4f1d-a4ac-9ad82b810d54,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-ee2fae21-965d-444c-823e-d6e03619a915,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1160130976-172.17.0.19-1597538165595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41339,DS-2bc30807-9a09-4f01-a671-9098e843a600,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-2b7b11c1-3e6d-47ee-9e3d-75df05d8148d,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-be267caa-89e7-4767-be81-dc512fb25514,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-7fdacdda-52d4-4a18-8ee1-e7361af939c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-f091e040-bd72-4d00-9be6-4732e02d215b,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-acfdf18c-c837-4f77-bb83-4189641c79bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-de5d6eba-eb20-43bd-a930-add932294e06,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-5c161d90-b8c6-4ad2-8399-fa9158cbff9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1160130976-172.17.0.19-1597538165595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41339,DS-2bc30807-9a09-4f01-a671-9098e843a600,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-2b7b11c1-3e6d-47ee-9e3d-75df05d8148d,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-be267caa-89e7-4767-be81-dc512fb25514,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-7fdacdda-52d4-4a18-8ee1-e7361af939c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-f091e040-bd72-4d00-9be6-4732e02d215b,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-acfdf18c-c837-4f77-bb83-4189641c79bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-de5d6eba-eb20-43bd-a930-add932294e06,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-5c161d90-b8c6-4ad2-8399-fa9158cbff9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2009763382-172.17.0.19-1597538199645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36784,DS-09b4f4ae-4de2-446f-91fa-3fe626304bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-05cd2bca-c88b-429a-aa0a-393f4d0a7067,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-55c61307-6648-43d1-9f44-1680fa1b8449,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-a63ba21d-6c6b-4264-8db1-8ab04fdc0586,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-0edc9854-dca1-481c-90d0-ca34038354b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-6ea4be33-311f-40f0-a95d-c6a709585fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-856ce873-23bb-4986-b236-1e75a4a945a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-d7b93df6-c32d-44a3-b453-88be28565cec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2009763382-172.17.0.19-1597538199645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36784,DS-09b4f4ae-4de2-446f-91fa-3fe626304bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-05cd2bca-c88b-429a-aa0a-393f4d0a7067,DISK], DatanodeInfoWithStorage[127.0.0.1:38427,DS-55c61307-6648-43d1-9f44-1680fa1b8449,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-a63ba21d-6c6b-4264-8db1-8ab04fdc0586,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-0edc9854-dca1-481c-90d0-ca34038354b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-6ea4be33-311f-40f0-a95d-c6a709585fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-856ce873-23bb-4986-b236-1e75a4a945a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-d7b93df6-c32d-44a3-b453-88be28565cec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851197745-172.17.0.19-1597539008529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43558,DS-f820c9b5-cb7b-438c-9b56-2ecbe907673c,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-30b24c9e-46e9-4061-a120-a9a1fb4a9d71,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-fea9a3c7-ef95-4646-90b9-c57f8c4e0939,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-9b6251f5-e879-4343-b50a-3ad89fe4da5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-ffc4c69b-415f-422b-98bd-61b438975b19,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-62791afd-7532-49b1-873d-dd52b9551fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-4d6b08c4-803e-4b73-9b0a-22f0ad4334eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-def2eef4-34f5-42fd-8025-e4e3f9c2db09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851197745-172.17.0.19-1597539008529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43558,DS-f820c9b5-cb7b-438c-9b56-2ecbe907673c,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-30b24c9e-46e9-4061-a120-a9a1fb4a9d71,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-fea9a3c7-ef95-4646-90b9-c57f8c4e0939,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-9b6251f5-e879-4343-b50a-3ad89fe4da5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-ffc4c69b-415f-422b-98bd-61b438975b19,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-62791afd-7532-49b1-873d-dd52b9551fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-4d6b08c4-803e-4b73-9b0a-22f0ad4334eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-def2eef4-34f5-42fd-8025-e4e3f9c2db09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1536545954-172.17.0.19-1597539044159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42883,DS-d794f412-f7c0-4027-9b75-d0821403a90b,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-6f0eff09-5d15-4bd4-8a5a-c9bad8e2bd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-8d7c2998-8f48-43e1-835a-3d2ea1c99b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-d101f31c-c2d2-4283-9c60-969beb0a50f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-4af0122e-9921-42b6-80a4-d321301ddc63,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-cce1b1b1-f4cc-4a1e-a28b-236ca71ce57d,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-c6cc61bc-f796-4b1e-bbfc-075d15cfe3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-c2dc6cf8-6c91-4c30-996d-c224eb9ab987,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1536545954-172.17.0.19-1597539044159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42883,DS-d794f412-f7c0-4027-9b75-d0821403a90b,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-6f0eff09-5d15-4bd4-8a5a-c9bad8e2bd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-8d7c2998-8f48-43e1-835a-3d2ea1c99b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-d101f31c-c2d2-4283-9c60-969beb0a50f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-4af0122e-9921-42b6-80a4-d321301ddc63,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-cce1b1b1-f4cc-4a1e-a28b-236ca71ce57d,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-c6cc61bc-f796-4b1e-bbfc-075d15cfe3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-c2dc6cf8-6c91-4c30-996d-c224eb9ab987,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-43729427-172.17.0.19-1597539085406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37721,DS-2c8d192e-1e97-4074-b193-1c4dd394fbac,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-d2627233-0278-4d32-aef0-ab4d0578a658,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-127a7d7a-5471-4207-ae53-d59b69091d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-5f429165-468a-4b68-a7af-6dadd05ec55a,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-abe16782-1720-4870-8520-3765b8048b55,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-9c8e6c5b-5663-4e3d-b1c8-de60f855ac03,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-57f3e1ca-8d86-4fea-ac6f-d16b2da3df6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-083099b0-02c4-46d6-b384-da13159b8fe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-43729427-172.17.0.19-1597539085406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37721,DS-2c8d192e-1e97-4074-b193-1c4dd394fbac,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-d2627233-0278-4d32-aef0-ab4d0578a658,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-127a7d7a-5471-4207-ae53-d59b69091d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-5f429165-468a-4b68-a7af-6dadd05ec55a,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-abe16782-1720-4870-8520-3765b8048b55,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-9c8e6c5b-5663-4e3d-b1c8-de60f855ac03,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-57f3e1ca-8d86-4fea-ac6f-d16b2da3df6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-083099b0-02c4-46d6-b384-da13159b8fe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1924461701-172.17.0.19-1597539126289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42962,DS-abb4a2f0-1050-47b2-b9bf-2909ca121dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-5b786ae3-d413-443a-af5e-09dd01204499,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-1b94c236-3762-443c-bf15-27c399767d84,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-9170fada-55ae-462d-b894-d297d6c987e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-c230f99b-8401-49c8-bcf3-63f7ceab25cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-9e2101ad-0fb8-4315-82cd-b69befa75bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-32107d9d-c638-4933-a001-79a4ec3ab4be,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-ab57c1b2-3e9d-4673-9d44-1fe02e686439,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1924461701-172.17.0.19-1597539126289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42962,DS-abb4a2f0-1050-47b2-b9bf-2909ca121dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-5b786ae3-d413-443a-af5e-09dd01204499,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-1b94c236-3762-443c-bf15-27c399767d84,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-9170fada-55ae-462d-b894-d297d6c987e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-c230f99b-8401-49c8-bcf3-63f7ceab25cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-9e2101ad-0fb8-4315-82cd-b69befa75bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:42465,DS-32107d9d-c638-4933-a001-79a4ec3ab4be,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-ab57c1b2-3e9d-4673-9d44-1fe02e686439,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887658725-172.17.0.19-1597539709575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36859,DS-60c407c1-6707-4e6b-af43-8620574251f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-91e5e988-8ce7-418d-b13a-031d17ada606,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-dd784cd2-2c2c-419a-b169-f21990cdaf81,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-1e272e39-027e-431c-9302-a4345bad87c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-187f75c4-7621-4d41-9269-a74c93602e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-0723195e-3b24-4bb8-9d1b-444066d9c1af,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-9cd5acb7-6a68-4ac7-a145-4aa908718127,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-985cca40-910a-4dcd-ba15-97a17a0a7f5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887658725-172.17.0.19-1597539709575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36859,DS-60c407c1-6707-4e6b-af43-8620574251f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-91e5e988-8ce7-418d-b13a-031d17ada606,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-dd784cd2-2c2c-419a-b169-f21990cdaf81,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-1e272e39-027e-431c-9302-a4345bad87c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-187f75c4-7621-4d41-9269-a74c93602e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-0723195e-3b24-4bb8-9d1b-444066d9c1af,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-9cd5acb7-6a68-4ac7-a145-4aa908718127,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-985cca40-910a-4dcd-ba15-97a17a0a7f5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-982586190-172.17.0.19-1597539938042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46188,DS-b005b5ba-acbc-4728-8e08-c0329f706185,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-5a3afc5f-8739-468f-90be-d506f7d3b19c,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-290f8cd6-64c2-4ba1-bc16-a08fa4f20749,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-487afeb3-45d2-40cc-b3bc-ecdb5afb9b06,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-09cc54f9-b146-4bea-9e99-1e7e795ea957,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-05d5798d-451f-4a31-a848-e5d44e187036,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-71742ecc-41ef-45ea-a16f-50ad62a5ccb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-f2aeb94e-317c-4318-b6e2-39fc8440862d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-982586190-172.17.0.19-1597539938042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46188,DS-b005b5ba-acbc-4728-8e08-c0329f706185,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-5a3afc5f-8739-468f-90be-d506f7d3b19c,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-290f8cd6-64c2-4ba1-bc16-a08fa4f20749,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-487afeb3-45d2-40cc-b3bc-ecdb5afb9b06,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-09cc54f9-b146-4bea-9e99-1e7e795ea957,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-05d5798d-451f-4a31-a848-e5d44e187036,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-71742ecc-41ef-45ea-a16f-50ad62a5ccb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-f2aeb94e-317c-4318-b6e2-39fc8440862d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846017740-172.17.0.19-1597540638206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36837,DS-d6fce4b4-a45a-4862-9120-795a6ed3e7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-81da84d0-92f9-4581-8806-bce4a97f592a,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-54c059df-daef-412c-ba9c-3073cd6cfb43,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-c6ffa1fa-e9e4-4ac7-8f64-66edf4725084,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-5518092d-72fa-45cb-b858-aea8fb18cb45,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-d2a97e4e-7773-4644-aa5e-3636e1b485c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-23af4532-94fa-4316-850d-586300f7a2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-83992821-c1cc-49fa-98b8-0e8a9edef80a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846017740-172.17.0.19-1597540638206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36837,DS-d6fce4b4-a45a-4862-9120-795a6ed3e7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-81da84d0-92f9-4581-8806-bce4a97f592a,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-54c059df-daef-412c-ba9c-3073cd6cfb43,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-c6ffa1fa-e9e4-4ac7-8f64-66edf4725084,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-5518092d-72fa-45cb-b858-aea8fb18cb45,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-d2a97e4e-7773-4644-aa5e-3636e1b485c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-23af4532-94fa-4316-850d-586300f7a2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-83992821-c1cc-49fa-98b8-0e8a9edef80a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.kerberos.min.seconds.before.relogin
component: hdfs:NameNode
v1: 6000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525141222-172.17.0.19-1597540720582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45762,DS-47979399-2749-4463-a53d-6d65b239f606,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-c63f8bd5-561f-4090-9308-cf0fca4b4119,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-9823c569-79f9-4bdd-9d3d-ae851ca68897,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-e4c3519c-a71d-423c-a736-461fc66f08af,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-e81ca996-cfc9-4cca-8b1c-aa8a60264c00,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-becbd2a2-ab22-4821-a398-5d5e23dd8ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-d651d22f-b7d6-42bc-a586-fe2b382ee9da,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-cea85cab-bc9a-428f-98f3-3f4653f774e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525141222-172.17.0.19-1597540720582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45762,DS-47979399-2749-4463-a53d-6d65b239f606,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-c63f8bd5-561f-4090-9308-cf0fca4b4119,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-9823c569-79f9-4bdd-9d3d-ae851ca68897,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-e4c3519c-a71d-423c-a736-461fc66f08af,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-e81ca996-cfc9-4cca-8b1c-aa8a60264c00,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-becbd2a2-ab22-4821-a398-5d5e23dd8ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-d651d22f-b7d6-42bc-a586-fe2b382ee9da,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-cea85cab-bc9a-428f-98f3-3f4653f774e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5707
