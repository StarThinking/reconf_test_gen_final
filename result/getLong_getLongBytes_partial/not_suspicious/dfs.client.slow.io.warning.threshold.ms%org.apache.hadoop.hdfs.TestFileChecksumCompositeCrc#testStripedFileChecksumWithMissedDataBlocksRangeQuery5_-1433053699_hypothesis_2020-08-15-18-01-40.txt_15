reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 40000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 40000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981357162-172.17.0.18-1597514512574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33248,DS-1ca81c8e-f6ee-474d-9556-9697f38d3a53,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-e512897d-602f-420f-8f78-9edf8fb40de1,DISK], DatanodeInfoWithStorage[127.0.0.1:34841,DS-4380f230-61f6-4b54-b746-c3197f8cf15b,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-393c06c0-b723-4b2e-b544-ad3b7d44bb08,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-7758c96f-975b-475d-96ec-580421107062,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-aaf82979-508b-499a-981a-edd24d24d44d,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-180c2a4b-0f0c-4730-a8ce-49cc54413b48,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-718d20b7-dd1f-464d-941d-c529c9531230,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981357162-172.17.0.18-1597514512574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33248,DS-1ca81c8e-f6ee-474d-9556-9697f38d3a53,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-e512897d-602f-420f-8f78-9edf8fb40de1,DISK], DatanodeInfoWithStorage[127.0.0.1:34841,DS-4380f230-61f6-4b54-b746-c3197f8cf15b,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-393c06c0-b723-4b2e-b544-ad3b7d44bb08,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-7758c96f-975b-475d-96ec-580421107062,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-aaf82979-508b-499a-981a-edd24d24d44d,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-180c2a4b-0f0c-4730-a8ce-49cc54413b48,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-718d20b7-dd1f-464d-941d-c529c9531230,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 40000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-843037767-172.17.0.18-1597515178262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39363,DS-3f8fdaa1-5380-4e7b-943b-dc732b725865,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-c6822c2a-fb71-4963-a9c8-57ad353e2295,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-8cbdacb4-8cb6-4b43-a567-fcd9a517587f,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-537cc5ce-729c-4a98-904b-ffe3e9e7b939,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-995a7384-8bb2-4189-92fe-4a098e76aff5,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-c57af52e-e684-43d1-acfb-12612afe5beb,DISK], DatanodeInfoWithStorage[127.0.0.1:34687,DS-a41dee0a-d2fe-44c1-8b72-49d3ea7df8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-6c171552-f884-4173-8502-ed2829eb6bc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-843037767-172.17.0.18-1597515178262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39363,DS-3f8fdaa1-5380-4e7b-943b-dc732b725865,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-c6822c2a-fb71-4963-a9c8-57ad353e2295,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-8cbdacb4-8cb6-4b43-a567-fcd9a517587f,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-537cc5ce-729c-4a98-904b-ffe3e9e7b939,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-995a7384-8bb2-4189-92fe-4a098e76aff5,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-c57af52e-e684-43d1-acfb-12612afe5beb,DISK], DatanodeInfoWithStorage[127.0.0.1:34687,DS-a41dee0a-d2fe-44c1-8b72-49d3ea7df8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-6c171552-f884-4173-8502-ed2829eb6bc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 40000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-314470403-172.17.0.18-1597515213649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45036,DS-5e5eeda8-ac25-4d6f-bff3-b4f36365ab14,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-732fc28b-ee94-435e-a583-4db1914a9b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-4790be5e-0c40-4d9e-a274-4fe1fdab2692,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-53e24853-274e-453a-85d1-de9f2f3c89f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-aad1cfbc-e71e-4915-9f22-d1bd961e78f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-3229a489-7cfb-4415-87c7-16d9df236e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-d846432a-e545-46c5-867a-33277e9ab17c,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-d02a1dcb-eda0-4911-91c1-39e314f4dda7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-314470403-172.17.0.18-1597515213649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45036,DS-5e5eeda8-ac25-4d6f-bff3-b4f36365ab14,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-732fc28b-ee94-435e-a583-4db1914a9b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-4790be5e-0c40-4d9e-a274-4fe1fdab2692,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-53e24853-274e-453a-85d1-de9f2f3c89f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-aad1cfbc-e71e-4915-9f22-d1bd961e78f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-3229a489-7cfb-4415-87c7-16d9df236e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-d846432a-e545-46c5-867a-33277e9ab17c,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-d02a1dcb-eda0-4911-91c1-39e314f4dda7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 40000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-478879185-172.17.0.18-1597515432399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41489,DS-284c36b5-4841-4eb9-80ea-9c8b5addb2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-a61b44ec-7a01-4c84-a9e6-c33c0a23b5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-e93e8db2-ed0a-4e33-a725-9fa67026e857,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-8586caa1-0a4d-4b49-a6e3-1795d7ee47e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-712e2837-ecf8-4e0e-8c53-58ca66ca48b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-bc92f100-34bc-400b-90c0-7c61fde8e887,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-437619b4-ec28-4268-8e2b-ebcabbbb5b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-51f962ad-d63b-4e92-a571-4385c479b6fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-478879185-172.17.0.18-1597515432399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41489,DS-284c36b5-4841-4eb9-80ea-9c8b5addb2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-a61b44ec-7a01-4c84-a9e6-c33c0a23b5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-e93e8db2-ed0a-4e33-a725-9fa67026e857,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-8586caa1-0a4d-4b49-a6e3-1795d7ee47e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-712e2837-ecf8-4e0e-8c53-58ca66ca48b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-bc92f100-34bc-400b-90c0-7c61fde8e887,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-437619b4-ec28-4268-8e2b-ebcabbbb5b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-51f962ad-d63b-4e92-a571-4385c479b6fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 40000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1573443676-172.17.0.18-1597515609369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33719,DS-34676aed-89ae-44f3-b801-bb0b2727cd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35916,DS-a93125de-fa55-41d1-936b-dc586f9af5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-a27dffad-52e6-47fb-9049-3408944497cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40909,DS-2a527adb-464a-4a72-8d63-5319d7cfcd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-57065696-3ba5-4db2-8a99-2ca390c8e93c,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-4f6ee3f4-7176-4eab-925c-42748df7f030,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-ff2b1b8f-a312-4293-9fb3-4ed87d6ec692,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-39beca0b-c23d-4bae-8697-e08697d25e26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1573443676-172.17.0.18-1597515609369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33719,DS-34676aed-89ae-44f3-b801-bb0b2727cd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35916,DS-a93125de-fa55-41d1-936b-dc586f9af5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-a27dffad-52e6-47fb-9049-3408944497cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40909,DS-2a527adb-464a-4a72-8d63-5319d7cfcd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-57065696-3ba5-4db2-8a99-2ca390c8e93c,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-4f6ee3f4-7176-4eab-925c-42748df7f030,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-ff2b1b8f-a312-4293-9fb3-4ed87d6ec692,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-39beca0b-c23d-4bae-8697-e08697d25e26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 40000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86943063-172.17.0.18-1597515645972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41015,DS-4c660d10-868a-4d13-bac0-6439fcfdfe67,DISK], DatanodeInfoWithStorage[127.0.0.1:43885,DS-ba275e7c-f16a-4583-a9bc-89241f00451f,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-d05cf78e-55cc-4185-b987-269c658c527f,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-64da86d6-49e1-4c1a-ad86-63991ad32878,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-280ed1a4-00db-4c3c-98c4-b469338b6aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-f4b51aa9-167a-4910-ae06-5ed8f6c77e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-4c2b7c1a-309a-45a6-a9fe-7dba1bd24d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-d79dd531-104a-479f-9c9c-8234807626ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86943063-172.17.0.18-1597515645972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41015,DS-4c660d10-868a-4d13-bac0-6439fcfdfe67,DISK], DatanodeInfoWithStorage[127.0.0.1:43885,DS-ba275e7c-f16a-4583-a9bc-89241f00451f,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-d05cf78e-55cc-4185-b987-269c658c527f,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-64da86d6-49e1-4c1a-ad86-63991ad32878,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-280ed1a4-00db-4c3c-98c4-b469338b6aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-f4b51aa9-167a-4910-ae06-5ed8f6c77e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-4c2b7c1a-309a-45a6-a9fe-7dba1bd24d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-d79dd531-104a-479f-9c9c-8234807626ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 40000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1554626520-172.17.0.18-1597515825260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40226,DS-1b7cfd8a-538a-42e6-b491-b9e2e66488c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-4b3926af-d086-41d5-b934-7916ab9828f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-4744a79c-c463-43d6-aa20-f2c34b57e6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-ad64a8d2-fb9f-471d-935a-92df08ddf916,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-a28932f5-eb73-4c56-89f6-f399d92e80fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-d70d9b24-17dd-4171-8734-23b58448b38c,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-46ed3ea7-0ac0-4df4-8827-d8d722d257d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-b0f37f15-c70a-4faa-a81a-959db5e7b65d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1554626520-172.17.0.18-1597515825260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40226,DS-1b7cfd8a-538a-42e6-b491-b9e2e66488c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-4b3926af-d086-41d5-b934-7916ab9828f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-4744a79c-c463-43d6-aa20-f2c34b57e6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-ad64a8d2-fb9f-471d-935a-92df08ddf916,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-a28932f5-eb73-4c56-89f6-f399d92e80fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-d70d9b24-17dd-4171-8734-23b58448b38c,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-46ed3ea7-0ac0-4df4-8827-d8d722d257d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-b0f37f15-c70a-4faa-a81a-959db5e7b65d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 40000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-831258422-172.17.0.18-1597515974603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42612,DS-9324b129-1b67-469e-9334-00356fe9db1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-3a91fabb-6abd-428a-b2ad-03fb9fe7a9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-dacb91ee-97d2-42ae-b58c-4d468f97b871,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-c8aa6ffd-6d2c-4aaa-91a0-cccc8d2be683,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-e6d4d83c-9c4c-42a9-b305-a7d5e0199df0,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-fd07af54-9853-445d-b2da-21ed4cba9132,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-c1c097fa-af67-4e37-9534-a683b5a2e374,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-095b6835-0c85-474f-b221-03a5f006cf29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-831258422-172.17.0.18-1597515974603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42612,DS-9324b129-1b67-469e-9334-00356fe9db1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-3a91fabb-6abd-428a-b2ad-03fb9fe7a9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-dacb91ee-97d2-42ae-b58c-4d468f97b871,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-c8aa6ffd-6d2c-4aaa-91a0-cccc8d2be683,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-e6d4d83c-9c4c-42a9-b305-a7d5e0199df0,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-fd07af54-9853-445d-b2da-21ed4cba9132,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-c1c097fa-af67-4e37-9534-a683b5a2e374,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-095b6835-0c85-474f-b221-03a5f006cf29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 40000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-311686779-172.17.0.18-1597516745230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34964,DS-084339bc-15fc-4e9d-b3d1-9e87376bfbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-8a8b4003-1b82-4bad-a704-38355bd419c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-ca36fe4a-48ac-43b0-a9e9-6de9ee1fa861,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-4e850fe6-28b5-4310-81af-664df74b2225,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-26d60825-8bb8-4dff-865c-b88c715c8501,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-b91adef5-bd11-4dd3-825d-a264e8c65f72,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-864a8836-5943-4693-b51d-7f1c679a6631,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-d019c8c6-6f6a-46bd-83ee-60ce367d8a0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-311686779-172.17.0.18-1597516745230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34964,DS-084339bc-15fc-4e9d-b3d1-9e87376bfbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-8a8b4003-1b82-4bad-a704-38355bd419c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-ca36fe4a-48ac-43b0-a9e9-6de9ee1fa861,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-4e850fe6-28b5-4310-81af-664df74b2225,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-26d60825-8bb8-4dff-865c-b88c715c8501,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-b91adef5-bd11-4dd3-825d-a264e8c65f72,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-864a8836-5943-4693-b51d-7f1c679a6631,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-d019c8c6-6f6a-46bd-83ee-60ce367d8a0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 40000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960382232-172.17.0.18-1597517209753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42211,DS-8ae69574-ab30-4d5c-96a3-561a264c8c47,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-55cee008-8286-4ada-b649-d5f7ad42d844,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-0be1dfe4-a669-4421-b785-1c5042fe18a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-13c81b21-d4b5-4db7-acf9-1d0a84b83ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-cbed81f8-f78b-4e83-9f35-109986941472,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-4d756360-fce8-42dd-bf53-8266b2fea215,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-8362cbab-a2ef-465a-b853-9455443f7167,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-43600201-4b9e-4bde-b758-d99dde61abdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960382232-172.17.0.18-1597517209753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42211,DS-8ae69574-ab30-4d5c-96a3-561a264c8c47,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-55cee008-8286-4ada-b649-d5f7ad42d844,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-0be1dfe4-a669-4421-b785-1c5042fe18a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-13c81b21-d4b5-4db7-acf9-1d0a84b83ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-cbed81f8-f78b-4e83-9f35-109986941472,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-4d756360-fce8-42dd-bf53-8266b2fea215,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-8362cbab-a2ef-465a-b853-9455443f7167,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-43600201-4b9e-4bde-b758-d99dde61abdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 40000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1679336464-172.17.0.18-1597517276221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42682,DS-c1ed5018-c1a0-40ad-9ca5-976c6ddd2985,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-a3fd6542-09de-4c6c-969e-d419f2951a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-e20534de-a4c7-4ff6-b571-8574ac70704b,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-f0219e94-adb8-4387-8a36-ca4aab10d2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-e557a2f3-3d18-41ab-9658-3bdf312d5ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-f2f18928-a19b-4d2a-9597-0a1117edd09f,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-ec19dfad-e98c-41b0-8184-3e16466cd7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-4c9bfe6c-263a-49a9-ab05-0824711f1807,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1679336464-172.17.0.18-1597517276221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42682,DS-c1ed5018-c1a0-40ad-9ca5-976c6ddd2985,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-a3fd6542-09de-4c6c-969e-d419f2951a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-e20534de-a4c7-4ff6-b571-8574ac70704b,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-f0219e94-adb8-4387-8a36-ca4aab10d2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-e557a2f3-3d18-41ab-9658-3bdf312d5ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-f2f18928-a19b-4d2a-9597-0a1117edd09f,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-ec19dfad-e98c-41b0-8184-3e16466cd7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-4c9bfe6c-263a-49a9-ab05-0824711f1807,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 40000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-747266428-172.17.0.18-1597517526540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37046,DS-6649bc32-40ea-4f39-a4e1-e8762682c992,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-63a77297-b570-4fc0-bd92-9b6d016fe2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-90b4b469-cb9d-459c-bbec-dc30ef884453,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-250ad17d-9875-49ad-8e3c-73f639cc78bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-1e43303e-fa16-4d09-b3f8-c829ae0ad471,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-0d21775a-16fe-4871-8a20-19c6117d1db2,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-73070c5d-4a91-4973-aff1-feb207488893,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-90e0c3c6-71b8-438c-a2f9-7dce16f537b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-747266428-172.17.0.18-1597517526540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37046,DS-6649bc32-40ea-4f39-a4e1-e8762682c992,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-63a77297-b570-4fc0-bd92-9b6d016fe2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-90b4b469-cb9d-459c-bbec-dc30ef884453,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-250ad17d-9875-49ad-8e3c-73f639cc78bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-1e43303e-fa16-4d09-b3f8-c829ae0ad471,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-0d21775a-16fe-4871-8a20-19c6117d1db2,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-73070c5d-4a91-4973-aff1-feb207488893,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-90e0c3c6-71b8-438c-a2f9-7dce16f537b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 40000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-776552243-172.17.0.18-1597517682619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45638,DS-0a659c87-c9f1-400b-a670-9f420a0aa724,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-895cea2b-9f56-4647-b1d4-f6c3ae6cf65f,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-e9bebd24-9ede-45e9-bba6-bb30b6eb089e,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-f26b93a8-3522-4d02-bd8e-f13059fe5a42,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-4e75fe1f-2183-4458-8f92-8c2bba716541,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-68b53c06-1efd-4993-80ad-29efb8605728,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-4ce15132-9bc7-48f8-8340-96e551206437,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-ed56211f-0907-4c7f-86a7-6616c33098ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-776552243-172.17.0.18-1597517682619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45638,DS-0a659c87-c9f1-400b-a670-9f420a0aa724,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-895cea2b-9f56-4647-b1d4-f6c3ae6cf65f,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-e9bebd24-9ede-45e9-bba6-bb30b6eb089e,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-f26b93a8-3522-4d02-bd8e-f13059fe5a42,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-4e75fe1f-2183-4458-8f92-8c2bba716541,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-68b53c06-1efd-4993-80ad-29efb8605728,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-4ce15132-9bc7-48f8-8340-96e551206437,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-ed56211f-0907-4c7f-86a7-6616c33098ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.slow.io.warning.threshold.ms
component: hdfs:NameNode
v1: 40000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563828531-172.17.0.18-1597518364092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35520,DS-4c6cabba-9f2f-42f7-b080-596df4d51924,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-98809889-0efc-48e4-9ac9-1815c517b7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-6a58f900-6580-4315-852e-8a153d99b0db,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-ea761566-e32c-452a-aadd-cb23436c97a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-7d5eac12-fcaa-4d41-9650-752cacfc2a89,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-11fd821b-8f32-41b7-a64e-46e7ecabbbff,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-dce79ca2-a0ec-445f-815f-386cbddde3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-9de44474-e1e3-4e42-a874-815681217c16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563828531-172.17.0.18-1597518364092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35520,DS-4c6cabba-9f2f-42f7-b080-596df4d51924,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-98809889-0efc-48e4-9ac9-1815c517b7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-6a58f900-6580-4315-852e-8a153d99b0db,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-ea761566-e32c-452a-aadd-cb23436c97a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-7d5eac12-fcaa-4d41-9650-752cacfc2a89,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-11fd821b-8f32-41b7-a64e-46e7ecabbbff,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-dce79ca2-a0ec-445f-815f-386cbddde3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-9de44474-e1e3-4e42-a874-815681217c16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5313
