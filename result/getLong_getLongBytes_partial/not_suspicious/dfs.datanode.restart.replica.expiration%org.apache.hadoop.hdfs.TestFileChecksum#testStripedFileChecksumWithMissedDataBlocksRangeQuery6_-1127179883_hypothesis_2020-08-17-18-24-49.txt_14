reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933244604-172.17.0.18-1597688855257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32879,DS-f65fe793-e9e4-4fce-9113-6f5c8af4d499,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-e61bf364-2dcf-42d7-8e93-5a8c732483ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-d158bc81-e934-4a48-801c-b11a4e098375,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-7ef4bfd2-90ae-4c25-afea-39f79250d30b,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-82710419-fc12-4bce-8852-a6ad87d87663,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-ba90a102-f2d7-44c9-938d-c9d027257277,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-f0886e9b-6cd2-41fe-93e6-806774ba4efa,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-8a37dd88-85da-490b-aa77-f37628930064,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933244604-172.17.0.18-1597688855257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32879,DS-f65fe793-e9e4-4fce-9113-6f5c8af4d499,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-e61bf364-2dcf-42d7-8e93-5a8c732483ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-d158bc81-e934-4a48-801c-b11a4e098375,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-7ef4bfd2-90ae-4c25-afea-39f79250d30b,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-82710419-fc12-4bce-8852-a6ad87d87663,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-ba90a102-f2d7-44c9-938d-c9d027257277,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-f0886e9b-6cd2-41fe-93e6-806774ba4efa,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-8a37dd88-85da-490b-aa77-f37628930064,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-720770586-172.17.0.18-1597688971291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46237,DS-3ced1911-0348-464f-aafd-ee2f40260046,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-bbd6aab4-c91c-4c44-bb41-52aed952a27b,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-2482e6b4-c7f9-4e1c-92a6-c6154a027935,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-246ac20b-3a5f-4ee6-ab47-f217953fa6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-9191fd31-4c36-4e0f-9089-43b8a8aaed0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-76d1c300-3a4f-44c4-8d5f-9a5e7cf4de5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-b27865cb-4b34-496a-8fb7-e7827834e0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-0c70749a-3b6a-4927-a65b-47dd26171923,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-720770586-172.17.0.18-1597688971291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46237,DS-3ced1911-0348-464f-aafd-ee2f40260046,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-bbd6aab4-c91c-4c44-bb41-52aed952a27b,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-2482e6b4-c7f9-4e1c-92a6-c6154a027935,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-246ac20b-3a5f-4ee6-ab47-f217953fa6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-9191fd31-4c36-4e0f-9089-43b8a8aaed0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-76d1c300-3a4f-44c4-8d5f-9a5e7cf4de5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-b27865cb-4b34-496a-8fb7-e7827834e0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-0c70749a-3b6a-4927-a65b-47dd26171923,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1005904715-172.17.0.18-1597689008514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38349,DS-4eb4bc8d-a0f3-413f-b4f2-e2fcdc917e46,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-fed1c5bc-28be-4126-abf3-1f0e5afac879,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-c63d8bbe-c55c-4744-aa96-95ab3d49c3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-e0985dda-737a-4fce-8655-d63cdd8d7891,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-111281f0-781e-42d8-855f-d7142c2ebeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-321b7d7b-1c42-4b02-b1d7-7316b55fadf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-137c579e-0105-40a9-bd34-51404b107bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-d7600177-ca24-454d-9a05-77afe5d2c509,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1005904715-172.17.0.18-1597689008514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38349,DS-4eb4bc8d-a0f3-413f-b4f2-e2fcdc917e46,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-fed1c5bc-28be-4126-abf3-1f0e5afac879,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-c63d8bbe-c55c-4744-aa96-95ab3d49c3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-e0985dda-737a-4fce-8655-d63cdd8d7891,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-111281f0-781e-42d8-855f-d7142c2ebeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-321b7d7b-1c42-4b02-b1d7-7316b55fadf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-137c579e-0105-40a9-bd34-51404b107bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-d7600177-ca24-454d-9a05-77afe5d2c509,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353700357-172.17.0.18-1597689201388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43979,DS-1b2dffcd-f65c-43f7-8e35-5188e9c72f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-f8220428-078f-4c51-8d29-de365dddd50b,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-f991f307-3668-4b05-8c4f-77e21f4902df,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-0b39bef1-098e-4993-ac44-ba5e9f89d4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-9b7eccfb-16bd-4088-9116-eb99315ff151,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-d93f27c3-00b3-47ee-a5ea-03a7665b5fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-a7840d90-85eb-4069-83b6-cdcff0be1a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-ba59b645-9481-4d26-8431-8714ad0fdaf0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353700357-172.17.0.18-1597689201388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43979,DS-1b2dffcd-f65c-43f7-8e35-5188e9c72f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-f8220428-078f-4c51-8d29-de365dddd50b,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-f991f307-3668-4b05-8c4f-77e21f4902df,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-0b39bef1-098e-4993-ac44-ba5e9f89d4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-9b7eccfb-16bd-4088-9116-eb99315ff151,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-d93f27c3-00b3-47ee-a5ea-03a7665b5fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-a7840d90-85eb-4069-83b6-cdcff0be1a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-ba59b645-9481-4d26-8431-8714ad0fdaf0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1735992436-172.17.0.18-1597689324328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43350,DS-d7e8a825-3d5e-4305-aabe-f51228845871,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-883444b3-64ba-44c8-95e3-bb84443d3b37,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-0227f81b-7992-4ec0-89a1-b4afaab807aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-6ba4ebe1-5314-4822-8fff-5dcd951f38c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-d42706c3-883a-4290-b103-eb5c3102071f,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-d54ee611-a15a-4e25-aee9-760357861fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-42f70c1e-cdda-4ae3-beb6-fde787e31682,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-f058dc60-8a7f-4318-8d23-a6185620e623,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1735992436-172.17.0.18-1597689324328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43350,DS-d7e8a825-3d5e-4305-aabe-f51228845871,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-883444b3-64ba-44c8-95e3-bb84443d3b37,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-0227f81b-7992-4ec0-89a1-b4afaab807aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-6ba4ebe1-5314-4822-8fff-5dcd951f38c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-d42706c3-883a-4290-b103-eb5c3102071f,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-d54ee611-a15a-4e25-aee9-760357861fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-42f70c1e-cdda-4ae3-beb6-fde787e31682,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-f058dc60-8a7f-4318-8d23-a6185620e623,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-738196331-172.17.0.18-1597689360026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43933,DS-8c74aaca-52a9-44f6-8037-ad47340d98c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-022f9d08-bb51-4ad1-a76d-a4cfac02c1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-cc9a0080-2229-42e6-8683-6ff4e71d8940,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-6609fb83-99d8-4723-9f02-ef14301bff33,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-6623d9fe-1981-4f48-b133-fbb6b4473cda,DISK], DatanodeInfoWithStorage[127.0.0.1:43169,DS-483a9195-0905-4048-be9d-787b52ddfb03,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-5e41a056-ce03-4fd4-974e-091c6d11e0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-2deab0e4-9366-4fb3-8408-406377c64599,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-738196331-172.17.0.18-1597689360026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43933,DS-8c74aaca-52a9-44f6-8037-ad47340d98c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-022f9d08-bb51-4ad1-a76d-a4cfac02c1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-cc9a0080-2229-42e6-8683-6ff4e71d8940,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-6609fb83-99d8-4723-9f02-ef14301bff33,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-6623d9fe-1981-4f48-b133-fbb6b4473cda,DISK], DatanodeInfoWithStorage[127.0.0.1:43169,DS-483a9195-0905-4048-be9d-787b52ddfb03,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-5e41a056-ce03-4fd4-974e-091c6d11e0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-2deab0e4-9366-4fb3-8408-406377c64599,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383097413-172.17.0.18-1597689669589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42953,DS-420b3d39-5dc3-4545-a382-098fc0350fed,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-3f9faf3f-76b4-431b-a5ed-77bac2eb8b54,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-9cc6b65f-081e-45dd-bd49-cfa4d6ec3e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-1e84b545-b025-42eb-b292-0f05d690de32,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-cccd7de8-1237-4eba-b461-6a1b8a6c19bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-56fff76c-36d5-4efc-8126-fbc337d4f067,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-c420b6fe-53b5-4d20-b501-e68993276b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-0f7d3f7d-e5a5-409d-b990-fd7fd00d7ca0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383097413-172.17.0.18-1597689669589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42953,DS-420b3d39-5dc3-4545-a382-098fc0350fed,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-3f9faf3f-76b4-431b-a5ed-77bac2eb8b54,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-9cc6b65f-081e-45dd-bd49-cfa4d6ec3e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-1e84b545-b025-42eb-b292-0f05d690de32,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-cccd7de8-1237-4eba-b461-6a1b8a6c19bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-56fff76c-36d5-4efc-8126-fbc337d4f067,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-c420b6fe-53b5-4d20-b501-e68993276b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-0f7d3f7d-e5a5-409d-b990-fd7fd00d7ca0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1038439047-172.17.0.18-1597689937377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45438,DS-7b054dcd-dce6-4fca-b350-983f0da0bb69,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-2a36a688-ea9c-4965-817a-e199bacba3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-8bbc8628-982f-4524-9c98-788d7a109e35,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-e5353b98-c37f-436e-997c-3ed65b2ae209,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-f15a4493-6a87-43d7-b8f4-2b9b39771ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-564feedd-68c7-447e-b3ef-1d1ec085617c,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-2627b011-c51b-4abe-b675-a2f134e7ce33,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-b487c82e-87d5-4086-b35e-bf307684001c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1038439047-172.17.0.18-1597689937377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45438,DS-7b054dcd-dce6-4fca-b350-983f0da0bb69,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-2a36a688-ea9c-4965-817a-e199bacba3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-8bbc8628-982f-4524-9c98-788d7a109e35,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-e5353b98-c37f-436e-997c-3ed65b2ae209,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-f15a4493-6a87-43d7-b8f4-2b9b39771ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-564feedd-68c7-447e-b3ef-1d1ec085617c,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-2627b011-c51b-4abe-b675-a2f134e7ce33,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-b487c82e-87d5-4086-b35e-bf307684001c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-802489637-172.17.0.18-1597690122050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37654,DS-f28597a3-653c-4297-b88f-8ac2816f9510,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-e1d72ed9-712a-4436-bb2b-1413eecff597,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-3bc8f4a2-e964-4343-ac34-5141aaa23ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-91da8f7e-4dcf-4724-b344-661ba4ca8d85,DISK], DatanodeInfoWithStorage[127.0.0.1:44131,DS-9c70f3cf-22aa-48df-b4e5-671f8596a2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-c1e39fd3-8ef6-4aff-a361-d0285704dedf,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-6968b634-7255-45c9-a78d-20e96d7d991c,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-7dd33f78-b3a5-4f3c-ae29-c189c1c963c1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-802489637-172.17.0.18-1597690122050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37654,DS-f28597a3-653c-4297-b88f-8ac2816f9510,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-e1d72ed9-712a-4436-bb2b-1413eecff597,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-3bc8f4a2-e964-4343-ac34-5141aaa23ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-91da8f7e-4dcf-4724-b344-661ba4ca8d85,DISK], DatanodeInfoWithStorage[127.0.0.1:44131,DS-9c70f3cf-22aa-48df-b4e5-671f8596a2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-c1e39fd3-8ef6-4aff-a361-d0285704dedf,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-6968b634-7255-45c9-a78d-20e96d7d991c,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-7dd33f78-b3a5-4f3c-ae29-c189c1c963c1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176797888-172.17.0.18-1597690469982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45733,DS-6f362808-676d-4d3e-b096-78c37247e69b,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-33dd96e4-a4c7-4a14-9e1c-e63f10d33f83,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-8710c939-17a1-419f-96b3-2adca8e63198,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-1a41a46b-06dd-4a37-b23b-885006c1b22b,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-1847a67b-fbf7-4697-8e1b-31acb8cdb3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-18b704e6-ec22-4f73-93f0-724dd7b9fb62,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-6094c0fa-4344-444f-a012-86048a4ffcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-53868417-a094-4e3b-ad65-cd0e7927cd9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176797888-172.17.0.18-1597690469982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45733,DS-6f362808-676d-4d3e-b096-78c37247e69b,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-33dd96e4-a4c7-4a14-9e1c-e63f10d33f83,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-8710c939-17a1-419f-96b3-2adca8e63198,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-1a41a46b-06dd-4a37-b23b-885006c1b22b,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-1847a67b-fbf7-4697-8e1b-31acb8cdb3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-18b704e6-ec22-4f73-93f0-724dd7b9fb62,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-6094c0fa-4344-444f-a012-86048a4ffcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-53868417-a094-4e3b-ad65-cd0e7927cd9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-152938635-172.17.0.18-1597690531065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43707,DS-8046e57b-2471-4af1-9760-58c2f4376ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:35505,DS-cf21dbe8-a284-4704-b8cc-c8025987388a,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-31f795b0-0442-4f16-9af5-c4ca5ee8cfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-ed738b3a-9fd7-4b00-bcc5-5cb54297e40b,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-db8c00f3-d04a-4ee7-8b56-eab8dfe13879,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-f3a1f0d7-9f9d-4e21-a28b-80c9130e6839,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-1092b443-ce0a-4e02-9f2a-5e498676a20e,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-dc05d05c-29d8-4d26-80d4-bd524443da65,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-152938635-172.17.0.18-1597690531065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43707,DS-8046e57b-2471-4af1-9760-58c2f4376ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:35505,DS-cf21dbe8-a284-4704-b8cc-c8025987388a,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-31f795b0-0442-4f16-9af5-c4ca5ee8cfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-ed738b3a-9fd7-4b00-bcc5-5cb54297e40b,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-db8c00f3-d04a-4ee7-8b56-eab8dfe13879,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-f3a1f0d7-9f9d-4e21-a28b-80c9130e6839,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-1092b443-ce0a-4e02-9f2a-5e498676a20e,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-dc05d05c-29d8-4d26-80d4-bd524443da65,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638203447-172.17.0.18-1597690573464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39681,DS-c67f794c-6ce8-4313-8461-79527777aafe,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-f83970f6-f571-4850-8ec7-dd6ccf4450fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-2471c5fd-76ef-4896-8da0-f7c2dbb804f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-11c916d0-47eb-4129-ab9a-ff79ed6973e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-4ec4a86e-4361-41ab-ab58-541e739c06d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-5d9935b4-14b0-4c5f-811e-0a8994b6eb64,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-4f50a6ba-6153-4113-b1dd-e07b4214ebce,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-a33f05c6-be78-46f3-854d-36713501afcb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638203447-172.17.0.18-1597690573464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39681,DS-c67f794c-6ce8-4313-8461-79527777aafe,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-f83970f6-f571-4850-8ec7-dd6ccf4450fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-2471c5fd-76ef-4896-8da0-f7c2dbb804f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-11c916d0-47eb-4129-ab9a-ff79ed6973e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-4ec4a86e-4361-41ab-ab58-541e739c06d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-5d9935b4-14b0-4c5f-811e-0a8994b6eb64,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-4f50a6ba-6153-4113-b1dd-e07b4214ebce,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-a33f05c6-be78-46f3-854d-36713501afcb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140482647-172.17.0.18-1597690725750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44247,DS-a3b65f03-097b-4893-a2fd-8ce15920a2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-fbcd198b-2433-41b3-912e-dcf7ea136c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-cc4855f0-8321-4260-bcc6-3e67a14602ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-b45f1726-4502-44e8-8d6c-9761ffc66833,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-52bf557a-d3fc-4192-b8eb-f1002ef5b930,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-8cc3e233-4f16-4981-a8f9-a12d6dea657e,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-bc495b62-cff9-4327-9980-093f6401025c,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-62e4aa43-90ad-4357-8fc5-e3a1291a5e5c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140482647-172.17.0.18-1597690725750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44247,DS-a3b65f03-097b-4893-a2fd-8ce15920a2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-fbcd198b-2433-41b3-912e-dcf7ea136c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-cc4855f0-8321-4260-bcc6-3e67a14602ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-b45f1726-4502-44e8-8d6c-9761ffc66833,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-52bf557a-d3fc-4192-b8eb-f1002ef5b930,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-8cc3e233-4f16-4981-a8f9-a12d6dea657e,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-bc495b62-cff9-4327-9980-093f6401025c,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-62e4aa43-90ad-4357-8fc5-e3a1291a5e5c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1321421563-172.17.0.18-1597690807433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45343,DS-15cc8619-f22f-4b31-bbdd-0d5ca41bc489,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-f8322190-8df9-4dae-9fad-87d20cafa1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-6828791b-c42a-472c-b867-16dd6b2b5cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-312082a8-f367-48ac-99f8-1f90a264e40b,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-ebfb7c37-f292-4add-ae07-df711620a30a,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-8ae3fb24-1e14-40da-82ff-030e93585038,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-040b6502-c393-438b-8a67-eeeb56328015,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-97e7b4fe-eb36-459f-abcd-211f1db0fc18,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1321421563-172.17.0.18-1597690807433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45343,DS-15cc8619-f22f-4b31-bbdd-0d5ca41bc489,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-f8322190-8df9-4dae-9fad-87d20cafa1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-6828791b-c42a-472c-b867-16dd6b2b5cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-312082a8-f367-48ac-99f8-1f90a264e40b,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-ebfb7c37-f292-4add-ae07-df711620a30a,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-8ae3fb24-1e14-40da-82ff-030e93585038,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-040b6502-c393-438b-8a67-eeeb56328015,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-97e7b4fe-eb36-459f-abcd-211f1db0fc18,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-477291710-172.17.0.18-1597691194245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39581,DS-a1b6c4cb-5a0c-4955-b5db-49610671386c,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-e4fa8a89-4796-4cb5-be43-0ae19c211d97,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-9bcc9e92-aa79-4b93-b384-5ad84a438f84,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-650a4f54-a00a-4871-9835-d5b515dbfa1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-3a54a87f-9ea6-4dce-8bcc-73301d966ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-230d138f-6755-4a82-8151-eb380d6ede63,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-2798a538-ac23-4d83-ac22-74a03f179d59,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-d491ebab-857b-4752-9c6d-d5bed194f8aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-477291710-172.17.0.18-1597691194245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39581,DS-a1b6c4cb-5a0c-4955-b5db-49610671386c,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-e4fa8a89-4796-4cb5-be43-0ae19c211d97,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-9bcc9e92-aa79-4b93-b384-5ad84a438f84,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-650a4f54-a00a-4871-9835-d5b515dbfa1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-3a54a87f-9ea6-4dce-8bcc-73301d966ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-230d138f-6755-4a82-8151-eb380d6ede63,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-2798a538-ac23-4d83-ac22-74a03f179d59,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-d491ebab-857b-4752-9c6d-d5bed194f8aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1588836427-172.17.0.18-1597691351131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46744,DS-20f5a18a-8923-4e0e-88ea-b4160196832f,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-ba34c26a-eed9-4bfb-ba2d-c4a8a12375cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-223ad694-fcb5-4846-9603-5dde96087a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-025928d8-b56f-45c2-b8a6-3aa12cff8e01,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-fdf61a6f-f3be-4b38-abc5-a468fdc4810e,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-84dbf8e3-ca81-44e0-a671-49d179cbd1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-3653cd82-ec6d-4ab1-9687-76be505409d3,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-9fa63ae6-aca2-4c6d-919c-f091a401ada0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1588836427-172.17.0.18-1597691351131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46744,DS-20f5a18a-8923-4e0e-88ea-b4160196832f,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-ba34c26a-eed9-4bfb-ba2d-c4a8a12375cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-223ad694-fcb5-4846-9603-5dde96087a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-025928d8-b56f-45c2-b8a6-3aa12cff8e01,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-fdf61a6f-f3be-4b38-abc5-a468fdc4810e,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-84dbf8e3-ca81-44e0-a671-49d179cbd1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-3653cd82-ec6d-4ab1-9687-76be505409d3,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-9fa63ae6-aca2-4c6d-919c-f091a401ada0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668720720-172.17.0.18-1597691417435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42122,DS-2948ef65-3c76-443a-9d03-864b031eb905,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-a96e1377-2d4f-4a9f-938f-791d818ed4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-d0c1f472-09a3-48b2-a784-f2fd2d6146b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-c2f699df-d834-430d-ac3e-3b08e7fc63e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-7a017cb7-0ab7-4717-af9e-891e558c1935,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-b7f3defd-b23c-44dc-8588-36b20772bd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36240,DS-234b29ed-7e5d-4f4c-b4a1-284000d4b2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-8b56afc9-90a4-4d60-b1db-2a47e87a8b94,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668720720-172.17.0.18-1597691417435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42122,DS-2948ef65-3c76-443a-9d03-864b031eb905,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-a96e1377-2d4f-4a9f-938f-791d818ed4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-d0c1f472-09a3-48b2-a784-f2fd2d6146b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-c2f699df-d834-430d-ac3e-3b08e7fc63e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-7a017cb7-0ab7-4717-af9e-891e558c1935,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-b7f3defd-b23c-44dc-8588-36b20772bd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36240,DS-234b29ed-7e5d-4f4c-b4a1-284000d4b2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-8b56afc9-90a4-4d60-b1db-2a47e87a8b94,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700763967-172.17.0.18-1597691637425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37898,DS-c71b2d25-99d6-499c-8612-6adad98b455a,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-1c227cb7-78a0-4736-b852-f1986cefc0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-c02dc5fa-abfd-4fb3-bc92-5770ad7f19bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-2bac49f5-06b6-46d9-ab3e-5235728f04b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-423f91ec-b784-4370-96f3-e7d27b4df01b,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-a1dd0d8c-ad09-47d6-879a-d8bf91c33143,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-02f84ae4-f835-407f-9cfc-3a4ca0524fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-23b7f11a-28d5-4fcf-96a1-642dab94a23f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700763967-172.17.0.18-1597691637425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37898,DS-c71b2d25-99d6-499c-8612-6adad98b455a,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-1c227cb7-78a0-4736-b852-f1986cefc0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-c02dc5fa-abfd-4fb3-bc92-5770ad7f19bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-2bac49f5-06b6-46d9-ab3e-5235728f04b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-423f91ec-b784-4370-96f3-e7d27b4df01b,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-a1dd0d8c-ad09-47d6-879a-d8bf91c33143,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-02f84ae4-f835-407f-9cfc-3a4ca0524fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-23b7f11a-28d5-4fcf-96a1-642dab94a23f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1715423400-172.17.0.18-1597691752482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33034,DS-37c86f70-9b9e-460a-a01f-41f0482f85ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-8099bcba-c693-4ff7-9f53-fcc92de1fb53,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-fc0140bb-f1ad-48c5-8af9-692b7567c02d,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-87593ae3-991d-4b57-a321-6a72ab801b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-19005fcf-7764-4619-b440-61fb32b4f922,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-e2b8022f-0971-4c5e-9f7e-1e0433367a62,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-17287f9c-a031-43ab-96da-66809d823399,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-26d71b2c-9241-4a18-bae1-78398a5de994,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1715423400-172.17.0.18-1597691752482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33034,DS-37c86f70-9b9e-460a-a01f-41f0482f85ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-8099bcba-c693-4ff7-9f53-fcc92de1fb53,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-fc0140bb-f1ad-48c5-8af9-692b7567c02d,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-87593ae3-991d-4b57-a321-6a72ab801b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-19005fcf-7764-4619-b440-61fb32b4f922,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-e2b8022f-0971-4c5e-9f7e-1e0433367a62,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-17287f9c-a031-43ab-96da-66809d823399,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-26d71b2c-9241-4a18-bae1-78398a5de994,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1206735270-172.17.0.18-1597691860664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34185,DS-907e61db-3213-4fbe-9c77-b64b614d6bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-9cb68bc6-505d-4286-92ef-3b528ab4db00,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-b492b739-72a4-4546-aa9d-4d2b30f5e89c,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-c83c965c-ce8c-4bea-bd45-6db6f8592559,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-f76823ec-c7dc-4209-a318-6f985f360e73,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-6406e4bb-ee77-49e1-af04-b132e199b365,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-6c7df552-e1d3-4bde-ac9b-c7343545c772,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-d11e9f25-9fb5-4671-a997-ec878f2e0047,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1206735270-172.17.0.18-1597691860664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34185,DS-907e61db-3213-4fbe-9c77-b64b614d6bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-9cb68bc6-505d-4286-92ef-3b528ab4db00,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-b492b739-72a4-4546-aa9d-4d2b30f5e89c,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-c83c965c-ce8c-4bea-bd45-6db6f8592559,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-f76823ec-c7dc-4209-a318-6f985f360e73,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-6406e4bb-ee77-49e1-af04-b132e199b365,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-6c7df552-e1d3-4bde-ac9b-c7343545c772,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-d11e9f25-9fb5-4671-a997-ec878f2e0047,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394176268-172.17.0.18-1597692164920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46699,DS-117f7440-36bb-4792-9942-c9bfdc36607c,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-ab0fdf34-ba38-4362-a3da-28ff2a2d2164,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-78750006-28ea-42e0-a083-ef5e02ea3019,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-b13410f4-2cff-4501-b527-d89f724c8dce,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-18dda7e3-c06f-44ca-8df6-e85abc349c32,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-500d3a56-367c-437c-8467-3bcc76fe096d,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-9732a568-43ab-4e7b-9eed-78a170feef57,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-2f8fd197-85af-401a-a627-195f8919b4e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394176268-172.17.0.18-1597692164920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46699,DS-117f7440-36bb-4792-9942-c9bfdc36607c,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-ab0fdf34-ba38-4362-a3da-28ff2a2d2164,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-78750006-28ea-42e0-a083-ef5e02ea3019,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-b13410f4-2cff-4501-b527-d89f724c8dce,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-18dda7e3-c06f-44ca-8df6-e85abc349c32,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-500d3a56-367c-437c-8467-3bcc76fe096d,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-9732a568-43ab-4e7b-9eed-78a170feef57,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-2f8fd197-85af-401a-a627-195f8919b4e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1481851684-172.17.0.18-1597692200201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33703,DS-367d4da0-38ce-4e05-8ac3-e9a51776ca6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-4051844f-0c20-4a02-b5e5-6c8b5b2bd8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-9ee10f16-a78a-4b1e-b169-21e2ec088f29,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-cefb8c0c-7811-492a-8d08-85d620c25694,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-4e58968b-5554-47cb-b7a0-230c1fb6854f,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-c5354c2e-ef2a-432d-9830-115661877ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-eb4abc3b-8360-45b9-94f5-21fc91a2fc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-c8c56362-d22e-48a6-b39b-695c082e2ca7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1481851684-172.17.0.18-1597692200201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33703,DS-367d4da0-38ce-4e05-8ac3-e9a51776ca6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-4051844f-0c20-4a02-b5e5-6c8b5b2bd8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-9ee10f16-a78a-4b1e-b169-21e2ec088f29,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-cefb8c0c-7811-492a-8d08-85d620c25694,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-4e58968b-5554-47cb-b7a0-230c1fb6854f,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-c5354c2e-ef2a-432d-9830-115661877ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-eb4abc3b-8360-45b9-94f5-21fc91a2fc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-c8c56362-d22e-48a6-b39b-695c082e2ca7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1970534248-172.17.0.18-1597692340650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42748,DS-da3e4f9a-37d4-4c09-b7e2-80762af2477f,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-9bfa0ef6-0b2f-47be-a72f-74ad2bd56285,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-1e607c37-68f6-4893-9bcd-14f600b3be44,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-94b23955-1b12-49b2-8c3f-617942e8fcab,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-393266e7-57a4-4b3f-a3d3-c47197e3e184,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-c1a2ab0b-e387-4468-a853-6f2ebb04f730,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-9bfcaa65-7ea2-405e-86a2-48252a08695d,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-ef9ab4ff-699d-4418-b7dd-0c588b000b13,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1970534248-172.17.0.18-1597692340650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42748,DS-da3e4f9a-37d4-4c09-b7e2-80762af2477f,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-9bfa0ef6-0b2f-47be-a72f-74ad2bd56285,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-1e607c37-68f6-4893-9bcd-14f600b3be44,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-94b23955-1b12-49b2-8c3f-617942e8fcab,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-393266e7-57a4-4b3f-a3d3-c47197e3e184,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-c1a2ab0b-e387-4468-a853-6f2ebb04f730,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-9bfcaa65-7ea2-405e-86a2-48252a08695d,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-ef9ab4ff-699d-4418-b7dd-0c588b000b13,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-493753176-172.17.0.18-1597692629792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39671,DS-ef513c4d-f7ae-4b48-9f5c-07d69d98afd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-d78600be-3972-449d-9c46-856f7971fdfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-298511a0-88d3-4e02-9bae-91ce75e44469,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-406b42d4-be93-4c92-b910-ba8e9c514a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-8336d127-134b-43f0-aa2b-713d5eafcc10,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-9cb45f11-7f3f-420a-a0dc-39701ff385b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-4e27fe6d-81d1-4e8e-90bb-5f376f2cd8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-65fdb41b-777a-4202-89b6-bd47ce6504be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-493753176-172.17.0.18-1597692629792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39671,DS-ef513c4d-f7ae-4b48-9f5c-07d69d98afd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-d78600be-3972-449d-9c46-856f7971fdfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-298511a0-88d3-4e02-9bae-91ce75e44469,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-406b42d4-be93-4c92-b910-ba8e9c514a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-8336d127-134b-43f0-aa2b-713d5eafcc10,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-9cb45f11-7f3f-420a-a0dc-39701ff385b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-4e27fe6d-81d1-4e8e-90bb-5f376f2cd8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-65fdb41b-777a-4202-89b6-bd47ce6504be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968838715-172.17.0.18-1597693382837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34227,DS-9db4fdff-0137-4d40-8118-b596df555782,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-85e8e167-1803-48de-aaba-cc1c08efd093,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-144990ae-708c-4ab3-ad04-b48bfbcd5a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-e110ea96-da01-4760-93ba-cacc0c10c557,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-81ba39bf-2914-4abb-995c-67e086b386e2,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-60b109a7-4bcb-4720-a7b2-2a2a7f97ba03,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-9cd7409d-7acd-4218-ad34-c3ba256a5494,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-18fb80db-5785-4979-a92d-c6be75f6ffd0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968838715-172.17.0.18-1597693382837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34227,DS-9db4fdff-0137-4d40-8118-b596df555782,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-85e8e167-1803-48de-aaba-cc1c08efd093,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-144990ae-708c-4ab3-ad04-b48bfbcd5a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-e110ea96-da01-4760-93ba-cacc0c10c557,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-81ba39bf-2914-4abb-995c-67e086b386e2,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-60b109a7-4bcb-4720-a7b2-2a2a7f97ba03,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-9cd7409d-7acd-4218-ad34-c3ba256a5494,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-18fb80db-5785-4979-a92d-c6be75f6ffd0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1593966576-172.17.0.18-1597693460428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40509,DS-23a64276-8355-42a1-86b6-eb6816e5b3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-7b7234fd-2ec2-4345-ae15-eca79ee2129b,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-3d16be3f-25df-4f74-9dc5-65d129e79c01,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-f91238b2-c471-49da-af5a-f6fce2a22403,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-df6181fc-5969-4672-ab8f-8456f727e1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-56f4ce7a-2e00-4e43-be80-737944b087e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-577e70da-0c70-4204-8ffb-f3ccf7dcffa4,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-cd0647ec-6c02-4a77-b11b-12fbd77fee4a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1593966576-172.17.0.18-1597693460428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40509,DS-23a64276-8355-42a1-86b6-eb6816e5b3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-7b7234fd-2ec2-4345-ae15-eca79ee2129b,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-3d16be3f-25df-4f74-9dc5-65d129e79c01,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-f91238b2-c471-49da-af5a-f6fce2a22403,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-df6181fc-5969-4672-ab8f-8456f727e1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-56f4ce7a-2e00-4e43-be80-737944b087e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-577e70da-0c70-4204-8ffb-f3ccf7dcffa4,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-cd0647ec-6c02-4a77-b11b-12fbd77fee4a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1265859251-172.17.0.18-1597693496060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33015,DS-5f5b8cce-94d5-44b4-9d8f-5adbfe60f9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-302d5124-86a4-49e5-bed6-be0421fc8f12,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-1e2847b7-38f9-4e40-9be5-cccf39c5c506,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-def4e7cd-d8f4-416b-b64f-90388a761b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-52549509-8435-4ea6-854a-fa75124074ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-4e54d040-16cf-4a77-a70f-325772e81055,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-d5323be7-b561-44c1-b22e-9a1e2fe2160f,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-9c22e4be-e3ac-437a-b206-e6ac247eda50,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1265859251-172.17.0.18-1597693496060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33015,DS-5f5b8cce-94d5-44b4-9d8f-5adbfe60f9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-302d5124-86a4-49e5-bed6-be0421fc8f12,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-1e2847b7-38f9-4e40-9be5-cccf39c5c506,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-def4e7cd-d8f4-416b-b64f-90388a761b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-52549509-8435-4ea6-854a-fa75124074ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-4e54d040-16cf-4a77-a70f-325772e81055,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-d5323be7-b561-44c1-b22e-9a1e2fe2160f,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-9c22e4be-e3ac-437a-b206-e6ac247eda50,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-336450742-172.17.0.18-1597693675810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34202,DS-cfbf2fff-54e6-4e33-af40-a80bfe9a0b63,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-2758f3bc-1620-46fc-a76f-7e61dcfd2939,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-84ad5c69-7fed-4ec7-bf32-13b024209fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-2c0588e2-47d3-4746-ab15-13d1d85a6196,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-7dbd8887-e814-47f2-bbe4-4aad41a8328e,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-674f0b40-977a-413c-bb28-f3db690119d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-24b6e97b-ffc0-4549-80ad-25cb70885524,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-7b453057-aab9-4b17-ad6a-425f5614197a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-336450742-172.17.0.18-1597693675810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34202,DS-cfbf2fff-54e6-4e33-af40-a80bfe9a0b63,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-2758f3bc-1620-46fc-a76f-7e61dcfd2939,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-84ad5c69-7fed-4ec7-bf32-13b024209fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-2c0588e2-47d3-4746-ab15-13d1d85a6196,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-7dbd8887-e814-47f2-bbe4-4aad41a8328e,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-674f0b40-977a-413c-bb28-f3db690119d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-24b6e97b-ffc0-4549-80ad-25cb70885524,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-7b453057-aab9-4b17-ad6a-425f5614197a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-898586273-172.17.0.18-1597693873751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37653,DS-a3fd9989-e704-4640-8654-748c139b9a27,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-c44bd351-e2c2-4e55-8a35-9641a885e4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-dd27c755-5ae1-420e-bcf5-53e8807d4693,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-22b1145d-6594-401e-ae70-2925bd32da67,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-f4aec63b-7bae-44a9-89ec-cff0c332a79b,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-91f41d01-8a2a-404d-99de-100e6be4b05e,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-342bf305-9b30-4729-b661-158f79dde003,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-f13bfadf-a4b4-49b2-b0ca-8f3cc7288a2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-898586273-172.17.0.18-1597693873751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37653,DS-a3fd9989-e704-4640-8654-748c139b9a27,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-c44bd351-e2c2-4e55-8a35-9641a885e4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-dd27c755-5ae1-420e-bcf5-53e8807d4693,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-22b1145d-6594-401e-ae70-2925bd32da67,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-f4aec63b-7bae-44a9-89ec-cff0c332a79b,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-91f41d01-8a2a-404d-99de-100e6be4b05e,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-342bf305-9b30-4729-b661-158f79dde003,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-f13bfadf-a4b4-49b2-b0ca-8f3cc7288a2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2014401366-172.17.0.18-1597694027767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37695,DS-cf9c85ca-52d7-4946-8d3b-90b06449c382,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-066f3c56-713d-4781-9968-9274d5d530d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-7f376a77-d079-4156-840d-49b222da323a,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-5675fe66-1488-4105-a80b-6efc9aae83cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40996,DS-92d6c3a9-a3db-4fa6-af75-c79265b0ccf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-7f3712ec-dee7-4361-9897-b5a81ec1926d,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-64a9ba23-583b-4c27-a090-17d64d8616a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-c20db9f5-6b39-4911-9f6b-20d2ac3774ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2014401366-172.17.0.18-1597694027767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37695,DS-cf9c85ca-52d7-4946-8d3b-90b06449c382,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-066f3c56-713d-4781-9968-9274d5d530d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-7f376a77-d079-4156-840d-49b222da323a,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-5675fe66-1488-4105-a80b-6efc9aae83cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40996,DS-92d6c3a9-a3db-4fa6-af75-c79265b0ccf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-7f3712ec-dee7-4361-9897-b5a81ec1926d,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-64a9ba23-583b-4c27-a090-17d64d8616a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-c20db9f5-6b39-4911-9f6b-20d2ac3774ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1751683333-172.17.0.18-1597694061762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44831,DS-79cd4791-c263-4ae3-a548-eb3ac16b7473,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-86b57cff-164f-40e1-a622-efa858200c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-45b116ef-6b89-4387-954e-a18b151bba18,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-b0ff9a93-2626-4a59-85aa-d5569520b226,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-282a3829-0c7d-4caa-9e7a-bf2e302d2eba,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-dd2c1657-8b48-499d-b313-436ea111dfe4,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-0d4a0c44-71f8-4acc-b8a5-7332c15fdc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-27072bff-d7f8-4cb6-b794-aa890c4ed157,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1751683333-172.17.0.18-1597694061762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44831,DS-79cd4791-c263-4ae3-a548-eb3ac16b7473,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-86b57cff-164f-40e1-a622-efa858200c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33618,DS-45b116ef-6b89-4387-954e-a18b151bba18,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-b0ff9a93-2626-4a59-85aa-d5569520b226,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-282a3829-0c7d-4caa-9e7a-bf2e302d2eba,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-dd2c1657-8b48-499d-b313-436ea111dfe4,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-0d4a0c44-71f8-4acc-b8a5-7332c15fdc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-27072bff-d7f8-4cb6-b794-aa890c4ed157,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 18 out of 50
result: false positive !!!
Total execution time in seconds : 5576
