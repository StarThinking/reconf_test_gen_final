reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-158403587-172.17.0.6-1597711112342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34075,DS-47cf4bf2-8bd6-429e-9f9d-4a41c3b97a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-a175bf6d-f798-4ee0-bff8-2d77ccadf857,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-8fe29eee-6f5e-4c2b-b786-f987bd4161d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-80649bdf-52c2-4dd0-93cf-f9a5d793acc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-9c33fe07-bfdb-455f-899e-7a5888418b03,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-51dda89a-0944-4798-9552-53b03dc2c3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-ba0ffbd2-f4cf-4f32-b438-a5d0200fe354,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-c525e2fa-f046-454f-b264-365f868a4461,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-158403587-172.17.0.6-1597711112342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34075,DS-47cf4bf2-8bd6-429e-9f9d-4a41c3b97a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-a175bf6d-f798-4ee0-bff8-2d77ccadf857,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-8fe29eee-6f5e-4c2b-b786-f987bd4161d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-80649bdf-52c2-4dd0-93cf-f9a5d793acc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-9c33fe07-bfdb-455f-899e-7a5888418b03,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-51dda89a-0944-4798-9552-53b03dc2c3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-ba0ffbd2-f4cf-4f32-b438-a5d0200fe354,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-c525e2fa-f046-454f-b264-365f868a4461,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-544249058-172.17.0.6-1597711155536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46595,DS-891dbfbf-68de-4248-914a-febee7293789,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-ae262ba1-cced-4d50-a302-6735cc232a55,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-f6cd4ab4-ee73-4836-836e-2099401b5c86,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-c396d62f-d553-4973-9286-f644c1b19e93,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-bcbcb6ea-46ed-4960-98b5-b26342b91048,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-9750d419-850d-4a53-84a9-03f8f9efc16c,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-dce50f47-1ea6-4393-bd5f-0cc37a175f78,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-2d9c6b46-7ab3-44da-9b7c-469b5cbd4eb9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-544249058-172.17.0.6-1597711155536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46595,DS-891dbfbf-68de-4248-914a-febee7293789,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-ae262ba1-cced-4d50-a302-6735cc232a55,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-f6cd4ab4-ee73-4836-836e-2099401b5c86,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-c396d62f-d553-4973-9286-f644c1b19e93,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-bcbcb6ea-46ed-4960-98b5-b26342b91048,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-9750d419-850d-4a53-84a9-03f8f9efc16c,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-dce50f47-1ea6-4393-bd5f-0cc37a175f78,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-2d9c6b46-7ab3-44da-9b7c-469b5cbd4eb9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267294150-172.17.0.6-1597711376260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38766,DS-7e5d6480-3ec8-4520-9258-bc94faa1a791,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-c73f67d6-e0b0-4acf-b1b7-01503b54b2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-ec9185d5-334d-44dc-9c72-b0737d41e1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-6c897ce2-00de-489c-8da9-feeefab0710e,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-67291944-35de-4b88-9511-59447555bab4,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-f39fd357-12f6-49ac-9803-4af3b759c927,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-7f8d4cfd-6f74-489c-a6af-52a5331e5a46,DISK], DatanodeInfoWithStorage[127.0.0.1:41068,DS-ee24c02e-bcc4-42b4-a978-ca465745a994,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267294150-172.17.0.6-1597711376260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38766,DS-7e5d6480-3ec8-4520-9258-bc94faa1a791,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-c73f67d6-e0b0-4acf-b1b7-01503b54b2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-ec9185d5-334d-44dc-9c72-b0737d41e1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-6c897ce2-00de-489c-8da9-feeefab0710e,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-67291944-35de-4b88-9511-59447555bab4,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-f39fd357-12f6-49ac-9803-4af3b759c927,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-7f8d4cfd-6f74-489c-a6af-52a5331e5a46,DISK], DatanodeInfoWithStorage[127.0.0.1:41068,DS-ee24c02e-bcc4-42b4-a978-ca465745a994,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2095178620-172.17.0.6-1597711459024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32968,DS-f17abbd8-774d-4e9d-a157-e790c1b7d940,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-c9f6d191-3574-42ed-89fd-044871b62db5,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-359db812-3dc6-404c-b92a-807609818e36,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-3c8401bd-f75f-4395-870a-46147b42cc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-7c9c383f-39c7-4fd5-b327-07b8f971e205,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-ed797421-289b-4040-b93b-f563ddf64e99,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-f7229e4d-6f9a-4b5f-b0ba-58caab7d96b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-1be130c3-5473-4348-87c4-c4e537935df5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2095178620-172.17.0.6-1597711459024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32968,DS-f17abbd8-774d-4e9d-a157-e790c1b7d940,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-c9f6d191-3574-42ed-89fd-044871b62db5,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-359db812-3dc6-404c-b92a-807609818e36,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-3c8401bd-f75f-4395-870a-46147b42cc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-7c9c383f-39c7-4fd5-b327-07b8f971e205,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-ed797421-289b-4040-b93b-f563ddf64e99,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-f7229e4d-6f9a-4b5f-b0ba-58caab7d96b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-1be130c3-5473-4348-87c4-c4e537935df5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1698231866-172.17.0.6-1597711534074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46806,DS-5924737e-21a1-43ec-a349-f6fd089a0ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-6a70f8e6-4713-4ddf-b71f-ee9b32f12b84,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-c0500a48-5b9e-431a-90fa-714ff14ffdfd,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-3d36fc67-3237-46a7-92cc-82de3e6a3265,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-c26cb5be-926e-47f9-8275-50fa94187033,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-e02e7d98-9994-4ace-a705-a3781e2cd66f,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-f6999ea7-5e8d-4568-ab5f-a11fec01c372,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-4d6ac2fe-b07a-4b4b-9006-4f0b0c2d418d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1698231866-172.17.0.6-1597711534074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46806,DS-5924737e-21a1-43ec-a349-f6fd089a0ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-6a70f8e6-4713-4ddf-b71f-ee9b32f12b84,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-c0500a48-5b9e-431a-90fa-714ff14ffdfd,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-3d36fc67-3237-46a7-92cc-82de3e6a3265,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-c26cb5be-926e-47f9-8275-50fa94187033,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-e02e7d98-9994-4ace-a705-a3781e2cd66f,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-f6999ea7-5e8d-4568-ab5f-a11fec01c372,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-4d6ac2fe-b07a-4b4b-9006-4f0b0c2d418d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-186048562-172.17.0.6-1597712045182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38583,DS-ef27f4cd-0fc5-4db7-a4fb-daeb93b2ae3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-28344532-317d-4f79-9a04-4bf308f2f009,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-919ff777-d13e-48bc-99e1-c0a4bdca5912,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-37332b71-d670-417a-9edc-e59a742e15c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-80c323c3-4513-4e56-a577-11de3b88cd9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-1d47c8d1-11e2-4854-bb5d-50392f6ef3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-df9522d5-26d6-4904-8b7e-3e276e25c061,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-a9fcaee7-7a81-4d0c-a2b5-9f7dc401a1db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-186048562-172.17.0.6-1597712045182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38583,DS-ef27f4cd-0fc5-4db7-a4fb-daeb93b2ae3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-28344532-317d-4f79-9a04-4bf308f2f009,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-919ff777-d13e-48bc-99e1-c0a4bdca5912,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-37332b71-d670-417a-9edc-e59a742e15c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-80c323c3-4513-4e56-a577-11de3b88cd9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-1d47c8d1-11e2-4854-bb5d-50392f6ef3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-df9522d5-26d6-4904-8b7e-3e276e25c061,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-a9fcaee7-7a81-4d0c-a2b5-9f7dc401a1db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397936298-172.17.0.6-1597712085256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42768,DS-3821142c-2f41-47d5-8f3b-b8b51dfa69a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-922a6fdd-0d33-4e2c-8a99-b0149c58b2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-534f4f45-d826-402c-aa03-cb4e5ca80d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-b25a9f22-f74c-4309-9f76-9356aa5ac005,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-e5734093-a71a-4d6f-97de-d2f395ac57e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-d56bab7f-00b1-4366-91d9-2d8c06b0e642,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-72282012-2a78-44b3-8b72-26d4165187d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-f7fb83c4-5051-4354-bb0e-d4a378a5e3a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397936298-172.17.0.6-1597712085256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42768,DS-3821142c-2f41-47d5-8f3b-b8b51dfa69a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-922a6fdd-0d33-4e2c-8a99-b0149c58b2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-534f4f45-d826-402c-aa03-cb4e5ca80d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-b25a9f22-f74c-4309-9f76-9356aa5ac005,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-e5734093-a71a-4d6f-97de-d2f395ac57e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-d56bab7f-00b1-4366-91d9-2d8c06b0e642,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-72282012-2a78-44b3-8b72-26d4165187d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-f7fb83c4-5051-4354-bb0e-d4a378a5e3a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421214446-172.17.0.6-1597712310360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38780,DS-04385ae5-49e3-44cf-8836-51568b4fabae,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-8884f30e-ec03-4552-b86e-50539a29fec3,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-00e58aa2-cc4f-428b-b7e7-4a8fc70bd04a,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-d5797bf2-c86a-463b-8090-1260fcb74f68,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-06d8dd08-0397-4191-94df-439848cb54a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43506,DS-203b6f61-79db-479b-a0db-ca5b9b595efe,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-18925f03-3fbf-41ea-beab-2a70c37ac103,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-aea4033d-fef8-451b-8db2-f7aabad6feb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421214446-172.17.0.6-1597712310360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38780,DS-04385ae5-49e3-44cf-8836-51568b4fabae,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-8884f30e-ec03-4552-b86e-50539a29fec3,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-00e58aa2-cc4f-428b-b7e7-4a8fc70bd04a,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-d5797bf2-c86a-463b-8090-1260fcb74f68,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-06d8dd08-0397-4191-94df-439848cb54a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43506,DS-203b6f61-79db-479b-a0db-ca5b9b595efe,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-18925f03-3fbf-41ea-beab-2a70c37ac103,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-aea4033d-fef8-451b-8db2-f7aabad6feb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1429824289-172.17.0.6-1597712488621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42482,DS-2cd498ae-af6d-4d85-9218-95fc8696df9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-85ac17b0-dd18-4ed9-aa54-dfcb04103dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-ba07bf36-ca53-4474-b8bc-ae17b7dec231,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-8118ded7-cb45-4f87-bc6f-7ba5d800e4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-62a406a0-1aa5-48ec-b4fa-d4478f9abaed,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-b61417ab-0eec-4176-98d8-071400091b66,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-285ab8c6-5b0f-4d40-b5d3-1d4c21b004a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-c1b97dc3-41fa-48e6-ad5b-f7f86b088c86,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1429824289-172.17.0.6-1597712488621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42482,DS-2cd498ae-af6d-4d85-9218-95fc8696df9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-85ac17b0-dd18-4ed9-aa54-dfcb04103dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-ba07bf36-ca53-4474-b8bc-ae17b7dec231,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-8118ded7-cb45-4f87-bc6f-7ba5d800e4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-62a406a0-1aa5-48ec-b4fa-d4478f9abaed,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-b61417ab-0eec-4176-98d8-071400091b66,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-285ab8c6-5b0f-4d40-b5d3-1d4c21b004a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-c1b97dc3-41fa-48e6-ad5b-f7f86b088c86,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-277401362-172.17.0.6-1597712719615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45704,DS-cd901958-bff3-4c5b-bd44-23960f864b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-73a8064d-e71a-4d6c-9f17-79a955ebe7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-81169177-3440-4ae3-9c56-4a95b162e39a,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-db8c9f4f-dc63-4459-8db8-c2cd2f667868,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-6f1101f7-5261-4247-8797-e66584adbbde,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-bf5f527c-aff6-40dd-9456-4c5e18b3a22e,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-a7f2c014-2a19-40f9-a994-817054f9c53d,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-b140d537-2923-4827-9ac3-e16bc259f2ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-277401362-172.17.0.6-1597712719615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45704,DS-cd901958-bff3-4c5b-bd44-23960f864b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-73a8064d-e71a-4d6c-9f17-79a955ebe7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-81169177-3440-4ae3-9c56-4a95b162e39a,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-db8c9f4f-dc63-4459-8db8-c2cd2f667868,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-6f1101f7-5261-4247-8797-e66584adbbde,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-bf5f527c-aff6-40dd-9456-4c5e18b3a22e,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-a7f2c014-2a19-40f9-a994-817054f9c53d,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-b140d537-2923-4827-9ac3-e16bc259f2ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976012942-172.17.0.6-1597712770108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34953,DS-8fe25935-1a4d-49f0-8b5c-7e3b92bd438c,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-8eb404e5-cee5-46e1-9289-68d3730a7e41,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-21d09d48-2d65-47ba-b446-de3a1362efb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-c6f4cd5b-0b69-4eb0-9fe8-9fef237bad82,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-2d3161b1-bc5c-4717-a760-a9032d9a27d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-433c4d0b-2aac-4fd2-959f-63932b1d87e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-f0e3d405-8b0a-46cd-938c-d9f9970558c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-00183bd8-8716-45fe-885e-f03c34cb2628,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976012942-172.17.0.6-1597712770108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34953,DS-8fe25935-1a4d-49f0-8b5c-7e3b92bd438c,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-8eb404e5-cee5-46e1-9289-68d3730a7e41,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-21d09d48-2d65-47ba-b446-de3a1362efb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-c6f4cd5b-0b69-4eb0-9fe8-9fef237bad82,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-2d3161b1-bc5c-4717-a760-a9032d9a27d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-433c4d0b-2aac-4fd2-959f-63932b1d87e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-f0e3d405-8b0a-46cd-938c-d9f9970558c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-00183bd8-8716-45fe-885e-f03c34cb2628,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-479765965-172.17.0.6-1597712815051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42597,DS-72d81522-6676-4e2a-9063-af2c5b87a8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-ca971bcf-1e22-43fa-8bec-15638f26cf89,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-0652771f-122f-4367-8cbf-99bc19b419c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-f1d90cc2-a68b-483d-b4f0-c05a37ad60bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44241,DS-327540ba-ecba-451d-aab5-59b810927201,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-199e4151-435d-4fd0-a34f-1a6fc00ab1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-0c50930b-158c-466e-843e-de5fd0932a02,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-ec4d717b-1605-4c46-81fe-ed68ddb11277,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-479765965-172.17.0.6-1597712815051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42597,DS-72d81522-6676-4e2a-9063-af2c5b87a8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-ca971bcf-1e22-43fa-8bec-15638f26cf89,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-0652771f-122f-4367-8cbf-99bc19b419c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-f1d90cc2-a68b-483d-b4f0-c05a37ad60bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44241,DS-327540ba-ecba-451d-aab5-59b810927201,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-199e4151-435d-4fd0-a34f-1a6fc00ab1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-0c50930b-158c-466e-843e-de5fd0932a02,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-ec4d717b-1605-4c46-81fe-ed68ddb11277,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2081281850-172.17.0.6-1597712999571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37548,DS-b13fac13-dc30-4138-9401-48f82f94b56a,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-dcb615ea-4708-40ac-a090-65fedac91ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-96775f7b-5688-48d3-bac7-99b376086f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-3a79f2cc-77a4-4855-8769-994cac5f6ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-98f78085-0102-469c-bca8-3aebc54fbc49,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-4a193b54-4549-4f85-82e7-b7f2c4597707,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-e09b3dc2-170c-4782-b83d-484e7144bd33,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-31af1c15-1f67-4369-9f75-b038c115c86b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2081281850-172.17.0.6-1597712999571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37548,DS-b13fac13-dc30-4138-9401-48f82f94b56a,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-dcb615ea-4708-40ac-a090-65fedac91ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-96775f7b-5688-48d3-bac7-99b376086f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-3a79f2cc-77a4-4855-8769-994cac5f6ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-98f78085-0102-469c-bca8-3aebc54fbc49,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-4a193b54-4549-4f85-82e7-b7f2c4597707,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-e09b3dc2-170c-4782-b83d-484e7144bd33,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-31af1c15-1f67-4369-9f75-b038c115c86b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1610868757-172.17.0.6-1597713084214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44250,DS-ad0834b0-3b26-497f-9cbe-140e5048b880,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-709d5ddc-da81-4e5c-98f4-409bf56503ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-f32a3c6f-0adc-47f1-ad89-dce6a0d8f3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-9dcb260c-a55c-4e86-85fc-495babfdad32,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-fb78a55f-738f-41f3-a5f6-0685aaafedff,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-8152d71f-dc98-4105-8326-83a1ea9da776,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-9da2da57-ee35-4186-adea-ae76199dee79,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-c2372604-bc27-4533-871e-0d54314b509f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1610868757-172.17.0.6-1597713084214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44250,DS-ad0834b0-3b26-497f-9cbe-140e5048b880,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-709d5ddc-da81-4e5c-98f4-409bf56503ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-f32a3c6f-0adc-47f1-ad89-dce6a0d8f3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-9dcb260c-a55c-4e86-85fc-495babfdad32,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-fb78a55f-738f-41f3-a5f6-0685aaafedff,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-8152d71f-dc98-4105-8326-83a1ea9da776,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-9da2da57-ee35-4186-adea-ae76199dee79,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-c2372604-bc27-4533-871e-0d54314b509f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-964890301-172.17.0.6-1597713168356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36305,DS-faa5086a-7c14-4446-af20-0b241b3b3f61,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-6d7a9a66-09ef-4552-bfa5-b3bc76c2bbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-578de52a-f65c-48a9-a493-f1cd2fc951a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-090ac0f7-3f16-4b23-baea-506589faffcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-6b1b8759-0ca6-486c-b0b4-d2d41d614c24,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-ae14a61b-97d5-45bd-aea9-0be4ebc433a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-23365a7f-d19a-4d5e-935d-049c851bcc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-04f5dc61-3221-4046-8774-8efccff14e4f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-964890301-172.17.0.6-1597713168356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36305,DS-faa5086a-7c14-4446-af20-0b241b3b3f61,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-6d7a9a66-09ef-4552-bfa5-b3bc76c2bbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-578de52a-f65c-48a9-a493-f1cd2fc951a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-090ac0f7-3f16-4b23-baea-506589faffcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-6b1b8759-0ca6-486c-b0b4-d2d41d614c24,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-ae14a61b-97d5-45bd-aea9-0be4ebc433a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-23365a7f-d19a-4d5e-935d-049c851bcc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-04f5dc61-3221-4046-8774-8efccff14e4f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2013357744-172.17.0.6-1597713303464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46855,DS-da01cdf1-9348-43d1-a82e-b1555f4a9727,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-8290708e-96a2-4b96-a99e-5a7a3441a130,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-05f47a72-45bf-4789-9b10-37e7e6679543,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-e15d6f27-6f36-4116-9fe1-7012041b9451,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-fec7a0d0-b929-42d6-8441-de478bf3f360,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-e02703e0-791d-4aa5-8574-2bf336363347,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-7d390f34-29a9-4548-a56b-c96ed5fa8a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-298d8546-ebbc-4d0e-87e1-c62d03ef98b1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2013357744-172.17.0.6-1597713303464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46855,DS-da01cdf1-9348-43d1-a82e-b1555f4a9727,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-8290708e-96a2-4b96-a99e-5a7a3441a130,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-05f47a72-45bf-4789-9b10-37e7e6679543,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-e15d6f27-6f36-4116-9fe1-7012041b9451,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-fec7a0d0-b929-42d6-8441-de478bf3f360,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-e02703e0-791d-4aa5-8574-2bf336363347,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-7d390f34-29a9-4548-a56b-c96ed5fa8a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-298d8546-ebbc-4d0e-87e1-c62d03ef98b1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251102096-172.17.0.6-1597713478369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37559,DS-14821111-f892-4a10-8f7c-e819d6185831,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-601f2504-a008-4e83-99fc-17fb37f28f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-b59a97be-2f67-4cbd-a7b4-ad59236ac190,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-fbec44f9-2929-4677-98af-6ca5666e686d,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-18bf9f97-7738-48e9-a761-7ebd955f0aff,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-4e76b437-02f0-4e02-9b86-b990dc8d7a80,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-c8876b9b-0304-406e-b16d-2f23cdee111b,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-5d3457c4-1a58-4c94-8ffb-cf659f595dc4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251102096-172.17.0.6-1597713478369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37559,DS-14821111-f892-4a10-8f7c-e819d6185831,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-601f2504-a008-4e83-99fc-17fb37f28f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-b59a97be-2f67-4cbd-a7b4-ad59236ac190,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-fbec44f9-2929-4677-98af-6ca5666e686d,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-18bf9f97-7738-48e9-a761-7ebd955f0aff,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-4e76b437-02f0-4e02-9b86-b990dc8d7a80,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-c8876b9b-0304-406e-b16d-2f23cdee111b,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-5d3457c4-1a58-4c94-8ffb-cf659f595dc4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-922574264-172.17.0.6-1597713519195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43477,DS-85065a63-a129-4290-b288-3c10ba1dab53,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-d4539184-ddcc-4ab3-a1a6-b85c62631f48,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-ce6661d1-7b05-4837-a177-b671b455cb63,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-0aeba31d-05eb-4aae-b66d-2567ec05be2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-555efcaa-f27f-4421-ba16-ab764c5b8588,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-fdef9c90-37b2-4188-a482-6038d8b52396,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-96f08db4-a973-42cf-86b3-664de0b7b8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-a4d92500-a7e1-4550-b88b-f4c1ec05750e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-922574264-172.17.0.6-1597713519195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43477,DS-85065a63-a129-4290-b288-3c10ba1dab53,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-d4539184-ddcc-4ab3-a1a6-b85c62631f48,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-ce6661d1-7b05-4837-a177-b671b455cb63,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-0aeba31d-05eb-4aae-b66d-2567ec05be2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-555efcaa-f27f-4421-ba16-ab764c5b8588,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-fdef9c90-37b2-4188-a482-6038d8b52396,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-96f08db4-a973-42cf-86b3-664de0b7b8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-a4d92500-a7e1-4550-b88b-f4c1ec05750e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2002973762-172.17.0.6-1597713596899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43691,DS-77a4032d-5704-4790-bbaa-622b06e98a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-aec6f2f0-7150-4609-a06c-b9904cff99fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-64032afe-411e-4914-8b10-34eae44b9fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-23e853b9-b8c2-4569-8009-adb812fc3299,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-cde1591a-ed32-47bd-8016-3be319600cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-094f4531-3fbc-4342-bf08-fde0b0a2a089,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-79806c62-3a97-4126-a8bc-3f13dbc0135f,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-4e3048e1-aedb-4e3c-afaa-a9f1210e5edd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2002973762-172.17.0.6-1597713596899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43691,DS-77a4032d-5704-4790-bbaa-622b06e98a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-aec6f2f0-7150-4609-a06c-b9904cff99fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-64032afe-411e-4914-8b10-34eae44b9fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-23e853b9-b8c2-4569-8009-adb812fc3299,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-cde1591a-ed32-47bd-8016-3be319600cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-094f4531-3fbc-4342-bf08-fde0b0a2a089,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-79806c62-3a97-4126-a8bc-3f13dbc0135f,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-4e3048e1-aedb-4e3c-afaa-a9f1210e5edd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600916812-172.17.0.6-1597713633942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34310,DS-85386a97-e1e7-4369-bab9-987ad4950849,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-f5e3fd6c-47e2-4791-b9b5-8f88e52d8b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-d5f4e905-e6b8-49e7-ba14-d706fb664b14,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-2b6de973-4ce4-4a40-94de-a4ab3776444b,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-7385126e-4392-4c0c-9277-2fc4f7247fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-30163c45-2150-40f0-89ba-5ee915951531,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-af814d7c-37e6-44eb-ac02-631737da1a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-d1b4aa07-96bf-4ced-9a75-f31121dcc210,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600916812-172.17.0.6-1597713633942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34310,DS-85386a97-e1e7-4369-bab9-987ad4950849,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-f5e3fd6c-47e2-4791-b9b5-8f88e52d8b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-d5f4e905-e6b8-49e7-ba14-d706fb664b14,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-2b6de973-4ce4-4a40-94de-a4ab3776444b,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-7385126e-4392-4c0c-9277-2fc4f7247fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-30163c45-2150-40f0-89ba-5ee915951531,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-af814d7c-37e6-44eb-ac02-631737da1a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-d1b4aa07-96bf-4ced-9a75-f31121dcc210,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-502249872-172.17.0.6-1597713715291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35433,DS-88de9cce-6c5f-4a9f-9bd7-531d3daa35fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-edffc25f-be15-4586-8819-0a93e0d53b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-e6429961-d81f-4bff-9c69-12225826c602,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-1bbf9dc4-f556-48af-97b9-c1ce4bafae35,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-de58575b-8940-4f67-87e8-f25ed9a14e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-618f9466-fadc-44b1-b5ed-b6f854bbf8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-a27ff212-f222-4c8f-aa1b-3742ee66d843,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-d7fa699b-8d8d-42d9-b5ad-615aff4187c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-502249872-172.17.0.6-1597713715291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35433,DS-88de9cce-6c5f-4a9f-9bd7-531d3daa35fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-edffc25f-be15-4586-8819-0a93e0d53b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-e6429961-d81f-4bff-9c69-12225826c602,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-1bbf9dc4-f556-48af-97b9-c1ce4bafae35,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-de58575b-8940-4f67-87e8-f25ed9a14e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-618f9466-fadc-44b1-b5ed-b6f854bbf8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-a27ff212-f222-4c8f-aa1b-3742ee66d843,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-d7fa699b-8d8d-42d9-b5ad-615aff4187c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-420778845-172.17.0.6-1597714107754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39001,DS-e6ebc54b-7701-4831-ac2e-fb84694dcb96,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-8d50595e-88cc-4ec9-bb6f-6c4d241d9c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-f6c0866d-7a3a-4711-9ffd-d08749e2947e,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-48508def-ae49-44f9-8d8b-8679cc746eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-db75dae4-910e-440e-bc30-0f2e7e7f402f,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-ce7a6824-a9ac-4cbf-b474-52d9c4c21bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-c9957f2a-2834-4bfe-af0d-438659d3f2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-b749c82e-21d1-4366-acb6-bbc72a9ab58a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-420778845-172.17.0.6-1597714107754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39001,DS-e6ebc54b-7701-4831-ac2e-fb84694dcb96,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-8d50595e-88cc-4ec9-bb6f-6c4d241d9c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-f6c0866d-7a3a-4711-9ffd-d08749e2947e,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-48508def-ae49-44f9-8d8b-8679cc746eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-db75dae4-910e-440e-bc30-0f2e7e7f402f,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-ce7a6824-a9ac-4cbf-b474-52d9c4c21bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-c9957f2a-2834-4bfe-af0d-438659d3f2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-b749c82e-21d1-4366-acb6-bbc72a9ab58a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049365535-172.17.0.6-1597714143873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43093,DS-5020868b-7fe6-49bc-ad7b-149993b1db98,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-a073d562-3d62-4238-80d7-adde0e364441,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-c49836da-5836-44e1-a0c9-16b0be692cae,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-33f6b4cd-d7dd-438b-a1ea-a36e25364656,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-b24c9d24-9630-44e7-b1be-31509ffdd1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-304bd318-d5a8-4c53-9120-7d0b94ed66b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-1ae8517c-8466-4e54-bfa6-e63ffce497d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-fe23fc5e-5562-4421-9d29-a5306c90d97d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049365535-172.17.0.6-1597714143873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43093,DS-5020868b-7fe6-49bc-ad7b-149993b1db98,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-a073d562-3d62-4238-80d7-adde0e364441,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-c49836da-5836-44e1-a0c9-16b0be692cae,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-33f6b4cd-d7dd-438b-a1ea-a36e25364656,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-b24c9d24-9630-44e7-b1be-31509ffdd1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-304bd318-d5a8-4c53-9120-7d0b94ed66b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-1ae8517c-8466-4e54-bfa6-e63ffce497d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-fe23fc5e-5562-4421-9d29-a5306c90d97d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929129159-172.17.0.6-1597714198072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39341,DS-0521e2c4-9ce8-439a-bf7f-44d7b5f9f031,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-d6025286-43e6-40b4-956d-e9fca3822485,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-1bfa60cd-113c-4463-87df-f0383e6dc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-5df4a426-ddee-4a75-947d-44a269486405,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-aa6934dc-5449-44b9-b729-a0454755704d,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-76def2ae-e063-499f-84d7-a85be8e9dbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-964057b5-ddfa-49a4-861b-1d4f779bbd79,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-10b607b7-3197-4818-9d4f-a95975290a77,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929129159-172.17.0.6-1597714198072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39341,DS-0521e2c4-9ce8-439a-bf7f-44d7b5f9f031,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-d6025286-43e6-40b4-956d-e9fca3822485,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-1bfa60cd-113c-4463-87df-f0383e6dc1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-5df4a426-ddee-4a75-947d-44a269486405,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-aa6934dc-5449-44b9-b729-a0454755704d,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-76def2ae-e063-499f-84d7-a85be8e9dbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-964057b5-ddfa-49a4-861b-1d4f779bbd79,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-10b607b7-3197-4818-9d4f-a95975290a77,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-380557964-172.17.0.6-1597714272420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33351,DS-93a12c19-d16c-4df2-9bab-31ec1abac909,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-fccad8ed-394f-4113-962c-cce66b41742b,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-faa8d6dc-72ae-4ebd-a410-a5f9e3b82292,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-86a669ed-23ec-4164-bfc1-f339d6456143,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-16a7bc9c-44f7-4cfb-a848-6f1f9647abad,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-94bedc61-2126-43a8-a22f-b55361a4a3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-83b39d53-a246-497d-85d2-acfe5727f995,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-5c77560f-9e5b-45e8-b405-12782fe86f01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-380557964-172.17.0.6-1597714272420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33351,DS-93a12c19-d16c-4df2-9bab-31ec1abac909,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-fccad8ed-394f-4113-962c-cce66b41742b,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-faa8d6dc-72ae-4ebd-a410-a5f9e3b82292,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-86a669ed-23ec-4164-bfc1-f339d6456143,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-16a7bc9c-44f7-4cfb-a848-6f1f9647abad,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-94bedc61-2126-43a8-a22f-b55361a4a3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-83b39d53-a246-497d-85d2-acfe5727f995,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-5c77560f-9e5b-45e8-b405-12782fe86f01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712281608-172.17.0.6-1597714774907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40330,DS-e0081766-18e0-47a0-ae43-101120aaa49d,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-1a55c0d0-8d3a-4446-b3a1-1c1bc27d2c72,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-4a331e99-7df0-4aa4-b50e-f0421470dde0,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-d59f894d-a575-4587-8504-37515c352261,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-2276fa2b-2f14-4a9b-b919-5c9a3ea194d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-ae41374a-607f-4725-bb5e-8c74baaaf786,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-8f464658-b454-4d68-8e41-1be3dd1be8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-ba8107c7-834c-4519-9ca9-8950b6285ea5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712281608-172.17.0.6-1597714774907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40330,DS-e0081766-18e0-47a0-ae43-101120aaa49d,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-1a55c0d0-8d3a-4446-b3a1-1c1bc27d2c72,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-4a331e99-7df0-4aa4-b50e-f0421470dde0,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-d59f894d-a575-4587-8504-37515c352261,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-2276fa2b-2f14-4a9b-b919-5c9a3ea194d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-ae41374a-607f-4725-bb5e-8c74baaaf786,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-8f464658-b454-4d68-8e41-1be3dd1be8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-ba8107c7-834c-4519-9ca9-8950b6285ea5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1378381104-172.17.0.6-1597715108673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35218,DS-a9b0a487-eaea-410c-9132-2fe6ee891d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-d3db1982-f8fb-4683-864b-8fce4cbcf458,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-cae1e77b-fe05-414d-a12c-315519001471,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-3fed2c63-4cbf-4721-998a-b992bd1ac2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-2f5f19d3-83b4-47c0-8dfc-22559e9c475f,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-8632c689-c53e-4988-8242-8ce551f328f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-2a1158cd-ee59-450e-ab49-4a0d1f0a555a,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-611bf32a-5095-4a44-acd3-665500a6b7ff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1378381104-172.17.0.6-1597715108673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35218,DS-a9b0a487-eaea-410c-9132-2fe6ee891d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-d3db1982-f8fb-4683-864b-8fce4cbcf458,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-cae1e77b-fe05-414d-a12c-315519001471,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-3fed2c63-4cbf-4721-998a-b992bd1ac2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-2f5f19d3-83b4-47c0-8dfc-22559e9c475f,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-8632c689-c53e-4988-8242-8ce551f328f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-2a1158cd-ee59-450e-ab49-4a0d1f0a555a,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-611bf32a-5095-4a44-acd3-665500a6b7ff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-340651818-172.17.0.6-1597715249692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34386,DS-ab5b04ea-0d54-42f4-9a3b-b3056ba47976,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-655392a0-72ba-471b-95f4-4cd982d4721a,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-f6b142b1-ed54-477a-9907-84d7709fdaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-d22728c7-56fd-4c66-bd93-47d9508d4fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-db3d9466-99c5-433f-a158-9b37d0107889,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-353c2f6a-78ef-4ce1-9f0d-8476e2457059,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-6d20e69e-f5df-482e-8072-7263660d3ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-ab1da9ca-9243-4465-92dc-d5c2d9ed2e5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-340651818-172.17.0.6-1597715249692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34386,DS-ab5b04ea-0d54-42f4-9a3b-b3056ba47976,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-655392a0-72ba-471b-95f4-4cd982d4721a,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-f6b142b1-ed54-477a-9907-84d7709fdaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-d22728c7-56fd-4c66-bd93-47d9508d4fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-db3d9466-99c5-433f-a158-9b37d0107889,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-353c2f6a-78ef-4ce1-9f0d-8476e2457059,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-6d20e69e-f5df-482e-8072-7263660d3ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-ab1da9ca-9243-4465-92dc-d5c2d9ed2e5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600722914-172.17.0.6-1597715293210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35881,DS-f9257fa3-b1ce-48ed-8cda-c98a0871cde8,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-b38f7a7f-39d1-43ed-bffe-b823fdf58cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-60894aca-a02c-4fc3-9aa8-69a0f46037c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-4c0b1bf1-9343-445d-9bd6-c8ab17204168,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-0e0e4996-36a8-4ebc-8159-b7546f9228c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-882e881e-e39b-4a47-8ba5-ac2b4b7d07c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-28a6ff05-3341-4de4-addb-1c75a507376a,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-4d965a12-9359-47d3-a556-c1f61a7fee69,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600722914-172.17.0.6-1597715293210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35881,DS-f9257fa3-b1ce-48ed-8cda-c98a0871cde8,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-b38f7a7f-39d1-43ed-bffe-b823fdf58cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-60894aca-a02c-4fc3-9aa8-69a0f46037c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-4c0b1bf1-9343-445d-9bd6-c8ab17204168,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-0e0e4996-36a8-4ebc-8159-b7546f9228c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-882e881e-e39b-4a47-8ba5-ac2b4b7d07c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-28a6ff05-3341-4de4-addb-1c75a507376a,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-4d965a12-9359-47d3-a556-c1f61a7fee69,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-71750230-172.17.0.6-1597715582843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39468,DS-add0fb09-0489-4008-a486-3508b3ca58f7,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-91a268fc-07f3-4f9f-93c0-7970a1ad96b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-8f6ffbb3-9a55-48e4-9aa8-c45c0c869759,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-e7f42599-6696-49c6-acb0-a09511323afa,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-0ac3660d-19d4-454c-8884-4d8c7238d78a,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-11bb37a0-63c1-441e-9669-3f644bf2b153,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-8615b1c1-e753-4775-80d1-4816ee565037,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-a00a9a50-32fd-4d3d-873e-3bec6749929c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-71750230-172.17.0.6-1597715582843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39468,DS-add0fb09-0489-4008-a486-3508b3ca58f7,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-91a268fc-07f3-4f9f-93c0-7970a1ad96b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-8f6ffbb3-9a55-48e4-9aa8-c45c0c869759,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-e7f42599-6696-49c6-acb0-a09511323afa,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-0ac3660d-19d4-454c-8884-4d8c7238d78a,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-11bb37a0-63c1-441e-9669-3f644bf2b153,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-8615b1c1-e753-4775-80d1-4816ee565037,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-a00a9a50-32fd-4d3d-873e-3bec6749929c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-657258500-172.17.0.6-1597716313340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42276,DS-7bb7588a-2a7f-4e37-8830-7c82117d0979,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-e08d4e91-25ef-4ede-a5d1-7b1574b94957,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-1f825b4d-8fb1-4157-988d-b0e3540b5424,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-112cb67d-19ae-4a10-833b-62d779593a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-63e5d67b-120e-40c0-ba1f-d5594544df7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-475f1963-0da7-4c73-ae79-59fbae890356,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-9cad5b0b-6bdf-4d8c-b81a-36e576826157,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-53730c09-1290-4291-b086-6b6ba1faf2f4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-657258500-172.17.0.6-1597716313340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42276,DS-7bb7588a-2a7f-4e37-8830-7c82117d0979,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-e08d4e91-25ef-4ede-a5d1-7b1574b94957,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-1f825b4d-8fb1-4157-988d-b0e3540b5424,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-112cb67d-19ae-4a10-833b-62d779593a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-63e5d67b-120e-40c0-ba1f-d5594544df7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-475f1963-0da7-4c73-ae79-59fbae890356,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-9cad5b0b-6bdf-4d8c-b81a-36e576826157,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-53730c09-1290-4291-b086-6b6ba1faf2f4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-839740647-172.17.0.6-1597716453555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34118,DS-d2136548-11e1-42e0-86e3-ee758a7260db,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-39572416-db98-4a65-afc8-028ea2b16abb,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-7084b346-eee3-4ba7-ae0d-6ec6164fb5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-050c65e7-ff6a-4326-987d-3478156f03c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-a6e7378b-895f-4b8e-8a9f-fc2b124da091,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-a406aea3-c0f7-439e-b23d-b5a1c4c3de9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-ed1a7f97-b373-46af-9c26-16dedc255018,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-e7f7f5e8-bda9-4494-aa24-efdf7c701cca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-839740647-172.17.0.6-1597716453555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34118,DS-d2136548-11e1-42e0-86e3-ee758a7260db,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-39572416-db98-4a65-afc8-028ea2b16abb,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-7084b346-eee3-4ba7-ae0d-6ec6164fb5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-050c65e7-ff6a-4326-987d-3478156f03c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-a6e7378b-895f-4b8e-8a9f-fc2b124da091,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-a406aea3-c0f7-439e-b23d-b5a1c4c3de9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-ed1a7f97-b373-46af-9c26-16dedc255018,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-e7f7f5e8-bda9-4494-aa24-efdf7c701cca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1614922628-172.17.0.6-1597716505493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35222,DS-b8033b2e-6a6d-42e6-b150-a23938856b33,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-744d4ee9-de25-4ee0-b559-28411bb7597a,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-bbaa4985-283f-4510-9d37-07288016d0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-cef2f8b1-1825-432a-ba2e-a924a33c5f15,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-807c8444-88d6-461c-b5e2-7349e37e3ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-a8300efe-a841-443f-88c7-dbbfad241e99,DISK], DatanodeInfoWithStorage[127.0.0.1:41964,DS-4b337264-84f2-4381-95c4-b56e074a6af5,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-cf19da95-5a8b-4c3d-b5d8-9151f2046737,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1614922628-172.17.0.6-1597716505493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35222,DS-b8033b2e-6a6d-42e6-b150-a23938856b33,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-744d4ee9-de25-4ee0-b559-28411bb7597a,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-bbaa4985-283f-4510-9d37-07288016d0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-cef2f8b1-1825-432a-ba2e-a924a33c5f15,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-807c8444-88d6-461c-b5e2-7349e37e3ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-a8300efe-a841-443f-88c7-dbbfad241e99,DISK], DatanodeInfoWithStorage[127.0.0.1:41964,DS-4b337264-84f2-4381-95c4-b56e074a6af5,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-cf19da95-5a8b-4c3d-b5d8-9151f2046737,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822357220-172.17.0.6-1597716574163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46200,DS-006785e0-9c0a-4d03-b98c-dabdcde87539,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-1f4bb4f0-0703-4637-aea0-1db5e14b81b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-99659916-1ad2-4115-901d-0845ad6639f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-9ea9f9dc-f866-4d28-a408-c6a1a87f3971,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-2f877105-ee73-4a9b-8cba-1572f0c72822,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-5cfad3cf-fae4-47e6-80b3-f1bd321ff3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-9073facd-352d-4b28-99aa-ff0b307576b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-67af7ef1-8268-4f23-af68-276f7d01981f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822357220-172.17.0.6-1597716574163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46200,DS-006785e0-9c0a-4d03-b98c-dabdcde87539,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-1f4bb4f0-0703-4637-aea0-1db5e14b81b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-99659916-1ad2-4115-901d-0845ad6639f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-9ea9f9dc-f866-4d28-a408-c6a1a87f3971,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-2f877105-ee73-4a9b-8cba-1572f0c72822,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-5cfad3cf-fae4-47e6-80b3-f1bd321ff3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-9073facd-352d-4b28-99aa-ff0b307576b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-67af7ef1-8268-4f23-af68-276f7d01981f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059095551-172.17.0.6-1597716875850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34737,DS-d28cae53-e228-4eb2-8e2c-d73687603db1,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-fba02e5b-6270-457f-8ba8-16dc11ba6b00,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-8210a94c-35bf-4d6d-97f5-76c77cef03ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-ea70c3dd-733f-4346-b3b9-a72e6a15a3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-760fbdca-8191-4cb2-9325-2af89cb8182b,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-b409ab8a-2899-4f03-93e9-8076f07c7292,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-f6af52ea-f0cd-43a7-9642-a7270d580b27,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-1efe44a1-6a2e-49f4-856b-ea92c227aedb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059095551-172.17.0.6-1597716875850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34737,DS-d28cae53-e228-4eb2-8e2c-d73687603db1,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-fba02e5b-6270-457f-8ba8-16dc11ba6b00,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-8210a94c-35bf-4d6d-97f5-76c77cef03ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-ea70c3dd-733f-4346-b3b9-a72e6a15a3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-760fbdca-8191-4cb2-9325-2af89cb8182b,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-b409ab8a-2899-4f03-93e9-8076f07c7292,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-f6af52ea-f0cd-43a7-9642-a7270d580b27,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-1efe44a1-6a2e-49f4-856b-ea92c227aedb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1696906027-172.17.0.6-1597716952647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39132,DS-e14b0524-7127-4613-8d01-592f781d8b73,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-1a9a373b-9d2d-430b-ac9a-0a8f8c0e6ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-01b65397-25ee-41ec-8bea-e8f5d7630196,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-a41b9e1b-09c2-40c5-8d40-842909be4e27,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-fcfc5497-7f7d-47ce-b717-206216ba6ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-3807a032-a5be-42f4-9c5c-f5fc0abe34c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-25d6bf39-0d10-4287-92f1-d44781693835,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-0723c00c-f117-4314-beb6-7efd2760e293,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1696906027-172.17.0.6-1597716952647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39132,DS-e14b0524-7127-4613-8d01-592f781d8b73,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-1a9a373b-9d2d-430b-ac9a-0a8f8c0e6ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-01b65397-25ee-41ec-8bea-e8f5d7630196,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-a41b9e1b-09c2-40c5-8d40-842909be4e27,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-fcfc5497-7f7d-47ce-b717-206216ba6ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-3807a032-a5be-42f4-9c5c-f5fc0abe34c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-25d6bf39-0d10-4287-92f1-d44781693835,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-0723c00c-f117-4314-beb6-7efd2760e293,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.refresh.interval.ms
component: hdfs:NameNode
v1: 30000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1270978735-172.17.0.6-1597717043578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34513,DS-7d7654ff-12f3-43ff-bea7-f37e8146b39a,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-dce86d8e-7760-4f9b-b983-d2b36d9fb9db,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-6d3eeb44-8596-4180-9c2c-4f8348110293,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-a6e5acb5-14f8-4505-afc0-9e90ecc67b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-fe1bc313-1fb7-42d1-965a-e95f20a268e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-def0f611-9adb-456e-aa9e-744f39a18622,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-8ccabeaa-4903-417c-9a28-c818b5d21dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-e28ffdfd-474b-4c3e-9192-5b45ef8ddb85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1270978735-172.17.0.6-1597717043578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34513,DS-7d7654ff-12f3-43ff-bea7-f37e8146b39a,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-dce86d8e-7760-4f9b-b983-d2b36d9fb9db,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-6d3eeb44-8596-4180-9c2c-4f8348110293,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-a6e5acb5-14f8-4505-afc0-9e90ecc67b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-fe1bc313-1fb7-42d1-965a-e95f20a268e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-def0f611-9adb-456e-aa9e-744f39a18622,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-8ccabeaa-4903-417c-9a28-c818b5d21dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-e28ffdfd-474b-4c3e-9192-5b45ef8ddb85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 21 out of 50
result: false positive !!!
Total execution time in seconds : 6845
