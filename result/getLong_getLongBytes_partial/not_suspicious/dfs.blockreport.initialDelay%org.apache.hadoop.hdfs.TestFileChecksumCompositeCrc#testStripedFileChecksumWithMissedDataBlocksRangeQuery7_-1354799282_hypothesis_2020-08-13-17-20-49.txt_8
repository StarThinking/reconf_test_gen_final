reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-506301239-172.17.0.21-1597339345338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40731,DS-de287a60-6577-435d-843d-94106dbd9eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-72008ae9-d69f-40b6-8c2e-29bb8beaf3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-de6eea84-becd-4f64-b336-fb6a2a211bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-535a8444-cadf-4c4a-b9df-485f0dbf4ade,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-494f0d98-7f40-4d01-b09c-e8449143f1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-40e73390-856d-42f7-9495-7991926b63fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-451a6425-5fee-4f66-baf7-a24279fbeacf,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-08fd35c4-cc24-4309-b462-c2a5ead2b431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-506301239-172.17.0.21-1597339345338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40731,DS-de287a60-6577-435d-843d-94106dbd9eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-72008ae9-d69f-40b6-8c2e-29bb8beaf3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-de6eea84-becd-4f64-b336-fb6a2a211bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-535a8444-cadf-4c4a-b9df-485f0dbf4ade,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-494f0d98-7f40-4d01-b09c-e8449143f1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-40e73390-856d-42f7-9495-7991926b63fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-451a6425-5fee-4f66-baf7-a24279fbeacf,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-08fd35c4-cc24-4309-b462-c2a5ead2b431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851380787-172.17.0.21-1597339696586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36250,DS-b6cdf518-889a-4f07-8c28-2194a5e29ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-29cb2b9c-0b81-47f3-9673-6140793d7285,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-930d6621-1ef3-446c-81b5-4fdc3f8ab2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-07ef691e-26a4-426d-a985-93cc03a8aa22,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-0c1326ee-f818-44c9-9548-459682e5d937,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-52362f87-318e-4e70-8747-fe6bd39a2117,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-bdbfb88d-664a-4b2b-b131-c44af2cebf07,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-195dd6c9-0e0e-4e8f-9780-a4ad37af1206,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851380787-172.17.0.21-1597339696586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36250,DS-b6cdf518-889a-4f07-8c28-2194a5e29ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-29cb2b9c-0b81-47f3-9673-6140793d7285,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-930d6621-1ef3-446c-81b5-4fdc3f8ab2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-07ef691e-26a4-426d-a985-93cc03a8aa22,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-0c1326ee-f818-44c9-9548-459682e5d937,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-52362f87-318e-4e70-8747-fe6bd39a2117,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-bdbfb88d-664a-4b2b-b131-c44af2cebf07,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-195dd6c9-0e0e-4e8f-9780-a4ad37af1206,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1136506742-172.17.0.21-1597339778703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43134,DS-55b8f8ac-4f07-4cab-8e03-40334e100f27,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-395bcf75-89a9-4d7d-b8e1-a11ae6a5dfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-e58fdd9b-7d34-4d46-95db-9c3aeadcc199,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-cb8c0f12-154a-469c-a013-0ae2bd168335,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-b7d94574-8e1f-4441-9af2-851eaef2d269,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-08a387cf-a7c1-469d-968f-f964ea85f586,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-1eb7e9fb-8853-44e6-ac43-33180cb462b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-2238e415-6f6a-42e3-a798-6187940180f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1136506742-172.17.0.21-1597339778703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43134,DS-55b8f8ac-4f07-4cab-8e03-40334e100f27,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-395bcf75-89a9-4d7d-b8e1-a11ae6a5dfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-e58fdd9b-7d34-4d46-95db-9c3aeadcc199,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-cb8c0f12-154a-469c-a013-0ae2bd168335,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-b7d94574-8e1f-4441-9af2-851eaef2d269,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-08a387cf-a7c1-469d-968f-f964ea85f586,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-1eb7e9fb-8853-44e6-ac43-33180cb462b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-2238e415-6f6a-42e3-a798-6187940180f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1143645557-172.17.0.21-1597339883916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39138,DS-b4c2c58a-34a5-4998-9d55-4c2eb9b8cffa,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-2d0585a9-3d07-4afe-bafc-b1aa8296c137,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-efb8e635-47a5-40a9-aed9-756d238c4713,DISK], DatanodeInfoWithStorage[127.0.0.1:36288,DS-83fbfaaf-f083-4431-889c-694ceb02f6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-e105ae45-330b-4058-980d-f4aa3b69ecf7,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-6da47d4a-3b65-415f-888f-4b2417f20346,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-c139a480-1d53-4fdb-b080-e7ca05a41d35,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-2a8a566b-6f90-483c-895d-c605231bbb32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1143645557-172.17.0.21-1597339883916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39138,DS-b4c2c58a-34a5-4998-9d55-4c2eb9b8cffa,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-2d0585a9-3d07-4afe-bafc-b1aa8296c137,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-efb8e635-47a5-40a9-aed9-756d238c4713,DISK], DatanodeInfoWithStorage[127.0.0.1:36288,DS-83fbfaaf-f083-4431-889c-694ceb02f6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-e105ae45-330b-4058-980d-f4aa3b69ecf7,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-6da47d4a-3b65-415f-888f-4b2417f20346,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-c139a480-1d53-4fdb-b080-e7ca05a41d35,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-2a8a566b-6f90-483c-895d-c605231bbb32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726977755-172.17.0.21-1597339921733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40550,DS-e05e297d-7836-4f2d-8300-143f283950e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-4be83180-7222-40c6-a3b1-6a0ad15515c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-61936eeb-4117-4b15-bf66-1cf1a5b503fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-880a6417-deee-438a-aed9-47efdbfa8ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-eaf955a4-aac6-43c0-9a22-4b2cb57a4dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-0bc9622b-ba3a-4db4-9911-1aa3e4058bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-1f5265ff-fc91-4447-8605-ccd05f7ddd35,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-9944d64d-4745-4f33-bce6-0e92b0a8d4bc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726977755-172.17.0.21-1597339921733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40550,DS-e05e297d-7836-4f2d-8300-143f283950e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-4be83180-7222-40c6-a3b1-6a0ad15515c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-61936eeb-4117-4b15-bf66-1cf1a5b503fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-880a6417-deee-438a-aed9-47efdbfa8ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-eaf955a4-aac6-43c0-9a22-4b2cb57a4dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-0bc9622b-ba3a-4db4-9911-1aa3e4058bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-1f5265ff-fc91-4447-8605-ccd05f7ddd35,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-9944d64d-4745-4f33-bce6-0e92b0a8d4bc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1112069416-172.17.0.21-1597340003775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42787,DS-0b8ce219-734e-4e28-94bf-26de4525c307,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-bf94ba95-9c2b-46ce-93ad-5eba0c17116f,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-5ad98ad0-7ddb-477e-93e4-ae5cede6070f,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-c998fb7a-25a3-4037-ade7-e8a27eb1b992,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-c774c755-3512-4009-9600-d66d8593f9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36598,DS-89463baf-cb37-428e-ae37-f673ca91adee,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-c836ad74-3011-4848-aa49-68a2e7e99afc,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-5b542b53-1ec1-406e-a4e6-080affea25d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1112069416-172.17.0.21-1597340003775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42787,DS-0b8ce219-734e-4e28-94bf-26de4525c307,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-bf94ba95-9c2b-46ce-93ad-5eba0c17116f,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-5ad98ad0-7ddb-477e-93e4-ae5cede6070f,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-c998fb7a-25a3-4037-ade7-e8a27eb1b992,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-c774c755-3512-4009-9600-d66d8593f9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36598,DS-89463baf-cb37-428e-ae37-f673ca91adee,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-c836ad74-3011-4848-aa49-68a2e7e99afc,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-5b542b53-1ec1-406e-a4e6-080affea25d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1967038160-172.17.0.21-1597340280616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45504,DS-33fac08e-2358-4a30-8a3c-423ef829d61a,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-a2d1eb67-5b0e-47d3-bff4-541d4ce34bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-9c363eda-dac5-4cc9-9d2d-afffc66d8652,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-585d5b40-6ba5-4180-bcf8-c5783a5c9d50,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-879b2d41-cf5a-400f-a3da-e33e749fd8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-2673937e-19a7-4d3b-bbe2-18e4da27231b,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-633a2b30-e2a5-444c-8204-8a3f0f82146d,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-a3087846-295f-4aa1-915c-659a4a3a9931,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1967038160-172.17.0.21-1597340280616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45504,DS-33fac08e-2358-4a30-8a3c-423ef829d61a,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-a2d1eb67-5b0e-47d3-bff4-541d4ce34bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-9c363eda-dac5-4cc9-9d2d-afffc66d8652,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-585d5b40-6ba5-4180-bcf8-c5783a5c9d50,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-879b2d41-cf5a-400f-a3da-e33e749fd8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-2673937e-19a7-4d3b-bbe2-18e4da27231b,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-633a2b30-e2a5-444c-8204-8a3f0f82146d,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-a3087846-295f-4aa1-915c-659a4a3a9931,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467255359-172.17.0.21-1597340538058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42218,DS-1b2486e0-67b4-4713-9d7a-4158b5eee372,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-6fc666c3-5bf6-4131-a495-640fc811ea32,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-29ba9d08-b297-4351-9fd1-ad25de07adab,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-abc1b3b1-fe5f-481d-bab9-c826742185f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-447f0e24-ea5c-4fd4-a7a6-9ecfb50bd4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-7209b834-3abb-494d-9da4-a433b62e1db0,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-4e2047c8-bb2e-4c1d-9d32-2b96f61f947b,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-8cf5599a-0bff-49e4-b906-942394d285a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467255359-172.17.0.21-1597340538058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42218,DS-1b2486e0-67b4-4713-9d7a-4158b5eee372,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-6fc666c3-5bf6-4131-a495-640fc811ea32,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-29ba9d08-b297-4351-9fd1-ad25de07adab,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-abc1b3b1-fe5f-481d-bab9-c826742185f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-447f0e24-ea5c-4fd4-a7a6-9ecfb50bd4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-7209b834-3abb-494d-9da4-a433b62e1db0,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-4e2047c8-bb2e-4c1d-9d32-2b96f61f947b,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-8cf5599a-0bff-49e4-b906-942394d285a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314085813-172.17.0.21-1597340580212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39617,DS-ab7a418e-cdf6-46b4-8ef9-3aa4d933b864,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-2b0de978-c937-49c0-8ea5-8c1047034f67,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-9d4e3fa2-889b-43ad-8b9f-39586785cf42,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-24dc7bf1-c7d0-4c70-95c7-e2440adc3628,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-b868e597-39d9-4fae-9a1e-bd3a7c0e3ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-dee379f2-c7a6-4983-9390-6d2af449b017,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-8e628d36-aa89-4a10-87da-3f8d41d3ce0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-1f6d16cb-9f97-4977-9903-78af82110d09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314085813-172.17.0.21-1597340580212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39617,DS-ab7a418e-cdf6-46b4-8ef9-3aa4d933b864,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-2b0de978-c937-49c0-8ea5-8c1047034f67,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-9d4e3fa2-889b-43ad-8b9f-39586785cf42,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-24dc7bf1-c7d0-4c70-95c7-e2440adc3628,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-b868e597-39d9-4fae-9a1e-bd3a7c0e3ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-dee379f2-c7a6-4983-9390-6d2af449b017,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-8e628d36-aa89-4a10-87da-3f8d41d3ce0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-1f6d16cb-9f97-4977-9903-78af82110d09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-233354950-172.17.0.21-1597340793162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44602,DS-32732d5a-7751-4bfa-8c51-86789ff2802a,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-20108464-561c-4d07-b211-06413a550736,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-5c962c5d-05fb-4a19-906b-0c727c52c9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-079f2eb9-73bb-46e8-9121-cbc98d3e5dce,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-4e03c8ee-a6d8-4493-a99d-abae898fe842,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-a8e87631-1255-486c-97d8-1f7cfa6d63b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-80c716a0-71a3-453a-ae81-a2181c3ff01a,DISK], DatanodeInfoWithStorage[127.0.0.1:39174,DS-b963aac6-d2d9-4290-ba0a-354c277b0397,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-233354950-172.17.0.21-1597340793162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44602,DS-32732d5a-7751-4bfa-8c51-86789ff2802a,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-20108464-561c-4d07-b211-06413a550736,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-5c962c5d-05fb-4a19-906b-0c727c52c9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-079f2eb9-73bb-46e8-9121-cbc98d3e5dce,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-4e03c8ee-a6d8-4493-a99d-abae898fe842,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-a8e87631-1255-486c-97d8-1f7cfa6d63b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-80c716a0-71a3-453a-ae81-a2181c3ff01a,DISK], DatanodeInfoWithStorage[127.0.0.1:39174,DS-b963aac6-d2d9-4290-ba0a-354c277b0397,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-471345556-172.17.0.21-1597340835961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35857,DS-8f020e0d-1dda-45d4-a302-39960b6d3f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-ef4e4127-fac4-4136-a6ef-78dce0179683,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-68155dfe-ce9e-4714-add0-adf305e95006,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-7c9bc575-1b2f-44c9-b0f9-4a3ba141d1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-da559803-8572-4f1c-b846-cfec2d066ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-347c8aa3-b28c-4d08-89c2-baafa759fe6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-6f98c64f-0f00-4f76-be6c-4e88fd5de8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-ee07b5e7-cb02-4a9f-88a3-794ea7558c6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-471345556-172.17.0.21-1597340835961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35857,DS-8f020e0d-1dda-45d4-a302-39960b6d3f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-ef4e4127-fac4-4136-a6ef-78dce0179683,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-68155dfe-ce9e-4714-add0-adf305e95006,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-7c9bc575-1b2f-44c9-b0f9-4a3ba141d1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-da559803-8572-4f1c-b846-cfec2d066ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-347c8aa3-b28c-4d08-89c2-baafa759fe6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-6f98c64f-0f00-4f76-be6c-4e88fd5de8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-ee07b5e7-cb02-4a9f-88a3-794ea7558c6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016564838-172.17.0.21-1597341373900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45972,DS-979f6361-9b31-4ce6-84f2-2a9a2afa61f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-fd58130d-7b0e-452c-8e8d-ab48a48bb323,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-01bdc6c7-d9f1-46d4-ab60-eeb918be802e,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-c625e0b9-0682-446d-ac0a-ced39016320d,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-7dd50d50-df64-40b8-83cf-5d3ff5642141,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-7f87f258-7748-4c00-9ec6-8230cc204408,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-87bfb9e7-48c4-44ba-b330-e32ea8791e75,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-212266e3-160d-4285-8123-0c077e60ab6d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016564838-172.17.0.21-1597341373900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45972,DS-979f6361-9b31-4ce6-84f2-2a9a2afa61f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-fd58130d-7b0e-452c-8e8d-ab48a48bb323,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-01bdc6c7-d9f1-46d4-ab60-eeb918be802e,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-c625e0b9-0682-446d-ac0a-ced39016320d,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-7dd50d50-df64-40b8-83cf-5d3ff5642141,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-7f87f258-7748-4c00-9ec6-8230cc204408,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-87bfb9e7-48c4-44ba-b330-e32ea8791e75,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-212266e3-160d-4285-8123-0c077e60ab6d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913815943-172.17.0.21-1597341516439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37591,DS-e84b1359-19d2-4e01-b9bb-32391584f419,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-01c51f7a-c78e-4d81-bd5c-ee43a4c12468,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-3f0ffd69-3aa0-43d2-891d-5db6e044d03b,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-1357caf0-1c14-41fd-8c05-4643aa33c7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-6610a3ca-64b6-40dd-9f61-18765270d01f,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-86908a62-8a2f-4216-9dfb-1620340843a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-021e58ba-e251-4eab-8d28-c84bb091e706,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-a4254154-13e0-4d1e-9715-8871bc7fc821,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-913815943-172.17.0.21-1597341516439:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37591,DS-e84b1359-19d2-4e01-b9bb-32391584f419,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-01c51f7a-c78e-4d81-bd5c-ee43a4c12468,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-3f0ffd69-3aa0-43d2-891d-5db6e044d03b,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-1357caf0-1c14-41fd-8c05-4643aa33c7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-6610a3ca-64b6-40dd-9f61-18765270d01f,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-86908a62-8a2f-4216-9dfb-1620340843a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-021e58ba-e251-4eab-8d28-c84bb091e706,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-a4254154-13e0-4d1e-9715-8871bc7fc821,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351971926-172.17.0.21-1597341630390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33744,DS-65e135ec-5678-4384-9975-c8fc5bbcb13d,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-df5366ca-9f40-42fd-ae25-b008dd3881ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-6b2f301c-5d70-42d5-a1d4-a01907377eea,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-826a0f1e-4cf3-42e2-a255-9f040b4736e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-ff7deb82-f9af-4f3d-bea2-1913f0d3d86c,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-913cf831-eed0-4e02-82ed-f5442baefe06,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-b1b8e200-6829-44f7-8e91-23529be6dc09,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-6b1d109e-eaa4-4570-88cb-a87a936efd4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351971926-172.17.0.21-1597341630390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33744,DS-65e135ec-5678-4384-9975-c8fc5bbcb13d,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-df5366ca-9f40-42fd-ae25-b008dd3881ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-6b2f301c-5d70-42d5-a1d4-a01907377eea,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-826a0f1e-4cf3-42e2-a255-9f040b4736e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-ff7deb82-f9af-4f3d-bea2-1913f0d3d86c,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-913cf831-eed0-4e02-82ed-f5442baefe06,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-b1b8e200-6829-44f7-8e91-23529be6dc09,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-6b1d109e-eaa4-4570-88cb-a87a936efd4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1514334813-172.17.0.21-1597341660149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44144,DS-0012b34d-5f2d-4094-9049-449d1cccf071,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-b19c0039-d93a-4f25-baa8-60e9a0dfb45e,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-a8dae598-2262-4cfc-946d-57c114da3fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-e2f74d9e-67b5-4915-a3eb-9cca9d760380,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-6671e727-1be6-4c7d-8ba6-fa00b804119a,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-9407fc23-bfe2-4a38-b05c-ec3b9a8cd632,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-b89e5fcd-88ce-47c4-b761-fd4eba1a38ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-b5f1242b-745f-48fe-ac5e-2e594a017d54,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1514334813-172.17.0.21-1597341660149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44144,DS-0012b34d-5f2d-4094-9049-449d1cccf071,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-b19c0039-d93a-4f25-baa8-60e9a0dfb45e,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-a8dae598-2262-4cfc-946d-57c114da3fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-e2f74d9e-67b5-4915-a3eb-9cca9d760380,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-6671e727-1be6-4c7d-8ba6-fa00b804119a,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-9407fc23-bfe2-4a38-b05c-ec3b9a8cd632,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-b89e5fcd-88ce-47c4-b761-fd4eba1a38ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-b5f1242b-745f-48fe-ac5e-2e594a017d54,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-897464569-172.17.0.21-1597341765179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41340,DS-00ce7479-a917-4457-b01f-3bba79349c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-51b503a4-a2f5-4d3b-a950-c5a046240276,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-f5f9ccfc-9fd1-4412-8d4f-604d86829efc,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-3887fcc7-6584-4558-a323-0daef54d7a12,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-2b816dff-571a-4248-86fb-66fdd2fe72fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-2d6b36bb-75f0-44bd-a531-ec3059ee0c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-e013cd7e-9356-4c1a-9654-65a9a28cc0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-24a3f2e8-49fe-4a4f-9c35-07e2b2144839,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-897464569-172.17.0.21-1597341765179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41340,DS-00ce7479-a917-4457-b01f-3bba79349c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-51b503a4-a2f5-4d3b-a950-c5a046240276,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-f5f9ccfc-9fd1-4412-8d4f-604d86829efc,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-3887fcc7-6584-4558-a323-0daef54d7a12,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-2b816dff-571a-4248-86fb-66fdd2fe72fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-2d6b36bb-75f0-44bd-a531-ec3059ee0c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-e013cd7e-9356-4c1a-9654-65a9a28cc0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-24a3f2e8-49fe-4a4f-9c35-07e2b2144839,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1511509022-172.17.0.21-1597341841586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38552,DS-6e3a6e17-a477-4d3e-aaa4-0969ddbf6a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-9a4ceb27-3bc3-41ac-871f-9216364b8e79,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-ef343be1-e31d-44c6-8889-011478facbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-5a7cd058-162b-4f23-a263-758f217be217,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-a896117f-5d79-4a27-b877-b070f61a3e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-83e29887-7464-4c9e-bb0e-26ee57fbfc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-5f02791a-8fc6-42b1-b27e-8f5e7ef8771c,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-f4bb6dac-4ca2-4636-b633-ff319e08ec12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1511509022-172.17.0.21-1597341841586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38552,DS-6e3a6e17-a477-4d3e-aaa4-0969ddbf6a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-9a4ceb27-3bc3-41ac-871f-9216364b8e79,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-ef343be1-e31d-44c6-8889-011478facbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-5a7cd058-162b-4f23-a263-758f217be217,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-a896117f-5d79-4a27-b877-b070f61a3e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-83e29887-7464-4c9e-bb0e-26ee57fbfc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-5f02791a-8fc6-42b1-b27e-8f5e7ef8771c,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-f4bb6dac-4ca2-4636-b633-ff319e08ec12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-402304532-172.17.0.21-1597341884926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34433,DS-aadff620-806e-4561-be4c-31f7db94c209,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-eb565289-045a-4c4d-a700-4e518330bfdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-7c7623c4-f1fd-4031-866e-a605258479b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-b6aa32d3-7529-408b-bb2a-cbb4a77e3051,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-17c37a5b-7b0a-4f77-bd6b-e9597c3087f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-2240d284-4579-4b41-9f81-949b39e52e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-db8184be-3019-4d8d-a3d6-4cb40806a621,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-60948bce-cb6b-4602-b93f-a2172e45db52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-402304532-172.17.0.21-1597341884926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34433,DS-aadff620-806e-4561-be4c-31f7db94c209,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-eb565289-045a-4c4d-a700-4e518330bfdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-7c7623c4-f1fd-4031-866e-a605258479b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-b6aa32d3-7529-408b-bb2a-cbb4a77e3051,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-17c37a5b-7b0a-4f77-bd6b-e9597c3087f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-2240d284-4579-4b41-9f81-949b39e52e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-db8184be-3019-4d8d-a3d6-4cb40806a621,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-60948bce-cb6b-4602-b93f-a2172e45db52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997065504-172.17.0.21-1597341965230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46863,DS-3cd182ab-5695-4549-a130-718912260bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-8f1a9c85-879a-48df-bd35-b21963aad2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-b1d5c980-5a8b-419a-b262-1924a659d1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-0934b6a6-7a24-403b-b7b9-0070afdf287d,DISK], DatanodeInfoWithStorage[127.0.0.1:37810,DS-16777ba4-b0fd-4f70-a4fc-ebd76252ee89,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-228508d8-b611-409c-a9cc-c8d19e609fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-d5f377c7-a65e-489c-b85d-316fb079f501,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-3c34dd94-e93b-4f50-9cba-644b03199a27,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997065504-172.17.0.21-1597341965230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46863,DS-3cd182ab-5695-4549-a130-718912260bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-8f1a9c85-879a-48df-bd35-b21963aad2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-b1d5c980-5a8b-419a-b262-1924a659d1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-0934b6a6-7a24-403b-b7b9-0070afdf287d,DISK], DatanodeInfoWithStorage[127.0.0.1:37810,DS-16777ba4-b0fd-4f70-a4fc-ebd76252ee89,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-228508d8-b611-409c-a9cc-c8d19e609fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-d5f377c7-a65e-489c-b85d-316fb079f501,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-3c34dd94-e93b-4f50-9cba-644b03199a27,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-224289915-172.17.0.21-1597342001496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35621,DS-49700151-fd69-4c81-9ff3-bee50f0ca437,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-4440dacc-84f7-43ed-a79f-0accf395413f,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-90dc23b6-9d87-4bfe-97b1-09467ab1c0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-0db7861f-d327-4550-a3fe-91930549735c,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-22c1a3a9-5fc0-48ca-a0ae-049b3d7a9695,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-12b9ee4c-b228-44b8-bd0c-bc654bda0b46,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-a65b94da-5a75-4678-9c9b-2138dd8192a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-da0c1b67-ba59-4a94-a82e-9b47f972a9e9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-224289915-172.17.0.21-1597342001496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35621,DS-49700151-fd69-4c81-9ff3-bee50f0ca437,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-4440dacc-84f7-43ed-a79f-0accf395413f,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-90dc23b6-9d87-4bfe-97b1-09467ab1c0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-0db7861f-d327-4550-a3fe-91930549735c,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-22c1a3a9-5fc0-48ca-a0ae-049b3d7a9695,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-12b9ee4c-b228-44b8-bd0c-bc654bda0b46,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-a65b94da-5a75-4678-9c9b-2138dd8192a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-da0c1b67-ba59-4a94-a82e-9b47f972a9e9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512184141-172.17.0.21-1597342033821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41243,DS-c94f4924-9073-45f5-af2b-f3f1e726f205,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-ba07f69b-5831-48db-890f-8d2d237d705f,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-cfd0d89a-e64b-431d-908b-1ba833724912,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-ba1ca572-f01d-45f5-9ff3-f9f3d8a0b568,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-ef4dbea6-9042-48db-866b-ccb13bfc6088,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-907dfe97-3bc2-476d-85d7-5964b6d24f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-e77625de-8360-4a5a-882b-479cf556581b,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-a3458249-4017-415c-8276-80a529317621,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512184141-172.17.0.21-1597342033821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41243,DS-c94f4924-9073-45f5-af2b-f3f1e726f205,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-ba07f69b-5831-48db-890f-8d2d237d705f,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-cfd0d89a-e64b-431d-908b-1ba833724912,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-ba1ca572-f01d-45f5-9ff3-f9f3d8a0b568,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-ef4dbea6-9042-48db-866b-ccb13bfc6088,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-907dfe97-3bc2-476d-85d7-5964b6d24f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-e77625de-8360-4a5a-882b-479cf556581b,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-a3458249-4017-415c-8276-80a529317621,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-253171235-172.17.0.21-1597342262557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44852,DS-6d3be692-6231-4a3c-936a-fcb901962128,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-c5fc3df7-4e0c-41a3-a6de-93b0a25637e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-8e339c68-db01-4d54-83d9-ec19499dbfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41033,DS-1a524e4a-4d4d-4473-9d66-d75240824bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-81b77324-e4d5-4ba8-b062-8adebdcc10ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-88f4dfd0-62a4-4a94-9906-63c7394d4132,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-84d28b93-27a7-4af7-b694-3ee827e4061e,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-93fd6225-a1e0-454a-8d9a-8311e685fbaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-253171235-172.17.0.21-1597342262557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44852,DS-6d3be692-6231-4a3c-936a-fcb901962128,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-c5fc3df7-4e0c-41a3-a6de-93b0a25637e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-8e339c68-db01-4d54-83d9-ec19499dbfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41033,DS-1a524e4a-4d4d-4473-9d66-d75240824bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-81b77324-e4d5-4ba8-b062-8adebdcc10ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-88f4dfd0-62a4-4a94-9906-63c7394d4132,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-84d28b93-27a7-4af7-b694-3ee827e4061e,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-93fd6225-a1e0-454a-8d9a-8311e685fbaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1614274624-172.17.0.21-1597342301693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34059,DS-a963bd90-f6e4-44fe-9a5c-742cff2c6fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-61b08a70-b031-4a7e-86df-74c97b220fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-d2b50e38-b0c5-4b8f-beb8-484b4019586c,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-2f9f1204-efc7-443b-89ab-e917f4ab3dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-af242ec0-e7f9-4385-8ee3-ef70a61078f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-78398aa2-c661-4cd4-86e9-f847dcbad842,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-6b994243-33f9-4756-be75-05df3defd4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-a0d1fc3e-261a-4ad7-8887-cf8ee61c65d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1614274624-172.17.0.21-1597342301693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34059,DS-a963bd90-f6e4-44fe-9a5c-742cff2c6fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-61b08a70-b031-4a7e-86df-74c97b220fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-d2b50e38-b0c5-4b8f-beb8-484b4019586c,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-2f9f1204-efc7-443b-89ab-e917f4ab3dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-af242ec0-e7f9-4385-8ee3-ef70a61078f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-78398aa2-c661-4cd4-86e9-f847dcbad842,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-6b994243-33f9-4756-be75-05df3defd4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-a0d1fc3e-261a-4ad7-8887-cf8ee61c65d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2107455326-172.17.0.21-1597342458371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46455,DS-60d47efa-2064-4597-8a9d-67cc8acf8c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-06d05cfc-7d95-4764-9e00-411f50f2d99e,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-ca735e59-9bfe-45b8-a828-5f3a111f194b,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-0ac870bb-0c47-43d7-b0da-e677071ae97a,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-1a24e4d1-95b9-4a85-b9c0-885ae876f04d,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-e7d48b3b-7f02-4390-bb29-539eeb84fac3,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-c8fff6f2-8b02-4bbb-9d07-07584574df69,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-f0e2a41f-daee-4750-9fa7-e8eaf2355cb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2107455326-172.17.0.21-1597342458371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46455,DS-60d47efa-2064-4597-8a9d-67cc8acf8c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-06d05cfc-7d95-4764-9e00-411f50f2d99e,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-ca735e59-9bfe-45b8-a828-5f3a111f194b,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-0ac870bb-0c47-43d7-b0da-e677071ae97a,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-1a24e4d1-95b9-4a85-b9c0-885ae876f04d,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-e7d48b3b-7f02-4390-bb29-539eeb84fac3,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-c8fff6f2-8b02-4bbb-9d07-07584574df69,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-f0e2a41f-daee-4750-9fa7-e8eaf2355cb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-666495334-172.17.0.21-1597342544112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33293,DS-2d8f67b3-5f23-405e-a2d6-d7e7657462cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-a11f1f4f-9ad7-48a4-b97b-f6fb51b14f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-544f20e7-f3a1-4167-b1c5-2c7db45c8acb,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-607ba0eb-a393-4878-9f18-066ebb4077af,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-e8f7b968-55c5-474f-8039-3be97bd31e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-b3ca5779-d954-47d2-b2c9-a1391369cb01,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-969cec03-5e50-483b-992b-ea5037572e65,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-1b988306-51ce-4bf5-ae6f-2b9de234b54e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-666495334-172.17.0.21-1597342544112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33293,DS-2d8f67b3-5f23-405e-a2d6-d7e7657462cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-a11f1f4f-9ad7-48a4-b97b-f6fb51b14f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-544f20e7-f3a1-4167-b1c5-2c7db45c8acb,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-607ba0eb-a393-4878-9f18-066ebb4077af,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-e8f7b968-55c5-474f-8039-3be97bd31e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-b3ca5779-d954-47d2-b2c9-a1391369cb01,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-969cec03-5e50-483b-992b-ea5037572e65,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-1b988306-51ce-4bf5-ae6f-2b9de234b54e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1068990902-172.17.0.21-1597342618106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41237,DS-17931f8a-d71e-488d-a265-cb5475554b48,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-485e0d00-0a85-4030-8010-721548b494bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-c3e46c96-4f7b-42c1-9715-24cab32352b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-a982fb3c-0a1f-42e0-ad9a-5cfb12c22ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-23dd672b-00fb-4a15-bcd0-2b3eee724d73,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-7a908663-0821-43d3-9d41-90e6c1597ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-e84cf7ac-7d48-437d-a81f-264f1fc05747,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-1fe86020-c0ba-4a3a-8140-2ffca15493fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1068990902-172.17.0.21-1597342618106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41237,DS-17931f8a-d71e-488d-a265-cb5475554b48,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-485e0d00-0a85-4030-8010-721548b494bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-c3e46c96-4f7b-42c1-9715-24cab32352b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-a982fb3c-0a1f-42e0-ad9a-5cfb12c22ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-23dd672b-00fb-4a15-bcd0-2b3eee724d73,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-7a908663-0821-43d3-9d41-90e6c1597ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-e84cf7ac-7d48-437d-a81f-264f1fc05747,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-1fe86020-c0ba-4a3a-8140-2ffca15493fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-474794836-172.17.0.21-1597342658469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37139,DS-93dda298-c8aa-4064-a222-a68bd6b8dd66,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-6817333a-9233-46a0-ad2d-17b4d7b8bc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-02c3ef2a-e2f8-44aa-b1a5-8125287af1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-80e677e2-5347-4519-838c-3965eda382ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-3c495325-000f-4a52-8108-2d4a70c38272,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-a635a13d-6017-4c0a-a21f-9467b7e1d273,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-ff421f2a-795a-4391-a987-60e322626c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-1342095b-f9ea-4b34-a804-862a4579f8f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-474794836-172.17.0.21-1597342658469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37139,DS-93dda298-c8aa-4064-a222-a68bd6b8dd66,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-6817333a-9233-46a0-ad2d-17b4d7b8bc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-02c3ef2a-e2f8-44aa-b1a5-8125287af1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-80e677e2-5347-4519-838c-3965eda382ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-3c495325-000f-4a52-8108-2d4a70c38272,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-a635a13d-6017-4c0a-a21f-9467b7e1d273,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-ff421f2a-795a-4391-a987-60e322626c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-1342095b-f9ea-4b34-a804-862a4579f8f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1531073214-172.17.0.21-1597343220345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37177,DS-64cc463c-33bd-46a5-941a-b5f47af59892,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-cd96e333-f8ba-4b44-b7ae-a229e5d40a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-6a4bb0d2-12be-4e61-a42f-1069344f590a,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-0644955c-f1f6-4e98-8734-fdf34a5e9630,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-6e914551-ee0d-4149-b2c1-c72c72f60f31,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-15c951f8-cf47-4f9a-9c47-c594aac6a012,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-c594fd92-f7b7-40f8-99c7-3ca953a30ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-1272d6a2-5701-4568-a349-d2ed20f2a403,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1531073214-172.17.0.21-1597343220345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37177,DS-64cc463c-33bd-46a5-941a-b5f47af59892,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-cd96e333-f8ba-4b44-b7ae-a229e5d40a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-6a4bb0d2-12be-4e61-a42f-1069344f590a,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-0644955c-f1f6-4e98-8734-fdf34a5e9630,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-6e914551-ee0d-4149-b2c1-c72c72f60f31,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-15c951f8-cf47-4f9a-9c47-c594aac6a012,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-c594fd92-f7b7-40f8-99c7-3ca953a30ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-1272d6a2-5701-4568-a349-d2ed20f2a403,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-593176913-172.17.0.21-1597343333525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34789,DS-2dfb4afb-febe-4a2d-9456-ee2a6498bf74,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-da343e6f-5b8a-4b33-a893-5cc53cffe232,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-712b5a8a-6093-49a3-b0b5-9b75ce919379,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-495098fc-e629-4c80-9d65-871bfe595505,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-418acd77-c97d-4871-890f-b0f3992d020e,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-6c7480aa-3da4-46ae-81cc-ed373b1e1ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-e853b12f-53bc-4499-8d90-d486244dcd25,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-38341d72-7a87-43b2-a571-248d0a9c18d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-593176913-172.17.0.21-1597343333525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34789,DS-2dfb4afb-febe-4a2d-9456-ee2a6498bf74,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-da343e6f-5b8a-4b33-a893-5cc53cffe232,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-712b5a8a-6093-49a3-b0b5-9b75ce919379,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-495098fc-e629-4c80-9d65-871bfe595505,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-418acd77-c97d-4871-890f-b0f3992d020e,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-6c7480aa-3da4-46ae-81cc-ed373b1e1ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-e853b12f-53bc-4499-8d90-d486244dcd25,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-38341d72-7a87-43b2-a571-248d0a9c18d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-696535894-172.17.0.21-1597343370723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35933,DS-ea711ba1-1622-4760-b241-9062510da84e,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-eccc727d-caeb-41b1-882b-4e3840a638bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-1fbfe6ec-175f-4c0f-b4f5-6341cb3066fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-8ae8113f-0cb8-41af-acd7-ec5744b0e723,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-42904e2f-3481-4e10-bcb7-8c362db07d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-75848ac3-890e-48b0-84bf-ad7d4935473f,DISK], DatanodeInfoWithStorage[127.0.0.1:39703,DS-8c8bd5f3-9f3c-4317-b8d8-1a487ba25fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-39ebfca0-e2d7-4603-a698-2e5d49295602,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-696535894-172.17.0.21-1597343370723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35933,DS-ea711ba1-1622-4760-b241-9062510da84e,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-eccc727d-caeb-41b1-882b-4e3840a638bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-1fbfe6ec-175f-4c0f-b4f5-6341cb3066fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-8ae8113f-0cb8-41af-acd7-ec5744b0e723,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-42904e2f-3481-4e10-bcb7-8c362db07d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-75848ac3-890e-48b0-84bf-ad7d4935473f,DISK], DatanodeInfoWithStorage[127.0.0.1:39703,DS-8c8bd5f3-9f3c-4317-b8d8-1a487ba25fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-39ebfca0-e2d7-4603-a698-2e5d49295602,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1678888674-172.17.0.21-1597343415806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39318,DS-e9bf5677-d680-4713-9f5e-5068dc17323e,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-12c7a1c6-aaf3-4963-9e3f-5caef349187c,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-83d1ee49-4e35-4b1b-a86d-49a80bb26148,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-5a00aac3-b89c-4958-8271-3db6e53e7098,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-3d9931aa-040a-46fd-8835-6343156ee910,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-c4f9a247-3746-4009-abfa-9cdec0540d05,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-3c0d9c22-ee34-4423-a5f5-afc41e9982f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-582c7a0e-d193-4aa2-a834-1cbe92083aa8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1678888674-172.17.0.21-1597343415806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39318,DS-e9bf5677-d680-4713-9f5e-5068dc17323e,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-12c7a1c6-aaf3-4963-9e3f-5caef349187c,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-83d1ee49-4e35-4b1b-a86d-49a80bb26148,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-5a00aac3-b89c-4958-8271-3db6e53e7098,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-3d9931aa-040a-46fd-8835-6343156ee910,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-c4f9a247-3746-4009-abfa-9cdec0540d05,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-3c0d9c22-ee34-4423-a5f5-afc41e9982f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-582c7a0e-d193-4aa2-a834-1cbe92083aa8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-368871391-172.17.0.21-1597343619549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38115,DS-0e7eb6dc-02ed-4e97-92fd-5699ed1c4c70,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-96bc59f7-1aff-4168-92bc-e1c65a64a438,DISK], DatanodeInfoWithStorage[127.0.0.1:32946,DS-f810ed4a-9a9b-4e37-a1cb-269809068ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:45745,DS-447f196e-7028-4e62-adb5-67f888849e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-edfb71e2-14dc-47d0-a60b-4f379d83bdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-98561d96-f169-48c3-bcc4-4705840cbf00,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-b32b93da-36cc-4498-9f20-2ef3e131633e,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-57e892b2-2f59-4cb4-aa1a-a91bc0bdfd5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-368871391-172.17.0.21-1597343619549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38115,DS-0e7eb6dc-02ed-4e97-92fd-5699ed1c4c70,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-96bc59f7-1aff-4168-92bc-e1c65a64a438,DISK], DatanodeInfoWithStorage[127.0.0.1:32946,DS-f810ed4a-9a9b-4e37-a1cb-269809068ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:45745,DS-447f196e-7028-4e62-adb5-67f888849e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-edfb71e2-14dc-47d0-a60b-4f379d83bdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-98561d96-f169-48c3-bcc4-4705840cbf00,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-b32b93da-36cc-4498-9f20-2ef3e131633e,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-57e892b2-2f59-4cb4-aa1a-a91bc0bdfd5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1497600330-172.17.0.21-1597343735477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46830,DS-ff6b56c3-8feb-4009-a3d6-bf850c66eec1,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-6fc55612-ff3a-4280-842d-557c70bdf90d,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-b9e828d9-78cd-43b0-aaba-dbb7fffbc222,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-779742c6-e310-4865-968a-cbe8defc5880,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-e80740e2-30e8-4279-8325-c862fd4cb121,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-0fd0d936-6414-44aa-9f97-5f522747c38a,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-42cb3465-a786-4ce2-8877-ba8bb71e8b81,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-d8d562cd-a03b-4690-bf4c-a2af5d9c0f76,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1497600330-172.17.0.21-1597343735477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46830,DS-ff6b56c3-8feb-4009-a3d6-bf850c66eec1,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-6fc55612-ff3a-4280-842d-557c70bdf90d,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-b9e828d9-78cd-43b0-aaba-dbb7fffbc222,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-779742c6-e310-4865-968a-cbe8defc5880,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-e80740e2-30e8-4279-8325-c862fd4cb121,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-0fd0d936-6414-44aa-9f97-5f522747c38a,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-42cb3465-a786-4ce2-8877-ba8bb71e8b81,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-d8d562cd-a03b-4690-bf4c-a2af5d9c0f76,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1791766240-172.17.0.21-1597343843453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40472,DS-6cb83784-8fc7-4aa5-8180-0b108fbbedc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-0419f37e-e701-4102-82be-90fe798b13c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-4cc7531e-b654-4f9c-b486-a2f3bc784fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-ae3afc5b-857f-44b4-a5cf-92ac06921c08,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-e938850d-1edf-4645-bbcb-b380875f0636,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-80f580c5-248e-4178-a159-7a5edaaee4de,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-866f2efb-7f09-48a0-9c9c-53db80a18bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-392ad3e2-2bc3-4147-8418-4700c2ed952e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1791766240-172.17.0.21-1597343843453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40472,DS-6cb83784-8fc7-4aa5-8180-0b108fbbedc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-0419f37e-e701-4102-82be-90fe798b13c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-4cc7531e-b654-4f9c-b486-a2f3bc784fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-ae3afc5b-857f-44b4-a5cf-92ac06921c08,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-e938850d-1edf-4645-bbcb-b380875f0636,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-80f580c5-248e-4178-a159-7a5edaaee4de,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-866f2efb-7f09-48a0-9c9c-53db80a18bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-392ad3e2-2bc3-4147-8418-4700c2ed952e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132010413-172.17.0.21-1597344104538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36491,DS-86e292c9-f575-453a-82f8-514f3111dee3,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-2e08ce97-313a-44e7-abb1-d01787a0ed5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-069165b8-42f6-4c13-9401-c549c5771298,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-c32cd91b-417c-4254-93fa-3cef07c194bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-32c5f0ad-0d9b-4047-8a88-8c6ceb9b661f,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-323f3e27-94ff-445d-843a-ad10b6412ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-a4adf03f-8ecc-4d2b-a41d-859d9e2b97be,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-6a3e3640-160e-4c1d-9699-f5352a5efa92,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132010413-172.17.0.21-1597344104538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36491,DS-86e292c9-f575-453a-82f8-514f3111dee3,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-2e08ce97-313a-44e7-abb1-d01787a0ed5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-069165b8-42f6-4c13-9401-c549c5771298,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-c32cd91b-417c-4254-93fa-3cef07c194bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-32c5f0ad-0d9b-4047-8a88-8c6ceb9b661f,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-323f3e27-94ff-445d-843a-ad10b6412ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-a4adf03f-8ecc-4d2b-a41d-859d9e2b97be,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-6a3e3640-160e-4c1d-9699-f5352a5efa92,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1699638337-172.17.0.21-1597344711640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38195,DS-52d8e5bc-2492-4fdc-a670-f2b96acffa22,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-eba1fb75-88ce-4c7a-b624-bcb73a9d3e47,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-8567eb34-b76f-463e-9c74-ce410b1f1210,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-6c0db88f-bcce-435a-b913-c91c82f50447,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-f26fed4c-6e8b-4e74-b002-b38943e5160a,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-dcc56f58-ffae-4c1f-a7ed-e14c75c72081,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-7cb5ad3a-cebe-417e-aedb-100fc654f561,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-3483775a-713e-4141-a87b-5789a8f53e98,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1699638337-172.17.0.21-1597344711640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38195,DS-52d8e5bc-2492-4fdc-a670-f2b96acffa22,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-eba1fb75-88ce-4c7a-b624-bcb73a9d3e47,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-8567eb34-b76f-463e-9c74-ce410b1f1210,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-6c0db88f-bcce-435a-b913-c91c82f50447,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-f26fed4c-6e8b-4e74-b002-b38943e5160a,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-dcc56f58-ffae-4c1f-a7ed-e14c75c72081,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-7cb5ad3a-cebe-417e-aedb-100fc654f561,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-3483775a-713e-4141-a87b-5789a8f53e98,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-727874500-172.17.0.21-1597344752765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36197,DS-92741351-f30e-460c-87ed-9420eb05c6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-b5c2f50d-268b-491e-b2b6-055ca29ce817,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-424b3d91-2075-422e-959c-5b9434cdf15c,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-9dcf8491-bceb-4bb5-8e7c-1cd94963cd90,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-d86cc981-c444-4b1c-afb2-c539c9a8d375,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-9ec99f45-bf24-470c-88c7-0339ec8c58be,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-90d096ff-af64-45cc-abcd-8183f7e438a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-bfeb52c3-ee44-46da-b921-7e56476fce7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-727874500-172.17.0.21-1597344752765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36197,DS-92741351-f30e-460c-87ed-9420eb05c6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-b5c2f50d-268b-491e-b2b6-055ca29ce817,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-424b3d91-2075-422e-959c-5b9434cdf15c,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-9dcf8491-bceb-4bb5-8e7c-1cd94963cd90,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-d86cc981-c444-4b1c-afb2-c539c9a8d375,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-9ec99f45-bf24-470c-88c7-0339ec8c58be,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-90d096ff-af64-45cc-abcd-8183f7e438a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-bfeb52c3-ee44-46da-b921-7e56476fce7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 10ms
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1784342848-172.17.0.21-1597345028288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35847,DS-8ed6716e-257a-43ea-8bad-695435d54815,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-7fa38193-bfcc-408c-b607-964d1da3d599,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-fa16873d-0601-4a57-b4a5-b3eb7d98e1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-610c48db-5168-434b-aa75-c35f8eb956db,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-6336399b-e3fb-4dbb-8eba-d7653d965946,DISK], DatanodeInfoWithStorage[127.0.0.1:41122,DS-da9ce079-7a1e-4cae-ab96-e5c5dbe8395a,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-7f8d31f8-31d7-4dcd-8b3d-78a5d20f1964,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-e91993a2-1d7a-4e8a-a06d-ff605bd3099e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1784342848-172.17.0.21-1597345028288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35847,DS-8ed6716e-257a-43ea-8bad-695435d54815,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-7fa38193-bfcc-408c-b607-964d1da3d599,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-fa16873d-0601-4a57-b4a5-b3eb7d98e1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-610c48db-5168-434b-aa75-c35f8eb956db,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-6336399b-e3fb-4dbb-8eba-d7653d965946,DISK], DatanodeInfoWithStorage[127.0.0.1:41122,DS-da9ce079-7a1e-4cae-ab96-e5c5dbe8395a,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-7f8d31f8-31d7-4dcd-8b3d-78a5d20f1964,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-e91993a2-1d7a-4e8a-a06d-ff605bd3099e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 23 out of 50
result: false positive !!!
Total execution time in seconds : 5802
