reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1378842467-172.17.0.10-1597388391144:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40739,DS-82d4d722-fccf-4053-9adf-827795a29f73,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-b67328f3-c02a-41bd-9756-2912f2573ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-b6676710-2fb1-4989-b18b-ffd972f86c08,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-0c433dd8-36a7-4c16-a1d1-bec15c2f09d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-6d3b7dc1-7e5d-43b0-a94a-aada2a16df53,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-43fdbdac-b94d-4cef-859f-1e4e5776a535,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-d576e852-45dc-4eb0-84fc-462d03c95463,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-43713097-363c-4f01-ac1e-956cab36e6d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1378842467-172.17.0.10-1597388391144:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40739,DS-82d4d722-fccf-4053-9adf-827795a29f73,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-b67328f3-c02a-41bd-9756-2912f2573ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-b6676710-2fb1-4989-b18b-ffd972f86c08,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-0c433dd8-36a7-4c16-a1d1-bec15c2f09d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-6d3b7dc1-7e5d-43b0-a94a-aada2a16df53,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-43fdbdac-b94d-4cef-859f-1e4e5776a535,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-d576e852-45dc-4eb0-84fc-462d03c95463,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-43713097-363c-4f01-ac1e-956cab36e6d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1011034245-172.17.0.10-1597388584725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44940,DS-ba164f42-f758-479a-b45e-ea6f0f1d0764,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-15079a6a-8a26-46f6-a088-74bbf69e5435,DISK], DatanodeInfoWithStorage[127.0.0.1:45233,DS-5c7599dd-2742-496d-b782-2efd9ce64a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-017ae3b4-6a95-469d-a8d6-b0f13579cb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-881f99d9-8ab6-4d8e-acc0-8d504b4e670a,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-bd148adb-8593-4b41-84d5-64e5480bf8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-e05956b0-6fb5-4f38-867f-002aa24fb6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-0555353c-a7a2-46a5-806e-fa55a15f895a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1011034245-172.17.0.10-1597388584725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44940,DS-ba164f42-f758-479a-b45e-ea6f0f1d0764,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-15079a6a-8a26-46f6-a088-74bbf69e5435,DISK], DatanodeInfoWithStorage[127.0.0.1:45233,DS-5c7599dd-2742-496d-b782-2efd9ce64a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-017ae3b4-6a95-469d-a8d6-b0f13579cb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-881f99d9-8ab6-4d8e-acc0-8d504b4e670a,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-bd148adb-8593-4b41-84d5-64e5480bf8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-e05956b0-6fb5-4f38-867f-002aa24fb6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-0555353c-a7a2-46a5-806e-fa55a15f895a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-687063186-172.17.0.10-1597388773226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36871,DS-99c80f14-82da-4c18-b363-dd7d9557707a,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-0803ffcb-9933-4f76-ba1e-65f6d967642b,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-81dabec2-06ab-46bb-b66e-8ad7f678e3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-d0d33cf6-5134-452c-92f9-33614b5f8d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-fe41275b-ef6e-43ec-ab4d-0918dbdec6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-229d11e2-9ed4-4c9b-866f-f59c9da9096b,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-4bcfd8f9-3395-4d7d-92ac-84fbaa7fe96f,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-ab03042a-d3b1-4686-8738-1b8412e1babf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-687063186-172.17.0.10-1597388773226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36871,DS-99c80f14-82da-4c18-b363-dd7d9557707a,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-0803ffcb-9933-4f76-ba1e-65f6d967642b,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-81dabec2-06ab-46bb-b66e-8ad7f678e3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-d0d33cf6-5134-452c-92f9-33614b5f8d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-fe41275b-ef6e-43ec-ab4d-0918dbdec6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-229d11e2-9ed4-4c9b-866f-f59c9da9096b,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-4bcfd8f9-3395-4d7d-92ac-84fbaa7fe96f,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-ab03042a-d3b1-4686-8738-1b8412e1babf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1043748235-172.17.0.10-1597388994015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34894,DS-86101111-b7c6-48ad-8c4f-1f45fa174c11,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-f8a51a98-72a8-40f0-80db-45b903d1c1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-e04427df-1830-4828-8ad1-14ab0da4c9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-426fe8de-2eb2-4716-a559-5dc19347929c,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-267cc757-fc37-4111-bdf4-119c52dcd8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-30cc1afb-7f4f-4bdd-b89a-adeaad7c71f4,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-5820bdfd-5df3-478b-902e-1e64a924e71b,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-e78ff535-fc17-4da4-b7ed-2dfcfefc4e27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1043748235-172.17.0.10-1597388994015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34894,DS-86101111-b7c6-48ad-8c4f-1f45fa174c11,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-f8a51a98-72a8-40f0-80db-45b903d1c1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-e04427df-1830-4828-8ad1-14ab0da4c9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-426fe8de-2eb2-4716-a559-5dc19347929c,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-267cc757-fc37-4111-bdf4-119c52dcd8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-30cc1afb-7f4f-4bdd-b89a-adeaad7c71f4,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-5820bdfd-5df3-478b-902e-1e64a924e71b,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-e78ff535-fc17-4da4-b7ed-2dfcfefc4e27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1389492994-172.17.0.10-1597389490340:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46875,DS-e5a9cc34-1454-4c8d-8048-0bf9adc1f167,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-edae0208-0795-4c54-84b9-71d9d7da983f,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-c5679ade-624d-435a-87d4-ce6c7462fea0,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-b3be1cf8-603f-4140-90d5-c4e13f7a2de2,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-9f4947eb-d172-4e25-9167-36ce80b630e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-98d59ccd-4d97-4b25-8549-f68fbe0a3451,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-7460ef10-d20c-413e-9948-d295669e64ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-247ab11a-1ef6-40df-bee4-8877d92ff1a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1389492994-172.17.0.10-1597389490340:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46875,DS-e5a9cc34-1454-4c8d-8048-0bf9adc1f167,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-edae0208-0795-4c54-84b9-71d9d7da983f,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-c5679ade-624d-435a-87d4-ce6c7462fea0,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-b3be1cf8-603f-4140-90d5-c4e13f7a2de2,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-9f4947eb-d172-4e25-9167-36ce80b630e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-98d59ccd-4d97-4b25-8549-f68fbe0a3451,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-7460ef10-d20c-413e-9948-d295669e64ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-247ab11a-1ef6-40df-bee4-8877d92ff1a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564833980-172.17.0.10-1597389604461:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45532,DS-ee87ec83-40aa-47ad-ba8c-8c118d08435f,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-7e07b09f-1fb8-4bd5-8899-a35a8ee41855,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-11330bdb-b925-4b40-9357-a7d5b39a4868,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-57ca365e-150e-4cd6-a1ab-4ce245d09239,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-e7c36a7f-8845-42e0-872c-32822bc9c523,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-9493965c-ff0f-4c90-ac8c-d55371724762,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-37840ce5-242c-4d1e-bb83-8836f6cb8220,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-ccf3f46a-9b1e-4bfa-a0ab-1f1a3adf6779,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564833980-172.17.0.10-1597389604461:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45532,DS-ee87ec83-40aa-47ad-ba8c-8c118d08435f,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-7e07b09f-1fb8-4bd5-8899-a35a8ee41855,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-11330bdb-b925-4b40-9357-a7d5b39a4868,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-57ca365e-150e-4cd6-a1ab-4ce245d09239,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-e7c36a7f-8845-42e0-872c-32822bc9c523,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-9493965c-ff0f-4c90-ac8c-d55371724762,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-37840ce5-242c-4d1e-bb83-8836f6cb8220,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-ccf3f46a-9b1e-4bfa-a0ab-1f1a3adf6779,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-287009589-172.17.0.10-1597389779951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44648,DS-6d558d1d-5d7b-4581-a3fd-021cc7054293,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-c270f4a6-95be-422d-839b-b57dd9078374,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-2b237d72-e866-41c6-88d3-22beab076a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-d6833712-3af0-40be-84e3-513e24e0e404,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-fecba2a9-3406-4186-8dd2-b9487a5c6818,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-6ce5861f-9f97-43e6-b88f-16d0ee3b63e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-318e9a72-8ed2-4f87-8860-8f2232c8c2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-296b6002-c7f2-47eb-a6bf-33f186c97005,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-287009589-172.17.0.10-1597389779951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44648,DS-6d558d1d-5d7b-4581-a3fd-021cc7054293,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-c270f4a6-95be-422d-839b-b57dd9078374,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-2b237d72-e866-41c6-88d3-22beab076a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-d6833712-3af0-40be-84e3-513e24e0e404,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-fecba2a9-3406-4186-8dd2-b9487a5c6818,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-6ce5861f-9f97-43e6-b88f-16d0ee3b63e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-318e9a72-8ed2-4f87-8860-8f2232c8c2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-296b6002-c7f2-47eb-a6bf-33f186c97005,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1719382550-172.17.0.10-1597389959018:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33591,DS-fbf46fb7-8260-40aa-a396-17c70dfdf444,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-52143559-d7db-43ac-82a5-33b03292765f,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-9367bebd-236f-47af-95e5-71cd2880e558,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-2bbf93c7-dde0-4696-9de9-80847aa51663,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-3690ede2-7935-4cf9-9ec5-75e384fef0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-7f4a8e18-d3c9-4234-9813-9c13877733f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-d7e4154a-251e-45d1-b782-04c4071bf423,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-748f9974-4a5b-49a2-96b2-38780b67b4f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1719382550-172.17.0.10-1597389959018:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33591,DS-fbf46fb7-8260-40aa-a396-17c70dfdf444,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-52143559-d7db-43ac-82a5-33b03292765f,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-9367bebd-236f-47af-95e5-71cd2880e558,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-2bbf93c7-dde0-4696-9de9-80847aa51663,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-3690ede2-7935-4cf9-9ec5-75e384fef0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-7f4a8e18-d3c9-4234-9813-9c13877733f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-d7e4154a-251e-45d1-b782-04c4071bf423,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-748f9974-4a5b-49a2-96b2-38780b67b4f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-780876833-172.17.0.10-1597390403398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44426,DS-1cf51a3d-28b6-455b-8eb1-8eea792331ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-62ad0531-8438-4530-a227-f52415ad94cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-6212b50d-b6d8-44fd-8877-e6ba1209242c,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-fa8fc535-3b04-41b1-8bef-6cbc61ff0006,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-1aeb548e-4714-4e55-8ecd-cb5746dd51d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-cf791376-b7ec-461a-9cf8-a7cdd224a9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-a6bcfec6-b38d-4bfd-9f3c-cbf030b04312,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-22942647-158a-4051-9c9d-8f3ae0d5b743,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-780876833-172.17.0.10-1597390403398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44426,DS-1cf51a3d-28b6-455b-8eb1-8eea792331ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-62ad0531-8438-4530-a227-f52415ad94cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-6212b50d-b6d8-44fd-8877-e6ba1209242c,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-fa8fc535-3b04-41b1-8bef-6cbc61ff0006,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-1aeb548e-4714-4e55-8ecd-cb5746dd51d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-cf791376-b7ec-461a-9cf8-a7cdd224a9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-a6bcfec6-b38d-4bfd-9f3c-cbf030b04312,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-22942647-158a-4051-9c9d-8f3ae0d5b743,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-261042416-172.17.0.10-1597390477831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35874,DS-04ae979c-162e-4bad-9987-8a9fafb13221,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-f1a282b6-8135-43e1-b57e-29a8efbb578f,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-ae13d2c7-59d4-4325-8e83-c8e002a6f2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-e89f3baf-4967-49ee-a867-98e8fc7fc696,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-be2c2a2a-63b8-492f-9533-ffdcaef483c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-983ee397-aac6-447d-aa61-62fe26764a67,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-b2a5d960-0b9e-465c-ad59-52970636ed17,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-9039e559-1998-4219-8441-5d0515969eb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-261042416-172.17.0.10-1597390477831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35874,DS-04ae979c-162e-4bad-9987-8a9fafb13221,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-f1a282b6-8135-43e1-b57e-29a8efbb578f,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-ae13d2c7-59d4-4325-8e83-c8e002a6f2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-e89f3baf-4967-49ee-a867-98e8fc7fc696,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-be2c2a2a-63b8-492f-9533-ffdcaef483c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-983ee397-aac6-447d-aa61-62fe26764a67,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-b2a5d960-0b9e-465c-ad59-52970636ed17,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-9039e559-1998-4219-8441-5d0515969eb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1682635143-172.17.0.10-1597390738280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46232,DS-3fc40971-98a5-4cea-a6e5-e63caf76d307,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-991d68fd-91b2-43f4-8472-aede73525ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-84474a54-93be-4f31-a865-d268e734a915,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-40e09c0b-019e-4540-9bf5-b6c0ad0d5724,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-3818dbdd-7733-4cd8-b6b3-4c08c084a4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-1e77273c-3027-4306-8c7f-93cf931cd939,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-9fdf7b86-62b1-4e04-bc29-597d2f6c1da6,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-53564c2e-a36b-4993-87cc-dfa75eb88a41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1682635143-172.17.0.10-1597390738280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46232,DS-3fc40971-98a5-4cea-a6e5-e63caf76d307,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-991d68fd-91b2-43f4-8472-aede73525ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-84474a54-93be-4f31-a865-d268e734a915,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-40e09c0b-019e-4540-9bf5-b6c0ad0d5724,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-3818dbdd-7733-4cd8-b6b3-4c08c084a4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-1e77273c-3027-4306-8c7f-93cf931cd939,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-9fdf7b86-62b1-4e04-bc29-597d2f6c1da6,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-53564c2e-a36b-4993-87cc-dfa75eb88a41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-637117220-172.17.0.10-1597391431366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36862,DS-e1597fdd-a039-457a-b781-078a4b1fefb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-b9a89c9a-e602-41e7-baa4-a6a7ed20896b,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-64b8963d-919e-4390-b2a3-63f961b70c69,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-a73f60be-a51f-4452-ae46-1fb8669359c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-774a7452-d056-4ccd-b553-36e5012f47cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-dfbb8903-97b7-40fa-806c-d58eeed2c571,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-a4e17d2e-3e93-4f44-ac94-7c893888f803,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-fa995cea-885f-43ae-b55f-bb19383191f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-637117220-172.17.0.10-1597391431366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36862,DS-e1597fdd-a039-457a-b781-078a4b1fefb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-b9a89c9a-e602-41e7-baa4-a6a7ed20896b,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-64b8963d-919e-4390-b2a3-63f961b70c69,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-a73f60be-a51f-4452-ae46-1fb8669359c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-774a7452-d056-4ccd-b553-36e5012f47cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-dfbb8903-97b7-40fa-806c-d58eeed2c571,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-a4e17d2e-3e93-4f44-ac94-7c893888f803,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-fa995cea-885f-43ae-b55f-bb19383191f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1144808682-172.17.0.10-1597391837328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42634,DS-43b99386-ba77-44bc-9782-5d8bac9fa544,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-ef57215f-c5dc-422b-b58e-2e5317aeefc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-0232b923-eeaf-4784-8392-580402431406,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-a0662ae9-ff7b-43cd-80cf-87f8a3e88001,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-79a7eccf-3895-44ee-85cc-0983c965a042,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-5086bb74-060d-4515-b8d3-958af6c201f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-f0f83f91-b8ef-4e4b-9df6-97146dca8dda,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-b2e25758-d91c-44a8-81f3-fa1cf6c984d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1144808682-172.17.0.10-1597391837328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42634,DS-43b99386-ba77-44bc-9782-5d8bac9fa544,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-ef57215f-c5dc-422b-b58e-2e5317aeefc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-0232b923-eeaf-4784-8392-580402431406,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-a0662ae9-ff7b-43cd-80cf-87f8a3e88001,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-79a7eccf-3895-44ee-85cc-0983c965a042,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-5086bb74-060d-4515-b8d3-958af6c201f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-f0f83f91-b8ef-4e4b-9df6-97146dca8dda,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-b2e25758-d91c-44a8-81f3-fa1cf6c984d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1322621274-172.17.0.10-1597391876878:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35244,DS-8a35bad4-6565-4be3-a223-39f8ffb10d46,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-2ae33a0b-b3e6-40ee-9d85-1bf0c1157fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-1159a4bd-d56b-468f-9b5b-15495572b518,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-0c604486-26a6-42ed-bece-8985f6b9745d,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-6f79ad68-ff2c-4c59-baa6-cc2db73b4e70,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-6afc71cf-cc28-44a5-823e-c6f4ce6010aa,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-e5a552f6-2755-4be1-b974-8859519141c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-eeb80d3c-ba24-41c4-bd16-b2c04936e6b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1322621274-172.17.0.10-1597391876878:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35244,DS-8a35bad4-6565-4be3-a223-39f8ffb10d46,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-2ae33a0b-b3e6-40ee-9d85-1bf0c1157fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-1159a4bd-d56b-468f-9b5b-15495572b518,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-0c604486-26a6-42ed-bece-8985f6b9745d,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-6f79ad68-ff2c-4c59-baa6-cc2db73b4e70,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-6afc71cf-cc28-44a5-823e-c6f4ce6010aa,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-e5a552f6-2755-4be1-b974-8859519141c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-eeb80d3c-ba24-41c4-bd16-b2c04936e6b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-528605344-172.17.0.10-1597392581317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36988,DS-99eb1951-2061-4bf0-aac0-6616e1388777,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-481d156f-ab35-44e4-ba40-95e65d77e8da,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-28b17818-0bce-4944-b873-85eab7cb98d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-83016180-98ef-41e8-b082-72f6785cee24,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-1a8926e2-f2e4-4251-9ec1-b5b472849109,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-ab6174fd-2fd8-486f-ace2-a1216def8014,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-daf75ba4-92e2-4b96-baae-49e03d47a0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-890cd091-c167-45f9-b054-00c4c05c8ed7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-528605344-172.17.0.10-1597392581317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36988,DS-99eb1951-2061-4bf0-aac0-6616e1388777,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-481d156f-ab35-44e4-ba40-95e65d77e8da,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-28b17818-0bce-4944-b873-85eab7cb98d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-83016180-98ef-41e8-b082-72f6785cee24,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-1a8926e2-f2e4-4251-9ec1-b5b472849109,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-ab6174fd-2fd8-486f-ace2-a1216def8014,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-daf75ba4-92e2-4b96-baae-49e03d47a0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-890cd091-c167-45f9-b054-00c4c05c8ed7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20s
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-587624973-172.17.0.10-1597392841201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35935,DS-e2f925e3-d8e7-4fd1-9c71-ce2d81c8fb95,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-b47ce677-ff7b-4f48-a061-03b0975a9f09,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-90a118ff-dfd1-4099-959e-98a22a9438ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-515ea208-80c6-4253-82f0-0c4ba87901ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-f3ed2c4f-a6c5-4540-ae86-ec932753c78e,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-b22a13d4-bbea-4285-a6f9-b867375c9aac,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-9f13946a-c6e3-4e04-9bd9-bab2e94d9b54,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-608619ee-08c3-47a0-b511-b54c5bc461e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-587624973-172.17.0.10-1597392841201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35935,DS-e2f925e3-d8e7-4fd1-9c71-ce2d81c8fb95,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-b47ce677-ff7b-4f48-a061-03b0975a9f09,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-90a118ff-dfd1-4099-959e-98a22a9438ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44638,DS-515ea208-80c6-4253-82f0-0c4ba87901ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-f3ed2c4f-a6c5-4540-ae86-ec932753c78e,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-b22a13d4-bbea-4285-a6f9-b867375c9aac,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-9f13946a-c6e3-4e04-9bd9-bab2e94d9b54,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-608619ee-08c3-47a0-b511-b54c5bc461e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5635
