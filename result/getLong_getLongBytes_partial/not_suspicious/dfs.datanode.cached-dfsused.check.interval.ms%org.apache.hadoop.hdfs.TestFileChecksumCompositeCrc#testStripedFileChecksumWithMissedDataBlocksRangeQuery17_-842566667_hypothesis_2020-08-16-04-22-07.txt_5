reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1236362580-172.17.0.16-1597552334408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46711,DS-230e71f9-a3ee-433c-b60a-9b6b9f73478f,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-4d195601-160b-44ec-85dc-3b4894854e99,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-69f2ac88-d98e-499b-a7fc-dedca5de09b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-19396974-eb16-465d-9612-78c5733feb35,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-73f5a77e-49e4-404e-9d4e-1eccea98a76a,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-27b5964e-f52d-4230-b157-6ba87abb4f98,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-4d243b57-f1e9-4565-8490-098aefa672bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-d7b5c968-ae8e-4e2d-a38d-a0f0dc1a05c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1236362580-172.17.0.16-1597552334408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46711,DS-230e71f9-a3ee-433c-b60a-9b6b9f73478f,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-4d195601-160b-44ec-85dc-3b4894854e99,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-69f2ac88-d98e-499b-a7fc-dedca5de09b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-19396974-eb16-465d-9612-78c5733feb35,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-73f5a77e-49e4-404e-9d4e-1eccea98a76a,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-27b5964e-f52d-4230-b157-6ba87abb4f98,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-4d243b57-f1e9-4565-8490-098aefa672bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-d7b5c968-ae8e-4e2d-a38d-a0f0dc1a05c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-656312798-172.17.0.16-1597552476317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46610,DS-843d29c7-9d93-465a-b170-d256b17f49f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-2c992cf8-7927-468b-ad0b-e8b83bae2d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-3f206aed-394c-4bdc-8334-ec8eaf1c9cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-347ca3d3-332e-4389-b4cb-40ea093b0f07,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-0f5673a4-f983-441d-ad74-af7a17146e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-c7983b21-1097-4594-b272-78448b7bfdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-87d87d0f-0227-404e-93b2-cd15a1c79ced,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-694d3e4a-bc67-4cb4-9a50-7ff41ae9bb39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-656312798-172.17.0.16-1597552476317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46610,DS-843d29c7-9d93-465a-b170-d256b17f49f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-2c992cf8-7927-468b-ad0b-e8b83bae2d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-3f206aed-394c-4bdc-8334-ec8eaf1c9cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-347ca3d3-332e-4389-b4cb-40ea093b0f07,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-0f5673a4-f983-441d-ad74-af7a17146e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-c7983b21-1097-4594-b272-78448b7bfdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-87d87d0f-0227-404e-93b2-cd15a1c79ced,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-694d3e4a-bc67-4cb4-9a50-7ff41ae9bb39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1725058140-172.17.0.16-1597553118957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37518,DS-6141c316-f976-46b0-b9b3-07838b9f5ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-34bd78df-d7ee-45b8-a9e1-012e12f3dc97,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-5201d8ba-57e3-482f-a67a-2580d9e5f246,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-a5846950-40ab-45d5-8624-6716fb45f140,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-e0b4d779-df0d-4fc3-8a3f-0e7b6a39c1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-f20ffc0c-6c5a-4f3d-a0c4-e5c27b332634,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-d328360b-57bd-484c-a7c2-0c0c606e1601,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-f4529d7d-4f85-475a-832f-4e5f1f182e66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1725058140-172.17.0.16-1597553118957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37518,DS-6141c316-f976-46b0-b9b3-07838b9f5ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-34bd78df-d7ee-45b8-a9e1-012e12f3dc97,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-5201d8ba-57e3-482f-a67a-2580d9e5f246,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-a5846950-40ab-45d5-8624-6716fb45f140,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-e0b4d779-df0d-4fc3-8a3f-0e7b6a39c1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-f20ffc0c-6c5a-4f3d-a0c4-e5c27b332634,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-d328360b-57bd-484c-a7c2-0c0c606e1601,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-f4529d7d-4f85-475a-832f-4e5f1f182e66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1640425691-172.17.0.16-1597553381588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39336,DS-dad834a8-5fba-4302-a885-c6c39dccff5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-3747d3fb-abed-46bd-97ec-3754c0ad6f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-f7501739-ca93-44ba-9302-98cb3cf31655,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-df005573-84a3-4bd7-a1f7-1c6c39ff1268,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-e4aab73a-6626-4a2d-9c4c-ca3d49e4a3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-1df0c85a-81b6-4ec4-969d-7a886f1b630b,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-a29edf4f-09ec-4494-b402-6f3523c2c943,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-c00fb08d-ab47-484a-8da5-3bec8df3b0ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1640425691-172.17.0.16-1597553381588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39336,DS-dad834a8-5fba-4302-a885-c6c39dccff5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-3747d3fb-abed-46bd-97ec-3754c0ad6f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-f7501739-ca93-44ba-9302-98cb3cf31655,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-df005573-84a3-4bd7-a1f7-1c6c39ff1268,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-e4aab73a-6626-4a2d-9c4c-ca3d49e4a3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-1df0c85a-81b6-4ec4-969d-7a886f1b630b,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-a29edf4f-09ec-4494-b402-6f3523c2c943,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-c00fb08d-ab47-484a-8da5-3bec8df3b0ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1135219912-172.17.0.16-1597553414397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38867,DS-45ed05ff-7252-45c6-9526-61e772687294,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-85266dff-35f3-43a7-bb93-945c200a22f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-1eb66744-7633-4c88-9215-404ce43038c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-9db277c4-c307-48a7-b8eb-d5e23aafdbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-a3b48f9b-0477-44d2-b85c-3ef2aadf1314,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-71c8d0f3-ed52-444b-8291-b1eeddc85a77,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-143833d9-6d31-4820-a892-fd7bd81421aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-cde183ec-02db-4e5c-9608-7ff80777353d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1135219912-172.17.0.16-1597553414397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38867,DS-45ed05ff-7252-45c6-9526-61e772687294,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-85266dff-35f3-43a7-bb93-945c200a22f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-1eb66744-7633-4c88-9215-404ce43038c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-9db277c4-c307-48a7-b8eb-d5e23aafdbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-a3b48f9b-0477-44d2-b85c-3ef2aadf1314,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-71c8d0f3-ed52-444b-8291-b1eeddc85a77,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-143833d9-6d31-4820-a892-fd7bd81421aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-cde183ec-02db-4e5c-9608-7ff80777353d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1500394172-172.17.0.16-1597553491793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43464,DS-60e18f4a-0ef5-4818-a411-38805fff3bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41376,DS-fc25846f-da77-41c6-a657-1a7325275d58,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-3a2d9189-6bd3-4d50-b5ec-fb507bd2e964,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-51c938d5-4341-4429-901f-3771d22a33c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-1409b02a-ee80-43cd-bcc6-7471c58743b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-bad8368c-2ea6-4ca3-828c-c378f81cad40,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-20b1e0d1-ae9f-42c0-831c-8b245b6dbaed,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-f468614b-ec55-46c2-bc07-56383e08cc05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1500394172-172.17.0.16-1597553491793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43464,DS-60e18f4a-0ef5-4818-a411-38805fff3bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41376,DS-fc25846f-da77-41c6-a657-1a7325275d58,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-3a2d9189-6bd3-4d50-b5ec-fb507bd2e964,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-51c938d5-4341-4429-901f-3771d22a33c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-1409b02a-ee80-43cd-bcc6-7471c58743b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-bad8368c-2ea6-4ca3-828c-c378f81cad40,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-20b1e0d1-ae9f-42c0-831c-8b245b6dbaed,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-f468614b-ec55-46c2-bc07-56383e08cc05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1910680826-172.17.0.16-1597554227693:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46695,DS-1e5d1109-c238-4670-a8d0-848f0187a517,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-661d8a32-30e9-4e29-b013-fa7410ed3dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-0cf0a9bc-2621-4637-8eef-7fc521f38d93,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-3dd215ae-e236-453a-8167-c8f8572715e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-dd56cf8a-33bb-4d1b-925f-fdb78d228a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-afccffa2-8e97-4525-b739-123328d44636,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-c5be6115-3ce1-44d5-83ea-7c816e8b966b,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-e546aa2b-872c-4165-a980-b776c756416b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1910680826-172.17.0.16-1597554227693:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46695,DS-1e5d1109-c238-4670-a8d0-848f0187a517,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-661d8a32-30e9-4e29-b013-fa7410ed3dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-0cf0a9bc-2621-4637-8eef-7fc521f38d93,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-3dd215ae-e236-453a-8167-c8f8572715e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-dd56cf8a-33bb-4d1b-925f-fdb78d228a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-afccffa2-8e97-4525-b739-123328d44636,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-c5be6115-3ce1-44d5-83ea-7c816e8b966b,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-e546aa2b-872c-4165-a980-b776c756416b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-49336430-172.17.0.16-1597555122694:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46209,DS-824c3a1b-fd07-4d7e-ac78-b8c8f9ec80f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-f37f9890-2dd9-413d-8077-1fe1bdb585f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-91b68e41-4bbb-49e6-992b-487c5db32e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-474347a7-e3c8-4b53-b21b-18df56818e51,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-8acaf721-48ee-4431-9813-429feb26cd80,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-891b0aed-d3ad-4d18-9c8b-496f4f864b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-0a52d9ea-9405-423a-bb67-0c11250892ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-b03a8b58-1105-4f72-84e4-066afd7fca86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-49336430-172.17.0.16-1597555122694:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46209,DS-824c3a1b-fd07-4d7e-ac78-b8c8f9ec80f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-f37f9890-2dd9-413d-8077-1fe1bdb585f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-91b68e41-4bbb-49e6-992b-487c5db32e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-474347a7-e3c8-4b53-b21b-18df56818e51,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-8acaf721-48ee-4431-9813-429feb26cd80,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-891b0aed-d3ad-4d18-9c8b-496f4f864b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-0a52d9ea-9405-423a-bb67-0c11250892ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-b03a8b58-1105-4f72-84e4-066afd7fca86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2103404171-172.17.0.16-1597555311861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35006,DS-85fd1720-94ea-4ba9-978f-67a2457afd96,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-248ffb6f-c447-4759-a26c-e55a2cfa6ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-e7086061-e771-4372-be8d-3d458f833160,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-c4a8b42f-cde2-4084-8975-7dcfe5d11ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-17efd1b8-6f94-4fd6-96bf-fd5da6bb0b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-4e0f1950-2c70-4b49-8135-f6420e2dd40c,DISK], DatanodeInfoWithStorage[127.0.0.1:34246,DS-e86c0689-1a40-4228-8772-cdccf8c34159,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-ca9f0b96-3cac-48f5-85b0-c9f0a4847625,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2103404171-172.17.0.16-1597555311861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35006,DS-85fd1720-94ea-4ba9-978f-67a2457afd96,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-248ffb6f-c447-4759-a26c-e55a2cfa6ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-e7086061-e771-4372-be8d-3d458f833160,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-c4a8b42f-cde2-4084-8975-7dcfe5d11ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-17efd1b8-6f94-4fd6-96bf-fd5da6bb0b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-4e0f1950-2c70-4b49-8135-f6420e2dd40c,DISK], DatanodeInfoWithStorage[127.0.0.1:34246,DS-e86c0689-1a40-4228-8772-cdccf8c34159,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-ca9f0b96-3cac-48f5-85b0-c9f0a4847625,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-539261166-172.17.0.16-1597555500433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43212,DS-aee83090-de80-4959-b79d-669af7c6d1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-611375ac-9e27-4076-8168-cc2e9d7356b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-770a4373-3b03-4c18-9275-b7a82505cc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-83babc95-46bb-4a80-a512-c8c0d05274b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-7a90e82d-9bc0-4b86-a88d-5fd75b04bfb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-a84b0251-560c-4687-baa4-33edd6b383a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-a65ca7a0-9031-4964-9647-9e273e11cbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-892ecf40-482e-48e1-a0b7-2cae1fdb2e1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-539261166-172.17.0.16-1597555500433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43212,DS-aee83090-de80-4959-b79d-669af7c6d1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-611375ac-9e27-4076-8168-cc2e9d7356b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-770a4373-3b03-4c18-9275-b7a82505cc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-83babc95-46bb-4a80-a512-c8c0d05274b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-7a90e82d-9bc0-4b86-a88d-5fd75b04bfb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-a84b0251-560c-4687-baa4-33edd6b383a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-a65ca7a0-9031-4964-9647-9e273e11cbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-892ecf40-482e-48e1-a0b7-2cae1fdb2e1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-395121456-172.17.0.16-1597556080067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34741,DS-d8d7036c-8145-4582-8ca3-a1e792769e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-dfbd20e8-78c1-47a9-8fbe-c9539562c70c,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-5ec56a60-89f6-4b3e-a2be-5ee1edc491f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-fd871824-4331-4dc3-a970-2469ffb862cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-ddc28ed6-da50-4463-93cf-f2440a756ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-d79da9cb-18a9-49c9-a56e-eb4f56ad9ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-523cd601-f8cc-4906-9ab8-23fbe194a2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-b8e81f0a-5954-49df-a226-541e1d505136,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-395121456-172.17.0.16-1597556080067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34741,DS-d8d7036c-8145-4582-8ca3-a1e792769e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-dfbd20e8-78c1-47a9-8fbe-c9539562c70c,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-5ec56a60-89f6-4b3e-a2be-5ee1edc491f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-fd871824-4331-4dc3-a970-2469ffb862cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-ddc28ed6-da50-4463-93cf-f2440a756ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-d79da9cb-18a9-49c9-a56e-eb4f56ad9ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-523cd601-f8cc-4906-9ab8-23fbe194a2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-b8e81f0a-5954-49df-a226-541e1d505136,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-418224124-172.17.0.16-1597556525779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39668,DS-65d549ac-9dbb-4dd4-8d9f-07ee83012189,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-b8eed992-e19e-4aef-b652-2af4baace1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-48a97304-2256-48f0-8029-d0be65738df8,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-22451ad3-907e-49ad-9b25-a10a513a4ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-f54fe33c-610d-4437-b412-ad019c962559,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-c4a04569-95c4-43cf-95e8-15b17c505707,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-9e59206f-09fd-4ed2-b066-8bb18385016f,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-6922e58b-1775-4262-818b-9c4d35713074,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-418224124-172.17.0.16-1597556525779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39668,DS-65d549ac-9dbb-4dd4-8d9f-07ee83012189,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-b8eed992-e19e-4aef-b652-2af4baace1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-48a97304-2256-48f0-8029-d0be65738df8,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-22451ad3-907e-49ad-9b25-a10a513a4ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-f54fe33c-610d-4437-b412-ad019c962559,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-c4a04569-95c4-43cf-95e8-15b17c505707,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-9e59206f-09fd-4ed2-b066-8bb18385016f,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-6922e58b-1775-4262-818b-9c4d35713074,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5339
