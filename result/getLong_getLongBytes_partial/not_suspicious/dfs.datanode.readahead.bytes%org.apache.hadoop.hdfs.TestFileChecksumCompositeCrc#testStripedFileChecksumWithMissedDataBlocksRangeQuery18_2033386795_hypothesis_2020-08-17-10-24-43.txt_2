reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-387833199-172.17.0.12-1597659980672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37238,DS-5d1f9d97-0919-461b-a236-75fd414b9c34,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-b2c36f14-4544-4568-b764-7df95b2c3590,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-d412beb9-1411-446f-a07c-4b7c607ac90d,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-c04996ab-aeab-43e4-afd9-3de6ab1ce31a,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-e9d00951-9906-4b16-bffe-943f5ac49cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-abd57c75-70f6-4343-b559-6e82297ba00b,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-7115aa95-2e37-4306-8b07-3a3d695fb3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-57d95422-bd24-452e-b654-18757523e385,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-387833199-172.17.0.12-1597659980672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37238,DS-5d1f9d97-0919-461b-a236-75fd414b9c34,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-b2c36f14-4544-4568-b764-7df95b2c3590,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-d412beb9-1411-446f-a07c-4b7c607ac90d,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-c04996ab-aeab-43e4-afd9-3de6ab1ce31a,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-e9d00951-9906-4b16-bffe-943f5ac49cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-abd57c75-70f6-4343-b559-6e82297ba00b,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-7115aa95-2e37-4306-8b07-3a3d695fb3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-57d95422-bd24-452e-b654-18757523e385,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2100066583-172.17.0.12-1597660532265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34452,DS-23853020-0677-4137-97a9-468c80880164,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-51ebaea9-6025-48ba-80ca-deec916293be,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-61bf748a-b7b3-46f9-868d-4ee5de9d76e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-487f5cce-dbbc-4a19-8e67-12c686c1e1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-320f8ebb-6b7e-45ab-a1de-dfa725d70db3,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-44b9e014-a655-44db-9a4c-cd6a80ee1b89,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-11468c77-64ee-4751-91ad-cf55cc679d25,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-5f521d84-21db-4a12-a607-bf5fbd65cb0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2100066583-172.17.0.12-1597660532265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34452,DS-23853020-0677-4137-97a9-468c80880164,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-51ebaea9-6025-48ba-80ca-deec916293be,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-61bf748a-b7b3-46f9-868d-4ee5de9d76e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-487f5cce-dbbc-4a19-8e67-12c686c1e1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-320f8ebb-6b7e-45ab-a1de-dfa725d70db3,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-44b9e014-a655-44db-9a4c-cd6a80ee1b89,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-11468c77-64ee-4751-91ad-cf55cc679d25,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-5f521d84-21db-4a12-a607-bf5fbd65cb0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171884961-172.17.0.12-1597660570452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40780,DS-d2b15421-b37c-4dec-ae28-55acb42e2a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-5f78719f-43e0-4569-b89c-405e9451cc82,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-3543a2ef-97fa-453f-a0ee-d185dcaf3aec,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-9adde5c9-8d17-477e-8925-99ce97ac6e54,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-06e90cfc-b8db-423c-a645-f5a019740143,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-670ccbb1-4694-40a6-9339-e340ab1d8093,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-55694118-c3e2-4ff2-9c0f-aa3314b79ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-2d3ea304-b264-4ee1-94fb-b34488e9f077,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171884961-172.17.0.12-1597660570452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40780,DS-d2b15421-b37c-4dec-ae28-55acb42e2a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-5f78719f-43e0-4569-b89c-405e9451cc82,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-3543a2ef-97fa-453f-a0ee-d185dcaf3aec,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-9adde5c9-8d17-477e-8925-99ce97ac6e54,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-06e90cfc-b8db-423c-a645-f5a019740143,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-670ccbb1-4694-40a6-9339-e340ab1d8093,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-55694118-c3e2-4ff2-9c0f-aa3314b79ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-2d3ea304-b264-4ee1-94fb-b34488e9f077,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-126348851-172.17.0.12-1597661282921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46281,DS-c6e8f10a-20ad-4790-ba03-2114dc28c576,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-dfa5b392-8267-4f28-b920-e236f585bc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-ed3f6550-ec6c-49a9-8efb-ebfd9077ae2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-4f775947-f085-44ae-b76e-f59d17800078,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-f0b30874-3d3b-44aa-a7a3-052db6a1dd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-9cac44b0-3908-47c2-bfdc-fc6cb0e1bd41,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-136aeb36-75a3-404e-8053-4e221d44decc,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-e5ddb8fe-1259-486c-ac7c-b08ddc3ac444,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-126348851-172.17.0.12-1597661282921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46281,DS-c6e8f10a-20ad-4790-ba03-2114dc28c576,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-dfa5b392-8267-4f28-b920-e236f585bc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-ed3f6550-ec6c-49a9-8efb-ebfd9077ae2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-4f775947-f085-44ae-b76e-f59d17800078,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-f0b30874-3d3b-44aa-a7a3-052db6a1dd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-9cac44b0-3908-47c2-bfdc-fc6cb0e1bd41,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-136aeb36-75a3-404e-8053-4e221d44decc,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-e5ddb8fe-1259-486c-ac7c-b08ddc3ac444,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-79521871-172.17.0.12-1597661363483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33390,DS-6be8b160-34e5-4e9d-98ab-3b194e817973,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-686c4f27-5dbf-4bd5-9f00-b3fac402fc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-e4dcd6d2-f712-4137-aca6-1a65e67993f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-6f189ea7-eb02-49c4-9731-62921c705757,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-2937183f-69a0-488a-a245-c26287409180,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-aec2edaf-8803-4920-8b5f-f05b8d9e1203,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-f0448561-11e1-4d0d-b781-5b9e88a17930,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-191dca7f-48b8-4292-8bc7-d239eaf998a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-79521871-172.17.0.12-1597661363483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33390,DS-6be8b160-34e5-4e9d-98ab-3b194e817973,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-686c4f27-5dbf-4bd5-9f00-b3fac402fc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-e4dcd6d2-f712-4137-aca6-1a65e67993f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-6f189ea7-eb02-49c4-9731-62921c705757,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-2937183f-69a0-488a-a245-c26287409180,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-aec2edaf-8803-4920-8b5f-f05b8d9e1203,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-f0448561-11e1-4d0d-b781-5b9e88a17930,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-191dca7f-48b8-4292-8bc7-d239eaf998a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1892579081-172.17.0.12-1597661508718:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34879,DS-a5a871ea-c699-46f6-94ec-f782aa7bf301,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-e0876beb-cf68-42e6-8b63-b216546b5ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-57b3646d-1d05-4c4c-aa47-c21d6ae56f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-157b0778-2d15-49db-b584-5cad0b82fbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-a62a6013-ddbb-4316-b252-d9e580cda996,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-bba3f06b-e1f5-49e6-8cdc-0829f6002e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-1a7f03bd-e99b-48ea-8693-d57380904850,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-82261f0a-d21d-409a-8356-7c45a905cd40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1892579081-172.17.0.12-1597661508718:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34879,DS-a5a871ea-c699-46f6-94ec-f782aa7bf301,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-e0876beb-cf68-42e6-8b63-b216546b5ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-57b3646d-1d05-4c4c-aa47-c21d6ae56f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-157b0778-2d15-49db-b584-5cad0b82fbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-a62a6013-ddbb-4316-b252-d9e580cda996,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-bba3f06b-e1f5-49e6-8cdc-0829f6002e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-1a7f03bd-e99b-48ea-8693-d57380904850,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-82261f0a-d21d-409a-8356-7c45a905cd40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1876007236-172.17.0.12-1597661923486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35069,DS-43368adf-36d9-4353-9539-76d7c45e457b,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-d3b3a4c0-8716-4718-8042-8d6454da27a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-f56d93d6-ecdc-4708-9be6-3564c63cc9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-fac7bd99-a698-44d7-9545-29ea862cb02c,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-89bd9de7-436e-4ada-8aa4-2b94813f8e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-003e5ec0-1f0b-4284-83b6-5fdbf7d3448b,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-f10aebb0-e16d-4579-9774-2dd774444a09,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-edab8a81-0b3c-4aa7-8d6d-a4d679626a7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1876007236-172.17.0.12-1597661923486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35069,DS-43368adf-36d9-4353-9539-76d7c45e457b,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-d3b3a4c0-8716-4718-8042-8d6454da27a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-f56d93d6-ecdc-4708-9be6-3564c63cc9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-fac7bd99-a698-44d7-9545-29ea862cb02c,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-89bd9de7-436e-4ada-8aa4-2b94813f8e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-003e5ec0-1f0b-4284-83b6-5fdbf7d3448b,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-f10aebb0-e16d-4579-9774-2dd774444a09,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-edab8a81-0b3c-4aa7-8d6d-a4d679626a7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-391818881-172.17.0.12-1597662604022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39200,DS-2dacc3bc-c72e-4648-8392-5a9353d9524a,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-22a005ce-81f9-45f7-9d69-da12160b5a93,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-f0d29f7f-5625-467d-bea9-8913d08561b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-4717a1e7-98d8-44a1-9fe3-7b464f738ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-332ccfb6-ce3c-43d9-827b-cf4fd1659001,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-0b45e3ce-ea17-45ee-b90e-ea2925e35022,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-149e409c-c186-4ac0-9baf-9e58a6b08b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-c4318bdc-bb67-4d22-857a-adb630eab660,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-391818881-172.17.0.12-1597662604022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39200,DS-2dacc3bc-c72e-4648-8392-5a9353d9524a,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-22a005ce-81f9-45f7-9d69-da12160b5a93,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-f0d29f7f-5625-467d-bea9-8913d08561b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-4717a1e7-98d8-44a1-9fe3-7b464f738ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-332ccfb6-ce3c-43d9-827b-cf4fd1659001,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-0b45e3ce-ea17-45ee-b90e-ea2925e35022,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-149e409c-c186-4ac0-9baf-9e58a6b08b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-c4318bdc-bb67-4d22-857a-adb630eab660,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1199578809-172.17.0.12-1597663027521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43396,DS-eaa3de88-f6ac-43ee-b9d7-78dae6c70a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-f14953d0-a5d6-4709-8c30-484c4915b0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-b393841e-8e46-41d7-a413-f17b66a6c642,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-803fac3e-94b9-46ed-aa0e-c6d14ffbd449,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-803e7b39-4337-4303-b70f-507e54df16c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-d74d49f3-44c7-4d1c-90e3-3f8d85e0c274,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-ace0aa1c-83f6-4d05-998e-e752058d0042,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-7ec15163-d7f1-466c-9069-b4a2a0de0d2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1199578809-172.17.0.12-1597663027521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43396,DS-eaa3de88-f6ac-43ee-b9d7-78dae6c70a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-f14953d0-a5d6-4709-8c30-484c4915b0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-b393841e-8e46-41d7-a413-f17b66a6c642,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-803fac3e-94b9-46ed-aa0e-c6d14ffbd449,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-803e7b39-4337-4303-b70f-507e54df16c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-d74d49f3-44c7-4d1c-90e3-3f8d85e0c274,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-ace0aa1c-83f6-4d05-998e-e752058d0042,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-7ec15163-d7f1-466c-9069-b4a2a0de0d2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-484178149-172.17.0.12-1597663132563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39534,DS-b936a82e-93b2-48f7-9a17-cf1d74e76f58,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-7994eabd-0671-4840-920f-afb1464ab482,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-c282f793-1435-437c-8ac4-ff203a73a4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-95596b37-3f8d-4c35-941c-d032dfd9b317,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-93f39ac8-cb72-41d3-9b0f-bc53a2f2562a,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-5c9f3a6b-a4c4-40bd-9bd9-a906a184f1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46082,DS-743cf921-1937-4209-95be-6991a14a38aa,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-a3516e83-e071-4b1f-a2e6-b02bcadda6a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-484178149-172.17.0.12-1597663132563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39534,DS-b936a82e-93b2-48f7-9a17-cf1d74e76f58,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-7994eabd-0671-4840-920f-afb1464ab482,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-c282f793-1435-437c-8ac4-ff203a73a4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-95596b37-3f8d-4c35-941c-d032dfd9b317,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-93f39ac8-cb72-41d3-9b0f-bc53a2f2562a,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-5c9f3a6b-a4c4-40bd-9bd9-a906a184f1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46082,DS-743cf921-1937-4209-95be-6991a14a38aa,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-a3516e83-e071-4b1f-a2e6-b02bcadda6a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1839393510-172.17.0.12-1597663632438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35717,DS-60faa50f-3b7a-44b8-8fed-7f7e300b9f17,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-d90176cf-a9aa-4240-8d80-3447a7b4cb6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-f73e51df-5a76-4103-b01b-6dc994114717,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-722b2a8c-172a-428c-8c3a-04af70458123,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-e13abd29-97c2-4c08-a311-0684969f681c,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-d7a0c5f5-e3c3-4e41-9936-941a8b9dbd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-c7abf0a2-0595-494b-a87f-ddb5f0a67857,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-bd0530e2-b2b6-48b7-97a5-fcf885cb981b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1839393510-172.17.0.12-1597663632438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35717,DS-60faa50f-3b7a-44b8-8fed-7f7e300b9f17,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-d90176cf-a9aa-4240-8d80-3447a7b4cb6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-f73e51df-5a76-4103-b01b-6dc994114717,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-722b2a8c-172a-428c-8c3a-04af70458123,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-e13abd29-97c2-4c08-a311-0684969f681c,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-d7a0c5f5-e3c3-4e41-9936-941a8b9dbd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-c7abf0a2-0595-494b-a87f-ddb5f0a67857,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-bd0530e2-b2b6-48b7-97a5-fcf885cb981b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1881894236-172.17.0.12-1597663708888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33417,DS-4f5c3b88-94ae-4234-b3af-636b8b74f753,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-898e3f01-b5e6-4bf5-97e3-71f0129b362b,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-ee7519c5-ca4c-4ef2-a4ea-c5a0bab7dd4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-e89b3bc6-d73b-4574-8683-008f63c1b9af,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-8a86c021-3fc2-46cf-a7b6-8521a78e8331,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-d776df04-10dd-4b98-848a-9043e1c7d506,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-2c3723db-262d-43c0-bf78-5ecc90685e89,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-db9875cc-7997-4eb1-8660-c64eeae420b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1881894236-172.17.0.12-1597663708888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33417,DS-4f5c3b88-94ae-4234-b3af-636b8b74f753,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-898e3f01-b5e6-4bf5-97e3-71f0129b362b,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-ee7519c5-ca4c-4ef2-a4ea-c5a0bab7dd4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-e89b3bc6-d73b-4574-8683-008f63c1b9af,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-8a86c021-3fc2-46cf-a7b6-8521a78e8331,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-d776df04-10dd-4b98-848a-9043e1c7d506,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-2c3723db-262d-43c0-bf78-5ecc90685e89,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-db9875cc-7997-4eb1-8660-c64eeae420b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-159586672-172.17.0.12-1597664178035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38764,DS-dede13bf-9bd9-4cef-adf3-17c4cd179fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-c5b4fe25-5cf3-4b97-95c4-c2627ded766f,DISK], DatanodeInfoWithStorage[127.0.0.1:36111,DS-f25eaf3f-97fd-47ba-9c8a-eb7d32416081,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-bb11564f-f08b-4838-851b-b55be630f2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-8136bd53-3c87-4eeb-ac06-337e0fe5e1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-dbc818b5-e5fd-40ed-bbc9-1ead12203f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-7dbb680c-5e27-4cdf-887f-771df8216ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-26c1184e-03df-46b7-8db3-a9e55bfb69c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-159586672-172.17.0.12-1597664178035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38764,DS-dede13bf-9bd9-4cef-adf3-17c4cd179fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-c5b4fe25-5cf3-4b97-95c4-c2627ded766f,DISK], DatanodeInfoWithStorage[127.0.0.1:36111,DS-f25eaf3f-97fd-47ba-9c8a-eb7d32416081,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-bb11564f-f08b-4838-851b-b55be630f2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-8136bd53-3c87-4eeb-ac06-337e0fe5e1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-dbc818b5-e5fd-40ed-bbc9-1ead12203f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-7dbb680c-5e27-4cdf-887f-771df8216ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-26c1184e-03df-46b7-8db3-a9e55bfb69c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1739202416-172.17.0.12-1597664729333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34078,DS-271a7532-847a-45d8-8b3f-5c6c98c71d26,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-c8be4a57-4693-491f-b313-380ae8550508,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-d1bfed03-dbd0-4b82-a568-ff6237c48e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-1f0b5e35-925b-4679-9f33-95ab93b0274e,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-3d921637-474a-408d-a346-e6e27d2df74c,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-9dae29c9-dcb6-4bca-a540-81ecd17c309d,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-f438f82e-f352-4448-a4bf-7fa478282c65,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-25d6de15-b7f9-4845-aaed-f325d25d130e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1739202416-172.17.0.12-1597664729333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34078,DS-271a7532-847a-45d8-8b3f-5c6c98c71d26,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-c8be4a57-4693-491f-b313-380ae8550508,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-d1bfed03-dbd0-4b82-a568-ff6237c48e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-1f0b5e35-925b-4679-9f33-95ab93b0274e,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-3d921637-474a-408d-a346-e6e27d2df74c,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-9dae29c9-dcb6-4bca-a540-81ecd17c309d,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-f438f82e-f352-4448-a4bf-7fa478282c65,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-25d6de15-b7f9-4845-aaed-f325d25d130e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1840958844-172.17.0.12-1597664885049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40599,DS-66426707-df09-45bf-9d0a-1f9e5bc44f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-73070884-e1e6-4476-be2b-d3cb065c430c,DISK], DatanodeInfoWithStorage[127.0.0.1:44243,DS-63f5882b-d854-4dd4-9b7c-aeb1d5ea48aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-123becaf-2861-421a-bcb7-7c9b14eb4a90,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-4a11bb3e-0623-49f3-a3ac-24687981e5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-b45dae8d-6f87-42c9-82a5-d67edf0eb2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-b44a860b-23e1-4347-b8b7-8b27a1779442,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-5c83e853-50b8-46d0-a8db-05bd4e150cd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1840958844-172.17.0.12-1597664885049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40599,DS-66426707-df09-45bf-9d0a-1f9e5bc44f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-73070884-e1e6-4476-be2b-d3cb065c430c,DISK], DatanodeInfoWithStorage[127.0.0.1:44243,DS-63f5882b-d854-4dd4-9b7c-aeb1d5ea48aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-123becaf-2861-421a-bcb7-7c9b14eb4a90,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-4a11bb3e-0623-49f3-a3ac-24687981e5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-b45dae8d-6f87-42c9-82a5-d67edf0eb2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-b44a860b-23e1-4347-b8b7-8b27a1779442,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-5c83e853-50b8-46d0-a8db-05bd4e150cd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-519966371-172.17.0.12-1597664920751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43851,DS-410e0959-9230-41b7-9505-39b6c67b6a98,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-8ac32221-aca7-4b07-9c0b-75f211ab649b,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-516e8199-440f-4047-9e0a-db2de743d414,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-25f62e0b-8c6c-4dd7-874c-04adf3426f52,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-0c3343e3-c977-4509-a510-9892383d49f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-e98bcd10-a313-45e0-be68-37f49f40b16b,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-a6932c6b-e016-429f-bf58-7aabe85a03ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-add99811-36b8-4480-ae4e-0349d09e5c7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-519966371-172.17.0.12-1597664920751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43851,DS-410e0959-9230-41b7-9505-39b6c67b6a98,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-8ac32221-aca7-4b07-9c0b-75f211ab649b,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-516e8199-440f-4047-9e0a-db2de743d414,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-25f62e0b-8c6c-4dd7-874c-04adf3426f52,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-0c3343e3-c977-4509-a510-9892383d49f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-e98bcd10-a313-45e0-be68-37f49f40b16b,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-a6932c6b-e016-429f-bf58-7aabe85a03ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-add99811-36b8-4480-ae4e-0349d09e5c7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-803835477-172.17.0.12-1597665032273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40706,DS-25996ec0-5953-419a-a5f3-8ceecf678d05,DISK], DatanodeInfoWithStorage[127.0.0.1:38893,DS-4a002398-9915-42a0-8d05-d0004414da24,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-13cd7bd8-d45c-44c8-a4df-cb7920f262b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-0ae4f517-e5c0-490a-bdbd-0450403c02f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-31f6da0d-3da9-411c-8e65-6c520f7ed068,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-38e637dd-9793-4b1f-8ba0-c2cbaf1a1712,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-90928f7b-9d2a-4b65-b63f-1350d96c6206,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-01c5a386-2f23-4dac-80d2-480f5a26fda8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-803835477-172.17.0.12-1597665032273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40706,DS-25996ec0-5953-419a-a5f3-8ceecf678d05,DISK], DatanodeInfoWithStorage[127.0.0.1:38893,DS-4a002398-9915-42a0-8d05-d0004414da24,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-13cd7bd8-d45c-44c8-a4df-cb7920f262b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-0ae4f517-e5c0-490a-bdbd-0450403c02f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-31f6da0d-3da9-411c-8e65-6c520f7ed068,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-38e637dd-9793-4b1f-8ba0-c2cbaf1a1712,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-90928f7b-9d2a-4b65-b63f-1350d96c6206,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-01c5a386-2f23-4dac-80d2-480f5a26fda8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-737337903-172.17.0.12-1597665257250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45438,DS-c9a5bf0d-315e-4030-af7b-f64ca73523ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-b36dc0d2-a751-4c22-890d-eb58a2923517,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-b065f120-f89f-4528-b63d-78dab0273201,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-5ff4c3b2-ea90-4f98-9a5f-2cf0b9ae2124,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-980936bb-fb3d-40c7-b0a2-27c6798774d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-36e0e00b-0b60-489e-9711-b86ec5ae15b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-7efe8ff1-459d-4f1f-ab6c-af0768c7cdc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-0caeb4d9-8342-4136-8ffb-9969170c2ea9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-737337903-172.17.0.12-1597665257250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45438,DS-c9a5bf0d-315e-4030-af7b-f64ca73523ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-b36dc0d2-a751-4c22-890d-eb58a2923517,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-b065f120-f89f-4528-b63d-78dab0273201,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-5ff4c3b2-ea90-4f98-9a5f-2cf0b9ae2124,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-980936bb-fb3d-40c7-b0a2-27c6798774d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-36e0e00b-0b60-489e-9711-b86ec5ae15b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-7efe8ff1-459d-4f1f-ab6c-af0768c7cdc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-0caeb4d9-8342-4136-8ffb-9969170c2ea9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-454456113-172.17.0.12-1597665323025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43424,DS-3d154f54-f88d-4ef0-a824-7681f574eea3,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-8c9ddcd5-aaee-4f34-b61d-1b2faff5f458,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-922371ba-b71c-42d7-b47f-abc264c6152a,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-4f3c3a2d-a49b-44bf-8400-d19cb6f2f817,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-729dcba8-6ea9-4b0b-8c69-6347f618b421,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-36cb15f1-a58f-4466-85de-622f2d8d322d,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-055aa07b-b555-48c2-af98-41c13d8ba861,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-b1c169e7-165e-4bd7-8aaf-f727f745a09b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-454456113-172.17.0.12-1597665323025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43424,DS-3d154f54-f88d-4ef0-a824-7681f574eea3,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-8c9ddcd5-aaee-4f34-b61d-1b2faff5f458,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-922371ba-b71c-42d7-b47f-abc264c6152a,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-4f3c3a2d-a49b-44bf-8400-d19cb6f2f817,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-729dcba8-6ea9-4b0b-8c69-6347f618b421,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-36cb15f1-a58f-4466-85de-622f2d8d322d,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-055aa07b-b555-48c2-af98-41c13d8ba861,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-b1c169e7-165e-4bd7-8aaf-f727f745a09b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5497
