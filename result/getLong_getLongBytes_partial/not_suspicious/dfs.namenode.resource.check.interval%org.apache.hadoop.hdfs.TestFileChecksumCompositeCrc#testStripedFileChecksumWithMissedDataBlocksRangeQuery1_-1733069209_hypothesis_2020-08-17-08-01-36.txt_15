reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864708784-172.17.0.19-1597651669669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40613,DS-ae94726d-5f4c-4261-b0dd-f21243d70f83,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-5fc8fd97-ef32-45da-abc8-bf2ea9c58be4,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-9e7b1906-f81f-4608-9e13-b12151d0ac13,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-e49074fb-19c5-4c56-a204-da410a1d8809,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-2fd076c9-05e6-4d7a-bac1-b7a8c49abd05,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-036e5143-044c-4b86-9b8f-89e0f3c7a269,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-a7b7e763-ecea-45d4-ab64-f46dd694b8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-63cc7b2f-3057-4e78-bac7-e5b1d3c31a41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864708784-172.17.0.19-1597651669669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40613,DS-ae94726d-5f4c-4261-b0dd-f21243d70f83,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-5fc8fd97-ef32-45da-abc8-bf2ea9c58be4,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-9e7b1906-f81f-4608-9e13-b12151d0ac13,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-e49074fb-19c5-4c56-a204-da410a1d8809,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-2fd076c9-05e6-4d7a-bac1-b7a8c49abd05,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-036e5143-044c-4b86-9b8f-89e0f3c7a269,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-a7b7e763-ecea-45d4-ab64-f46dd694b8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-63cc7b2f-3057-4e78-bac7-e5b1d3c31a41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-618173436-172.17.0.19-1597652096488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43561,DS-8e3cc6d2-4953-48fb-bd6d-4a4cbb1a4045,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-eaa01f93-fbff-4a24-8bbc-959ff3d14f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-c436356d-9f6c-48a7-8860-8ae2673840c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-271e160c-e36c-4642-8463-02939332f322,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-185d1c43-f751-41a6-8f6f-25c0e1d0adae,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-edeb6fc0-1be8-43d6-87d0-a5f7c90592e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-fa489992-b491-4ebb-88bf-e90214f3c9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-4e90ee8c-7585-4b08-b8e0-89d8848d35f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-618173436-172.17.0.19-1597652096488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43561,DS-8e3cc6d2-4953-48fb-bd6d-4a4cbb1a4045,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-eaa01f93-fbff-4a24-8bbc-959ff3d14f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-c436356d-9f6c-48a7-8860-8ae2673840c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-271e160c-e36c-4642-8463-02939332f322,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-185d1c43-f751-41a6-8f6f-25c0e1d0adae,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-edeb6fc0-1be8-43d6-87d0-a5f7c90592e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-fa489992-b491-4ebb-88bf-e90214f3c9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-4e90ee8c-7585-4b08-b8e0-89d8848d35f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1667756910-172.17.0.19-1597652207544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43756,DS-5bd73015-4f69-47d3-8ba3-bc827645db91,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-c8433814-f79f-4d00-851a-5ae2c486ee8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-bffe91ae-b69e-4140-81d4-8002c42aa76f,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-894f9fd3-b8ad-4df8-8636-e55df364693b,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-6bb3186b-d36a-4400-ab52-51a84c4c0d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-8605456d-b349-4dd1-89cb-25f277bf3c33,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-253b86a3-28cd-4a87-babc-699b2cde5280,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-d6ba5fdf-7344-4cbf-ab9b-b4d5b1947805,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1667756910-172.17.0.19-1597652207544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43756,DS-5bd73015-4f69-47d3-8ba3-bc827645db91,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-c8433814-f79f-4d00-851a-5ae2c486ee8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-bffe91ae-b69e-4140-81d4-8002c42aa76f,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-894f9fd3-b8ad-4df8-8636-e55df364693b,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-6bb3186b-d36a-4400-ab52-51a84c4c0d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-8605456d-b349-4dd1-89cb-25f277bf3c33,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-253b86a3-28cd-4a87-babc-699b2cde5280,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-d6ba5fdf-7344-4cbf-ab9b-b4d5b1947805,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-979274094-172.17.0.19-1597653002690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36671,DS-83b748b8-bd8f-4224-8d53-86f32146fd58,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-33b80226-ecf1-44fb-8913-5505762e3168,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-3bae7d33-d55f-4083-a10e-e40bcb5f30ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-e9bce5d1-4733-4e6a-9380-ae5690138404,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-6a72880c-d42d-4523-8232-353572fc9d60,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-15afccab-14f6-43f6-8c8f-eaa05bdc5c26,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-adbc4080-38f7-49b5-8b5a-53113dbf6b61,DISK], DatanodeInfoWithStorage[127.0.0.1:46690,DS-f016b7b9-805b-4740-87b8-3efde13f53fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-979274094-172.17.0.19-1597653002690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36671,DS-83b748b8-bd8f-4224-8d53-86f32146fd58,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-33b80226-ecf1-44fb-8913-5505762e3168,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-3bae7d33-d55f-4083-a10e-e40bcb5f30ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-e9bce5d1-4733-4e6a-9380-ae5690138404,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-6a72880c-d42d-4523-8232-353572fc9d60,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-15afccab-14f6-43f6-8c8f-eaa05bdc5c26,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-adbc4080-38f7-49b5-8b5a-53113dbf6b61,DISK], DatanodeInfoWithStorage[127.0.0.1:46690,DS-f016b7b9-805b-4740-87b8-3efde13f53fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-174344610-172.17.0.19-1597653044138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35329,DS-9fcb72b1-42ff-4f2f-9d2f-74ea323e960e,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-9ccc5b13-2eed-404b-84c3-94178c5eace0,DISK], DatanodeInfoWithStorage[127.0.0.1:42223,DS-49d7b3a8-a71c-4a1f-ac47-bdf516243eea,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-deb67393-a9d7-4606-9e52-2a2ffea16938,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-47fcc072-2082-4e0d-97fd-359106657098,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-2584051b-284e-4cf7-9b21-ab31f42cff9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-098151de-a8ed-4fd4-a41e-d4258c611c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-5c400fb5-502a-4a59-9aa1-65ebdc47dfe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-174344610-172.17.0.19-1597653044138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35329,DS-9fcb72b1-42ff-4f2f-9d2f-74ea323e960e,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-9ccc5b13-2eed-404b-84c3-94178c5eace0,DISK], DatanodeInfoWithStorage[127.0.0.1:42223,DS-49d7b3a8-a71c-4a1f-ac47-bdf516243eea,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-deb67393-a9d7-4606-9e52-2a2ffea16938,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-47fcc072-2082-4e0d-97fd-359106657098,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-2584051b-284e-4cf7-9b21-ab31f42cff9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-098151de-a8ed-4fd4-a41e-d4258c611c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-5c400fb5-502a-4a59-9aa1-65ebdc47dfe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026388545-172.17.0.19-1597653849500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33345,DS-f9d62ccb-7031-445e-8876-4d83eb6e565a,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-3b2db2fd-fdbc-4386-8ee5-562fe212c53d,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-8c1a571c-f8fb-4b98-a13a-104ad927cc43,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-e824cefe-b81d-4ae4-a534-1d5e70f968fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-59d89c95-ef70-4c20-a59f-258187d9e0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-7289b343-e40a-45e0-a4f0-11f1023e5225,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-6389ff9c-af29-4570-9773-36cb67e5f132,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-70b2b1b5-896d-459b-bab5-e73a4c07c445,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026388545-172.17.0.19-1597653849500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33345,DS-f9d62ccb-7031-445e-8876-4d83eb6e565a,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-3b2db2fd-fdbc-4386-8ee5-562fe212c53d,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-8c1a571c-f8fb-4b98-a13a-104ad927cc43,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-e824cefe-b81d-4ae4-a534-1d5e70f968fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-59d89c95-ef70-4c20-a59f-258187d9e0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-7289b343-e40a-45e0-a4f0-11f1023e5225,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-6389ff9c-af29-4570-9773-36cb67e5f132,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-70b2b1b5-896d-459b-bab5-e73a4c07c445,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267195984-172.17.0.19-1597654884762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39484,DS-4f90da6e-79c1-4b36-9fc2-0fc2fdc453b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-fcea4b42-5143-49ea-842b-62c08d9260f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-a6772f31-2703-436a-bc89-dde6d2f1573c,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-9924d60a-d3eb-4f77-a46e-b4fe7d28e574,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-0e234736-028e-443b-be3b-d106805e33c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-2759428b-6250-4ac1-b1e2-6abbfdf30e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-3eff54cc-c4fc-4573-9e8c-0521e54889ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-1c44df7e-390a-4629-add0-6b7f1cb8fa14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267195984-172.17.0.19-1597654884762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39484,DS-4f90da6e-79c1-4b36-9fc2-0fc2fdc453b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-fcea4b42-5143-49ea-842b-62c08d9260f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-a6772f31-2703-436a-bc89-dde6d2f1573c,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-9924d60a-d3eb-4f77-a46e-b4fe7d28e574,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-0e234736-028e-443b-be3b-d106805e33c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-2759428b-6250-4ac1-b1e2-6abbfdf30e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-3eff54cc-c4fc-4573-9e8c-0521e54889ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-1c44df7e-390a-4629-add0-6b7f1cb8fa14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1605790778-172.17.0.19-1597655219010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34526,DS-7dddb995-732d-43b4-a9f0-ddb6e85e566b,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-3ccc3412-5fc8-41af-8a8e-8900c15eec77,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-3e195406-1634-4d08-8d2a-65bb3bf7664a,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-4a4490f7-9324-4ba6-85ca-c8ece5a38d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-20fec223-7667-40c7-9f11-a3b1b39bd902,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-38c96c57-3873-4642-acfb-a13262ff7484,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-30faad61-b896-4bef-b83b-941341ed8f80,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-7837bfae-48e5-4b56-a947-fb76d464ec7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1605790778-172.17.0.19-1597655219010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34526,DS-7dddb995-732d-43b4-a9f0-ddb6e85e566b,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-3ccc3412-5fc8-41af-8a8e-8900c15eec77,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-3e195406-1634-4d08-8d2a-65bb3bf7664a,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-4a4490f7-9324-4ba6-85ca-c8ece5a38d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-20fec223-7667-40c7-9f11-a3b1b39bd902,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-38c96c57-3873-4642-acfb-a13262ff7484,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-30faad61-b896-4bef-b83b-941341ed8f80,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-7837bfae-48e5-4b56-a947-fb76d464ec7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-62695449-172.17.0.19-1597655604132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40369,DS-15995e5f-368f-47ac-a350-7b4543c3ef55,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-3371b466-e43a-43d4-af84-3d44e6229fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-90c5bbda-41fb-411f-909a-d80a9aedde7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-f1a63aa3-e406-4918-875f-ded107c9cd44,DISK], DatanodeInfoWithStorage[127.0.0.1:35581,DS-4917f74a-c8d8-4728-9607-b029fad9ca02,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-6cf24fd8-b70d-47b1-89a0-7f9e779f4cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-1da4cb58-75a0-4883-892b-d1f9c99c1e31,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-994e36ee-ba78-48d6-a4e0-478eac359176,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-62695449-172.17.0.19-1597655604132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40369,DS-15995e5f-368f-47ac-a350-7b4543c3ef55,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-3371b466-e43a-43d4-af84-3d44e6229fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-90c5bbda-41fb-411f-909a-d80a9aedde7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-f1a63aa3-e406-4918-875f-ded107c9cd44,DISK], DatanodeInfoWithStorage[127.0.0.1:35581,DS-4917f74a-c8d8-4728-9607-b029fad9ca02,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-6cf24fd8-b70d-47b1-89a0-7f9e779f4cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-1da4cb58-75a0-4883-892b-d1f9c99c1e31,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-994e36ee-ba78-48d6-a4e0-478eac359176,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-424017114-172.17.0.19-1597656464118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44659,DS-a55e8e6f-25d2-483e-9520-3f748f017ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-29fa2d13-b47f-4fd9-9e8f-51c96bbc1abd,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-021611a2-9878-46c0-9a09-392fbc1ebe79,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-263308c1-19ba-4194-8712-c6d58d4b1be0,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-b58d65e6-80bc-48b7-91e2-2c58543b0f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-95341b9a-d5c3-4a4b-8751-b8b9127f0385,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-857abf0d-1d8d-41c4-9481-81ab2f7d5c22,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-a5f2ce81-d9dd-4d84-8de9-f82e7304900c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-424017114-172.17.0.19-1597656464118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44659,DS-a55e8e6f-25d2-483e-9520-3f748f017ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-29fa2d13-b47f-4fd9-9e8f-51c96bbc1abd,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-021611a2-9878-46c0-9a09-392fbc1ebe79,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-263308c1-19ba-4194-8712-c6d58d4b1be0,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-b58d65e6-80bc-48b7-91e2-2c58543b0f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-95341b9a-d5c3-4a4b-8751-b8b9127f0385,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-857abf0d-1d8d-41c4-9481-81ab2f7d5c22,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-a5f2ce81-d9dd-4d84-8de9-f82e7304900c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-389506273-172.17.0.19-1597656615292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46221,DS-02d4126b-f440-46cd-8d9e-4fbc2d357928,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-887d140f-ea30-4718-b12a-87df197a62f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-5748e5c1-1727-431d-b607-868f1a942a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-d7660ec0-3f6d-4da9-b7b3-91de8ebaa303,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-1586a28d-29d0-462e-be47-3c8ccafc45e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-4a19ded2-1bd4-4674-9303-9df61b326c68,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-bff1cc41-cba8-4e1d-8e70-20a4d24f3596,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-f9ed7fab-9ab1-4062-9f5f-6a6889447081,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-389506273-172.17.0.19-1597656615292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46221,DS-02d4126b-f440-46cd-8d9e-4fbc2d357928,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-887d140f-ea30-4718-b12a-87df197a62f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-5748e5c1-1727-431d-b607-868f1a942a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-d7660ec0-3f6d-4da9-b7b3-91de8ebaa303,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-1586a28d-29d0-462e-be47-3c8ccafc45e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-4a19ded2-1bd4-4674-9303-9df61b326c68,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-bff1cc41-cba8-4e1d-8e70-20a4d24f3596,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-f9ed7fab-9ab1-4062-9f5f-6a6889447081,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1608688212-172.17.0.19-1597656693732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35082,DS-ca58dc44-0396-4c31-bb6a-f56b703fb760,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-c24205e0-b8b6-4c8f-9ae7-bbcecdd83366,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-9af0a854-b7d5-4599-9fa5-a09a6e93ec91,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-4e7741e9-fc94-4f86-8110-f9d8aba4b9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-a921a4e3-f723-4d87-b56a-0d9612567f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45871,DS-66c9053d-be47-4090-a167-016f888b47c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-ce0f234d-c842-49cc-a3b8-62259752a0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-f244baea-1741-4685-8530-7b588c586bf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1608688212-172.17.0.19-1597656693732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35082,DS-ca58dc44-0396-4c31-bb6a-f56b703fb760,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-c24205e0-b8b6-4c8f-9ae7-bbcecdd83366,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-9af0a854-b7d5-4599-9fa5-a09a6e93ec91,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-4e7741e9-fc94-4f86-8110-f9d8aba4b9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-a921a4e3-f723-4d87-b56a-0d9612567f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45871,DS-66c9053d-be47-4090-a167-016f888b47c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-ce0f234d-c842-49cc-a3b8-62259752a0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-f244baea-1741-4685-8530-7b588c586bf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-193695376-172.17.0.19-1597656734203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36362,DS-a3fc0f67-1816-4cb2-9450-2e55c2e1bc33,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-446f9863-41c0-46c5-bf34-75fac832f84a,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-f8685880-42df-4806-99a0-5b8b3c42865f,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-91adaaa7-e295-4d89-98e6-3a7a207fe0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-65e6fe9d-6067-4f4e-9c33-ed65b7ef0ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:35866,DS-f3ce84ca-af6d-4f2b-9b62-04f417a969c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-0c3ea3ba-e932-44bb-8967-2a55848d73e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-0ce73d55-2691-495e-9ccc-bc6bfe7c496f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-193695376-172.17.0.19-1597656734203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36362,DS-a3fc0f67-1816-4cb2-9450-2e55c2e1bc33,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-446f9863-41c0-46c5-bf34-75fac832f84a,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-f8685880-42df-4806-99a0-5b8b3c42865f,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-91adaaa7-e295-4d89-98e6-3a7a207fe0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-65e6fe9d-6067-4f4e-9c33-ed65b7ef0ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:35866,DS-f3ce84ca-af6d-4f2b-9b62-04f417a969c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-0c3ea3ba-e932-44bb-8967-2a55848d73e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-0ce73d55-2691-495e-9ccc-bc6bfe7c496f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 5000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052019285-172.17.0.19-1597656844678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38421,DS-d74186d9-dc38-4a28-ab09-28ee7febb994,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-03fcc784-2e38-4810-b039-d35b105f8038,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-6882ff9d-1a24-4891-abee-4864c0e3fe40,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-369b1366-576d-48f3-a9ff-dcd16f734e67,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-34801e76-cc25-471c-abe3-4c6301ae4986,DISK], DatanodeInfoWithStorage[127.0.0.1:40549,DS-23765788-7027-46d7-80b6-be85fb2e1d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-3daf888b-5be1-4447-a7af-0dcfa12cff73,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-61b8a0eb-e2bb-41f3-8b89-8baacb11a347,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052019285-172.17.0.19-1597656844678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38421,DS-d74186d9-dc38-4a28-ab09-28ee7febb994,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-03fcc784-2e38-4810-b039-d35b105f8038,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-6882ff9d-1a24-4891-abee-4864c0e3fe40,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-369b1366-576d-48f3-a9ff-dcd16f734e67,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-34801e76-cc25-471c-abe3-4c6301ae4986,DISK], DatanodeInfoWithStorage[127.0.0.1:40549,DS-23765788-7027-46d7-80b6-be85fb2e1d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-3daf888b-5be1-4447-a7af-0dcfa12cff73,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-61b8a0eb-e2bb-41f3-8b89-8baacb11a347,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5756
