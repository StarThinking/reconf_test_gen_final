reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-196896938-172.17.0.3-1597413065861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34533,DS-b6d619bb-bc82-401b-a95c-a3a0e71d154c,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-3ad4127b-8f30-4ee1-8ea6-90ef5c736544,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-3bd26836-b00e-4a29-a651-fb9ced5ac243,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-c4779faa-05ab-4307-b727-18271c97033e,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-92bfadac-e44a-4cc0-a1f9-07fb6be9827e,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-11829687-3ac4-4ac6-b5a1-af6a66c27c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-c6eba818-5cd7-4cc9-bd8b-0879b27ec642,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-cff2c2e6-7765-498f-955c-4801fb91079b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-196896938-172.17.0.3-1597413065861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34533,DS-b6d619bb-bc82-401b-a95c-a3a0e71d154c,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-3ad4127b-8f30-4ee1-8ea6-90ef5c736544,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-3bd26836-b00e-4a29-a651-fb9ced5ac243,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-c4779faa-05ab-4307-b727-18271c97033e,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-92bfadac-e44a-4cc0-a1f9-07fb6be9827e,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-11829687-3ac4-4ac6-b5a1-af6a66c27c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-c6eba818-5cd7-4cc9-bd8b-0879b27ec642,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-cff2c2e6-7765-498f-955c-4801fb91079b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1164551685-172.17.0.3-1597413173372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32853,DS-26fcd565-eb75-4737-a79a-cc1ece9d95c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-115da728-03a3-4f7b-bd5e-8412de0d9486,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-ac6fbb71-b9d0-4677-b9e6-713c4254becc,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-4e5f8b4e-6924-4c46-928a-95afd2894073,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-c7cd1cf6-03f6-4bb4-917d-72d9d2fe29c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-9735b653-3237-4815-9a59-0beb9a2668c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-06691389-7249-488e-bbcb-3ad7201f97be,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-46e53fc8-e538-4cf0-a0d3-3c2707a851f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1164551685-172.17.0.3-1597413173372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32853,DS-26fcd565-eb75-4737-a79a-cc1ece9d95c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-115da728-03a3-4f7b-bd5e-8412de0d9486,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-ac6fbb71-b9d0-4677-b9e6-713c4254becc,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-4e5f8b4e-6924-4c46-928a-95afd2894073,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-c7cd1cf6-03f6-4bb4-917d-72d9d2fe29c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-9735b653-3237-4815-9a59-0beb9a2668c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-06691389-7249-488e-bbcb-3ad7201f97be,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-46e53fc8-e538-4cf0-a0d3-3c2707a851f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1548421078-172.17.0.3-1597413210933:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33213,DS-f0fe8c28-552b-4124-a791-aa2b80dd7bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-124acdf3-0b80-4d6f-8425-9913d3c06afa,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-ef7ffb9c-3c69-4886-85ed-69067e9a6c56,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-dcb62edf-af19-4d83-bc7d-698b850fd0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-6c09d7b7-45a4-46cb-a73f-5b1ab7719af1,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-fc52c250-f8c2-4499-9aa9-5904b41b797b,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-16baddab-7055-47be-bc22-b97b74941a29,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-9448d259-5607-45a4-9117-1aa4031b4de0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1548421078-172.17.0.3-1597413210933:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33213,DS-f0fe8c28-552b-4124-a791-aa2b80dd7bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-124acdf3-0b80-4d6f-8425-9913d3c06afa,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-ef7ffb9c-3c69-4886-85ed-69067e9a6c56,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-dcb62edf-af19-4d83-bc7d-698b850fd0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-6c09d7b7-45a4-46cb-a73f-5b1ab7719af1,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-fc52c250-f8c2-4499-9aa9-5904b41b797b,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-16baddab-7055-47be-bc22-b97b74941a29,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-9448d259-5607-45a4-9117-1aa4031b4de0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-924355909-172.17.0.3-1597413476542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34311,DS-f195dbe0-7b3e-4f63-9e47-ecd3efce3897,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-91437fde-a9fc-4e3f-9c9b-ef7bc8d7b33e,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-f04b47e8-7a41-4df5-887a-e04ee06ecca0,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-07a1e9ab-179e-439a-ae45-ecb4398cc684,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-5ff9d807-de6a-4e70-8a61-ef6ce96e9e67,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-af16794d-8f2b-49e7-8fd1-52695d24fab9,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-35a819af-8bb4-4d5a-ae03-1020944e824b,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-5a898e57-1a50-4800-9eec-cb25230365c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-924355909-172.17.0.3-1597413476542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34311,DS-f195dbe0-7b3e-4f63-9e47-ecd3efce3897,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-91437fde-a9fc-4e3f-9c9b-ef7bc8d7b33e,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-f04b47e8-7a41-4df5-887a-e04ee06ecca0,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-07a1e9ab-179e-439a-ae45-ecb4398cc684,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-5ff9d807-de6a-4e70-8a61-ef6ce96e9e67,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-af16794d-8f2b-49e7-8fd1-52695d24fab9,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-35a819af-8bb4-4d5a-ae03-1020944e824b,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-5a898e57-1a50-4800-9eec-cb25230365c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-655313458-172.17.0.3-1597415075993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36826,DS-3c2ec5fc-5f50-48cd-b371-29f7564226f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-7ed11772-0855-40a9-8426-466ffab58cce,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-ace06098-c6aa-4721-9904-1b5146c701c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-53ad5f8a-62c3-4d2d-8bc0-b4be591b7a27,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-0ea5e62f-8436-4b35-b11e-9f9a57fdbacc,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-50195da7-1dd0-4f59-98f5-a982ff5d8146,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-ef3d62f1-d2e3-4e97-805f-98d0ef4abd84,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-d4b10cf5-7b26-470c-8ce2-15ed90661a0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-655313458-172.17.0.3-1597415075993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36826,DS-3c2ec5fc-5f50-48cd-b371-29f7564226f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-7ed11772-0855-40a9-8426-466ffab58cce,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-ace06098-c6aa-4721-9904-1b5146c701c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-53ad5f8a-62c3-4d2d-8bc0-b4be591b7a27,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-0ea5e62f-8436-4b35-b11e-9f9a57fdbacc,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-50195da7-1dd0-4f59-98f5-a982ff5d8146,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-ef3d62f1-d2e3-4e97-805f-98d0ef4abd84,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-d4b10cf5-7b26-470c-8ce2-15ed90661a0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1065836890-172.17.0.3-1597415512406:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39718,DS-cedd946d-72e5-4381-b203-bf876885fd38,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-861a41f2-9769-4d44-ba43-1988d46e3c55,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-e9ee888e-a0e1-4823-9764-8f56a02e2e45,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-219b47fc-756a-4f2a-86a5-9efb7625661e,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-51a08800-bdc1-4db1-9bde-2470e712d855,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-cb4db85b-22df-402a-b2a0-2934a26503a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40722,DS-b0b23d7a-11a6-4ca0-9b23-ba186fd2f607,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-27087ebf-c59e-46e9-8efb-1f0125805ae1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1065836890-172.17.0.3-1597415512406:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39718,DS-cedd946d-72e5-4381-b203-bf876885fd38,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-861a41f2-9769-4d44-ba43-1988d46e3c55,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-e9ee888e-a0e1-4823-9764-8f56a02e2e45,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-219b47fc-756a-4f2a-86a5-9efb7625661e,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-51a08800-bdc1-4db1-9bde-2470e712d855,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-cb4db85b-22df-402a-b2a0-2934a26503a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40722,DS-b0b23d7a-11a6-4ca0-9b23-ba186fd2f607,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-27087ebf-c59e-46e9-8efb-1f0125805ae1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2011375379-172.17.0.3-1597415846579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42131,DS-0da8f0e5-620c-4f5f-b5ae-1eeec6c5eb79,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-eaf25d75-953b-4182-a46d-492960d1e402,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-a4776e84-c3a1-4ba0-8040-fdd416a69034,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-1d21cfe0-3baf-4269-9eb1-732dcde25470,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-07b986e5-e1f9-44aa-bbf2-17b636d4e556,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-4649cbc4-2392-46c0-82a4-2af41e06efc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-0c5af074-6241-4153-8ef1-f8e56d12d50f,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-bf74911d-6df2-4e53-9e25-0ff2f33b7831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2011375379-172.17.0.3-1597415846579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42131,DS-0da8f0e5-620c-4f5f-b5ae-1eeec6c5eb79,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-eaf25d75-953b-4182-a46d-492960d1e402,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-a4776e84-c3a1-4ba0-8040-fdd416a69034,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-1d21cfe0-3baf-4269-9eb1-732dcde25470,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-07b986e5-e1f9-44aa-bbf2-17b636d4e556,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-4649cbc4-2392-46c0-82a4-2af41e06efc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-0c5af074-6241-4153-8ef1-f8e56d12d50f,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-bf74911d-6df2-4e53-9e25-0ff2f33b7831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-797334918-172.17.0.3-1597415961599:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46543,DS-f2e77ce3-bf96-4636-aaa6-026c8154d99f,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-3b8ae0ca-461f-4a9d-be43-bfd2fa927d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-47d7971e-9685-4485-8186-d233b6e3f25b,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-42806527-ce77-4f5e-b637-8f42fd06a496,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-e3f277f3-7b1d-4083-addc-bd9a81f489c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-7189ba0a-09fc-45ab-8c6c-96c869119f02,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-a3b69cad-10e8-4256-bdcb-a356f80103a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-52b24833-9f43-4a11-9008-e37f4dc01dd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-797334918-172.17.0.3-1597415961599:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46543,DS-f2e77ce3-bf96-4636-aaa6-026c8154d99f,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-3b8ae0ca-461f-4a9d-be43-bfd2fa927d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-47d7971e-9685-4485-8186-d233b6e3f25b,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-42806527-ce77-4f5e-b637-8f42fd06a496,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-e3f277f3-7b1d-4083-addc-bd9a81f489c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-7189ba0a-09fc-45ab-8c6c-96c869119f02,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-a3b69cad-10e8-4256-bdcb-a356f80103a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-52b24833-9f43-4a11-9008-e37f4dc01dd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-193508910-172.17.0.3-1597416173718:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39635,DS-e907121b-b8f4-4155-b072-638d01215f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45415,DS-addfb478-c27a-44ea-b05f-d17faab436bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-83aabc5f-dbb0-4604-a025-ad03a2e9099c,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-46f8a5ee-b428-45e2-a21c-28a1b3fe0156,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-388801d0-b680-4da3-8022-c6000435148d,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-5db659c7-7136-4e75-bf17-0bc849fbd325,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-b3b87952-5a6f-4aa8-a1ee-d9df122d990a,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-1944a8da-2dfc-4f69-a168-b1fc3b7cc547,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-193508910-172.17.0.3-1597416173718:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39635,DS-e907121b-b8f4-4155-b072-638d01215f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45415,DS-addfb478-c27a-44ea-b05f-d17faab436bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-83aabc5f-dbb0-4604-a025-ad03a2e9099c,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-46f8a5ee-b428-45e2-a21c-28a1b3fe0156,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-388801d0-b680-4da3-8022-c6000435148d,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-5db659c7-7136-4e75-bf17-0bc849fbd325,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-b3b87952-5a6f-4aa8-a1ee-d9df122d990a,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-1944a8da-2dfc-4f69-a168-b1fc3b7cc547,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1219341060-172.17.0.3-1597416530975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46763,DS-d549b06f-b616-42d8-8dd5-4cf14b89da60,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-a276b4ba-30b0-4404-a769-2373401ce107,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-a031c47a-71a0-4fca-a62d-f057596ba3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-f16c3533-8627-4b33-9d17-f3bb689f840b,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-83c13ab4-d205-46d2-af59-05ccfe22e337,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-2ecc4324-9d34-46bc-b398-e74f01975e71,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-54ada32c-52a9-4a4e-9189-d709b6080af1,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-40a9c6cf-693b-4f3b-9a96-152096b38876,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1219341060-172.17.0.3-1597416530975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46763,DS-d549b06f-b616-42d8-8dd5-4cf14b89da60,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-a276b4ba-30b0-4404-a769-2373401ce107,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-a031c47a-71a0-4fca-a62d-f057596ba3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-f16c3533-8627-4b33-9d17-f3bb689f840b,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-83c13ab4-d205-46d2-af59-05ccfe22e337,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-2ecc4324-9d34-46bc-b398-e74f01975e71,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-54ada32c-52a9-4a4e-9189-d709b6080af1,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-40a9c6cf-693b-4f3b-9a96-152096b38876,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-11031098-172.17.0.3-1597416682170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45336,DS-5720acac-a81f-465a-bbdd-d42bd584bcf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-550f15d8-501a-4b39-9ecd-7e6bda916d61,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-ae2d4bb2-7926-474e-8370-7e3f8b6e24f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-5fd5b09d-1069-4db6-9f12-63d4a7bbec47,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-fc2184a5-eafa-4ef6-a7ba-9c758d67cc91,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-5fec7374-25b2-42b1-aa32-00889feb0269,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-47f548b0-9e2f-438c-a1dc-4917dd9ba0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-6d76d17b-f5c0-4f4e-91da-933364ef1dc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-11031098-172.17.0.3-1597416682170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45336,DS-5720acac-a81f-465a-bbdd-d42bd584bcf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-550f15d8-501a-4b39-9ecd-7e6bda916d61,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-ae2d4bb2-7926-474e-8370-7e3f8b6e24f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-5fd5b09d-1069-4db6-9f12-63d4a7bbec47,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-fc2184a5-eafa-4ef6-a7ba-9c758d67cc91,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-5fec7374-25b2-42b1-aa32-00889feb0269,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-47f548b0-9e2f-438c-a1dc-4917dd9ba0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-6d76d17b-f5c0-4f4e-91da-933364ef1dc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-530184423-172.17.0.3-1597416967461:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42886,DS-61a8cef5-465a-4e4a-8cde-8b156133b3da,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-473edcef-3f0c-47f7-9a41-c3b696615fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-0028a97a-afd7-426c-a3b8-9bac0b86643b,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-47bfcac7-38bb-4cff-9b13-342855f9451d,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-f5be7bf3-df98-40c5-9e6b-c70c3fe89771,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-be2951ac-2e05-45aa-85b7-0d47f66ed6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-30d09a26-ac01-4019-b367-8914b2760091,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-3e050716-46b1-4f6f-90e0-1a0feac751d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-530184423-172.17.0.3-1597416967461:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42886,DS-61a8cef5-465a-4e4a-8cde-8b156133b3da,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-473edcef-3f0c-47f7-9a41-c3b696615fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-0028a97a-afd7-426c-a3b8-9bac0b86643b,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-47bfcac7-38bb-4cff-9b13-342855f9451d,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-f5be7bf3-df98-40c5-9e6b-c70c3fe89771,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-be2951ac-2e05-45aa-85b7-0d47f66ed6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-30d09a26-ac01-4019-b367-8914b2760091,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-3e050716-46b1-4f6f-90e0-1a0feac751d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1519594675-172.17.0.3-1597417231862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35640,DS-d77b8f01-60ea-40d3-a80e-defad2e2f6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-386d0d6a-3713-4f6d-92f0-92d1e914f6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-339972e9-95d2-44da-b372-62498448b96d,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-9a112b8e-eb96-4315-a347-d887546c5968,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-e2d8b225-3f2d-464d-bc17-0971d66b09aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-3062d567-f3da-4690-89c2-d71bec3de53b,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-561a0265-27eb-4461-a9eb-b997a109f983,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-84b300a2-826d-4741-b98c-50dacbc55e45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1519594675-172.17.0.3-1597417231862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35640,DS-d77b8f01-60ea-40d3-a80e-defad2e2f6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-386d0d6a-3713-4f6d-92f0-92d1e914f6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-339972e9-95d2-44da-b372-62498448b96d,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-9a112b8e-eb96-4315-a347-d887546c5968,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-e2d8b225-3f2d-464d-bc17-0971d66b09aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-3062d567-f3da-4690-89c2-d71bec3de53b,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-561a0265-27eb-4461-a9eb-b997a109f983,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-84b300a2-826d-4741-b98c-50dacbc55e45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1359899019-172.17.0.3-1597417626644:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37891,DS-151f0033-da63-432f-8f8a-8377eed564a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-e85c764e-a6c2-436b-ba09-3f9176cb6029,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-b36b7f3a-183d-46fe-a51b-e539683533c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-d8c598a7-c50e-45e5-8ad5-4059abf1b767,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-7402ce32-cb0c-497d-8c89-ff8f80b3ba34,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-1b12467a-6464-4dd7-a1ee-9e923a6acd4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-f8fff29a-0432-49d9-8bc8-3710e0a4c650,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-d27d35a2-9097-4091-affe-99cc470ad0cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1359899019-172.17.0.3-1597417626644:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37891,DS-151f0033-da63-432f-8f8a-8377eed564a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-e85c764e-a6c2-436b-ba09-3f9176cb6029,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-b36b7f3a-183d-46fe-a51b-e539683533c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-d8c598a7-c50e-45e5-8ad5-4059abf1b767,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-7402ce32-cb0c-497d-8c89-ff8f80b3ba34,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-1b12467a-6464-4dd7-a1ee-9e923a6acd4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-f8fff29a-0432-49d9-8bc8-3710e0a4c650,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-d27d35a2-9097-4091-affe-99cc470ad0cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1484203622-172.17.0.3-1597417947471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36820,DS-d32a1371-b1b2-45bf-b50a-e65e079f22ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-3b74d0c1-8108-48a8-a404-f05e550baab0,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-7b925f34-a2f5-4be3-99ba-14c295cc83e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-ba773fc8-05a8-4cbe-8b25-c645aa962b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-76dc381f-cec9-4cd2-a13f-97793726c928,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-7c6d6062-0b7a-4f32-8e1c-cf0cc85e9e92,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-4c22264d-00b9-4958-81f7-0ebbc0e1abde,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-9909b78d-fe1e-43c3-9330-7c88eb1a9b7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1484203622-172.17.0.3-1597417947471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36820,DS-d32a1371-b1b2-45bf-b50a-e65e079f22ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-3b74d0c1-8108-48a8-a404-f05e550baab0,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-7b925f34-a2f5-4be3-99ba-14c295cc83e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-ba773fc8-05a8-4cbe-8b25-c645aa962b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-76dc381f-cec9-4cd2-a13f-97793726c928,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-7c6d6062-0b7a-4f32-8e1c-cf0cc85e9e92,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-4c22264d-00b9-4958-81f7-0ebbc0e1abde,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-9909b78d-fe1e-43c3-9330-7c88eb1a9b7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-437517568-172.17.0.3-1597418245097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44759,DS-5ed3b707-b3d4-40c0-9645-851b657f2b69,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-ee9a0166-8b4c-4beb-9931-4f082c94c250,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-f6b21ff3-0377-4f11-8857-2cb5867dfbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-2f55e2b1-d73a-4689-8f78-4c45a28dd44b,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-4286e415-c61a-4830-87ce-947563767200,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-d9f158d1-7f8c-473a-8b96-a1055bf3ef40,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-35700ef0-bf02-4310-98c3-39e6207043a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-0551058b-910f-45fc-a247-9efcf5cf49d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-437517568-172.17.0.3-1597418245097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44759,DS-5ed3b707-b3d4-40c0-9645-851b657f2b69,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-ee9a0166-8b4c-4beb-9931-4f082c94c250,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-f6b21ff3-0377-4f11-8857-2cb5867dfbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-2f55e2b1-d73a-4689-8f78-4c45a28dd44b,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-4286e415-c61a-4830-87ce-947563767200,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-d9f158d1-7f8c-473a-8b96-a1055bf3ef40,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-35700ef0-bf02-4310-98c3-39e6207043a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-0551058b-910f-45fc-a247-9efcf5cf49d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5527
