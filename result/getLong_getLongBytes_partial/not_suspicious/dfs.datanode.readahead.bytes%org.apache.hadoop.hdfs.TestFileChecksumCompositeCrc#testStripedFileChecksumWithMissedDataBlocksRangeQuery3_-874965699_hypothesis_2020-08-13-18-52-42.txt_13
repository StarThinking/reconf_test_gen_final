reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1114182371-172.17.0.16-1597344949895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39252,DS-58c50973-a615-427c-95c6-7924a5bf0f74,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-eb876b38-7203-46e3-9774-530c801e8146,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-1957b96c-6d39-45d6-b123-8ec8efb7d835,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-23d8c511-edc2-4777-9da5-139eb7648d17,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-26e73c06-8249-4866-a833-84982c65c21e,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-676dfb97-1dd1-4d1f-87df-00fb5632bc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-71da49ca-9355-4672-b23c-dd43ab15bb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-26c8f049-31af-44d5-8a38-f48cfb7caf8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1114182371-172.17.0.16-1597344949895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39252,DS-58c50973-a615-427c-95c6-7924a5bf0f74,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-eb876b38-7203-46e3-9774-530c801e8146,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-1957b96c-6d39-45d6-b123-8ec8efb7d835,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-23d8c511-edc2-4777-9da5-139eb7648d17,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-26e73c06-8249-4866-a833-84982c65c21e,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-676dfb97-1dd1-4d1f-87df-00fb5632bc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-71da49ca-9355-4672-b23c-dd43ab15bb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-26c8f049-31af-44d5-8a38-f48cfb7caf8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450225589-172.17.0.16-1597344987367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35779,DS-3ec26edb-241c-41a8-aa5b-ff4384e3493b,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-1702cd51-123e-4870-9955-27f83f537036,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-0568a386-e8ae-4cc1-812b-69146dece3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-3dfbd7eb-bc05-401a-b627-15ae08292fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-ea93e6b4-b30a-4c6a-84c7-da61c38803b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-27f89070-efc2-4bd7-8de5-e092c9effca1,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-b4e7987f-c089-47f8-b25f-7c4de9a0e296,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-c606f96c-effc-4ced-8b23-e49c8e5dfe2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450225589-172.17.0.16-1597344987367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35779,DS-3ec26edb-241c-41a8-aa5b-ff4384e3493b,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-1702cd51-123e-4870-9955-27f83f537036,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-0568a386-e8ae-4cc1-812b-69146dece3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-3dfbd7eb-bc05-401a-b627-15ae08292fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-ea93e6b4-b30a-4c6a-84c7-da61c38803b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-27f89070-efc2-4bd7-8de5-e092c9effca1,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-b4e7987f-c089-47f8-b25f-7c4de9a0e296,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-c606f96c-effc-4ced-8b23-e49c8e5dfe2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011691501-172.17.0.16-1597345069648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34937,DS-982069bd-3cc3-44e8-8bf9-543cb7883f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-0ec89a95-f2e8-45db-b82e-c070092901b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-77c54ba6-634d-4b17-9bea-f8b801e6bff0,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-76670165-541f-4ab2-81c6-8320b8d174cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-3a6e2518-5944-42bd-a365-41df61f8e579,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-0d66bd48-c280-4ea9-9b40-2bddfea16710,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-e03621fb-2721-493d-9c5f-c1c8bbdaceb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-cdfd5816-966b-44dc-8030-962c32ccbe71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011691501-172.17.0.16-1597345069648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34937,DS-982069bd-3cc3-44e8-8bf9-543cb7883f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-0ec89a95-f2e8-45db-b82e-c070092901b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-77c54ba6-634d-4b17-9bea-f8b801e6bff0,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-76670165-541f-4ab2-81c6-8320b8d174cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-3a6e2518-5944-42bd-a365-41df61f8e579,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-0d66bd48-c280-4ea9-9b40-2bddfea16710,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-e03621fb-2721-493d-9c5f-c1c8bbdaceb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-cdfd5816-966b-44dc-8030-962c32ccbe71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1290544584-172.17.0.16-1597345301777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44175,DS-ff50f725-da78-474a-b795-c8fc58c4951a,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-51819171-9eaa-4eb3-9ecb-b6ceb2b149d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-b94191c8-dc28-4c64-921a-643ebc00fe9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-55c4ca60-541e-454f-8eec-3736591e6e33,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-9028f647-0d44-4b2a-a593-16e4ee060b30,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-504d784b-7504-41e2-b58c-223eff384982,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-838e24bc-8322-4578-b0e6-a233c860e9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-c610f81c-6fcf-4bfa-9cf9-3504405b29e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1290544584-172.17.0.16-1597345301777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44175,DS-ff50f725-da78-474a-b795-c8fc58c4951a,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-51819171-9eaa-4eb3-9ecb-b6ceb2b149d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-b94191c8-dc28-4c64-921a-643ebc00fe9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-55c4ca60-541e-454f-8eec-3736591e6e33,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-9028f647-0d44-4b2a-a593-16e4ee060b30,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-504d784b-7504-41e2-b58c-223eff384982,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-838e24bc-8322-4578-b0e6-a233c860e9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-c610f81c-6fcf-4bfa-9cf9-3504405b29e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921339485-172.17.0.16-1597345416999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35380,DS-880f146a-729f-472a-91c9-eabf00824c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-211924c9-b198-44a2-9d81-aa5cf60ace16,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-6982adf6-d800-4cdb-8261-6eba21b2f8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-af0ed457-f5b9-40a2-96ea-d4ae37e44bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-29245fe0-274a-4b14-9dbf-44fcc50c834b,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-1cb49d7a-029e-4f94-a3ee-e1ce6d7515dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40574,DS-fa5f5ba4-2658-4b9f-8d68-f62f75737109,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-a7f9e015-4392-45f5-b46f-82082088aa88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921339485-172.17.0.16-1597345416999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35380,DS-880f146a-729f-472a-91c9-eabf00824c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-211924c9-b198-44a2-9d81-aa5cf60ace16,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-6982adf6-d800-4cdb-8261-6eba21b2f8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-af0ed457-f5b9-40a2-96ea-d4ae37e44bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-29245fe0-274a-4b14-9dbf-44fcc50c834b,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-1cb49d7a-029e-4f94-a3ee-e1ce6d7515dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40574,DS-fa5f5ba4-2658-4b9f-8d68-f62f75737109,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-a7f9e015-4392-45f5-b46f-82082088aa88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75323901-172.17.0.16-1597345505283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41410,DS-ab2d43cb-14f3-4c11-aa1e-3d37da4669ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-d5c07893-a755-43ea-96a1-45b4b8ec15fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-1f5caf99-58e0-4a5c-bb09-4015c61256eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-aef731b1-d9a6-44b5-8fae-61aa6b936cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-701cb2da-64b4-451e-8588-ce6b2240c5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-86f75657-25dc-4d31-a5ca-00d3144e8324,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-9037d859-6ef0-47b1-8bca-7e7ed1b14dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-4326b1b6-f29b-4204-a692-a07715a1a2ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75323901-172.17.0.16-1597345505283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41410,DS-ab2d43cb-14f3-4c11-aa1e-3d37da4669ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-d5c07893-a755-43ea-96a1-45b4b8ec15fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-1f5caf99-58e0-4a5c-bb09-4015c61256eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-aef731b1-d9a6-44b5-8fae-61aa6b936cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-701cb2da-64b4-451e-8588-ce6b2240c5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-86f75657-25dc-4d31-a5ca-00d3144e8324,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-9037d859-6ef0-47b1-8bca-7e7ed1b14dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-4326b1b6-f29b-4204-a692-a07715a1a2ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1415483905-172.17.0.16-1597345636848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35769,DS-b86e5afc-3872-48ac-bcaa-41bfe5456bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-8cc5ffca-10b3-44bc-99b2-99f16bdf3b54,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-fc8a7bdf-6e8c-484e-8a9f-c49205a42be0,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-01ca854e-4c93-4852-a55d-7b967a128f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-7d763607-e7f7-4fb4-b830-64b6aa450ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-22d8a23b-86f7-4ba2-b7f4-978f5457be05,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-2660828e-838d-4e40-836b-f3b2e3d93a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-fbcd275f-c011-4652-98fe-fa869f27e1fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1415483905-172.17.0.16-1597345636848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35769,DS-b86e5afc-3872-48ac-bcaa-41bfe5456bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-8cc5ffca-10b3-44bc-99b2-99f16bdf3b54,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-fc8a7bdf-6e8c-484e-8a9f-c49205a42be0,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-01ca854e-4c93-4852-a55d-7b967a128f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-7d763607-e7f7-4fb4-b830-64b6aa450ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-22d8a23b-86f7-4ba2-b7f4-978f5457be05,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-2660828e-838d-4e40-836b-f3b2e3d93a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-fbcd275f-c011-4652-98fe-fa869f27e1fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203911467-172.17.0.16-1597345683330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45594,DS-0b96dbc9-23e1-4218-bc49-930eb4ee481b,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-74ad3615-bbef-42a6-97a9-c3c5bcb37174,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-b09ac2eb-9a68-4f4d-8504-68d170feb6a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-f53c8879-2ca6-4898-9e56-f50f100a87f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-b915b22a-f7d6-42c4-bf16-41bd36c4544f,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-d4d7d0b8-702c-40e0-9f60-a0306d08112c,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-08fb5cff-7fa5-424c-a7a6-713287038f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-920c0d9d-2fb6-45fe-ae3b-2e2edb88c739,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203911467-172.17.0.16-1597345683330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45594,DS-0b96dbc9-23e1-4218-bc49-930eb4ee481b,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-74ad3615-bbef-42a6-97a9-c3c5bcb37174,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-b09ac2eb-9a68-4f4d-8504-68d170feb6a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-f53c8879-2ca6-4898-9e56-f50f100a87f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-b915b22a-f7d6-42c4-bf16-41bd36c4544f,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-d4d7d0b8-702c-40e0-9f60-a0306d08112c,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-08fb5cff-7fa5-424c-a7a6-713287038f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-920c0d9d-2fb6-45fe-ae3b-2e2edb88c739,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1852067458-172.17.0.16-1597346176123:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42403,DS-8d85a0c1-f5d5-4525-95bb-3753385b762c,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-e4f8e3cd-15b9-46c9-bea2-ea634fec8a42,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-c9b2b845-b0af-4294-836f-5683bbac6f41,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-87fe628c-546e-4043-b8b2-1649e402c268,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-7a2de98e-21f0-4540-868e-0a1f04800a29,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-330b21a2-5de4-41c4-aa4c-0467fab550b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-c6837677-eea0-4c80-b4e6-5d88a0ab6875,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-aeb55149-e630-4f68-9f5b-bf6844944e15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1852067458-172.17.0.16-1597346176123:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42403,DS-8d85a0c1-f5d5-4525-95bb-3753385b762c,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-e4f8e3cd-15b9-46c9-bea2-ea634fec8a42,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-c9b2b845-b0af-4294-836f-5683bbac6f41,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-87fe628c-546e-4043-b8b2-1649e402c268,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-7a2de98e-21f0-4540-868e-0a1f04800a29,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-330b21a2-5de4-41c4-aa4c-0467fab550b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-c6837677-eea0-4c80-b4e6-5d88a0ab6875,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-aeb55149-e630-4f68-9f5b-bf6844944e15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-186884706-172.17.0.16-1597346345851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36411,DS-881cfe80-0705-498a-a7f7-0831e941012b,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-f1de9c4c-8664-4a6f-9959-4173b460e620,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-2dc58915-6153-4cf7-8763-1170dfd2f135,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-91feb21c-4357-4d62-80f2-87b206889ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-1e45cca0-d331-4eb8-b378-c0e3437f2e05,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-3ea38310-f344-4c17-bbdc-e133ef7c9ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-5a4657be-5fae-4b46-b06f-b33f81086213,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-e55ed3fe-2faf-45e6-a37a-17d604afe8bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-186884706-172.17.0.16-1597346345851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36411,DS-881cfe80-0705-498a-a7f7-0831e941012b,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-f1de9c4c-8664-4a6f-9959-4173b460e620,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-2dc58915-6153-4cf7-8763-1170dfd2f135,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-91feb21c-4357-4d62-80f2-87b206889ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-1e45cca0-d331-4eb8-b378-c0e3437f2e05,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-3ea38310-f344-4c17-bbdc-e133ef7c9ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-5a4657be-5fae-4b46-b06f-b33f81086213,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-e55ed3fe-2faf-45e6-a37a-17d604afe8bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-603369792-172.17.0.16-1597346876115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41184,DS-478abcde-c994-4a64-bc27-7af8ce3f0cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-03f63cdd-a86c-4dd7-9477-bd5f857e22dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-7e7c9c4b-a15d-4abf-a410-0b487e6a30e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-430f1747-20d7-47fb-a5fa-869cb6ee3429,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-8e2d7e41-e321-4662-9b12-82d3c7030857,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-1469c705-7985-4b89-9deb-1a9ccb12b4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-821f1a96-8cb2-4170-bca0-d30bbe775cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-907d0600-92e9-4edc-a6da-35ed1a2ee3f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-603369792-172.17.0.16-1597346876115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41184,DS-478abcde-c994-4a64-bc27-7af8ce3f0cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-03f63cdd-a86c-4dd7-9477-bd5f857e22dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-7e7c9c4b-a15d-4abf-a410-0b487e6a30e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-430f1747-20d7-47fb-a5fa-869cb6ee3429,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-8e2d7e41-e321-4662-9b12-82d3c7030857,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-1469c705-7985-4b89-9deb-1a9ccb12b4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-821f1a96-8cb2-4170-bca0-d30bbe775cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-907d0600-92e9-4edc-a6da-35ed1a2ee3f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1944494754-172.17.0.16-1597347266737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46069,DS-3faf8426-695e-46fe-ad6a-610901fb683c,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-1fee7555-d0d3-4c5c-9d17-3fed05f97548,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-51e47d11-cfb2-4767-b2af-a2b12498b46c,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-bb806835-2fc5-47e0-9af2-26b595882db0,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-cbb2f001-fd4e-4419-85fb-d845d4f6b3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-f233f010-f99b-4228-ad5a-e6965b01fa36,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-70979994-53cd-434d-a14c-480d614c2d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-91fe725b-8f1b-43cd-881f-5c5f3140c0b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1944494754-172.17.0.16-1597347266737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46069,DS-3faf8426-695e-46fe-ad6a-610901fb683c,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-1fee7555-d0d3-4c5c-9d17-3fed05f97548,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-51e47d11-cfb2-4767-b2af-a2b12498b46c,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-bb806835-2fc5-47e0-9af2-26b595882db0,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-cbb2f001-fd4e-4419-85fb-d845d4f6b3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-f233f010-f99b-4228-ad5a-e6965b01fa36,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-70979994-53cd-434d-a14c-480d614c2d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-91fe725b-8f1b-43cd-881f-5c5f3140c0b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1981589435-172.17.0.16-1597347509298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44150,DS-c584e559-b25b-4e80-b23e-60625df4f537,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-695f25a8-0e8e-4a2c-9c02-3b0b8a022093,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-59962fd2-cd6a-405f-adfa-03a312c41a79,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-973c90f8-a550-466f-9b09-cb0f191cbd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-2f7edfd3-845c-423f-a873-c7cc870c9804,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-e366f06f-3f0f-40c3-a00e-4beea732b913,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-7c5558aa-3e97-4da3-b431-6c7e322ec462,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-84ea4e43-c877-43a3-8b41-e1fb5e78cc06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1981589435-172.17.0.16-1597347509298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44150,DS-c584e559-b25b-4e80-b23e-60625df4f537,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-695f25a8-0e8e-4a2c-9c02-3b0b8a022093,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-59962fd2-cd6a-405f-adfa-03a312c41a79,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-973c90f8-a550-466f-9b09-cb0f191cbd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-2f7edfd3-845c-423f-a873-c7cc870c9804,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-e366f06f-3f0f-40c3-a00e-4beea732b913,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-7c5558aa-3e97-4da3-b431-6c7e322ec462,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-84ea4e43-c877-43a3-8b41-e1fb5e78cc06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-41948924-172.17.0.16-1597348154430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41744,DS-86a1209d-3499-47df-9847-c78e2387c39d,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-13012f0c-4ebe-4027-bffb-9f30869cbe5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-440ef190-18bd-41b8-8253-abbbd01367b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-8572552d-8161-439e-8d2c-41247bef4e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-f2f16475-ebac-46d7-bd13-11aedc8938bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-2d182568-d93b-455a-94ad-99f8605ea7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-31040ab5-ce9e-4b72-b268-fcf055fef78a,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-155feec5-38a4-4f5a-8517-29709d270960,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-41948924-172.17.0.16-1597348154430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41744,DS-86a1209d-3499-47df-9847-c78e2387c39d,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-13012f0c-4ebe-4027-bffb-9f30869cbe5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-440ef190-18bd-41b8-8253-abbbd01367b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-8572552d-8161-439e-8d2c-41247bef4e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-f2f16475-ebac-46d7-bd13-11aedc8938bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-2d182568-d93b-455a-94ad-99f8605ea7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-31040ab5-ce9e-4b72-b268-fcf055fef78a,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-155feec5-38a4-4f5a-8517-29709d270960,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1849083983-172.17.0.16-1597348538364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35775,DS-25edace3-b6e0-4317-9c0c-7c4cece9435d,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-adf6ac5b-8346-4dbc-b9db-1376132758eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-f7945994-c5f7-4ad4-b798-93a270c8ad2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-5786525e-27f4-4c6c-84da-baad54d34ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-0a49f04a-5057-4d2f-b9d0-6601c11b00ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-dd6fec2d-a773-41be-a591-1c6f94c2597f,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-2d4edeef-d56c-4a48-9e5a-b9340424080d,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-91abf563-f194-45e9-8b4d-7962f48c9037,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1849083983-172.17.0.16-1597348538364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35775,DS-25edace3-b6e0-4317-9c0c-7c4cece9435d,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-adf6ac5b-8346-4dbc-b9db-1376132758eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-f7945994-c5f7-4ad4-b798-93a270c8ad2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-5786525e-27f4-4c6c-84da-baad54d34ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-0a49f04a-5057-4d2f-b9d0-6601c11b00ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-dd6fec2d-a773-41be-a591-1c6f94c2597f,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-2d4edeef-d56c-4a48-9e5a-b9340424080d,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-91abf563-f194-45e9-8b4d-7962f48c9037,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-949569828-172.17.0.16-1597348888832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33775,DS-6f5a5325-bac5-4ac2-b0bc-96432b7c5146,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-10532a42-ce14-4dfa-a000-3540943d5217,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-925b2f19-4ad0-483c-bcc5-690e987c2293,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-3bbeb56c-b049-4f27-af24-befc9d3acc47,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-e1b628ed-3195-4de0-adbe-19fe48b2b0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-9d1edf04-420f-4120-adfa-888b3dcea92b,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-c7dc2937-f985-473f-86de-dbf7bda6982a,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-306e19c4-f25b-4b48-829c-bcaab5a663c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-949569828-172.17.0.16-1597348888832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33775,DS-6f5a5325-bac5-4ac2-b0bc-96432b7c5146,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-10532a42-ce14-4dfa-a000-3540943d5217,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-925b2f19-4ad0-483c-bcc5-690e987c2293,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-3bbeb56c-b049-4f27-af24-befc9d3acc47,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-e1b628ed-3195-4de0-adbe-19fe48b2b0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-9d1edf04-420f-4120-adfa-888b3dcea92b,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-c7dc2937-f985-473f-86de-dbf7bda6982a,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-306e19c4-f25b-4b48-829c-bcaab5a663c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323537072-172.17.0.16-1597349540309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40170,DS-5a8fd97f-ce00-48e3-b7d6-aef85982797a,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-4eb3e60d-ae75-4f70-b1f2-71499fcf9703,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-eb99be1a-35f6-489c-827d-423aa1869298,DISK], DatanodeInfoWithStorage[127.0.0.1:41265,DS-c61ea244-abcc-43d6-a18a-4367e7d543de,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-e9df2140-ff66-410d-9aad-891028064b77,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-432865e6-4b72-4369-8416-e74bf14971ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-54a0d1fc-8d8f-4fc7-8ca5-1be777eea6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-a7fb3518-3ff8-471b-9ce5-163b5f86519b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323537072-172.17.0.16-1597349540309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40170,DS-5a8fd97f-ce00-48e3-b7d6-aef85982797a,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-4eb3e60d-ae75-4f70-b1f2-71499fcf9703,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-eb99be1a-35f6-489c-827d-423aa1869298,DISK], DatanodeInfoWithStorage[127.0.0.1:41265,DS-c61ea244-abcc-43d6-a18a-4367e7d543de,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-e9df2140-ff66-410d-9aad-891028064b77,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-432865e6-4b72-4369-8416-e74bf14971ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-54a0d1fc-8d8f-4fc7-8ca5-1be777eea6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-a7fb3518-3ff8-471b-9ce5-163b5f86519b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-866694658-172.17.0.16-1597349727427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43307,DS-887bb354-b1db-4a6e-980a-f905f85e2795,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-8379db63-6b49-49f8-9bcf-1c8d878d620d,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-8c6941d3-1a9b-4163-9afd-1090e4f90140,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-d0126a70-c7eb-4d12-af65-bd3b4185ecc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-b114c8f0-58d9-4fb0-91af-093d43187a34,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-fddb708c-c060-4ccc-82d0-815e10ad5fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-e75bdecb-5415-4571-ab9d-7dfbbc872105,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-2e1e681b-e5a8-4c92-aea6-fd04b0589849,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-866694658-172.17.0.16-1597349727427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43307,DS-887bb354-b1db-4a6e-980a-f905f85e2795,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-8379db63-6b49-49f8-9bcf-1c8d878d620d,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-8c6941d3-1a9b-4163-9afd-1090e4f90140,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-d0126a70-c7eb-4d12-af65-bd3b4185ecc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-b114c8f0-58d9-4fb0-91af-093d43187a34,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-fddb708c-c060-4ccc-82d0-815e10ad5fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-e75bdecb-5415-4571-ab9d-7dfbbc872105,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-2e1e681b-e5a8-4c92-aea6-fd04b0589849,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1072657829-172.17.0.16-1597349780561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37327,DS-def5c27e-c755-4f60-8f56-81cbe58e1931,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-7614e3c5-22f3-4933-aebb-394ab2c0e24b,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-0cd6c0ad-410b-453e-aafe-2ae6c00658a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-f5d18536-6944-46d7-b149-e3e986398afb,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-1dcec878-6b70-4cdf-b370-669fc4936e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-ffca78b0-b87a-4c88-8776-f3bda0e954cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-621e9cc5-242e-49bb-a557-71ee89b8544e,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-87877054-838f-4c22-93c8-86789181c83c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1072657829-172.17.0.16-1597349780561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37327,DS-def5c27e-c755-4f60-8f56-81cbe58e1931,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-7614e3c5-22f3-4933-aebb-394ab2c0e24b,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-0cd6c0ad-410b-453e-aafe-2ae6c00658a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-f5d18536-6944-46d7-b149-e3e986398afb,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-1dcec878-6b70-4cdf-b370-669fc4936e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-ffca78b0-b87a-4c88-8776-f3bda0e954cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-621e9cc5-242e-49bb-a557-71ee89b8544e,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-87877054-838f-4c22-93c8-86789181c83c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-555913032-172.17.0.16-1597350171041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36126,DS-906986bf-55ef-4296-82c3-76bac832552a,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-b15740de-28f8-42c4-91fe-1de9966010a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-fa9fb258-5ce7-45c0-9f01-5821ae7232a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-e7ea1a92-790c-433e-9d95-f72114914a10,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-89646fa5-2f07-43f4-aac7-61b9a336271b,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-ed9314e1-240d-440b-bf79-fb43682e438a,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-90877dc2-3130-409d-a4fb-61cc68418e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-5889e7bd-4f5b-4446-babc-ddf661e89b15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-555913032-172.17.0.16-1597350171041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36126,DS-906986bf-55ef-4296-82c3-76bac832552a,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-b15740de-28f8-42c4-91fe-1de9966010a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-fa9fb258-5ce7-45c0-9f01-5821ae7232a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-e7ea1a92-790c-433e-9d95-f72114914a10,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-89646fa5-2f07-43f4-aac7-61b9a336271b,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-ed9314e1-240d-440b-bf79-fb43682e438a,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-90877dc2-3130-409d-a4fb-61cc68418e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-5889e7bd-4f5b-4446-babc-ddf661e89b15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2135682791-172.17.0.16-1597350959243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37357,DS-c26a0173-d1dc-4b00-b9cf-8abdf0fe7eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-71452ab0-0cb0-43ee-8f3c-3bab27c709ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-fee32b7a-f22d-4585-90c6-a3d14a86c7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-ecbce44e-7f02-4be5-ad6b-f0594098827a,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-5182b7b6-0ba0-413f-9317-93db570fe07e,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-ac5e041f-bc6f-40ae-97ce-01a9af75290a,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-388b89f0-ac94-45a5-8dc4-ae5e815e08bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-b7ab9f85-a840-475d-8907-8d6af3b7f10b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2135682791-172.17.0.16-1597350959243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37357,DS-c26a0173-d1dc-4b00-b9cf-8abdf0fe7eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-71452ab0-0cb0-43ee-8f3c-3bab27c709ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-fee32b7a-f22d-4585-90c6-a3d14a86c7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-ecbce44e-7f02-4be5-ad6b-f0594098827a,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-5182b7b6-0ba0-413f-9317-93db570fe07e,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-ac5e041f-bc6f-40ae-97ce-01a9af75290a,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-388b89f0-ac94-45a5-8dc4-ae5e815e08bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-b7ab9f85-a840-475d-8907-8d6af3b7f10b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 4194304
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1577385885-172.17.0.16-1597351095889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40287,DS-ec0dbde0-1e46-4135-b666-2e381730799c,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-f4b58c2f-65b2-46c6-98f0-8227ae769248,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-de0ada83-decb-4bdf-89a3-3d7e1a7bb518,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-bd7fd97f-63d1-48af-a21a-ff9913df5a30,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-55018a75-b145-40cc-9a18-31b1964bafd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-76a768c5-0b9f-4295-931d-b187a8d1d099,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-1524921f-c29c-4d37-a4f5-4f9884d61f45,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-05cf552a-fcc5-4f37-a3e5-eb108471e68f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1577385885-172.17.0.16-1597351095889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40287,DS-ec0dbde0-1e46-4135-b666-2e381730799c,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-f4b58c2f-65b2-46c6-98f0-8227ae769248,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-de0ada83-decb-4bdf-89a3-3d7e1a7bb518,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-bd7fd97f-63d1-48af-a21a-ff9913df5a30,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-55018a75-b145-40cc-9a18-31b1964bafd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-76a768c5-0b9f-4295-931d-b187a8d1d099,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-1524921f-c29c-4d37-a4f5-4f9884d61f45,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-05cf552a-fcc5-4f37-a3e5-eb108471e68f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 6683
