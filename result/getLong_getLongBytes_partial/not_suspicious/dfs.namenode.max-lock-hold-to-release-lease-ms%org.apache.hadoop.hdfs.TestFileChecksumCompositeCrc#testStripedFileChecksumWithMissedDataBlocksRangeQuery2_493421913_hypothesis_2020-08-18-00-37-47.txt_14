reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-711116684-172.17.0.20-1597711197744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41837,DS-2108a460-4ea5-403c-bf9f-77e4378bd051,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-b3c4d271-4d9d-4919-9eac-82da321d6e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-c9741457-c038-4035-ac35-3d89120f8e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-05e2927b-279e-47cd-953f-83391d5e0971,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-caad7fc5-0efe-45e1-8726-124639ab3a41,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-13fbba2a-3873-405a-aa4d-cde501aaf4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-691e73f4-39c7-4d07-8db2-7f0d9da798b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-7444008b-45c9-4f4c-8530-09af8168a248,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-711116684-172.17.0.20-1597711197744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41837,DS-2108a460-4ea5-403c-bf9f-77e4378bd051,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-b3c4d271-4d9d-4919-9eac-82da321d6e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-c9741457-c038-4035-ac35-3d89120f8e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-05e2927b-279e-47cd-953f-83391d5e0971,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-caad7fc5-0efe-45e1-8726-124639ab3a41,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-13fbba2a-3873-405a-aa4d-cde501aaf4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-691e73f4-39c7-4d07-8db2-7f0d9da798b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-7444008b-45c9-4f4c-8530-09af8168a248,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906087664-172.17.0.20-1597711481176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35139,DS-8d275e5b-b9c8-46c6-860f-73a4383bd1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-dae5aa5a-45bf-4fb7-a256-328878058a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-799d0e6b-309d-4538-a2a7-083eebd8e8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-cc0c4f58-ac74-4220-80bb-058b011eea33,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-f29e9d29-fba0-4a11-b210-8bc312a72d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-a9923c4c-9a01-40c5-868d-73c2fb197aff,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-369bbf69-f12b-4cb9-bf9f-b189010d001d,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-ee0ec795-fce3-4d56-8792-2c7a71ac2e1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906087664-172.17.0.20-1597711481176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35139,DS-8d275e5b-b9c8-46c6-860f-73a4383bd1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-dae5aa5a-45bf-4fb7-a256-328878058a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-799d0e6b-309d-4538-a2a7-083eebd8e8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-cc0c4f58-ac74-4220-80bb-058b011eea33,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-f29e9d29-fba0-4a11-b210-8bc312a72d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-a9923c4c-9a01-40c5-868d-73c2fb197aff,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-369bbf69-f12b-4cb9-bf9f-b189010d001d,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-ee0ec795-fce3-4d56-8792-2c7a71ac2e1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1504023937-172.17.0.20-1597711548434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46509,DS-3a58fd30-f21a-46d0-b6ac-26bc6c12b1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-0c42661b-792a-4777-a682-2817b447f0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-9ccfd5f8-966d-4738-b1c2-962417f9a11e,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-860a41c3-9ea7-4d65-b7a7-6a2662d46d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-255adecf-ae95-46fb-9cbf-5d8ed3757b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-f36caedb-2632-43d6-b34f-b154f666b8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-238233b4-810a-445b-b87e-65be2cb23607,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-28008d45-9a5e-4696-979d-5c7b967bac0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1504023937-172.17.0.20-1597711548434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46509,DS-3a58fd30-f21a-46d0-b6ac-26bc6c12b1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-0c42661b-792a-4777-a682-2817b447f0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-9ccfd5f8-966d-4738-b1c2-962417f9a11e,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-860a41c3-9ea7-4d65-b7a7-6a2662d46d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-255adecf-ae95-46fb-9cbf-5d8ed3757b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-f36caedb-2632-43d6-b34f-b154f666b8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-238233b4-810a-445b-b87e-65be2cb23607,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-28008d45-9a5e-4696-979d-5c7b967bac0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-984636563-172.17.0.20-1597711659161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44195,DS-c72393d2-5688-4c06-956a-88557db45b24,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-aa051227-ae83-4fbd-9d69-58c7acacf465,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-48f1b3d0-9b76-4219-b6d5-a40bedddb1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-eb272f5a-a3f9-4056-bb30-15bd57bafade,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-157fa4a8-9292-4c4a-b5c4-513d875bdab2,DISK], DatanodeInfoWithStorage[127.0.0.1:38148,DS-8dfb748f-3ee5-4e72-9bca-625e5fd7e9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-b2dae8b1-1f4a-4d33-874a-e4a52ece7c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-250efb44-1434-4c3d-b5ca-4ed75e29f3c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-984636563-172.17.0.20-1597711659161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44195,DS-c72393d2-5688-4c06-956a-88557db45b24,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-aa051227-ae83-4fbd-9d69-58c7acacf465,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-48f1b3d0-9b76-4219-b6d5-a40bedddb1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-eb272f5a-a3f9-4056-bb30-15bd57bafade,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-157fa4a8-9292-4c4a-b5c4-513d875bdab2,DISK], DatanodeInfoWithStorage[127.0.0.1:38148,DS-8dfb748f-3ee5-4e72-9bca-625e5fd7e9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-b2dae8b1-1f4a-4d33-874a-e4a52ece7c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-250efb44-1434-4c3d-b5ca-4ed75e29f3c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440980852-172.17.0.20-1597711734044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33298,DS-a4071408-5bd2-43fd-8416-9c42d2e6d1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-17121cf6-e189-4e20-9d45-49286c944006,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-1112c1f5-c41c-44b4-a907-0e433cbdb510,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-e7384f89-b65b-4cec-8d3e-bc67d764bf7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-cc2e2d59-9a08-42a8-860c-f0c36ff08ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-a9dad779-b437-477c-885d-7296a5ceb1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-9505a7f5-bd6a-4490-abd7-0c544dd2356a,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-9340b28e-bb6d-4dba-9c99-b5bd7ef22c6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440980852-172.17.0.20-1597711734044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33298,DS-a4071408-5bd2-43fd-8416-9c42d2e6d1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-17121cf6-e189-4e20-9d45-49286c944006,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-1112c1f5-c41c-44b4-a907-0e433cbdb510,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-e7384f89-b65b-4cec-8d3e-bc67d764bf7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-cc2e2d59-9a08-42a8-860c-f0c36ff08ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-a9dad779-b437-477c-885d-7296a5ceb1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-9505a7f5-bd6a-4490-abd7-0c544dd2356a,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-9340b28e-bb6d-4dba-9c99-b5bd7ef22c6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39123399-172.17.0.20-1597711985837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45743,DS-3787a076-3882-4af5-adff-3b2ccd89629d,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-bcac6916-56ce-43d4-837a-d8159b668439,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-72fd1185-4b53-47a8-a3fb-a0ca7c2d6272,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-c177eed8-204d-411b-b73d-9fd558a60c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-3638ce76-73fe-4659-b572-c78986b46864,DISK], DatanodeInfoWithStorage[127.0.0.1:43397,DS-75fce935-79d1-48bd-a19e-268baa51f4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-8e82958e-4515-4668-b37a-1f91429a83c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-d7cef54e-d8d2-4240-9b57-14459a313a0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39123399-172.17.0.20-1597711985837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45743,DS-3787a076-3882-4af5-adff-3b2ccd89629d,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-bcac6916-56ce-43d4-837a-d8159b668439,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-72fd1185-4b53-47a8-a3fb-a0ca7c2d6272,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-c177eed8-204d-411b-b73d-9fd558a60c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-3638ce76-73fe-4659-b572-c78986b46864,DISK], DatanodeInfoWithStorage[127.0.0.1:43397,DS-75fce935-79d1-48bd-a19e-268baa51f4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-8e82958e-4515-4668-b37a-1f91429a83c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-d7cef54e-d8d2-4240-9b57-14459a313a0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396242947-172.17.0.20-1597712090013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46355,DS-5cff978f-4176-42b9-879b-6790793375e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-fbf43bfe-1954-40c1-bc04-e47c22666d11,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-e72974f7-acfb-4e4e-a95f-2b7353cfe2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-b9347905-ad32-4f72-b12f-0848cc0738f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-6275fab4-c86e-4d6c-9ee1-0dc001fcbc49,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-66e7ef70-ad52-4fe6-8808-84bca63fa345,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-d47ecafb-eacc-4b4c-b3d2-82b9390299e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-bf7862fd-0bca-4f03-a72b-e8a29b7e1636,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396242947-172.17.0.20-1597712090013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46355,DS-5cff978f-4176-42b9-879b-6790793375e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-fbf43bfe-1954-40c1-bc04-e47c22666d11,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-e72974f7-acfb-4e4e-a95f-2b7353cfe2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-b9347905-ad32-4f72-b12f-0848cc0738f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-6275fab4-c86e-4d6c-9ee1-0dc001fcbc49,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-66e7ef70-ad52-4fe6-8808-84bca63fa345,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-d47ecafb-eacc-4b4c-b3d2-82b9390299e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-bf7862fd-0bca-4f03-a72b-e8a29b7e1636,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796550722-172.17.0.20-1597712170623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41290,DS-c565cb99-0094-4c96-a375-189328105c47,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-bd51c1c5-dad9-4f8d-9c13-a3e329f4888b,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-93ba0a85-7381-4697-b9db-ea4a9e8299f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-d348274a-ab82-4eea-8bb8-543d30f1586d,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-28c0495e-e55b-49cd-b401-6f6b476fdc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-b65cce62-89e4-4c8a-83c3-97d37cdb6e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-b46681a2-3af2-4959-9dde-2216fb04228f,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-b43e2a55-30c9-4399-9d3d-2c7564b9ee52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796550722-172.17.0.20-1597712170623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41290,DS-c565cb99-0094-4c96-a375-189328105c47,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-bd51c1c5-dad9-4f8d-9c13-a3e329f4888b,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-93ba0a85-7381-4697-b9db-ea4a9e8299f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-d348274a-ab82-4eea-8bb8-543d30f1586d,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-28c0495e-e55b-49cd-b401-6f6b476fdc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-b65cce62-89e4-4c8a-83c3-97d37cdb6e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-b46681a2-3af2-4959-9dde-2216fb04228f,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-b43e2a55-30c9-4399-9d3d-2c7564b9ee52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2010574045-172.17.0.20-1597712317038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33597,DS-dfbbc383-46a4-4b50-b41d-9196560f7d79,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-a5f282fe-2c02-4bd5-b934-5b5393a7fb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-153edc47-6ddf-4941-bf5f-2a681114b98e,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-492be954-6450-47ca-bf23-811ad6ac44e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-a47558e3-c64b-4f0c-be1f-57dce2f91dea,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-4513322d-51fc-41e9-81d0-44b0e3ee33b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-c8f14623-5e08-4aac-a69c-f118557c4554,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-a19ca542-cde9-4d7b-b71e-8ba443fd8800,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2010574045-172.17.0.20-1597712317038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33597,DS-dfbbc383-46a4-4b50-b41d-9196560f7d79,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-a5f282fe-2c02-4bd5-b934-5b5393a7fb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-153edc47-6ddf-4941-bf5f-2a681114b98e,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-492be954-6450-47ca-bf23-811ad6ac44e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-a47558e3-c64b-4f0c-be1f-57dce2f91dea,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-4513322d-51fc-41e9-81d0-44b0e3ee33b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-c8f14623-5e08-4aac-a69c-f118557c4554,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-a19ca542-cde9-4d7b-b71e-8ba443fd8800,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024565405-172.17.0.20-1597712359528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46812,DS-49bea178-96f3-4e51-9df6-df284afc8741,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-42fcac44-74b6-4745-878b-278a41c85f12,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-4e25fcff-cd85-4463-9cb0-54be2482120b,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-ce71cb00-de99-42e1-97b5-e2152e02b3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-bd615571-87b0-4dc6-a890-f34cc83cc981,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-d68bf84e-b6b3-4c38-9ea8-51a7d5fa556d,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-6a08896a-3d60-4c28-9c6d-9fe7f304fc41,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-d5e39ba6-82da-442d-8be0-51822e671ff6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024565405-172.17.0.20-1597712359528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46812,DS-49bea178-96f3-4e51-9df6-df284afc8741,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-42fcac44-74b6-4745-878b-278a41c85f12,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-4e25fcff-cd85-4463-9cb0-54be2482120b,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-ce71cb00-de99-42e1-97b5-e2152e02b3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-bd615571-87b0-4dc6-a890-f34cc83cc981,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-d68bf84e-b6b3-4c38-9ea8-51a7d5fa556d,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-6a08896a-3d60-4c28-9c6d-9fe7f304fc41,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-d5e39ba6-82da-442d-8be0-51822e671ff6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202708389-172.17.0.20-1597712613007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36661,DS-01c7836b-c5f5-40d8-815b-723317f6a6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-ca15761d-ba07-4c7e-b19e-401bb1ee6dac,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-ff44de67-71f8-4612-9a38-cedf20348acf,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-1afc1ee1-9246-4044-9785-83b7e88b47df,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-c166f3ae-84e2-4180-b3d1-f8296be1899f,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-146cde5c-f88c-47b7-afa8-3cd585e5e8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-69658c06-2dcb-4a63-85ed-fc220bd52921,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-38d900d6-b9c8-44f8-b047-41d6eb4b7a6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202708389-172.17.0.20-1597712613007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36661,DS-01c7836b-c5f5-40d8-815b-723317f6a6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-ca15761d-ba07-4c7e-b19e-401bb1ee6dac,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-ff44de67-71f8-4612-9a38-cedf20348acf,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-1afc1ee1-9246-4044-9785-83b7e88b47df,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-c166f3ae-84e2-4180-b3d1-f8296be1899f,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-146cde5c-f88c-47b7-afa8-3cd585e5e8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-69658c06-2dcb-4a63-85ed-fc220bd52921,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-38d900d6-b9c8-44f8-b047-41d6eb4b7a6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603300962-172.17.0.20-1597713029516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38954,DS-98b0929b-f126-4ab5-9e46-d82d240e3530,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-fd79fd29-9c4d-4bf9-b49a-48f5a4c97968,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-65ebb044-3168-4d9a-85eb-b8694bb85469,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-965e0e42-2d36-4a16-a356-7ea8da0698f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-887e1f6e-9f15-4cc4-8396-217166dff9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-4124eef8-9853-467b-b5ca-c8e94231109a,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-a5c9bebf-41c0-49a3-8846-5b01fb8ec5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-6cd13767-f28c-43e9-81d8-f05e2515d1a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603300962-172.17.0.20-1597713029516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38954,DS-98b0929b-f126-4ab5-9e46-d82d240e3530,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-fd79fd29-9c4d-4bf9-b49a-48f5a4c97968,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-65ebb044-3168-4d9a-85eb-b8694bb85469,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-965e0e42-2d36-4a16-a356-7ea8da0698f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-887e1f6e-9f15-4cc4-8396-217166dff9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-4124eef8-9853-467b-b5ca-c8e94231109a,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-a5c9bebf-41c0-49a3-8846-5b01fb8ec5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-6cd13767-f28c-43e9-81d8-f05e2515d1a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1940388455-172.17.0.20-1597714655387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34737,DS-b46dc61a-2a52-4267-9095-5a1c68ef5147,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-cdc66b9f-4ba6-4993-81a8-9b7f294edbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-97bc13ce-4a5c-44ea-9bcc-0946da83c74c,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-c1af9448-b30a-420b-a381-2db72adb4e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-ac939e3f-28a1-4d50-8416-596bd513264b,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-58873982-a931-4a30-b78e-ec149383a064,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-d0aa4f77-4366-419f-a367-9524b4c618e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-d4e7e997-b18f-4ba8-9424-7c5b5c4201b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1940388455-172.17.0.20-1597714655387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34737,DS-b46dc61a-2a52-4267-9095-5a1c68ef5147,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-cdc66b9f-4ba6-4993-81a8-9b7f294edbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-97bc13ce-4a5c-44ea-9bcc-0946da83c74c,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-c1af9448-b30a-420b-a381-2db72adb4e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-ac939e3f-28a1-4d50-8416-596bd513264b,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-58873982-a931-4a30-b78e-ec149383a064,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-d0aa4f77-4366-419f-a367-9524b4c618e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-d4e7e997-b18f-4ba8-9424-7c5b5c4201b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512840590-172.17.0.20-1597714762420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37031,DS-7c754435-14d3-47c1-b40a-be87ee95e35d,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-ab33da53-ffbc-4136-b828-00ff49d6d373,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-5bbbf948-70e3-4cd8-9618-0970a99f9d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-12b361f5-fa9b-4ee6-bec9-9d588eef970e,DISK], DatanodeInfoWithStorage[127.0.0.1:41455,DS-8f06bcbb-d036-4981-adb9-56ac7dbfb7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-2a560454-dcf7-4c3c-bf09-ef0e0a97a227,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-4edd5f53-2504-4364-a43a-baca866db05c,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-6cd89d6b-c3bf-4aa5-adb7-ffc8041add0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512840590-172.17.0.20-1597714762420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37031,DS-7c754435-14d3-47c1-b40a-be87ee95e35d,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-ab33da53-ffbc-4136-b828-00ff49d6d373,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-5bbbf948-70e3-4cd8-9618-0970a99f9d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-12b361f5-fa9b-4ee6-bec9-9d588eef970e,DISK], DatanodeInfoWithStorage[127.0.0.1:41455,DS-8f06bcbb-d036-4981-adb9-56ac7dbfb7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-2a560454-dcf7-4c3c-bf09-ef0e0a97a227,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-4edd5f53-2504-4364-a43a-baca866db05c,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-6cd89d6b-c3bf-4aa5-adb7-ffc8041add0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-183930514-172.17.0.20-1597714803211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42055,DS-44d3446d-72c2-4507-8664-9c10c5fe6b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-0ab4bce0-ac60-4200-a6ef-5e2e62606f32,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-fccdd55c-b8ac-4988-a3eb-428b2cd8c2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-f30b68da-46c9-4029-be17-49871fd2f6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-60d6d537-2bff-4fbf-836f-d6f81935d564,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-09c345b5-caca-470d-8ce0-dbac392bf3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-3269b806-e05a-43b3-9f68-d229023fe2da,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-b902a3f1-0aa0-4143-ba8f-a066fc69d5d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-183930514-172.17.0.20-1597714803211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42055,DS-44d3446d-72c2-4507-8664-9c10c5fe6b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-0ab4bce0-ac60-4200-a6ef-5e2e62606f32,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-fccdd55c-b8ac-4988-a3eb-428b2cd8c2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-f30b68da-46c9-4029-be17-49871fd2f6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-60d6d537-2bff-4fbf-836f-d6f81935d564,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-09c345b5-caca-470d-8ce0-dbac392bf3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-3269b806-e05a-43b3-9f68-d229023fe2da,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-b902a3f1-0aa0-4143-ba8f-a066fc69d5d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1179545725-172.17.0.20-1597714959195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33859,DS-5ce2246f-ab00-420a-ae64-ee3a494d258d,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-2635a16c-1d95-4f47-a7c1-a7692cb5bfb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-50e394b4-0c83-4cdd-bc97-944d645dc662,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-fb2ed007-b250-4e08-8763-7eea088ab212,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-0fa373ee-c239-432d-acdc-f0f970adf30f,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-3261496f-6b05-4e63-a9cb-c22cb5c711ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-92cdf408-b262-4e63-ac3e-ca1b1eb5ae2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-f84920f2-0da4-44df-ab73-79b00c0ebd7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1179545725-172.17.0.20-1597714959195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33859,DS-5ce2246f-ab00-420a-ae64-ee3a494d258d,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-2635a16c-1d95-4f47-a7c1-a7692cb5bfb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-50e394b4-0c83-4cdd-bc97-944d645dc662,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-fb2ed007-b250-4e08-8763-7eea088ab212,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-0fa373ee-c239-432d-acdc-f0f970adf30f,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-3261496f-6b05-4e63-a9cb-c22cb5c711ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-92cdf408-b262-4e63-ac3e-ca1b1eb5ae2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-f84920f2-0da4-44df-ab73-79b00c0ebd7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-219863100-172.17.0.20-1597715433589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42335,DS-d74fd92c-879f-488e-9ab5-deb3665ced4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-3bfa9d4a-3819-466f-9582-e8dae9033603,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-0e7c8d4c-cca7-4721-a4fb-f4b5fb523dac,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-bd0b33ef-4a6e-4e64-ac39-5fb406e52f22,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-8d22b36d-b509-45c7-8f87-d6a233f596cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-d126f7eb-5eb8-497e-b6c8-3c452664042c,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-7745b317-49f8-49f9-8120-4f9f33687301,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-188035c0-2251-438e-9331-a6eefd898fad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-219863100-172.17.0.20-1597715433589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42335,DS-d74fd92c-879f-488e-9ab5-deb3665ced4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-3bfa9d4a-3819-466f-9582-e8dae9033603,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-0e7c8d4c-cca7-4721-a4fb-f4b5fb523dac,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-bd0b33ef-4a6e-4e64-ac39-5fb406e52f22,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-8d22b36d-b509-45c7-8f87-d6a233f596cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-d126f7eb-5eb8-497e-b6c8-3c452664042c,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-7745b317-49f8-49f9-8120-4f9f33687301,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-188035c0-2251-438e-9331-a6eefd898fad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 2500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663124583-172.17.0.20-1597716015875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35628,DS-f0d37380-7655-44f4-8180-09f86b5f6715,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-092317e8-1b4d-4291-99a7-90fe2ca6a08c,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-764d018a-4e23-45fb-8bc0-017cde45ce0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-d604103a-7c11-43fe-8e61-7603f6327470,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-8479e905-dc5c-4b29-9828-68a7f2a1f06f,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-8a58edd2-4d47-487f-8f80-4c966036873a,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-20c7d59f-1c11-42b9-8a0a-dd4f7f0e73a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-f61ea095-362f-414e-a77b-d66d67fcf9c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663124583-172.17.0.20-1597716015875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35628,DS-f0d37380-7655-44f4-8180-09f86b5f6715,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-092317e8-1b4d-4291-99a7-90fe2ca6a08c,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-764d018a-4e23-45fb-8bc0-017cde45ce0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-d604103a-7c11-43fe-8e61-7603f6327470,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-8479e905-dc5c-4b29-9828-68a7f2a1f06f,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-8a58edd2-4d47-487f-8f80-4c966036873a,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-20c7d59f-1c11-42b9-8a0a-dd4f7f0e73a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-f61ea095-362f-414e-a77b-d66d67fcf9c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5633
