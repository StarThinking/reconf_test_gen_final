reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1805994744-172.17.0.19-1597653677387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37063,DS-183c5098-e182-4c6e-824d-90b6074e973c,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-d7b4625c-d8b9-404d-99b5-2780bcf49aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-defcc9b6-9f37-424b-9478-0262938413b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-a0a17ff5-79a4-4511-93f7-c353e583d8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-89aaffd7-db1c-47f7-ab93-d29d1763f2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-ef5d0279-d4cc-4a8c-885a-29faa7d3fcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-71406b9e-17a1-4eff-af77-c74ddf26b13b,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-be58b7c4-e706-4e42-9e57-f5a46e1c68dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1805994744-172.17.0.19-1597653677387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37063,DS-183c5098-e182-4c6e-824d-90b6074e973c,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-d7b4625c-d8b9-404d-99b5-2780bcf49aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-defcc9b6-9f37-424b-9478-0262938413b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-a0a17ff5-79a4-4511-93f7-c353e583d8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45439,DS-89aaffd7-db1c-47f7-ab93-d29d1763f2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-ef5d0279-d4cc-4a8c-885a-29faa7d3fcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-71406b9e-17a1-4eff-af77-c74ddf26b13b,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-be58b7c4-e706-4e42-9e57-f5a46e1c68dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-535498916-172.17.0.19-1597653848387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46338,DS-cd46dfa8-7cda-45ee-8564-775beab4c774,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-a3191dfd-ff0f-409a-865b-35c043addccf,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-8f7738b7-4a13-480b-8aba-c59630d4f2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-da7f49d9-3724-47d0-83d5-274be1b13a03,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-f3b18bef-09eb-4dce-b24d-f2741e3ca0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-71dc0156-b710-455e-8925-5ae9981088d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-6aa9be7c-862f-4b0d-baed-a0cb90984fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-c27e22db-0566-4c39-9a04-73fb968bc771,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-535498916-172.17.0.19-1597653848387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46338,DS-cd46dfa8-7cda-45ee-8564-775beab4c774,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-a3191dfd-ff0f-409a-865b-35c043addccf,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-8f7738b7-4a13-480b-8aba-c59630d4f2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-da7f49d9-3724-47d0-83d5-274be1b13a03,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-f3b18bef-09eb-4dce-b24d-f2741e3ca0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-71dc0156-b710-455e-8925-5ae9981088d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-6aa9be7c-862f-4b0d-baed-a0cb90984fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-c27e22db-0566-4c39-9a04-73fb968bc771,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1746699833-172.17.0.19-1597654176171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44101,DS-048fb244-4a5c-44a0-8fdd-8bd54c0d03ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-baa0010e-1c69-44b6-801a-efb16758efd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-105906bc-e7b0-46d1-a0fb-e912d6f4d89c,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-b7f7cdc7-f0c8-4c38-8409-4b7283c9d678,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-7229cf63-542e-43f2-95e4-76f960faa085,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-438352d9-6b07-45c0-b556-97a5d3066e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-d0a1e987-1928-49a6-ba0e-c1fd23d95f38,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-2ccba888-34f1-4dd6-920f-79b83946bfca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1746699833-172.17.0.19-1597654176171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44101,DS-048fb244-4a5c-44a0-8fdd-8bd54c0d03ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-baa0010e-1c69-44b6-801a-efb16758efd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-105906bc-e7b0-46d1-a0fb-e912d6f4d89c,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-b7f7cdc7-f0c8-4c38-8409-4b7283c9d678,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-7229cf63-542e-43f2-95e4-76f960faa085,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-438352d9-6b07-45c0-b556-97a5d3066e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-d0a1e987-1928-49a6-ba0e-c1fd23d95f38,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-2ccba888-34f1-4dd6-920f-79b83946bfca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1706974005-172.17.0.19-1597654295679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41813,DS-42341657-292a-439a-9e83-3655f838c473,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-9b74c45c-9af1-43d9-ad49-f8a129fd1b73,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-5dd7b069-ca79-4967-a1f4-718460b45bca,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-07735233-1c6d-4a40-9966-cded11650d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-8e5f4726-c250-484f-b0bf-1aadcce210f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-850f254a-e51a-4bd8-8d4e-d7b0e945b9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-f2dc91fd-c5bf-4d1f-80a2-d6acd172c698,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-c2a0467b-a220-4f1d-9af6-4a44e665ca48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1706974005-172.17.0.19-1597654295679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41813,DS-42341657-292a-439a-9e83-3655f838c473,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-9b74c45c-9af1-43d9-ad49-f8a129fd1b73,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-5dd7b069-ca79-4967-a1f4-718460b45bca,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-07735233-1c6d-4a40-9966-cded11650d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-8e5f4726-c250-484f-b0bf-1aadcce210f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-850f254a-e51a-4bd8-8d4e-d7b0e945b9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-f2dc91fd-c5bf-4d1f-80a2-d6acd172c698,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-c2a0467b-a220-4f1d-9af6-4a44e665ca48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662643636-172.17.0.19-1597654561992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37542,DS-a10fb446-234f-4507-9c21-ace9be5f9ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-83807367-fd2d-4aa3-bd48-778f107b5ded,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-0d4e47de-7140-4bd4-ac82-07ecd05c1c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-7941bb6f-2c80-4a7b-a2c4-eb158fbcfe70,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-d4380a02-f9e2-4b18-82e8-fe5c4471ba29,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-e858e41a-79d4-487e-a105-1b5193ee2ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-4d314c38-2b13-4767-9bc9-57dbfd09a6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-53770f6e-4da1-4357-a599-67ceeeabf2c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662643636-172.17.0.19-1597654561992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37542,DS-a10fb446-234f-4507-9c21-ace9be5f9ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-83807367-fd2d-4aa3-bd48-778f107b5ded,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-0d4e47de-7140-4bd4-ac82-07ecd05c1c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-7941bb6f-2c80-4a7b-a2c4-eb158fbcfe70,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-d4380a02-f9e2-4b18-82e8-fe5c4471ba29,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-e858e41a-79d4-487e-a105-1b5193ee2ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-4d314c38-2b13-4767-9bc9-57dbfd09a6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-53770f6e-4da1-4357-a599-67ceeeabf2c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110819420-172.17.0.19-1597654796087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37520,DS-f43f09f9-bbfd-41e9-ae20-a5766875ed46,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-adf07d3e-a1ba-4a94-8666-eecd60b0dfda,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-b09ce5b7-50a3-456e-bf95-a2043f69e7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-f0407930-35f4-478c-814d-65233e59dd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-be6edfb5-d66b-4079-a3d2-af40c3685960,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-6f9de3bf-d6d2-4bc0-b94c-ab9f3279a02b,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-d742f857-710f-4a26-92a4-debf7ffa8ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-d20743bb-8a75-44de-ae8e-156a751041c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110819420-172.17.0.19-1597654796087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37520,DS-f43f09f9-bbfd-41e9-ae20-a5766875ed46,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-adf07d3e-a1ba-4a94-8666-eecd60b0dfda,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-b09ce5b7-50a3-456e-bf95-a2043f69e7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-f0407930-35f4-478c-814d-65233e59dd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-be6edfb5-d66b-4079-a3d2-af40c3685960,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-6f9de3bf-d6d2-4bc0-b94c-ab9f3279a02b,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-d742f857-710f-4a26-92a4-debf7ffa8ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-d20743bb-8a75-44de-ae8e-156a751041c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024462006-172.17.0.19-1597655069349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43473,DS-eb77661d-95eb-40d8-a997-8c3b73cf4e53,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-c360c82d-fb1a-4873-b223-95df2a083b06,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-cd6ebb29-f89d-469d-a6da-3da98f6fc7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-a8534902-30a5-48bd-90b2-f09adc6f48d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-fb67a8cc-f811-4e99-9f53-12f43ab34cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-ed1e90b5-fcac-42c4-b2a6-c5ff6e34c3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-b067f3fd-17f7-4263-bf7b-6799ab64ae24,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-140eb74f-82b9-4aa8-ac13-16347aab2c9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2024462006-172.17.0.19-1597655069349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43473,DS-eb77661d-95eb-40d8-a997-8c3b73cf4e53,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-c360c82d-fb1a-4873-b223-95df2a083b06,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-cd6ebb29-f89d-469d-a6da-3da98f6fc7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-a8534902-30a5-48bd-90b2-f09adc6f48d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-fb67a8cc-f811-4e99-9f53-12f43ab34cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-ed1e90b5-fcac-42c4-b2a6-c5ff6e34c3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-b067f3fd-17f7-4263-bf7b-6799ab64ae24,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-140eb74f-82b9-4aa8-ac13-16347aab2c9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-280780999-172.17.0.19-1597655553453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33763,DS-fe9925e8-8e9e-417f-8545-0c76d3a4a56c,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-365aff81-4278-490a-899d-70154e4ea13d,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-fd7ac0bb-c53a-4f3b-98db-74f5973e82ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-20d7b37c-f362-4296-9ff0-47872c03ed4f,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-a7423cf0-f76b-4406-9b23-fb119e07c199,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-1736f294-b123-4220-ba11-e60b08352661,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-b4726084-925e-4046-9b2d-a5054f629513,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-405e05b0-4091-44ab-a21e-93b9fb255619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-280780999-172.17.0.19-1597655553453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33763,DS-fe9925e8-8e9e-417f-8545-0c76d3a4a56c,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-365aff81-4278-490a-899d-70154e4ea13d,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-fd7ac0bb-c53a-4f3b-98db-74f5973e82ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-20d7b37c-f362-4296-9ff0-47872c03ed4f,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-a7423cf0-f76b-4406-9b23-fb119e07c199,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-1736f294-b123-4220-ba11-e60b08352661,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-b4726084-925e-4046-9b2d-a5054f629513,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-405e05b0-4091-44ab-a21e-93b9fb255619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-668017035-172.17.0.19-1597655668428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38552,DS-aac2bed4-6392-4b28-b07c-7db8c4b95aef,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-39a76e0c-ce26-4876-aef1-14772a3f1234,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-fc280081-fc0c-4871-a312-300f887b3c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-b446bd1d-f4a8-466c-a910-e1235fcc29ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-149e993b-74c3-46fb-a486-6ffd001c8ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-f228a33d-13a1-4615-99a1-f638eea189e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-41cc151e-30a7-4a99-b92b-8073b64d2337,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-205c7964-934b-4068-9db4-bdb24aac58df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-668017035-172.17.0.19-1597655668428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38552,DS-aac2bed4-6392-4b28-b07c-7db8c4b95aef,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-39a76e0c-ce26-4876-aef1-14772a3f1234,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-fc280081-fc0c-4871-a312-300f887b3c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-b446bd1d-f4a8-466c-a910-e1235fcc29ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-149e993b-74c3-46fb-a486-6ffd001c8ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-f228a33d-13a1-4615-99a1-f638eea189e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-41cc151e-30a7-4a99-b92b-8073b64d2337,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-205c7964-934b-4068-9db4-bdb24aac58df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1938406687-172.17.0.19-1597655913179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37128,DS-0c0ecd12-8e04-481a-9599-7ce03b31cf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-9685d85a-a782-4161-802e-c0d4c96fc31b,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-bb935921-cfeb-486e-9bd9-6176ef547c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-c087bc5d-5e55-46dc-a513-f0d13e866bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-32edae94-b917-49aa-9b75-04b4f8cae05d,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-5e40e852-6159-43c7-b49a-fd5b3d46e50d,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-1f1a6e0d-446a-477e-bca2-09c9311a013d,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-1d71df14-818f-4f54-8105-5543fc5e11c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1938406687-172.17.0.19-1597655913179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37128,DS-0c0ecd12-8e04-481a-9599-7ce03b31cf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-9685d85a-a782-4161-802e-c0d4c96fc31b,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-bb935921-cfeb-486e-9bd9-6176ef547c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-c087bc5d-5e55-46dc-a513-f0d13e866bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-32edae94-b917-49aa-9b75-04b4f8cae05d,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-5e40e852-6159-43c7-b49a-fd5b3d46e50d,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-1f1a6e0d-446a-477e-bca2-09c9311a013d,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-1d71df14-818f-4f54-8105-5543fc5e11c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-640772202-172.17.0.19-1597656183561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41282,DS-d17f8b41-9acf-4579-90e5-d583727476f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-58ac6ec2-c03b-429e-a211-96c9f8c2d619,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-bf833222-05c8-4c90-9afd-6eb9e6ef4482,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-2ef4e42b-32ad-4ef4-a19c-98decdafbee6,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-e4d4fddb-4485-46ec-9276-b098309de8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-4e5ca197-506e-444b-9ceb-937188e82d18,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-4f60d147-1380-42f7-b991-a5f3c497dd20,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-daba5598-d149-46f4-9d77-703421f2bc18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-640772202-172.17.0.19-1597656183561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41282,DS-d17f8b41-9acf-4579-90e5-d583727476f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-58ac6ec2-c03b-429e-a211-96c9f8c2d619,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-bf833222-05c8-4c90-9afd-6eb9e6ef4482,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-2ef4e42b-32ad-4ef4-a19c-98decdafbee6,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-e4d4fddb-4485-46ec-9276-b098309de8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-4e5ca197-506e-444b-9ceb-937188e82d18,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-4f60d147-1380-42f7-b991-a5f3c497dd20,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-daba5598-d149-46f4-9d77-703421f2bc18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-397605118-172.17.0.19-1597656428492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36326,DS-5b848c72-c4ae-4b4a-bca3-e0eb32d77334,DISK], DatanodeInfoWithStorage[127.0.0.1:43885,DS-e764a03d-982f-42f2-a3eb-4071702b41d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-e743db96-a9b5-4e61-9d45-22f91ac44670,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-55f215be-ba2a-4fcc-ac7e-6fd3dde9030a,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-d3b7a245-c05b-4ed3-b2f2-fbd6229fda4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-5121e3a8-ccef-4e59-903a-a442d2b86484,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-acbf3c53-e5f8-42f4-9202-6c8e137c2770,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-0e23c3d7-431c-4ed5-b1c8-d4e8e844cc22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-397605118-172.17.0.19-1597656428492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36326,DS-5b848c72-c4ae-4b4a-bca3-e0eb32d77334,DISK], DatanodeInfoWithStorage[127.0.0.1:43885,DS-e764a03d-982f-42f2-a3eb-4071702b41d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-e743db96-a9b5-4e61-9d45-22f91ac44670,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-55f215be-ba2a-4fcc-ac7e-6fd3dde9030a,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-d3b7a245-c05b-4ed3-b2f2-fbd6229fda4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-5121e3a8-ccef-4e59-903a-a442d2b86484,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-acbf3c53-e5f8-42f4-9202-6c8e137c2770,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-0e23c3d7-431c-4ed5-b1c8-d4e8e844cc22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143931026-172.17.0.19-1597656833225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46739,DS-8e3c212d-c0a5-496c-a9d7-2d4c9e620d00,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-c070d97e-fada-4475-a031-9283d9e90b44,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-c1dd225a-16d9-402a-b3fe-488f2aa125c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-8a6640a0-f259-4af4-bb5d-b63aecf771dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-ad1923d3-90d4-46a7-9e72-3d5a089188d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-4d83b168-6b77-4ca0-b92d-40bd57531e37,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-7bc813a7-0071-4528-b64b-d4bf83aa1265,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-43016460-214e-4554-a35c-59ae54430273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143931026-172.17.0.19-1597656833225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46739,DS-8e3c212d-c0a5-496c-a9d7-2d4c9e620d00,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-c070d97e-fada-4475-a031-9283d9e90b44,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-c1dd225a-16d9-402a-b3fe-488f2aa125c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-8a6640a0-f259-4af4-bb5d-b63aecf771dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-ad1923d3-90d4-46a7-9e72-3d5a089188d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-4d83b168-6b77-4ca0-b92d-40bd57531e37,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-7bc813a7-0071-4528-b64b-d4bf83aa1265,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-43016460-214e-4554-a35c-59ae54430273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934742982-172.17.0.19-1597656919111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41266,DS-4839e63d-4cde-4f44-8a09-a034195d765e,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-09b971f1-ceaa-4ca5-a316-48ced786f91e,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-dc150287-92f3-4f8c-bd7b-2f686b7b06de,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-cc4bcff8-f7ce-4563-b4fa-42f30bbb41b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-239ac1ab-ff25-49c9-b4be-08b130737649,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-fd91ba28-9a56-4d8f-b7f8-7601b3a7f854,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-23905bac-908d-470d-9a74-34cd68dc38f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-a6530f08-239a-4244-8d53-cb8db4e81c43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934742982-172.17.0.19-1597656919111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41266,DS-4839e63d-4cde-4f44-8a09-a034195d765e,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-09b971f1-ceaa-4ca5-a316-48ced786f91e,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-dc150287-92f3-4f8c-bd7b-2f686b7b06de,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-cc4bcff8-f7ce-4563-b4fa-42f30bbb41b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-239ac1ab-ff25-49c9-b4be-08b130737649,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-fd91ba28-9a56-4d8f-b7f8-7601b3a7f854,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-23905bac-908d-470d-9a74-34cd68dc38f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-a6530f08-239a-4244-8d53-cb8db4e81c43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1797684061-172.17.0.19-1597656966318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40329,DS-c8997158-0706-450d-af80-12bd40f356bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-3cb12761-2d74-4378-b4f5-f2e82920994d,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-9870987a-6c81-4869-b872-72a2a1fe9fea,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-ee5f5403-3b65-479e-ad8b-209b7983a3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-444ef972-3bb7-45bd-910c-e99542c632b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-17e74b93-fefc-467b-a188-6afe16b8372e,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-3c809938-00f3-4050-a058-15595f851bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-b1a36890-9389-41b9-8502-b430ba07d26c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1797684061-172.17.0.19-1597656966318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40329,DS-c8997158-0706-450d-af80-12bd40f356bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-3cb12761-2d74-4378-b4f5-f2e82920994d,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-9870987a-6c81-4869-b872-72a2a1fe9fea,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-ee5f5403-3b65-479e-ad8b-209b7983a3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-444ef972-3bb7-45bd-910c-e99542c632b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-17e74b93-fefc-467b-a188-6afe16b8372e,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-3c809938-00f3-4050-a058-15595f851bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-b1a36890-9389-41b9-8502-b430ba07d26c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-129260599-172.17.0.19-1597657002253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36881,DS-a32c313e-fe0e-4837-a926-edc2942aade8,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-afd20b71-4fa3-4b42-bece-ace2fca6ae82,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-f311bdb8-dcaf-48bd-99a4-25d9c46832dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-05d33f54-232f-44a4-80ca-f0cdafa6f256,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-7789ce0d-f5c8-436c-87a4-a103d422a430,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-0c641962-3a45-4c8b-b776-5ddd4f867cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-982b82f9-fe2b-4dfa-b530-d2295d6e3edb,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-abb721dd-7b63-46c9-bc34-e47cd6b59dc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-129260599-172.17.0.19-1597657002253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36881,DS-a32c313e-fe0e-4837-a926-edc2942aade8,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-afd20b71-4fa3-4b42-bece-ace2fca6ae82,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-f311bdb8-dcaf-48bd-99a4-25d9c46832dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-05d33f54-232f-44a4-80ca-f0cdafa6f256,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-7789ce0d-f5c8-436c-87a4-a103d422a430,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-0c641962-3a45-4c8b-b776-5ddd4f867cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-982b82f9-fe2b-4dfa-b530-d2295d6e3edb,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-abb721dd-7b63-46c9-bc34-e47cd6b59dc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2020664676-172.17.0.19-1597657040776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41163,DS-cdd67fde-5340-4373-8a24-cad688876277,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-f2b3929c-032c-41e8-8e1e-297705246541,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-67a98b93-546d-44fb-b705-4060f95b157b,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-fdcbeb70-86ba-488f-8e68-665104ab9e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-44b8c825-c93c-40ec-bd2d-f65893d82579,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-b9e69810-037b-4b73-b324-e155750a5869,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-90869533-71c5-4a30-96e4-ef7c3945c50b,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-7af6dbe8-1596-4b06-b37f-b82b6e2591ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2020664676-172.17.0.19-1597657040776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41163,DS-cdd67fde-5340-4373-8a24-cad688876277,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-f2b3929c-032c-41e8-8e1e-297705246541,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-67a98b93-546d-44fb-b705-4060f95b157b,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-fdcbeb70-86ba-488f-8e68-665104ab9e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-44b8c825-c93c-40ec-bd2d-f65893d82579,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-b9e69810-037b-4b73-b324-e155750a5869,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-90869533-71c5-4a30-96e4-ef7c3945c50b,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-7af6dbe8-1596-4b06-b37f-b82b6e2591ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-390627800-172.17.0.19-1597657081460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44460,DS-fe3df67f-994f-49af-b6b0-12979edb03e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-1fbcb3a0-ad78-4556-99f1-ee5867451a40,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-1f142e23-8b7a-4b52-9897-233f19acbf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-5fe94f94-a9f4-4fc9-8076-92afb81b1e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-4ce00c60-2490-4349-b912-a31c4904d607,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-7342332b-704b-4cf8-9b14-8185957fe34a,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-b9ca112d-a5cf-4c2a-9204-5d9b71bffc97,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-5a5c7a43-2615-4759-b93f-d4602bfe0bb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-390627800-172.17.0.19-1597657081460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44460,DS-fe3df67f-994f-49af-b6b0-12979edb03e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-1fbcb3a0-ad78-4556-99f1-ee5867451a40,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-1f142e23-8b7a-4b52-9897-233f19acbf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-5fe94f94-a9f4-4fc9-8076-92afb81b1e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-4ce00c60-2490-4349-b912-a31c4904d607,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-7342332b-704b-4cf8-9b14-8185957fe34a,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-b9ca112d-a5cf-4c2a-9204-5d9b71bffc97,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-5a5c7a43-2615-4759-b93f-d4602bfe0bb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2021103720-172.17.0.19-1597658285550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35128,DS-2b9e91ed-d255-4183-87e3-6419e1a0e77d,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-410963db-8d34-4e29-942b-f36499c9e070,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-a5665512-9bf8-462a-9b53-5f005e4300a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-3a94dc5b-3c5d-4180-84e7-206b42a9b036,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-b0563c9a-cfb0-469f-9092-7c638d10bea1,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-210e9242-6183-4872-a440-cdd7289cadc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-21babb64-4eb1-45db-86c6-5c5abe01e318,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-58978398-16ab-4ec1-9f61-800fe59fdd67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2021103720-172.17.0.19-1597658285550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35128,DS-2b9e91ed-d255-4183-87e3-6419e1a0e77d,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-410963db-8d34-4e29-942b-f36499c9e070,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-a5665512-9bf8-462a-9b53-5f005e4300a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-3a94dc5b-3c5d-4180-84e7-206b42a9b036,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-b0563c9a-cfb0-469f-9092-7c638d10bea1,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-210e9242-6183-4872-a440-cdd7289cadc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-21babb64-4eb1-45db-86c6-5c5abe01e318,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-58978398-16ab-4ec1-9f61-800fe59fdd67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1590963477-172.17.0.19-1597658662144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41179,DS-9cf68b78-42d6-4ddf-aeb1-0206ade9e2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-862abb24-414d-4f92-91d0-491af88f01a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-fefa75d1-1520-4ad9-9c26-4f67feb7c064,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-eb973935-e24a-4e8d-8616-6a8ae042cd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-003ee0fe-1900-4275-9e78-c9749f18a9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-20242e6f-d22a-4a64-8143-e8dddec4cf6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-232048b6-c59c-47c7-9411-57cd928a1ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-53a97fc2-5a39-40ce-bfac-4277ab9e39d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1590963477-172.17.0.19-1597658662144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41179,DS-9cf68b78-42d6-4ddf-aeb1-0206ade9e2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-862abb24-414d-4f92-91d0-491af88f01a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-fefa75d1-1520-4ad9-9c26-4f67feb7c064,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-eb973935-e24a-4e8d-8616-6a8ae042cd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-003ee0fe-1900-4275-9e78-c9749f18a9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-20242e6f-d22a-4a64-8143-e8dddec4cf6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-232048b6-c59c-47c7-9411-57cd928a1ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-53a97fc2-5a39-40ce-bfac-4277ab9e39d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-807604704-172.17.0.19-1597658881198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38789,DS-be693b01-d915-47bb-afc4-2ca0512f5285,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-90a0d998-2987-4d73-8275-77b2ca572f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-fdd979fe-8840-4dc5-a542-ffc6d9d1133f,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-c78e416b-2839-48d1-8f56-d0256024f466,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-cc0b021e-ba03-479d-b51f-2be1b907da84,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-cd4132d9-a317-4b17-817d-cbd6dc7c8f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-c4c76e3a-86f6-4ff6-8e72-a236e312f1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-b4159c69-5bce-4d88-8d49-489ae7b6697e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-807604704-172.17.0.19-1597658881198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38789,DS-be693b01-d915-47bb-afc4-2ca0512f5285,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-90a0d998-2987-4d73-8275-77b2ca572f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-fdd979fe-8840-4dc5-a542-ffc6d9d1133f,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-c78e416b-2839-48d1-8f56-d0256024f466,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-cc0b021e-ba03-479d-b51f-2be1b907da84,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-cd4132d9-a317-4b17-817d-cbd6dc7c8f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-c4c76e3a-86f6-4ff6-8e72-a236e312f1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-b4159c69-5bce-4d88-8d49-489ae7b6697e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-711689030-172.17.0.19-1597658958605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33324,DS-f6738f0c-52cb-400c-9dd6-149ae71a404a,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-905805e8-7ecc-4567-9674-2845508f4701,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-1805723c-d276-447e-8946-8b22941db37e,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-8d6464b7-ab1b-454d-b94d-02845089edb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-d186cfb6-a249-4e33-bce7-afdd7535f026,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-8b115720-8791-43d4-a381-92eaf2080f43,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-d3609979-e58f-4881-a258-3ce42d242824,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-e4ac85dc-46af-4f6d-96dc-747a33408350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-711689030-172.17.0.19-1597658958605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33324,DS-f6738f0c-52cb-400c-9dd6-149ae71a404a,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-905805e8-7ecc-4567-9674-2845508f4701,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-1805723c-d276-447e-8946-8b22941db37e,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-8d6464b7-ab1b-454d-b94d-02845089edb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-d186cfb6-a249-4e33-bce7-afdd7535f026,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-8b115720-8791-43d4-a381-92eaf2080f43,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-d3609979-e58f-4881-a258-3ce42d242824,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-e4ac85dc-46af-4f6d-96dc-747a33408350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-332046261-172.17.0.19-1597659096031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44172,DS-97c8651d-75ea-414c-8308-d767c8e79650,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-08e323fa-0b9f-4cbd-82a2-f3549a47739a,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-40406c3d-3117-45e1-807f-bcc1ae9ad42d,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-9cf3ed78-8e4f-4afe-a215-f6871211e9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-6f6ef688-7b1e-4543-ab4f-3866022500ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-ead07c10-f6c7-4dae-adfc-da368ab4711a,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-cf38c154-8011-48e8-adfb-794b74428be8,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-af09bf7d-1bf6-4907-86ee-2085ba52a3cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-332046261-172.17.0.19-1597659096031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44172,DS-97c8651d-75ea-414c-8308-d767c8e79650,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-08e323fa-0b9f-4cbd-82a2-f3549a47739a,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-40406c3d-3117-45e1-807f-bcc1ae9ad42d,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-9cf3ed78-8e4f-4afe-a215-f6871211e9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-6f6ef688-7b1e-4543-ab4f-3866022500ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-ead07c10-f6c7-4dae-adfc-da368ab4711a,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-cf38c154-8011-48e8-adfb-794b74428be8,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-af09bf7d-1bf6-4907-86ee-2085ba52a3cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5757
