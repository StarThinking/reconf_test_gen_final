reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1828763356-172.17.0.14-1597723820260:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36407,DS-3b2c8a43-26df-4709-9914-e242997246a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33095,DS-d1e23320-0d40-4fe7-88f4-a1802197aa33,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-72a5ff1c-73f2-473c-855b-9237ecf963a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-dcec2993-617c-4ad5-8e20-9a105147c94d,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-cce34770-b779-47a9-b8c7-e07e628a8700,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-2d3aaa3b-c517-4176-aa3d-0f0132d393db,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-e63547c7-2b2b-4724-b171-75b82cfeb0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-00a496e7-1bbd-4839-bbd6-3b9290ea52d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1828763356-172.17.0.14-1597723820260:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36407,DS-3b2c8a43-26df-4709-9914-e242997246a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33095,DS-d1e23320-0d40-4fe7-88f4-a1802197aa33,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-72a5ff1c-73f2-473c-855b-9237ecf963a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-dcec2993-617c-4ad5-8e20-9a105147c94d,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-cce34770-b779-47a9-b8c7-e07e628a8700,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-2d3aaa3b-c517-4176-aa3d-0f0132d393db,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-e63547c7-2b2b-4724-b171-75b82cfeb0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-00a496e7-1bbd-4839-bbd6-3b9290ea52d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1740584429-172.17.0.14-1597724032069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41874,DS-c132e569-e7a7-4e46-95f4-08ace0078785,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-e8d197c1-e793-4516-8609-d848390235f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-b64077da-f141-4401-9cf2-1163258d4bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-f7ab24bb-a75e-4177-9c72-b5e7cf25404a,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-14203dce-d81b-4e63-8646-da9a9c88501c,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-b301e760-0500-4c15-b651-eee4956704d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-33e4fbd3-d8ce-42b6-b12b-32cc62b8b9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-6491d165-e3b4-4420-809b-f5c1a6de9aab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1740584429-172.17.0.14-1597724032069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41874,DS-c132e569-e7a7-4e46-95f4-08ace0078785,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-e8d197c1-e793-4516-8609-d848390235f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-b64077da-f141-4401-9cf2-1163258d4bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-f7ab24bb-a75e-4177-9c72-b5e7cf25404a,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-14203dce-d81b-4e63-8646-da9a9c88501c,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-b301e760-0500-4c15-b651-eee4956704d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-33e4fbd3-d8ce-42b6-b12b-32cc62b8b9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-6491d165-e3b4-4420-809b-f5c1a6de9aab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1160685220-172.17.0.14-1597724509604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45598,DS-492ec0a4-b5ba-41f5-8a5e-56b76e9696de,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-22717b8e-6270-48f7-b353-75c50621f397,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-94e076e7-5a09-4444-8db2-6feef7487906,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-0f03aefd-185b-473c-9c86-6b7cec0f609e,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-f1b5080a-450b-45d5-af51-894a5a24b47d,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-11c6196f-c346-4db5-8209-c97c47e06d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-5e94ed52-2bba-4c54-a665-62f1147895d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-e59f38f9-0c14-4133-9b70-85ddc608a0c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1160685220-172.17.0.14-1597724509604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45598,DS-492ec0a4-b5ba-41f5-8a5e-56b76e9696de,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-22717b8e-6270-48f7-b353-75c50621f397,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-94e076e7-5a09-4444-8db2-6feef7487906,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-0f03aefd-185b-473c-9c86-6b7cec0f609e,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-f1b5080a-450b-45d5-af51-894a5a24b47d,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-11c6196f-c346-4db5-8209-c97c47e06d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-5e94ed52-2bba-4c54-a665-62f1147895d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-e59f38f9-0c14-4133-9b70-85ddc608a0c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-960539334-172.17.0.14-1597724946639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40413,DS-8d05d408-f15e-4857-b5f7-759b4b7110bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-a56bda53-92e3-494f-a150-859964c7324f,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-7a1bc860-831f-4a0c-91b2-9bf47166c1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-84313dad-e769-4f6e-9383-9fa941afc498,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-b40bc1c3-648b-4960-98a9-deb5616a901d,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-a864763e-db30-4afe-8092-4dad1060ac56,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-891b2241-c13d-4ae2-b6a0-0bf2d2f8d580,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-4d24e3d3-c2e2-4503-aa84-30830b49990a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-960539334-172.17.0.14-1597724946639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40413,DS-8d05d408-f15e-4857-b5f7-759b4b7110bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-a56bda53-92e3-494f-a150-859964c7324f,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-7a1bc860-831f-4a0c-91b2-9bf47166c1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-84313dad-e769-4f6e-9383-9fa941afc498,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-b40bc1c3-648b-4960-98a9-deb5616a901d,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-a864763e-db30-4afe-8092-4dad1060ac56,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-891b2241-c13d-4ae2-b6a0-0bf2d2f8d580,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-4d24e3d3-c2e2-4503-aa84-30830b49990a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1814810989-172.17.0.14-1597725087501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32793,DS-76c59c55-208d-4bdd-83b6-4b00e5995d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-459ec131-913d-4826-900b-4d264be50109,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-c13dd35e-9f5d-4412-943a-794e7cf9fa97,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-74752756-2faf-4142-b98d-c5630d569eea,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-d51a2491-c4a0-4dba-b585-b9da3ed49380,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-92b2850c-f0dd-49c6-abc3-e2f620c9475e,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-27e7eff6-a883-440f-82e7-d98517c0befa,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-42bcae69-9a97-4ce7-8d0f-ce5713f0b8d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1814810989-172.17.0.14-1597725087501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32793,DS-76c59c55-208d-4bdd-83b6-4b00e5995d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-459ec131-913d-4826-900b-4d264be50109,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-c13dd35e-9f5d-4412-943a-794e7cf9fa97,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-74752756-2faf-4142-b98d-c5630d569eea,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-d51a2491-c4a0-4dba-b585-b9da3ed49380,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-92b2850c-f0dd-49c6-abc3-e2f620c9475e,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-27e7eff6-a883-440f-82e7-d98517c0befa,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-42bcae69-9a97-4ce7-8d0f-ce5713f0b8d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1512530673-172.17.0.14-1597725380963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38077,DS-29edd218-693f-44a4-ae78-825e6198d43a,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-9d372a75-4222-4f77-a2c5-27c4a5c542cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-30f10bae-8554-497c-9603-290b45a702f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-76ef69c7-5e22-4d53-95be-9546eff08abe,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-83c923e1-b855-4f78-89a9-0eaa85f79551,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-680fc847-2393-4100-9ef0-43852713efb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-d25d69c1-3a06-45dd-8e8a-82104c998993,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-a66b82e6-fe05-42bc-939e-f60301ed716b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1512530673-172.17.0.14-1597725380963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38077,DS-29edd218-693f-44a4-ae78-825e6198d43a,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-9d372a75-4222-4f77-a2c5-27c4a5c542cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-30f10bae-8554-497c-9603-290b45a702f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-76ef69c7-5e22-4d53-95be-9546eff08abe,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-83c923e1-b855-4f78-89a9-0eaa85f79551,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-680fc847-2393-4100-9ef0-43852713efb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-d25d69c1-3a06-45dd-8e8a-82104c998993,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-a66b82e6-fe05-42bc-939e-f60301ed716b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1541604788-172.17.0.14-1597725603555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37626,DS-abec0d97-0737-4f33-bced-34df39f570df,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-db314a7b-bf9b-4695-af8e-6304ecf3d51a,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-1c39980a-eca4-4d53-935a-10ea73e23a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-8d3733fc-a0a9-4f1e-9f76-05ddf7447d88,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-04529baa-94cd-42d8-9570-85a155359170,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-dbac9be6-8bbc-4146-ae44-278e7e781678,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-24c473ed-7c8b-46e4-bd2f-f93a04a4c9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-54a8207c-b769-4658-acc9-2c47f450b06b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1541604788-172.17.0.14-1597725603555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37626,DS-abec0d97-0737-4f33-bced-34df39f570df,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-db314a7b-bf9b-4695-af8e-6304ecf3d51a,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-1c39980a-eca4-4d53-935a-10ea73e23a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-8d3733fc-a0a9-4f1e-9f76-05ddf7447d88,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-04529baa-94cd-42d8-9570-85a155359170,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-dbac9be6-8bbc-4146-ae44-278e7e781678,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-24c473ed-7c8b-46e4-bd2f-f93a04a4c9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-54a8207c-b769-4658-acc9-2c47f450b06b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1352037840-172.17.0.14-1597725713922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35880,DS-2e754122-14e0-40cc-8e10-d15b7bcda7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-2a6bfa09-ceff-4525-96e6-479d7105782a,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-5b6fdd24-4248-43a2-b53c-c8c2a6721a33,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-90ba600b-1708-430e-8cbb-7d525da8621a,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-49a0760c-4f54-4b8d-8614-25f0e875e2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-891d9a92-44c3-46a5-983e-0eac60c03875,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-323e8da0-4c31-43a3-8c02-85a6c39d2d86,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-34e1b7e0-2a66-444f-a7d4-4b501122efe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1352037840-172.17.0.14-1597725713922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35880,DS-2e754122-14e0-40cc-8e10-d15b7bcda7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-2a6bfa09-ceff-4525-96e6-479d7105782a,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-5b6fdd24-4248-43a2-b53c-c8c2a6721a33,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-90ba600b-1708-430e-8cbb-7d525da8621a,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-49a0760c-4f54-4b8d-8614-25f0e875e2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-891d9a92-44c3-46a5-983e-0eac60c03875,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-323e8da0-4c31-43a3-8c02-85a6c39d2d86,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-34e1b7e0-2a66-444f-a7d4-4b501122efe0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-490302563-172.17.0.14-1597725850845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46187,DS-8f3b3d9a-fe7b-4b94-b574-b8468dc66317,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-73359af9-f0ea-4196-9338-4b99d80cbe29,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-cffe63c0-0453-4379-b687-4cb18064bad0,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-39a9bf22-4f03-47f7-b8c8-71d3a2d61d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-16a3c660-7850-43aa-9e2d-a3cc9256dcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-5d7ea75c-c6f3-4504-a0f3-1247e93403af,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-e1e777fd-005e-4418-83e7-7039ec305706,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-f38d4221-2b7b-495e-a916-099d607ea8ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-490302563-172.17.0.14-1597725850845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46187,DS-8f3b3d9a-fe7b-4b94-b574-b8468dc66317,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-73359af9-f0ea-4196-9338-4b99d80cbe29,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-cffe63c0-0453-4379-b687-4cb18064bad0,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-39a9bf22-4f03-47f7-b8c8-71d3a2d61d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-16a3c660-7850-43aa-9e2d-a3cc9256dcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-5d7ea75c-c6f3-4504-a0f3-1247e93403af,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-e1e777fd-005e-4418-83e7-7039ec305706,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-f38d4221-2b7b-495e-a916-099d607ea8ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-462505572-172.17.0.14-1597728143351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46116,DS-3dcad745-4191-49bd-a527-a3478d2760dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-e88349bf-2a2c-4ea4-b270-46c8e31b2e38,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-af3270f7-a828-4f61-9c2a-53bb9be5a9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-15e8aaf9-5597-4cce-b490-6a89c7551dac,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-55983800-458a-4e7a-a5b9-a6dcf7676bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-f8907378-f5af-44b8-b4be-6323df83ef5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-63e9578f-99b0-4882-9219-ddb6072a66cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-23a69c03-25a4-4dd6-83f8-f12ef8280483,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-462505572-172.17.0.14-1597728143351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46116,DS-3dcad745-4191-49bd-a527-a3478d2760dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-e88349bf-2a2c-4ea4-b270-46c8e31b2e38,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-af3270f7-a828-4f61-9c2a-53bb9be5a9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-15e8aaf9-5597-4cce-b490-6a89c7551dac,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-55983800-458a-4e7a-a5b9-a6dcf7676bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-f8907378-f5af-44b8-b4be-6323df83ef5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-63e9578f-99b0-4882-9219-ddb6072a66cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-23a69c03-25a4-4dd6-83f8-f12ef8280483,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1787403865-172.17.0.14-1597728592912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34957,DS-f55b95ba-2939-44a7-9b75-4d3cffbfe76a,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-844761f0-7fd9-4c28-b7e8-2d0b2c02d9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-29dd2dda-ad9c-49b7-bbe1-d6482ea2d2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-cb793f9f-a284-462c-ae3e-59f21852df42,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-330cfd48-7f69-4eaf-b1d1-f8062332e6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-d170a880-6bc1-450f-ac03-ae4a783e7654,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-48ded2f2-aaaa-48a6-a59a-d877b33c76b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-cce84fa8-362c-4bb9-9991-26d1b527d415,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1787403865-172.17.0.14-1597728592912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34957,DS-f55b95ba-2939-44a7-9b75-4d3cffbfe76a,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-844761f0-7fd9-4c28-b7e8-2d0b2c02d9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-29dd2dda-ad9c-49b7-bbe1-d6482ea2d2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-cb793f9f-a284-462c-ae3e-59f21852df42,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-330cfd48-7f69-4eaf-b1d1-f8062332e6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-d170a880-6bc1-450f-ac03-ae4a783e7654,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-48ded2f2-aaaa-48a6-a59a-d877b33c76b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-cce84fa8-362c-4bb9-9991-26d1b527d415,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-710566647-172.17.0.14-1597728842312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41039,DS-ffaca3a5-2324-4022-8d3f-0d635cc45944,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-9bee1aa0-5c63-4ef2-ae8f-e23a1f65cd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-4c25c3f4-4fb9-47a4-b45a-0c0ffdb4f093,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-d2a825ff-d37f-49c3-a1b0-acf97a9af808,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-27f9213f-7a01-488b-860b-ce4f03eff825,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-0463ad73-4c33-4ff6-9b54-f78e79d2c163,DISK], DatanodeInfoWithStorage[127.0.0.1:33514,DS-999c9072-fcf1-47e2-8526-ab6da71fa131,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-dc745244-db79-45c8-bc5a-4cb10364fe5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-710566647-172.17.0.14-1597728842312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41039,DS-ffaca3a5-2324-4022-8d3f-0d635cc45944,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-9bee1aa0-5c63-4ef2-ae8f-e23a1f65cd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-4c25c3f4-4fb9-47a4-b45a-0c0ffdb4f093,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-d2a825ff-d37f-49c3-a1b0-acf97a9af808,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-27f9213f-7a01-488b-860b-ce4f03eff825,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-0463ad73-4c33-4ff6-9b54-f78e79d2c163,DISK], DatanodeInfoWithStorage[127.0.0.1:33514,DS-999c9072-fcf1-47e2-8526-ab6da71fa131,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-dc745244-db79-45c8-bc5a-4cb10364fe5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1830451417-172.17.0.14-1597729125215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43933,DS-f4046c58-3a0b-4b75-a684-e3353af0b0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-f7dc26d2-5114-480f-bd79-8db7cae51c68,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-1b9e63bb-3141-4e92-85c3-d1191db369f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-218884d1-a3b4-4927-a829-8849932dd79d,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-76f506c2-058b-401f-8018-5010b75f3e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-3968ef8a-c64a-484c-89eb-c53dd474f2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-f9d6ccdb-d9f2-4958-82d2-15fc218ed283,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-35ef9296-6b55-47a3-bbac-fdfb0801729e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1830451417-172.17.0.14-1597729125215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43933,DS-f4046c58-3a0b-4b75-a684-e3353af0b0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-f7dc26d2-5114-480f-bd79-8db7cae51c68,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-1b9e63bb-3141-4e92-85c3-d1191db369f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-218884d1-a3b4-4927-a829-8849932dd79d,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-76f506c2-058b-401f-8018-5010b75f3e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-3968ef8a-c64a-484c-89eb-c53dd474f2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-f9d6ccdb-d9f2-4958-82d2-15fc218ed283,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-35ef9296-6b55-47a3-bbac-fdfb0801729e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5463
