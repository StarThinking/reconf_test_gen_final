reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-270994580-172.17.0.2-1597736261479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43211,DS-cec84804-f8de-446b-89ef-299895084569,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-fad59164-91ec-44f8-8a0d-faa258bb81eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-d161519f-1764-442a-a65d-6f3ab782a3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-eabb78b2-a762-41b7-8289-8c1153ac3f69,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-6c72aab4-1d2a-48fb-a691-923453b296e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-4c724040-d02a-4165-953e-50f23a7a519d,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-6f850d27-6ac6-415e-9277-996afb7fd994,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-7e6b23d6-18c0-4460-91a2-a47792cd1320,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-270994580-172.17.0.2-1597736261479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43211,DS-cec84804-f8de-446b-89ef-299895084569,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-fad59164-91ec-44f8-8a0d-faa258bb81eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-d161519f-1764-442a-a65d-6f3ab782a3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-eabb78b2-a762-41b7-8289-8c1153ac3f69,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-6c72aab4-1d2a-48fb-a691-923453b296e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-4c724040-d02a-4165-953e-50f23a7a519d,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-6f850d27-6ac6-415e-9277-996afb7fd994,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-7e6b23d6-18c0-4460-91a2-a47792cd1320,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-777661208-172.17.0.2-1597736297771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43785,DS-a953b246-3793-4f48-873c-0438263c49e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-4bc03cfa-434f-43cf-8515-ba4e17884f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-6638f710-51cf-42d6-8ead-4055efc8b206,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-3917aac3-af01-4629-97b1-b13c58f4ffa9,DISK], DatanodeInfoWithStorage[127.0.0.1:46835,DS-af64b1c3-6140-48d6-bfe6-8cf1c928515d,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-2a918f79-fb70-4b2d-8ae9-440b7e5f1df6,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-11c8411a-82b6-4aa2-9e37-a83d5961fa3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-212e62ef-fc03-4b62-852b-a7379eae43dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-777661208-172.17.0.2-1597736297771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43785,DS-a953b246-3793-4f48-873c-0438263c49e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-4bc03cfa-434f-43cf-8515-ba4e17884f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-6638f710-51cf-42d6-8ead-4055efc8b206,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-3917aac3-af01-4629-97b1-b13c58f4ffa9,DISK], DatanodeInfoWithStorage[127.0.0.1:46835,DS-af64b1c3-6140-48d6-bfe6-8cf1c928515d,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-2a918f79-fb70-4b2d-8ae9-440b7e5f1df6,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-11c8411a-82b6-4aa2-9e37-a83d5961fa3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-212e62ef-fc03-4b62-852b-a7379eae43dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-298292303-172.17.0.2-1597736337719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42438,DS-1b50cd36-de9f-48f9-8346-e76d4f953cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-83455cdf-dad6-4ea9-96ed-d2db36abfc82,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-80cfcf70-7b7b-42b2-b09f-d148aa851adc,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-da439139-d144-4346-963b-cc2a874da185,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-30a1347c-72b6-4103-af5d-e5ea94b946c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-d017d3d4-d5dc-496a-ad36-0773f6c65e48,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-520a5e60-4c5f-4463-967f-b60d0ada7246,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-71717d0c-899d-4abf-896d-7e8d1d1799db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-298292303-172.17.0.2-1597736337719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42438,DS-1b50cd36-de9f-48f9-8346-e76d4f953cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-83455cdf-dad6-4ea9-96ed-d2db36abfc82,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-80cfcf70-7b7b-42b2-b09f-d148aa851adc,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-da439139-d144-4346-963b-cc2a874da185,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-30a1347c-72b6-4103-af5d-e5ea94b946c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-d017d3d4-d5dc-496a-ad36-0773f6c65e48,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-520a5e60-4c5f-4463-967f-b60d0ada7246,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-71717d0c-899d-4abf-896d-7e8d1d1799db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1297332646-172.17.0.2-1597737449820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40038,DS-82c5bd2a-05ee-4c32-ac38-d8248448a37c,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-a3911ddb-f400-4650-8d3a-df0e4fe7355c,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-6560dba4-a3ca-46cd-a560-e388939d2703,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-3e99d38d-6dd0-4b37-bebf-a0f2a362443f,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-ae3cab5b-0282-4eb6-ad4c-f8be225bf721,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-302a3fb4-360f-4f0d-8884-635fb0c195f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-672272c8-17fe-4fd8-874f-2e0eed812a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-1c32f0d4-2c9b-4c6c-8e6c-ace2186353e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1297332646-172.17.0.2-1597737449820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40038,DS-82c5bd2a-05ee-4c32-ac38-d8248448a37c,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-a3911ddb-f400-4650-8d3a-df0e4fe7355c,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-6560dba4-a3ca-46cd-a560-e388939d2703,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-3e99d38d-6dd0-4b37-bebf-a0f2a362443f,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-ae3cab5b-0282-4eb6-ad4c-f8be225bf721,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-302a3fb4-360f-4f0d-8884-635fb0c195f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-672272c8-17fe-4fd8-874f-2e0eed812a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-1c32f0d4-2c9b-4c6c-8e6c-ace2186353e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1543219290-172.17.0.2-1597737722411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39361,DS-155f30b6-a4b1-4b05-91cf-7326ff8cd471,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-337d17d3-8b1f-4cd0-8ec8-4f49fe7eb668,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-f11491d7-d4da-4a94-9eb9-d6e0b73c6722,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-1e6596fd-5c5c-4b36-87f9-c365b4507775,DISK], DatanodeInfoWithStorage[127.0.0.1:45499,DS-bba71b14-a8e0-4f84-bcbf-48dc901d6b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-f8cb2242-88bb-4f1f-83ec-ebe134336b86,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-22c2792d-81db-454c-a443-e0529804dbee,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-6bf8dee5-d593-4223-954f-cd5f8423279b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1543219290-172.17.0.2-1597737722411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39361,DS-155f30b6-a4b1-4b05-91cf-7326ff8cd471,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-337d17d3-8b1f-4cd0-8ec8-4f49fe7eb668,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-f11491d7-d4da-4a94-9eb9-d6e0b73c6722,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-1e6596fd-5c5c-4b36-87f9-c365b4507775,DISK], DatanodeInfoWithStorage[127.0.0.1:45499,DS-bba71b14-a8e0-4f84-bcbf-48dc901d6b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-f8cb2242-88bb-4f1f-83ec-ebe134336b86,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-22c2792d-81db-454c-a443-e0529804dbee,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-6bf8dee5-d593-4223-954f-cd5f8423279b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-76986262-172.17.0.2-1597738020947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46410,DS-985cdb63-c183-4433-b429-e9f20593c35e,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-86ef5152-822b-449b-b77e-2a9023d0dfa2,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-b1843934-0547-4c31-b948-6e6f046a063e,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-ea6dab97-1ed3-4c85-888c-e2c09d7a8dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-8d7135b8-b750-49b4-89b4-7bff69802356,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-8599afef-906a-4571-8a4b-0d1eaef60ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-19a6438a-e338-45f8-bf4b-3e37bf2ad56e,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-eb91bb55-3e2d-4553-8ded-95eef379891f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-76986262-172.17.0.2-1597738020947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46410,DS-985cdb63-c183-4433-b429-e9f20593c35e,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-86ef5152-822b-449b-b77e-2a9023d0dfa2,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-b1843934-0547-4c31-b948-6e6f046a063e,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-ea6dab97-1ed3-4c85-888c-e2c09d7a8dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-8d7135b8-b750-49b4-89b4-7bff69802356,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-8599afef-906a-4571-8a4b-0d1eaef60ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-19a6438a-e338-45f8-bf4b-3e37bf2ad56e,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-eb91bb55-3e2d-4553-8ded-95eef379891f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-551244567-172.17.0.2-1597738055268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38406,DS-6c9918ec-c36a-40b1-84fa-6731ab314b28,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-c6651ead-93cb-4583-bdd0-13e813c79628,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-a19b9997-b945-4cdd-a363-8647f3fdb6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-e2e1afb7-a306-451c-a761-abd5309cc3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-fee6851f-01fc-40d0-97ac-ca71a5f34865,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-335a73bf-a552-4076-b209-090d1b2bcdcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-dcba0ac2-00bf-4237-b6c6-d902ff305e12,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-5d544052-4307-4487-9252-953085472c63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-551244567-172.17.0.2-1597738055268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38406,DS-6c9918ec-c36a-40b1-84fa-6731ab314b28,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-c6651ead-93cb-4583-bdd0-13e813c79628,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-a19b9997-b945-4cdd-a363-8647f3fdb6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-e2e1afb7-a306-451c-a761-abd5309cc3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-fee6851f-01fc-40d0-97ac-ca71a5f34865,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-335a73bf-a552-4076-b209-090d1b2bcdcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-dcba0ac2-00bf-4237-b6c6-d902ff305e12,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-5d544052-4307-4487-9252-953085472c63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1031864822-172.17.0.2-1597738379400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41579,DS-a9394785-7806-4dcb-8eca-37870c58a667,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-613d416f-9f33-4703-b75e-a6345b33d490,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-c670d824-ec02-43ee-87bf-a0c842978b98,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-058a8b74-1932-4d0f-90a9-975519862915,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-31403d7d-4932-4ab0-8740-dbbe2802e45a,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-4f3c514e-f59a-44d9-ae35-91f88d9f89d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-d4e55787-464a-4a2d-9dfd-a721e3be8a96,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-deeb4069-e9fc-4a29-bf65-5d9ea188621d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1031864822-172.17.0.2-1597738379400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41579,DS-a9394785-7806-4dcb-8eca-37870c58a667,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-613d416f-9f33-4703-b75e-a6345b33d490,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-c670d824-ec02-43ee-87bf-a0c842978b98,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-058a8b74-1932-4d0f-90a9-975519862915,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-31403d7d-4932-4ab0-8740-dbbe2802e45a,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-4f3c514e-f59a-44d9-ae35-91f88d9f89d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-d4e55787-464a-4a2d-9dfd-a721e3be8a96,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-deeb4069-e9fc-4a29-bf65-5d9ea188621d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1133370026-172.17.0.2-1597738429410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34661,DS-445b7308-1755-4d9d-a469-f74f9d606ced,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-fc6acba4-1983-4db3-a063-6c75265beb95,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-35f7a147-d7e0-4514-a02a-c9bf812d587f,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-b0d169fe-b582-4dc3-bdc3-f244d25f4fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-f09b3e9c-d4d0-4e7a-8ac2-baa4ea7809b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-27d61e1c-e8ad-4121-b82b-a702a1021aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-f38cdcbd-f19d-4f42-944e-284526a2c2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-37824a66-d79b-4ea5-95f0-5d8ea3279b27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1133370026-172.17.0.2-1597738429410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34661,DS-445b7308-1755-4d9d-a469-f74f9d606ced,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-fc6acba4-1983-4db3-a063-6c75265beb95,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-35f7a147-d7e0-4514-a02a-c9bf812d587f,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-b0d169fe-b582-4dc3-bdc3-f244d25f4fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-f09b3e9c-d4d0-4e7a-8ac2-baa4ea7809b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-27d61e1c-e8ad-4121-b82b-a702a1021aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-f38cdcbd-f19d-4f42-944e-284526a2c2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-37824a66-d79b-4ea5-95f0-5d8ea3279b27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2097344305-172.17.0.2-1597738523133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41874,DS-3c4bc284-c814-48b3-b2f0-e6c782fc2c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-3c0b619e-edcc-40ba-8aac-3b19617fa665,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-17eb7cbe-c9f3-40fb-9e0a-1dd01f30624c,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-9eead409-08d7-4e51-a190-a57f7bd93be7,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-5fbb651e-2361-4ebb-a3d0-f30583308b96,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-2c412646-d0ed-4253-849b-f63da0c96273,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-4a6da69d-34b3-4b32-ba05-08906ea689a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-b35965dc-e0e1-4d23-ba87-6f66e5b0acb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2097344305-172.17.0.2-1597738523133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41874,DS-3c4bc284-c814-48b3-b2f0-e6c782fc2c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-3c0b619e-edcc-40ba-8aac-3b19617fa665,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-17eb7cbe-c9f3-40fb-9e0a-1dd01f30624c,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-9eead409-08d7-4e51-a190-a57f7bd93be7,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-5fbb651e-2361-4ebb-a3d0-f30583308b96,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-2c412646-d0ed-4253-849b-f63da0c96273,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-4a6da69d-34b3-4b32-ba05-08906ea689a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-b35965dc-e0e1-4d23-ba87-6f66e5b0acb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1927880980-172.17.0.2-1597739022697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40796,DS-3a330f1d-8336-49b4-a0ff-833eda796c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-4c67de04-0499-4eee-89d4-30cf72446f47,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-107b881e-e97b-4d80-81b1-ee726fb80089,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-9e1aacc4-180d-46a9-b493-4d4bf380113a,DISK], DatanodeInfoWithStorage[127.0.0.1:35468,DS-23bd67b4-a2c1-4c41-ba49-5e1bf636e335,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-e3eebcc2-275e-4c98-9771-8d9e475ba36a,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-b5f18346-aeab-4fb1-a4ed-dac19af77d47,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-9d7502f3-85aa-400c-a3c5-7d7760bfb241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1927880980-172.17.0.2-1597739022697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40796,DS-3a330f1d-8336-49b4-a0ff-833eda796c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-4c67de04-0499-4eee-89d4-30cf72446f47,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-107b881e-e97b-4d80-81b1-ee726fb80089,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-9e1aacc4-180d-46a9-b493-4d4bf380113a,DISK], DatanodeInfoWithStorage[127.0.0.1:35468,DS-23bd67b4-a2c1-4c41-ba49-5e1bf636e335,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-e3eebcc2-275e-4c98-9771-8d9e475ba36a,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-b5f18346-aeab-4fb1-a4ed-dac19af77d47,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-9d7502f3-85aa-400c-a3c5-7d7760bfb241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-432642359-172.17.0.2-1597739411749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36994,DS-905c2d71-3881-40f8-abf7-ddae43802b30,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-eb99f23b-7239-4b17-acac-370c475da57f,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-e228091f-3a19-42f1-9e4d-981b539d57c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-f6ff11af-0eaf-49f9-9584-079c6514072d,DISK], DatanodeInfoWithStorage[127.0.0.1:43896,DS-41d62627-56aa-4de4-b9f4-0590f106516d,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-4e4063d8-06a1-4a61-998f-2708c94956be,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-b375c189-be20-4e40-b8fb-89350bd6052e,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-ab87c1a0-b359-460f-8b42-a6c1b9dd1d91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-432642359-172.17.0.2-1597739411749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36994,DS-905c2d71-3881-40f8-abf7-ddae43802b30,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-eb99f23b-7239-4b17-acac-370c475da57f,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-e228091f-3a19-42f1-9e4d-981b539d57c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-f6ff11af-0eaf-49f9-9584-079c6514072d,DISK], DatanodeInfoWithStorage[127.0.0.1:43896,DS-41d62627-56aa-4de4-b9f4-0590f106516d,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-4e4063d8-06a1-4a61-998f-2708c94956be,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-b375c189-be20-4e40-b8fb-89350bd6052e,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-ab87c1a0-b359-460f-8b42-a6c1b9dd1d91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-197394285-172.17.0.2-1597739506505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35956,DS-66c15185-9bdf-4648-9731-526bd93f4d00,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-5604c5cb-5f82-4f22-b33e-4816a6ebfbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-676496ea-b076-4206-978a-aa2ffa1c0cef,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-33b1cda1-243d-4227-946d-c8045e9ecab0,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-854bc0bc-76c5-40d8-9694-9ffb465e08db,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-37bba8d1-96b2-4884-833e-8ad043e6a8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-834b5a8f-852e-434f-8d56-6d9a4a55d6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-a3ad7448-e1e8-41ad-a877-5a28f62bb35b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-197394285-172.17.0.2-1597739506505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35956,DS-66c15185-9bdf-4648-9731-526bd93f4d00,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-5604c5cb-5f82-4f22-b33e-4816a6ebfbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-676496ea-b076-4206-978a-aa2ffa1c0cef,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-33b1cda1-243d-4227-946d-c8045e9ecab0,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-854bc0bc-76c5-40d8-9694-9ffb465e08db,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-37bba8d1-96b2-4884-833e-8ad043e6a8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-834b5a8f-852e-434f-8d56-6d9a4a55d6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-a3ad7448-e1e8-41ad-a877-5a28f62bb35b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-950809036-172.17.0.2-1597739821409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44239,DS-d71d38de-dc84-4ac7-afa1-bf00462575d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-9a003149-08b6-462c-891e-78c0a82f0495,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-42f31cfd-730d-4424-8d38-209fddd55164,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-4a0ac9a7-0353-4e77-8ddb-caca4bebf782,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-9ae7cf10-1364-4a39-a8d9-b07e52c02872,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-051aa5da-e8b6-4d24-b02d-946003cae8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-73647b6f-4c5c-4be1-9218-dde2fc12ce9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-a248db8c-3e58-4b41-b987-3cc99d72dd9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-950809036-172.17.0.2-1597739821409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44239,DS-d71d38de-dc84-4ac7-afa1-bf00462575d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-9a003149-08b6-462c-891e-78c0a82f0495,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-42f31cfd-730d-4424-8d38-209fddd55164,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-4a0ac9a7-0353-4e77-8ddb-caca4bebf782,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-9ae7cf10-1364-4a39-a8d9-b07e52c02872,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-051aa5da-e8b6-4d24-b02d-946003cae8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-73647b6f-4c5c-4be1-9218-dde2fc12ce9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-a248db8c-3e58-4b41-b987-3cc99d72dd9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-858243798-172.17.0.2-1597740241944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45985,DS-09021a3a-8011-4b82-a456-2686736e614e,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-27dbb0b1-7e9e-4505-bf37-11fe7df02a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-22211675-f778-4aca-afef-df7d16dbee1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-e493d9c3-91ff-463a-914d-535b9b5eae53,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-4a3fc975-be0d-4e59-8d55-2c991b1e419c,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-c44c945b-cdcf-4b02-beb1-e8239df83fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-760df73f-f18d-4f35-973f-a620fb3d19d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-456f67a1-cedf-48c7-a230-28ac41317366,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-858243798-172.17.0.2-1597740241944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45985,DS-09021a3a-8011-4b82-a456-2686736e614e,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-27dbb0b1-7e9e-4505-bf37-11fe7df02a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-22211675-f778-4aca-afef-df7d16dbee1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-e493d9c3-91ff-463a-914d-535b9b5eae53,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-4a3fc975-be0d-4e59-8d55-2c991b1e419c,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-c44c945b-cdcf-4b02-beb1-e8239df83fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-760df73f-f18d-4f35-973f-a620fb3d19d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-456f67a1-cedf-48c7-a230-28ac41317366,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1253266494-172.17.0.2-1597740571379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34236,DS-1e52459b-0297-4ca6-90c7-33e587dfb748,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-b1bbf5b8-75c3-4f9a-9a46-30e71f934bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-3fd0b992-dc6e-4108-8468-3730e3dfe5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-8ffbedf7-38d8-4289-b51e-4ca2f846e04b,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-7dd379f8-72b3-40c3-9a5d-f54f9e674cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-ff35759c-6296-4a3b-b110-39b9d027c080,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-3f069488-4aff-4332-ae9a-a0c7fbe004d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-3c3be302-edce-4f6a-9ef1-ce730e4c3765,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1253266494-172.17.0.2-1597740571379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34236,DS-1e52459b-0297-4ca6-90c7-33e587dfb748,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-b1bbf5b8-75c3-4f9a-9a46-30e71f934bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-3fd0b992-dc6e-4108-8468-3730e3dfe5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-8ffbedf7-38d8-4289-b51e-4ca2f846e04b,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-7dd379f8-72b3-40c3-9a5d-f54f9e674cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-ff35759c-6296-4a3b-b110-39b9d027c080,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-3f069488-4aff-4332-ae9a-a0c7fbe004d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-3c3be302-edce-4f6a-9ef1-ce730e4c3765,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2066460187-172.17.0.2-1597740660070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46229,DS-1b722981-aa67-4a42-94ce-548c94fe3f46,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-193c107f-28f4-4449-b120-56c697ede9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-a6e6223a-eee2-44c7-bd01-5fd157121696,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-5ab4e980-59db-4292-af70-6fddad4917be,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-34bd3c2c-e3b7-4bc0-b3be-b26407d37ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-ad573805-2dca-4199-84f7-0b5aca5fac89,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-11df6199-8b7b-4403-ba89-36bec11436aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-887f1832-41df-481c-bc4b-e20392a9e87f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2066460187-172.17.0.2-1597740660070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46229,DS-1b722981-aa67-4a42-94ce-548c94fe3f46,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-193c107f-28f4-4449-b120-56c697ede9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-a6e6223a-eee2-44c7-bd01-5fd157121696,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-5ab4e980-59db-4292-af70-6fddad4917be,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-34bd3c2c-e3b7-4bc0-b3be-b26407d37ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-ad573805-2dca-4199-84f7-0b5aca5fac89,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-11df6199-8b7b-4403-ba89-36bec11436aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-887f1832-41df-481c-bc4b-e20392a9e87f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-451349755-172.17.0.2-1597740708495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39039,DS-74592235-be4e-4cad-bc8e-e678b596461b,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-c133ad89-df37-403c-bf1a-39e3314e6fce,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-99043ffa-a516-498f-ac4b-7a012e1e1eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-22ad378c-9167-4fde-8d38-6fb8ca3c94ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-ce2a12e1-b0ed-4e80-b2d3-791b7c3acfef,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-2bed4e76-d663-4692-9ba8-f65910524c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-fc8982c9-918e-4c3b-a1bb-27657157bbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-f4b650e0-c601-4ee7-8a2c-85af08a19e4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-451349755-172.17.0.2-1597740708495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39039,DS-74592235-be4e-4cad-bc8e-e678b596461b,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-c133ad89-df37-403c-bf1a-39e3314e6fce,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-99043ffa-a516-498f-ac4b-7a012e1e1eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-22ad378c-9167-4fde-8d38-6fb8ca3c94ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-ce2a12e1-b0ed-4e80-b2d3-791b7c3acfef,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-2bed4e76-d663-4692-9ba8-f65910524c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-fc8982c9-918e-4c3b-a1bb-27657157bbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-f4b650e0-c601-4ee7-8a2c-85af08a19e4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-781222395-172.17.0.2-1597741292601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41012,DS-7a96a671-3261-443b-b1db-42c4ca5871c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-1ed8d5c6-0306-4b83-a215-060d1ca313fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-3e1b054c-d3fc-4915-9f28-631feb371cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-917bfb18-6046-49c2-8000-6d47db85ebfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-71d424eb-6203-4753-9ac1-4298013e1724,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-537de440-948e-4a58-9bce-2a0dd48bba34,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-04a06f79-f3c3-4184-90b8-2e50b3f5eeda,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-cc54d57e-1ebe-4833-90a2-170f2fb65c42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-781222395-172.17.0.2-1597741292601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41012,DS-7a96a671-3261-443b-b1db-42c4ca5871c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-1ed8d5c6-0306-4b83-a215-060d1ca313fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-3e1b054c-d3fc-4915-9f28-631feb371cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-917bfb18-6046-49c2-8000-6d47db85ebfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-71d424eb-6203-4753-9ac1-4298013e1724,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-537de440-948e-4a58-9bce-2a0dd48bba34,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-04a06f79-f3c3-4184-90b8-2e50b3f5eeda,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-cc54d57e-1ebe-4833-90a2-170f2fb65c42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-233868953-172.17.0.2-1597741667807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33157,DS-ebea43a3-51d7-4e92-a01a-5fdb386e6f75,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-19fcdcae-7de3-459c-b76f-a34f9fdd3b68,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-b7d45da8-ab63-4e93-a8c2-01324696dec5,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-6faa67e5-20b4-4503-8d32-2c0ab32ced24,DISK], DatanodeInfoWithStorage[127.0.0.1:35980,DS-ddc33d63-7908-492e-8f40-30d44625b077,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-dc24c1da-204a-4a65-99b4-102a8ac87ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-e90fb289-0710-4b63-ae2d-5d7734befb85,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-fc7affb7-d6a9-4fdf-b05a-910667c022ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-233868953-172.17.0.2-1597741667807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33157,DS-ebea43a3-51d7-4e92-a01a-5fdb386e6f75,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-19fcdcae-7de3-459c-b76f-a34f9fdd3b68,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-b7d45da8-ab63-4e93-a8c2-01324696dec5,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-6faa67e5-20b4-4503-8d32-2c0ab32ced24,DISK], DatanodeInfoWithStorage[127.0.0.1:35980,DS-ddc33d63-7908-492e-8f40-30d44625b077,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-dc24c1da-204a-4a65-99b4-102a8ac87ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-e90fb289-0710-4b63-ae2d-5d7734befb85,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-fc7affb7-d6a9-4fdf-b05a-910667c022ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: might be true error
Total execution time in seconds : 6929
