reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1067309962-172.17.0.11-1597483828245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34712,DS-b797db80-5b18-47ea-8031-51b32512f034,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-15d26f35-f726-4914-879b-555bd4f325d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-c57af4f4-2825-4072-aa51-7048860f5c27,DISK], DatanodeInfoWithStorage[127.0.0.1:35026,DS-a66d72c2-04c5-42f4-9a5a-fbd702463259,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-6bacfca4-851a-4e4c-83fd-fa727cbab5de,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-531da6c0-ef33-416a-8888-764ed49cf778,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-140c12cd-2dd6-4060-b45b-dc6d29005ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-be024ba3-974b-43a0-b6da-6bd1df0d83cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1067309962-172.17.0.11-1597483828245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34712,DS-b797db80-5b18-47ea-8031-51b32512f034,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-15d26f35-f726-4914-879b-555bd4f325d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-c57af4f4-2825-4072-aa51-7048860f5c27,DISK], DatanodeInfoWithStorage[127.0.0.1:35026,DS-a66d72c2-04c5-42f4-9a5a-fbd702463259,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-6bacfca4-851a-4e4c-83fd-fa727cbab5de,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-531da6c0-ef33-416a-8888-764ed49cf778,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-140c12cd-2dd6-4060-b45b-dc6d29005ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-be024ba3-974b-43a0-b6da-6bd1df0d83cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1235182802-172.17.0.11-1597484129756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43327,DS-a2328abf-9e88-4e7e-8bb4-7853ad85e687,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-720923aa-eff6-4e49-9d2b-81ffe93e4733,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-f706a555-1fdd-4638-9493-5e9a00b2a5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-b4909287-a668-4b74-8060-b4a581271a64,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-8aca1f8a-797f-4316-aaec-bc2d1fc49bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-a64d3e90-d6e0-43fe-8972-a795cfcd8cde,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-ec77d98f-0336-426b-8c30-86c7d37b7500,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-4f79649e-e5f8-4d82-a1c3-c954c85e2a59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1235182802-172.17.0.11-1597484129756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43327,DS-a2328abf-9e88-4e7e-8bb4-7853ad85e687,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-720923aa-eff6-4e49-9d2b-81ffe93e4733,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-f706a555-1fdd-4638-9493-5e9a00b2a5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-b4909287-a668-4b74-8060-b4a581271a64,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-8aca1f8a-797f-4316-aaec-bc2d1fc49bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-a64d3e90-d6e0-43fe-8972-a795cfcd8cde,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-ec77d98f-0336-426b-8c30-86c7d37b7500,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-4f79649e-e5f8-4d82-a1c3-c954c85e2a59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-326236585-172.17.0.11-1597484205842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33348,DS-f59af6c3-cd0a-4e4e-a420-5b1d8d4971b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-03925513-149b-4dfb-8572-3c84da215cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-a03dcd93-5838-4b80-8ca7-22bb21db18d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-713c0b71-da34-41a7-a642-31b5d40b47f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-9c7b5b0a-806c-428d-a665-4997705f2245,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-987973d4-75e6-482e-bcae-d6f41b366011,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-ea51cec7-84f8-486e-80c5-c48beb4b849c,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-8b2b68c7-5069-4206-8062-518771d4245d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-326236585-172.17.0.11-1597484205842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33348,DS-f59af6c3-cd0a-4e4e-a420-5b1d8d4971b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-03925513-149b-4dfb-8572-3c84da215cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-a03dcd93-5838-4b80-8ca7-22bb21db18d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-713c0b71-da34-41a7-a642-31b5d40b47f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-9c7b5b0a-806c-428d-a665-4997705f2245,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-987973d4-75e6-482e-bcae-d6f41b366011,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-ea51cec7-84f8-486e-80c5-c48beb4b849c,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-8b2b68c7-5069-4206-8062-518771d4245d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1730930049-172.17.0.11-1597484954632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46144,DS-55ad8cc5-028e-4164-866a-d11acf596f42,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-c74bdf16-ccf5-475d-be79-cc9f23df9d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-52c74bca-05d0-4ebf-a922-46e0556bdc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-07166032-df10-4c60-934c-ae663cfcafbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-7568718b-3a84-47b0-a0f4-3007773a4fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-743cc54e-084a-4ffe-8225-ab2f4808ec43,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-311c5307-893c-4b8c-9307-9b761c552093,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-323077be-e2e0-4430-892c-8e045ce390b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1730930049-172.17.0.11-1597484954632:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46144,DS-55ad8cc5-028e-4164-866a-d11acf596f42,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-c74bdf16-ccf5-475d-be79-cc9f23df9d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-52c74bca-05d0-4ebf-a922-46e0556bdc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-07166032-df10-4c60-934c-ae663cfcafbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-7568718b-3a84-47b0-a0f4-3007773a4fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-743cc54e-084a-4ffe-8225-ab2f4808ec43,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-311c5307-893c-4b8c-9307-9b761c552093,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-323077be-e2e0-4430-892c-8e045ce390b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-306948621-172.17.0.11-1597485092499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42087,DS-fa4490f1-c196-4485-883b-afb59076a8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-9af80972-8a27-4182-80a2-2764c2b1e977,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-1e8baa74-ca11-4c2c-afe9-3286e9f5c050,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-a28cba97-20a8-45d7-9df0-1247c4c03756,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-1e25cbfe-99c7-4859-81c3-ee4419fc4ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-7ca9d61b-eda9-434d-8ad0-0d2688e6b563,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-e8934bc0-f753-4498-b8e9-0d90631d20cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-afc37b95-84ee-4ccc-a43a-99a2cfa7b2cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-306948621-172.17.0.11-1597485092499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42087,DS-fa4490f1-c196-4485-883b-afb59076a8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-9af80972-8a27-4182-80a2-2764c2b1e977,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-1e8baa74-ca11-4c2c-afe9-3286e9f5c050,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-a28cba97-20a8-45d7-9df0-1247c4c03756,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-1e25cbfe-99c7-4859-81c3-ee4419fc4ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-7ca9d61b-eda9-434d-8ad0-0d2688e6b563,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-e8934bc0-f753-4498-b8e9-0d90631d20cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-afc37b95-84ee-4ccc-a43a-99a2cfa7b2cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1049089211-172.17.0.11-1597485330099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37912,DS-85e2f2f1-91e7-4d29-b5d4-1efe5666e121,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-56565d48-8378-4961-9992-b5ac994b0d77,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-ff9b8702-ad4a-46aa-817a-93342a28f5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-90c7e054-866c-4808-81ee-fc6f0f02af67,DISK], DatanodeInfoWithStorage[127.0.0.1:41295,DS-c51ad4ad-739e-4788-9ab7-df22dd33e5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-66b071bc-0121-40d3-80c7-bf79d13e5343,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-afbb9c03-b13a-4e03-a2a7-71835fddfe5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-c53cbb45-c9db-4ae3-9415-b30b2ec82c4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1049089211-172.17.0.11-1597485330099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37912,DS-85e2f2f1-91e7-4d29-b5d4-1efe5666e121,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-56565d48-8378-4961-9992-b5ac994b0d77,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-ff9b8702-ad4a-46aa-817a-93342a28f5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-90c7e054-866c-4808-81ee-fc6f0f02af67,DISK], DatanodeInfoWithStorage[127.0.0.1:41295,DS-c51ad4ad-739e-4788-9ab7-df22dd33e5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-66b071bc-0121-40d3-80c7-bf79d13e5343,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-afbb9c03-b13a-4e03-a2a7-71835fddfe5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-c53cbb45-c9db-4ae3-9415-b30b2ec82c4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-986313178-172.17.0.11-1597485855439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39333,DS-90a36ae5-94e2-498f-ad0c-408b3b1e5307,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-2acdbd3a-9b5e-4376-9994-b42072039d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-36f92f39-9237-4bbd-822b-9f9846f4db5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-0c0d142b-4e06-4df2-99cf-1c0bb83b3dad,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-e1590cd0-3203-476a-9672-0d852e58b380,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-3e9bb9fc-cd97-469e-b4f7-0fa9701a9fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:40722,DS-7315d793-95b5-4342-ab40-7d3f3c63f6af,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-829376a4-a766-4c79-bd00-9f8daae1b296,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-986313178-172.17.0.11-1597485855439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39333,DS-90a36ae5-94e2-498f-ad0c-408b3b1e5307,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-2acdbd3a-9b5e-4376-9994-b42072039d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-36f92f39-9237-4bbd-822b-9f9846f4db5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-0c0d142b-4e06-4df2-99cf-1c0bb83b3dad,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-e1590cd0-3203-476a-9672-0d852e58b380,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-3e9bb9fc-cd97-469e-b4f7-0fa9701a9fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:40722,DS-7315d793-95b5-4342-ab40-7d3f3c63f6af,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-829376a4-a766-4c79-bd00-9f8daae1b296,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-72595822-172.17.0.11-1597486327204:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41131,DS-c01728aa-dbbe-4262-8143-c989fa2f13df,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-2946bb02-83ca-4450-accc-5ee82c2ed5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-6d466691-7957-429b-970f-64e00cead456,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-1c0b840e-7cc3-4931-afc1-419c2876de13,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-f071481c-58c6-4402-b0cb-bb48f404385b,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-0752a758-b820-4d42-8428-289f17d9e26b,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-f6c924cf-4a2b-444e-9bdf-76daece6aaea,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-19d9eea9-f919-4e46-8808-1714c25e3e67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-72595822-172.17.0.11-1597486327204:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41131,DS-c01728aa-dbbe-4262-8143-c989fa2f13df,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-2946bb02-83ca-4450-accc-5ee82c2ed5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-6d466691-7957-429b-970f-64e00cead456,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-1c0b840e-7cc3-4931-afc1-419c2876de13,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-f071481c-58c6-4402-b0cb-bb48f404385b,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-0752a758-b820-4d42-8428-289f17d9e26b,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-f6c924cf-4a2b-444e-9bdf-76daece6aaea,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-19d9eea9-f919-4e46-8808-1714c25e3e67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-962080352-172.17.0.11-1597487221242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42710,DS-3091f9aa-7739-4cce-ae84-036eb2342a91,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-73a4e59d-ffd4-45ec-8f51-7caa5740b8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-b5348d14-8f50-4e32-beb3-39d2d370ec52,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-2fe5396a-767a-4ffc-a431-7fbefb1f99b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-cfb8da79-8ae2-451a-8878-cf470f88227a,DISK], DatanodeInfoWithStorage[127.0.0.1:41518,DS-0979f8ba-2670-4791-a949-2dd16192860e,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-fee5583a-2e31-46b3-bd2a-9045b0455ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-2c5eeb32-0196-4228-a6f9-1fc2e9a8468a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-962080352-172.17.0.11-1597487221242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42710,DS-3091f9aa-7739-4cce-ae84-036eb2342a91,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-73a4e59d-ffd4-45ec-8f51-7caa5740b8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40201,DS-b5348d14-8f50-4e32-beb3-39d2d370ec52,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-2fe5396a-767a-4ffc-a431-7fbefb1f99b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-cfb8da79-8ae2-451a-8878-cf470f88227a,DISK], DatanodeInfoWithStorage[127.0.0.1:41518,DS-0979f8ba-2670-4791-a949-2dd16192860e,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-fee5583a-2e31-46b3-bd2a-9045b0455ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-2c5eeb32-0196-4228-a6f9-1fc2e9a8468a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1365782267-172.17.0.11-1597487955634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39601,DS-9c759f30-f1f7-4586-84ef-6dec10c69536,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-a0de8930-99a3-4693-8973-c9f1c868dd71,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-85070582-e750-4633-ab8c-26c754375c30,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-793861bf-3df7-4827-8c7a-d181b1f12139,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-a82da961-444a-4aba-abbd-44d1bb37c4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-b4c3cd62-c334-413e-846e-6f1ccc18b1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-2cfcb180-59b9-42d9-bcd8-e3790f6960ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-b768c824-a184-4710-b85b-93865194ed25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1365782267-172.17.0.11-1597487955634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39601,DS-9c759f30-f1f7-4586-84ef-6dec10c69536,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-a0de8930-99a3-4693-8973-c9f1c868dd71,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-85070582-e750-4633-ab8c-26c754375c30,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-793861bf-3df7-4827-8c7a-d181b1f12139,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-a82da961-444a-4aba-abbd-44d1bb37c4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-b4c3cd62-c334-413e-846e-6f1ccc18b1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-2cfcb180-59b9-42d9-bcd8-e3790f6960ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-b768c824-a184-4710-b85b-93865194ed25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-552438571-172.17.0.11-1597488026490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34925,DS-d1266f38-3b18-4b9b-8ffd-c92353792270,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-44daad34-f067-4ab2-905e-e2efe4cb8fec,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-31608e51-cbbb-4322-a80b-f34e13dbaaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:42591,DS-f5c32620-e8cb-4b47-b53c-433f6b025862,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-237e4fdd-cd21-41bc-a09a-c478c5c2aed0,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-aeb20930-b2de-4f13-9875-5fb8f96bb3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-86f31dae-17ea-4456-b660-8328b1d3b488,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-18f4cd92-74a6-45f3-8ef1-1c7706307436,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-552438571-172.17.0.11-1597488026490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34925,DS-d1266f38-3b18-4b9b-8ffd-c92353792270,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-44daad34-f067-4ab2-905e-e2efe4cb8fec,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-31608e51-cbbb-4322-a80b-f34e13dbaaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:42591,DS-f5c32620-e8cb-4b47-b53c-433f6b025862,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-237e4fdd-cd21-41bc-a09a-c478c5c2aed0,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-aeb20930-b2de-4f13-9875-5fb8f96bb3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-86f31dae-17ea-4456-b660-8328b1d3b488,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-18f4cd92-74a6-45f3-8ef1-1c7706307436,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1176748437-172.17.0.11-1597488064746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37336,DS-8194b629-7c3a-4b2c-9a02-5bea8dea7138,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-326f90ef-090a-4138-8196-53d43cbd6ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-21b07984-3b75-4b52-a232-a6e60fd78140,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-dca68ca6-4e1a-4db7-a7f5-d3a0d830f5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-1409bf64-54e7-428b-85dd-a48eda4c396a,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-ebe74652-0a5b-426a-94ed-83e86761520c,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-f7347976-c11b-48ea-ab95-274f381a8174,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-a24805f4-d761-4087-be71-4298e2b9ac23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1176748437-172.17.0.11-1597488064746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37336,DS-8194b629-7c3a-4b2c-9a02-5bea8dea7138,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-326f90ef-090a-4138-8196-53d43cbd6ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-21b07984-3b75-4b52-a232-a6e60fd78140,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-dca68ca6-4e1a-4db7-a7f5-d3a0d830f5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-1409bf64-54e7-428b-85dd-a48eda4c396a,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-ebe74652-0a5b-426a-94ed-83e86761520c,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-f7347976-c11b-48ea-ab95-274f381a8174,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-a24805f4-d761-4087-be71-4298e2b9ac23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1825228233-172.17.0.11-1597488200464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44641,DS-135f0f3d-fe16-4766-9672-5bb23ede7e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-a7f0de81-9071-4e9c-bee3-97453b9adf99,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-b5a81601-31fc-4e0c-a898-0008418e6a53,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-7ffe1127-3304-41a1-936c-3613a1db06fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-0e1e921f-f0ba-404e-a41c-adb900a17fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-334c4ea5-2098-4a25-ba63-6e417d1ffafa,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-9d652ead-54fb-4f3d-8437-8560c76de0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-753d0710-129c-4ffa-a316-e113a40f27cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1825228233-172.17.0.11-1597488200464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44641,DS-135f0f3d-fe16-4766-9672-5bb23ede7e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-a7f0de81-9071-4e9c-bee3-97453b9adf99,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-b5a81601-31fc-4e0c-a898-0008418e6a53,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-7ffe1127-3304-41a1-936c-3613a1db06fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-0e1e921f-f0ba-404e-a41c-adb900a17fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-334c4ea5-2098-4a25-ba63-6e417d1ffafa,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-9d652ead-54fb-4f3d-8437-8560c76de0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-753d0710-129c-4ffa-a316-e113a40f27cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2128337914-172.17.0.11-1597488646532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44630,DS-344cd355-4c44-4f28-a4c3-da1209083105,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-4e5b09c2-1c25-4e36-9358-c7a7471200a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-396804bb-0cd0-4a19-b770-4396da300176,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-838c6a5f-a9d9-400f-81cc-936874ace945,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-317d535c-1a1e-4abe-aca5-4279873a678e,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-c31b2452-cb73-4c09-aeef-8d6d7878d0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-88ef705a-53cf-4657-bb31-dc6e10502468,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-56b2a581-f27f-483b-ba6a-a4cc9249218d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2128337914-172.17.0.11-1597488646532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44630,DS-344cd355-4c44-4f28-a4c3-da1209083105,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-4e5b09c2-1c25-4e36-9358-c7a7471200a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-396804bb-0cd0-4a19-b770-4396da300176,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-838c6a5f-a9d9-400f-81cc-936874ace945,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-317d535c-1a1e-4abe-aca5-4279873a678e,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-c31b2452-cb73-4c09-aeef-8d6d7878d0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-88ef705a-53cf-4657-bb31-dc6e10502468,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-56b2a581-f27f-483b-ba6a-a4cc9249218d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1767330039-172.17.0.11-1597488684520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42637,DS-a1251db4-19b3-4878-a942-3bbae9692caa,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-e5eb6485-b21b-4c8a-84c9-0424e6e63234,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-2b717dec-6ab6-4c41-90dc-e4122d62b2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-2c78ad23-0aa8-4963-95cf-68aff71653d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-8a1747df-1877-4f16-8e88-db2ad459f5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-6807d216-d397-412a-a9e6-2a38cf541bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-282eacae-dea7-4382-8a7e-5dd151f3caf4,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-1cd77f03-a699-4046-a8e2-31df11a85bcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1767330039-172.17.0.11-1597488684520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42637,DS-a1251db4-19b3-4878-a942-3bbae9692caa,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-e5eb6485-b21b-4c8a-84c9-0424e6e63234,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-2b717dec-6ab6-4c41-90dc-e4122d62b2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-2c78ad23-0aa8-4963-95cf-68aff71653d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-8a1747df-1877-4f16-8e88-db2ad459f5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-6807d216-d397-412a-a9e6-2a38cf541bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-282eacae-dea7-4382-8a7e-5dd151f3caf4,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-1cd77f03-a699-4046-a8e2-31df11a85bcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5509
