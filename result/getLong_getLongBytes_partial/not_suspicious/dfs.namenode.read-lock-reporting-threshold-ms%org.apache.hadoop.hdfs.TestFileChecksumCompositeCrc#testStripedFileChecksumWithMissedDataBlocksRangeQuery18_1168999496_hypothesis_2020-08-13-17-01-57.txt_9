reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1765193691-172.17.0.19-1597338136610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33454,DS-993053ef-55f7-4d59-8943-baca0db8504f,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-b1589696-25be-44ec-b6ea-7f7ff6973cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-af8c0448-c480-498b-bc85-a233f9816a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-f7c25de9-1f5a-46f2-803b-877dfb3d9ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-9ef90a91-fc41-4382-a136-39fefaaca041,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-2bad8b82-7562-442c-917e-8caa16b45802,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-1581a994-1b69-4ce9-be5f-4536a48f65e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-22409a49-c8a1-446f-bcb9-852db7c74219,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1765193691-172.17.0.19-1597338136610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33454,DS-993053ef-55f7-4d59-8943-baca0db8504f,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-b1589696-25be-44ec-b6ea-7f7ff6973cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-af8c0448-c480-498b-bc85-a233f9816a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-f7c25de9-1f5a-46f2-803b-877dfb3d9ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-9ef90a91-fc41-4382-a136-39fefaaca041,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-2bad8b82-7562-442c-917e-8caa16b45802,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-1581a994-1b69-4ce9-be5f-4536a48f65e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-22409a49-c8a1-446f-bcb9-852db7c74219,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1650795999-172.17.0.19-1597338414041:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43998,DS-dab068f7-cf84-4eef-baf9-a5363cb865d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-b2f9d555-92e7-4c9a-ac31-b272bd154c24,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-c6329e79-67d2-4742-9028-3cea4db3d687,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-27d4386e-bab2-42e1-bcb9-eb81417211b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-973ab4ac-977f-4451-a91e-e658180f589b,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-69cd15d8-7acc-4dd7-9f08-7c300dd8c250,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-42928573-6ac4-4b4f-9073-bfc1a23239a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-b6eb9dc7-2e60-46e6-8dd5-81ea17c70f80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1650795999-172.17.0.19-1597338414041:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43998,DS-dab068f7-cf84-4eef-baf9-a5363cb865d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-b2f9d555-92e7-4c9a-ac31-b272bd154c24,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-c6329e79-67d2-4742-9028-3cea4db3d687,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-27d4386e-bab2-42e1-bcb9-eb81417211b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-973ab4ac-977f-4451-a91e-e658180f589b,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-69cd15d8-7acc-4dd7-9f08-7c300dd8c250,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-42928573-6ac4-4b4f-9073-bfc1a23239a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-b6eb9dc7-2e60-46e6-8dd5-81ea17c70f80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-602103643-172.17.0.19-1597338604714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34864,DS-97f26c5f-6763-4d93-90e1-dda13ee6853e,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-4bd008cb-f855-4c7e-a9d8-936150fb4fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-d21dea7e-6eb1-4e1c-acab-73fe24cfaa80,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-05c7651a-ae9c-4205-ae71-89b52187b838,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-9cb8f0c0-5829-4978-af88-3658f56a796e,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-26f6a88a-397c-4ec1-9e05-e920b122c726,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-58b8949a-81e2-439f-9ec4-2bbaf3b5f773,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-d849cb42-bf82-4055-94f1-001156bfced2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-602103643-172.17.0.19-1597338604714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34864,DS-97f26c5f-6763-4d93-90e1-dda13ee6853e,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-4bd008cb-f855-4c7e-a9d8-936150fb4fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-d21dea7e-6eb1-4e1c-acab-73fe24cfaa80,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-05c7651a-ae9c-4205-ae71-89b52187b838,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-9cb8f0c0-5829-4978-af88-3658f56a796e,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-26f6a88a-397c-4ec1-9e05-e920b122c726,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-58b8949a-81e2-439f-9ec4-2bbaf3b5f773,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-d849cb42-bf82-4055-94f1-001156bfced2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1964578111-172.17.0.19-1597339164994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34550,DS-fba7e978-a1c7-4175-a9a3-311ea1540df3,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-a9a13d5e-0e38-445b-98f3-8a50843dd16d,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-b103ba70-028f-436b-94b5-2f4c10a98e25,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-476f9562-3aca-4883-a1c4-e388f622272b,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-34eed681-f561-4d6f-a463-be7c23a15c36,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-a9518865-e48c-4fda-a61a-35adbc1986cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-00c8413b-d188-429e-8537-ccde7bf204e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-33623fba-131a-4506-a3a5-7b84ccd3480b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1964578111-172.17.0.19-1597339164994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34550,DS-fba7e978-a1c7-4175-a9a3-311ea1540df3,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-a9a13d5e-0e38-445b-98f3-8a50843dd16d,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-b103ba70-028f-436b-94b5-2f4c10a98e25,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-476f9562-3aca-4883-a1c4-e388f622272b,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-34eed681-f561-4d6f-a463-be7c23a15c36,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-a9518865-e48c-4fda-a61a-35adbc1986cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-00c8413b-d188-429e-8537-ccde7bf204e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-33623fba-131a-4506-a3a5-7b84ccd3480b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-285302279-172.17.0.19-1597339548981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32781,DS-6e14ccb0-716f-47cf-b3cb-ffd38eaff6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-1871ab0d-a91c-4a0d-987b-f1618327595c,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-0ad4347c-dac0-4b84-8955-fea4c897ff19,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-6bfa397e-8c64-490a-87d5-a574f7bb7f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-cf70f2b1-6d71-4dda-bdd4-c8be7bd31bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-c3310945-6ea3-45c9-bf59-74c8149a7ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-3fa166ed-63da-49eb-a5ad-b165251761f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-af026545-6682-495a-8bc2-f92115a519cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-285302279-172.17.0.19-1597339548981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32781,DS-6e14ccb0-716f-47cf-b3cb-ffd38eaff6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-1871ab0d-a91c-4a0d-987b-f1618327595c,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-0ad4347c-dac0-4b84-8955-fea4c897ff19,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-6bfa397e-8c64-490a-87d5-a574f7bb7f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-cf70f2b1-6d71-4dda-bdd4-c8be7bd31bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-c3310945-6ea3-45c9-bf59-74c8149a7ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-3fa166ed-63da-49eb-a5ad-b165251761f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-af026545-6682-495a-8bc2-f92115a519cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1593101709-172.17.0.19-1597339646236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42619,DS-56907f7c-f193-493f-bc36-aa81a4bfba6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-f58eb71d-6721-4332-a6af-78262c24c4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-1c705108-ab11-4697-b8bf-f8bc969ea3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-0643d0e7-292e-44b9-82c0-b341c7c77aec,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-11d4cfa9-9e56-46b0-afca-d34ac6c4a653,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-4d0c0b6a-1a36-4440-b9ba-9c95c5a3bc09,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-0e6e9a30-632d-4f10-ba14-ffcc839ee99f,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-c3c70a78-2be4-4bb1-b98a-0b2fc6e9032f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1593101709-172.17.0.19-1597339646236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42619,DS-56907f7c-f193-493f-bc36-aa81a4bfba6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-f58eb71d-6721-4332-a6af-78262c24c4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-1c705108-ab11-4697-b8bf-f8bc969ea3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-0643d0e7-292e-44b9-82c0-b341c7c77aec,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-11d4cfa9-9e56-46b0-afca-d34ac6c4a653,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-4d0c0b6a-1a36-4440-b9ba-9c95c5a3bc09,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-0e6e9a30-632d-4f10-ba14-ffcc839ee99f,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-c3c70a78-2be4-4bb1-b98a-0b2fc6e9032f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-792922799-172.17.0.19-1597341205180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39841,DS-d8cf32df-22c9-4c86-b105-ba3da21164ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-36b9b9f1-88ab-4efd-9cda-70eba53a8e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35823,DS-cd2d1e70-7cf2-4cfc-8dff-9eb1e636a95d,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-dd26fd39-057a-4cca-9827-8ef3277382ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-70db8e53-3a56-47da-8bee-68c4480e1fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-ea875fc7-9d74-4a0e-9688-b562d5c19596,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-aa4e586f-2e11-491c-8e36-c1bccfab0896,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-cefe7d74-56b3-4e18-96e7-756e9d925667,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-792922799-172.17.0.19-1597341205180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39841,DS-d8cf32df-22c9-4c86-b105-ba3da21164ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-36b9b9f1-88ab-4efd-9cda-70eba53a8e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35823,DS-cd2d1e70-7cf2-4cfc-8dff-9eb1e636a95d,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-dd26fd39-057a-4cca-9827-8ef3277382ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-70db8e53-3a56-47da-8bee-68c4480e1fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-ea875fc7-9d74-4a0e-9688-b562d5c19596,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-aa4e586f-2e11-491c-8e36-c1bccfab0896,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-cefe7d74-56b3-4e18-96e7-756e9d925667,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-142629688-172.17.0.19-1597341635171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45075,DS-b502c4c8-dc0c-4c31-9b5c-fbcd9dcd2e97,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-509a312d-b81c-41c8-8fe0-dc1440c5e7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-5c5f90b5-21c2-4721-b4a2-f88c7d4ba100,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-5d0df6a1-292f-46a8-a057-aab0139bc316,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-7bd21105-088e-4886-a4d6-0315d2ddeea2,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-1bf911b7-2706-453c-8338-d19543a243d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-0a96e16f-338e-4b17-8e1e-4e53160eee9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-ee83a0e5-5301-4468-9df3-51d9f9a69a10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-142629688-172.17.0.19-1597341635171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45075,DS-b502c4c8-dc0c-4c31-9b5c-fbcd9dcd2e97,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-509a312d-b81c-41c8-8fe0-dc1440c5e7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-5c5f90b5-21c2-4721-b4a2-f88c7d4ba100,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-5d0df6a1-292f-46a8-a057-aab0139bc316,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-7bd21105-088e-4886-a4d6-0315d2ddeea2,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-1bf911b7-2706-453c-8338-d19543a243d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-0a96e16f-338e-4b17-8e1e-4e53160eee9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-ee83a0e5-5301-4468-9df3-51d9f9a69a10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-126446283-172.17.0.19-1597342357404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44577,DS-a836b42f-20ec-44b7-acae-76c7056949a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-aeeec34a-5f29-49a9-82fd-574c0965c73b,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-224645e5-fbf3-4660-861c-78b09f1cd0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-25b6bc98-c80c-4b57-9883-5a1796bae20b,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-509b3009-5ff1-425d-98f2-ee87dffe224e,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-4ea4ae3e-e592-4293-a984-f2e3750c5f02,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-ded85051-e44b-494c-94f8-3e6bf5ac9898,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-af80cd40-a280-4a45-83fd-fbee5ea655af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-126446283-172.17.0.19-1597342357404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44577,DS-a836b42f-20ec-44b7-acae-76c7056949a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-aeeec34a-5f29-49a9-82fd-574c0965c73b,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-224645e5-fbf3-4660-861c-78b09f1cd0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-25b6bc98-c80c-4b57-9883-5a1796bae20b,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-509b3009-5ff1-425d-98f2-ee87dffe224e,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-4ea4ae3e-e592-4293-a984-f2e3750c5f02,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-ded85051-e44b-494c-94f8-3e6bf5ac9898,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-af80cd40-a280-4a45-83fd-fbee5ea655af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1794621960-172.17.0.19-1597342508435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35574,DS-56458d85-d486-4025-9744-b30fce55906d,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-d8e7c62e-c474-46ec-b052-696b2c4230e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-92f5a60e-d9b5-4e55-b686-efb5eb981f17,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-66a2fda8-d408-4f86-a0a1-746c2528850f,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-893e0c1d-a982-4250-bf5c-82aefe84b1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-21c45586-7c74-4502-801d-83ac5d755ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-7c04bb89-6726-4f1a-8a87-7fd4854b7eed,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-17529a0b-0c2c-4578-9592-d16092729964,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1794621960-172.17.0.19-1597342508435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35574,DS-56458d85-d486-4025-9744-b30fce55906d,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-d8e7c62e-c474-46ec-b052-696b2c4230e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-92f5a60e-d9b5-4e55-b686-efb5eb981f17,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-66a2fda8-d408-4f86-a0a1-746c2528850f,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-893e0c1d-a982-4250-bf5c-82aefe84b1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-21c45586-7c74-4502-801d-83ac5d755ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-7c04bb89-6726-4f1a-8a87-7fd4854b7eed,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-17529a0b-0c2c-4578-9592-d16092729964,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970756244-172.17.0.19-1597342802028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43742,DS-51d5f3b5-dd8d-4d5b-a5ea-1ea92f821731,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-22dc2200-0f8c-42c5-8a7e-8aee823f4850,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-0692de96-b452-494a-aa58-45e6806d2855,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-448e6be9-4a1f-42f3-9947-8648317130d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-64da2889-9354-4cd1-a2ca-db3d19f9e2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-f2f77a30-a8a8-46e0-8338-0408f1cce18a,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-440e12b1-1465-44d6-9e86-6244a64bff7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-84ee3a0f-8720-443d-af95-9f469e69ba9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970756244-172.17.0.19-1597342802028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43742,DS-51d5f3b5-dd8d-4d5b-a5ea-1ea92f821731,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-22dc2200-0f8c-42c5-8a7e-8aee823f4850,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-0692de96-b452-494a-aa58-45e6806d2855,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-448e6be9-4a1f-42f3-9947-8648317130d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-64da2889-9354-4cd1-a2ca-db3d19f9e2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-f2f77a30-a8a8-46e0-8338-0408f1cce18a,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-440e12b1-1465-44d6-9e86-6244a64bff7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-84ee3a0f-8720-443d-af95-9f469e69ba9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-501724243-172.17.0.19-1597343439306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43681,DS-85c91018-cd9f-4062-88d0-d89bacfa13ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-e5913549-dd15-4a78-ac97-c916bccee15e,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-e80b4c95-3ccc-49d0-bb1d-20271eb4bdd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-27a06345-a03a-47d7-9940-17caac806bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-d0058151-5a19-42e4-baae-517152dd817f,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-45566868-9086-4a17-9aba-b46e5d174ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-0f6f6ddd-255c-4710-ac21-26171f86db2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-1d73b0f2-a5b7-4949-8606-fe147e3848b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-501724243-172.17.0.19-1597343439306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43681,DS-85c91018-cd9f-4062-88d0-d89bacfa13ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-e5913549-dd15-4a78-ac97-c916bccee15e,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-e80b4c95-3ccc-49d0-bb1d-20271eb4bdd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-27a06345-a03a-47d7-9940-17caac806bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-d0058151-5a19-42e4-baae-517152dd817f,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-45566868-9086-4a17-9aba-b46e5d174ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-0f6f6ddd-255c-4710-ac21-26171f86db2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-1d73b0f2-a5b7-4949-8606-fe147e3848b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1824183130-172.17.0.19-1597343629465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38058,DS-6fb51a9e-4d0d-4225-8a4c-9ec4b4f00496,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-6b5e0d69-458b-4e1d-85cc-5875b82469fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-5374ecdb-c92b-4522-99e8-737c102285a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-8aa1083e-7d01-4aa4-9345-b7931207e8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-7322f591-4b2a-464a-8f41-710d3a65dd22,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-21913912-bfc1-4578-8ddc-cd84ac53fe32,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-a7d0c376-977f-4dd7-b8e2-432b1bbe87d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-d3bc9842-0dfb-421a-8ed6-655f91747255,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1824183130-172.17.0.19-1597343629465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38058,DS-6fb51a9e-4d0d-4225-8a4c-9ec4b4f00496,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-6b5e0d69-458b-4e1d-85cc-5875b82469fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-5374ecdb-c92b-4522-99e8-737c102285a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-8aa1083e-7d01-4aa4-9345-b7931207e8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-7322f591-4b2a-464a-8f41-710d3a65dd22,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-21913912-bfc1-4578-8ddc-cd84ac53fe32,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-a7d0c376-977f-4dd7-b8e2-432b1bbe87d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-d3bc9842-0dfb-421a-8ed6-655f91747255,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-989980566-172.17.0.19-1597343903113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34927,DS-d6498476-1c83-4dab-808a-1f8344e3936b,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-7d2d057c-9f55-4bf2-8732-c0863cd760a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-461c2788-5ba3-41d1-b559-d73277a2479c,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-2c7809e7-e50b-46bd-b919-2003febfa3be,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-e8b688a6-d5b4-48b9-b88f-5850e6f5cad8,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-192ff5b8-6ca4-4587-9aea-823ef8e96539,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-8273216e-39a6-40ed-8155-3d9f5007fb76,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-e70e6776-9a6e-4f6b-8606-58d6709f298e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-989980566-172.17.0.19-1597343903113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34927,DS-d6498476-1c83-4dab-808a-1f8344e3936b,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-7d2d057c-9f55-4bf2-8732-c0863cd760a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-461c2788-5ba3-41d1-b559-d73277a2479c,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-2c7809e7-e50b-46bd-b919-2003febfa3be,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-e8b688a6-d5b4-48b9-b88f-5850e6f5cad8,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-192ff5b8-6ca4-4587-9aea-823ef8e96539,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-8273216e-39a6-40ed-8155-3d9f5007fb76,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-e70e6776-9a6e-4f6b-8606-58d6709f298e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-788101380-172.17.0.19-1597344803450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40535,DS-4c27bc8a-cba0-4700-8937-5ab8f24fc5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-69206c43-631f-418c-8f9e-62ba74fbd016,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-ed7458e6-7672-47e1-9f44-f9e5fe76760f,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-10f7391b-3db8-42e2-abd8-f23141dc65da,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-2c473add-9dfa-4935-b982-df9db23e4676,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-6d289523-c672-4771-94c4-8198eb8a2c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-c9f31975-7090-4cbe-86a9-a85a3dea2939,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-b70162bc-88a5-419c-8b46-98ed84bbaef6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-788101380-172.17.0.19-1597344803450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40535,DS-4c27bc8a-cba0-4700-8937-5ab8f24fc5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-69206c43-631f-418c-8f9e-62ba74fbd016,DISK], DatanodeInfoWithStorage[127.0.0.1:45139,DS-ed7458e6-7672-47e1-9f44-f9e5fe76760f,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-10f7391b-3db8-42e2-abd8-f23141dc65da,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-2c473add-9dfa-4935-b982-df9db23e4676,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-6d289523-c672-4771-94c4-8198eb8a2c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-c9f31975-7090-4cbe-86a9-a85a3dea2939,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-b70162bc-88a5-419c-8b46-98ed84bbaef6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6990
