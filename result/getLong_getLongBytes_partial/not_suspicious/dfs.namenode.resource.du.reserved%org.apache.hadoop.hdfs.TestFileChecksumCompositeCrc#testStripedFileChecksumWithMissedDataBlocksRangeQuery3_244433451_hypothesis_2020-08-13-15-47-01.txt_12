reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1677721600
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1677721600
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1050348724-172.17.0.17-1597333834743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43009,DS-c464d5d0-9fdc-438b-8629-4d2067702a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-c849609f-6b43-4946-9719-352c0dadd4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-da130d91-fb71-45eb-b96b-ffa670c24a53,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-94f6de16-a7c0-467b-ad9f-3fea4c713801,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-d3383978-a9fe-4864-b62a-9af9a2e855a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-9c1d30e0-add9-4e20-887f-306b1256321c,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-84a4c056-a210-4755-a674-b46b45213339,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-36d6b333-936e-4b40-85ba-f57fa506a38d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1050348724-172.17.0.17-1597333834743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43009,DS-c464d5d0-9fdc-438b-8629-4d2067702a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-c849609f-6b43-4946-9719-352c0dadd4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-da130d91-fb71-45eb-b96b-ffa670c24a53,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-94f6de16-a7c0-467b-ad9f-3fea4c713801,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-d3383978-a9fe-4864-b62a-9af9a2e855a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-9c1d30e0-add9-4e20-887f-306b1256321c,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-84a4c056-a210-4755-a674-b46b45213339,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-36d6b333-936e-4b40-85ba-f57fa506a38d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1677721600
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-180093598-172.17.0.17-1597333908969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33553,DS-c34af33b-7efe-4d7c-ad45-5478422888ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-1c602586-cb90-40bc-abe6-9eec2a7de263,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-e8f06742-44a6-4e4e-bbf8-c419f4a52ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-0b31d671-6074-47cd-a1c6-7d97c869c504,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-7a47c2de-7666-4a2d-9590-89f49252f1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-44873df2-82c6-41c4-8889-5578908034e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-e570227e-8ace-4b02-a9cb-3c27d9b9fcf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-28abcac6-6070-46a9-b344-66da4201b226,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-180093598-172.17.0.17-1597333908969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33553,DS-c34af33b-7efe-4d7c-ad45-5478422888ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-1c602586-cb90-40bc-abe6-9eec2a7de263,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-e8f06742-44a6-4e4e-bbf8-c419f4a52ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-0b31d671-6074-47cd-a1c6-7d97c869c504,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-7a47c2de-7666-4a2d-9590-89f49252f1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-44873df2-82c6-41c4-8889-5578908034e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-e570227e-8ace-4b02-a9cb-3c27d9b9fcf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-28abcac6-6070-46a9-b344-66da4201b226,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1677721600
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2064785884-172.17.0.17-1597334104094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35664,DS-c9a83568-add1-4f7d-b271-a5943f510f48,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-1e7cf2c3-7a06-44f6-97bf-d46d5da0d8db,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-64d41e82-38f9-4d44-90ed-aa2b64712fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46505,DS-8b255df3-919b-419d-bd0c-590dcc0dbb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-309135ba-3afa-42bf-a205-b809e744be19,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-5645a356-5e46-44f3-9006-c2091a56ee00,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-13ac770a-f628-499a-9bed-6199f4a4ff68,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-98e0f314-bde3-44f2-a90c-ea2e69f09b99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2064785884-172.17.0.17-1597334104094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35664,DS-c9a83568-add1-4f7d-b271-a5943f510f48,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-1e7cf2c3-7a06-44f6-97bf-d46d5da0d8db,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-64d41e82-38f9-4d44-90ed-aa2b64712fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46505,DS-8b255df3-919b-419d-bd0c-590dcc0dbb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-309135ba-3afa-42bf-a205-b809e744be19,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-5645a356-5e46-44f3-9006-c2091a56ee00,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-13ac770a-f628-499a-9bed-6199f4a4ff68,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-98e0f314-bde3-44f2-a90c-ea2e69f09b99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1677721600
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1288353033-172.17.0.17-1597334184140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35239,DS-60913430-49d2-4e2c-8abb-c81440fdcf20,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-ee739d9f-fadf-4807-94bf-463084afef06,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-f13136b9-999f-4677-9447-3601a2f7bde0,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-ab2dc2d3-3559-47fc-97cc-6c1ea84c701f,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-4791595c-1e89-4777-b9ed-813cbcfb08a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-8d65f590-c741-485b-b44f-a516bc16ce5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-6d5b4c7b-7a51-4746-904b-b0a09cbe8086,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-459b1e47-351c-414e-959d-5d3766332390,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1288353033-172.17.0.17-1597334184140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35239,DS-60913430-49d2-4e2c-8abb-c81440fdcf20,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-ee739d9f-fadf-4807-94bf-463084afef06,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-f13136b9-999f-4677-9447-3601a2f7bde0,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-ab2dc2d3-3559-47fc-97cc-6c1ea84c701f,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-4791595c-1e89-4777-b9ed-813cbcfb08a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-8d65f590-c741-485b-b44f-a516bc16ce5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-6d5b4c7b-7a51-4746-904b-b0a09cbe8086,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-459b1e47-351c-414e-959d-5d3766332390,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1677721600
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1863877727-172.17.0.17-1597334400017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44675,DS-4d2b3f06-684a-4007-8f0f-00b6b1f66e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-3988b4b7-0518-46ea-b02a-ef0497509182,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-9bc9e1f3-fee3-4b66-9082-0eb1a1e8df87,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-fe565f12-1203-4e08-a38f-828f9a602ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-e144e20d-67da-4f1a-97e3-45e2dff9c2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-31cbe658-afa2-4f71-9649-7e4709e0d344,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-c65491d8-f1c5-423b-970b-a72f5a0a0ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-34e7a0d9-c394-4264-9b0d-9b1381e7570f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1863877727-172.17.0.17-1597334400017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44675,DS-4d2b3f06-684a-4007-8f0f-00b6b1f66e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-3988b4b7-0518-46ea-b02a-ef0497509182,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-9bc9e1f3-fee3-4b66-9082-0eb1a1e8df87,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-fe565f12-1203-4e08-a38f-828f9a602ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-e144e20d-67da-4f1a-97e3-45e2dff9c2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-31cbe658-afa2-4f71-9649-7e4709e0d344,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-c65491d8-f1c5-423b-970b-a72f5a0a0ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-34e7a0d9-c394-4264-9b0d-9b1381e7570f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1677721600
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-563604581-172.17.0.17-1597334431198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46385,DS-af348a51-d8f5-42a1-bfad-c48d45877193,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-6fdbda8b-2467-41f5-a160-73930ecdff21,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-a3b3cd5c-1e3c-489f-b6cb-b3cd6168125a,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-bbdb38e4-bcbb-4136-ad26-ad0597811726,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-c67a8cba-3dcb-4e03-86c3-81429e97e14d,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-490179ec-fee7-4021-b6de-2c9358f9c798,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-2fa5aaa6-45a0-48f9-a2f4-69adc1388679,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-aa25de97-bf55-4d2b-bbab-cc4355d33547,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-563604581-172.17.0.17-1597334431198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46385,DS-af348a51-d8f5-42a1-bfad-c48d45877193,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-6fdbda8b-2467-41f5-a160-73930ecdff21,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-a3b3cd5c-1e3c-489f-b6cb-b3cd6168125a,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-bbdb38e4-bcbb-4136-ad26-ad0597811726,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-c67a8cba-3dcb-4e03-86c3-81429e97e14d,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-490179ec-fee7-4021-b6de-2c9358f9c798,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-2fa5aaa6-45a0-48f9-a2f4-69adc1388679,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-aa25de97-bf55-4d2b-bbab-cc4355d33547,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1677721600
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884811820-172.17.0.17-1597334575973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36857,DS-f168330f-ae72-491d-9c59-8b1a7438ab85,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-becd93c1-ba0e-46e3-8a73-ae5690366423,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-f1a820f9-c558-4fb9-8c60-5833a55522e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-28f6af32-9f87-4c44-9627-1b92b9c3bc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-2f3419fa-5eb2-41f3-b4a7-9c9cd4f00fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-b9da0854-0c8d-4a1b-b7f2-5db3aaa54cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-9ed65c25-07ac-4b3a-9fdf-4746303b351f,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-4e641e3b-bd8f-4232-a251-9cf2a3cd73ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884811820-172.17.0.17-1597334575973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36857,DS-f168330f-ae72-491d-9c59-8b1a7438ab85,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-becd93c1-ba0e-46e3-8a73-ae5690366423,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-f1a820f9-c558-4fb9-8c60-5833a55522e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-28f6af32-9f87-4c44-9627-1b92b9c3bc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-2f3419fa-5eb2-41f3-b4a7-9c9cd4f00fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-b9da0854-0c8d-4a1b-b7f2-5db3aaa54cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-9ed65c25-07ac-4b3a-9fdf-4746303b351f,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-4e641e3b-bd8f-4232-a251-9cf2a3cd73ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1677721600
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614612851-172.17.0.17-1597335060652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41232,DS-50483da4-deb4-4310-8500-8108b73ce2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-883e60fc-8097-4fa4-a871-dd2cf5890a13,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-45e394a6-7669-45ea-bdb6-92f2e502c077,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-a9cb42f7-e1fc-490b-83bb-82fd1e1dd6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-d9aa5ed4-3fbe-4756-8c39-33035841ed42,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-04caebc3-817e-447a-a1d1-fc7bb312cd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-fa3a7f6a-c5b1-47bb-939a-999ad4da4e56,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-e9df5f21-6b83-4980-a446-a1ff56e8fa72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614612851-172.17.0.17-1597335060652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41232,DS-50483da4-deb4-4310-8500-8108b73ce2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-883e60fc-8097-4fa4-a871-dd2cf5890a13,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-45e394a6-7669-45ea-bdb6-92f2e502c077,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-a9cb42f7-e1fc-490b-83bb-82fd1e1dd6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-d9aa5ed4-3fbe-4756-8c39-33035841ed42,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-04caebc3-817e-447a-a1d1-fc7bb312cd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-fa3a7f6a-c5b1-47bb-939a-999ad4da4e56,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-e9df5f21-6b83-4980-a446-a1ff56e8fa72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1677721600
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436986756-172.17.0.17-1597335723572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46065,DS-935f0394-4a8f-47fe-b06a-05a19d56e7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-b722a5c0-35ea-427e-ab15-db6a0b814cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-de20cdc0-cf5c-4a41-98e7-cc2ab0a04060,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-5077b299-d200-44b9-a0b7-9dc7635970ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-fa00d7c3-b846-4b1b-96e2-073250133a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-8a4ace7b-0d8e-4230-b77a-12eb88e0ea4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-a4cba9e8-0a49-4483-abd6-238207907f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-71605f32-8733-4735-9c2b-682f4b7e98e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436986756-172.17.0.17-1597335723572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46065,DS-935f0394-4a8f-47fe-b06a-05a19d56e7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-b722a5c0-35ea-427e-ab15-db6a0b814cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-de20cdc0-cf5c-4a41-98e7-cc2ab0a04060,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-5077b299-d200-44b9-a0b7-9dc7635970ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-fa00d7c3-b846-4b1b-96e2-073250133a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-8a4ace7b-0d8e-4230-b77a-12eb88e0ea4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-a4cba9e8-0a49-4483-abd6-238207907f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-71605f32-8733-4735-9c2b-682f4b7e98e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1677721600
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647888716-172.17.0.17-1597335756618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35561,DS-33c1e51b-b774-41c3-a0b2-e8fc52d31573,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-3fd82a4a-1c27-43d5-af9b-a9926b1c59c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-f4d14cdd-c834-4be9-8c40-8be6a9f2000d,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-a8bf1e38-bfca-480a-abc1-c7e19a5966c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-2b9474b1-a5bd-4e6b-8f49-94b83f78c254,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-8dedc770-9882-402d-9567-7b63a451eba4,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-3398a87e-c1e5-4bf6-bb29-2c14cba8251e,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-056a595b-1c39-4281-9d45-99c66c209841,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647888716-172.17.0.17-1597335756618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35561,DS-33c1e51b-b774-41c3-a0b2-e8fc52d31573,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-3fd82a4a-1c27-43d5-af9b-a9926b1c59c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-f4d14cdd-c834-4be9-8c40-8be6a9f2000d,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-a8bf1e38-bfca-480a-abc1-c7e19a5966c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-2b9474b1-a5bd-4e6b-8f49-94b83f78c254,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-8dedc770-9882-402d-9567-7b63a451eba4,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-3398a87e-c1e5-4bf6-bb29-2c14cba8251e,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-056a595b-1c39-4281-9d45-99c66c209841,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1677721600
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647015642-172.17.0.17-1597335947246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32823,DS-4a6dcb92-f7e9-4b83-b3c6-f1004c6bdf73,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-72d492fd-941f-4b0e-bbef-27876a4ad6da,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-0d051053-359a-4131-a6d4-6dd35c97c893,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-a5b43610-40d6-4b55-9dd1-1782f4a58423,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-6c426c62-cd63-4f63-b74e-f64f0d2989b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-fc3c8778-bfd9-4328-9f1a-4f7da6ee9ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-317a9bb1-c92a-4c04-b1cc-21bbcdd0302d,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-d5d1f63b-a436-4dbd-a1be-be199cd45c3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647015642-172.17.0.17-1597335947246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32823,DS-4a6dcb92-f7e9-4b83-b3c6-f1004c6bdf73,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-72d492fd-941f-4b0e-bbef-27876a4ad6da,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-0d051053-359a-4131-a6d4-6dd35c97c893,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-a5b43610-40d6-4b55-9dd1-1782f4a58423,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-6c426c62-cd63-4f63-b74e-f64f0d2989b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-fc3c8778-bfd9-4328-9f1a-4f7da6ee9ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-317a9bb1-c92a-4c04-b1cc-21bbcdd0302d,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-d5d1f63b-a436-4dbd-a1be-be199cd45c3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1677721600
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-62441467-172.17.0.17-1597336475312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44959,DS-f4fb5846-b9ba-491a-ad80-6eb1a87988e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-50176748-ac4f-4f6a-aef3-97aba584e471,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-3d01044d-7e99-4ea1-88c0-a318c9aff51c,DISK], DatanodeInfoWithStorage[127.0.0.1:36296,DS-d3c619f4-26ab-4158-8f8c-eea41b493668,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-04930ffd-e5ee-4f46-a17b-9a4cd55dd6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-0375714b-4a60-4b2e-803c-27b14d2a1de9,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-ef83b603-dfa0-498e-9e90-f2e0545ecff0,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-39c7b36f-fec9-4e70-922d-186ecd15751c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-62441467-172.17.0.17-1597336475312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44959,DS-f4fb5846-b9ba-491a-ad80-6eb1a87988e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-50176748-ac4f-4f6a-aef3-97aba584e471,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-3d01044d-7e99-4ea1-88c0-a318c9aff51c,DISK], DatanodeInfoWithStorage[127.0.0.1:36296,DS-d3c619f4-26ab-4158-8f8c-eea41b493668,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-04930ffd-e5ee-4f46-a17b-9a4cd55dd6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-0375714b-4a60-4b2e-803c-27b14d2a1de9,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-ef83b603-dfa0-498e-9e90-f2e0545ecff0,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-39c7b36f-fec9-4e70-922d-186ecd15751c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1677721600
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1798836613-172.17.0.17-1597336700657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35480,DS-fb729b2d-71fb-4ac4-a9ca-7ec9b0346cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-e67cf8fb-f0fe-419e-8c6c-93faa8c3a121,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-3f2d258c-fd6b-45eb-ac2d-91c4f8218840,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-20e31a3d-6e60-4138-bde7-175e4cf6dff3,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-25e60519-2c8b-4387-ab7d-f96f88329d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-639a3f02-31d0-4e4f-b929-970a2ac846b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-67cf04d4-7c15-4197-96f4-fefb78d74d61,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-3e0c9f3c-b682-44d6-8aba-e65113020590,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1798836613-172.17.0.17-1597336700657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35480,DS-fb729b2d-71fb-4ac4-a9ca-7ec9b0346cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-e67cf8fb-f0fe-419e-8c6c-93faa8c3a121,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-3f2d258c-fd6b-45eb-ac2d-91c4f8218840,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-20e31a3d-6e60-4138-bde7-175e4cf6dff3,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-25e60519-2c8b-4387-ab7d-f96f88329d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-639a3f02-31d0-4e4f-b929-970a2ac846b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-67cf04d4-7c15-4197-96f4-fefb78d74d61,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-3e0c9f3c-b682-44d6-8aba-e65113020590,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1677721600
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-671162458-172.17.0.17-1597336923257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45370,DS-c05d84f6-a362-411f-838a-0e25e8d1733b,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-21207873-3ad0-44bb-b685-909a1fbe4f56,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-debf1e47-d508-4bbf-9660-40ac6abe60f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-2a6e2002-47de-45bd-b372-ae72403cb306,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-cab84403-feab-41e3-be9f-fa16df6bca76,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-1e4ac757-cd3f-4cc8-9bb2-1dbc7e6aca8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-30148412-2c91-4ce1-9936-2d187acde6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-be772c99-a5b7-4c4b-b3d6-b910fb4095fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-671162458-172.17.0.17-1597336923257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45370,DS-c05d84f6-a362-411f-838a-0e25e8d1733b,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-21207873-3ad0-44bb-b685-909a1fbe4f56,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-debf1e47-d508-4bbf-9660-40ac6abe60f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-2a6e2002-47de-45bd-b372-ae72403cb306,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-cab84403-feab-41e3-be9f-fa16df6bca76,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-1e4ac757-cd3f-4cc8-9bb2-1dbc7e6aca8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-30148412-2c91-4ce1-9936-2d187acde6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-be772c99-a5b7-4c4b-b3d6-b910fb4095fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1677721600
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1340704110-172.17.0.17-1597336958484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39152,DS-1ea556b0-1e08-4da8-bdda-5b8791c356f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33185,DS-4efe98e6-3b3e-452f-8fe5-d83618c68bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-089d5960-eda8-4e79-94dc-a45c2b8252eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-752a7b18-5e9e-443c-a6ff-a70e38d51a83,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-9787fce5-6df6-4e3d-9aee-b1cfe95d45a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-cefe0478-4873-4ba8-b8cb-f53aa96e9d07,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-b3ff7448-8240-46e9-a0c9-6b61c6286f23,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-5b41eb83-e139-4761-aedb-0278000f1b48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1340704110-172.17.0.17-1597336958484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39152,DS-1ea556b0-1e08-4da8-bdda-5b8791c356f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33185,DS-4efe98e6-3b3e-452f-8fe5-d83618c68bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-089d5960-eda8-4e79-94dc-a45c2b8252eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-752a7b18-5e9e-443c-a6ff-a70e38d51a83,DISK], DatanodeInfoWithStorage[127.0.0.1:35267,DS-9787fce5-6df6-4e3d-9aee-b1cfe95d45a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-cefe0478-4873-4ba8-b8cb-f53aa96e9d07,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-b3ff7448-8240-46e9-a0c9-6b61c6286f23,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-5b41eb83-e139-4761-aedb-0278000f1b48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1677721600
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63878320-172.17.0.17-1597337289473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41605,DS-1e9ef171-ec09-485c-a4f5-886d05d951dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-e543f5ac-b57f-46f4-96f0-1d758e16aa3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-11645f13-04ac-461d-b9cc-d38590d00518,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-0f3a8a21-7230-44c2-955a-75228e22e00c,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-76d20e79-425e-41e6-a193-3ab81810e73c,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-00f73767-f96a-4f5b-8be1-43b70bf89614,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-b70f8adb-fac8-4626-8418-48abf8cbe88d,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-d049ed86-8b37-4e81-b2ef-292df2f115e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63878320-172.17.0.17-1597337289473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41605,DS-1e9ef171-ec09-485c-a4f5-886d05d951dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-e543f5ac-b57f-46f4-96f0-1d758e16aa3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-11645f13-04ac-461d-b9cc-d38590d00518,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-0f3a8a21-7230-44c2-955a-75228e22e00c,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-76d20e79-425e-41e6-a193-3ab81810e73c,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-00f73767-f96a-4f5b-8be1-43b70bf89614,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-b70f8adb-fac8-4626-8418-48abf8cbe88d,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-d049ed86-8b37-4e81-b2ef-292df2f115e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1677721600
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-43707938-172.17.0.17-1597337519592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39378,DS-4edaeac5-f719-4059-a5b8-1f43c97087fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-bfbb4074-3b1e-45c3-98c1-81f5823461f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-251c49e0-0a53-483c-8c66-e74b96eb21f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-f5064278-63bd-4bc2-b25f-032aabd3c5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-9653c6ab-3773-42cb-8ad6-6d613f0d2da9,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-c00a8b42-c2bb-4c33-97fe-75e1f90da0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-9e71bdff-fad1-4cdc-9b45-c08b23cfcf25,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-3ab2327d-34ba-40b5-ae75-64c1936ec985,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-43707938-172.17.0.17-1597337519592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39378,DS-4edaeac5-f719-4059-a5b8-1f43c97087fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-bfbb4074-3b1e-45c3-98c1-81f5823461f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-251c49e0-0a53-483c-8c66-e74b96eb21f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-f5064278-63bd-4bc2-b25f-032aabd3c5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-9653c6ab-3773-42cb-8ad6-6d613f0d2da9,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-c00a8b42-c2bb-4c33-97fe-75e1f90da0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-9e71bdff-fad1-4cdc-9b45-c08b23cfcf25,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-3ab2327d-34ba-40b5-ae75-64c1936ec985,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.du.reserved
component: hdfs:NameNode
v1: 1677721600
v2: 104857600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1987265924-172.17.0.17-1597338246242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43505,DS-2d323984-8fae-450e-87ed-f4024c0a2379,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-7b97ef80-e330-4acf-8a38-d7e45bfd1917,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-ed2e05b8-95d6-416a-ae38-275fa6b5bf18,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-d6ef82cc-b2bf-4f5e-8c9a-53c2670db3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-151669b1-4eff-4662-a654-8d25e937406c,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-64df551d-1dde-4c97-9bc4-ea96cc9df3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-7d2c8c1b-95cb-4844-98f8-084433d5bf29,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-0c8e714c-9ed7-42a5-8bc5-4df3d0ef93ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1987265924-172.17.0.17-1597338246242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43505,DS-2d323984-8fae-450e-87ed-f4024c0a2379,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-7b97ef80-e330-4acf-8a38-d7e45bfd1917,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-ed2e05b8-95d6-416a-ae38-275fa6b5bf18,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-d6ef82cc-b2bf-4f5e-8c9a-53c2670db3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-151669b1-4eff-4662-a654-8d25e937406c,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-64df551d-1dde-4c97-9bc4-ea96cc9df3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-7d2c8c1b-95cb-4844-98f8-084433d5bf29,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-0c8e714c-9ed7-42a5-8bc5-4df3d0ef93ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5500
