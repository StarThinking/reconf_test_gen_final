reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-244024012-172.17.0.9-1597481903291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35008,DS-53feb42c-0c9a-4a5b-bec9-a1a836a3a816,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-908b019c-b2e2-477b-838f-6ffab740c84d,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-34d5b7da-2a86-4e2d-9a5b-ebc46ee4f6be,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-bcee1229-20db-4f18-8f53-d01a827a7cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-54750d7b-bcec-407a-b2bc-23eb83611ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-e8a36986-ea9d-49d7-97e5-edd138c37665,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-079b4ad2-7541-400d-b17e-7d3938cfa01f,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-21477f3d-ea8b-42bd-9f00-50756b5f8e6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-244024012-172.17.0.9-1597481903291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35008,DS-53feb42c-0c9a-4a5b-bec9-a1a836a3a816,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-908b019c-b2e2-477b-838f-6ffab740c84d,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-34d5b7da-2a86-4e2d-9a5b-ebc46ee4f6be,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-bcee1229-20db-4f18-8f53-d01a827a7cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-54750d7b-bcec-407a-b2bc-23eb83611ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-e8a36986-ea9d-49d7-97e5-edd138c37665,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-079b4ad2-7541-400d-b17e-7d3938cfa01f,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-21477f3d-ea8b-42bd-9f00-50756b5f8e6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1048697751-172.17.0.9-1597481968120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44070,DS-ad4ce017-1daf-41b4-9dfb-b05f821fb217,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-709b510c-287f-41bc-becd-63e42563625c,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-7f9f363d-6831-4479-a1ea-de34da5084ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-df8a7593-164f-4f69-b336-6e95df719c94,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-09594e02-7e40-4554-a479-e3bdf0694779,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-3bc52ad9-32b6-43d5-87e0-e6cced1340e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-c0f006a2-918e-44ed-9e19-2534424a75e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-15fa0485-9b42-4633-8aae-f7516ec5e328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1048697751-172.17.0.9-1597481968120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44070,DS-ad4ce017-1daf-41b4-9dfb-b05f821fb217,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-709b510c-287f-41bc-becd-63e42563625c,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-7f9f363d-6831-4479-a1ea-de34da5084ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-df8a7593-164f-4f69-b336-6e95df719c94,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-09594e02-7e40-4554-a479-e3bdf0694779,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-3bc52ad9-32b6-43d5-87e0-e6cced1340e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-c0f006a2-918e-44ed-9e19-2534424a75e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-15fa0485-9b42-4633-8aae-f7516ec5e328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1157849002-172.17.0.9-1597482004249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34273,DS-287d8ccc-03a3-4d92-a6a0-c962481df1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-86a566a9-873c-46eb-89f9-2ce6744dd4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-b6309932-be26-4b52-8717-5d1147a40fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-79a00937-b515-4a33-a056-984ebb720f33,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-1f484e28-a384-4e0f-a9ec-aeddf5e3a37d,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-291bab3f-1a91-4cc1-8cf9-9cdf3e650407,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-9f2eadc8-d126-4c0c-a49b-66ee93ef432f,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-2ddbe273-074b-4e88-99f0-f6989f939e5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1157849002-172.17.0.9-1597482004249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34273,DS-287d8ccc-03a3-4d92-a6a0-c962481df1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-86a566a9-873c-46eb-89f9-2ce6744dd4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-b6309932-be26-4b52-8717-5d1147a40fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-79a00937-b515-4a33-a056-984ebb720f33,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-1f484e28-a384-4e0f-a9ec-aeddf5e3a37d,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-291bab3f-1a91-4cc1-8cf9-9cdf3e650407,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-9f2eadc8-d126-4c0c-a49b-66ee93ef432f,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-2ddbe273-074b-4e88-99f0-f6989f939e5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-476870112-172.17.0.9-1597482352531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40630,DS-e8b741fb-d700-44c8-a82e-e9d908d87b60,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-f1ce2c51-91e7-4dee-aeb6-0509d0d687cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-7640ea38-10f8-409f-b995-de394113a33d,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-2afd73f2-44f2-40a8-ba8f-598fc412db3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-8351cff7-86fe-42dd-bf9a-9465ba5ad37a,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-5b54a1a3-b606-4e65-8397-fe9d9194e02f,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-f33de668-8733-4225-8765-cba556b007cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-b74e7d37-cb18-42ee-b38b-863a0420b33c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-476870112-172.17.0.9-1597482352531:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40630,DS-e8b741fb-d700-44c8-a82e-e9d908d87b60,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-f1ce2c51-91e7-4dee-aeb6-0509d0d687cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-7640ea38-10f8-409f-b995-de394113a33d,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-2afd73f2-44f2-40a8-ba8f-598fc412db3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-8351cff7-86fe-42dd-bf9a-9465ba5ad37a,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-5b54a1a3-b606-4e65-8397-fe9d9194e02f,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-f33de668-8733-4225-8765-cba556b007cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-b74e7d37-cb18-42ee-b38b-863a0420b33c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-649420951-172.17.0.9-1597482979321:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41049,DS-11ae938d-53d4-4d2a-9068-9aea79c52753,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-929cdb97-4fb5-460d-bc02-fe3a341963a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-555a1392-4753-4111-aa0c-2d2502f0960b,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-552e4f0e-397b-4f7a-a227-0180b50f11a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-897d2b04-de77-4545-9aad-5c1fe4e4804e,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-46f84e19-6a67-471a-add5-5d55eb9e346e,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-7bb60643-12a7-4bba-a6ff-8ca295056e94,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-58aceab0-917f-4e19-b6fb-61cd6677e560,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-649420951-172.17.0.9-1597482979321:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41049,DS-11ae938d-53d4-4d2a-9068-9aea79c52753,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-929cdb97-4fb5-460d-bc02-fe3a341963a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-555a1392-4753-4111-aa0c-2d2502f0960b,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-552e4f0e-397b-4f7a-a227-0180b50f11a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-897d2b04-de77-4545-9aad-5c1fe4e4804e,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-46f84e19-6a67-471a-add5-5d55eb9e346e,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-7bb60643-12a7-4bba-a6ff-8ca295056e94,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-58aceab0-917f-4e19-b6fb-61cd6677e560,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-567877196-172.17.0.9-1597483052566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43649,DS-7d3c0f1f-1248-43f4-9fa0-e0fe4f73050f,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-cf15adef-a651-4b46-aaec-8abda55de51e,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-3e7ec7b3-30ef-4fda-8a81-db88dbee99c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-dcec2a02-4d3c-43b7-a9db-9f189dec9174,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-ce52b32a-4393-4799-9a4c-e05373a63906,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-edfd7029-c6ae-41e1-942f-d8915687ed09,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-8a31e5a4-cc8f-43e2-b504-6d9de3bf2487,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-3640f3c0-f76d-45d3-8508-ea54f468bfa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-567877196-172.17.0.9-1597483052566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43649,DS-7d3c0f1f-1248-43f4-9fa0-e0fe4f73050f,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-cf15adef-a651-4b46-aaec-8abda55de51e,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-3e7ec7b3-30ef-4fda-8a81-db88dbee99c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-dcec2a02-4d3c-43b7-a9db-9f189dec9174,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-ce52b32a-4393-4799-9a4c-e05373a63906,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-edfd7029-c6ae-41e1-942f-d8915687ed09,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-8a31e5a4-cc8f-43e2-b504-6d9de3bf2487,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-3640f3c0-f76d-45d3-8508-ea54f468bfa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-31260471-172.17.0.9-1597483094307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40823,DS-ec9d097c-0d15-470f-8d92-3bbd0b53899b,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-584514e6-71e9-4e09-80b5-21395e717c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-b3275648-353a-417d-92db-ce3fb7818550,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-c42ec643-9e90-43f0-9809-d38e228f9aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-8273f9df-3220-4232-9eee-eef703deffca,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-b76e3c5f-b830-4a42-a3b9-22047dea5b10,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-a742aa1e-545e-4c62-9da5-bc23164ae05b,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-3acb7cb3-a787-4986-a047-cba85a6ef61b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-31260471-172.17.0.9-1597483094307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40823,DS-ec9d097c-0d15-470f-8d92-3bbd0b53899b,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-584514e6-71e9-4e09-80b5-21395e717c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-b3275648-353a-417d-92db-ce3fb7818550,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-c42ec643-9e90-43f0-9809-d38e228f9aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-8273f9df-3220-4232-9eee-eef703deffca,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-b76e3c5f-b830-4a42-a3b9-22047dea5b10,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-a742aa1e-545e-4c62-9da5-bc23164ae05b,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-3acb7cb3-a787-4986-a047-cba85a6ef61b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-197754068-172.17.0.9-1597483131548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32857,DS-91064dac-a51e-413b-9c51-2ca3922a32ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-d50057c1-2674-4436-9db8-33a70b17c2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-64b37815-20c5-4279-ba3f-401e471c1958,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-ed3db7e4-85dc-4acc-a119-f5955c4b7c09,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-36cd86f5-8c1d-411e-be34-49fce0c8d559,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-29a1c54b-0964-4b89-b76f-fa135a5b00ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-ffe61b23-d3c5-4267-9a14-0890fb1047b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-0ac3ed9e-aaaf-478d-b9e7-d0cc609dcf3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-197754068-172.17.0.9-1597483131548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32857,DS-91064dac-a51e-413b-9c51-2ca3922a32ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-d50057c1-2674-4436-9db8-33a70b17c2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-64b37815-20c5-4279-ba3f-401e471c1958,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-ed3db7e4-85dc-4acc-a119-f5955c4b7c09,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-36cd86f5-8c1d-411e-be34-49fce0c8d559,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-29a1c54b-0964-4b89-b76f-fa135a5b00ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-ffe61b23-d3c5-4267-9a14-0890fb1047b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-0ac3ed9e-aaaf-478d-b9e7-d0cc609dcf3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-350586405-172.17.0.9-1597483516787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46171,DS-117ea3c0-2c69-470b-8c1d-9b81208c74e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-6cae3546-1c3b-4d6a-a0b1-b1a57a47190f,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-d783183d-4ea3-401a-bc6f-a06f4fc1c60a,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-8e22788b-0809-45f9-981d-c4102e3a8d07,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-effbf757-67a6-4ede-8c13-8a77082891cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39436,DS-7584e425-c125-4a3f-b99a-b4a469f07e03,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-91104055-1eca-4041-9932-fd9d3997e55f,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-2c1992ea-ec6e-403d-97a4-e4f681c9ddcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-350586405-172.17.0.9-1597483516787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46171,DS-117ea3c0-2c69-470b-8c1d-9b81208c74e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-6cae3546-1c3b-4d6a-a0b1-b1a57a47190f,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-d783183d-4ea3-401a-bc6f-a06f4fc1c60a,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-8e22788b-0809-45f9-981d-c4102e3a8d07,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-effbf757-67a6-4ede-8c13-8a77082891cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39436,DS-7584e425-c125-4a3f-b99a-b4a469f07e03,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-91104055-1eca-4041-9932-fd9d3997e55f,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-2c1992ea-ec6e-403d-97a4-e4f681c9ddcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1529461028-172.17.0.9-1597484573250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40012,DS-5632b6de-b818-41fb-89ee-16f6d80618ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-906282bc-0f59-494c-959d-5b33f6e3fad7,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-812c97cd-0b40-498c-8a94-1cf6334a6348,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-69cf47da-05ef-49d0-8949-5f1f57420c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-59659005-0ad1-4bc3-88f0-332a72231d61,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-79d70ff3-3375-4cd7-bbd6-acc05756e8db,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-32e55adb-42a5-4db0-aa70-f17d0cba655a,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-19d33d01-0a02-44a5-bf2e-a9e80968abc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1529461028-172.17.0.9-1597484573250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40012,DS-5632b6de-b818-41fb-89ee-16f6d80618ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-906282bc-0f59-494c-959d-5b33f6e3fad7,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-812c97cd-0b40-498c-8a94-1cf6334a6348,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-69cf47da-05ef-49d0-8949-5f1f57420c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-59659005-0ad1-4bc3-88f0-332a72231d61,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-79d70ff3-3375-4cd7-bbd6-acc05756e8db,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-32e55adb-42a5-4db0-aa70-f17d0cba655a,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-19d33d01-0a02-44a5-bf2e-a9e80968abc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-619566718-172.17.0.9-1597484643759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34151,DS-a73cc49e-fed9-4076-98cf-489784890127,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-39a3dcbc-7232-4b21-8483-f57eee1dd92f,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-18b4942b-2312-48af-b4fc-85a1b35f178d,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-38dad742-69ba-43af-a528-bb3d6db8474a,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-50256d65-4954-4c5b-81be-8ca368af1978,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-47585137-bbfd-415e-bd54-7cb0773078fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-c25c6836-1807-4d3d-ae22-eb6371ae132a,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-5131d19c-a625-448c-9ff0-c392947a3b37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-619566718-172.17.0.9-1597484643759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34151,DS-a73cc49e-fed9-4076-98cf-489784890127,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-39a3dcbc-7232-4b21-8483-f57eee1dd92f,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-18b4942b-2312-48af-b4fc-85a1b35f178d,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-38dad742-69ba-43af-a528-bb3d6db8474a,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-50256d65-4954-4c5b-81be-8ca368af1978,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-47585137-bbfd-415e-bd54-7cb0773078fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-c25c6836-1807-4d3d-ae22-eb6371ae132a,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-5131d19c-a625-448c-9ff0-c392947a3b37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-546198310-172.17.0.9-1597485951781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36860,DS-b9329cb2-afaf-44f9-812f-0c7f2f8d489c,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-636923cf-c5fd-4910-8184-91cefd76a3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-898eeafe-8b0c-4ab5-9998-f160d92dcc96,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-b8fb797b-1bc0-41ff-a338-710958f5bea3,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-42773bef-ea49-4441-bbca-e43f592cc07b,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-a56790aa-8412-4802-b71c-1bc1a38f3c05,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-b87f6fd0-40d1-4377-853e-bfef8f2ea5de,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-3843ca92-0689-4d03-b375-b38e85856492,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-546198310-172.17.0.9-1597485951781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36860,DS-b9329cb2-afaf-44f9-812f-0c7f2f8d489c,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-636923cf-c5fd-4910-8184-91cefd76a3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-898eeafe-8b0c-4ab5-9998-f160d92dcc96,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-b8fb797b-1bc0-41ff-a338-710958f5bea3,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-42773bef-ea49-4441-bbca-e43f592cc07b,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-a56790aa-8412-4802-b71c-1bc1a38f3c05,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-b87f6fd0-40d1-4377-853e-bfef8f2ea5de,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-3843ca92-0689-4d03-b375-b38e85856492,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 36
v2: 3600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1737912052-172.17.0.9-1597486216479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46296,DS-e8508c33-2256-4cb9-829d-cee53200066d,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-02b37758-8d19-467e-9198-bad36cccb202,DISK], DatanodeInfoWithStorage[127.0.0.1:33835,DS-fb147abb-8cc6-4efa-bde2-fbc54bd7a2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-13d5b331-aa5c-4c67-9784-a667bb4dc751,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-2733d738-57a3-464b-8d42-4d94b79e7dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-e2692528-bdd7-4e4a-9655-f99b6cc97323,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-77c57ec5-ac60-43be-b591-2376e19c5c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-cb9ef0a0-12a4-41cb-8069-646eb94bb5b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1737912052-172.17.0.9-1597486216479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46296,DS-e8508c33-2256-4cb9-829d-cee53200066d,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-02b37758-8d19-467e-9198-bad36cccb202,DISK], DatanodeInfoWithStorage[127.0.0.1:33835,DS-fb147abb-8cc6-4efa-bde2-fbc54bd7a2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-13d5b331-aa5c-4c67-9784-a667bb4dc751,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-2733d738-57a3-464b-8d42-4d94b79e7dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-e2692528-bdd7-4e4a-9655-f99b6cc97323,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-77c57ec5-ac60-43be-b591-2376e19c5c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-cb9ef0a0-12a4-41cb-8069-646eb94bb5b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5315
