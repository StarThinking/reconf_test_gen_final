reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-504961317-172.17.0.4-1597720054010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34098,DS-fdcbea23-8318-40f3-903d-9338091ff5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-fae6409c-4219-4011-9684-165972626ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-f501ecdb-8653-4dad-8897-d507d6420080,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-e0c2fca1-e36f-440b-bf19-6fa06fabd1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-04d41a8f-c113-407a-a01f-194586d7feae,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-87807cac-39c6-469e-aef8-33afd400a8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-40ac461d-b451-4083-8ad8-ffaf8ffe4a99,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-b63a4de7-8ba9-4a19-bf9a-7b23cc3e64bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-504961317-172.17.0.4-1597720054010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34098,DS-fdcbea23-8318-40f3-903d-9338091ff5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-fae6409c-4219-4011-9684-165972626ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-f501ecdb-8653-4dad-8897-d507d6420080,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-e0c2fca1-e36f-440b-bf19-6fa06fabd1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-04d41a8f-c113-407a-a01f-194586d7feae,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-87807cac-39c6-469e-aef8-33afd400a8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-40ac461d-b451-4083-8ad8-ffaf8ffe4a99,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-b63a4de7-8ba9-4a19-bf9a-7b23cc3e64bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-810824067-172.17.0.4-1597720335504:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42442,DS-104c14f4-4056-4758-be3b-3995b8aede7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-cf3b2185-c866-4142-afa4-82033af369bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-13e491b0-4df0-416c-a241-e25affdaa698,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-499e73e9-0f03-4fe4-bcb8-abd45b9801c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-6bb355eb-50a4-4394-a09d-f9ff3a7b61c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-fd11ffbf-9395-47c3-b428-1e3d719eadb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-576b92b6-e6f5-4cf8-8310-b0d228606049,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-06f6c4cb-1c0c-4702-875e-fe467a8738f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-810824067-172.17.0.4-1597720335504:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42442,DS-104c14f4-4056-4758-be3b-3995b8aede7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-cf3b2185-c866-4142-afa4-82033af369bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-13e491b0-4df0-416c-a241-e25affdaa698,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-499e73e9-0f03-4fe4-bcb8-abd45b9801c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-6bb355eb-50a4-4394-a09d-f9ff3a7b61c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-fd11ffbf-9395-47c3-b428-1e3d719eadb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-576b92b6-e6f5-4cf8-8310-b0d228606049,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-06f6c4cb-1c0c-4702-875e-fe467a8738f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1523445727-172.17.0.4-1597720685082:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37610,DS-cfa11ac8-d82f-4277-b843-9e2ea719d7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-7bd95b32-e4e4-47a4-ae6d-2491a2c87535,DISK], DatanodeInfoWithStorage[127.0.0.1:32976,DS-b537ffc3-7886-4475-8e4e-f21a048d41bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-b4102b66-c27c-4760-bb7a-27af338eac0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-57fb166b-686b-40f0-9542-f12710394524,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-61e87e0b-249b-415f-93ff-9e3caf16178e,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-653c3f27-400e-4cb7-877d-267996b73172,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-0915e617-7ddd-425f-ae3b-42676e79eba0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1523445727-172.17.0.4-1597720685082:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37610,DS-cfa11ac8-d82f-4277-b843-9e2ea719d7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-7bd95b32-e4e4-47a4-ae6d-2491a2c87535,DISK], DatanodeInfoWithStorage[127.0.0.1:32976,DS-b537ffc3-7886-4475-8e4e-f21a048d41bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-b4102b66-c27c-4760-bb7a-27af338eac0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-57fb166b-686b-40f0-9542-f12710394524,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-61e87e0b-249b-415f-93ff-9e3caf16178e,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-653c3f27-400e-4cb7-877d-267996b73172,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-0915e617-7ddd-425f-ae3b-42676e79eba0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1638997267-172.17.0.4-1597720811007:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42902,DS-4e83e336-0b6c-4275-afa4-8996bada407f,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-1fc5f2eb-6eaa-4dbb-bec0-8b5f02ecaa93,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-1ab4f57b-342c-4e72-9616-2d86a9218a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-26b1e4ae-15c2-4179-a345-4c30f1e6df8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-cfbd44f4-dcce-4d5a-81d3-c8ceade20394,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-96a7cc27-870f-4807-b7de-41dce61f9f93,DISK], DatanodeInfoWithStorage[127.0.0.1:34667,DS-eaaff1f9-6973-4e2a-a3b3-e14fdd04947a,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-e40411bf-4884-4f03-b71e-66309981d7c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1638997267-172.17.0.4-1597720811007:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42902,DS-4e83e336-0b6c-4275-afa4-8996bada407f,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-1fc5f2eb-6eaa-4dbb-bec0-8b5f02ecaa93,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-1ab4f57b-342c-4e72-9616-2d86a9218a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-26b1e4ae-15c2-4179-a345-4c30f1e6df8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-cfbd44f4-dcce-4d5a-81d3-c8ceade20394,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-96a7cc27-870f-4807-b7de-41dce61f9f93,DISK], DatanodeInfoWithStorage[127.0.0.1:34667,DS-eaaff1f9-6973-4e2a-a3b3-e14fdd04947a,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-e40411bf-4884-4f03-b71e-66309981d7c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-811829750-172.17.0.4-1597720979465:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38238,DS-ca46dd05-1ac7-46d2-8b15-aeeb34e66641,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-fd71fb4c-f4e8-4775-b964-82667fd6cdcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-19df1772-1bc1-4011-a456-d7a03587a564,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-91d37bf0-dc4b-41ce-884d-32ee0b29a678,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-6b11f826-1691-4d53-95e4-1dbe2f90b7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-9e22f72d-cd17-48e3-9320-82b4806d4f89,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-7c702b93-53c7-45ec-b941-001b6dec7d94,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-b63e6406-145d-45d5-ba47-641faadf3f8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-811829750-172.17.0.4-1597720979465:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38238,DS-ca46dd05-1ac7-46d2-8b15-aeeb34e66641,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-fd71fb4c-f4e8-4775-b964-82667fd6cdcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-19df1772-1bc1-4011-a456-d7a03587a564,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-91d37bf0-dc4b-41ce-884d-32ee0b29a678,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-6b11f826-1691-4d53-95e4-1dbe2f90b7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-9e22f72d-cd17-48e3-9320-82b4806d4f89,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-7c702b93-53c7-45ec-b941-001b6dec7d94,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-b63e6406-145d-45d5-ba47-641faadf3f8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1725556746-172.17.0.4-1597721496111:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46406,DS-f01b728f-41b4-470a-8cd2-04bf0b2b23b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-c91f3cda-c028-486f-a5eb-0ca1aa20f180,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-d63a90ef-6d71-4d48-abda-c7a57ed180c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-87d68937-aea1-471c-90db-c8980b6521ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-5c988949-cf92-4acd-97b8-c8f4a2c06738,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-fbc70f7d-3c3b-47b0-806c-c3ed0a8c4301,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-10fecbe5-554d-4405-9b1e-ac6f7b30274c,DISK], DatanodeInfoWithStorage[127.0.0.1:36053,DS-7981fdd6-5b23-4c13-8995-baa5ab01446f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1725556746-172.17.0.4-1597721496111:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46406,DS-f01b728f-41b4-470a-8cd2-04bf0b2b23b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-c91f3cda-c028-486f-a5eb-0ca1aa20f180,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-d63a90ef-6d71-4d48-abda-c7a57ed180c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-87d68937-aea1-471c-90db-c8980b6521ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-5c988949-cf92-4acd-97b8-c8f4a2c06738,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-fbc70f7d-3c3b-47b0-806c-c3ed0a8c4301,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-10fecbe5-554d-4405-9b1e-ac6f7b30274c,DISK], DatanodeInfoWithStorage[127.0.0.1:36053,DS-7981fdd6-5b23-4c13-8995-baa5ab01446f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1949215207-172.17.0.4-1597721647150:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41442,DS-5d3e1acc-8459-4ded-b82a-4080c562c244,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-e584ceaa-60e3-435f-b060-ecf8155e6976,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-49e7a4f8-d836-4093-b3d0-bf54cc571754,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-855e2f7e-0eaa-4d4f-8219-144f44058c42,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-50a020ee-a3e6-4673-ab14-332d6bd4b083,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-3a09c3aa-f038-4785-a2a7-4c2cb765439c,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-0be6d557-9e20-40cc-be52-2773d24d7cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-de22c1ce-ae50-4bbc-9dcb-fc1ef15b4c6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1949215207-172.17.0.4-1597721647150:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41442,DS-5d3e1acc-8459-4ded-b82a-4080c562c244,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-e584ceaa-60e3-435f-b060-ecf8155e6976,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-49e7a4f8-d836-4093-b3d0-bf54cc571754,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-855e2f7e-0eaa-4d4f-8219-144f44058c42,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-50a020ee-a3e6-4673-ab14-332d6bd4b083,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-3a09c3aa-f038-4785-a2a7-4c2cb765439c,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-0be6d557-9e20-40cc-be52-2773d24d7cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-de22c1ce-ae50-4bbc-9dcb-fc1ef15b4c6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2031461383-172.17.0.4-1597721691392:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34381,DS-45b039b7-8dcd-4fa2-b81a-eac67f7526c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-8363a206-714b-4650-96f0-0fa7dd4596da,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-4efc79a8-a427-4640-846b-829388753f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-54fd8fc8-ada6-4cbf-baf2-8a2c470b10b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-af9fc426-a587-485c-a974-1094627a9b90,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-650b24a9-d356-428d-af7d-edb8d58aa4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-9c4ab40c-ffdb-4058-974a-bcf17a86be8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-1c6ed934-e905-467b-9b2c-9f17ed3aaacb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2031461383-172.17.0.4-1597721691392:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34381,DS-45b039b7-8dcd-4fa2-b81a-eac67f7526c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-8363a206-714b-4650-96f0-0fa7dd4596da,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-4efc79a8-a427-4640-846b-829388753f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-54fd8fc8-ada6-4cbf-baf2-8a2c470b10b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-af9fc426-a587-485c-a974-1094627a9b90,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-650b24a9-d356-428d-af7d-edb8d58aa4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-9c4ab40c-ffdb-4058-974a-bcf17a86be8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-1c6ed934-e905-467b-9b2c-9f17ed3aaacb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1865871720-172.17.0.4-1597722169444:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42569,DS-4e41d040-c801-4569-b152-9fe78981b144,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-11ff5cb0-ca66-4c23-a5bd-419c30ce4c98,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-7d51324c-7e02-4d64-a0f9-e50ac091b3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-8d87d9a5-a6cc-4819-98fe-8c588fe6f958,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-5365d8cd-7103-4690-a562-f9ca3032f5df,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-44b6fd1d-aba2-429a-b678-84cdeb0b573a,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-c655851f-9f96-49ec-ae0b-3b1d96ede88e,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-fab2ecca-88f1-47c5-85cb-054823b79c0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1865871720-172.17.0.4-1597722169444:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42569,DS-4e41d040-c801-4569-b152-9fe78981b144,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-11ff5cb0-ca66-4c23-a5bd-419c30ce4c98,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-7d51324c-7e02-4d64-a0f9-e50ac091b3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-8d87d9a5-a6cc-4819-98fe-8c588fe6f958,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-5365d8cd-7103-4690-a562-f9ca3032f5df,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-44b6fd1d-aba2-429a-b678-84cdeb0b573a,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-c655851f-9f96-49ec-ae0b-3b1d96ede88e,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-fab2ecca-88f1-47c5-85cb-054823b79c0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1783660694-172.17.0.4-1597722462852:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46416,DS-eba8e1a7-6ffd-40fc-a4b2-5814a96238af,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-712f3104-5519-405d-8135-313a8d3abf93,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-9eb85b45-8e01-4aba-86ca-90acda464b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-bf05bcca-c569-416b-8b26-3f84cfe63ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-533e99e5-e46a-47ba-8eff-eecf311d9fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-594359d6-47fd-42e7-a5bb-eb0ace35ccdf,DISK], DatanodeInfoWithStorage[127.0.0.1:45758,DS-06f4918c-3d6f-4156-bee1-dc92f41a7f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-c31e1a04-55cd-4c59-9949-77de5ac71f96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1783660694-172.17.0.4-1597722462852:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46416,DS-eba8e1a7-6ffd-40fc-a4b2-5814a96238af,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-712f3104-5519-405d-8135-313a8d3abf93,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-9eb85b45-8e01-4aba-86ca-90acda464b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-bf05bcca-c569-416b-8b26-3f84cfe63ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-533e99e5-e46a-47ba-8eff-eecf311d9fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-594359d6-47fd-42e7-a5bb-eb0ace35ccdf,DISK], DatanodeInfoWithStorage[127.0.0.1:45758,DS-06f4918c-3d6f-4156-bee1-dc92f41a7f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-c31e1a04-55cd-4c59-9949-77de5ac71f96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-715798426-172.17.0.4-1597722980093:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41123,DS-1bc1d118-416c-4db9-b9a1-dea7d5d69821,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-2eb8cb5e-b549-448a-a875-d630d731326d,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-65751f55-c911-4c5d-8238-74df07cc5b87,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-0f928bf4-3778-49b8-98b1-b9be248fe910,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-81fdeb91-3518-4970-b226-bba63ecfa33c,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-dcec571b-537b-4c18-b8a8-93b851b63bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-3031ccb8-b44e-4d8c-999a-5765c6709174,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-423452d8-1a84-4b51-9b7d-93b5a8afc93c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-715798426-172.17.0.4-1597722980093:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41123,DS-1bc1d118-416c-4db9-b9a1-dea7d5d69821,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-2eb8cb5e-b549-448a-a875-d630d731326d,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-65751f55-c911-4c5d-8238-74df07cc5b87,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-0f928bf4-3778-49b8-98b1-b9be248fe910,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-81fdeb91-3518-4970-b226-bba63ecfa33c,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-dcec571b-537b-4c18-b8a8-93b851b63bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-3031ccb8-b44e-4d8c-999a-5765c6709174,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-423452d8-1a84-4b51-9b7d-93b5a8afc93c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-667283608-172.17.0.4-1597723020987:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33094,DS-daedf87d-ffff-478b-8bbb-dfe60a55c5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-ac74c311-3d31-4f54-ac1a-21c89bcbfef6,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-d01487af-d235-4b2b-b934-3ba4d72bbbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-b72950c3-afb2-4717-a1ce-f4f688f9c23c,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-8af64a6e-9846-4494-b659-b6141e181d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-372339f9-5847-4a2d-a80b-baebd2670f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-b08e9e7a-0e93-4cf4-b0dc-075ce1715898,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-7562e5c6-9fac-4330-bcbf-f4ecdfc47457,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-667283608-172.17.0.4-1597723020987:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33094,DS-daedf87d-ffff-478b-8bbb-dfe60a55c5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-ac74c311-3d31-4f54-ac1a-21c89bcbfef6,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-d01487af-d235-4b2b-b934-3ba4d72bbbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-b72950c3-afb2-4717-a1ce-f4f688f9c23c,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-8af64a6e-9846-4494-b659-b6141e181d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-372339f9-5847-4a2d-a80b-baebd2670f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-b08e9e7a-0e93-4cf4-b0dc-075ce1715898,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-7562e5c6-9fac-4330-bcbf-f4ecdfc47457,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696442543-172.17.0.4-1597723529286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35922,DS-f5539958-56e5-47f6-a39c-4775281678af,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-22da74de-3ebb-44fa-b607-3c4679dd9f63,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-e8c7887a-7bfd-40bd-952b-0ca312ede1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-3d958078-9b9c-47d6-87c8-545831bb8eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-8cf4747d-fb93-4f63-b27c-2ee90efc3844,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-154225d0-5811-4452-a967-1b9af913d11f,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-f9fb0083-39cc-4661-a496-d2e01b3df91a,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-98c77d3a-9efb-4e58-a47a-0ce32bfb4344,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696442543-172.17.0.4-1597723529286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35922,DS-f5539958-56e5-47f6-a39c-4775281678af,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-22da74de-3ebb-44fa-b607-3c4679dd9f63,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-e8c7887a-7bfd-40bd-952b-0ca312ede1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-3d958078-9b9c-47d6-87c8-545831bb8eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-8cf4747d-fb93-4f63-b27c-2ee90efc3844,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-154225d0-5811-4452-a967-1b9af913d11f,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-f9fb0083-39cc-4661-a496-d2e01b3df91a,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-98c77d3a-9efb-4e58-a47a-0ce32bfb4344,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1582451697-172.17.0.4-1597724059120:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35364,DS-ca6dd6d1-68a0-4ebe-8164-6ece4f31baa7,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-949ac75a-7d16-4113-a81f-18861d858cec,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-588231da-8220-4185-bf14-c851855a31af,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-0a8b5f95-f9ab-4882-b71b-3df8c337ac0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-3a90f2e7-237f-49f3-9c59-15f9a9e7df2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-b7f475be-7c3f-4ed3-8a65-4e833e4aed1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-2cccf5a3-696e-4527-a3d8-db791f830133,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-36bb26d5-40f4-41ff-bec5-fb59e34db5bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1582451697-172.17.0.4-1597724059120:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35364,DS-ca6dd6d1-68a0-4ebe-8164-6ece4f31baa7,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-949ac75a-7d16-4113-a81f-18861d858cec,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-588231da-8220-4185-bf14-c851855a31af,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-0a8b5f95-f9ab-4882-b71b-3df8c337ac0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-3a90f2e7-237f-49f3-9c59-15f9a9e7df2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-b7f475be-7c3f-4ed3-8a65-4e833e4aed1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-2cccf5a3-696e-4527-a3d8-db791f830133,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-36bb26d5-40f4-41ff-bec5-fb59e34db5bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1402367227-172.17.0.4-1597725164838:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40173,DS-30590c37-79c3-4dee-a99d-35d9a52898d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-6ffadd62-4556-47f8-8968-c7fbc33b9b31,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-4c098a6c-4cf0-4663-816d-3932c4826b58,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-74d33eaf-59da-4445-a161-5c7e62ce8de8,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-ee20e8c9-6845-4ba4-b7ab-1c6fba2396b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-bc75a234-1ccb-462c-b7ca-08daf5bd5a25,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-a94d09e8-bcd2-42ef-9e3c-f2c532760971,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-338e2d05-d2a0-4aa4-b41e-7f6abba56661,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1402367227-172.17.0.4-1597725164838:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40173,DS-30590c37-79c3-4dee-a99d-35d9a52898d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-6ffadd62-4556-47f8-8968-c7fbc33b9b31,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-4c098a6c-4cf0-4663-816d-3932c4826b58,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-74d33eaf-59da-4445-a161-5c7e62ce8de8,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-ee20e8c9-6845-4ba4-b7ab-1c6fba2396b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-bc75a234-1ccb-462c-b7ca-08daf5bd5a25,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-a94d09e8-bcd2-42ef-9e3c-f2c532760971,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-338e2d05-d2a0-4aa4-b41e-7f6abba56661,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1662294553-172.17.0.4-1597725317956:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44086,DS-d189e3f4-6b87-4284-a920-bc41cbb34037,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-45050d25-06b0-4dc8-91cc-df37a0da7ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-31f4b8d0-e5a6-4150-9f78-6475529b08cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-4a15ded0-4566-47b8-bdc3-546fd14d1bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-6768b6bc-e9ff-4723-a4b3-767e291189db,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-cd143efd-7e4e-453a-8145-6a1d3e4fdbff,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-2c696a29-2d4c-45a2-86bd-75c2ec06d098,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-7b003d09-2fa9-4043-87cd-b71035bdf151,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1662294553-172.17.0.4-1597725317956:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44086,DS-d189e3f4-6b87-4284-a920-bc41cbb34037,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-45050d25-06b0-4dc8-91cc-df37a0da7ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-31f4b8d0-e5a6-4150-9f78-6475529b08cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-4a15ded0-4566-47b8-bdc3-546fd14d1bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-6768b6bc-e9ff-4723-a4b3-767e291189db,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-cd143efd-7e4e-453a-8145-6a1d3e4fdbff,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-2c696a29-2d4c-45a2-86bd-75c2ec06d098,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-7b003d09-2fa9-4043-87cd-b71035bdf151,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-896391700-172.17.0.4-1597725401611:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44707,DS-1a48ba51-faeb-4fed-934b-a66df0ab87ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-740bda27-387b-4eba-8a3c-4e99ec0edf36,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-676fc388-a198-497a-bfc5-3e916b1a6c50,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-eb703d4e-9eb9-4fab-b17c-f3c74eaedcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-081116e7-bdd1-4c0d-af23-1e5e05e3108b,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-7a803412-8c60-4083-9994-24e08aa3eb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-3df63a92-d894-4fd5-bd37-1795342e15ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-f7a0718b-4515-475e-9421-1eed2b15a334,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-896391700-172.17.0.4-1597725401611:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44707,DS-1a48ba51-faeb-4fed-934b-a66df0ab87ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-740bda27-387b-4eba-8a3c-4e99ec0edf36,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-676fc388-a198-497a-bfc5-3e916b1a6c50,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-eb703d4e-9eb9-4fab-b17c-f3c74eaedcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-081116e7-bdd1-4c0d-af23-1e5e05e3108b,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-7a803412-8c60-4083-9994-24e08aa3eb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-3df63a92-d894-4fd5-bd37-1795342e15ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-f7a0718b-4515-475e-9421-1eed2b15a334,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5902
