reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 1800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 1800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-984831347-172.17.0.13-1597418075958:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45876,DS-932beb39-ce22-4d37-b97c-6cee6dbb7e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-6fd4b444-4a75-4ae8-904e-ee2a50c56c10,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-457df543-102d-4808-9edc-c6a0acf74185,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-26915ada-7a1b-48ef-aeb7-fe9988cebe36,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-22788552-1cbf-4e30-99ee-3f66363a31a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-6a46804d-29d9-4cbd-afcb-3cd814d32c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-3cbe62e5-638c-4181-b5b5-961130a3660a,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-9f44e4aa-fdb6-4b89-b0d2-4bac9be2be74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-984831347-172.17.0.13-1597418075958:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45876,DS-932beb39-ce22-4d37-b97c-6cee6dbb7e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-6fd4b444-4a75-4ae8-904e-ee2a50c56c10,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-457df543-102d-4808-9edc-c6a0acf74185,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-26915ada-7a1b-48ef-aeb7-fe9988cebe36,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-22788552-1cbf-4e30-99ee-3f66363a31a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-6a46804d-29d9-4cbd-afcb-3cd814d32c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-3cbe62e5-638c-4181-b5b5-961130a3660a,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-9f44e4aa-fdb6-4b89-b0d2-4bac9be2be74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 1800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597749322-172.17.0.13-1597418150036:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34968,DS-44e56373-9d5f-4bb6-b7aa-6b6514ff2284,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-7839008f-0464-42f6-9ba5-6cef57859821,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-e614c8db-65f0-40b7-a701-e7b44ab528ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-90966b55-fa71-4682-aeea-2dd0ea143d72,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-632a7bfc-1bee-44a3-bb2f-aee8492f0324,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-80a08439-16a9-43b6-bfa3-ccb1519584f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-a1d10b35-2f72-45e6-a46f-8bccc4bae3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-610c828f-dc2f-4a0c-a5a8-86a853f64965,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597749322-172.17.0.13-1597418150036:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34968,DS-44e56373-9d5f-4bb6-b7aa-6b6514ff2284,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-7839008f-0464-42f6-9ba5-6cef57859821,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-e614c8db-65f0-40b7-a701-e7b44ab528ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-90966b55-fa71-4682-aeea-2dd0ea143d72,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-632a7bfc-1bee-44a3-bb2f-aee8492f0324,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-80a08439-16a9-43b6-bfa3-ccb1519584f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-a1d10b35-2f72-45e6-a46f-8bccc4bae3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-610c828f-dc2f-4a0c-a5a8-86a853f64965,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 1800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-77892081-172.17.0.13-1597418265671:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40043,DS-b9e27562-912b-4983-9c28-a3038fc3b320,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-b4703c50-6007-4d13-b220-6db063732be0,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-a629f847-b7e5-4339-a694-aed43d5c34bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-b17dc49d-0d8b-4f76-a527-e020c2abde24,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-9b69c307-a6d5-4d7b-9dcf-6d94053c3e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-dc52431b-d209-40fd-9640-7b3df2df48fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-38db352c-24ae-429a-8c96-b8eab5815e53,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-94e1b042-c801-47c9-b819-cff097822c60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-77892081-172.17.0.13-1597418265671:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40043,DS-b9e27562-912b-4983-9c28-a3038fc3b320,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-b4703c50-6007-4d13-b220-6db063732be0,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-a629f847-b7e5-4339-a694-aed43d5c34bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-b17dc49d-0d8b-4f76-a527-e020c2abde24,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-9b69c307-a6d5-4d7b-9dcf-6d94053c3e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-dc52431b-d209-40fd-9640-7b3df2df48fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-38db352c-24ae-429a-8c96-b8eab5815e53,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-94e1b042-c801-47c9-b819-cff097822c60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 1800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1972561239-172.17.0.13-1597418378543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37872,DS-1597bc08-cf34-44f9-b002-75f3fda0272a,DISK], DatanodeInfoWithStorage[127.0.0.1:34032,DS-a227b4d2-280c-49a5-be61-a19f3b83afdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-a16674e4-add6-4c1e-b621-fdc492b4521d,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-4608bf0e-a1e5-4b7b-b9ed-b3b7031a4435,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-f3569985-c371-4974-bd65-5e95fff71b57,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-cba9475d-b612-40b9-adc7-c322ae51bde3,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-db38c2b4-ce2a-493f-b286-867dd5e6b482,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-f3c89d6e-de74-40c4-8329-f148e4be7391,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1972561239-172.17.0.13-1597418378543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37872,DS-1597bc08-cf34-44f9-b002-75f3fda0272a,DISK], DatanodeInfoWithStorage[127.0.0.1:34032,DS-a227b4d2-280c-49a5-be61-a19f3b83afdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-a16674e4-add6-4c1e-b621-fdc492b4521d,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-4608bf0e-a1e5-4b7b-b9ed-b3b7031a4435,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-f3569985-c371-4974-bd65-5e95fff71b57,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-cba9475d-b612-40b9-adc7-c322ae51bde3,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-db38c2b4-ce2a-493f-b286-867dd5e6b482,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-f3c89d6e-de74-40c4-8329-f148e4be7391,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 1800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-242433796-172.17.0.13-1597418411313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37759,DS-8af8cb9c-8e47-413c-a042-728423553be3,DISK], DatanodeInfoWithStorage[127.0.0.1:45831,DS-f6bdc639-d33c-4f0d-9f2a-910b0fc3b637,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-ef5da841-af52-4f11-a49a-10718f3088cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-b6098901-2cc5-4237-b296-e63f01b044dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-8bdbd01c-bf3a-4157-91f3-35948eefa9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-7292a386-0641-47b4-a8fd-fc23780e6d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-9a102fbc-7f9c-44b9-b9eb-5d48a1ac8732,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-af22224a-fe47-4597-a428-66f74dac131a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-242433796-172.17.0.13-1597418411313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37759,DS-8af8cb9c-8e47-413c-a042-728423553be3,DISK], DatanodeInfoWithStorage[127.0.0.1:45831,DS-f6bdc639-d33c-4f0d-9f2a-910b0fc3b637,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-ef5da841-af52-4f11-a49a-10718f3088cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-b6098901-2cc5-4237-b296-e63f01b044dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-8bdbd01c-bf3a-4157-91f3-35948eefa9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-7292a386-0641-47b4-a8fd-fc23780e6d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-9a102fbc-7f9c-44b9-b9eb-5d48a1ac8732,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-af22224a-fe47-4597-a428-66f74dac131a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 1800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1456162705-172.17.0.13-1597419431974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38816,DS-0ee5914b-c0e8-4d7e-9077-1d7dde434350,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-fa757bc2-58bd-442f-93a0-3888cf62da0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-ea0d45da-bf31-4781-9b5d-6e308766c66e,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-5cb7adca-4d0b-4d96-93b1-086e63cc22e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-2bf634b5-fea4-44c4-9373-7ae994acd119,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-505b6a4d-19b3-46e4-9242-3457fb41547c,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-257f45a2-46b5-4e3b-b865-3533f87fd05d,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-5a29f8a6-d394-4ed8-9ffa-af5d6e7d99a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1456162705-172.17.0.13-1597419431974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38816,DS-0ee5914b-c0e8-4d7e-9077-1d7dde434350,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-fa757bc2-58bd-442f-93a0-3888cf62da0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-ea0d45da-bf31-4781-9b5d-6e308766c66e,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-5cb7adca-4d0b-4d96-93b1-086e63cc22e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-2bf634b5-fea4-44c4-9373-7ae994acd119,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-505b6a4d-19b3-46e4-9242-3457fb41547c,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-257f45a2-46b5-4e3b-b865-3533f87fd05d,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-5a29f8a6-d394-4ed8-9ffa-af5d6e7d99a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 1800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-955545152-172.17.0.13-1597420026304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44686,DS-8104b00a-c728-4f49-bcd3-564c5c992115,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-97e71742-02f8-428c-9b3a-0ae7ccfddfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-da0a8a95-e53c-4c0a-b6ee-f5b0b14a1841,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-910008fd-44fa-48d1-9d65-d28be72f913d,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-55967111-5e80-4574-bee9-c8d523c23c97,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-f1b8d598-b093-47ee-b2c3-76971a99dce8,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-4e4e776b-887c-4d7a-81ca-a42a483f02d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-ab571d4a-7cab-4c58-9159-aead79725058,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-955545152-172.17.0.13-1597420026304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44686,DS-8104b00a-c728-4f49-bcd3-564c5c992115,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-97e71742-02f8-428c-9b3a-0ae7ccfddfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-da0a8a95-e53c-4c0a-b6ee-f5b0b14a1841,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-910008fd-44fa-48d1-9d65-d28be72f913d,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-55967111-5e80-4574-bee9-c8d523c23c97,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-f1b8d598-b093-47ee-b2c3-76971a99dce8,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-4e4e776b-887c-4d7a-81ca-a42a483f02d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-ab571d4a-7cab-4c58-9159-aead79725058,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 1800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-219333385-172.17.0.13-1597420173538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38073,DS-1ac2952f-7a31-4ae5-a0f0-e1280761728b,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-252492fc-70dc-48a9-b246-1537711b83c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-691aa8ad-554a-4cdf-92f3-ba8705da197c,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-23ada110-caf4-423b-a02e-09ac8490b89a,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-2debd616-4bef-44ec-93a7-b264ab4b3c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-8609028c-adca-44ce-88c4-95cfa36d7b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-ca6ba7ae-ffe8-4599-ac46-c7441ffaf860,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-2ac4b6cc-d180-485a-b965-e349de673333,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-219333385-172.17.0.13-1597420173538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38073,DS-1ac2952f-7a31-4ae5-a0f0-e1280761728b,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-252492fc-70dc-48a9-b246-1537711b83c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-691aa8ad-554a-4cdf-92f3-ba8705da197c,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-23ada110-caf4-423b-a02e-09ac8490b89a,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-2debd616-4bef-44ec-93a7-b264ab4b3c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-8609028c-adca-44ce-88c4-95cfa36d7b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-ca6ba7ae-ffe8-4599-ac46-c7441ffaf860,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-2ac4b6cc-d180-485a-b965-e349de673333,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 1800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1454759968-172.17.0.13-1597420379778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33291,DS-ff30b300-9854-49fa-a409-82234dbb4890,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-2254a3c9-e19a-4de0-a038-ca23262381d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-009fdde6-5456-4977-89ca-bbfbeacafc8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-7e63831f-381b-4b28-9d2b-a137f3c3df08,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-edcae4be-3a28-4b56-beea-a70150d09a35,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-829c87b8-cbd2-440f-80a1-bc787262b341,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-aff88ca9-c1a7-4a16-8bac-0b5b5cbeb776,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-c564c225-196f-4ac3-970d-0a325b3c248f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1454759968-172.17.0.13-1597420379778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33291,DS-ff30b300-9854-49fa-a409-82234dbb4890,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-2254a3c9-e19a-4de0-a038-ca23262381d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-009fdde6-5456-4977-89ca-bbfbeacafc8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-7e63831f-381b-4b28-9d2b-a137f3c3df08,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-edcae4be-3a28-4b56-beea-a70150d09a35,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-829c87b8-cbd2-440f-80a1-bc787262b341,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-aff88ca9-c1a7-4a16-8bac-0b5b5cbeb776,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-c564c225-196f-4ac3-970d-0a325b3c248f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 1800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-499924660-172.17.0.13-1597421196219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44949,DS-6235863f-95ac-4343-830b-ebcd07763f37,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-a508c6af-f7cf-4c4e-882a-f517dac8b565,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-0494e45f-15be-4ddd-945f-fe28d80fcbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-37eb7095-587a-4071-8104-b6274c21615c,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-1d413092-48ff-4ecf-914e-187708ed3344,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-2ebbe10d-1c55-4ce8-aca5-ba126726eef4,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-651afc07-fb4b-448b-96b7-d28728ff4109,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-aefe431a-a890-4a0e-a68d-1aad2ad716ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-499924660-172.17.0.13-1597421196219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44949,DS-6235863f-95ac-4343-830b-ebcd07763f37,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-a508c6af-f7cf-4c4e-882a-f517dac8b565,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-0494e45f-15be-4ddd-945f-fe28d80fcbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-37eb7095-587a-4071-8104-b6274c21615c,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-1d413092-48ff-4ecf-914e-187708ed3344,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-2ebbe10d-1c55-4ce8-aca5-ba126726eef4,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-651afc07-fb4b-448b-96b7-d28728ff4109,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-aefe431a-a890-4a0e-a68d-1aad2ad716ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 1800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1861808390-172.17.0.13-1597421312769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45549,DS-4a69cd2d-90ed-4e51-9ac0-d639645f01a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-1c0c294f-f7b7-4e91-b3a2-10ff82f834c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-9fa0f185-ad2e-40b1-808a-d064bf2b71d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-52b5c2c0-79d5-4828-9431-7a88c55f9df7,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-05316479-61ee-47ec-aa44-047c5ba871e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-1f2405fc-0985-44f2-898f-2bd31945cacd,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-1c88dbac-087c-45b3-9b03-c2acf6a4c8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-b0ff2ed1-6f10-4d7f-85f6-adc719c9db51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1861808390-172.17.0.13-1597421312769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45549,DS-4a69cd2d-90ed-4e51-9ac0-d639645f01a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-1c0c294f-f7b7-4e91-b3a2-10ff82f834c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-9fa0f185-ad2e-40b1-808a-d064bf2b71d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-52b5c2c0-79d5-4828-9431-7a88c55f9df7,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-05316479-61ee-47ec-aa44-047c5ba871e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-1f2405fc-0985-44f2-898f-2bd31945cacd,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-1c88dbac-087c-45b3-9b03-c2acf6a4c8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-b0ff2ed1-6f10-4d7f-85f6-adc719c9db51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 1800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-702436897-172.17.0.13-1597421509828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45140,DS-f1fefaa2-1f9f-4eff-a262-4f5536abeb46,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-d7103368-e57d-4ff9-abf9-be3114992a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-e4596100-c76f-485d-83c0-09f5d5ac8317,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-edfc461e-5a28-4bcc-bd24-65851859b827,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-7e4f8a41-58b8-47e4-8f1c-8da7ef5410dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-29b6b8e2-9613-4bb5-91f8-78bdeb932909,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-1fa39619-c517-43d9-8282-236b894c9d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-539bceca-bc38-46ee-8151-926508a195f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-702436897-172.17.0.13-1597421509828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45140,DS-f1fefaa2-1f9f-4eff-a262-4f5536abeb46,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-d7103368-e57d-4ff9-abf9-be3114992a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-e4596100-c76f-485d-83c0-09f5d5ac8317,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-edfc461e-5a28-4bcc-bd24-65851859b827,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-7e4f8a41-58b8-47e4-8f1c-8da7ef5410dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-29b6b8e2-9613-4bb5-91f8-78bdeb932909,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-1fa39619-c517-43d9-8282-236b894c9d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-539bceca-bc38-46ee-8151-926508a195f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 1800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-66926272-172.17.0.13-1597421580286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36585,DS-89661b90-9aca-4809-a353-03910d460fee,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-97605c43-9d4c-4524-bea5-5a1603587920,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-950682c0-5e60-47dd-8050-fdc6b067ac97,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-bfd07999-c9c1-43e1-a790-95ee87530a15,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-e4c0484c-d320-4521-9bd1-9a34a4e923fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-0f4536fb-292e-45bd-8c9b-4aa6abeecea4,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-fddf2ce6-858d-43fa-bf03-2ab9d9839520,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-37c938df-9fca-4013-9ce9-ee6354ae93ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-66926272-172.17.0.13-1597421580286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36585,DS-89661b90-9aca-4809-a353-03910d460fee,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-97605c43-9d4c-4524-bea5-5a1603587920,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-950682c0-5e60-47dd-8050-fdc6b067ac97,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-bfd07999-c9c1-43e1-a790-95ee87530a15,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-e4c0484c-d320-4521-9bd1-9a34a4e923fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-0f4536fb-292e-45bd-8c9b-4aa6abeecea4,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-fddf2ce6-858d-43fa-bf03-2ab9d9839520,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-37c938df-9fca-4013-9ce9-ee6354ae93ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 1800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-722561803-172.17.0.13-1597421621851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41344,DS-be2cb26c-d790-420a-bf88-c258dbcd6f65,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-f19d1325-c49a-4378-971d-698af1138bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-14e94208-c30d-4fb9-9151-1d3b504809b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-5faf69ab-f374-410c-9026-eed8cf39532d,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-5f5373f5-1737-4509-8c60-14f7308dc2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-db42039e-b78d-4e31-90da-ac859bc1fc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-daac5cfe-b1c9-4c5a-b697-0b5f0d316aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-0356c27d-884c-45bd-946e-b5f7a479c59c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-722561803-172.17.0.13-1597421621851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41344,DS-be2cb26c-d790-420a-bf88-c258dbcd6f65,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-f19d1325-c49a-4378-971d-698af1138bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-14e94208-c30d-4fb9-9151-1d3b504809b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-5faf69ab-f374-410c-9026-eed8cf39532d,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-5f5373f5-1737-4509-8c60-14f7308dc2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-db42039e-b78d-4e31-90da-ac859bc1fc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-daac5cfe-b1c9-4c5a-b697-0b5f0d316aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-0356c27d-884c-45bd-946e-b5f7a479c59c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 1800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171461934-172.17.0.13-1597421665058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36035,DS-191f7c69-379a-4880-97a5-445f9a8bf660,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-2559b8bb-4644-456c-a773-7cc3c4af27da,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-a8a46c39-3ac1-4197-bcd1-ee442608e9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-45e55e09-710a-49a8-b76f-557c26e1234c,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-d55111d0-6a31-470b-b1c3-02986c571b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-ddcd7532-364a-4fa3-949b-60941e36dab2,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-41c170f9-c9a6-420d-8eeb-c11cf67cd072,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-2c84173a-e2c5-4781-b589-20007823fb3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171461934-172.17.0.13-1597421665058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36035,DS-191f7c69-379a-4880-97a5-445f9a8bf660,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-2559b8bb-4644-456c-a773-7cc3c4af27da,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-a8a46c39-3ac1-4197-bcd1-ee442608e9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-45e55e09-710a-49a8-b76f-557c26e1234c,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-d55111d0-6a31-470b-b1c3-02986c571b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-ddcd7532-364a-4fa3-949b-60941e36dab2,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-41c170f9-c9a6-420d-8eeb-c11cf67cd072,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-2c84173a-e2c5-4781-b589-20007823fb3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 1800000
v2: 1800
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2099366726-172.17.0.13-1597422162687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46728,DS-c04c7def-7a38-4df8-90ec-450ab6961e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-bff13c40-3ea6-413c-9da4-0a58e1631e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-6ace619d-e13b-460f-9da8-bbfa9d3da400,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-6a5aa918-959c-4dfd-8991-6f7028d576ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-c119602d-5ce8-44a1-a95c-47980d0be1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-82d7990a-c403-4e7a-8acf-20c84d3aa8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-206b9378-eeee-46be-b377-d53c5a41929f,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-ac577f84-b9e8-4e8b-8663-9a0e919fd0ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2099366726-172.17.0.13-1597422162687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46728,DS-c04c7def-7a38-4df8-90ec-450ab6961e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-bff13c40-3ea6-413c-9da4-0a58e1631e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-6ace619d-e13b-460f-9da8-bbfa9d3da400,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-6a5aa918-959c-4dfd-8991-6f7028d576ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-c119602d-5ce8-44a1-a95c-47980d0be1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-82d7990a-c403-4e7a-8acf-20c84d3aa8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-206b9378-eeee-46be-b377-d53c5a41929f,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-ac577f84-b9e8-4e8b-8663-9a0e919fd0ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5554
