reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-761846675-172.17.0.7-1597731454940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42888,DS-26e70446-23e3-4f67-8a21-f83dda52d12c,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-9bdb1fa9-0f2f-4cbe-9fdb-5a27d12ee81b,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-98e9aede-d0ff-4d00-b86c-3548ca74f9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-3721492e-35e6-4b84-b792-0df70916f383,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-ed3df0f1-c3ff-4d98-8887-7b4abeea3b18,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-34ec9e03-9e88-4247-acd1-a86e62aaa302,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-df90d3f4-0f2d-4791-8851-0eeab3452f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-0545adae-dc6d-47dd-86ca-584c94d4e77f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-761846675-172.17.0.7-1597731454940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42888,DS-26e70446-23e3-4f67-8a21-f83dda52d12c,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-9bdb1fa9-0f2f-4cbe-9fdb-5a27d12ee81b,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-98e9aede-d0ff-4d00-b86c-3548ca74f9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-3721492e-35e6-4b84-b792-0df70916f383,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-ed3df0f1-c3ff-4d98-8887-7b4abeea3b18,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-34ec9e03-9e88-4247-acd1-a86e62aaa302,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-df90d3f4-0f2d-4791-8851-0eeab3452f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-0545adae-dc6d-47dd-86ca-584c94d4e77f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1999391887-172.17.0.7-1597731859392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42995,DS-ad0c3967-3b3a-4113-81ee-8bb5b1ced2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41545,DS-47e98b08-8ab2-41b5-818b-7b54b81664be,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-80b56444-7345-4cba-84cf-0838a000e94c,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-f94cf077-e0cb-4ce3-adef-97ac301de39c,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-4bcd25dc-819e-40e4-aef7-1ff3b859dfc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-e55228ac-14b7-425a-a9bf-9a565532f4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-0af79ae2-db50-4923-8a23-93424dc5f75c,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-977e82b9-dcc1-4257-a7e4-80ed28ef7b12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1999391887-172.17.0.7-1597731859392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42995,DS-ad0c3967-3b3a-4113-81ee-8bb5b1ced2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41545,DS-47e98b08-8ab2-41b5-818b-7b54b81664be,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-80b56444-7345-4cba-84cf-0838a000e94c,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-f94cf077-e0cb-4ce3-adef-97ac301de39c,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-4bcd25dc-819e-40e4-aef7-1ff3b859dfc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-e55228ac-14b7-425a-a9bf-9a565532f4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-0af79ae2-db50-4923-8a23-93424dc5f75c,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-977e82b9-dcc1-4257-a7e4-80ed28ef7b12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-575633534-172.17.0.7-1597732004838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40656,DS-a672dda8-133f-4633-a08b-7a78b9d8fb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-4f28d518-9ebd-412c-b879-b2ba41d59857,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-b1bf4617-fa8c-47ad-9961-228a6e7a546b,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-021c1981-0c6f-49b7-80d4-22726427e7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-3e10e1d2-f61f-43cb-be31-b44b5d696e73,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-b4652d04-b1ae-4138-aef6-d0f6fe218999,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-7c4d640a-18b9-46e3-9be9-c004ffad85c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-44fb15d3-6345-430a-bb81-6108527f5e1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-575633534-172.17.0.7-1597732004838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40656,DS-a672dda8-133f-4633-a08b-7a78b9d8fb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-4f28d518-9ebd-412c-b879-b2ba41d59857,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-b1bf4617-fa8c-47ad-9961-228a6e7a546b,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-021c1981-0c6f-49b7-80d4-22726427e7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-3e10e1d2-f61f-43cb-be31-b44b5d696e73,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-b4652d04-b1ae-4138-aef6-d0f6fe218999,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-7c4d640a-18b9-46e3-9be9-c004ffad85c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-44fb15d3-6345-430a-bb81-6108527f5e1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-596770719-172.17.0.7-1597732714449:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38197,DS-d3c15e5c-f9bd-4575-a553-f6b035ae3aef,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-b9d56a57-803b-45c0-a2b0-7094f29a37c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-bd69a560-4376-4e91-9e5b-4b9874b46168,DISK], DatanodeInfoWithStorage[127.0.0.1:41796,DS-7c71c975-b4ec-420d-bcba-67c1747f5690,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-215d7555-013d-439e-bc3d-60e2e48d2877,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-0e60174b-3d97-4e19-ac44-ffb6de0c8eac,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-c225de66-2d4b-4d5a-96c8-25589253c797,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-2a2e7efa-175f-40af-b629-f641106f1ff7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-596770719-172.17.0.7-1597732714449:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38197,DS-d3c15e5c-f9bd-4575-a553-f6b035ae3aef,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-b9d56a57-803b-45c0-a2b0-7094f29a37c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-bd69a560-4376-4e91-9e5b-4b9874b46168,DISK], DatanodeInfoWithStorage[127.0.0.1:41796,DS-7c71c975-b4ec-420d-bcba-67c1747f5690,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-215d7555-013d-439e-bc3d-60e2e48d2877,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-0e60174b-3d97-4e19-ac44-ffb6de0c8eac,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-c225de66-2d4b-4d5a-96c8-25589253c797,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-2a2e7efa-175f-40af-b629-f641106f1ff7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1024238392-172.17.0.7-1597732923508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38434,DS-714e246e-aba0-4f69-a1e2-766a4b94d363,DISK], DatanodeInfoWithStorage[127.0.0.1:33514,DS-052d1849-af0b-4462-b601-6166c9b8ae3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-4fc6ef6f-7679-4b2f-915c-ee868dc9f880,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-d33929c9-7a2e-4c43-b81a-360bd03dc4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-fe2a7b6e-d10b-4505-ae14-a8de14f5f203,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-c37c6805-29a1-4d32-a885-991172f39007,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-9b533e1b-9415-46a9-a346-0de7594c3f35,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-82f3ae72-6e00-47e6-bd2f-377cf8d217f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1024238392-172.17.0.7-1597732923508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38434,DS-714e246e-aba0-4f69-a1e2-766a4b94d363,DISK], DatanodeInfoWithStorage[127.0.0.1:33514,DS-052d1849-af0b-4462-b601-6166c9b8ae3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-4fc6ef6f-7679-4b2f-915c-ee868dc9f880,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-d33929c9-7a2e-4c43-b81a-360bd03dc4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-fe2a7b6e-d10b-4505-ae14-a8de14f5f203,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-c37c6805-29a1-4d32-a885-991172f39007,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-9b533e1b-9415-46a9-a346-0de7594c3f35,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-82f3ae72-6e00-47e6-bd2f-377cf8d217f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1247449187-172.17.0.7-1597733537829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46810,DS-26011e4f-7c43-41a7-8d9e-b94a335a5cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-00df86c6-1ef8-42cc-a504-554a6ace2e11,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-be36921d-c57d-4243-9985-cc72930b9ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-2bfbcee1-acdb-4e79-b34d-b1a8a626d38f,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-c20a38b5-53a7-492d-a241-b45431e2b94a,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-f4804c7c-4105-4fe3-a06c-8d18a4fadef9,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-9eb07686-93d0-440d-8009-28bd6ff532fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-34bbacbf-bd8d-43e9-8b20-b8c53bfe3d92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1247449187-172.17.0.7-1597733537829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46810,DS-26011e4f-7c43-41a7-8d9e-b94a335a5cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-00df86c6-1ef8-42cc-a504-554a6ace2e11,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-be36921d-c57d-4243-9985-cc72930b9ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-2bfbcee1-acdb-4e79-b34d-b1a8a626d38f,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-c20a38b5-53a7-492d-a241-b45431e2b94a,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-f4804c7c-4105-4fe3-a06c-8d18a4fadef9,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-9eb07686-93d0-440d-8009-28bd6ff532fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-34bbacbf-bd8d-43e9-8b20-b8c53bfe3d92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-968569099-172.17.0.7-1597733569696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38227,DS-ba421e56-eef3-48cc-991b-c0dddeb14307,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-555ed810-d40f-4c9d-b2ea-32783f5657ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-65c918b4-5d8f-4251-8936-28d83b77664b,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-36fe58a9-5ad5-42d6-85f6-8e45f72efab9,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-83f313c7-1e84-4675-93d1-2443ba26d3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-856ef895-10b9-4e42-8016-22ed0f913ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-4856616c-1d53-4fc7-bcb3-fbb7c4004ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-48d8e9cc-c881-4ed2-a256-cca8fc1dcde1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-968569099-172.17.0.7-1597733569696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38227,DS-ba421e56-eef3-48cc-991b-c0dddeb14307,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-555ed810-d40f-4c9d-b2ea-32783f5657ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-65c918b4-5d8f-4251-8936-28d83b77664b,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-36fe58a9-5ad5-42d6-85f6-8e45f72efab9,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-83f313c7-1e84-4675-93d1-2443ba26d3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-856ef895-10b9-4e42-8016-22ed0f913ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-4856616c-1d53-4fc7-bcb3-fbb7c4004ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-48d8e9cc-c881-4ed2-a256-cca8fc1dcde1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1937073241-172.17.0.7-1597733680879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33785,DS-16355069-0c29-49bc-990c-bca2425e3167,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-dce1ed64-42d2-4843-96f3-0a621cc80512,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-029d0704-5ce5-432f-82c3-28926bf44852,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-df9eadf5-0f20-4fbd-8713-0cad1e3c51bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-f13fc890-5326-4954-a736-470b56c69caf,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-77eb4be6-ce68-42af-a6e3-e7788e891ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-e6942826-87ec-4fe7-8820-219387257bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-8a45d831-b41b-4b5d-9475-cb5a6d388c97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1937073241-172.17.0.7-1597733680879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33785,DS-16355069-0c29-49bc-990c-bca2425e3167,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-dce1ed64-42d2-4843-96f3-0a621cc80512,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-029d0704-5ce5-432f-82c3-28926bf44852,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-df9eadf5-0f20-4fbd-8713-0cad1e3c51bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-f13fc890-5326-4954-a736-470b56c69caf,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-77eb4be6-ce68-42af-a6e3-e7788e891ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-e6942826-87ec-4fe7-8820-219387257bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-8a45d831-b41b-4b5d-9475-cb5a6d388c97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1235724997-172.17.0.7-1597734444441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42291,DS-36c0ec66-e709-421b-87ce-6b6a7a04cc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-a83ec0b7-68b9-414e-9cc0-c34c24fb98ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-932ea94d-bc7c-4908-95ff-ddb0d25ff72a,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-dbf7b5ff-2081-472d-84ad-642c8497afdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-7b3e270e-2437-41cc-9e14-dca43b6c6b85,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-e89b6865-4278-4025-b422-913738b6e906,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-f88db5a6-d012-417f-a19c-2383f57807ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-724b9811-a8bc-4938-b31d-976b03cdd1d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1235724997-172.17.0.7-1597734444441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42291,DS-36c0ec66-e709-421b-87ce-6b6a7a04cc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-a83ec0b7-68b9-414e-9cc0-c34c24fb98ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-932ea94d-bc7c-4908-95ff-ddb0d25ff72a,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-dbf7b5ff-2081-472d-84ad-642c8497afdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-7b3e270e-2437-41cc-9e14-dca43b6c6b85,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-e89b6865-4278-4025-b422-913738b6e906,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-f88db5a6-d012-417f-a19c-2383f57807ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-724b9811-a8bc-4938-b31d-976b03cdd1d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-43764908-172.17.0.7-1597734553482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41263,DS-ff3122e5-3c3f-4c4e-9654-df85dc180687,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-ce5d58ca-12ae-44b9-8bb3-1d850ee07e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-ff2750eb-8c9e-4bbd-ab90-1a906ea6b77e,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-27bf44c7-69fa-4ccb-b4e5-73dd89d986a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-43f119e1-55dd-4989-a965-ebc41387ed22,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-6d783a95-e624-4f43-8a56-b94af158428b,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-032af7b0-7734-4173-9ee4-366bf925cea0,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-f4a09c0e-2703-41bd-8335-34b523524ee8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-43764908-172.17.0.7-1597734553482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41263,DS-ff3122e5-3c3f-4c4e-9654-df85dc180687,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-ce5d58ca-12ae-44b9-8bb3-1d850ee07e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-ff2750eb-8c9e-4bbd-ab90-1a906ea6b77e,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-27bf44c7-69fa-4ccb-b4e5-73dd89d986a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37801,DS-43f119e1-55dd-4989-a965-ebc41387ed22,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-6d783a95-e624-4f43-8a56-b94af158428b,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-032af7b0-7734-4173-9ee4-366bf925cea0,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-f4a09c0e-2703-41bd-8335-34b523524ee8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1044120272-172.17.0.7-1597734703323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36377,DS-281d9b1f-58b5-4f59-b33f-3dad0ba85d32,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-a5c16def-f3b4-42b2-9a0d-e96d538b2a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-52e8022a-89e4-441f-bfe0-eb67f9899649,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-30ec9840-a873-49b9-888b-921b5ca48081,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-e3cf599d-d6f5-49ea-82aa-f48d9ac2bafd,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-6716fbe5-dce4-4784-b3af-6068a7c438ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-91043894-34f9-4f6e-b17b-6cf802f4707e,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-41ee9195-0188-4d8e-b7d3-68e897c991ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1044120272-172.17.0.7-1597734703323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36377,DS-281d9b1f-58b5-4f59-b33f-3dad0ba85d32,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-a5c16def-f3b4-42b2-9a0d-e96d538b2a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-52e8022a-89e4-441f-bfe0-eb67f9899649,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-30ec9840-a873-49b9-888b-921b5ca48081,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-e3cf599d-d6f5-49ea-82aa-f48d9ac2bafd,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-6716fbe5-dce4-4784-b3af-6068a7c438ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-91043894-34f9-4f6e-b17b-6cf802f4707e,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-41ee9195-0188-4d8e-b7d3-68e897c991ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-653664971-172.17.0.7-1597735242806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42773,DS-92d3262e-ea21-4d76-9686-5ab9e18be4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-c61dc006-5ee6-4bd7-98b9-f36e5cf1ab50,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-b20be25b-0709-4129-9fed-3cab8e6cebe3,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-7dbf0622-7327-4a17-8451-9b9190fe611e,DISK], DatanodeInfoWithStorage[127.0.0.1:39019,DS-7a6e5372-ea26-4cb6-8822-7faffbdd234e,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-493586c5-f61f-4a6f-8682-235302f945fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-f019dc66-cbbe-4d62-9c3d-f65afe17e4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-a76e120a-d7cc-4a04-a07d-95cf4a2ab1b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-653664971-172.17.0.7-1597735242806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42773,DS-92d3262e-ea21-4d76-9686-5ab9e18be4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-c61dc006-5ee6-4bd7-98b9-f36e5cf1ab50,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-b20be25b-0709-4129-9fed-3cab8e6cebe3,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-7dbf0622-7327-4a17-8451-9b9190fe611e,DISK], DatanodeInfoWithStorage[127.0.0.1:39019,DS-7a6e5372-ea26-4cb6-8822-7faffbdd234e,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-493586c5-f61f-4a6f-8682-235302f945fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-f019dc66-cbbe-4d62-9c3d-f65afe17e4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-a76e120a-d7cc-4a04-a07d-95cf4a2ab1b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1442072597-172.17.0.7-1597735863559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46592,DS-7d14b29f-3575-4880-ae53-dc1bfdab5812,DISK], DatanodeInfoWithStorage[127.0.0.1:37321,DS-85bb5186-f4a5-4769-a4d1-f010b597a385,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-16327a4f-7edb-4a99-ad30-fe4510aa7b59,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-5b8f460e-c526-449a-b479-e4daaa42f54f,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-80db8cb1-8179-454b-9541-a74335da75d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-a0e96ed1-9f68-497b-9f86-1b28c6d81911,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-87849612-bddb-46db-8940-66287e48c0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-67f7948c-4f6c-4940-a097-8d0d127b816c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1442072597-172.17.0.7-1597735863559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46592,DS-7d14b29f-3575-4880-ae53-dc1bfdab5812,DISK], DatanodeInfoWithStorage[127.0.0.1:37321,DS-85bb5186-f4a5-4769-a4d1-f010b597a385,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-16327a4f-7edb-4a99-ad30-fe4510aa7b59,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-5b8f460e-c526-449a-b479-e4daaa42f54f,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-80db8cb1-8179-454b-9541-a74335da75d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-a0e96ed1-9f68-497b-9f86-1b28c6d81911,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-87849612-bddb-46db-8940-66287e48c0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-67f7948c-4f6c-4940-a097-8d0d127b816c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-282356460-172.17.0.7-1597736581422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43015,DS-463c2c7b-5172-419b-b4c2-d5553572f56c,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-7e9fc1b9-1089-4b94-b743-2ce29d0f4a11,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-1026f42f-7f60-427b-bd8b-fe13c817fd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-f7d89b01-1ffc-4a84-bfe1-ba3089bc3f54,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-5d6ce572-eae3-4316-8432-5c8658be1b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-75f84539-ffee-4965-a4db-6c2ce61da40f,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-0daec654-b16c-4802-b82a-58e8916277af,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-dc14eb9d-c1d7-4031-b781-b7dbd22dfac7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-282356460-172.17.0.7-1597736581422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43015,DS-463c2c7b-5172-419b-b4c2-d5553572f56c,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-7e9fc1b9-1089-4b94-b743-2ce29d0f4a11,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-1026f42f-7f60-427b-bd8b-fe13c817fd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-f7d89b01-1ffc-4a84-bfe1-ba3089bc3f54,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-5d6ce572-eae3-4316-8432-5c8658be1b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-75f84539-ffee-4965-a4db-6c2ce61da40f,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-0daec654-b16c-4802-b82a-58e8916277af,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-dc14eb9d-c1d7-4031-b781-b7dbd22dfac7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5480
