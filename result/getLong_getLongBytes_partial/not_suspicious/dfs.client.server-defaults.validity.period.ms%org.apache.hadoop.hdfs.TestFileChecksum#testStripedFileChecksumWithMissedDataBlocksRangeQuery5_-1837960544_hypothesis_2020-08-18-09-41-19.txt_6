reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1522205575-172.17.0.4-1597744042661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38423,DS-5b2efbf3-a140-4bb4-9ab1-88ba953d2968,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-4abe4bee-97ed-4247-b8af-597ca7b5d1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-761c5657-0575-4a2b-a933-995a9167940d,DISK], DatanodeInfoWithStorage[127.0.0.1:38532,DS-9100bfbe-7620-46d8-a86c-0551938466d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-d0d287c1-6ae8-42a6-9462-767cd77223e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-5a421185-8ca1-4ef1-8abb-f507fe5234f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-044fcc87-ef18-4daa-9cc0-ebca8f356f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-f9b34318-fca4-4c1b-95c0-e9e09043a2a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1522205575-172.17.0.4-1597744042661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38423,DS-5b2efbf3-a140-4bb4-9ab1-88ba953d2968,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-4abe4bee-97ed-4247-b8af-597ca7b5d1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-761c5657-0575-4a2b-a933-995a9167940d,DISK], DatanodeInfoWithStorage[127.0.0.1:38532,DS-9100bfbe-7620-46d8-a86c-0551938466d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-d0d287c1-6ae8-42a6-9462-767cd77223e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-5a421185-8ca1-4ef1-8abb-f507fe5234f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-044fcc87-ef18-4daa-9cc0-ebca8f356f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-f9b34318-fca4-4c1b-95c0-e9e09043a2a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-231856215-172.17.0.4-1597744270990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41085,DS-66156b5d-ef2b-4f28-b006-8e9b5b3749d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-2b5c9080-d0c5-4a67-bf79-0597ea0aa8df,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-6ed2c16f-a7fe-408e-aa03-492825e48872,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-578cff6a-27cc-46ec-9c8c-92459c868785,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-f98b4e2c-98de-41ee-a1cd-807e097e4b21,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-c74e3cbd-1c25-4e21-9c69-1313eb1481a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-e0c371db-47cf-4793-a490-d7c0761c4d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-d6d7dfa9-b755-4160-8250-d27d5650bb37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-231856215-172.17.0.4-1597744270990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41085,DS-66156b5d-ef2b-4f28-b006-8e9b5b3749d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-2b5c9080-d0c5-4a67-bf79-0597ea0aa8df,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-6ed2c16f-a7fe-408e-aa03-492825e48872,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-578cff6a-27cc-46ec-9c8c-92459c868785,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-f98b4e2c-98de-41ee-a1cd-807e097e4b21,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-c74e3cbd-1c25-4e21-9c69-1313eb1481a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-e0c371db-47cf-4793-a490-d7c0761c4d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-d6d7dfa9-b755-4160-8250-d27d5650bb37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1820654438-172.17.0.4-1597744488914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42417,DS-cb1392f4-ce0f-4edc-a8b8-29c00963c127,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-458f4ade-e91f-4a9e-bd4c-ecefe8be1035,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-77a287e4-5fa0-492e-82aa-a81ee96509c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-4edba944-b5db-4a71-ba87-9e3de10bf209,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-3aa217fb-7437-4e50-8743-8edb820dc524,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-0a17f861-66d6-43d0-a255-4022ba867e90,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-7c485a9a-6eb8-447e-ac0c-3cd8cfc14ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-20af283a-74fe-4042-b2e1-862a9fc2b9c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1820654438-172.17.0.4-1597744488914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42417,DS-cb1392f4-ce0f-4edc-a8b8-29c00963c127,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-458f4ade-e91f-4a9e-bd4c-ecefe8be1035,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-77a287e4-5fa0-492e-82aa-a81ee96509c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-4edba944-b5db-4a71-ba87-9e3de10bf209,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-3aa217fb-7437-4e50-8743-8edb820dc524,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-0a17f861-66d6-43d0-a255-4022ba867e90,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-7c485a9a-6eb8-447e-ac0c-3cd8cfc14ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-20af283a-74fe-4042-b2e1-862a9fc2b9c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1580324476-172.17.0.4-1597744598388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36476,DS-880e1e68-068c-475c-8ff2-51f0d0f735d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-a138d346-5bd5-47be-87ca-1d47b575068a,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-5b4cc453-3905-4c96-afc3-2521afb396a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-afc2b80a-540d-4b35-8c7f-0e48f4570c58,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-67a584a7-92e6-4a8e-9b2d-8a3ea0144bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-865da97a-9bf1-43e6-8d7f-90457c19dc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-2f251ea5-df80-4563-90ee-d1be810609bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-bb66c9ba-3076-4202-bd1d-6bc12db69ff0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1580324476-172.17.0.4-1597744598388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36476,DS-880e1e68-068c-475c-8ff2-51f0d0f735d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-a138d346-5bd5-47be-87ca-1d47b575068a,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-5b4cc453-3905-4c96-afc3-2521afb396a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-afc2b80a-540d-4b35-8c7f-0e48f4570c58,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-67a584a7-92e6-4a8e-9b2d-8a3ea0144bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-865da97a-9bf1-43e6-8d7f-90457c19dc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-2f251ea5-df80-4563-90ee-d1be810609bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-bb66c9ba-3076-4202-bd1d-6bc12db69ff0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-722528056-172.17.0.4-1597744643412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34371,DS-eb1bc981-00e8-4e92-b129-a8423b91a356,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-ffc6df35-5b6f-4e54-a990-022916f1558f,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-f2f38ee1-99dd-469c-ab62-2202c6cdec3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-ec41dae9-5b5b-418f-b43b-7ac74f7ac160,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-1b6ccce1-90a1-44dc-9402-8ff1690cc3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-f3bec998-35d9-4aa6-ad8d-41e6048993ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-82ea20ed-9f72-44e1-9484-8da9988bf6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-1102674b-6f9c-463c-ba27-56000beb47ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-722528056-172.17.0.4-1597744643412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34371,DS-eb1bc981-00e8-4e92-b129-a8423b91a356,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-ffc6df35-5b6f-4e54-a990-022916f1558f,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-f2f38ee1-99dd-469c-ab62-2202c6cdec3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-ec41dae9-5b5b-418f-b43b-7ac74f7ac160,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-1b6ccce1-90a1-44dc-9402-8ff1690cc3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-f3bec998-35d9-4aa6-ad8d-41e6048993ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-82ea20ed-9f72-44e1-9484-8da9988bf6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-1102674b-6f9c-463c-ba27-56000beb47ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548497561-172.17.0.4-1597744761542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43265,DS-79441484-3e3f-466b-a6b1-318708e42ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-1fd84fe0-afeb-4d28-8bc6-d20f6fb6dd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-99359cc6-80cf-4b6b-bcd4-103df3dd2eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-6531fa12-d79f-47fe-aec3-c65238c42ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-76be91c1-f530-4a57-9d40-ef502c58bfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-78672b7d-6f68-4f49-af96-f03bfbba10d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43319,DS-173a90fa-820b-403e-805b-63b717241ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-656bdb0f-588b-4944-8698-d0abaa4a8684,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548497561-172.17.0.4-1597744761542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43265,DS-79441484-3e3f-466b-a6b1-318708e42ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-1fd84fe0-afeb-4d28-8bc6-d20f6fb6dd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-99359cc6-80cf-4b6b-bcd4-103df3dd2eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-6531fa12-d79f-47fe-aec3-c65238c42ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-76be91c1-f530-4a57-9d40-ef502c58bfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-78672b7d-6f68-4f49-af96-f03bfbba10d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43319,DS-173a90fa-820b-403e-805b-63b717241ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-656bdb0f-588b-4944-8698-d0abaa4a8684,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-836519542-172.17.0.4-1597745217889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40364,DS-a6799360-4043-4519-a2b7-d76668867218,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-2489c74f-373d-4a8d-ad3e-77dc134730ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-9273756e-81f5-4756-8d1d-a6c4690523da,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-825d576d-cb87-4783-8e6c-080852cf0a46,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-c20d53d7-589e-4d9d-a377-2efe600f393d,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-975f4afe-5e35-46d1-99d7-19e059e29cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-e943867f-8f47-495c-9160-f533c7485df7,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-2864bed4-8778-4009-9b35-de9098e9d65c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-836519542-172.17.0.4-1597745217889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40364,DS-a6799360-4043-4519-a2b7-d76668867218,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-2489c74f-373d-4a8d-ad3e-77dc134730ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-9273756e-81f5-4756-8d1d-a6c4690523da,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-825d576d-cb87-4783-8e6c-080852cf0a46,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-c20d53d7-589e-4d9d-a377-2efe600f393d,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-975f4afe-5e35-46d1-99d7-19e059e29cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-e943867f-8f47-495c-9160-f533c7485df7,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-2864bed4-8778-4009-9b35-de9098e9d65c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430525504-172.17.0.4-1597745289068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43669,DS-dcefff8b-0237-4be6-aa64-aee8b6cc4e38,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-05a19635-0283-4369-a79d-60f10dfc8dba,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-a23498e5-f743-48ea-83b8-e690a9746b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-7df75233-206b-4720-9784-21cd69175764,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-f1481a67-b00f-49ff-a2fa-6841f84035b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-41388c1f-6c1d-4ad3-9fc1-729b6aaf5fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-934ca692-e08a-4b22-a9a1-fe2c941180c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-3a951627-968e-48ff-bb5a-bfb2f0765727,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430525504-172.17.0.4-1597745289068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43669,DS-dcefff8b-0237-4be6-aa64-aee8b6cc4e38,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-05a19635-0283-4369-a79d-60f10dfc8dba,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-a23498e5-f743-48ea-83b8-e690a9746b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-7df75233-206b-4720-9784-21cd69175764,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-f1481a67-b00f-49ff-a2fa-6841f84035b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-41388c1f-6c1d-4ad3-9fc1-729b6aaf5fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-934ca692-e08a-4b22-a9a1-fe2c941180c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-3a951627-968e-48ff-bb5a-bfb2f0765727,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1023300993-172.17.0.4-1597745364042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42150,DS-75586cc6-4c50-455d-8c02-d797d4cf44fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-57ba0bf8-d53f-478d-9760-18f9ae37d054,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-f15c2471-0b42-4fb0-9fec-7c05f0873116,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-e4997937-9201-432f-9dfe-059d268eddda,DISK], DatanodeInfoWithStorage[127.0.0.1:43938,DS-be16b146-0118-4778-9d41-606ea8439d92,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-c4732c09-63d1-480f-a48f-94bc8326524a,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-b7edb943-dcc3-4781-9b0e-2e5649308041,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-9229e794-fddc-44b6-b498-4d22e2ad4d9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1023300993-172.17.0.4-1597745364042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42150,DS-75586cc6-4c50-455d-8c02-d797d4cf44fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-57ba0bf8-d53f-478d-9760-18f9ae37d054,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-f15c2471-0b42-4fb0-9fec-7c05f0873116,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-e4997937-9201-432f-9dfe-059d268eddda,DISK], DatanodeInfoWithStorage[127.0.0.1:43938,DS-be16b146-0118-4778-9d41-606ea8439d92,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-c4732c09-63d1-480f-a48f-94bc8326524a,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-b7edb943-dcc3-4781-9b0e-2e5649308041,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-9229e794-fddc-44b6-b498-4d22e2ad4d9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2123410485-172.17.0.4-1597745656764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34268,DS-c991ad37-00be-4182-8d23-a9a7da056d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-04f347fa-0f76-4390-b3d5-5ecfc26c83e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-8175a52a-266d-435c-ae1f-a60c9be3ae3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-633b1099-7d6a-4e80-af51-0e771de7244a,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-9f8936eb-0a19-435e-9741-77c31fc37a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-bf44a8e1-a9e1-422c-b78c-1ff66564f6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-e8f45fac-ec6f-49b9-a31b-fcd5f19f7b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-1b818c52-7e80-435d-b7cd-b2c7899b88c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2123410485-172.17.0.4-1597745656764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34268,DS-c991ad37-00be-4182-8d23-a9a7da056d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42057,DS-04f347fa-0f76-4390-b3d5-5ecfc26c83e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-8175a52a-266d-435c-ae1f-a60c9be3ae3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-633b1099-7d6a-4e80-af51-0e771de7244a,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-9f8936eb-0a19-435e-9741-77c31fc37a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-bf44a8e1-a9e1-422c-b78c-1ff66564f6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-e8f45fac-ec6f-49b9-a31b-fcd5f19f7b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-1b818c52-7e80-435d-b7cd-b2c7899b88c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1137295486-172.17.0.4-1597745819681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37447,DS-446500fc-e2f1-432a-a154-1efe103f86de,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-e81b7075-0c73-4cca-903f-e3038963afb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-b45d0320-24eb-4412-a5b6-4cf9921757a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-f65bc342-4132-4c7a-a943-18cdfdf31e74,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-70f0670f-8021-4a3e-ac90-79bee7380725,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-61653b94-fbd3-4fdc-90d5-57bccc0d044c,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-153294ae-fbd5-4afc-83d1-0b505b82ed3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-60b4e75d-92a8-47ad-9f6c-1387c19dd5f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1137295486-172.17.0.4-1597745819681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37447,DS-446500fc-e2f1-432a-a154-1efe103f86de,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-e81b7075-0c73-4cca-903f-e3038963afb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-b45d0320-24eb-4412-a5b6-4cf9921757a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-f65bc342-4132-4c7a-a943-18cdfdf31e74,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-70f0670f-8021-4a3e-ac90-79bee7380725,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-61653b94-fbd3-4fdc-90d5-57bccc0d044c,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-153294ae-fbd5-4afc-83d1-0b505b82ed3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-60b4e75d-92a8-47ad-9f6c-1387c19dd5f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-998689940-172.17.0.4-1597745858325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39509,DS-b6895932-7bc7-475c-a09c-556996901cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-dc870825-09aa-44d3-b33a-0d1b4c122448,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-968ad0cb-20c6-47f4-9b8e-66fd7e977d92,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-39984fc6-9d82-43a1-810e-69fcb6082f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-2a7a10c1-6455-40af-8d39-00563599f6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-360eaa33-0cc0-415a-a33e-086a3415a79c,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-24ff45d2-ea27-426e-944e-92488da3f87b,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-73632ac5-83d3-41fe-8652-e348eb0dc7db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-998689940-172.17.0.4-1597745858325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39509,DS-b6895932-7bc7-475c-a09c-556996901cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-dc870825-09aa-44d3-b33a-0d1b4c122448,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-968ad0cb-20c6-47f4-9b8e-66fd7e977d92,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-39984fc6-9d82-43a1-810e-69fcb6082f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-2a7a10c1-6455-40af-8d39-00563599f6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-360eaa33-0cc0-415a-a33e-086a3415a79c,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-24ff45d2-ea27-426e-944e-92488da3f87b,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-73632ac5-83d3-41fe-8652-e348eb0dc7db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488629841-172.17.0.4-1597746613854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33256,DS-aca429dc-62f2-433f-82f6-70c1c6396335,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-2434c6f2-e5d4-4c13-a1de-6df3f5a10c41,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-d7107fc7-e448-4979-a43f-a841b9104c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-7275f789-5347-48c5-a168-12f4ce9a2f08,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-6ff4026b-eda2-44ae-9915-25c494b5b955,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-a7f3b5f0-f00b-4325-afeb-04224b8aafb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-97100101-0376-4bb3-af90-10f6fd22f411,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-7d5c5ce2-7550-4692-bf01-681464066c4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488629841-172.17.0.4-1597746613854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33256,DS-aca429dc-62f2-433f-82f6-70c1c6396335,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-2434c6f2-e5d4-4c13-a1de-6df3f5a10c41,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-d7107fc7-e448-4979-a43f-a841b9104c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-7275f789-5347-48c5-a168-12f4ce9a2f08,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-6ff4026b-eda2-44ae-9915-25c494b5b955,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-a7f3b5f0-f00b-4325-afeb-04224b8aafb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-97100101-0376-4bb3-af90-10f6fd22f411,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-7d5c5ce2-7550-4692-bf01-681464066c4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-530416803-172.17.0.4-1597747614160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38937,DS-c7cd188a-91c3-4c80-99ed-31a97a4fa04c,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-f0e41b86-f762-4983-8d41-a659e2ef6c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-3950ed40-d4ca-493f-b2f9-71ea61f308b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-53d483ad-cba7-4080-8fa4-f1269af6fc52,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-ebd73625-f99b-469f-8469-f0d495339797,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-bed8f70c-e87c-4761-b04a-f708dca805f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-704f1bd8-fc5e-47f3-9e6c-2479b6330f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-0b230108-84fb-4c18-8b4a-03ab9f5aa3b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-530416803-172.17.0.4-1597747614160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38937,DS-c7cd188a-91c3-4c80-99ed-31a97a4fa04c,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-f0e41b86-f762-4983-8d41-a659e2ef6c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-3950ed40-d4ca-493f-b2f9-71ea61f308b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-53d483ad-cba7-4080-8fa4-f1269af6fc52,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-ebd73625-f99b-469f-8469-f0d495339797,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-bed8f70c-e87c-4761-b04a-f708dca805f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-704f1bd8-fc5e-47f3-9e6c-2479b6330f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-0b230108-84fb-4c18-8b4a-03ab9f5aa3b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-591112945-172.17.0.4-1597748488970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41297,DS-e3d6a107-01bc-43eb-9629-30b66b5321ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-77f69ae8-b572-418e-b01e-dd5190b165bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-7009ad45-96d7-4978-be61-9dab7f03c5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-4ee26439-e6f6-460a-abed-3fc1443a840b,DISK], DatanodeInfoWithStorage[127.0.0.1:36565,DS-81d6156e-3de3-457e-825d-9a70a71b90c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-cb2a9875-1edc-4513-afb8-3ca448bdc31a,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-f9194004-2ee5-45e3-962d-d54fdff29c01,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-a86e2d3c-4233-4885-b454-c4f17fcd60f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-591112945-172.17.0.4-1597748488970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41297,DS-e3d6a107-01bc-43eb-9629-30b66b5321ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-77f69ae8-b572-418e-b01e-dd5190b165bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-7009ad45-96d7-4978-be61-9dab7f03c5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-4ee26439-e6f6-460a-abed-3fc1443a840b,DISK], DatanodeInfoWithStorage[127.0.0.1:36565,DS-81d6156e-3de3-457e-825d-9a70a71b90c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-cb2a9875-1edc-4513-afb8-3ca448bdc31a,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-f9194004-2ee5-45e3-962d-d54fdff29c01,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-a86e2d3c-4233-4885-b454-c4f17fcd60f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 36
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1244536403-172.17.0.4-1597748996299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33992,DS-40beaedc-c3ea-4ab6-b566-7b29acbe8408,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-8746115c-b050-415d-bd07-dec686edf53c,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-d81691a6-2fc6-4231-9992-a75caf230a22,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-ff214da7-6b41-4ade-8e0e-63ecd756410c,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-34539e4c-2366-4954-ae6b-5a1749d67b51,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-7a87e4cd-a643-446a-ab95-f0a5c511eafb,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-97aac2c0-e80c-47ad-93a5-56007fd043dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-b0c00c0f-80d4-47f0-aa8d-1f208f0acdbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1244536403-172.17.0.4-1597748996299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33992,DS-40beaedc-c3ea-4ab6-b566-7b29acbe8408,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-8746115c-b050-415d-bd07-dec686edf53c,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-d81691a6-2fc6-4231-9992-a75caf230a22,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-ff214da7-6b41-4ade-8e0e-63ecd756410c,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-34539e4c-2366-4954-ae6b-5a1749d67b51,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-7a87e4cd-a643-446a-ab95-f0a5c511eafb,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-97aac2c0-e80c-47ad-93a5-56007fd043dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-b0c00c0f-80d4-47f0-aa8d-1f208f0acdbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5415
