reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934894136-172.17.0.21-1597502967457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37320,DS-025c838e-bf34-400d-8ed5-f1994713e743,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-806be5dc-77fd-41c0-ab7d-74ec2e81e8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-297ca3f5-d26a-4043-a34b-da074dbd8127,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-b92dfd5a-86a4-485a-a2d6-8f3029d990d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-2dc4886b-5993-4eca-853c-246dc768c200,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-2349fde0-3e14-4966-b508-66d8a90443bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-eac62737-fab8-48e1-b3b0-e30c25297846,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-ccffca96-55ed-42a5-a5be-671d8034b452,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934894136-172.17.0.21-1597502967457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37320,DS-025c838e-bf34-400d-8ed5-f1994713e743,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-806be5dc-77fd-41c0-ab7d-74ec2e81e8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-297ca3f5-d26a-4043-a34b-da074dbd8127,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-b92dfd5a-86a4-485a-a2d6-8f3029d990d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-2dc4886b-5993-4eca-853c-246dc768c200,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-2349fde0-3e14-4966-b508-66d8a90443bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-eac62737-fab8-48e1-b3b0-e30c25297846,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-ccffca96-55ed-42a5-a5be-671d8034b452,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-292253395-172.17.0.21-1597503109045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35202,DS-41fcf6cf-0346-433b-8004-7eba35d48186,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-3ac9972e-0871-4aa0-aab2-ed9cd89a2116,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-464241cf-9af5-427f-9e10-c71ad7cb9601,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-f434d5e5-033a-4f01-822d-53e61b436eca,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-86d58c77-4228-4d96-82ee-e6a70c30954d,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-8501b837-a52d-46f5-b62c-7e141026b57a,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-fc76a5ae-18c3-4ddc-9f40-9a890748b662,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-8d680b28-c3b9-4b9d-b918-9ab93356a1ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-292253395-172.17.0.21-1597503109045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35202,DS-41fcf6cf-0346-433b-8004-7eba35d48186,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-3ac9972e-0871-4aa0-aab2-ed9cd89a2116,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-464241cf-9af5-427f-9e10-c71ad7cb9601,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-f434d5e5-033a-4f01-822d-53e61b436eca,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-86d58c77-4228-4d96-82ee-e6a70c30954d,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-8501b837-a52d-46f5-b62c-7e141026b57a,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-fc76a5ae-18c3-4ddc-9f40-9a890748b662,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-8d680b28-c3b9-4b9d-b918-9ab93356a1ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388356316-172.17.0.21-1597503258521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35044,DS-a1e67dbe-6c67-46d0-985e-37eb11ea2d83,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-036bd0ef-4e97-420b-a3b6-3c4586f91588,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-5ab0e9c1-8d3c-425e-b5c1-9d5c3e6c0497,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-362cb9f5-84a0-44ad-8a16-5e8a0d2a7fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-8d2df248-427c-4b18-8c50-79b0669ae09f,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-94dec839-da72-4a77-b905-9d8f6ce72c57,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-e35afac0-2bc5-44d4-83e1-20185c92248a,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-31c76ae7-ab33-4a9f-bb8a-15bb08cf787f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388356316-172.17.0.21-1597503258521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35044,DS-a1e67dbe-6c67-46d0-985e-37eb11ea2d83,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-036bd0ef-4e97-420b-a3b6-3c4586f91588,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-5ab0e9c1-8d3c-425e-b5c1-9d5c3e6c0497,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-362cb9f5-84a0-44ad-8a16-5e8a0d2a7fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-8d2df248-427c-4b18-8c50-79b0669ae09f,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-94dec839-da72-4a77-b905-9d8f6ce72c57,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-e35afac0-2bc5-44d4-83e1-20185c92248a,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-31c76ae7-ab33-4a9f-bb8a-15bb08cf787f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1354378822-172.17.0.21-1597503376871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46858,DS-d19397ca-0e90-4a8a-a2b6-834eb8943c30,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-889c66bb-1ab5-4d42-9e8d-a5b4d4c113b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-506487d3-8e00-4fe5-be7a-be0939dc2e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-c4f5bf45-7eb6-40af-aaa7-b2abc3a53f87,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-985db946-e98b-4066-b2a8-986a01a025fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-a6419f06-dcb0-4c68-af85-2f1310924d03,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-b41670ff-49da-4ec5-bea1-d78c9549f82b,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-94302177-0240-4713-91a8-82d9fb1c3c98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1354378822-172.17.0.21-1597503376871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46858,DS-d19397ca-0e90-4a8a-a2b6-834eb8943c30,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-889c66bb-1ab5-4d42-9e8d-a5b4d4c113b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-506487d3-8e00-4fe5-be7a-be0939dc2e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-c4f5bf45-7eb6-40af-aaa7-b2abc3a53f87,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-985db946-e98b-4066-b2a8-986a01a025fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-a6419f06-dcb0-4c68-af85-2f1310924d03,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-b41670ff-49da-4ec5-bea1-d78c9549f82b,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-94302177-0240-4713-91a8-82d9fb1c3c98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1777009552-172.17.0.21-1597503814978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44460,DS-9292c649-769c-405c-ad18-5a9513bc5ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-d29ae632-ac44-4fa7-a7f8-cc9d13e08201,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-3500c1e9-81b4-4890-bea4-35eed2df8031,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-e2677c29-e2ce-4721-aa66-1b937ded70f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-9b15eeef-db13-4e6c-9ac3-40bb4c38b466,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-894178f5-b92d-4d98-ab0e-1c29fe27a042,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-e2bf752b-23d9-4521-a5b1-ae9ef8f87171,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-b4495e42-65d7-4b12-ab6f-e9c1306d0780,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1777009552-172.17.0.21-1597503814978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44460,DS-9292c649-769c-405c-ad18-5a9513bc5ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-d29ae632-ac44-4fa7-a7f8-cc9d13e08201,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-3500c1e9-81b4-4890-bea4-35eed2df8031,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-e2677c29-e2ce-4721-aa66-1b937ded70f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-9b15eeef-db13-4e6c-9ac3-40bb4c38b466,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-894178f5-b92d-4d98-ab0e-1c29fe27a042,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-e2bf752b-23d9-4521-a5b1-ae9ef8f87171,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-b4495e42-65d7-4b12-ab6f-e9c1306d0780,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123316900-172.17.0.21-1597503848747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41741,DS-8b76cbec-8bbe-449c-85d7-d001fd95c147,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-6865c1ca-d38f-42d5-b562-ab0f8b20253f,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-72d2cc7f-1d63-462a-884b-eacb8f00b746,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-e2120c66-ab10-4c4c-8725-5fac35dcd6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-802ca99f-28dc-4413-8bcd-ba767140001a,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-54bd45b7-32cf-4059-aaed-ba43ea642323,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-dd8c3000-af77-4399-b86f-a41ec7d243d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-e38c7db5-4b48-4f12-8738-48a20bf994da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123316900-172.17.0.21-1597503848747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41741,DS-8b76cbec-8bbe-449c-85d7-d001fd95c147,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-6865c1ca-d38f-42d5-b562-ab0f8b20253f,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-72d2cc7f-1d63-462a-884b-eacb8f00b746,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-e2120c66-ab10-4c4c-8725-5fac35dcd6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-802ca99f-28dc-4413-8bcd-ba767140001a,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-54bd45b7-32cf-4059-aaed-ba43ea642323,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-dd8c3000-af77-4399-b86f-a41ec7d243d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-e38c7db5-4b48-4f12-8738-48a20bf994da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051845535-172.17.0.21-1597504204257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39534,DS-914a9561-ea93-44b3-9ab2-aa62ccc0c80f,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-d1bc1af8-9cc5-40fe-9581-2af23ed9a8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-6f9df57e-440f-4981-9291-b6b43ce4819b,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-efad8b32-c772-4ec8-bda1-f88f6fd029a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-50de3202-ac2a-4185-9ec8-0a6207d6620a,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-d7ec59c6-fdda-4ae7-86d4-d713b6696628,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-80069b87-8aa5-4ffb-99c8-3063bff3f68b,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-4976adbe-aaf1-4bb1-8589-b7a4b3ca8904,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051845535-172.17.0.21-1597504204257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39534,DS-914a9561-ea93-44b3-9ab2-aa62ccc0c80f,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-d1bc1af8-9cc5-40fe-9581-2af23ed9a8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-6f9df57e-440f-4981-9291-b6b43ce4819b,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-efad8b32-c772-4ec8-bda1-f88f6fd029a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-50de3202-ac2a-4185-9ec8-0a6207d6620a,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-d7ec59c6-fdda-4ae7-86d4-d713b6696628,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-80069b87-8aa5-4ffb-99c8-3063bff3f68b,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-4976adbe-aaf1-4bb1-8589-b7a4b3ca8904,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-578009857-172.17.0.21-1597504346279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41204,DS-01b620ea-e449-4437-8a9b-6472255ae1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-afbe38db-c3a5-4cab-b3e5-c555e4a38246,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-e71806d7-22b7-4f46-a1af-52d7b6983d56,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-d5dcfc2c-ebd5-47a9-a8c8-013b16426fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-dcd1f1c7-14a7-4701-b73b-fd1c68984794,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-5cc162b5-be57-4041-bf28-ac1a5991037a,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-fd367e63-1ac1-47d1-a91e-cb19d54d938b,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-de67e21b-da17-4a40-9dd2-83d2b7c26203,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-578009857-172.17.0.21-1597504346279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41204,DS-01b620ea-e449-4437-8a9b-6472255ae1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-afbe38db-c3a5-4cab-b3e5-c555e4a38246,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-e71806d7-22b7-4f46-a1af-52d7b6983d56,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-d5dcfc2c-ebd5-47a9-a8c8-013b16426fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-dcd1f1c7-14a7-4701-b73b-fd1c68984794,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-5cc162b5-be57-4041-bf28-ac1a5991037a,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-fd367e63-1ac1-47d1-a91e-cb19d54d938b,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-de67e21b-da17-4a40-9dd2-83d2b7c26203,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-658430003-172.17.0.21-1597504533612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46636,DS-dbd2ff0a-0ef5-4c2b-9f1d-fb08c055fd97,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-b3d66aef-6ce7-4916-be24-69f76a1e064d,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-a189d06f-7dd3-49f2-929f-13aa10ca5676,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-bd94a06a-0ddd-434e-a4f7-853b3a29246c,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-394dbd61-deee-4e26-8157-fd10af5233d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-5ad911f5-9390-478e-a3c3-d0e05ff6b2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-698154d6-4091-499e-b548-9cc380403120,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-ac0fb72f-d607-4fde-9a03-32d09fa91ca4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-658430003-172.17.0.21-1597504533612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46636,DS-dbd2ff0a-0ef5-4c2b-9f1d-fb08c055fd97,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-b3d66aef-6ce7-4916-be24-69f76a1e064d,DISK], DatanodeInfoWithStorage[127.0.0.1:44217,DS-a189d06f-7dd3-49f2-929f-13aa10ca5676,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-bd94a06a-0ddd-434e-a4f7-853b3a29246c,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-394dbd61-deee-4e26-8157-fd10af5233d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-5ad911f5-9390-478e-a3c3-d0e05ff6b2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-698154d6-4091-499e-b548-9cc380403120,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-ac0fb72f-d607-4fde-9a03-32d09fa91ca4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675019838-172.17.0.21-1597505178073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34311,DS-eab0c349-8370-4a3b-8f31-a096bf9883f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-5004d037-6179-476b-b94a-b60b5b5b34e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-227a1581-83a8-4284-aac3-59afd3998a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-259c7e88-07f7-489b-9e9e-e699cf7dcc28,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-9a7374ba-4162-409b-aa4a-b85163aa4780,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-ecd3a561-7e4f-4843-8cff-d665c90fd573,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-d9b6eac2-9cee-439a-9558-880d9287cedf,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-7bce1923-ecb5-4f45-84cb-ce0d9642868e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675019838-172.17.0.21-1597505178073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34311,DS-eab0c349-8370-4a3b-8f31-a096bf9883f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-5004d037-6179-476b-b94a-b60b5b5b34e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42396,DS-227a1581-83a8-4284-aac3-59afd3998a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-259c7e88-07f7-489b-9e9e-e699cf7dcc28,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-9a7374ba-4162-409b-aa4a-b85163aa4780,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-ecd3a561-7e4f-4843-8cff-d665c90fd573,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-d9b6eac2-9cee-439a-9558-880d9287cedf,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-7bce1923-ecb5-4f45-84cb-ce0d9642868e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-907791328-172.17.0.21-1597505572766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46546,DS-f0a07bed-862d-4458-813a-423c26da46d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-be17639b-ba04-4d6e-a413-e867f764b215,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-8d835812-253e-4cf3-beea-8ba887ebc75b,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-9c40f3d1-fa96-4cdd-8069-4daf82049570,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-2886a4a3-61ec-41a8-9942-342e6f69bcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-78c6018d-b0f4-4267-abdd-38a0f2769344,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-88b6605e-5602-4051-9998-877c9a1e3000,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-ea98d2b1-f328-4cae-9b44-3baf19ca638c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-907791328-172.17.0.21-1597505572766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46546,DS-f0a07bed-862d-4458-813a-423c26da46d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-be17639b-ba04-4d6e-a413-e867f764b215,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-8d835812-253e-4cf3-beea-8ba887ebc75b,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-9c40f3d1-fa96-4cdd-8069-4daf82049570,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-2886a4a3-61ec-41a8-9942-342e6f69bcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-78c6018d-b0f4-4267-abdd-38a0f2769344,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-88b6605e-5602-4051-9998-877c9a1e3000,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-ea98d2b1-f328-4cae-9b44-3baf19ca638c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203343151-172.17.0.21-1597505907109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32825,DS-035bcac7-592c-4889-94d9-e5b1f74355bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-3ee7a62d-27e1-460a-9208-63dd62cec106,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-cbed48af-fbac-464d-ac5e-019a89648952,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-dd017b01-5743-4fbe-9962-00dd35dbc071,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-ff5b5aea-d767-4f03-854f-871305e092bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-eebe0fa0-1eda-44e5-a94a-970cd65da925,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-4ba88c07-faec-4618-83cf-43003822d2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-b657fc14-32f2-45d1-b2b1-b7ded9ebb301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203343151-172.17.0.21-1597505907109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32825,DS-035bcac7-592c-4889-94d9-e5b1f74355bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-3ee7a62d-27e1-460a-9208-63dd62cec106,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-cbed48af-fbac-464d-ac5e-019a89648952,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-dd017b01-5743-4fbe-9962-00dd35dbc071,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-ff5b5aea-d767-4f03-854f-871305e092bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-eebe0fa0-1eda-44e5-a94a-970cd65da925,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-4ba88c07-faec-4618-83cf-43003822d2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-b657fc14-32f2-45d1-b2b1-b7ded9ebb301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-728329468-172.17.0.21-1597506351161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33384,DS-5d105c74-b72d-4549-b83e-1962a013dc05,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-38b5f69a-c977-486f-ade5-94f7e2282595,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-7c5bbedd-a289-4747-b4e1-4f75d7b9d417,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-87395610-fe14-41e4-a5d0-9f2cb21175c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-d1bd2880-b33c-45ef-86b3-f38d3f164e65,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-3f3caf1e-e5e7-42b3-bc00-99870b46c2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-d406e57c-ca83-4304-a8d9-71ec3fd7d0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-3a10bf46-e3bf-40dd-b8d0-36ca68bdbe5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-728329468-172.17.0.21-1597506351161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33384,DS-5d105c74-b72d-4549-b83e-1962a013dc05,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-38b5f69a-c977-486f-ade5-94f7e2282595,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-7c5bbedd-a289-4747-b4e1-4f75d7b9d417,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-87395610-fe14-41e4-a5d0-9f2cb21175c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-d1bd2880-b33c-45ef-86b3-f38d3f164e65,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-3f3caf1e-e5e7-42b3-bc00-99870b46c2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-d406e57c-ca83-4304-a8d9-71ec3fd7d0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-3a10bf46-e3bf-40dd-b8d0-36ca68bdbe5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-769324979-172.17.0.21-1597506801796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35465,DS-ad42ffc3-8315-4fcd-a3f9-d13362a4e296,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-24965fe6-b403-4256-95de-2b0ab19108c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-feeb23b4-13c5-45f2-b44e-257411d92c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-dae88849-a916-4244-b169-6bd226bf68ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-30e8c9f0-f5e8-47be-ac24-bf0aa1053762,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-927d9920-5f79-40b6-ac5d-ad8711bebcf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37321,DS-5f61adb7-3ce6-4111-9b07-5b6a802dcfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-5fd554b7-34f5-4ec4-b100-9ac46b079a6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-769324979-172.17.0.21-1597506801796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35465,DS-ad42ffc3-8315-4fcd-a3f9-d13362a4e296,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-24965fe6-b403-4256-95de-2b0ab19108c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-feeb23b4-13c5-45f2-b44e-257411d92c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-dae88849-a916-4244-b169-6bd226bf68ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-30e8c9f0-f5e8-47be-ac24-bf0aa1053762,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-927d9920-5f79-40b6-ac5d-ad8711bebcf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37321,DS-5f61adb7-3ce6-4111-9b07-5b6a802dcfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-5fd554b7-34f5-4ec4-b100-9ac46b079a6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1190638911-172.17.0.21-1597506841124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35820,DS-2988a2c7-e29d-4924-b9ed-eda6c8bc56ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-20bffeae-4e1f-45a4-b103-f44d41b3d286,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-5c9b54ce-c025-4fcb-ab41-c6aebe83be73,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-e481bc6f-5b56-4a11-aca4-e21cc96b7db6,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-82c31477-a6e4-4bcb-b576-cb38be5f33bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-8b54b558-f4f9-4a9f-988f-b6f098e596a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-d8405a40-c878-429c-8720-0047b54ad3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-a78f78ae-050a-40e7-91d2-04dc039ddb08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1190638911-172.17.0.21-1597506841124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35820,DS-2988a2c7-e29d-4924-b9ed-eda6c8bc56ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-20bffeae-4e1f-45a4-b103-f44d41b3d286,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-5c9b54ce-c025-4fcb-ab41-c6aebe83be73,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-e481bc6f-5b56-4a11-aca4-e21cc96b7db6,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-82c31477-a6e4-4bcb-b576-cb38be5f33bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-8b54b558-f4f9-4a9f-988f-b6f098e596a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-d8405a40-c878-429c-8720-0047b54ad3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-a78f78ae-050a-40e7-91d2-04dc039ddb08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1231784822-172.17.0.21-1597506876064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42985,DS-8e251723-365c-4b1b-801a-80ee119fc81b,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-84ec356f-a5b6-4053-8637-7be7068424ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-72d2f4b8-faa2-4177-a82e-4abf581eda06,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-7b739eae-f686-47ac-8d79-1f860dffded1,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-8ccfac96-f23d-4683-a8a5-9df040faba98,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-4dc17d57-5d98-449e-84a1-ed2a1ac67d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-0dd2d2c1-784a-4271-8292-d3938fc8ad36,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-1ed5ab3d-c85f-48b7-9a86-b0fdb74e4a04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1231784822-172.17.0.21-1597506876064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42985,DS-8e251723-365c-4b1b-801a-80ee119fc81b,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-84ec356f-a5b6-4053-8637-7be7068424ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-72d2f4b8-faa2-4177-a82e-4abf581eda06,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-7b739eae-f686-47ac-8d79-1f860dffded1,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-8ccfac96-f23d-4683-a8a5-9df040faba98,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-4dc17d57-5d98-449e-84a1-ed2a1ac67d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-0dd2d2c1-784a-4271-8292-d3938fc8ad36,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-1ed5ab3d-c85f-48b7-9a86-b0fdb74e4a04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870964012-172.17.0.21-1597506949189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40702,DS-f95f7a4a-fc5e-4a8e-922a-5cd5c6f63791,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-a957e134-d10e-4a9b-99ae-0507d1a02527,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-d4c0e1c9-8527-4afc-8e05-423860963614,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-78540d65-3028-4680-a6d6-37e01869c5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-c404c7d0-4b82-44cc-b500-b0981d2b1c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-79a9aa4c-68c5-49c6-b497-61a1499b0ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-22ff9bca-9516-4548-bc85-512d1673fbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-cc500c0b-c2f8-4c7e-b225-42b39843a546,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870964012-172.17.0.21-1597506949189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40702,DS-f95f7a4a-fc5e-4a8e-922a-5cd5c6f63791,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-a957e134-d10e-4a9b-99ae-0507d1a02527,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-d4c0e1c9-8527-4afc-8e05-423860963614,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-78540d65-3028-4680-a6d6-37e01869c5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-c404c7d0-4b82-44cc-b500-b0981d2b1c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-79a9aa4c-68c5-49c6-b497-61a1499b0ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-22ff9bca-9516-4548-bc85-512d1673fbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-cc500c0b-c2f8-4c7e-b225-42b39843a546,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1672057207-172.17.0.21-1597507034869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33245,DS-502e9c4a-cd8c-48b3-8ca7-0853ad4df9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-4091730f-68c1-41d5-a96a-34a6aa12f53e,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-4b05af4a-fbc3-48f6-a8fd-a7fb8806c446,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-db7d3e44-e594-4054-b12b-26de9b79f929,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-7b4047d2-8fea-45b9-bde0-597fb475a7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-0164e463-a821-4c09-8698-27d3eedc7c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-127b50a6-7e67-469b-a5e3-a2af576f6294,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-f5deb764-d318-450b-967d-bb64ee1ec10d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1672057207-172.17.0.21-1597507034869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33245,DS-502e9c4a-cd8c-48b3-8ca7-0853ad4df9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-4091730f-68c1-41d5-a96a-34a6aa12f53e,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-4b05af4a-fbc3-48f6-a8fd-a7fb8806c446,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-db7d3e44-e594-4054-b12b-26de9b79f929,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-7b4047d2-8fea-45b9-bde0-597fb475a7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-0164e463-a821-4c09-8698-27d3eedc7c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-127b50a6-7e67-469b-a5e3-a2af576f6294,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-f5deb764-d318-450b-967d-bb64ee1ec10d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1069934592-172.17.0.21-1597507075272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35540,DS-c82af22d-4a53-48c1-93ad-83255264a499,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-6f161ca0-7f8e-46b0-b267-8ba0acb4b54d,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-439ea137-e2b3-4719-847b-0b8ce9f38229,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-f76a14a3-9688-4787-b1d0-505d07c0c882,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-8788cbfa-34bc-4ff1-859d-57a396b490f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-3f71f18a-82c5-4c47-adb4-8278efb8e519,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-fab6a208-379c-4bf3-ab92-ae29941ddfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-7476bde5-33b3-4e53-9792-5ab0285f19db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1069934592-172.17.0.21-1597507075272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35540,DS-c82af22d-4a53-48c1-93ad-83255264a499,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-6f161ca0-7f8e-46b0-b267-8ba0acb4b54d,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-439ea137-e2b3-4719-847b-0b8ce9f38229,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-f76a14a3-9688-4787-b1d0-505d07c0c882,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-8788cbfa-34bc-4ff1-859d-57a396b490f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-3f71f18a-82c5-4c47-adb4-8278efb8e519,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-fab6a208-379c-4bf3-ab92-ae29941ddfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-7476bde5-33b3-4e53-9792-5ab0285f19db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537209260-172.17.0.21-1597507508795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45154,DS-62679859-6ab6-463d-b0de-a3578b6c020d,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-57d09920-b8c8-4b3b-8db0-d8fed612efcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42201,DS-bc11925c-79e5-4edc-a554-98fd83c97e24,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-7baabf6a-ccf0-4c8a-a0a8-60834421e25f,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-6cd1945a-a025-49d2-8e34-c01567be9b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-20d89384-277f-43b1-9ff5-ad0049c411e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-651dc788-fc6d-4c14-8185-849ca63bfe99,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-cf59d99f-f92a-4213-9b6e-4675054ccb7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537209260-172.17.0.21-1597507508795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45154,DS-62679859-6ab6-463d-b0de-a3578b6c020d,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-57d09920-b8c8-4b3b-8db0-d8fed612efcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42201,DS-bc11925c-79e5-4edc-a554-98fd83c97e24,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-7baabf6a-ccf0-4c8a-a0a8-60834421e25f,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-6cd1945a-a025-49d2-8e34-c01567be9b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-20d89384-277f-43b1-9ff5-ad0049c411e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-651dc788-fc6d-4c14-8185-849ca63bfe99,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-cf59d99f-f92a-4213-9b6e-4675054ccb7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1812923537-172.17.0.21-1597507815212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37636,DS-15145b12-c691-47bc-be50-df6c0d42d023,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-ccb7fbf0-9a67-4011-9669-7053f33688f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-44c98991-ac8f-46f1-b768-f3b20e99d30d,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-ce2d15ed-f9fa-4087-8f41-b4648dbd1f60,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-770f2b9b-2ae1-4d87-ac24-caa589b11bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-c52262ee-7777-4938-b0e8-7e0ed2f9c86e,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-cf3c999e-9e34-4709-a66a-ee1972cec717,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-b57f6054-93b6-4451-86a1-43e1579a01bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1812923537-172.17.0.21-1597507815212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37636,DS-15145b12-c691-47bc-be50-df6c0d42d023,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-ccb7fbf0-9a67-4011-9669-7053f33688f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-44c98991-ac8f-46f1-b768-f3b20e99d30d,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-ce2d15ed-f9fa-4087-8f41-b4648dbd1f60,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-770f2b9b-2ae1-4d87-ac24-caa589b11bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-c52262ee-7777-4938-b0e8-7e0ed2f9c86e,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-cf3c999e-9e34-4709-a66a-ee1972cec717,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-b57f6054-93b6-4451-86a1-43e1579a01bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1453004887-172.17.0.21-1597507932480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33553,DS-3a217181-23f6-44ef-b77e-328e5032f48c,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-f44ab6b4-02d8-4b82-ab7d-129afd54d277,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-1ef1aaae-2460-4b37-a7cd-02ef922d7d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-5e76779e-3396-4409-b333-ef5b8b315967,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-cf50fa15-0fed-441d-98e3-da9fdc40c9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-a807d07c-2f4d-4a58-abae-97f9ff71534c,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-ffe68d81-4179-47d2-9578-ce304737ad5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-5e183b92-7875-46f0-b993-53869a6b6560,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1453004887-172.17.0.21-1597507932480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33553,DS-3a217181-23f6-44ef-b77e-328e5032f48c,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-f44ab6b4-02d8-4b82-ab7d-129afd54d277,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-1ef1aaae-2460-4b37-a7cd-02ef922d7d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-5e76779e-3396-4409-b333-ef5b8b315967,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-cf50fa15-0fed-441d-98e3-da9fdc40c9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-a807d07c-2f4d-4a58-abae-97f9ff71534c,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-ffe68d81-4179-47d2-9578-ce304737ad5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-5e183b92-7875-46f0-b993-53869a6b6560,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1906284690-172.17.0.21-1597508043699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41081,DS-089a8a68-1362-4e93-bdc1-8413848717e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-a9adca3e-9a98-4d3b-b687-cf4b93b7cc76,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-ef15298c-7987-4b5a-8d37-d945a2a729fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-6f242b9b-d706-4b58-a9fa-9eb9b00cc9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-0d09a2e1-3a75-4e7b-9264-463bb638c36a,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-ad868362-a12e-48bb-86d6-ea625b02bd77,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-3e85fcac-3984-420c-afbe-c6fb6c802178,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-899f0bdc-322f-4012-91c8-2030a1c8f323,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1906284690-172.17.0.21-1597508043699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41081,DS-089a8a68-1362-4e93-bdc1-8413848717e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-a9adca3e-9a98-4d3b-b687-cf4b93b7cc76,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-ef15298c-7987-4b5a-8d37-d945a2a729fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-6f242b9b-d706-4b58-a9fa-9eb9b00cc9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-0d09a2e1-3a75-4e7b-9264-463bb638c36a,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-ad868362-a12e-48bb-86d6-ea625b02bd77,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-3e85fcac-3984-420c-afbe-c6fb6c802178,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-899f0bdc-322f-4012-91c8-2030a1c8f323,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-98728269-172.17.0.21-1597508273274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36690,DS-970de3b1-f570-41c7-8c0f-4943ae222150,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-f1eb335f-98a1-4c26-a7ff-bde57a7f99ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-7af6588c-3cb5-4712-90c7-8bf3d270b572,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-cf2697e6-a240-47ec-8672-0b2c5823a463,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-d5c8f387-9657-4f86-9f9c-6627870cf1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-8cb6d19b-e44f-4e33-b791-a86d756190c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-496365ce-a232-4f99-a6d9-3d0390fec32f,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-724af8bd-9863-45cb-be03-8456a50e52fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-98728269-172.17.0.21-1597508273274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36690,DS-970de3b1-f570-41c7-8c0f-4943ae222150,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-f1eb335f-98a1-4c26-a7ff-bde57a7f99ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-7af6588c-3cb5-4712-90c7-8bf3d270b572,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-cf2697e6-a240-47ec-8672-0b2c5823a463,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-d5c8f387-9657-4f86-9f9c-6627870cf1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-8cb6d19b-e44f-4e33-b791-a86d756190c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-496365ce-a232-4f99-a6d9-3d0390fec32f,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-724af8bd-9863-45cb-be03-8456a50e52fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011943587-172.17.0.21-1597508344857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37606,DS-79e1441b-6012-4d0d-b7be-21b291081066,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-77bacc18-361f-4074-afd0-d2e6043709cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-40254635-f7ce-47c0-9e76-3c2e94601379,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-1bda11be-20a0-4b8b-ae9b-fecd33a4f69f,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-16df7ca1-f954-48b1-8795-8432a85e52bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-5a665d47-3ff9-43a6-ab80-e3cb2393bf76,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-951e9f5c-cea9-4094-986e-e65b2bc2409a,DISK], DatanodeInfoWithStorage[127.0.0.1:39172,DS-32e2639f-ce7e-470b-97d7-2e96a5508e9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011943587-172.17.0.21-1597508344857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37606,DS-79e1441b-6012-4d0d-b7be-21b291081066,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-77bacc18-361f-4074-afd0-d2e6043709cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-40254635-f7ce-47c0-9e76-3c2e94601379,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-1bda11be-20a0-4b8b-ae9b-fecd33a4f69f,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-16df7ca1-f954-48b1-8795-8432a85e52bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-5a665d47-3ff9-43a6-ab80-e3cb2393bf76,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-951e9f5c-cea9-4094-986e-e65b2bc2409a,DISK], DatanodeInfoWithStorage[127.0.0.1:39172,DS-32e2639f-ce7e-470b-97d7-2e96a5508e9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-970859464-172.17.0.21-1597508469883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38046,DS-d9d280e6-b47a-4828-bd62-f81882fec3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-74450f64-5e52-41af-ac61-93757467663d,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-74c37a0e-4a8c-42db-bf3c-96e88615fc43,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-d8ca950c-44ca-4347-8faf-7d17d216ec19,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-bf74518a-69ce-4e1f-b10c-f0e002c7b62d,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-ddb80052-9554-48f4-a6c9-27c6cbb07223,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-ab96b7e2-b10e-4a06-ac0a-6d1000319bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-7973c3d1-dc19-46d5-af45-74eb989ae7a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-970859464-172.17.0.21-1597508469883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38046,DS-d9d280e6-b47a-4828-bd62-f81882fec3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-74450f64-5e52-41af-ac61-93757467663d,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-74c37a0e-4a8c-42db-bf3c-96e88615fc43,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-d8ca950c-44ca-4347-8faf-7d17d216ec19,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-bf74518a-69ce-4e1f-b10c-f0e002c7b62d,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-ddb80052-9554-48f4-a6c9-27c6cbb07223,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-ab96b7e2-b10e-4a06-ac0a-6d1000319bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-7973c3d1-dc19-46d5-af45-74eb989ae7a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701349429-172.17.0.21-1597508504276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39245,DS-65615198-5d9b-4e34-b6cf-f8575c8b5e62,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-ea132ba8-f06c-427e-8b9b-bd57224945e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-eff58c2b-7d7a-43e6-a49d-644afcdecefe,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-21272f39-74a0-4d11-bba1-d92668300d40,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-31d8c075-a727-404f-a060-af302ae89379,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-250479db-d383-4479-8dc4-f4146b13f0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-61771015-80fe-440c-ac22-fbef5b75bd80,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-ad22a229-7ebe-4494-89ec-46d50cd4ce21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701349429-172.17.0.21-1597508504276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39245,DS-65615198-5d9b-4e34-b6cf-f8575c8b5e62,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-ea132ba8-f06c-427e-8b9b-bd57224945e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-eff58c2b-7d7a-43e6-a49d-644afcdecefe,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-21272f39-74a0-4d11-bba1-d92668300d40,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-31d8c075-a727-404f-a060-af302ae89379,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-250479db-d383-4479-8dc4-f4146b13f0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-61771015-80fe-440c-ac22-fbef5b75bd80,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-ad22a229-7ebe-4494-89ec-46d50cd4ce21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1000
v2: 100000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188460727-172.17.0.21-1597508547522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40898,DS-6aae7267-5b9b-4183-a08d-a6e8ab9fc3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-d89d14c4-3c71-4baf-89ce-ec8bd971a90c,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-d230a47c-a2cb-4f2e-b65a-6902fb39c8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-03e04c58-014d-4b43-a660-1663958e7112,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-a5eca922-e373-4209-a7a7-c921fc6d53c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-650f4ac9-c4b6-4b7d-9b28-6c8c817ba6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-166298b2-276e-4ae8-a398-023e2e47696b,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-9e7d255e-d4e0-45d3-b3ed-d241add33642,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188460727-172.17.0.21-1597508547522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40898,DS-6aae7267-5b9b-4183-a08d-a6e8ab9fc3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-d89d14c4-3c71-4baf-89ce-ec8bd971a90c,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-d230a47c-a2cb-4f2e-b65a-6902fb39c8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-03e04c58-014d-4b43-a660-1663958e7112,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-a5eca922-e373-4209-a7a7-c921fc6d53c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-650f4ac9-c4b6-4b7d-9b28-6c8c817ba6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-166298b2-276e-4ae8-a398-023e2e47696b,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-9e7d255e-d4e0-45d3-b3ed-d241add33642,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 18 out of 50
result: false positive !!!
Total execution time in seconds : 5711
