reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-147732828-172.17.0.6-1597277393818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35258,DS-06dc8e13-4af9-44a2-b94c-c0ca2d42ff32,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-efb5d8a3-aee4-4afb-ba0f-98c2a3d848a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-57c0aa2b-cd28-4223-9cf4-f8949ba95a54,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-3a108ed9-f2df-42a8-905e-6eb68e47928c,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-8a0ddf2f-8aa0-43ad-b804-5f8533025a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-eb8dae5a-b3ac-4742-8931-3b5e529a495e,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-dc419d11-852f-49c7-aff4-35caaf331e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-33ff83d1-3cf1-4cf9-a1c2-67cc31b3eaa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-147732828-172.17.0.6-1597277393818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35258,DS-06dc8e13-4af9-44a2-b94c-c0ca2d42ff32,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-efb5d8a3-aee4-4afb-ba0f-98c2a3d848a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37931,DS-57c0aa2b-cd28-4223-9cf4-f8949ba95a54,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-3a108ed9-f2df-42a8-905e-6eb68e47928c,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-8a0ddf2f-8aa0-43ad-b804-5f8533025a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-eb8dae5a-b3ac-4742-8931-3b5e529a495e,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-dc419d11-852f-49c7-aff4-35caaf331e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-33ff83d1-3cf1-4cf9-a1c2-67cc31b3eaa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-883233554-172.17.0.6-1597277502277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46433,DS-35843dfe-ccfa-4a72-9be4-e7f904c26aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-bbd85bef-97e4-4fce-b5b6-bcefa905d01e,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-cc485c40-36d6-4dbb-9298-6f96dd957ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-ba669fc7-f3bb-4599-9893-f397794c71d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34770,DS-93c2d2b1-8a75-4265-a677-8cc202a0d542,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-50dc6c4c-793e-4aff-b079-9c1a9beb7313,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-6dc0ddc1-5ba3-43fb-acfc-887f245d1739,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-b3b775a1-c9e6-48f4-8950-1773b4e628d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-883233554-172.17.0.6-1597277502277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46433,DS-35843dfe-ccfa-4a72-9be4-e7f904c26aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-bbd85bef-97e4-4fce-b5b6-bcefa905d01e,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-cc485c40-36d6-4dbb-9298-6f96dd957ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-ba669fc7-f3bb-4599-9893-f397794c71d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34770,DS-93c2d2b1-8a75-4265-a677-8cc202a0d542,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-50dc6c4c-793e-4aff-b079-9c1a9beb7313,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-6dc0ddc1-5ba3-43fb-acfc-887f245d1739,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-b3b775a1-c9e6-48f4-8950-1773b4e628d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597012755-172.17.0.6-1597278014922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33353,DS-5e4a67e5-e167-4dd0-8c44-6b187786193e,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-aa9bd3c9-df62-4533-86a1-ec308e66d6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-7789e08c-5612-470c-b1ab-203f8561db02,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-adebbcb8-32b4-4102-97f9-b1ed9f5e0ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-c228bb61-4fac-487a-a2f5-bac2d188ff66,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-78e17dd7-5eb9-4ad8-a0fa-82adb1b531fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-c7057752-f563-4f1b-b7ae-0d99088e4cca,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-c13f24e6-ca27-4090-b912-3cf2d63fc167,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597012755-172.17.0.6-1597278014922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33353,DS-5e4a67e5-e167-4dd0-8c44-6b187786193e,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-aa9bd3c9-df62-4533-86a1-ec308e66d6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-7789e08c-5612-470c-b1ab-203f8561db02,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-adebbcb8-32b4-4102-97f9-b1ed9f5e0ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-c228bb61-4fac-487a-a2f5-bac2d188ff66,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-78e17dd7-5eb9-4ad8-a0fa-82adb1b531fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-c7057752-f563-4f1b-b7ae-0d99088e4cca,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-c13f24e6-ca27-4090-b912-3cf2d63fc167,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1241261275-172.17.0.6-1597278883648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42081,DS-17702106-f4d7-4e3a-b172-c0fc9a94ff15,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-b58bdaa1-02e3-46ec-85e9-9008a9eea056,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-5282c570-50ca-4dcb-b22f-28bf7d1d2421,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-9b40fbe6-8d6f-44e2-9cd1-10a7939d9b94,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-8442bd03-86bc-4786-a758-c8cc328564ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-cf02e45b-aa79-4a3a-9ace-2997bc933c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-00af6ff3-0d6e-4306-9696-ded8119544a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-4681f7fc-4101-441c-8238-3ee72944789b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1241261275-172.17.0.6-1597278883648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42081,DS-17702106-f4d7-4e3a-b172-c0fc9a94ff15,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-b58bdaa1-02e3-46ec-85e9-9008a9eea056,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-5282c570-50ca-4dcb-b22f-28bf7d1d2421,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-9b40fbe6-8d6f-44e2-9cd1-10a7939d9b94,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-8442bd03-86bc-4786-a758-c8cc328564ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-cf02e45b-aa79-4a3a-9ace-2997bc933c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-00af6ff3-0d6e-4306-9696-ded8119544a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-4681f7fc-4101-441c-8238-3ee72944789b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-307716452-172.17.0.6-1597279288331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37224,DS-62ce4ffd-c477-48c6-8f7e-6d0e578dceb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-c919684c-e01c-4ceb-a3cb-6f77da64b1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-f17bf432-b864-4972-823d-d8a24f498f22,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-0186845b-5964-4685-a2c7-c19b4533a8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-83f36631-e68b-4658-92e9-82248da82bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-c38bb2ab-93d9-4176-8686-4a748e033a76,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-51cffb03-1dc1-41bb-981a-d9fba470886f,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-0c5c3a1e-73df-4077-ab38-19435d65feb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-307716452-172.17.0.6-1597279288331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37224,DS-62ce4ffd-c477-48c6-8f7e-6d0e578dceb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-c919684c-e01c-4ceb-a3cb-6f77da64b1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-f17bf432-b864-4972-823d-d8a24f498f22,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-0186845b-5964-4685-a2c7-c19b4533a8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-83f36631-e68b-4658-92e9-82248da82bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-c38bb2ab-93d9-4176-8686-4a748e033a76,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-51cffb03-1dc1-41bb-981a-d9fba470886f,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-0c5c3a1e-73df-4077-ab38-19435d65feb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841507403-172.17.0.6-1597279546073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43047,DS-c26fe14d-a4eb-42a5-bb39-6a3a7ac8b3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-1b3cc88c-b93d-4bbd-ac13-b9bfb2b00db4,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-b96fc33e-a386-4b4d-9423-e0dd140f7501,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-cf977a0e-4e91-4808-8fd9-b4404062ccad,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-56a9fba5-92c0-44dc-9301-26864ff16650,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-c7c331d3-ffed-4be1-b98c-72255d383f33,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-6683e5c3-42bd-4be7-a1ae-9a911a3d056e,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-9f063713-0f34-4b00-8178-104778ebdefd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841507403-172.17.0.6-1597279546073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43047,DS-c26fe14d-a4eb-42a5-bb39-6a3a7ac8b3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-1b3cc88c-b93d-4bbd-ac13-b9bfb2b00db4,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-b96fc33e-a386-4b4d-9423-e0dd140f7501,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-cf977a0e-4e91-4808-8fd9-b4404062ccad,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-56a9fba5-92c0-44dc-9301-26864ff16650,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-c7c331d3-ffed-4be1-b98c-72255d383f33,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-6683e5c3-42bd-4be7-a1ae-9a911a3d056e,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-9f063713-0f34-4b00-8178-104778ebdefd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052166011-172.17.0.6-1597280531418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37069,DS-14745729-d3fe-49b2-b6c2-b1db1e0b0fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-12f7f1c6-57ce-4c19-8625-5ebdd9c11aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42723,DS-aa7f37a6-b717-4a99-ba5b-e5fe8a8f3528,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-897f2438-f8ae-4c7a-b8aa-8deedfa92c41,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-996986b8-2aa0-41b9-a800-e69a756814cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-a4ee34df-f3c8-4d7a-b8a0-5bffdda87490,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-0b6f3a4c-f89f-40f6-918a-84317417cf75,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-4e17ad6b-0eae-4747-b1c7-6f1099a605c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052166011-172.17.0.6-1597280531418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37069,DS-14745729-d3fe-49b2-b6c2-b1db1e0b0fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-12f7f1c6-57ce-4c19-8625-5ebdd9c11aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42723,DS-aa7f37a6-b717-4a99-ba5b-e5fe8a8f3528,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-897f2438-f8ae-4c7a-b8aa-8deedfa92c41,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-996986b8-2aa0-41b9-a800-e69a756814cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-a4ee34df-f3c8-4d7a-b8a0-5bffdda87490,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-0b6f3a4c-f89f-40f6-918a-84317417cf75,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-4e17ad6b-0eae-4747-b1c7-6f1099a605c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-681011627-172.17.0.6-1597281026362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46024,DS-e6f3903a-acb4-4e24-abd0-9c7f6e72ec1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-e3ba41d0-34dd-4b21-9317-ceb4d9e9b15f,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-850a1e71-31d1-4976-84b1-84b33d3d538d,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-97a716c0-b7d1-43bc-b711-4a22383c7280,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-efa0b338-69a3-4869-b3e2-2d62df9916df,DISK], DatanodeInfoWithStorage[127.0.0.1:44858,DS-8f32bcfa-0d51-4af5-b0ee-319affa5ebe0,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-69b52b67-7519-4374-a7a9-725584dfae12,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-3e03849d-beb5-43d1-b059-745933a3a2a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-681011627-172.17.0.6-1597281026362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46024,DS-e6f3903a-acb4-4e24-abd0-9c7f6e72ec1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-e3ba41d0-34dd-4b21-9317-ceb4d9e9b15f,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-850a1e71-31d1-4976-84b1-84b33d3d538d,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-97a716c0-b7d1-43bc-b711-4a22383c7280,DISK], DatanodeInfoWithStorage[127.0.0.1:35631,DS-efa0b338-69a3-4869-b3e2-2d62df9916df,DISK], DatanodeInfoWithStorage[127.0.0.1:44858,DS-8f32bcfa-0d51-4af5-b0ee-319affa5ebe0,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-69b52b67-7519-4374-a7a9-725584dfae12,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-3e03849d-beb5-43d1-b059-745933a3a2a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-539735368-172.17.0.6-1597281135337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41694,DS-904bd9e1-5670-40d4-8cad-b5d2f005b5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-37045e8f-97fd-4996-b313-84c9463b42eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-4ac446ec-ab2c-44ee-8fda-18c2471ab7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-ab39f03a-8311-4d1b-8ded-a384324bab7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-5064da9f-6dd6-4f65-8133-9fd9754b8e23,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-a0721369-7284-4809-8420-f77261909120,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-d98fadca-8935-4e4b-84a6-5e5968c92ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-704a19aa-2bc6-4626-aece-d5ee79ffd907,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-539735368-172.17.0.6-1597281135337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41694,DS-904bd9e1-5670-40d4-8cad-b5d2f005b5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-37045e8f-97fd-4996-b313-84c9463b42eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-4ac446ec-ab2c-44ee-8fda-18c2471ab7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-ab39f03a-8311-4d1b-8ded-a384324bab7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-5064da9f-6dd6-4f65-8133-9fd9754b8e23,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-a0721369-7284-4809-8420-f77261909120,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-d98fadca-8935-4e4b-84a6-5e5968c92ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-704a19aa-2bc6-4626-aece-d5ee79ffd907,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117669614-172.17.0.6-1597281273545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43419,DS-60e5e950-471b-43e3-9075-be142510d509,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-3dda687c-b2a1-42f8-9bdd-104acddd16f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-baf5f028-bbf5-4f23-932b-b88173878614,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-520e7028-7ffd-4a09-893f-440527b894d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-e3911aa9-c3a6-4f06-9000-563f2cce3542,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-535d9b1a-2ad4-4bb9-97d7-03c36dbc533c,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-16a3f467-668c-484a-90f1-e495a0cd8995,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-98dbd4e1-d134-4813-b91c-7bafa79ae86d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117669614-172.17.0.6-1597281273545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43419,DS-60e5e950-471b-43e3-9075-be142510d509,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-3dda687c-b2a1-42f8-9bdd-104acddd16f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-baf5f028-bbf5-4f23-932b-b88173878614,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-520e7028-7ffd-4a09-893f-440527b894d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-e3911aa9-c3a6-4f06-9000-563f2cce3542,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-535d9b1a-2ad4-4bb9-97d7-03c36dbc533c,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-16a3f467-668c-484a-90f1-e495a0cd8995,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-98dbd4e1-d134-4813-b91c-7bafa79ae86d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1949531168-172.17.0.6-1597281519842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43994,DS-b74a526f-3658-45f7-9e2c-e7282f1934fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-fb385a77-d95e-4722-a196-88cdcce6ac66,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-245e7ba5-b020-4fb5-97b3-addbb8acff90,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-5552f46c-ebeb-452f-9aa7-13c9a0ac9437,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-8bcad173-f72f-49c7-b3e7-ae4208c6837d,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-c7cb6c4f-b1a3-4a5b-b1de-cb40acba787c,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-1ea77d28-8da3-4560-9852-66a53eb86a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-3fed2d57-9464-4516-baf9-4a75d255b7a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1949531168-172.17.0.6-1597281519842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43994,DS-b74a526f-3658-45f7-9e2c-e7282f1934fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-fb385a77-d95e-4722-a196-88cdcce6ac66,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-245e7ba5-b020-4fb5-97b3-addbb8acff90,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-5552f46c-ebeb-452f-9aa7-13c9a0ac9437,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-8bcad173-f72f-49c7-b3e7-ae4208c6837d,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-c7cb6c4f-b1a3-4a5b-b1de-cb40acba787c,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-1ea77d28-8da3-4560-9852-66a53eb86a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-3fed2d57-9464-4516-baf9-4a75d255b7a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1256408063-172.17.0.6-1597281790963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43269,DS-fdd07b50-1206-41da-b21d-2d7d85ad310f,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-2098e335-eca8-4a60-ab3f-0ce4d1d20785,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-13c862ee-f602-46d9-944b-f29dff6f7024,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-6368c471-6cc1-4f0a-b5e3-f016f7831d82,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-328d37b8-d4bb-467c-8eb1-a30cc59e6d22,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-8bc255df-1cde-4b01-8458-c95c7979e12b,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-8a995de5-437d-48cc-9ab4-29e4821bddec,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-043eec25-1b3a-4391-9350-de6c9c8b9dd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1256408063-172.17.0.6-1597281790963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43269,DS-fdd07b50-1206-41da-b21d-2d7d85ad310f,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-2098e335-eca8-4a60-ab3f-0ce4d1d20785,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-13c862ee-f602-46d9-944b-f29dff6f7024,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-6368c471-6cc1-4f0a-b5e3-f016f7831d82,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-328d37b8-d4bb-467c-8eb1-a30cc59e6d22,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-8bc255df-1cde-4b01-8458-c95c7979e12b,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-8a995de5-437d-48cc-9ab4-29e4821bddec,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-043eec25-1b3a-4391-9350-de6c9c8b9dd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1131169970-172.17.0.6-1597282016472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41214,DS-b5f12d98-92a1-4e10-9504-b2ce072a6666,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-75e599c2-86e2-4332-9189-ae19418e199b,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-745dcc69-94cd-4fc1-b6e9-8b50b6c1556e,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-3dc95dd0-7914-40fe-8704-3726488f34e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-e9dee039-9b68-4826-9172-6f36320570aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-fadf89c3-c1f0-410e-8b33-d67846c3bc96,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-be5ea046-f01b-439c-9eac-0553ae60c332,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-97468d69-7777-45b2-aa61-b57c8c24af6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1131169970-172.17.0.6-1597282016472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41214,DS-b5f12d98-92a1-4e10-9504-b2ce072a6666,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-75e599c2-86e2-4332-9189-ae19418e199b,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-745dcc69-94cd-4fc1-b6e9-8b50b6c1556e,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-3dc95dd0-7914-40fe-8704-3726488f34e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-e9dee039-9b68-4826-9172-6f36320570aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-fadf89c3-c1f0-410e-8b33-d67846c3bc96,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-be5ea046-f01b-439c-9eac-0553ae60c332,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-97468d69-7777-45b2-aa61-b57c8c24af6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1973645010-172.17.0.6-1597282276884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34856,DS-3e0859b4-4062-4e69-9323-c928a2efe473,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-6d1e1364-e091-4174-98d9-119d79110824,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-a0267281-46ad-4fac-a799-a75265d5ff90,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-6177b4a0-89b3-463b-8ad5-be0cc6a2fb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-171ed3a0-bb44-448d-85c5-e92c47665c91,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-dd5930a8-8c49-418f-9e12-a33f8a99d976,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-da096da2-e486-4a7a-87c9-58f2c962aec7,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-ba67991d-2a25-467f-bf88-fb78f73d55a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1973645010-172.17.0.6-1597282276884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34856,DS-3e0859b4-4062-4e69-9323-c928a2efe473,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-6d1e1364-e091-4174-98d9-119d79110824,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-a0267281-46ad-4fac-a799-a75265d5ff90,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-6177b4a0-89b3-463b-8ad5-be0cc6a2fb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-171ed3a0-bb44-448d-85c5-e92c47665c91,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-dd5930a8-8c49-418f-9e12-a33f8a99d976,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-da096da2-e486-4a7a-87c9-58f2c962aec7,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-ba67991d-2a25-467f-bf88-fb78f73d55a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-622702911-172.17.0.6-1597282673633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36132,DS-4e616969-904f-45a8-9935-7b4e12dba100,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-a6575081-99cf-44be-a5e9-7da1e5cb2395,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-c437af64-c654-4278-88fc-bee66fdf8367,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-db10eb12-4ca9-4014-bddc-5a602dc4ecc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-90854f7e-4490-48e5-b441-adb195850ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-825c298f-c005-431f-b286-4d3c6d4f7564,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-acbc97c8-31b4-4ac5-91b2-2f1b9f496592,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-2d3da070-6bd2-4bc9-9866-00316de37025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-622702911-172.17.0.6-1597282673633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36132,DS-4e616969-904f-45a8-9935-7b4e12dba100,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-a6575081-99cf-44be-a5e9-7da1e5cb2395,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-c437af64-c654-4278-88fc-bee66fdf8367,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-db10eb12-4ca9-4014-bddc-5a602dc4ecc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-90854f7e-4490-48e5-b441-adb195850ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:35529,DS-825c298f-c005-431f-b286-4d3c6d4f7564,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-acbc97c8-31b4-4ac5-91b2-2f1b9f496592,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-2d3da070-6bd2-4bc9-9866-00316de37025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threshold.millis
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052212334-172.17.0.6-1597282750287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39121,DS-f62d8548-7d9f-4b17-817c-4fd518c66644,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-97abf4eb-ae83-4f62-b571-36162e06f960,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-cf5f56e6-42e8-4728-9b6a-35804709155f,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-6b6e8af8-794d-41d4-b4fd-8c07846fbd88,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-866d2399-e21a-46b6-b690-3e9a31cee79d,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-630e1ed2-f51e-4ccc-91fb-72e733e98cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-af1b3396-fe60-4bc7-927c-8676d58b293c,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-f0ec4e5c-45fc-454e-bf1f-140052017165,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052212334-172.17.0.6-1597282750287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39121,DS-f62d8548-7d9f-4b17-817c-4fd518c66644,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-97abf4eb-ae83-4f62-b571-36162e06f960,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-cf5f56e6-42e8-4728-9b6a-35804709155f,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-6b6e8af8-794d-41d4-b4fd-8c07846fbd88,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-866d2399-e21a-46b6-b690-3e9a31cee79d,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-630e1ed2-f51e-4ccc-91fb-72e733e98cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-af1b3396-fe60-4bc7-927c-8676d58b293c,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-f0ec4e5c-45fc-454e-bf1f-140052017165,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5544
