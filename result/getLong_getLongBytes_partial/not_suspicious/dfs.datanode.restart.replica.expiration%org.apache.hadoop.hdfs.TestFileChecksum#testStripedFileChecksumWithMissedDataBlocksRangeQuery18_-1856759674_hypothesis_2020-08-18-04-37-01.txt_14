reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1418820177-172.17.0.20-1597726009984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37242,DS-dc8c82a6-4382-4519-9995-4b3d61992128,DISK], DatanodeInfoWithStorage[127.0.0.1:37473,DS-f7bf4fca-e6d3-4945-8ed0-e81ab02a8e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-b0816653-056f-48e5-acb6-f776aa0b79d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-f9cac620-853c-4de7-bb02-7a875565b6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-ad94f399-0c9b-4992-acd3-011535d87315,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-26f0a849-d234-4cda-bd73-d30e7eac75bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42019,DS-49486cff-194d-4442-ab6b-4c9022d13bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-cb6e120b-b6d8-486a-b80e-b51b55392398,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1418820177-172.17.0.20-1597726009984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37242,DS-dc8c82a6-4382-4519-9995-4b3d61992128,DISK], DatanodeInfoWithStorage[127.0.0.1:37473,DS-f7bf4fca-e6d3-4945-8ed0-e81ab02a8e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-b0816653-056f-48e5-acb6-f776aa0b79d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-f9cac620-853c-4de7-bb02-7a875565b6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-ad94f399-0c9b-4992-acd3-011535d87315,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-26f0a849-d234-4cda-bd73-d30e7eac75bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42019,DS-49486cff-194d-4442-ab6b-4c9022d13bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-cb6e120b-b6d8-486a-b80e-b51b55392398,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1400340032-172.17.0.20-1597726142817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35856,DS-1bd69c7d-94c0-4881-9599-3db0fbd8902b,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-d72ab598-e986-4b9a-9ae9-f16cfd16ab18,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-01676059-8c01-4ec9-aed4-3e2452fc5b35,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-d887a71e-e7ed-42a6-b166-685de050e7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-509b1694-aae3-4729-b559-31db123070e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-5619a0ee-a979-47bd-b3e4-ac5be840b9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-fd008263-af60-4fbb-8559-7f08a6b079a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-4b6032f5-146f-46dd-93db-fd8f1162cbb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1400340032-172.17.0.20-1597726142817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35856,DS-1bd69c7d-94c0-4881-9599-3db0fbd8902b,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-d72ab598-e986-4b9a-9ae9-f16cfd16ab18,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-01676059-8c01-4ec9-aed4-3e2452fc5b35,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-d887a71e-e7ed-42a6-b166-685de050e7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-509b1694-aae3-4729-b559-31db123070e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-5619a0ee-a979-47bd-b3e4-ac5be840b9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-fd008263-af60-4fbb-8559-7f08a6b079a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-4b6032f5-146f-46dd-93db-fd8f1162cbb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1243089060-172.17.0.20-1597726570970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36781,DS-afb08018-ee4b-4b84-921f-f464e16d6983,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-fa5d6867-6d6f-42ef-9eb7-e2dbe1e920ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-e9282f69-4b9a-49d1-840d-b5aec54c3d39,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-d704e28c-8ab0-4ce1-b63a-95ec2c5c906f,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-8e8b68bb-f42d-4abb-9fd6-506cf2d1f7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-80620f22-c574-4f37-86b3-831022929b16,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-045ab32a-fcc1-4fca-b589-05ac3d2510dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-1d9e1f62-9f1d-4f32-9d1f-3c9304668275,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1243089060-172.17.0.20-1597726570970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36781,DS-afb08018-ee4b-4b84-921f-f464e16d6983,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-fa5d6867-6d6f-42ef-9eb7-e2dbe1e920ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-e9282f69-4b9a-49d1-840d-b5aec54c3d39,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-d704e28c-8ab0-4ce1-b63a-95ec2c5c906f,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-8e8b68bb-f42d-4abb-9fd6-506cf2d1f7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-80620f22-c574-4f37-86b3-831022929b16,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-045ab32a-fcc1-4fca-b589-05ac3d2510dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-1d9e1f62-9f1d-4f32-9d1f-3c9304668275,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2127878686-172.17.0.20-1597726647981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44867,DS-ff0c9d28-b730-4d9c-8274-327b2fe35d86,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-532eeb4e-def0-4a88-ac63-29b45ee9f810,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-266daf70-39f9-4fcb-b125-c00d7e213bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-875374a9-1809-4a34-8af3-abd5efef5e43,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-8a649a6f-380b-46a2-80c1-1966f84f4883,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-f84e05c6-ddab-4872-8e4d-6c923d0a5c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-6fc07b4e-3838-4ebf-8da2-8892525aaa2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-24477888-744e-4b16-a0ce-ee03f70fd8eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2127878686-172.17.0.20-1597726647981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44867,DS-ff0c9d28-b730-4d9c-8274-327b2fe35d86,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-532eeb4e-def0-4a88-ac63-29b45ee9f810,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-266daf70-39f9-4fcb-b125-c00d7e213bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-875374a9-1809-4a34-8af3-abd5efef5e43,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-8a649a6f-380b-46a2-80c1-1966f84f4883,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-f84e05c6-ddab-4872-8e4d-6c923d0a5c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-6fc07b4e-3838-4ebf-8da2-8892525aaa2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-24477888-744e-4b16-a0ce-ee03f70fd8eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-136619660-172.17.0.20-1597726729709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33057,DS-69399a4d-5046-4057-a726-0adb862d5065,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-d7d793c0-e46c-4de4-b286-bb2d45c10ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-cf839fda-6549-459a-9265-917d3663fadf,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-f43ae396-a606-4576-9253-e7a3e22a29d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-7509897b-9ba1-44c6-ac3c-118221610e63,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-9eb0230d-58ef-4642-b5cc-a085498012a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-9b16ff0f-6bfa-4c57-9b54-97eb69be5519,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-dda72fd2-cc8a-4f2d-a0b4-e47bc38e9528,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-136619660-172.17.0.20-1597726729709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33057,DS-69399a4d-5046-4057-a726-0adb862d5065,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-d7d793c0-e46c-4de4-b286-bb2d45c10ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-cf839fda-6549-459a-9265-917d3663fadf,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-f43ae396-a606-4576-9253-e7a3e22a29d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-7509897b-9ba1-44c6-ac3c-118221610e63,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-9eb0230d-58ef-4642-b5cc-a085498012a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-9b16ff0f-6bfa-4c57-9b54-97eb69be5519,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-dda72fd2-cc8a-4f2d-a0b4-e47bc38e9528,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-535277744-172.17.0.20-1597726797456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40861,DS-4ea620b3-17f0-421f-a398-e4a2b7c2d671,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-390670ef-ec83-43fe-8d8c-e82f08113e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-68d3087a-7c9f-4afe-97a3-78fb8a8aaad1,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-edc09276-39cf-4790-9422-3d04d645bd99,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-366e8f9a-fcd6-4a9b-9c17-368e22456dba,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-f5768d96-7337-4789-a9db-63de1895ab48,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-a7969dbe-6d80-431c-8953-b5840b260ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-da885b69-feaa-477a-9c93-dc15ce1bac64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-535277744-172.17.0.20-1597726797456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40861,DS-4ea620b3-17f0-421f-a398-e4a2b7c2d671,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-390670ef-ec83-43fe-8d8c-e82f08113e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-68d3087a-7c9f-4afe-97a3-78fb8a8aaad1,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-edc09276-39cf-4790-9422-3d04d645bd99,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-366e8f9a-fcd6-4a9b-9c17-368e22456dba,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-f5768d96-7337-4789-a9db-63de1895ab48,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-a7969dbe-6d80-431c-8953-b5840b260ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-da885b69-feaa-477a-9c93-dc15ce1bac64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1716160625-172.17.0.20-1597727437250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43601,DS-50dcb79e-2bc0-43ef-80af-13b607d283fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-f1802bf1-699b-486a-be8d-a47020f0149a,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-c4015c14-7dcb-4259-87ad-9320041cf6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-0574eaaa-50a8-4593-8a61-9b9bfe520f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-2dc2a38c-844d-441f-8d49-48e5532232d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-8848e6fb-8fec-4db4-a1bb-475552ddd241,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-4eefd709-7d2c-40a0-a9e5-deb6384a2b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-d7994396-6080-4dba-a745-0e55835d981c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1716160625-172.17.0.20-1597727437250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43601,DS-50dcb79e-2bc0-43ef-80af-13b607d283fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-f1802bf1-699b-486a-be8d-a47020f0149a,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-c4015c14-7dcb-4259-87ad-9320041cf6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-0574eaaa-50a8-4593-8a61-9b9bfe520f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-2dc2a38c-844d-441f-8d49-48e5532232d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-8848e6fb-8fec-4db4-a1bb-475552ddd241,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-4eefd709-7d2c-40a0-a9e5-deb6384a2b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-d7994396-6080-4dba-a745-0e55835d981c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1683597655-172.17.0.20-1597727947220:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41302,DS-6428751f-00e5-4f64-9f2d-789e1dbec8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-fc9c8f10-c925-4c55-87f8-9575b4d01869,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-617238b0-99ed-489e-8ca5-0b25897afc90,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-527c5d09-8633-410d-9690-2cb13ac1e651,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-113629ba-7c02-47d3-822f-1c481aaf66d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-2e2996e2-acd3-462a-851b-6da54bf66f53,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-025b6899-eb4b-438a-b8e3-1f9cddfdf373,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-c2ae4cd0-5867-48a6-8b72-776c15741737,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1683597655-172.17.0.20-1597727947220:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41302,DS-6428751f-00e5-4f64-9f2d-789e1dbec8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-fc9c8f10-c925-4c55-87f8-9575b4d01869,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-617238b0-99ed-489e-8ca5-0b25897afc90,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-527c5d09-8633-410d-9690-2cb13ac1e651,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-113629ba-7c02-47d3-822f-1c481aaf66d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-2e2996e2-acd3-462a-851b-6da54bf66f53,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-025b6899-eb4b-438a-b8e3-1f9cddfdf373,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-c2ae4cd0-5867-48a6-8b72-776c15741737,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-322623176-172.17.0.20-1597728087069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42832,DS-6e200b65-2233-429b-a4eb-ba851471770e,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-a359ecc4-64e6-46e0-a4c0-155647c80db6,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-bec40c32-197b-4488-a1b1-c4b699847d58,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-8726e531-a02c-4d94-92b5-1c5ff019d109,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-167421bd-2b71-46ca-a711-ae499936ca95,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-2387c200-8c42-411c-a410-e72355aed8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-c76f89e1-c73f-4234-96a1-b25b21aaea4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-3e7759c5-5d32-48ad-99b9-689eed9c61e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-322623176-172.17.0.20-1597728087069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42832,DS-6e200b65-2233-429b-a4eb-ba851471770e,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-a359ecc4-64e6-46e0-a4c0-155647c80db6,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-bec40c32-197b-4488-a1b1-c4b699847d58,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-8726e531-a02c-4d94-92b5-1c5ff019d109,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-167421bd-2b71-46ca-a711-ae499936ca95,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-2387c200-8c42-411c-a410-e72355aed8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-c76f89e1-c73f-4234-96a1-b25b21aaea4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-3e7759c5-5d32-48ad-99b9-689eed9c61e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-976104149-172.17.0.20-1597728125349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33987,DS-56a36d5c-7a9b-4976-a423-f582c7ba9a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-98c79947-4d14-43cf-abc3-3e9ae079ba53,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-fbea4c05-c8bc-4eeb-8cb3-9c6e8e623b29,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-8335c10c-abbf-4b6d-83cf-a51416ebee67,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-79f90ae0-2933-47a4-91af-61d5e0189ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-2ff034ba-8971-4c12-983f-30632e69b20d,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-74077aef-178d-4f70-8d30-ffa115d8bfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-9ddcfaf3-b703-4c96-ab24-81b739420e77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-976104149-172.17.0.20-1597728125349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33987,DS-56a36d5c-7a9b-4976-a423-f582c7ba9a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-98c79947-4d14-43cf-abc3-3e9ae079ba53,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-fbea4c05-c8bc-4eeb-8cb3-9c6e8e623b29,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-8335c10c-abbf-4b6d-83cf-a51416ebee67,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-79f90ae0-2933-47a4-91af-61d5e0189ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-2ff034ba-8971-4c12-983f-30632e69b20d,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-74077aef-178d-4f70-8d30-ffa115d8bfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-9ddcfaf3-b703-4c96-ab24-81b739420e77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-953576061-172.17.0.20-1597728212535:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42514,DS-f6b5512e-5f90-4656-9b3b-13837ef763ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-c2620a1e-916f-47c9-b33f-b17cb5f259e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-88f576ab-874d-466a-a753-7a4994b1767d,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-8196382f-7a25-49d5-a292-705887a9e25b,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-2bb04617-d1f2-4605-a42a-d0560d56f037,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-6c60e249-70b4-484b-9df0-de40f12a2bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-1fedeaa8-e428-4e89-9cf4-9825fe07cf24,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-52f52dce-1baa-4e54-a354-a09c619ea6d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-953576061-172.17.0.20-1597728212535:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42514,DS-f6b5512e-5f90-4656-9b3b-13837ef763ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-c2620a1e-916f-47c9-b33f-b17cb5f259e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-88f576ab-874d-466a-a753-7a4994b1767d,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-8196382f-7a25-49d5-a292-705887a9e25b,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-2bb04617-d1f2-4605-a42a-d0560d56f037,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-6c60e249-70b4-484b-9df0-de40f12a2bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-1fedeaa8-e428-4e89-9cf4-9825fe07cf24,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-52f52dce-1baa-4e54-a354-a09c619ea6d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2028275474-172.17.0.20-1597728816487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33426,DS-d4484ebe-7987-46f3-8232-2a1dc8c05192,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-dce284a1-9a34-4ea2-82c2-0bd0a2a4f33f,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-7da624f3-9941-41ea-8adf-83598724ebf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-ce4e8bb7-1181-4387-99ea-894740c8b71c,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-0549d9b7-e0e7-43a2-af0c-bc9df178eff2,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-7c9d155c-7cc6-485c-9f68-62b8f00e61d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-5089219f-d32e-480c-a9fb-f2c87e36cb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-4ebebcc4-7158-40a7-bece-095e06f295bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2028275474-172.17.0.20-1597728816487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33426,DS-d4484ebe-7987-46f3-8232-2a1dc8c05192,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-dce284a1-9a34-4ea2-82c2-0bd0a2a4f33f,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-7da624f3-9941-41ea-8adf-83598724ebf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-ce4e8bb7-1181-4387-99ea-894740c8b71c,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-0549d9b7-e0e7-43a2-af0c-bc9df178eff2,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-7c9d155c-7cc6-485c-9f68-62b8f00e61d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-5089219f-d32e-480c-a9fb-f2c87e36cb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-4ebebcc4-7158-40a7-bece-095e06f295bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-537167090-172.17.0.20-1597729239781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44676,DS-7ed5ea90-2376-4b5b-8a09-b347f266ed63,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-6fa0fc92-8782-4f69-b704-7f439ec28188,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-38bd1542-cd0f-4594-a954-c2d4a9114d75,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-a8094581-3f56-46ae-a394-11c74814f340,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-17cce386-e354-4427-b820-bf97b1683769,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-d529940d-2a69-4732-8397-7e778654199e,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-a37b3e4a-41f1-4414-8b6c-57d7ec54be89,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-b1ecd656-57ea-41b1-a9d4-7838108c4af4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-537167090-172.17.0.20-1597729239781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44676,DS-7ed5ea90-2376-4b5b-8a09-b347f266ed63,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-6fa0fc92-8782-4f69-b704-7f439ec28188,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-38bd1542-cd0f-4594-a954-c2d4a9114d75,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-a8094581-3f56-46ae-a394-11c74814f340,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-17cce386-e354-4427-b820-bf97b1683769,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-d529940d-2a69-4732-8397-7e778654199e,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-a37b3e4a-41f1-4414-8b6c-57d7ec54be89,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-b1ecd656-57ea-41b1-a9d4-7838108c4af4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-849072701-172.17.0.20-1597730164119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36529,DS-20d8acfa-1e73-4106-983b-c4fc83583d38,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-2b4c92ed-bf4b-4b1f-9562-fcd355d4a597,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-4ec09c6a-786d-4d05-be2c-9459f19f8966,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-009262c6-5940-4390-b518-ef14d57e39bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39436,DS-68073fbf-e5f7-40ce-832f-53cfab79dbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-d684385d-ac98-462a-90a5-df43ea043cae,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-ac6d327d-3739-4508-9bf9-2067191c33cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-87037df6-d9d8-4bf1-8d0c-66222371477c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-849072701-172.17.0.20-1597730164119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36529,DS-20d8acfa-1e73-4106-983b-c4fc83583d38,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-2b4c92ed-bf4b-4b1f-9562-fcd355d4a597,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-4ec09c6a-786d-4d05-be2c-9459f19f8966,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-009262c6-5940-4390-b518-ef14d57e39bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39436,DS-68073fbf-e5f7-40ce-832f-53cfab79dbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-d684385d-ac98-462a-90a5-df43ea043cae,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-ac6d327d-3739-4508-9bf9-2067191c33cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-87037df6-d9d8-4bf1-8d0c-66222371477c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1934494716-172.17.0.20-1597730651051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46558,DS-912e1657-53ed-41f1-af53-9c4436442886,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-a6f5633d-ee31-49a0-bc8f-3463aa5b18b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-1c291381-f472-46dc-b75e-452275b101ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-e17e9556-55e2-4de0-994f-337890bfdc93,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-04eaad7b-4c39-4414-b793-5e3d6306bf2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-c9bee44a-d6fe-4fa8-ba05-112c8d3703b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-6be3d48e-1d95-410d-af9b-7e2ff55b9bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40081,DS-76eef692-4988-4d78-ab95-ba02207c422d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1934494716-172.17.0.20-1597730651051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46558,DS-912e1657-53ed-41f1-af53-9c4436442886,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-a6f5633d-ee31-49a0-bc8f-3463aa5b18b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-1c291381-f472-46dc-b75e-452275b101ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-e17e9556-55e2-4de0-994f-337890bfdc93,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-04eaad7b-4c39-4414-b793-5e3d6306bf2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-c9bee44a-d6fe-4fa8-ba05-112c8d3703b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-6be3d48e-1d95-410d-af9b-7e2ff55b9bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40081,DS-76eef692-4988-4d78-ab95-ba02207c422d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5395
