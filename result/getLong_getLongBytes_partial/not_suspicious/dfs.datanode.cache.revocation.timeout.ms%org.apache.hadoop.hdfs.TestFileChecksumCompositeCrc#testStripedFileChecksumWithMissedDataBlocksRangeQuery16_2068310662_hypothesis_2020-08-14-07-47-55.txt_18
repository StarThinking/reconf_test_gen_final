reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1830459291-172.17.0.16-1597391613717:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46503,DS-9e8cbaab-2545-4bcf-9cc6-585a540345dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-b58e56ae-eec5-46f3-849c-c5424799e7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-a82563a5-6fda-4f8b-94b8-f40f67738077,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-bcd07907-744b-4310-a141-38b03f5c7f63,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-341f22ce-b938-498c-b807-8751ab1fa76c,DISK], DatanodeInfoWithStorage[127.0.0.1:43867,DS-9eaef1d2-b3c7-468b-986c-9e7351bfdd05,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-594499aa-a5c5-46cd-8491-94fa90a857fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34382,DS-21b08453-35c2-432e-ab77-b3329bd0c9b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1830459291-172.17.0.16-1597391613717:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46503,DS-9e8cbaab-2545-4bcf-9cc6-585a540345dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-b58e56ae-eec5-46f3-849c-c5424799e7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-a82563a5-6fda-4f8b-94b8-f40f67738077,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-bcd07907-744b-4310-a141-38b03f5c7f63,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-341f22ce-b938-498c-b807-8751ab1fa76c,DISK], DatanodeInfoWithStorage[127.0.0.1:43867,DS-9eaef1d2-b3c7-468b-986c-9e7351bfdd05,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-594499aa-a5c5-46cd-8491-94fa90a857fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34382,DS-21b08453-35c2-432e-ab77-b3329bd0c9b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1551326916-172.17.0.16-1597392109442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33347,DS-5856e0bc-bf8b-4903-b0da-9108722bd4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-1269d1cd-6ef8-4c38-8efb-fd3bde9414cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-568febd1-cc96-4759-9852-29b5c4628aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-fe2e2454-6f12-4cf0-8769-745cb9e4eb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-f5c557cc-8fe6-4137-af5d-8ce7d172d065,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-a5c88bba-8422-4ae4-bef3-38cbf14afe49,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-38ce1691-e02c-46e6-b904-20ca857ae721,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-52ffb75a-e147-447b-bc87-4c3b3f67fc37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1551326916-172.17.0.16-1597392109442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33347,DS-5856e0bc-bf8b-4903-b0da-9108722bd4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-1269d1cd-6ef8-4c38-8efb-fd3bde9414cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-568febd1-cc96-4759-9852-29b5c4628aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-fe2e2454-6f12-4cf0-8769-745cb9e4eb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-f5c557cc-8fe6-4137-af5d-8ce7d172d065,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-a5c88bba-8422-4ae4-bef3-38cbf14afe49,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-38ce1691-e02c-46e6-b904-20ca857ae721,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-52ffb75a-e147-447b-bc87-4c3b3f67fc37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1748764244-172.17.0.16-1597392188845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45535,DS-bf463a58-3339-42d8-8ff7-d1a591ef50e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-77d43c8c-d2ac-4adf-ba6d-4959a1e7ca06,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-ec5ab06e-cdeb-4e1d-b8ca-97c94b83f459,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-9eba4dbc-648f-4e82-bcfa-c719247030dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-c81bf6a3-7561-45a5-8fb6-329498265af5,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-87935ccb-65cd-4072-9cd7-94e9c68258b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-ef8aa32a-d6d5-4e39-874b-c4c82ee062e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-08a8bc05-15bf-4cb9-9060-b791dffed43e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1748764244-172.17.0.16-1597392188845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45535,DS-bf463a58-3339-42d8-8ff7-d1a591ef50e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-77d43c8c-d2ac-4adf-ba6d-4959a1e7ca06,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-ec5ab06e-cdeb-4e1d-b8ca-97c94b83f459,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-9eba4dbc-648f-4e82-bcfa-c719247030dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-c81bf6a3-7561-45a5-8fb6-329498265af5,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-87935ccb-65cd-4072-9cd7-94e9c68258b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-ef8aa32a-d6d5-4e39-874b-c4c82ee062e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-08a8bc05-15bf-4cb9-9060-b791dffed43e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1113431023-172.17.0.16-1597393557650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33444,DS-4d897c0d-0723-4564-ae8e-b833457dc330,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-bb1d3ab6-f067-4f5c-a1a1-e6465d911bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-bfe81cca-da11-48b1-873a-6c062a7c6e64,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-517eefa2-f5d0-4140-81ba-dc63a5b4e090,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-0e8ebf41-f614-419c-b916-c8f12e3d6f76,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-90c17932-3d29-4597-89ca-026883d5be16,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-72cb0754-5a77-406e-ae9e-9d293ab1d4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-1bf74c81-617a-42b2-ac4f-a3417e33b724,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1113431023-172.17.0.16-1597393557650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33444,DS-4d897c0d-0723-4564-ae8e-b833457dc330,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-bb1d3ab6-f067-4f5c-a1a1-e6465d911bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-bfe81cca-da11-48b1-873a-6c062a7c6e64,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-517eefa2-f5d0-4140-81ba-dc63a5b4e090,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-0e8ebf41-f614-419c-b916-c8f12e3d6f76,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-90c17932-3d29-4597-89ca-026883d5be16,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-72cb0754-5a77-406e-ae9e-9d293ab1d4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-1bf74c81-617a-42b2-ac4f-a3417e33b724,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-107385308-172.17.0.16-1597393998077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42261,DS-c274d141-ca09-464e-a6cb-184483d21d84,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-ce0babb6-8dd6-42f8-b673-38c710be46dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-33584ac6-f04e-4bdf-b334-fef7a8bf1420,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-5705e0b1-849b-4da3-882f-ae8cf9fae721,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-ef25b7cc-98fc-451d-9bf8-28bd0ff802dd,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-ac4574ae-344b-4dde-91c8-9cbcab59a895,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-b2760526-b3c7-4a40-867d-e681b62327f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-52fed0c9-f115-4fa5-a95c-32426d2ddd8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-107385308-172.17.0.16-1597393998077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42261,DS-c274d141-ca09-464e-a6cb-184483d21d84,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-ce0babb6-8dd6-42f8-b673-38c710be46dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-33584ac6-f04e-4bdf-b334-fef7a8bf1420,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-5705e0b1-849b-4da3-882f-ae8cf9fae721,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-ef25b7cc-98fc-451d-9bf8-28bd0ff802dd,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-ac4574ae-344b-4dde-91c8-9cbcab59a895,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-b2760526-b3c7-4a40-867d-e681b62327f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-52fed0c9-f115-4fa5-a95c-32426d2ddd8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-643203647-172.17.0.16-1597394219055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39999,DS-db6eaa6c-4beb-4103-8429-c84dd26f6d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-22b1c022-5c06-4741-989a-3919368cbada,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-34209ec6-996d-40e8-96b0-4f218726ba56,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-bc710383-5de7-477a-8d8c-98c8088230c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-a6bd1285-eb6f-4b1f-a5bf-2b16cac222c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-1f401aa0-62d0-4528-855d-f21118804b22,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-6650a81a-5618-4410-bd15-ff49b5297eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-02e383b7-3cf3-4b01-9fcc-2d898e264e1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-643203647-172.17.0.16-1597394219055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39999,DS-db6eaa6c-4beb-4103-8429-c84dd26f6d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-22b1c022-5c06-4741-989a-3919368cbada,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-34209ec6-996d-40e8-96b0-4f218726ba56,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-bc710383-5de7-477a-8d8c-98c8088230c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-a6bd1285-eb6f-4b1f-a5bf-2b16cac222c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-1f401aa0-62d0-4528-855d-f21118804b22,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-6650a81a-5618-4410-bd15-ff49b5297eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-02e383b7-3cf3-4b01-9fcc-2d898e264e1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1226856882-172.17.0.16-1597395848139:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38069,DS-52c04901-c009-407e-b2e5-2e180da05ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-4893870e-da51-49bd-8c38-2f085394f86c,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-dd8d8135-4e20-43b5-8b54-ca499cdec64f,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-3b2f6782-32a6-498a-bed6-0ab7deeb0a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-6b98fc07-becf-4b98-8d34-78445d1d69be,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-a8f66afc-26cd-415e-83da-fae0d7d43d63,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-9d8108fa-1138-4e55-9723-a9cc3ada3cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-ca46b77b-8258-458c-8364-224924bfa541,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1226856882-172.17.0.16-1597395848139:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38069,DS-52c04901-c009-407e-b2e5-2e180da05ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-4893870e-da51-49bd-8c38-2f085394f86c,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-dd8d8135-4e20-43b5-8b54-ca499cdec64f,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-3b2f6782-32a6-498a-bed6-0ab7deeb0a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-6b98fc07-becf-4b98-8d34-78445d1d69be,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-a8f66afc-26cd-415e-83da-fae0d7d43d63,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-9d8108fa-1138-4e55-9723-a9cc3ada3cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-ca46b77b-8258-458c-8364-224924bfa541,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1421340854-172.17.0.16-1597396230711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34280,DS-356d9f00-3b0c-4dc3-9721-1a4124f7d7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-8ef36d6b-1632-4c1a-942a-cfbc0aed45be,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-94ea8b80-c0fa-4bee-86f0-a74046a2ab9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-c4acfe90-dae9-45c9-8728-a90681898006,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-22328944-854f-403d-85da-e61e5475b41f,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-a3a5a6cf-cbad-4c31-a987-71ca385ab261,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-07bde962-5353-49b6-9080-037bd3aa6b44,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-303bcc5d-ac1d-443c-9389-7b225363bcfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1421340854-172.17.0.16-1597396230711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34280,DS-356d9f00-3b0c-4dc3-9721-1a4124f7d7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-8ef36d6b-1632-4c1a-942a-cfbc0aed45be,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-94ea8b80-c0fa-4bee-86f0-a74046a2ab9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-c4acfe90-dae9-45c9-8728-a90681898006,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-22328944-854f-403d-85da-e61e5475b41f,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-a3a5a6cf-cbad-4c31-a987-71ca385ab261,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-07bde962-5353-49b6-9080-037bd3aa6b44,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-303bcc5d-ac1d-443c-9389-7b225363bcfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-133549438-172.17.0.16-1597396364544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41106,DS-3283f2b0-46b9-4b36-9c41-f8a7c0a8064c,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-bd0a24c3-a9e5-48d0-9e2e-048c1d674bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-a3e53828-fb04-4086-903e-86f44aea882b,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-faecd6cd-aaa4-4c80-bf50-881a0d91bfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-fb196498-5ae0-4e85-ad65-f58630c51e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-67f7cbb7-f875-4b36-a12e-feb8724e0cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-0b0ffd3b-8a0c-40cf-bb23-1c7f8c6c032b,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-13d3e278-548a-46c7-a99e-33d1d769d2e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-133549438-172.17.0.16-1597396364544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41106,DS-3283f2b0-46b9-4b36-9c41-f8a7c0a8064c,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-bd0a24c3-a9e5-48d0-9e2e-048c1d674bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-a3e53828-fb04-4086-903e-86f44aea882b,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-faecd6cd-aaa4-4c80-bf50-881a0d91bfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-fb196498-5ae0-4e85-ad65-f58630c51e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-67f7cbb7-f875-4b36-a12e-feb8724e0cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-0b0ffd3b-8a0c-40cf-bb23-1c7f8c6c032b,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-13d3e278-548a-46c7-a99e-33d1d769d2e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1384347852-172.17.0.16-1597397653985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33613,DS-f84369a8-baa0-4953-85d8-a9077a2928ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-e2f6bca0-2f52-44e7-972a-862fd8b4ae61,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-55c7722b-313f-44f2-ba04-946f85d004a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-82698f01-5e1e-49ac-a25b-5a7292dc6d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-50479882-4ff6-4a6e-965f-07814268ba05,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-a67fd938-6c54-4c11-b008-c88db80bd2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-fb25c2f6-888f-420b-a6b1-5f97a38056aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-a70b705e-0c67-475b-b78d-5bb2d506abcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1384347852-172.17.0.16-1597397653985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33613,DS-f84369a8-baa0-4953-85d8-a9077a2928ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-e2f6bca0-2f52-44e7-972a-862fd8b4ae61,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-55c7722b-313f-44f2-ba04-946f85d004a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-82698f01-5e1e-49ac-a25b-5a7292dc6d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-50479882-4ff6-4a6e-965f-07814268ba05,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-a67fd938-6c54-4c11-b008-c88db80bd2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-fb25c2f6-888f-420b-a6b1-5f97a38056aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-a70b705e-0c67-475b-b78d-5bb2d506abcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 900000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1401463996-172.17.0.16-1597397859127:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43049,DS-bcc0b02a-6ef7-4f4a-a36e-2023e2b11ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-4d1e40a0-bce8-4e54-891b-d6334c0bc1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-fd0dddda-1b17-488e-86f5-ba1d3e2f4f78,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-ccdd498d-8758-4cb8-9a77-b6fe1133114a,DISK], DatanodeInfoWithStorage[127.0.0.1:42406,DS-8e5081ee-7010-4995-8405-d0cbbb8033c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46761,DS-43582781-ba90-43be-9c8c-b10e879e61b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-481e1ae7-c88d-4514-9aa9-c2be284fbc54,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-814304ff-8958-4d89-a8f6-010cd7436a4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1401463996-172.17.0.16-1597397859127:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43049,DS-bcc0b02a-6ef7-4f4a-a36e-2023e2b11ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-4d1e40a0-bce8-4e54-891b-d6334c0bc1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-fd0dddda-1b17-488e-86f5-ba1d3e2f4f78,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-ccdd498d-8758-4cb8-9a77-b6fe1133114a,DISK], DatanodeInfoWithStorage[127.0.0.1:42406,DS-8e5081ee-7010-4995-8405-d0cbbb8033c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46761,DS-43582781-ba90-43be-9c8c-b10e879e61b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-481e1ae7-c88d-4514-9aa9-c2be284fbc54,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-814304ff-8958-4d89-a8f6-010cd7436a4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6918
