reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 86
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 86
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959160416-172.17.0.10-1597362732436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45097,DS-130cc929-c135-494d-903b-4b8fb1a19882,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-9fa5f9ad-09c9-4c20-9bd2-3aaffa9ad814,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-d97b6441-eabb-487d-88a4-8d9964dabe4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-f27af847-55bd-410c-8340-c6cbbdbad4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-1ba365f8-c3fc-45b2-a95c-a5a70c7c95aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-e7ba6062-347e-4650-9433-eaa9a1818408,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-3fca0588-50a8-42a4-a288-e8cc4264a8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-4d7b8759-c1f4-4701-a183-993c7212c0ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959160416-172.17.0.10-1597362732436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45097,DS-130cc929-c135-494d-903b-4b8fb1a19882,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-9fa5f9ad-09c9-4c20-9bd2-3aaffa9ad814,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-d97b6441-eabb-487d-88a4-8d9964dabe4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-f27af847-55bd-410c-8340-c6cbbdbad4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-1ba365f8-c3fc-45b2-a95c-a5a70c7c95aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-e7ba6062-347e-4650-9433-eaa9a1818408,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-3fca0588-50a8-42a4-a288-e8cc4264a8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-4d7b8759-c1f4-4701-a183-993c7212c0ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 86
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-492890365-172.17.0.10-1597362900182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41638,DS-688db475-ec2e-4bc9-b8d5-f667b73fd8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-e35f6492-8c91-450c-b532-15dd1ce68998,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-7de91d80-64b9-4d19-aa16-7a1f56f398b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-d92e13d4-4c59-4e96-99c5-a87ea8fc9476,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-5101b6fb-088b-40a8-8fb3-e8d3c2a312f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-4e308a45-b6c8-42e7-bc9f-6402e6bf8b29,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-b671d457-7113-4d0f-9ba4-e96ee4df761a,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-a3711ef9-f628-488e-a629-bbf3ad33a0e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-492890365-172.17.0.10-1597362900182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41638,DS-688db475-ec2e-4bc9-b8d5-f667b73fd8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-e35f6492-8c91-450c-b532-15dd1ce68998,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-7de91d80-64b9-4d19-aa16-7a1f56f398b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-d92e13d4-4c59-4e96-99c5-a87ea8fc9476,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-5101b6fb-088b-40a8-8fb3-e8d3c2a312f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-4e308a45-b6c8-42e7-bc9f-6402e6bf8b29,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-b671d457-7113-4d0f-9ba4-e96ee4df761a,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-a3711ef9-f628-488e-a629-bbf3ad33a0e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 86
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-572864684-172.17.0.10-1597363879475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38696,DS-6241b566-af6a-4553-9171-b7d3e5bd31c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-72ebf20d-cb5a-4860-9ecb-eb3299493f03,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-e2ad5d2e-d366-4d3b-99c8-37b68570d228,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-e2c2c514-fddd-4f89-af9c-48a6f6db3e54,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-01eb518c-9185-4db4-ba06-7e84144e5d22,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-3b4d86af-3df4-4222-a54b-8926a6617101,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-0b5d4f57-f742-4a69-bbb2-bd45bc7f22c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-7005a3f9-a56c-4dcb-ba45-4d938acc1592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-572864684-172.17.0.10-1597363879475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38696,DS-6241b566-af6a-4553-9171-b7d3e5bd31c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-72ebf20d-cb5a-4860-9ecb-eb3299493f03,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-e2ad5d2e-d366-4d3b-99c8-37b68570d228,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-e2c2c514-fddd-4f89-af9c-48a6f6db3e54,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-01eb518c-9185-4db4-ba06-7e84144e5d22,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-3b4d86af-3df4-4222-a54b-8926a6617101,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-0b5d4f57-f742-4a69-bbb2-bd45bc7f22c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-7005a3f9-a56c-4dcb-ba45-4d938acc1592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 86
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2119751107-172.17.0.10-1597364041653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37973,DS-53faa8c5-21bb-489d-8874-1f75e401cf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-2bab7026-1595-49b3-88fb-c4810fce7256,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-1b58669f-b197-4489-b579-f38c89e368db,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-5f104e37-aa30-47c3-bd63-86bf09ec8a22,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-f1a01e5a-09eb-4158-8a61-381b75d4f8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-c21553d3-359d-4c74-9dbf-550195853296,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-169c5a17-7e0e-4b79-9091-96131610ac2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-54d9a999-f860-468a-bc3f-9157ccdb87dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2119751107-172.17.0.10-1597364041653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37973,DS-53faa8c5-21bb-489d-8874-1f75e401cf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-2bab7026-1595-49b3-88fb-c4810fce7256,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-1b58669f-b197-4489-b579-f38c89e368db,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-5f104e37-aa30-47c3-bd63-86bf09ec8a22,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-f1a01e5a-09eb-4158-8a61-381b75d4f8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-c21553d3-359d-4c74-9dbf-550195853296,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-169c5a17-7e0e-4b79-9091-96131610ac2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-54d9a999-f860-468a-bc3f-9157ccdb87dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 86
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-500405643-172.17.0.10-1597364182020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32812,DS-67d2d259-cb3f-4274-9936-cf2a2f3e6562,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-449c88f4-e774-4293-ad72-a9041e9ca48e,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-b58c9945-6a9c-4ace-8f9e-689d6b5218ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-10fbb7c5-c800-446d-a22f-43148ff648de,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-3edcf1b9-08a5-4491-af21-02285102a56d,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-47e0c079-c15a-42b1-bfe5-f946a865621c,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-bcdd8c2c-0fdb-4999-82df-aaec1a578658,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-5c28098d-150d-4e7d-9b63-f2b7910355b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-500405643-172.17.0.10-1597364182020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32812,DS-67d2d259-cb3f-4274-9936-cf2a2f3e6562,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-449c88f4-e774-4293-ad72-a9041e9ca48e,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-b58c9945-6a9c-4ace-8f9e-689d6b5218ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-10fbb7c5-c800-446d-a22f-43148ff648de,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-3edcf1b9-08a5-4491-af21-02285102a56d,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-47e0c079-c15a-42b1-bfe5-f946a865621c,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-bcdd8c2c-0fdb-4999-82df-aaec1a578658,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-5c28098d-150d-4e7d-9b63-f2b7910355b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 86
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673324297-172.17.0.10-1597365371293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33850,DS-c085d741-b7e5-4661-955a-13bd9b5c4c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-afd3ba65-4ad2-42a3-a32a-f264effe949b,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-f0724b2d-9ec8-4570-88d9-72dc481df8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-1647eeeb-585b-4e7d-b0b5-9c76a252366b,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-325dc24f-e669-46d4-8888-38267c46ad5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-8c063b26-9423-400c-ba77-8f9c905e1061,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-162b2111-12c0-49be-acef-7e92348b654b,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-fe8e76e3-3dbf-462b-8ccc-643df3727d18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673324297-172.17.0.10-1597365371293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33850,DS-c085d741-b7e5-4661-955a-13bd9b5c4c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-afd3ba65-4ad2-42a3-a32a-f264effe949b,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-f0724b2d-9ec8-4570-88d9-72dc481df8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-1647eeeb-585b-4e7d-b0b5-9c76a252366b,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-325dc24f-e669-46d4-8888-38267c46ad5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-8c063b26-9423-400c-ba77-8f9c905e1061,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-162b2111-12c0-49be-acef-7e92348b654b,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-fe8e76e3-3dbf-462b-8ccc-643df3727d18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 86
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403024567-172.17.0.10-1597366366058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33330,DS-e70c2b2e-cb7c-4fac-b248-765ba7c67764,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-3b39d935-039f-480f-9b7c-589612b9535a,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-c096b38e-5a8f-4700-a423-0bf3e1345b34,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-7ced6f01-4951-4efd-95f6-e2de10daf828,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-1d67d532-f779-4a06-8f1f-afd8e856d4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-2706d253-a958-4ce7-a5ef-1a4305708297,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-002c73b2-34f4-442f-8f4e-d59554e3374e,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-73dc4bed-2fda-4ffd-9433-b8d5e0dff3b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403024567-172.17.0.10-1597366366058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33330,DS-e70c2b2e-cb7c-4fac-b248-765ba7c67764,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-3b39d935-039f-480f-9b7c-589612b9535a,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-c096b38e-5a8f-4700-a423-0bf3e1345b34,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-7ced6f01-4951-4efd-95f6-e2de10daf828,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-1d67d532-f779-4a06-8f1f-afd8e856d4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-2706d253-a958-4ce7-a5ef-1a4305708297,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-002c73b2-34f4-442f-8f4e-d59554e3374e,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-73dc4bed-2fda-4ffd-9433-b8d5e0dff3b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 86
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-863223958-172.17.0.10-1597366671322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45098,DS-44811f4a-4b94-4e3f-b81e-9ce87131cb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-28cb9abc-8f5b-4156-9e21-d864e0b1c35f,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-a467068f-d1b8-4e67-b98b-68d6a4942cca,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-433c0567-5631-491f-bfcd-c49e8f6a5cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-d7e96536-254c-4420-bc55-098e12379393,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-32f9cee2-cc5b-42ed-9ea3-c18422d2abb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-a7fb0020-15fb-4e1f-91eb-bffd24ccb6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-c386e7df-a5bd-4be5-bfc8-4eddfa38b323,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-863223958-172.17.0.10-1597366671322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45098,DS-44811f4a-4b94-4e3f-b81e-9ce87131cb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-28cb9abc-8f5b-4156-9e21-d864e0b1c35f,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-a467068f-d1b8-4e67-b98b-68d6a4942cca,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-433c0567-5631-491f-bfcd-c49e8f6a5cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-d7e96536-254c-4420-bc55-098e12379393,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-32f9cee2-cc5b-42ed-9ea3-c18422d2abb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-a7fb0020-15fb-4e1f-91eb-bffd24ccb6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-c386e7df-a5bd-4be5-bfc8-4eddfa38b323,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 86
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654373605-172.17.0.10-1597366907599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41198,DS-766618e5-f0cd-4e0f-8189-bedc16e95619,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-ddcd541f-7480-4da5-a90b-a1a5f9a212c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-5a15994f-c334-4fc2-8626-1e23d81a003a,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-a75e2d10-13c7-484a-881f-9225c1004296,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-371b69b1-e9f5-4d4b-9040-1f2648f032c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-00657c65-c1d6-4bc7-9202-a18a82e29260,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-140efd58-3c62-4c7e-a48c-b06cce1e6d49,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-80df9c90-afc3-4186-b65b-6e318a00c829,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654373605-172.17.0.10-1597366907599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41198,DS-766618e5-f0cd-4e0f-8189-bedc16e95619,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-ddcd541f-7480-4da5-a90b-a1a5f9a212c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-5a15994f-c334-4fc2-8626-1e23d81a003a,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-a75e2d10-13c7-484a-881f-9225c1004296,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-371b69b1-e9f5-4d4b-9040-1f2648f032c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-00657c65-c1d6-4bc7-9202-a18a82e29260,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-140efd58-3c62-4c7e-a48c-b06cce1e6d49,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-80df9c90-afc3-4186-b65b-6e318a00c829,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 86
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884856623-172.17.0.10-1597367302023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36623,DS-f25e81ba-bef4-4f91-a2e0-efdaf0fed734,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-974eb311-d774-4d9e-bd50-59a2688de5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-25bbb05b-a64e-4ad2-ad68-ab6ea1d40ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-241b9712-4249-41f5-93a1-6d80d7ade520,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-6e5e3e40-6d2c-4ac1-86e2-66dafd343bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-d2f5d20b-b9fd-4a34-a007-d38b3faca866,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-0de098d6-1595-4794-aae8-bc0b0d44f876,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-9df0ea59-43a5-475f-83d7-53b8d79ac111,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884856623-172.17.0.10-1597367302023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36623,DS-f25e81ba-bef4-4f91-a2e0-efdaf0fed734,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-974eb311-d774-4d9e-bd50-59a2688de5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-25bbb05b-a64e-4ad2-ad68-ab6ea1d40ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-241b9712-4249-41f5-93a1-6d80d7ade520,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-6e5e3e40-6d2c-4ac1-86e2-66dafd343bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-d2f5d20b-b9fd-4a34-a007-d38b3faca866,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-0de098d6-1595-4794-aae8-bc0b0d44f876,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-9df0ea59-43a5-475f-83d7-53b8d79ac111,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 86
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1690802873-172.17.0.10-1597367379159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39829,DS-b437b572-cf7b-45d3-924f-c46939f7525d,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-84074b8b-c9f5-4c3a-9369-c8bcfb7c7c92,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-03d9845c-8232-4301-9f7e-b704d62008a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-209dd494-6f8f-4bf5-8d4a-26ee72fc7c05,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-b0cde24b-3bfc-4cdd-8300-12145f5c529d,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-84121d43-81d3-4fa2-8732-9bd8640ee0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-49fc5d6d-84ec-49f5-9ee5-8975da21eb36,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-f015c41e-233b-45fc-83d9-64b3231ac715,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1690802873-172.17.0.10-1597367379159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39829,DS-b437b572-cf7b-45d3-924f-c46939f7525d,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-84074b8b-c9f5-4c3a-9369-c8bcfb7c7c92,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-03d9845c-8232-4301-9f7e-b704d62008a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-209dd494-6f8f-4bf5-8d4a-26ee72fc7c05,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-b0cde24b-3bfc-4cdd-8300-12145f5c529d,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-84121d43-81d3-4fa2-8732-9bd8640ee0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-49fc5d6d-84ec-49f5-9ee5-8975da21eb36,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-f015c41e-233b-45fc-83d9-64b3231ac715,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 86
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1195722439-172.17.0.10-1597367489609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44419,DS-9e0f45ae-08fa-499b-95c7-6badc05f7b84,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-5f0bbfaa-76a8-4903-a04e-9415a047daf8,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-793c6acc-eac4-406e-bbd3-aabd0029a3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-b18ebc04-ec9e-4c83-a1d4-d4a956724db3,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-28bc06d1-ad57-45af-a5ef-4bc34afe4b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-b753501f-570e-4ace-b1bf-919001642393,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-54295cb3-8a47-4b1d-87d6-c4730905ea50,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-557924e1-ecce-45de-aeca-9297eb4ef28d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1195722439-172.17.0.10-1597367489609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44419,DS-9e0f45ae-08fa-499b-95c7-6badc05f7b84,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-5f0bbfaa-76a8-4903-a04e-9415a047daf8,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-793c6acc-eac4-406e-bbd3-aabd0029a3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-b18ebc04-ec9e-4c83-a1d4-d4a956724db3,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-28bc06d1-ad57-45af-a5ef-4bc34afe4b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-b753501f-570e-4ace-b1bf-919001642393,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-54295cb3-8a47-4b1d-87d6-c4730905ea50,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-557924e1-ecce-45de-aeca-9297eb4ef28d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 86
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642734841-172.17.0.10-1597367528950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41228,DS-e6259e46-8d31-4414-b9ca-d2b2e1c75217,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-fc6745bc-0bfd-47a1-991e-701e1df7eafd,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-be96b7fb-7333-48eb-a194-b4376f022153,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-b2c4230c-1ad0-4362-aced-e5ebd6d82c13,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-8f57d496-9cc1-4e92-a51b-e7f48a493b44,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-5b0f5857-9dce-4cbb-919f-aadde1038803,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-3981c038-a3d8-4c0a-9226-4aeda8949efd,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-504b1068-716c-412f-acb1-48ef2a17c6ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642734841-172.17.0.10-1597367528950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41228,DS-e6259e46-8d31-4414-b9ca-d2b2e1c75217,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-fc6745bc-0bfd-47a1-991e-701e1df7eafd,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-be96b7fb-7333-48eb-a194-b4376f022153,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-b2c4230c-1ad0-4362-aced-e5ebd6d82c13,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-8f57d496-9cc1-4e92-a51b-e7f48a493b44,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-5b0f5857-9dce-4cbb-919f-aadde1038803,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-3981c038-a3d8-4c0a-9226-4aeda8949efd,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-504b1068-716c-412f-acb1-48ef2a17c6ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 86
v2: 864000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2055036859-172.17.0.10-1597367785032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46368,DS-77aeae34-e174-450a-b661-cc1f2e779da8,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-81c826d2-f816-438a-b952-a8bed47add04,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-e5c00c75-25ad-4b15-8184-2d49d8037f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-e8b7d16d-63ee-4813-b4cd-10e5abad4b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-a6a57d34-d085-4386-9b76-fe3b41573b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-edf26580-5bfc-40b0-b2de-a9b053851f79,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-72ac750d-ed69-4f18-9145-de2cf77d431a,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-1dd96fce-f794-4ce3-b6f8-d8a9106ae925,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2055036859-172.17.0.10-1597367785032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46368,DS-77aeae34-e174-450a-b661-cc1f2e779da8,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-81c826d2-f816-438a-b952-a8bed47add04,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-e5c00c75-25ad-4b15-8184-2d49d8037f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-e8b7d16d-63ee-4813-b4cd-10e5abad4b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-a6a57d34-d085-4386-9b76-fe3b41573b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-edf26580-5bfc-40b0-b2de-a9b053851f79,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-72ac750d-ed69-4f18-9145-de2cf77d431a,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-1dd96fce-f794-4ce3-b6f8-d8a9106ae925,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5450
