reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1672419614-172.17.0.11-1597274173585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40364,DS-b72a31c8-5e51-41a0-9e9e-eb89f76e2155,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-3d0a633d-9e77-491d-8a7e-0c553e1ce395,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-5e711137-9aaf-4167-b5ac-ff915fd5f56f,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-26b01470-1ee0-4387-8d86-963ad8968c30,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-1ddcb61a-7c2d-4db6-a2dd-8c85242397d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-72798612-ff62-4464-9967-911114872035,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-fcac3f67-0a37-49bd-8d4d-a0710ea009c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-bad87fb6-5367-4db6-b131-b14d13f99d92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1672419614-172.17.0.11-1597274173585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40364,DS-b72a31c8-5e51-41a0-9e9e-eb89f76e2155,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-3d0a633d-9e77-491d-8a7e-0c553e1ce395,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-5e711137-9aaf-4167-b5ac-ff915fd5f56f,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-26b01470-1ee0-4387-8d86-963ad8968c30,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-1ddcb61a-7c2d-4db6-a2dd-8c85242397d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-72798612-ff62-4464-9967-911114872035,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-fcac3f67-0a37-49bd-8d4d-a0710ea009c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-bad87fb6-5367-4db6-b131-b14d13f99d92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-726988401-172.17.0.11-1597274458726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42095,DS-dbff9d4d-7b15-4962-af5a-448648755cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-ee2b11d9-9768-464e-87d3-dae70af6ccec,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-f6a7a5f8-85d4-47dd-9a72-4068e2f8e491,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-64b4fd52-165a-4f33-bcff-e9da02e50889,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-ce56191e-7366-434c-ab47-a81ce672f6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-90992bf0-9bbc-43fc-b161-f931633da71e,DISK], DatanodeInfoWithStorage[127.0.0.1:37611,DS-6d4385d2-d841-48f3-90ff-8a567397893c,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-ba27b325-81e0-47c7-8a9a-892bd23cacfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-726988401-172.17.0.11-1597274458726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42095,DS-dbff9d4d-7b15-4962-af5a-448648755cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-ee2b11d9-9768-464e-87d3-dae70af6ccec,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-f6a7a5f8-85d4-47dd-9a72-4068e2f8e491,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-64b4fd52-165a-4f33-bcff-e9da02e50889,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-ce56191e-7366-434c-ab47-a81ce672f6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-90992bf0-9bbc-43fc-b161-f931633da71e,DISK], DatanodeInfoWithStorage[127.0.0.1:37611,DS-6d4385d2-d841-48f3-90ff-8a567397893c,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-ba27b325-81e0-47c7-8a9a-892bd23cacfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-953037360-172.17.0.11-1597274534371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44414,DS-69cc69d2-8715-470c-b4d0-b6c181de5c00,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-38950f23-a05b-4ee6-9c04-5a4e1c70a089,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-474db0a0-6ec2-450f-b522-f3d23f2a47a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-9991be46-7056-4ff6-a1d2-692a758cfe2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-e7d4017c-e599-4a04-ba10-1137f84e5fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-cf1f2266-097e-410c-b858-c4a9160463e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-53362bc4-d88f-4a57-add3-bacc1d1248ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-099ccecb-0ab4-4d04-9c96-fbd2131dc6c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-953037360-172.17.0.11-1597274534371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44414,DS-69cc69d2-8715-470c-b4d0-b6c181de5c00,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-38950f23-a05b-4ee6-9c04-5a4e1c70a089,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-474db0a0-6ec2-450f-b522-f3d23f2a47a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-9991be46-7056-4ff6-a1d2-692a758cfe2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-e7d4017c-e599-4a04-ba10-1137f84e5fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-cf1f2266-097e-410c-b858-c4a9160463e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-53362bc4-d88f-4a57-add3-bacc1d1248ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-099ccecb-0ab4-4d04-9c96-fbd2131dc6c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1836757243-172.17.0.11-1597275601848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36176,DS-6fb2785f-1a52-42d1-be7e-c6c0bdf35b07,DISK], DatanodeInfoWithStorage[127.0.0.1:41711,DS-019d69e2-ef6a-4a2b-8fc5-381d029c9672,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-8dc604b8-940b-484f-bfea-286cf2211f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-83d248f8-6571-4797-8db9-4a6f7bce0147,DISK], DatanodeInfoWithStorage[127.0.0.1:36816,DS-b7b9d879-7e7d-4ecd-880b-465f75853b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-4579f549-30bf-4a10-919b-035ae6715d65,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-e8e86a9b-402d-4c39-8bdc-4601a6d631c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-fd01f26f-6c94-4670-b28c-02bd978cf10e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1836757243-172.17.0.11-1597275601848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36176,DS-6fb2785f-1a52-42d1-be7e-c6c0bdf35b07,DISK], DatanodeInfoWithStorage[127.0.0.1:41711,DS-019d69e2-ef6a-4a2b-8fc5-381d029c9672,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-8dc604b8-940b-484f-bfea-286cf2211f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-83d248f8-6571-4797-8db9-4a6f7bce0147,DISK], DatanodeInfoWithStorage[127.0.0.1:36816,DS-b7b9d879-7e7d-4ecd-880b-465f75853b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-4579f549-30bf-4a10-919b-035ae6715d65,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-e8e86a9b-402d-4c39-8bdc-4601a6d631c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-fd01f26f-6c94-4670-b28c-02bd978cf10e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1461803486-172.17.0.11-1597275676015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35223,DS-22d41cd5-33ff-4ccc-be48-d4028e033f60,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-f5f3e946-9b8d-403f-b347-2a3accfcc008,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-f7bd6569-1551-4fd6-be50-c72875a8decf,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-dadd26f0-d3a2-4236-b2d2-69c14df7358f,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-d40a273c-7f62-4394-bc07-53084be0a339,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-409b39fe-9f5e-4354-af53-110932dc9fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-8a7e7106-caf1-4417-b902-faaedf2a936a,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-017f9e60-c199-4972-8ead-c4fab0223cff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1461803486-172.17.0.11-1597275676015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35223,DS-22d41cd5-33ff-4ccc-be48-d4028e033f60,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-f5f3e946-9b8d-403f-b347-2a3accfcc008,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-f7bd6569-1551-4fd6-be50-c72875a8decf,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-dadd26f0-d3a2-4236-b2d2-69c14df7358f,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-d40a273c-7f62-4394-bc07-53084be0a339,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-409b39fe-9f5e-4354-af53-110932dc9fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-8a7e7106-caf1-4417-b902-faaedf2a936a,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-017f9e60-c199-4972-8ead-c4fab0223cff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1047906229-172.17.0.11-1597276650746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46505,DS-b07a0a7b-a494-4769-a969-2fe1c02bcbe2,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-2c755ef5-cc41-4d90-8fa6-47ae94e8d99d,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-6228f6fa-7a4d-4fe2-a020-34015075a619,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-2d93628f-a08a-4ee4-8221-32ca345453f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-fb3d17dc-886a-498d-8b92-1471d5e7a6db,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-430a9d48-0a11-430b-bbbc-a57a5e3a1115,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-b7273e25-d565-4326-88c8-ca482e49381d,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-e4c5db2b-0fb2-4a3a-90d2-235872888d1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1047906229-172.17.0.11-1597276650746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46505,DS-b07a0a7b-a494-4769-a969-2fe1c02bcbe2,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-2c755ef5-cc41-4d90-8fa6-47ae94e8d99d,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-6228f6fa-7a4d-4fe2-a020-34015075a619,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-2d93628f-a08a-4ee4-8221-32ca345453f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-fb3d17dc-886a-498d-8b92-1471d5e7a6db,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-430a9d48-0a11-430b-bbbc-a57a5e3a1115,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-b7273e25-d565-4326-88c8-ca482e49381d,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-e4c5db2b-0fb2-4a3a-90d2-235872888d1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1993976484-172.17.0.11-1597276691629:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35791,DS-2ca7827b-6726-4958-9f60-4c62c2a8a917,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-2d370e5e-4ebb-4259-8f60-35b03d58db4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-5eea5637-1c1e-4143-836a-045f5bd364be,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-b3f25240-830d-41e8-9684-6fd84f296108,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-3e1461e5-5b38-428f-8c6b-043a9ae96dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-be2799ea-04b7-4c95-bda8-67091ec731ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41173,DS-dcccc2cf-f342-4d19-acc3-63d9399d9549,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-dd75cc27-c9ee-4407-ab55-3e4cb98d7a7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1993976484-172.17.0.11-1597276691629:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35791,DS-2ca7827b-6726-4958-9f60-4c62c2a8a917,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-2d370e5e-4ebb-4259-8f60-35b03d58db4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-5eea5637-1c1e-4143-836a-045f5bd364be,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-b3f25240-830d-41e8-9684-6fd84f296108,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-3e1461e5-5b38-428f-8c6b-043a9ae96dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-be2799ea-04b7-4c95-bda8-67091ec731ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41173,DS-dcccc2cf-f342-4d19-acc3-63d9399d9549,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-dd75cc27-c9ee-4407-ab55-3e4cb98d7a7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1993833031-172.17.0.11-1597276758224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41522,DS-ea156e8b-0526-4708-83ee-1a61d2c5d0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-6950ff64-ab9a-45d3-8999-04181e89465e,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-34590823-048c-4deb-8c7b-d30a374b233e,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-dc1ef352-314b-4c0f-90db-ed5be09d84bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-c7345ca1-71ef-4284-b1b9-f60eb453c6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-6e5651e3-5a27-47e3-9600-e7814553fb82,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-3d99adce-9b62-4ff7-85b6-4ad406579ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-e0551bfe-90bc-4168-8d70-2c7d28183d23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1993833031-172.17.0.11-1597276758224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41522,DS-ea156e8b-0526-4708-83ee-1a61d2c5d0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-6950ff64-ab9a-45d3-8999-04181e89465e,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-34590823-048c-4deb-8c7b-d30a374b233e,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-dc1ef352-314b-4c0f-90db-ed5be09d84bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-c7345ca1-71ef-4284-b1b9-f60eb453c6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-6e5651e3-5a27-47e3-9600-e7814553fb82,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-3d99adce-9b62-4ff7-85b6-4ad406579ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-e0551bfe-90bc-4168-8d70-2c7d28183d23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-659934240-172.17.0.11-1597276825588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41750,DS-51d04bc3-b2bb-4a1a-8c1c-43299606605a,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-fed8d5b0-7868-489b-9871-fc44a5629758,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-d6abb54e-ce02-4cb7-a194-0d23d4de30cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42012,DS-e10c7fb7-6401-4ec2-a9f4-f33656d89c18,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-e55b4fd6-b921-4fa9-afad-b9edb6ce6dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-19905557-1a5c-4ec7-8769-253ba5ba2a91,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-5faa1755-b151-40d6-a021-d9d61449fd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-b98b86d6-ad84-4dfb-bff5-e200fed3a78a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-659934240-172.17.0.11-1597276825588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41750,DS-51d04bc3-b2bb-4a1a-8c1c-43299606605a,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-fed8d5b0-7868-489b-9871-fc44a5629758,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-d6abb54e-ce02-4cb7-a194-0d23d4de30cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42012,DS-e10c7fb7-6401-4ec2-a9f4-f33656d89c18,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-e55b4fd6-b921-4fa9-afad-b9edb6ce6dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-19905557-1a5c-4ec7-8769-253ba5ba2a91,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-5faa1755-b151-40d6-a021-d9d61449fd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-b98b86d6-ad84-4dfb-bff5-e200fed3a78a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-166791571-172.17.0.11-1597277546944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39128,DS-d1e67dc9-9c4e-4e73-839b-84cce6f2d254,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-d15d6d61-a6a8-46a6-bf60-7594cbffc7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-cf6200b8-1199-43f5-9fe8-50cc513a9152,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-d92912aa-ffa2-4342-8348-e6c47b2eef83,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-ddd5ced0-c187-4fd3-8947-97156718fe75,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-24ff72d7-59ea-4ebe-9c1c-e949527c9c76,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-efea8d77-a2d3-42c4-b3fb-df5677defbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-9b99b735-fdac-48f9-9ffb-cb19f04a61fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-166791571-172.17.0.11-1597277546944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39128,DS-d1e67dc9-9c4e-4e73-839b-84cce6f2d254,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-d15d6d61-a6a8-46a6-bf60-7594cbffc7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-cf6200b8-1199-43f5-9fe8-50cc513a9152,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-d92912aa-ffa2-4342-8348-e6c47b2eef83,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-ddd5ced0-c187-4fd3-8947-97156718fe75,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-24ff72d7-59ea-4ebe-9c1c-e949527c9c76,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-efea8d77-a2d3-42c4-b3fb-df5677defbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-9b99b735-fdac-48f9-9ffb-cb19f04a61fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1325971600-172.17.0.11-1597277742671:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39221,DS-f3d8beb9-b350-4c3e-a8c9-0afe98693aed,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-a19eebcf-14a4-4f0a-9dad-9917dbcb4f57,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-0347af9a-5e6f-4d29-b225-af1155701879,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-88da973d-e3b5-40f2-ba21-45caf7d60de9,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-a23bed6c-30f5-4ad0-aa7d-0d258df28306,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-bf3715bf-397c-4d24-b02f-c4d903b21cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-87153097-90ca-4fe5-b1af-08d05ee41b47,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-7af20118-a8c0-4bc6-b7ed-f7acb221c787,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1325971600-172.17.0.11-1597277742671:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39221,DS-f3d8beb9-b350-4c3e-a8c9-0afe98693aed,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-a19eebcf-14a4-4f0a-9dad-9917dbcb4f57,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-0347af9a-5e6f-4d29-b225-af1155701879,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-88da973d-e3b5-40f2-ba21-45caf7d60de9,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-a23bed6c-30f5-4ad0-aa7d-0d258df28306,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-bf3715bf-397c-4d24-b02f-c4d903b21cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-87153097-90ca-4fe5-b1af-08d05ee41b47,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-7af20118-a8c0-4bc6-b7ed-f7acb221c787,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-937513362-172.17.0.11-1597277783169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40368,DS-506ca26e-37a6-49ea-831f-2eeb467c93f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-72503d9d-c087-450e-8d9b-6a236eac4036,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-13522209-8670-4d2b-b318-faaa519edbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:36700,DS-687e50bc-0718-43a1-80c8-68fcc32bbd61,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-6790b120-a067-4bf7-8e64-d66bda641053,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-8a88585b-79e0-446a-bd88-ecc0e98142ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-117588bd-3417-4156-ae54-643aeaa06ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-ea842c63-1664-47da-bc9a-cac3e6296b44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-937513362-172.17.0.11-1597277783169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40368,DS-506ca26e-37a6-49ea-831f-2eeb467c93f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-72503d9d-c087-450e-8d9b-6a236eac4036,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-13522209-8670-4d2b-b318-faaa519edbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:36700,DS-687e50bc-0718-43a1-80c8-68fcc32bbd61,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-6790b120-a067-4bf7-8e64-d66bda641053,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-8a88585b-79e0-446a-bd88-ecc0e98142ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-117588bd-3417-4156-ae54-643aeaa06ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-ea842c63-1664-47da-bc9a-cac3e6296b44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970568522-172.17.0.11-1597278069958:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33447,DS-43211930-f1e9-4807-92ec-2d890406669c,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-de576713-a1c4-46a7-ba63-280cd920481b,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-0fdae2cb-cee3-445f-b340-cff27b1f200b,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-233d5495-b582-44bb-b2c5-c37d5ee40408,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-9af1e27a-e163-4771-8b4a-90e2fc0e3bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-27949b67-8424-4ac4-bbe9-498b0dd5221c,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-f45e4179-2b5d-43e6-9225-a4b2a10cb25f,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-1cc96bfe-7974-4185-983d-971a80756431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970568522-172.17.0.11-1597278069958:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33447,DS-43211930-f1e9-4807-92ec-2d890406669c,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-de576713-a1c4-46a7-ba63-280cd920481b,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-0fdae2cb-cee3-445f-b340-cff27b1f200b,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-233d5495-b582-44bb-b2c5-c37d5ee40408,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-9af1e27a-e163-4771-8b4a-90e2fc0e3bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-27949b67-8424-4ac4-bbe9-498b0dd5221c,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-f45e4179-2b5d-43e6-9225-a4b2a10cb25f,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-1cc96bfe-7974-4185-983d-971a80756431,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1371713080-172.17.0.11-1597278465502:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42962,DS-a28f5f13-d393-4a6e-a73b-71de6c9b6cad,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-53ce62d9-e348-4439-840f-f491de7e950f,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-ef4801dc-381e-4e10-8db6-be63e211a473,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-b9759b91-0bbc-4505-8da2-f203fa56c11c,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-6dab1704-33f7-4bc4-b578-81af4a1da5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-69db6a54-44cd-4f4d-bb07-44cc04b3b90e,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-4bcfcccf-e8cb-4c3b-8ecd-b512ee35290b,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-3dad19d0-d8c1-4d2a-a37c-d8a888390866,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1371713080-172.17.0.11-1597278465502:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42962,DS-a28f5f13-d393-4a6e-a73b-71de6c9b6cad,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-53ce62d9-e348-4439-840f-f491de7e950f,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-ef4801dc-381e-4e10-8db6-be63e211a473,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-b9759b91-0bbc-4505-8da2-f203fa56c11c,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-6dab1704-33f7-4bc4-b578-81af4a1da5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-69db6a54-44cd-4f4d-bb07-44cc04b3b90e,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-4bcfcccf-e8cb-4c3b-8ecd-b512ee35290b,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-3dad19d0-d8c1-4d2a-a37c-d8a888390866,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5442
