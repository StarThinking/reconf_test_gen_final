reconf_parameter: dfs.namenode.max.objects
component: hdfs:NameNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: hdfs:NameNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-416852438-172.17.0.18-1597652329543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43101,DS-7d37f39e-d630-4228-88d7-7aa008a7559e,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-2ae75f36-78e9-4e7c-a8ea-aaaef3f0a48d,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-f386fa99-fdb4-4ff4-9cb3-bfabbf7e3671,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-f69c8667-78ed-4f0c-9b40-4c4462f8d554,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-59edfcf2-62ed-4616-be1c-dae499fe4640,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-4a99ee53-037c-44fc-ae9b-d7dbf6a86eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-121ed7ca-2476-4203-9b2f-2bd767ec714b,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-e8602ce4-b4ad-42d5-b2f0-c34d3ab37022,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-416852438-172.17.0.18-1597652329543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43101,DS-7d37f39e-d630-4228-88d7-7aa008a7559e,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-2ae75f36-78e9-4e7c-a8ea-aaaef3f0a48d,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-f386fa99-fdb4-4ff4-9cb3-bfabbf7e3671,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-f69c8667-78ed-4f0c-9b40-4c4462f8d554,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-59edfcf2-62ed-4616-be1c-dae499fe4640,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-4a99ee53-037c-44fc-ae9b-d7dbf6a86eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-121ed7ca-2476-4203-9b2f-2bd767ec714b,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-e8602ce4-b4ad-42d5-b2f0-c34d3ab37022,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: hdfs:NameNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1173175494-172.17.0.18-1597652370379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41271,DS-06f65ad0-411a-4896-b08c-c25c80048a09,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-7eb1d6eb-fa20-4ceb-a6ff-281ebcb1ea8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-d329c27c-8bbb-4694-94b2-8c9fd5b472aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-103fe92c-3f65-4924-87d4-0dcf29ce6dac,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-cf1b4dc2-118a-4328-8d50-49d18c148294,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-0b2e4050-d278-4147-947f-565e391f442e,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-8c4f0633-8e6e-4fa4-a113-f105915c7295,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-f2255661-162a-4386-ab47-a924de852f3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1173175494-172.17.0.18-1597652370379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41271,DS-06f65ad0-411a-4896-b08c-c25c80048a09,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-7eb1d6eb-fa20-4ceb-a6ff-281ebcb1ea8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-d329c27c-8bbb-4694-94b2-8c9fd5b472aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-103fe92c-3f65-4924-87d4-0dcf29ce6dac,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-cf1b4dc2-118a-4328-8d50-49d18c148294,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-0b2e4050-d278-4147-947f-565e391f442e,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-8c4f0633-8e6e-4fa4-a113-f105915c7295,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-f2255661-162a-4386-ab47-a924de852f3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: hdfs:NameNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-411572746-172.17.0.18-1597652588202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38731,DS-7d8ecf40-20de-4fe4-9778-09eae89e414d,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-a9d62dc4-bce4-4e4a-924d-731926e8c468,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-32f45c62-d93b-49cb-ba18-0ce48c0f56c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-ceba5ae2-d16b-4696-9e7b-a48d168bd7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-526d502d-7605-403c-85ee-067310235d75,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-d96ae2b6-3da8-4db1-8a24-d493503d6f61,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-f244db71-b711-456a-b9cc-5f7201110635,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-dda8b44a-f932-4315-9a90-0c38a390ee2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-411572746-172.17.0.18-1597652588202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38731,DS-7d8ecf40-20de-4fe4-9778-09eae89e414d,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-a9d62dc4-bce4-4e4a-924d-731926e8c468,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-32f45c62-d93b-49cb-ba18-0ce48c0f56c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-ceba5ae2-d16b-4696-9e7b-a48d168bd7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-526d502d-7605-403c-85ee-067310235d75,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-d96ae2b6-3da8-4db1-8a24-d493503d6f61,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-f244db71-b711-456a-b9cc-5f7201110635,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-dda8b44a-f932-4315-9a90-0c38a390ee2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: hdfs:NameNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1736882978-172.17.0.18-1597653599323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33538,DS-2a984131-940f-470b-92aa-699699e72170,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-ae052ef2-0aab-4eea-8ba5-ddeefe572f24,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-4131c557-17d3-4c67-a7e8-4862c793240a,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-1612f093-fd22-4e6e-958e-c30c9aba034d,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-ee54aa5f-d2a5-4b2c-bb1e-277b80e902cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-761e7579-b8ac-4166-8b25-97dc82a7a201,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-fa0f8428-d634-426c-a73e-569e8b2b5a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-48eecb86-5195-48fa-a016-053971188f64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1736882978-172.17.0.18-1597653599323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33538,DS-2a984131-940f-470b-92aa-699699e72170,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-ae052ef2-0aab-4eea-8ba5-ddeefe572f24,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-4131c557-17d3-4c67-a7e8-4862c793240a,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-1612f093-fd22-4e6e-958e-c30c9aba034d,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-ee54aa5f-d2a5-4b2c-bb1e-277b80e902cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-761e7579-b8ac-4166-8b25-97dc82a7a201,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-fa0f8428-d634-426c-a73e-569e8b2b5a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-48eecb86-5195-48fa-a016-053971188f64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: hdfs:NameNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-122859305-172.17.0.18-1597653690531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33697,DS-393989a8-3039-40e3-908f-efe804256245,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-f5d3d4f6-d02d-4b85-a84b-3a9e03a9bec0,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-0087ed4f-f9e1-491d-b1a6-310b71724320,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-324a5e8a-f7e0-4a39-9a83-63a86a5877df,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-c3f4fd1c-54ab-4edc-ba33-afeca7ba0824,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-3aa4d67c-e60b-41f9-ae78-d0b05a3eec19,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-32055fe8-3113-4ea6-9fc0-d2068351f79d,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-44725de5-2e00-487d-8ddb-da912072c5c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-122859305-172.17.0.18-1597653690531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33697,DS-393989a8-3039-40e3-908f-efe804256245,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-f5d3d4f6-d02d-4b85-a84b-3a9e03a9bec0,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-0087ed4f-f9e1-491d-b1a6-310b71724320,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-324a5e8a-f7e0-4a39-9a83-63a86a5877df,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-c3f4fd1c-54ab-4edc-ba33-afeca7ba0824,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-3aa4d67c-e60b-41f9-ae78-d0b05a3eec19,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-32055fe8-3113-4ea6-9fc0-d2068351f79d,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-44725de5-2e00-487d-8ddb-da912072c5c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: hdfs:NameNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-528413673-172.17.0.18-1597654177999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37099,DS-7f2b403d-a5ec-44e6-9697-ba0bc2a92a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-fbe2e7ca-abe4-4bac-8c87-6d5dd50d4fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-7e703441-84a6-4cd5-907d-95ba00115adf,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-860cb595-81da-40e1-8f1e-781c45e9afda,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-16ef38d9-e683-4976-90af-4066592998dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-af1dcba2-0107-4baa-ae9c-de192c55573c,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-b5ecf9db-b986-4350-923b-45bfa8b08b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-d2db4252-52ff-48f0-b865-b39d56394447,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-528413673-172.17.0.18-1597654177999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37099,DS-7f2b403d-a5ec-44e6-9697-ba0bc2a92a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-fbe2e7ca-abe4-4bac-8c87-6d5dd50d4fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-7e703441-84a6-4cd5-907d-95ba00115adf,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-860cb595-81da-40e1-8f1e-781c45e9afda,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-16ef38d9-e683-4976-90af-4066592998dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-af1dcba2-0107-4baa-ae9c-de192c55573c,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-b5ecf9db-b986-4350-923b-45bfa8b08b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-d2db4252-52ff-48f0-b865-b39d56394447,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: hdfs:NameNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1710400587-172.17.0.18-1597654411716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39510,DS-250f0452-e179-4166-bc75-b83af31745d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-5fc42ce0-4c45-4bbd-8a63-a0925ae0fddc,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-8df97bf5-2398-4101-9db5-be7ce16c3c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-3f94c7f6-e669-44ec-a8ce-e2f47d5aa2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-6b4ab7cc-2ddb-4ab8-9b10-40be82088f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41711,DS-fa0c7374-7609-47c3-89a3-dfd7d81dc4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-05133228-50f0-4e80-a2ad-b6933b765985,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-83e941f8-bc00-4fd0-98d9-c261ab6a5a20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1710400587-172.17.0.18-1597654411716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39510,DS-250f0452-e179-4166-bc75-b83af31745d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-5fc42ce0-4c45-4bbd-8a63-a0925ae0fddc,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-8df97bf5-2398-4101-9db5-be7ce16c3c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-3f94c7f6-e669-44ec-a8ce-e2f47d5aa2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-6b4ab7cc-2ddb-4ab8-9b10-40be82088f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41711,DS-fa0c7374-7609-47c3-89a3-dfd7d81dc4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-05133228-50f0-4e80-a2ad-b6933b765985,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-83e941f8-bc00-4fd0-98d9-c261ab6a5a20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: hdfs:NameNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-712893282-172.17.0.18-1597654546458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43036,DS-bac02a6c-fd86-4b0f-8052-ab8f2d5beba2,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-da9ca29c-5c31-4c45-a333-4f05ec66d898,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-ede07380-2436-42f3-a2b2-bbc2594e6d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-8ca9ed97-893d-4800-988a-86f49a6dd29d,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-18238b51-6357-497c-b23d-6c79b200df6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42261,DS-2c9e80fd-f026-4e58-9796-7e081c04c67d,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-93f74179-ebc3-4191-9e8a-7f30a6014f91,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-7921d9e1-5823-484b-89cf-9943bf7023ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-712893282-172.17.0.18-1597654546458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43036,DS-bac02a6c-fd86-4b0f-8052-ab8f2d5beba2,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-da9ca29c-5c31-4c45-a333-4f05ec66d898,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-ede07380-2436-42f3-a2b2-bbc2594e6d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-8ca9ed97-893d-4800-988a-86f49a6dd29d,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-18238b51-6357-497c-b23d-6c79b200df6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42261,DS-2c9e80fd-f026-4e58-9796-7e081c04c67d,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-93f74179-ebc3-4191-9e8a-7f30a6014f91,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-7921d9e1-5823-484b-89cf-9943bf7023ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: hdfs:NameNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1297383916-172.17.0.18-1597654875316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39086,DS-a4c35e5d-4f63-44c5-abe2-a009f4e9467e,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-97c5c094-5d83-4bf7-836e-84b718f1128b,DISK], DatanodeInfoWithStorage[127.0.0.1:35051,DS-5e0c3674-394d-41fb-9ce1-22666ef4fe54,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-41410a4e-340e-4e6c-96b9-4b34df7114b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-4caa6abd-2e1f-475b-a587-13ddab09dd32,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-1f1223f7-22cf-4a17-9542-d338fca84323,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-657a248a-c154-4567-8727-7d7a596fe41f,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-16aa16f5-758f-4f96-b32f-8a38d4bc0fcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1297383916-172.17.0.18-1597654875316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39086,DS-a4c35e5d-4f63-44c5-abe2-a009f4e9467e,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-97c5c094-5d83-4bf7-836e-84b718f1128b,DISK], DatanodeInfoWithStorage[127.0.0.1:35051,DS-5e0c3674-394d-41fb-9ce1-22666ef4fe54,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-41410a4e-340e-4e6c-96b9-4b34df7114b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-4caa6abd-2e1f-475b-a587-13ddab09dd32,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-1f1223f7-22cf-4a17-9542-d338fca84323,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-657a248a-c154-4567-8727-7d7a596fe41f,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-16aa16f5-758f-4f96-b32f-8a38d4bc0fcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: hdfs:NameNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1608013518-172.17.0.18-1597655609714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42187,DS-6cb94703-3221-4139-8bc2-7e275a182a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-00d8da61-0d97-4f9d-b54c-9616ad0a55c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-2671701b-5272-43d8-ade8-4d0bfe88b66d,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-aa18acbb-144e-4f40-8be4-9a8a545cb28f,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-efa82df8-e6f1-4712-bda5-d4954ebae5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-3e058fef-123a-43d8-83c1-2ebe003d051e,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-5e506d12-6b31-4e77-813b-8c4c00485f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-1fccce9c-6e21-466b-a15c-5aff7b65339a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1608013518-172.17.0.18-1597655609714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42187,DS-6cb94703-3221-4139-8bc2-7e275a182a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-00d8da61-0d97-4f9d-b54c-9616ad0a55c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-2671701b-5272-43d8-ade8-4d0bfe88b66d,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-aa18acbb-144e-4f40-8be4-9a8a545cb28f,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-efa82df8-e6f1-4712-bda5-d4954ebae5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-3e058fef-123a-43d8-83c1-2ebe003d051e,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-5e506d12-6b31-4e77-813b-8c4c00485f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-1fccce9c-6e21-466b-a15c-5aff7b65339a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: hdfs:NameNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1099234191-172.17.0.18-1597655744782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42946,DS-56d8e318-4e9c-4f54-8f7c-f375aba68a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-91498e97-9251-435b-9ca2-ae09bdf51790,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-33eee008-51c1-4257-9ec4-5b40d1fa87be,DISK], DatanodeInfoWithStorage[127.0.0.1:33348,DS-92809c15-cb08-4e5a-adf4-7fb639a1db48,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-d36036e8-a427-45ff-96c5-93044f1c3eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-f21dd44e-8f3c-45b6-9526-dd48c6f1b14c,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-561b30b7-7cc7-4917-a9f5-93c56a4bd9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-e2f8f15a-7d58-43c2-9fbe-292e68dd84a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1099234191-172.17.0.18-1597655744782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42946,DS-56d8e318-4e9c-4f54-8f7c-f375aba68a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-91498e97-9251-435b-9ca2-ae09bdf51790,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-33eee008-51c1-4257-9ec4-5b40d1fa87be,DISK], DatanodeInfoWithStorage[127.0.0.1:33348,DS-92809c15-cb08-4e5a-adf4-7fb639a1db48,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-d36036e8-a427-45ff-96c5-93044f1c3eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-f21dd44e-8f3c-45b6-9526-dd48c6f1b14c,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-561b30b7-7cc7-4917-a9f5-93c56a4bd9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-e2f8f15a-7d58-43c2-9fbe-292e68dd84a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: hdfs:NameNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1849150166-172.17.0.18-1597655841253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36305,DS-a2448d9c-29b7-4ee7-8f9d-0dba32a27dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-71e8e189-9b44-4bfe-9d56-38ed2e0253a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-53f52741-5470-446d-bbf2-e7b15af77f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-3004ef30-f0e4-440c-8909-d2f89c73afa1,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-16a5d72a-364b-41f2-9c12-e3dcfe7c63d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-e99d2f3a-1496-486c-a6da-8affd621320c,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-1b7f85ab-124b-4a82-a061-001a34f70e53,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-adc9211e-250e-4b21-b4c2-b3ca0ebde2e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1849150166-172.17.0.18-1597655841253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36305,DS-a2448d9c-29b7-4ee7-8f9d-0dba32a27dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-71e8e189-9b44-4bfe-9d56-38ed2e0253a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-53f52741-5470-446d-bbf2-e7b15af77f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-3004ef30-f0e4-440c-8909-d2f89c73afa1,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-16a5d72a-364b-41f2-9c12-e3dcfe7c63d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-e99d2f3a-1496-486c-a6da-8affd621320c,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-1b7f85ab-124b-4a82-a061-001a34f70e53,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-adc9211e-250e-4b21-b4c2-b3ca0ebde2e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: hdfs:NameNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-378274558-172.17.0.18-1597656175368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41327,DS-27bdaab1-a2f4-423a-b6ed-cbcd61aeff9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-3818bd90-2a47-4aa8-bef7-396dcb1f2aed,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-d1455316-c62f-48b4-8a1b-56a325baa4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-03c2dd29-2cdd-4561-9de4-b5cef7cbfa41,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-4a333744-6c69-437e-b1c0-d01ddfdd243f,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-82643090-4e34-4e88-979b-4249e9365513,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-a799583f-1a26-4620-adf0-e3068f0642d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-39d71caa-c0e6-465e-bdfa-526e015655a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-378274558-172.17.0.18-1597656175368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41327,DS-27bdaab1-a2f4-423a-b6ed-cbcd61aeff9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-3818bd90-2a47-4aa8-bef7-396dcb1f2aed,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-d1455316-c62f-48b4-8a1b-56a325baa4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-03c2dd29-2cdd-4561-9de4-b5cef7cbfa41,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-4a333744-6c69-437e-b1c0-d01ddfdd243f,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-82643090-4e34-4e88-979b-4249e9365513,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-a799583f-1a26-4620-adf0-e3068f0642d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-39d71caa-c0e6-465e-bdfa-526e015655a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: hdfs:NameNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272495833-172.17.0.18-1597656505194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37383,DS-ad831f8f-6857-46b3-b09e-96340982bdb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-a12f5b46-c3e6-4f58-bd70-bb46f4730397,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-cb4563a3-b74b-4834-bd37-84765eb61066,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-0567ca1c-5c5f-4c1a-9ce0-bc79421deb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-265640ba-ae5a-4d5e-8163-3e9a9362d70e,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-bc5be488-3d80-4cd1-aa5d-9e1a7ee1eb32,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-ece2a7bc-fec4-47c1-ae2f-ed12db187acd,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-9a4134d5-a850-41eb-9999-6fac2cf7c500,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272495833-172.17.0.18-1597656505194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37383,DS-ad831f8f-6857-46b3-b09e-96340982bdb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-a12f5b46-c3e6-4f58-bd70-bb46f4730397,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-cb4563a3-b74b-4834-bd37-84765eb61066,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-0567ca1c-5c5f-4c1a-9ce0-bc79421deb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-265640ba-ae5a-4d5e-8163-3e9a9362d70e,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-bc5be488-3d80-4cd1-aa5d-9e1a7ee1eb32,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-ece2a7bc-fec4-47c1-ae2f-ed12db187acd,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-9a4134d5-a850-41eb-9999-6fac2cf7c500,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max.objects
component: hdfs:NameNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1935273614-172.17.0.18-1597656552566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43420,DS-3eb7ae75-c240-40a0-9c3b-fac528aed0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-cb325959-c9a1-499e-bdda-f7b06bb376e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-6e95c1cc-0b52-4106-be6e-534cbfaffe40,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-fe3cf1eb-76b4-4f0c-8602-056feb5ac053,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-5cee30cd-7864-4cc4-b625-e35f109cada2,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-ae7e04df-48cb-422c-855e-64401d91499e,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-ef2dfca4-8634-4c56-816d-3de8f10e158b,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-4e32fac7-cbc9-47cb-bd5a-7592c99a669e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1935273614-172.17.0.18-1597656552566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43420,DS-3eb7ae75-c240-40a0-9c3b-fac528aed0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-cb325959-c9a1-499e-bdda-f7b06bb376e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-6e95c1cc-0b52-4106-be6e-534cbfaffe40,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-fe3cf1eb-76b4-4f0c-8602-056feb5ac053,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-5cee30cd-7864-4cc4-b625-e35f109cada2,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-ae7e04df-48cb-422c-855e-64401d91499e,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-ef2dfca4-8634-4c56-816d-3de8f10e158b,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-4e32fac7-cbc9-47cb-bd5a-7592c99a669e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: hdfs:NameNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853960843-172.17.0.18-1597656608371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35413,DS-83d48500-e54e-4d7f-8a4e-910a7b44de3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-33bb8b49-3984-479a-b402-2111cb0e78ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-c03c8779-f003-4d3b-b256-9ec05c76e8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-9668c774-db99-42df-a384-39fb87a40814,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-2db9dc63-d07e-4a3d-a889-5457fc6473d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-19b877f3-f164-496c-b27a-7b3de496edbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-0a4937c0-744a-4daa-bbc8-2f6a2692c183,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-7eb90170-7628-492b-b128-73b59abb461d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853960843-172.17.0.18-1597656608371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35413,DS-83d48500-e54e-4d7f-8a4e-910a7b44de3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-33bb8b49-3984-479a-b402-2111cb0e78ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-c03c8779-f003-4d3b-b256-9ec05c76e8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-9668c774-db99-42df-a384-39fb87a40814,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-2db9dc63-d07e-4a3d-a889-5457fc6473d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-19b877f3-f164-496c-b27a-7b3de496edbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-0a4937c0-744a-4daa-bbc8-2f6a2692c183,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-7eb90170-7628-492b-b128-73b59abb461d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: hdfs:NameNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-657108988-172.17.0.18-1597657408474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37177,DS-79806337-ff9a-4b2a-b3b5-eaaba905358c,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-75fe148a-e6f0-4e88-9cd1-1186eeb2dbce,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-5fbb752e-7235-40c8-b0a8-e8b3eda53a63,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-4c920c59-995a-4ccf-81aa-8110df1adb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-45f30438-0491-4873-bea3-f3e4b6cc682f,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-e1ea1025-892a-432f-b284-7cecd5f52e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-2c08a0f3-e97a-4580-9fcb-116699460f73,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-959ddbcd-a082-47c0-8ee3-a518017b5f39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-657108988-172.17.0.18-1597657408474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37177,DS-79806337-ff9a-4b2a-b3b5-eaaba905358c,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-75fe148a-e6f0-4e88-9cd1-1186eeb2dbce,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-5fbb752e-7235-40c8-b0a8-e8b3eda53a63,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-4c920c59-995a-4ccf-81aa-8110df1adb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-45f30438-0491-4873-bea3-f3e4b6cc682f,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-e1ea1025-892a-432f-b284-7cecd5f52e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-2c08a0f3-e97a-4580-9fcb-116699460f73,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-959ddbcd-a082-47c0-8ee3-a518017b5f39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: hdfs:NameNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58909280-172.17.0.18-1597658328582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40356,DS-52265d66-b784-4d11-bcb2-357739ac1ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-d331c7bb-7ffb-4f44-ba56-dc50f6c6dcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-f8a01ab5-92a1-4bef-9c53-3192f657b3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-c512f73d-874d-4908-bffd-6b24be2ea82a,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-0d2c88df-be27-488e-bb8b-b49744f83a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-b3e415ac-5151-4526-b9d5-7cdcb11c4ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:36944,DS-962fb992-c43c-4251-a983-922937e44891,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-dbd8c8ac-ff5f-4c50-a308-acfa9f9a510a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58909280-172.17.0.18-1597658328582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40356,DS-52265d66-b784-4d11-bcb2-357739ac1ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-d331c7bb-7ffb-4f44-ba56-dc50f6c6dcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-f8a01ab5-92a1-4bef-9c53-3192f657b3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-c512f73d-874d-4908-bffd-6b24be2ea82a,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-0d2c88df-be27-488e-bb8b-b49744f83a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-b3e415ac-5151-4526-b9d5-7cdcb11c4ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:36944,DS-962fb992-c43c-4251-a983-922937e44891,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-dbd8c8ac-ff5f-4c50-a308-acfa9f9a510a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.objects
component: hdfs:NameNode
v1: 0
v2: 1024
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1948418255-172.17.0.18-1597658413339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41378,DS-7720b548-4fa6-428a-9081-96e167b7f813,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-592349d3-1b42-4928-bb47-e113c5204a07,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-abb8dede-71b1-43de-a6ae-61445d11f751,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-fadf4906-f905-4b24-8e26-a8d63436637b,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-306d3554-3c57-4c57-8bce-7b27b77c6cca,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-ab3e2122-6393-4087-a07d-8a2efede60dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-01c86652-ca96-4413-a8e9-47cd9a0f0394,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-0cc93d25-d407-4e0f-a09c-ac9416bfa47f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1948418255-172.17.0.18-1597658413339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41378,DS-7720b548-4fa6-428a-9081-96e167b7f813,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-592349d3-1b42-4928-bb47-e113c5204a07,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-abb8dede-71b1-43de-a6ae-61445d11f751,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-fadf4906-f905-4b24-8e26-a8d63436637b,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-306d3554-3c57-4c57-8bce-7b27b77c6cca,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-ab3e2122-6393-4087-a07d-8a2efede60dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-01c86652-ca96-4413-a8e9-47cd9a0f0394,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-0cc93d25-d407-4e0f-a09c-ac9416bfa47f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6978
