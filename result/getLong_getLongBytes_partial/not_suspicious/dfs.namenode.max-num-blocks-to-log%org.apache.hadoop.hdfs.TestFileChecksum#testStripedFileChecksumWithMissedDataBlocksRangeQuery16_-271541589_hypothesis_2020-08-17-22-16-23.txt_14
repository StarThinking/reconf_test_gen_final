reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2092409790-172.17.0.4-1597703381521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38354,DS-39d50c10-8c36-4fdc-8e48-bea98ff49820,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-e0002717-0378-4d3c-93b3-1a74f3f8ff59,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-86b24e76-6444-4ec3-b185-03e207a3a6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-7644d0c9-ff25-4b66-96fb-11250a6cf30f,DISK], DatanodeInfoWithStorage[127.0.0.1:35505,DS-38246922-4197-49d8-86c0-74e44e05ccb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-1eebf3ee-8830-4e4a-811b-bdd40f5b4d54,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-4da4dd5e-d8f1-400f-9e43-18bd52e9bbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-727da12f-d762-4a69-b64a-b1a325443b5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2092409790-172.17.0.4-1597703381521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38354,DS-39d50c10-8c36-4fdc-8e48-bea98ff49820,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-e0002717-0378-4d3c-93b3-1a74f3f8ff59,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-86b24e76-6444-4ec3-b185-03e207a3a6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-7644d0c9-ff25-4b66-96fb-11250a6cf30f,DISK], DatanodeInfoWithStorage[127.0.0.1:35505,DS-38246922-4197-49d8-86c0-74e44e05ccb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-1eebf3ee-8830-4e4a-811b-bdd40f5b4d54,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-4da4dd5e-d8f1-400f-9e43-18bd52e9bbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-727da12f-d762-4a69-b64a-b1a325443b5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-125590934-172.17.0.4-1597703457646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39400,DS-b5381f4f-8d6f-4b33-80f0-db6aba4f89c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-c008807d-c0e5-4319-bd08-70694578f112,DISK], DatanodeInfoWithStorage[127.0.0.1:45924,DS-edb71c89-c415-4ddb-bd28-8adb3993b8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-01ccf93a-fc11-48f7-90e5-e0720fb8d7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-3adca547-9ce4-4aff-9f03-bda1fb7b44c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-5afbbe60-7d1c-4ccb-864e-3d2aeedfb9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-0764459d-d6fd-45d4-88a6-f98c73dbc068,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-895b925a-4380-4ec9-8184-da413e83a8ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-125590934-172.17.0.4-1597703457646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39400,DS-b5381f4f-8d6f-4b33-80f0-db6aba4f89c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-c008807d-c0e5-4319-bd08-70694578f112,DISK], DatanodeInfoWithStorage[127.0.0.1:45924,DS-edb71c89-c415-4ddb-bd28-8adb3993b8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-01ccf93a-fc11-48f7-90e5-e0720fb8d7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-3adca547-9ce4-4aff-9f03-bda1fb7b44c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-5afbbe60-7d1c-4ccb-864e-3d2aeedfb9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-0764459d-d6fd-45d4-88a6-f98c73dbc068,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-895b925a-4380-4ec9-8184-da413e83a8ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2015451218-172.17.0.4-1597703600781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46791,DS-1a314f3a-9d00-4897-bc1a-9724b0d4fdce,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-405a8f5d-3542-45d4-897a-0c3264c8ad63,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-3496f420-c6a1-46a8-90aa-9103ab553618,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-5575162d-309d-445a-9832-12f4746b67ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-87a0745c-4b00-46c9-a6af-f731019ab395,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-c68dd31b-fe76-48f3-82b0-3ee875e2ee0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-2b2227f6-39da-454d-a6b6-1085f0377942,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-1eb710a4-3a71-4589-8279-83d98cc3a8c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2015451218-172.17.0.4-1597703600781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46791,DS-1a314f3a-9d00-4897-bc1a-9724b0d4fdce,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-405a8f5d-3542-45d4-897a-0c3264c8ad63,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-3496f420-c6a1-46a8-90aa-9103ab553618,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-5575162d-309d-445a-9832-12f4746b67ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-87a0745c-4b00-46c9-a6af-f731019ab395,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-c68dd31b-fe76-48f3-82b0-3ee875e2ee0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-2b2227f6-39da-454d-a6b6-1085f0377942,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-1eb710a4-3a71-4589-8279-83d98cc3a8c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1667167269-172.17.0.4-1597704347590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42982,DS-c0688f57-9d52-4a6f-b141-3f3f52cc3df1,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-26869a62-e6b6-4341-9683-7a259d2439fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-a03ee75f-fe64-4275-9f66-4bb9d9b644ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-4f857973-66f7-4131-aef0-4e334ff71519,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-88262fde-5f90-4709-88b4-1042cc4ea371,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-b02ea126-2d2f-45a9-ba0c-8148b9f5d9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-c50d1df8-d431-48a1-9b2f-827b9799a6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-d93663e2-2058-4ee1-b9a4-ffd2257f7659,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1667167269-172.17.0.4-1597704347590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42982,DS-c0688f57-9d52-4a6f-b141-3f3f52cc3df1,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-26869a62-e6b6-4341-9683-7a259d2439fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-a03ee75f-fe64-4275-9f66-4bb9d9b644ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-4f857973-66f7-4131-aef0-4e334ff71519,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-88262fde-5f90-4709-88b4-1042cc4ea371,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-b02ea126-2d2f-45a9-ba0c-8148b9f5d9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-c50d1df8-d431-48a1-9b2f-827b9799a6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-d93663e2-2058-4ee1-b9a4-ffd2257f7659,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-339267927-172.17.0.4-1597704502566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44702,DS-b933ef94-a545-4384-9306-61994062b4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-dd27d04c-5862-4876-8c08-3e22ab218183,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-dd5e478a-2667-45b2-ab39-d14b9ca578da,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-9b49db89-8104-4650-95ae-e5f55e6a452a,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-ecb8c085-5ccf-4fc2-8c5e-b46c3dda79d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-efefba07-7187-4076-9367-3de35648fdee,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-78bc68a1-5565-46c0-bfd7-8a91aeb7240a,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-c136da35-8d26-467f-bd9c-83e1eea358e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-339267927-172.17.0.4-1597704502566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44702,DS-b933ef94-a545-4384-9306-61994062b4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-dd27d04c-5862-4876-8c08-3e22ab218183,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-dd5e478a-2667-45b2-ab39-d14b9ca578da,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-9b49db89-8104-4650-95ae-e5f55e6a452a,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-ecb8c085-5ccf-4fc2-8c5e-b46c3dda79d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-efefba07-7187-4076-9367-3de35648fdee,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-78bc68a1-5565-46c0-bfd7-8a91aeb7240a,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-c136da35-8d26-467f-bd9c-83e1eea358e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-986163449-172.17.0.4-1597704542565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37765,DS-524bdd90-34db-4642-a3ce-62e6e1c34aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-05bf39be-d127-4be3-a990-a9bf6d9df996,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-ba212d94-0b84-42a7-97ae-c459474b5381,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-2d6e1636-83c8-4be8-8fe0-83c73f41f10b,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-da22a634-7b6f-471c-87d8-d0c311aef3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-b2be91fd-e8d0-4455-902f-4a756720cb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-6f00072d-4401-4573-92b7-abae28863382,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-f0410129-245f-4803-a505-731637bcb6cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-986163449-172.17.0.4-1597704542565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37765,DS-524bdd90-34db-4642-a3ce-62e6e1c34aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-05bf39be-d127-4be3-a990-a9bf6d9df996,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-ba212d94-0b84-42a7-97ae-c459474b5381,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-2d6e1636-83c8-4be8-8fe0-83c73f41f10b,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-da22a634-7b6f-471c-87d8-d0c311aef3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-b2be91fd-e8d0-4455-902f-4a756720cb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-6f00072d-4401-4573-92b7-abae28863382,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-f0410129-245f-4803-a505-731637bcb6cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2100920653-172.17.0.4-1597704679175:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34798,DS-c5c24031-1237-47f4-b092-a2b2229a83fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-616fbd99-af6e-47d1-b6ee-7ac96044f546,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-49459e5e-ae6c-45e9-85e7-7ecb82167e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-95555b24-2df1-4366-970a-ffcc9ba57950,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-abad36ca-1d31-42bb-b8f4-d4f8c39dee62,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-bb8cb8ce-99fc-4c5d-8e74-42306c0a9442,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-bf902d48-e7e0-497b-bd14-700d6560d2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-3a75b569-2248-42b3-93d3-e0aba2621215,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2100920653-172.17.0.4-1597704679175:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34798,DS-c5c24031-1237-47f4-b092-a2b2229a83fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-616fbd99-af6e-47d1-b6ee-7ac96044f546,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-49459e5e-ae6c-45e9-85e7-7ecb82167e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-95555b24-2df1-4366-970a-ffcc9ba57950,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-abad36ca-1d31-42bb-b8f4-d4f8c39dee62,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-bb8cb8ce-99fc-4c5d-8e74-42306c0a9442,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-bf902d48-e7e0-497b-bd14-700d6560d2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-3a75b569-2248-42b3-93d3-e0aba2621215,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1528050204-172.17.0.4-1597705009589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37637,DS-e3be7c2c-c3ca-442a-a283-8bc10db62380,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-b617b76d-5a95-4d82-859a-f0e02317de42,DISK], DatanodeInfoWithStorage[127.0.0.1:38359,DS-a5ad5b92-f7db-450f-bdd7-94808ef491b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-55a39aec-394b-45d1-ab6a-4ab89a11b991,DISK], DatanodeInfoWithStorage[127.0.0.1:45202,DS-80bc5375-bd2c-49d2-9f57-8742929e18c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-3d736a3e-9a99-481b-8d32-9241422d535b,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-9db7970a-012c-4782-a9dd-822e0b5515c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-1b17a439-4552-4595-853f-ce8b9236116d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1528050204-172.17.0.4-1597705009589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37637,DS-e3be7c2c-c3ca-442a-a283-8bc10db62380,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-b617b76d-5a95-4d82-859a-f0e02317de42,DISK], DatanodeInfoWithStorage[127.0.0.1:38359,DS-a5ad5b92-f7db-450f-bdd7-94808ef491b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-55a39aec-394b-45d1-ab6a-4ab89a11b991,DISK], DatanodeInfoWithStorage[127.0.0.1:45202,DS-80bc5375-bd2c-49d2-9f57-8742929e18c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-3d736a3e-9a99-481b-8d32-9241422d535b,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-9db7970a-012c-4782-a9dd-822e0b5515c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-1b17a439-4552-4595-853f-ce8b9236116d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1814876364-172.17.0.4-1597705749558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46075,DS-366d986a-e4e4-4fe2-815f-0e6f35fa99d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-138ba4db-1aac-4fbe-85ac-75a1f1dda670,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-2c30e1d4-f268-480f-ab9e-e7e5fa01ce59,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-cff14127-d650-4132-91e6-c47e454fcf59,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-3ee00b9e-b2cb-43ad-8193-4163d0cb976f,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-2ac2ab7d-0061-4d57-9f49-f6d1bfb806ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-aaefb81d-b276-40b3-af68-38d7c736a376,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-f03861ae-809c-4af7-b8f0-9614702c4258,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1814876364-172.17.0.4-1597705749558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46075,DS-366d986a-e4e4-4fe2-815f-0e6f35fa99d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-138ba4db-1aac-4fbe-85ac-75a1f1dda670,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-2c30e1d4-f268-480f-ab9e-e7e5fa01ce59,DISK], DatanodeInfoWithStorage[127.0.0.1:36242,DS-cff14127-d650-4132-91e6-c47e454fcf59,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-3ee00b9e-b2cb-43ad-8193-4163d0cb976f,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-2ac2ab7d-0061-4d57-9f49-f6d1bfb806ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-aaefb81d-b276-40b3-af68-38d7c736a376,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-f03861ae-809c-4af7-b8f0-9614702c4258,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1736426781-172.17.0.4-1597705835153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41285,DS-a5598233-d3e1-4be8-90ee-3e9959214bff,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-57254abb-2b77-47db-aad0-50d3f276a776,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-8db0f9d7-5fdb-435e-a0c8-ee3ac07db147,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-30d40517-bd91-4456-aa55-fb1f8237393d,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-4c60c3a9-0c54-4133-b250-78f723507aae,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-3735628e-ebaa-467f-bd2d-5741123520d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-747cf103-8447-4746-b47c-dd2cb8444ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-d2356000-d628-4507-bad7-1775cee97e03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1736426781-172.17.0.4-1597705835153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41285,DS-a5598233-d3e1-4be8-90ee-3e9959214bff,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-57254abb-2b77-47db-aad0-50d3f276a776,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-8db0f9d7-5fdb-435e-a0c8-ee3ac07db147,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-30d40517-bd91-4456-aa55-fb1f8237393d,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-4c60c3a9-0c54-4133-b250-78f723507aae,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-3735628e-ebaa-467f-bd2d-5741123520d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-747cf103-8447-4746-b47c-dd2cb8444ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-d2356000-d628-4507-bad7-1775cee97e03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1311223574-172.17.0.4-1597705917301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35211,DS-428a3ad5-fe42-4990-860b-d52aad542d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-298efbcd-0ce3-4e0b-bc6a-6d0fe59bb066,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-c5f3cfde-728c-46e6-97cd-3c11ffc2ad5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-f7b2e1aa-9897-45aa-b39d-02b40baac84d,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-cd665e0d-98f1-48ca-9557-bf2de76d2642,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-175b4c0d-6a60-4355-b621-2b41cc0d4307,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-6a3d112b-105e-426c-82b7-167138fd8eee,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-6ec4c0e4-e743-4a7c-b398-a69ee4093bf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1311223574-172.17.0.4-1597705917301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35211,DS-428a3ad5-fe42-4990-860b-d52aad542d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-298efbcd-0ce3-4e0b-bc6a-6d0fe59bb066,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-c5f3cfde-728c-46e6-97cd-3c11ffc2ad5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-f7b2e1aa-9897-45aa-b39d-02b40baac84d,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-cd665e0d-98f1-48ca-9557-bf2de76d2642,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-175b4c0d-6a60-4355-b621-2b41cc0d4307,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-6a3d112b-105e-426c-82b7-167138fd8eee,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-6ec4c0e4-e743-4a7c-b398-a69ee4093bf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1100888802-172.17.0.4-1597705968047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44867,DS-546942f7-19f3-4564-afa5-331880936263,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-13ba1355-36bf-4fc1-9b36-fa9a90e312c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-5fb889ca-bb5c-4a52-9a91-72b961ffed7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-fb9b368e-3f6b-46b4-ac9b-cf5ecf5ac0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37651,DS-dd92cce4-45bf-4209-97e9-6ae4f11629d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-818c1f21-2fcf-4a5d-a284-d0187ff9e514,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-846d8f2c-9347-452f-856f-3a13d59c9c67,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-15cfe878-6d1a-469a-b07b-f9ed61f0325a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1100888802-172.17.0.4-1597705968047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44867,DS-546942f7-19f3-4564-afa5-331880936263,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-13ba1355-36bf-4fc1-9b36-fa9a90e312c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-5fb889ca-bb5c-4a52-9a91-72b961ffed7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-fb9b368e-3f6b-46b4-ac9b-cf5ecf5ac0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37651,DS-dd92cce4-45bf-4209-97e9-6ae4f11629d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-818c1f21-2fcf-4a5d-a284-d0187ff9e514,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-846d8f2c-9347-452f-856f-3a13d59c9c67,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-15cfe878-6d1a-469a-b07b-f9ed61f0325a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1072483772-172.17.0.4-1597706194183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38356,DS-97ddc515-672d-49a8-a571-32b710c7c7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-17bf45f3-f9a7-4f23-a370-16a0f207e648,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-c6d54bab-6749-47f1-9927-0a57a18890d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-94657492-6131-4bde-a120-f89b1dd1e189,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-800e7312-4994-4e85-8d09-b89980f54ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-ab9ec80b-b7cd-4f71-b4ec-6ee6af030c09,DISK], DatanodeInfoWithStorage[127.0.0.1:36111,DS-edf09c60-07c6-4dde-8b2c-ebc5c4ab30d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-e4ee7212-a164-46a6-b433-741e384a5795,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1072483772-172.17.0.4-1597706194183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38356,DS-97ddc515-672d-49a8-a571-32b710c7c7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-17bf45f3-f9a7-4f23-a370-16a0f207e648,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-c6d54bab-6749-47f1-9927-0a57a18890d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-94657492-6131-4bde-a120-f89b1dd1e189,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-800e7312-4994-4e85-8d09-b89980f54ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-ab9ec80b-b7cd-4f71-b4ec-6ee6af030c09,DISK], DatanodeInfoWithStorage[127.0.0.1:36111,DS-edf09c60-07c6-4dde-8b2c-ebc5c4ab30d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-e4ee7212-a164-46a6-b433-741e384a5795,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1577722598-172.17.0.4-1597706239459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41500,DS-e3c81527-526f-432e-b202-890a3a7d2b48,DISK], DatanodeInfoWithStorage[127.0.0.1:34218,DS-f1f505ce-866d-4dad-9f86-09d2668115e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-3d9d9577-0ec2-4cab-ab44-5554a596c59b,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-9fc0266b-67a6-4286-b29d-08476dc13310,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-e3aa49ef-da15-4a09-a68e-3e07d43d76b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-6c5db242-33be-47ef-9276-ceef952a14c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-cad39300-838e-413d-905a-bc2b8f591f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-4469b2ce-b5f2-42f5-b1fa-ce516465bc63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1577722598-172.17.0.4-1597706239459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41500,DS-e3c81527-526f-432e-b202-890a3a7d2b48,DISK], DatanodeInfoWithStorage[127.0.0.1:34218,DS-f1f505ce-866d-4dad-9f86-09d2668115e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-3d9d9577-0ec2-4cab-ab44-5554a596c59b,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-9fc0266b-67a6-4286-b29d-08476dc13310,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-e3aa49ef-da15-4a09-a68e-3e07d43d76b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-6c5db242-33be-47ef-9276-ceef952a14c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-cad39300-838e-413d-905a-bc2b8f591f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-4469b2ce-b5f2-42f5-b1fa-ce516465bc63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-150219472-172.17.0.4-1597707069017:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45129,DS-db4929b9-494d-4b80-8a9f-10403f32d0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-718dc775-87fa-43b7-aaae-04351cc800b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-4163d1ab-d6ba-4b5c-b892-be4a811a0d27,DISK], DatanodeInfoWithStorage[127.0.0.1:34089,DS-a2cae4de-2951-4b68-9a6b-265c98018636,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-b2f2a265-3020-4c28-b224-8d74053cad1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-acb83ab3-ca88-477a-8099-a847b741160e,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-8ab2511c-521c-43dd-9985-912f6443ecee,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-60dce925-14fd-4cc1-b10d-f4def981714e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-150219472-172.17.0.4-1597707069017:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45129,DS-db4929b9-494d-4b80-8a9f-10403f32d0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-718dc775-87fa-43b7-aaae-04351cc800b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-4163d1ab-d6ba-4b5c-b892-be4a811a0d27,DISK], DatanodeInfoWithStorage[127.0.0.1:34089,DS-a2cae4de-2951-4b68-9a6b-265c98018636,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-b2f2a265-3020-4c28-b224-8d74053cad1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-acb83ab3-ca88-477a-8099-a847b741160e,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-8ab2511c-521c-43dd-9985-912f6443ecee,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-60dce925-14fd-4cc1-b10d-f4def981714e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-652525480-172.17.0.4-1597707191528:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45151,DS-2073a680-1fed-4d09-a716-f34b0feeba9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-0efc57f8-dac0-47fd-96e1-221cb09250b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-869174df-4ed1-4187-99e1-112d5ad599fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-b8631934-2f55-4dab-a51f-da41d9ac8be0,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-e58fb4fb-3e13-4adb-9e53-1377478f1947,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-c3cbcc16-b955-4fbd-8198-3614198d77c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-bd064725-9d9c-4747-b2ba-33043dc0068d,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-01d68b59-d5be-45ce-8078-cdbe3c29be6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-652525480-172.17.0.4-1597707191528:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45151,DS-2073a680-1fed-4d09-a716-f34b0feeba9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-0efc57f8-dac0-47fd-96e1-221cb09250b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-869174df-4ed1-4187-99e1-112d5ad599fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-b8631934-2f55-4dab-a51f-da41d9ac8be0,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-e58fb4fb-3e13-4adb-9e53-1377478f1947,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-c3cbcc16-b955-4fbd-8198-3614198d77c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-bd064725-9d9c-4747-b2ba-33043dc0068d,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-01d68b59-d5be-45ce-8078-cdbe3c29be6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1548737168-172.17.0.4-1597707890435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40186,DS-ef561d60-816b-4072-b5e0-8b72a24437c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-51092beb-1516-4537-92c4-ca9e08844574,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-717781fc-1e0f-4f9c-8631-ea67838abb87,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-a9b5ed73-dc72-44f2-a61f-6161a001fd13,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-78d5e825-28b1-4c96-b8af-346ad1a070fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-f305d14a-a1da-4e38-9791-13f27bfa48ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-c66f597a-a51a-45c7-a65b-459fe87061c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35766,DS-9a126f11-7693-4ed6-b5e9-862357add143,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1548737168-172.17.0.4-1597707890435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40186,DS-ef561d60-816b-4072-b5e0-8b72a24437c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-51092beb-1516-4537-92c4-ca9e08844574,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-717781fc-1e0f-4f9c-8631-ea67838abb87,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-a9b5ed73-dc72-44f2-a61f-6161a001fd13,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-78d5e825-28b1-4c96-b8af-346ad1a070fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-f305d14a-a1da-4e38-9791-13f27bfa48ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-c66f597a-a51a-45c7-a65b-459fe87061c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35766,DS-9a126f11-7693-4ed6-b5e9-862357add143,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1208970800-172.17.0.4-1597708076234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33656,DS-5e0cc4a0-24ef-4daf-9fd0-61f635c3027a,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-c6dc7e37-c300-4c67-9fd7-fda056a576b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-d6e55eca-12f9-4fcf-8b0a-0bb3dcee58d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-ff371a1c-c924-44de-a2f4-5c20e6296c39,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-9c639d0c-650b-471d-9687-4cda5403a64e,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-6662a293-8bba-437f-8b40-435a5a8ab6d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-5dbeba6f-3f90-44ff-97b6-ec85efcf66ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-f5eb5d4c-7d95-4be7-9e4b-48852fcedb59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1208970800-172.17.0.4-1597708076234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33656,DS-5e0cc4a0-24ef-4daf-9fd0-61f635c3027a,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-c6dc7e37-c300-4c67-9fd7-fda056a576b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-d6e55eca-12f9-4fcf-8b0a-0bb3dcee58d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-ff371a1c-c924-44de-a2f4-5c20e6296c39,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-9c639d0c-650b-471d-9687-4cda5403a64e,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-6662a293-8bba-437f-8b40-435a5a8ab6d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-5dbeba6f-3f90-44ff-97b6-ec85efcf66ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-f5eb5d4c-7d95-4be7-9e4b-48852fcedb59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1257201352-172.17.0.4-1597708365073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33089,DS-c1b97894-00fb-4c6b-a4ec-421eb8e58ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-afe953a8-ede2-443f-ac95-4c0e9b5675e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-9f0dfe27-101f-461b-a966-68d3d5bdd761,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-c345f056-3e39-44f2-b122-4271f2491716,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-f3c1ac82-6137-4d8f-88ac-721d7f172a09,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-cb87274b-f690-4e89-b59b-e4df6f316960,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-49feb58b-e98e-4cae-96ef-cfeace82e2df,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-3a55b62e-7fae-4b5e-8cb9-76d8b8828fdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1257201352-172.17.0.4-1597708365073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33089,DS-c1b97894-00fb-4c6b-a4ec-421eb8e58ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-afe953a8-ede2-443f-ac95-4c0e9b5675e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-9f0dfe27-101f-461b-a966-68d3d5bdd761,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-c345f056-3e39-44f2-b122-4271f2491716,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-f3c1ac82-6137-4d8f-88ac-721d7f172a09,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-cb87274b-f690-4e89-b59b-e4df6f316960,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-49feb58b-e98e-4cae-96ef-cfeace82e2df,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-3a55b62e-7fae-4b5e-8cb9-76d8b8828fdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1584183064-172.17.0.4-1597708584541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39581,DS-edea2179-a56f-45ee-9a76-fb4fd8ea54c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-2f5e4732-9f87-41f6-a475-bc9dd11f3d84,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-d498978d-0c34-43ba-a46b-704f8a649d07,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-f38fbadb-2a5c-455c-ba42-86008c9f70a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-1c766ee5-45de-4a61-8273-9102589c9bac,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-10149cd2-f8f6-48cc-9695-dbff3d1ad1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-4dbc43ca-e681-401a-8a3a-25c1c0b5f328,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-1b61f4ba-a0d3-4f0a-b7d4-9f4288eb7c94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1584183064-172.17.0.4-1597708584541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39581,DS-edea2179-a56f-45ee-9a76-fb4fd8ea54c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-2f5e4732-9f87-41f6-a475-bc9dd11f3d84,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-d498978d-0c34-43ba-a46b-704f8a649d07,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-f38fbadb-2a5c-455c-ba42-86008c9f70a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-1c766ee5-45de-4a61-8273-9102589c9bac,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-10149cd2-f8f6-48cc-9695-dbff3d1ad1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-4dbc43ca-e681-401a-8a3a-25c1c0b5f328,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-1b61f4ba-a0d3-4f0a-b7d4-9f4288eb7c94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6846
