reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439397260-172.17.0.11-1597315777105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41666,DS-bc1c7a08-4f87-4ae3-a94f-872ec4baa0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-768d3bbb-bd47-469c-8ad8-fc0a53b557f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-15a13a08-342a-44de-8d12-103fc0dce3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-e8e2e331-6fe9-48fc-87a3-e5345fb1ef29,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-3e24ca0d-3274-4022-b911-f70180d8c7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-34647ad0-9bce-45da-bdfa-996879ca868a,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-06050529-5509-4d5f-8f35-fd3e42c59fca,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-091ba62c-1684-4384-a202-cf31b3c6ad7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439397260-172.17.0.11-1597315777105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41666,DS-bc1c7a08-4f87-4ae3-a94f-872ec4baa0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-768d3bbb-bd47-469c-8ad8-fc0a53b557f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-15a13a08-342a-44de-8d12-103fc0dce3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-e8e2e331-6fe9-48fc-87a3-e5345fb1ef29,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-3e24ca0d-3274-4022-b911-f70180d8c7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-34647ad0-9bce-45da-bdfa-996879ca868a,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-06050529-5509-4d5f-8f35-fd3e42c59fca,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-091ba62c-1684-4384-a202-cf31b3c6ad7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-452984743-172.17.0.11-1597316111345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39558,DS-f5800682-8c7d-4578-a17e-4d1823add1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-0174d2ae-75bd-4f4b-a1ec-a7a4b5cf2410,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-12188fc5-9739-4c82-9c4c-0ebff1b6e6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-59e69a20-cb25-4122-b5ea-82ea30a3faa2,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-66b38ae2-c3e2-438d-a3ea-0b127da235b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-a8a20b6f-e5a2-49bc-8e16-317271321f65,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-2e9001fe-0552-420b-9c76-b6c98fcf99c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-64a931dc-c09e-49a7-85e5-1a107b482907,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-452984743-172.17.0.11-1597316111345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39558,DS-f5800682-8c7d-4578-a17e-4d1823add1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-0174d2ae-75bd-4f4b-a1ec-a7a4b5cf2410,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-12188fc5-9739-4c82-9c4c-0ebff1b6e6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-59e69a20-cb25-4122-b5ea-82ea30a3faa2,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-66b38ae2-c3e2-438d-a3ea-0b127da235b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-a8a20b6f-e5a2-49bc-8e16-317271321f65,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-2e9001fe-0552-420b-9c76-b6c98fcf99c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-64a931dc-c09e-49a7-85e5-1a107b482907,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-823450970-172.17.0.11-1597316501867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44458,DS-534c66b8-a08f-4e6a-a008-f5a45f92f8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-093eeeba-67f4-4ce0-93eb-f2d1df613ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-1a54003a-cc71-4fc8-a0d7-9046a0f8fa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-77b5aa58-bea5-4ee7-b7ed-9bd97683c4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-cede212c-c5e5-4c8b-b52c-11af95e3fd28,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-064db7d3-91cf-4beb-bcb7-b8dd0a4c45ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-1bdf3261-f591-4a44-8557-d98862f6330e,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-8879d409-e556-40be-8151-8fc74d65b3b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-823450970-172.17.0.11-1597316501867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44458,DS-534c66b8-a08f-4e6a-a008-f5a45f92f8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-093eeeba-67f4-4ce0-93eb-f2d1df613ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-1a54003a-cc71-4fc8-a0d7-9046a0f8fa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-77b5aa58-bea5-4ee7-b7ed-9bd97683c4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-cede212c-c5e5-4c8b-b52c-11af95e3fd28,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-064db7d3-91cf-4beb-bcb7-b8dd0a4c45ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-1bdf3261-f591-4a44-8557-d98862f6330e,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-8879d409-e556-40be-8151-8fc74d65b3b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1915186585-172.17.0.11-1597316896665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36067,DS-8dd99507-dec1-47ac-a7de-58a2680e8f18,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-225ea0bc-9b05-4d0a-98fb-5180fa1ef1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-a987529e-2ba6-45cb-ba23-6a09ac5181e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-140d6626-aba9-4e7c-98f1-84fa45e87e67,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-7f9e4de7-f6b1-4670-8c71-6b3764366bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-3fb59661-67a3-4be9-82e8-eddf2d6dfb25,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-9adb4067-72a1-4f65-adca-928440e8689a,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-17f91527-174a-4344-9f28-2b4970815e3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1915186585-172.17.0.11-1597316896665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36067,DS-8dd99507-dec1-47ac-a7de-58a2680e8f18,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-225ea0bc-9b05-4d0a-98fb-5180fa1ef1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-a987529e-2ba6-45cb-ba23-6a09ac5181e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-140d6626-aba9-4e7c-98f1-84fa45e87e67,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-7f9e4de7-f6b1-4670-8c71-6b3764366bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-3fb59661-67a3-4be9-82e8-eddf2d6dfb25,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-9adb4067-72a1-4f65-adca-928440e8689a,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-17f91527-174a-4344-9f28-2b4970815e3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1921111726-172.17.0.11-1597316967626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40981,DS-6deb833a-5554-4d5f-8536-a67b4400b093,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-adbfa769-d7bb-4021-826c-1776fcba2951,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-272a9fbe-f078-4164-a25c-bc28801cde57,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-0e50b39a-f8cb-4815-ab1a-51cb49bddc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40344,DS-61d8f005-a75f-40ad-b0c1-586ace00945c,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-d865e714-56f5-4cba-bd7c-27725494ffe9,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-f2b33968-cd0e-48c1-b413-f0341a6966a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40675,DS-a56d8951-7336-4484-b731-3883872b964b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1921111726-172.17.0.11-1597316967626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40981,DS-6deb833a-5554-4d5f-8536-a67b4400b093,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-adbfa769-d7bb-4021-826c-1776fcba2951,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-272a9fbe-f078-4164-a25c-bc28801cde57,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-0e50b39a-f8cb-4815-ab1a-51cb49bddc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40344,DS-61d8f005-a75f-40ad-b0c1-586ace00945c,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-d865e714-56f5-4cba-bd7c-27725494ffe9,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-f2b33968-cd0e-48c1-b413-f0341a6966a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40675,DS-a56d8951-7336-4484-b731-3883872b964b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-359689473-172.17.0.11-1597317167945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41617,DS-7e670383-556e-4acc-941e-b42a104910c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-173af82f-8119-41af-85a8-8100d93275c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-295f105c-41b6-4bd5-bc98-07f306633345,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-436e2312-64e7-43f7-acdf-a369e3d7fb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-ad874292-6501-4c29-8ab5-bec43139f85f,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-e1ff6f28-ecbd-439c-a91d-3d7ed6818a62,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-4cb40cf1-f5dc-42b6-aaea-9836c89ad7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-40f7d54a-a681-4732-8855-8af67df291d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-359689473-172.17.0.11-1597317167945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41617,DS-7e670383-556e-4acc-941e-b42a104910c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-173af82f-8119-41af-85a8-8100d93275c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-295f105c-41b6-4bd5-bc98-07f306633345,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-436e2312-64e7-43f7-acdf-a369e3d7fb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-ad874292-6501-4c29-8ab5-bec43139f85f,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-e1ff6f28-ecbd-439c-a91d-3d7ed6818a62,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-4cb40cf1-f5dc-42b6-aaea-9836c89ad7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-40f7d54a-a681-4732-8855-8af67df291d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019467912-172.17.0.11-1597317779126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37124,DS-88b7c62f-9ca9-42da-8bba-5d6b9f104cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-668fb6b6-f737-4852-9954-ffb10b0dc416,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-7f18bb38-f75a-48ab-9fb6-f70e6a0dd265,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-d1ea82b8-0467-4035-ad9c-9e2ad00e6cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-b785ecda-b6aa-4dcd-b90f-2b61fde3f7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-735e9f70-3f7f-43ef-912c-4e8f298268c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-6ebff182-0639-4b00-bfeb-fa87b9828580,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-3fb607e4-5a14-461d-857b-3cb3cb0af1c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019467912-172.17.0.11-1597317779126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37124,DS-88b7c62f-9ca9-42da-8bba-5d6b9f104cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-668fb6b6-f737-4852-9954-ffb10b0dc416,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-7f18bb38-f75a-48ab-9fb6-f70e6a0dd265,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-d1ea82b8-0467-4035-ad9c-9e2ad00e6cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-b785ecda-b6aa-4dcd-b90f-2b61fde3f7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-735e9f70-3f7f-43ef-912c-4e8f298268c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-6ebff182-0639-4b00-bfeb-fa87b9828580,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-3fb607e4-5a14-461d-857b-3cb3cb0af1c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097514343-172.17.0.11-1597318426876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42505,DS-a2708f77-69aa-4c61-a38b-ac4daf61b290,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-d2c44607-2fef-4ce5-a4f0-0a517ca63a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-60b15b66-990e-476b-a1b0-42b57d2589bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-6930001c-415d-4af3-8899-c36ff75083fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-5f3c9f40-5ea0-4ebd-b27a-0f00cfed5ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-e931ed71-5cbd-435a-9808-63200dfaf41d,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-03a1f535-2017-40fd-b743-034d0f13daf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-24b53159-32dd-444d-a5a1-358f71e35596,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097514343-172.17.0.11-1597318426876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42505,DS-a2708f77-69aa-4c61-a38b-ac4daf61b290,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-d2c44607-2fef-4ce5-a4f0-0a517ca63a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-60b15b66-990e-476b-a1b0-42b57d2589bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-6930001c-415d-4af3-8899-c36ff75083fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-5f3c9f40-5ea0-4ebd-b27a-0f00cfed5ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-e931ed71-5cbd-435a-9808-63200dfaf41d,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-03a1f535-2017-40fd-b743-034d0f13daf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-24b53159-32dd-444d-a5a1-358f71e35596,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436028177-172.17.0.11-1597318580122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41758,DS-ad2cbf04-b881-4056-91c7-c0b007baf9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-7386286a-8cef-461d-8dbe-0e985c8748fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-5b952a18-9539-4bec-8e6e-53348cd4c344,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-e5d79a4b-1066-4045-a34d-8b6c87f3209c,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-3fa8e29e-b4bd-45dd-8496-903ba78cf7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-3d5d4ff5-e297-42c4-8bb9-729863969c80,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-ea094a62-e9d6-4f14-b457-d50cad947973,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-57a3a0b6-3e34-4f07-a412-ac12e6853675,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436028177-172.17.0.11-1597318580122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41758,DS-ad2cbf04-b881-4056-91c7-c0b007baf9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-7386286a-8cef-461d-8dbe-0e985c8748fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-5b952a18-9539-4bec-8e6e-53348cd4c344,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-e5d79a4b-1066-4045-a34d-8b6c87f3209c,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-3fa8e29e-b4bd-45dd-8496-903ba78cf7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-3d5d4ff5-e297-42c4-8bb9-729863969c80,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-ea094a62-e9d6-4f14-b457-d50cad947973,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-57a3a0b6-3e34-4f07-a412-ac12e6853675,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921688809-172.17.0.11-1597319154427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41352,DS-a1397cda-ed42-4faa-ae4d-377ad02806dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-e3a5533d-3797-403b-9456-387a4fc6ef17,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-3e000e60-45ef-4cab-be4a-eaaa7bcc3119,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-5977d0bf-637c-44cb-864c-5b6504c1a34d,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-a187f431-bfa3-4a9e-bc9b-dc7ee6cba426,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-633d2735-0d11-45b4-85d7-821ced8716cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-71b57f30-21b3-44c2-bfb4-c74bc78b4c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-2ddbbdb4-8117-493f-bcb6-4f4fb6c6a645,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921688809-172.17.0.11-1597319154427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41352,DS-a1397cda-ed42-4faa-ae4d-377ad02806dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-e3a5533d-3797-403b-9456-387a4fc6ef17,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-3e000e60-45ef-4cab-be4a-eaaa7bcc3119,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-5977d0bf-637c-44cb-864c-5b6504c1a34d,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-a187f431-bfa3-4a9e-bc9b-dc7ee6cba426,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-633d2735-0d11-45b4-85d7-821ced8716cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-71b57f30-21b3-44c2-bfb4-c74bc78b4c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-2ddbbdb4-8117-493f-bcb6-4f4fb6c6a645,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-197411183-172.17.0.11-1597319638806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34433,DS-739c37e5-8932-4997-b255-c4f9264a7691,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-cfeb9686-194b-4ca5-b2cc-2645a0525af0,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-4e0db0d4-57ec-4c67-805a-bd345c869786,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-86f209d4-36d0-48d0-aa6a-59c96b4c531b,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-bb9b9a07-2702-4fad-96dc-4fbc938759c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-6baa5be9-71aa-4318-aed6-95f5d3833e67,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-9ec9395a-3656-4eb7-9c22-c1323ef0186e,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-dd7a8c56-32af-4341-bba7-27330ebb18c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-197411183-172.17.0.11-1597319638806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34433,DS-739c37e5-8932-4997-b255-c4f9264a7691,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-cfeb9686-194b-4ca5-b2cc-2645a0525af0,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-4e0db0d4-57ec-4c67-805a-bd345c869786,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-86f209d4-36d0-48d0-aa6a-59c96b4c531b,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-bb9b9a07-2702-4fad-96dc-4fbc938759c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-6baa5be9-71aa-4318-aed6-95f5d3833e67,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-9ec9395a-3656-4eb7-9c22-c1323ef0186e,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-dd7a8c56-32af-4341-bba7-27330ebb18c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-821582958-172.17.0.11-1597319783927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39670,DS-e34aaf3c-3ce9-49e3-9e26-93efd76d0ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-72d6705a-6473-4f34-95f3-d68fdea7f347,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-2bbe7686-a345-4eef-b1eb-834dd285c216,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-c2542b8c-f9e3-4c4c-8f7e-3c6abc80f928,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-c83b8db2-ab5f-4c05-adb7-ddb4e2a93f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-b01a61b6-d071-4c7d-af99-2fe097e17116,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-b7ed798a-3c3d-4fe1-8585-b9df3c50b6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-1b68945b-8ca0-4b94-9e8a-937e077ad625,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-821582958-172.17.0.11-1597319783927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39670,DS-e34aaf3c-3ce9-49e3-9e26-93efd76d0ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-72d6705a-6473-4f34-95f3-d68fdea7f347,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-2bbe7686-a345-4eef-b1eb-834dd285c216,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-c2542b8c-f9e3-4c4c-8f7e-3c6abc80f928,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-c83b8db2-ab5f-4c05-adb7-ddb4e2a93f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-b01a61b6-d071-4c7d-af99-2fe097e17116,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-b7ed798a-3c3d-4fe1-8585-b9df3c50b6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-1b68945b-8ca0-4b94-9e8a-937e077ad625,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361972089-172.17.0.11-1597320177337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41657,DS-f68f11e9-31f4-494c-b2b7-88774ecd3d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-80d23ce9-2353-4bbc-9cc8-1a5cfdf35716,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-8335a832-3de2-4698-87be-e45fe719d57a,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-f3e914da-4358-494c-90f4-7acfc05abcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-86c47b1f-6898-4917-96a1-4a7d56a68783,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-63c29d20-0b54-43ab-b883-f41d98f60e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-e83e948f-9893-4b54-aa53-a62972bd7f42,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-24d89188-c5f9-4368-8378-5f9c5aa1e923,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361972089-172.17.0.11-1597320177337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41657,DS-f68f11e9-31f4-494c-b2b7-88774ecd3d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-80d23ce9-2353-4bbc-9cc8-1a5cfdf35716,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-8335a832-3de2-4698-87be-e45fe719d57a,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-f3e914da-4358-494c-90f4-7acfc05abcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-86c47b1f-6898-4917-96a1-4a7d56a68783,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-63c29d20-0b54-43ab-b883-f41d98f60e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-e83e948f-9893-4b54-aa53-a62972bd7f42,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-24d89188-c5f9-4368-8378-5f9c5aa1e923,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015367803-172.17.0.11-1597320515231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37723,DS-27131ab2-710d-4c7e-bc8f-46484b2e7849,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-d71c150e-7d07-4ed5-8712-9fd7b3696e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-955fbd34-9a5c-4a2d-bc30-99278108f2db,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-4be16fdb-b87e-42fa-9be0-7c3ff7b3b947,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-8b19a840-f7de-4a79-8fd2-20a0e606b2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-cfd57f77-2b67-4aaf-bd7a-88fa20365f07,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-30b5d075-46b5-492e-aa55-ddc6a3aa240d,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-f82599c4-4662-4336-b040-a274cf00672c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015367803-172.17.0.11-1597320515231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37723,DS-27131ab2-710d-4c7e-bc8f-46484b2e7849,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-d71c150e-7d07-4ed5-8712-9fd7b3696e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-955fbd34-9a5c-4a2d-bc30-99278108f2db,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-4be16fdb-b87e-42fa-9be0-7c3ff7b3b947,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-8b19a840-f7de-4a79-8fd2-20a0e606b2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-cfd57f77-2b67-4aaf-bd7a-88fa20365f07,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-30b5d075-46b5-492e-aa55-ddc6a3aa240d,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-f82599c4-4662-4336-b040-a274cf00672c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914105011-172.17.0.11-1597320705709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43769,DS-a14dac29-a5fa-47f4-875f-cf9d75cba942,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-99dead03-22a8-44db-923b-56bf0121644b,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-43b07b15-2109-4a9c-a023-22f732f23336,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-ae6e33fb-3614-4c10-8a41-b3219c5674c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-244d3acc-0d8d-4a60-bd6f-bf737f619f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-a9d4e9ee-63aa-4e5e-9fab-e1f54bbdd318,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-1b60b99a-a6c8-43ae-967d-3b98bc7d53d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-0efd3b39-9bf5-403e-a2d4-eeaec9e8500c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914105011-172.17.0.11-1597320705709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43769,DS-a14dac29-a5fa-47f4-875f-cf9d75cba942,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-99dead03-22a8-44db-923b-56bf0121644b,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-43b07b15-2109-4a9c-a023-22f732f23336,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-ae6e33fb-3614-4c10-8a41-b3219c5674c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-244d3acc-0d8d-4a60-bd6f-bf737f619f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-a9d4e9ee-63aa-4e5e-9fab-e1f54bbdd318,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-1b60b99a-a6c8-43ae-967d-3b98bc7d53d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-0efd3b39-9bf5-403e-a2d4-eeaec9e8500c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542749700-172.17.0.11-1597320822861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42177,DS-62b5b893-fbf3-462c-b3fb-0af33553cc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-20b9cd19-785f-4745-b3cd-3c00ce1404d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-0d7331ee-5ea1-475c-bda1-b53efdbc1f44,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-dfd964a9-0361-4ff9-8938-efc3cfb997aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-2746b96c-2fba-4070-943c-30b336f4920b,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-96ad789b-ac2c-476d-b860-7d5bc29a6f02,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-1e8cfa41-0af7-4157-b421-07ae517c3a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-e4cc6a8d-e8dc-4733-8bf4-8d648a5b6581,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542749700-172.17.0.11-1597320822861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42177,DS-62b5b893-fbf3-462c-b3fb-0af33553cc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-20b9cd19-785f-4745-b3cd-3c00ce1404d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-0d7331ee-5ea1-475c-bda1-b53efdbc1f44,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-dfd964a9-0361-4ff9-8938-efc3cfb997aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-2746b96c-2fba-4070-943c-30b336f4920b,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-96ad789b-ac2c-476d-b860-7d5bc29a6f02,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-1e8cfa41-0af7-4157-b421-07ae517c3a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-e4cc6a8d-e8dc-4733-8bf4-8d648a5b6581,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616135548-172.17.0.11-1597320977628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40202,DS-63215d11-e309-495f-8c1c-f75b30a85939,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-1c469933-7000-49c6-810c-55806c408630,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-e790ac6b-7f6c-4754-bc55-cb3e69942f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-7036d769-b6e5-46cc-b630-951b45fdae66,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-1be76654-03b5-494f-9678-4e90778eea60,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-99fec931-40ae-4352-9ab2-9101330c6544,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-25516b37-34f6-437a-b352-1d23d1dabf78,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-57c8d579-a27d-4328-8172-182711bdbe94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616135548-172.17.0.11-1597320977628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40202,DS-63215d11-e309-495f-8c1c-f75b30a85939,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-1c469933-7000-49c6-810c-55806c408630,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-e790ac6b-7f6c-4754-bc55-cb3e69942f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-7036d769-b6e5-46cc-b630-951b45fdae66,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-1be76654-03b5-494f-9678-4e90778eea60,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-99fec931-40ae-4352-9ab2-9101330c6544,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-25516b37-34f6-437a-b352-1d23d1dabf78,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-57c8d579-a27d-4328-8172-182711bdbe94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1439295905-172.17.0.11-1597321090376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38134,DS-1e2dfd1c-6ff9-45ea-b1fe-3ad453b7f34d,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-4d6bc178-2b59-4076-86d8-959d0fc95c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-12cc9d76-8219-4c48-83bb-fa6b4603b2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-3db4ed46-376f-4164-8043-b3f01727aede,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-64cbd489-6199-41c2-a832-fffa470d17e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-304b0135-2f8e-4340-97a1-5870904d5400,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-5015d17f-c387-4a08-b171-5d1f10441b23,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-1e976c50-ae9c-43e8-bd56-eceeda7f488d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1439295905-172.17.0.11-1597321090376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38134,DS-1e2dfd1c-6ff9-45ea-b1fe-3ad453b7f34d,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-4d6bc178-2b59-4076-86d8-959d0fc95c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-12cc9d76-8219-4c48-83bb-fa6b4603b2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-3db4ed46-376f-4164-8043-b3f01727aede,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-64cbd489-6199-41c2-a832-fffa470d17e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-304b0135-2f8e-4340-97a1-5870904d5400,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-5015d17f-c387-4a08-b171-5d1f10441b23,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-1e976c50-ae9c-43e8-bd56-eceeda7f488d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1462078594-172.17.0.11-1597321334747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45749,DS-8ed766f2-d555-415a-9fd5-1ad076362619,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-8159ae9f-82a6-4ca3-982f-e92c97daa8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-3d23ae34-8264-40ff-9d0e-c953fb4ed6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34358,DS-954b5c36-0578-4c1e-992f-784769ece3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-f6c7b1b5-957b-4062-ad65-61703f4db16b,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-2e650927-6239-44a6-b2d5-4ef2eab15fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-43ab19b0-786b-4bc0-ab32-ce192010e355,DISK], DatanodeInfoWithStorage[127.0.0.1:46313,DS-836f5baa-1d17-421e-abc7-bac91ba4f6b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1462078594-172.17.0.11-1597321334747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45749,DS-8ed766f2-d555-415a-9fd5-1ad076362619,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-8159ae9f-82a6-4ca3-982f-e92c97daa8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-3d23ae34-8264-40ff-9d0e-c953fb4ed6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34358,DS-954b5c36-0578-4c1e-992f-784769ece3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-f6c7b1b5-957b-4062-ad65-61703f4db16b,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-2e650927-6239-44a6-b2d5-4ef2eab15fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-43ab19b0-786b-4bc0-ab32-ce192010e355,DISK], DatanodeInfoWithStorage[127.0.0.1:46313,DS-836f5baa-1d17-421e-abc7-bac91ba4f6b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5724
