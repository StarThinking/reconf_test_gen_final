reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119895247-172.17.0.21-1597724862336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33136,DS-02243968-a113-4fd7-a419-c1e476a1fb99,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-fdd240f3-a0aa-448e-ae2f-64c141f254a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-0384b26f-78f2-4e20-a5c7-3716d8524ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-770de150-bdce-4eaa-9d9a-688f8bfab0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-0c75fad2-f313-4f12-b71b-bf2cb87212cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-1406aed2-dfb7-4841-b443-2ab532027056,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-97c00b1d-947d-4ab9-9c11-25ad4deb03c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-dc3c8d46-7293-4078-82bd-8ba87a630e05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119895247-172.17.0.21-1597724862336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33136,DS-02243968-a113-4fd7-a419-c1e476a1fb99,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-fdd240f3-a0aa-448e-ae2f-64c141f254a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-0384b26f-78f2-4e20-a5c7-3716d8524ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-770de150-bdce-4eaa-9d9a-688f8bfab0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-0c75fad2-f313-4f12-b71b-bf2cb87212cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-1406aed2-dfb7-4841-b443-2ab532027056,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-97c00b1d-947d-4ab9-9c11-25ad4deb03c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-dc3c8d46-7293-4078-82bd-8ba87a630e05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1661799766-172.17.0.21-1597725371789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33297,DS-42d9a02a-adfc-48b3-9323-81e153513b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-3654f281-d8bb-4a27-9fba-967796d105c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-678c7506-c1a8-4d79-b02c-1d0a3955a822,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-f4ed5659-e80c-4435-815d-f02694b19d41,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-022ced0b-ac17-4c59-bb62-df1e306854d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43383,DS-d10e8a15-3221-48c7-aeec-7351fc031b38,DISK], DatanodeInfoWithStorage[127.0.0.1:40574,DS-ff0418c5-25b2-4f28-a3b1-7905e3b2179d,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-f0a2d234-8618-4bef-91c9-57f2e9f1dad7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1661799766-172.17.0.21-1597725371789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33297,DS-42d9a02a-adfc-48b3-9323-81e153513b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-3654f281-d8bb-4a27-9fba-967796d105c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-678c7506-c1a8-4d79-b02c-1d0a3955a822,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-f4ed5659-e80c-4435-815d-f02694b19d41,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-022ced0b-ac17-4c59-bb62-df1e306854d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43383,DS-d10e8a15-3221-48c7-aeec-7351fc031b38,DISK], DatanodeInfoWithStorage[127.0.0.1:40574,DS-ff0418c5-25b2-4f28-a3b1-7905e3b2179d,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-f0a2d234-8618-4bef-91c9-57f2e9f1dad7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2073929264-172.17.0.21-1597725440151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42252,DS-de1023ce-96d0-4d96-8fed-e87acbb5aa51,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-2e38fca4-410d-4487-8540-1dce27f1c97c,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-0cad590a-0c68-43c1-a190-d00a0b487458,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-d70ca1bb-1743-425c-b468-952efe26e390,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-cca01bdd-9442-4b98-9e0a-07f07c4c874e,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-dad884a1-f479-447e-8469-a1b171d3fe5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-86d68fbf-2d32-42b5-839e-d896118ba38a,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-525882dc-980e-4bec-8d7b-8534beceda16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2073929264-172.17.0.21-1597725440151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42252,DS-de1023ce-96d0-4d96-8fed-e87acbb5aa51,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-2e38fca4-410d-4487-8540-1dce27f1c97c,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-0cad590a-0c68-43c1-a190-d00a0b487458,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-d70ca1bb-1743-425c-b468-952efe26e390,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-cca01bdd-9442-4b98-9e0a-07f07c4c874e,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-dad884a1-f479-447e-8469-a1b171d3fe5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-86d68fbf-2d32-42b5-839e-d896118ba38a,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-525882dc-980e-4bec-8d7b-8534beceda16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-463543205-172.17.0.21-1597725479745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45438,DS-39cf4b1e-ece0-434d-8250-22e397c8dfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-0f09107a-e349-4e45-9127-7567d6f60b94,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-411368c3-df3e-486e-8637-2b37ed398c01,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-4046a3f4-a09d-43c9-8029-6165b154f2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-aacf5b76-33b5-4432-b1f0-0e5bed1f7e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-39479b19-2f4a-4444-a7cd-e385c1b20329,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-18887f3f-0b9c-4d6c-8667-9f9be3b75872,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-1c33210e-a706-46f0-a079-761caeb52e32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-463543205-172.17.0.21-1597725479745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45438,DS-39cf4b1e-ece0-434d-8250-22e397c8dfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-0f09107a-e349-4e45-9127-7567d6f60b94,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-411368c3-df3e-486e-8637-2b37ed398c01,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-4046a3f4-a09d-43c9-8029-6165b154f2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-aacf5b76-33b5-4432-b1f0-0e5bed1f7e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-39479b19-2f4a-4444-a7cd-e385c1b20329,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-18887f3f-0b9c-4d6c-8667-9f9be3b75872,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-1c33210e-a706-46f0-a079-761caeb52e32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742875327-172.17.0.21-1597725584091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39317,DS-e745919a-2341-4ef9-af02-c90d7205cf95,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-04415ef0-eafe-40b0-add9-7a949c246d90,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-fd506959-ce53-4bca-a5ba-38700850d6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-c36395c6-d867-4b6d-80d2-9a0fd1af13fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-e48b1c7e-bb32-4972-ab9a-7d662c9e19eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-c0980976-a7ee-4351-9199-df2ffe875b72,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-a60ade9c-b881-4433-951e-63a226de2fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-80450d99-93b5-4229-b42c-8a745bb879e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742875327-172.17.0.21-1597725584091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39317,DS-e745919a-2341-4ef9-af02-c90d7205cf95,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-04415ef0-eafe-40b0-add9-7a949c246d90,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-fd506959-ce53-4bca-a5ba-38700850d6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-c36395c6-d867-4b6d-80d2-9a0fd1af13fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-e48b1c7e-bb32-4972-ab9a-7d662c9e19eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-c0980976-a7ee-4351-9199-df2ffe875b72,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-a60ade9c-b881-4433-951e-63a226de2fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-80450d99-93b5-4229-b42c-8a745bb879e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566707589-172.17.0.21-1597726348453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43355,DS-b949f124-592b-4179-98a7-579638fe6354,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-49b850d7-ce9b-41d5-84cc-f569417246fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-feb12e04-7d81-43c3-8888-3f999d482ade,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-5d14888b-bdb4-4638-936e-e9b9ce66c711,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-1cacaade-926c-4bf0-b4fb-480efbeed080,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-44b787f4-a43b-4c3d-a826-ee3d588cbd70,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-c1cde176-1725-4cd8-b403-8a0728b40168,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-ae54886c-80da-4426-9bbb-17a5560db641,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566707589-172.17.0.21-1597726348453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43355,DS-b949f124-592b-4179-98a7-579638fe6354,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-49b850d7-ce9b-41d5-84cc-f569417246fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-feb12e04-7d81-43c3-8888-3f999d482ade,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-5d14888b-bdb4-4638-936e-e9b9ce66c711,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-1cacaade-926c-4bf0-b4fb-480efbeed080,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-44b787f4-a43b-4c3d-a826-ee3d588cbd70,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-c1cde176-1725-4cd8-b403-8a0728b40168,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-ae54886c-80da-4426-9bbb-17a5560db641,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1768431169-172.17.0.21-1597726493087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32916,DS-576107b2-0f13-43e9-98fb-ba18bccb9937,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-8813c6df-1f94-4fe1-a1c6-d30f8e51e9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-ade9ed8b-55b3-4c44-9a52-faa6aca88d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-b56a7008-ebaa-4fce-bede-e4e20aa3aa70,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-4a95c03d-bb82-423a-84f9-b1fef0ad7a27,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-60020d40-75c1-4f0d-8612-9c3b0cf2720e,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-f6001d64-1ada-4220-88fb-3c2631877649,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-828eeee9-858f-4601-82d5-ce9a197c8dfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1768431169-172.17.0.21-1597726493087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32916,DS-576107b2-0f13-43e9-98fb-ba18bccb9937,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-8813c6df-1f94-4fe1-a1c6-d30f8e51e9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-ade9ed8b-55b3-4c44-9a52-faa6aca88d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-b56a7008-ebaa-4fce-bede-e4e20aa3aa70,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-4a95c03d-bb82-423a-84f9-b1fef0ad7a27,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-60020d40-75c1-4f0d-8612-9c3b0cf2720e,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-f6001d64-1ada-4220-88fb-3c2631877649,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-828eeee9-858f-4601-82d5-ce9a197c8dfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1897265694-172.17.0.21-1597726533337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42685,DS-26eb8a23-579e-43d7-85bd-013d70273a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-a9344f4f-890f-4cd9-925c-5062d2e3b82d,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-6250a756-bee6-4fcd-83d7-925f2f182bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-6188b947-0b02-4c63-b239-cfa668e2daf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33492,DS-a2dc8d62-cd62-48ea-a575-37879ed591d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-f1edc4d3-a5dc-4a7e-a9b6-2f4f351cbea7,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-400bff88-19d5-4e07-ac09-990406e7d351,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-b4af6259-b5bc-4b90-b6c5-15249ff5343b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1897265694-172.17.0.21-1597726533337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42685,DS-26eb8a23-579e-43d7-85bd-013d70273a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-a9344f4f-890f-4cd9-925c-5062d2e3b82d,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-6250a756-bee6-4fcd-83d7-925f2f182bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-6188b947-0b02-4c63-b239-cfa668e2daf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33492,DS-a2dc8d62-cd62-48ea-a575-37879ed591d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-f1edc4d3-a5dc-4a7e-a9b6-2f4f351cbea7,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-400bff88-19d5-4e07-ac09-990406e7d351,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-b4af6259-b5bc-4b90-b6c5-15249ff5343b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-242781161-172.17.0.21-1597726835194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33863,DS-f26266ac-89f4-47aa-afa2-df83ab49c1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-5198923b-5a5d-4dc8-bd8b-ef62a9e76306,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-3e8e7fad-5df6-48f4-885a-8ad45a30b73b,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-9b958bd0-05da-4c02-9623-edf772d24804,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-986b9fcf-0dd4-4a60-ad50-2d45daaaa014,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-d0f5ffe3-65cd-4bca-8c1f-7bdb08cd64da,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-55915e5c-97d7-4891-8faf-bd4f3d7c438e,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-76591149-b1cf-4e18-a9ac-843324e618ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-242781161-172.17.0.21-1597726835194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33863,DS-f26266ac-89f4-47aa-afa2-df83ab49c1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-5198923b-5a5d-4dc8-bd8b-ef62a9e76306,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-3e8e7fad-5df6-48f4-885a-8ad45a30b73b,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-9b958bd0-05da-4c02-9623-edf772d24804,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-986b9fcf-0dd4-4a60-ad50-2d45daaaa014,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-d0f5ffe3-65cd-4bca-8c1f-7bdb08cd64da,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-55915e5c-97d7-4891-8faf-bd4f3d7c438e,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-76591149-b1cf-4e18-a9ac-843324e618ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130989462-172.17.0.21-1597726875830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43824,DS-30d964ce-aed6-4521-83ff-2c9534ddd66d,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-a60b0eb5-1523-4825-8eca-ec8e0aa964ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-c63e1255-6a88-499e-bdb7-2bc95418208c,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-ec8b2aa5-4d40-4371-8798-bb078735e2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-2474991e-49ef-4611-a32a-7ad3d0fe3aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-2478df5e-d66b-439a-8d90-057a7ab8fda4,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-c6b5e0c1-4b55-4883-9c53-ae97eb14088a,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-a5b6cb18-d8bb-4664-a502-16c472081b0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130989462-172.17.0.21-1597726875830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43824,DS-30d964ce-aed6-4521-83ff-2c9534ddd66d,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-a60b0eb5-1523-4825-8eca-ec8e0aa964ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-c63e1255-6a88-499e-bdb7-2bc95418208c,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-ec8b2aa5-4d40-4371-8798-bb078735e2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-2474991e-49ef-4611-a32a-7ad3d0fe3aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-2478df5e-d66b-439a-8d90-057a7ab8fda4,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-c6b5e0c1-4b55-4883-9c53-ae97eb14088a,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-a5b6cb18-d8bb-4664-a502-16c472081b0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-633250692-172.17.0.21-1597727247179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43486,DS-bd42ab6a-2436-48ed-88aa-12e010c35df7,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-8601a194-37e8-4ab8-98a1-d9017830b719,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-9fab0f16-9679-4347-87a7-c0077f30eda1,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-40970d86-ffdb-41a6-a878-c4bf5bf928e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-3703b0b2-b254-4921-8e93-3bb41cd3a169,DISK], DatanodeInfoWithStorage[127.0.0.1:40172,DS-fe6e668b-0af6-49d8-aa83-85f4fb343cee,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-f43f3d06-9750-4330-bc95-d4d15568e306,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-604c5b03-bc0b-4654-81f7-f5a072063add,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-633250692-172.17.0.21-1597727247179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43486,DS-bd42ab6a-2436-48ed-88aa-12e010c35df7,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-8601a194-37e8-4ab8-98a1-d9017830b719,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-9fab0f16-9679-4347-87a7-c0077f30eda1,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-40970d86-ffdb-41a6-a878-c4bf5bf928e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-3703b0b2-b254-4921-8e93-3bb41cd3a169,DISK], DatanodeInfoWithStorage[127.0.0.1:40172,DS-fe6e668b-0af6-49d8-aa83-85f4fb343cee,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-f43f3d06-9750-4330-bc95-d4d15568e306,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-604c5b03-bc0b-4654-81f7-f5a072063add,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-83435551-172.17.0.21-1597727536086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32800,DS-20040c6a-4ffb-4931-ac06-e196cb2b2dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-1faaf7f2-8d70-4500-9420-427f9f39c969,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-55c12d5e-f2a5-4fb9-94e4-f4eeb823f223,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-408b25d3-2b96-44e9-84cb-4a98f8c3c5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-9138878c-d548-4536-a88e-0fc80680ce9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-6db3f174-6773-46a0-bdc4-8fd706886f52,DISK], DatanodeInfoWithStorage[127.0.0.1:36858,DS-5ffccfe5-491d-4102-957d-e52e5c4ecd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-00a91a5a-a63d-4d6f-a4d7-cdaaaed3b3c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-83435551-172.17.0.21-1597727536086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32800,DS-20040c6a-4ffb-4931-ac06-e196cb2b2dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-1faaf7f2-8d70-4500-9420-427f9f39c969,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-55c12d5e-f2a5-4fb9-94e4-f4eeb823f223,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-408b25d3-2b96-44e9-84cb-4a98f8c3c5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-9138878c-d548-4536-a88e-0fc80680ce9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-6db3f174-6773-46a0-bdc4-8fd706886f52,DISK], DatanodeInfoWithStorage[127.0.0.1:36858,DS-5ffccfe5-491d-4102-957d-e52e5c4ecd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-00a91a5a-a63d-4d6f-a4d7-cdaaaed3b3c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-653386056-172.17.0.21-1597727801704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41694,DS-ec089fba-ec4f-47b5-9e89-31f6ae1ea74d,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-bfded267-e01d-4244-bcbe-fa2d51effc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-9665f7de-d17b-4d23-bce5-34c818a50fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-8e6a5c5b-a25a-49a4-bf73-88706e644c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-f38e7f38-6071-4b61-aeed-e2a2b28ce848,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-78859102-f6e9-4943-b251-7fd5b4a3f0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-606fb824-e28a-417b-ad1a-3d49b1e259b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-0c3f9506-465b-477d-9319-1d356ef251e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-653386056-172.17.0.21-1597727801704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41694,DS-ec089fba-ec4f-47b5-9e89-31f6ae1ea74d,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-bfded267-e01d-4244-bcbe-fa2d51effc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-9665f7de-d17b-4d23-bce5-34c818a50fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-8e6a5c5b-a25a-49a4-bf73-88706e644c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-f38e7f38-6071-4b61-aeed-e2a2b28ce848,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-78859102-f6e9-4943-b251-7fd5b4a3f0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-606fb824-e28a-417b-ad1a-3d49b1e259b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-0c3f9506-465b-477d-9319-1d356ef251e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088228330-172.17.0.21-1597728211456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45985,DS-23b208e1-9140-4889-9c4e-7be7fa63b31a,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-a7617b4b-97c5-420d-9054-0aa4ee8c01d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-24d67d92-85c6-4721-8a7c-e6b816e99b08,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-3ca45c44-c1fd-46b4-8e02-813eb5a2f830,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-e78c2d53-3ac3-40d0-a684-3a6ec5e8bba9,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-c6fc9f08-fd7e-46c4-9baf-4aa8bcd18101,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-6ddbd4c9-db09-4eab-9c45-42b76959ba7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-a8877941-20a2-4388-8714-963f891403ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088228330-172.17.0.21-1597728211456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45985,DS-23b208e1-9140-4889-9c4e-7be7fa63b31a,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-a7617b4b-97c5-420d-9054-0aa4ee8c01d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-24d67d92-85c6-4721-8a7c-e6b816e99b08,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-3ca45c44-c1fd-46b4-8e02-813eb5a2f830,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-e78c2d53-3ac3-40d0-a684-3a6ec5e8bba9,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-c6fc9f08-fd7e-46c4-9baf-4aa8bcd18101,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-6ddbd4c9-db09-4eab-9c45-42b76959ba7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-a8877941-20a2-4388-8714-963f891403ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047027406-172.17.0.21-1597728247552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37343,DS-a955ccf3-3e79-446d-9ddf-79b15d45e78a,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-f8a2efab-95cf-46a9-96a3-229da4ec6022,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-329ebf00-95a9-4a8c-bdeb-430b29603932,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-568ba453-9f5d-4687-8b53-cdef827b07f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-c8c2ce39-58e7-40f8-9b7e-7c3aef7c1d24,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-fac9b446-d55c-4e0f-ab5d-ea4c9f073229,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-9d95b4f3-0b2c-4e4b-9bde-f0a76b75a5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-0052d065-363e-4ef9-89f5-ce706d1c2c9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047027406-172.17.0.21-1597728247552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37343,DS-a955ccf3-3e79-446d-9ddf-79b15d45e78a,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-f8a2efab-95cf-46a9-96a3-229da4ec6022,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-329ebf00-95a9-4a8c-bdeb-430b29603932,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-568ba453-9f5d-4687-8b53-cdef827b07f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-c8c2ce39-58e7-40f8-9b7e-7c3aef7c1d24,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-fac9b446-d55c-4e0f-ab5d-ea4c9f073229,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-9d95b4f3-0b2c-4e4b-9bde-f0a76b75a5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-0052d065-363e-4ef9-89f5-ce706d1c2c9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99578588-172.17.0.21-1597728714043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41909,DS-fbd2bb48-b712-479f-90b2-0606aea4a6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-20e7067f-e45f-465b-b1e5-6845c2a4fcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-e8c904f0-811d-4473-a253-65f23060313e,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-7a27ec5f-ea83-470e-87e1-7dbf70e7c019,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-d97e7c76-e719-480e-8144-84a8e09dc87a,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-e8815412-0f42-464e-8580-bc615400963c,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-8180579c-59c2-4ca9-be98-b812475b8555,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-e08c24bd-0ef0-43ab-b720-6939321842f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99578588-172.17.0.21-1597728714043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41909,DS-fbd2bb48-b712-479f-90b2-0606aea4a6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-20e7067f-e45f-465b-b1e5-6845c2a4fcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-e8c904f0-811d-4473-a253-65f23060313e,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-7a27ec5f-ea83-470e-87e1-7dbf70e7c019,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-d97e7c76-e719-480e-8144-84a8e09dc87a,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-e8815412-0f42-464e-8580-bc615400963c,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-8180579c-59c2-4ca9-be98-b812475b8555,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-e08c24bd-0ef0-43ab-b720-6939321842f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892618156-172.17.0.21-1597728984352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37277,DS-a6e37a6d-bee0-4ea7-b662-a9588b469eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-0a693c4f-6bbe-4683-a373-195796a3b804,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-228842ba-6d7e-4dc6-9ebd-5e05616b4fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-96f367b9-3705-439d-8d33-68991d0e9f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-4b18b25f-62ea-411e-a1dd-051e31cba517,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-95b7d52e-6b6d-4729-97bd-c6be8d3af531,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-2b23e0b1-7d7a-4049-8b15-82d4295798c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-7a9aaecf-0d99-434b-be3f-3cf739e53265,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892618156-172.17.0.21-1597728984352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37277,DS-a6e37a6d-bee0-4ea7-b662-a9588b469eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-0a693c4f-6bbe-4683-a373-195796a3b804,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-228842ba-6d7e-4dc6-9ebd-5e05616b4fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-96f367b9-3705-439d-8d33-68991d0e9f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-4b18b25f-62ea-411e-a1dd-051e31cba517,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-95b7d52e-6b6d-4729-97bd-c6be8d3af531,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-2b23e0b1-7d7a-4049-8b15-82d4295798c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-7a9aaecf-0d99-434b-be3f-3cf739e53265,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5579
