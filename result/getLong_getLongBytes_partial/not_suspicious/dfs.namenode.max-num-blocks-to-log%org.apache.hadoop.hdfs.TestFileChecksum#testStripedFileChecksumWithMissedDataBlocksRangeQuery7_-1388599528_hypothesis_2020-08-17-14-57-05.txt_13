reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-277856695-172.17.0.8-1597676240909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37140,DS-eecebe4d-4d5d-4a39-bb13-c57c28d1c5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-3c6e5890-1978-448e-9064-2fbfc1708738,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-f49f3dcb-a674-4cad-aa9b-7b0cad814d07,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-3a4ac1fa-3b3f-4f20-aeb2-58f051303cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-24c7e955-e361-413c-9660-1adcdcb98b23,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-51fd94c9-e5d2-4a43-98ac-8020cfc8e96f,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-a86b6f29-bba3-4f42-8566-c810a45b830d,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-72eb84de-11c6-4b1f-afee-75cda8c2acf5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-277856695-172.17.0.8-1597676240909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37140,DS-eecebe4d-4d5d-4a39-bb13-c57c28d1c5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-3c6e5890-1978-448e-9064-2fbfc1708738,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-f49f3dcb-a674-4cad-aa9b-7b0cad814d07,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-3a4ac1fa-3b3f-4f20-aeb2-58f051303cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-24c7e955-e361-413c-9660-1adcdcb98b23,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-51fd94c9-e5d2-4a43-98ac-8020cfc8e96f,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-a86b6f29-bba3-4f42-8566-c810a45b830d,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-72eb84de-11c6-4b1f-afee-75cda8c2acf5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1169316283-172.17.0.8-1597676407624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41155,DS-cacf54d9-d5fb-4fd2-b52b-d598c8cdc0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-7d793175-b4c5-4134-a4ce-0e38d50540f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-f3dfa475-6277-40b3-ac43-b3e32cf624db,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-5722cb18-ab63-4650-9ffb-1d705d5fefc6,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-046b9315-cc61-4f9e-b422-070566adcafb,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-08d5bcf6-cce9-4e29-98ca-ce51fd57ea84,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-91b6c989-94d2-4588-8bc5-bbaa2941e422,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-42f100a7-9010-4389-be4b-aea70cbe1c34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1169316283-172.17.0.8-1597676407624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41155,DS-cacf54d9-d5fb-4fd2-b52b-d598c8cdc0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-7d793175-b4c5-4134-a4ce-0e38d50540f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-f3dfa475-6277-40b3-ac43-b3e32cf624db,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-5722cb18-ab63-4650-9ffb-1d705d5fefc6,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-046b9315-cc61-4f9e-b422-070566adcafb,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-08d5bcf6-cce9-4e29-98ca-ce51fd57ea84,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-91b6c989-94d2-4588-8bc5-bbaa2941e422,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-42f100a7-9010-4389-be4b-aea70cbe1c34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204959922-172.17.0.8-1597676671487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45419,DS-a0c00044-943d-4217-9ec8-66562d9c5c19,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-59921510-0e7d-4c24-8ea0-6910e6b7163d,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-8877865e-493c-41b7-b92b-08885c71a251,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-d0ad4fd4-5234-428f-9f22-e1d9aa9acd47,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-b1cd3f5a-4e40-4dc7-8acb-b8c09a2b42cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-924ee2d0-2b9e-46a3-874b-2ca10be77177,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-b5c6c813-563f-4974-8251-5a4891c589c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-6d7f86c8-6928-4e31-a5b7-1c64eb000102,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204959922-172.17.0.8-1597676671487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45419,DS-a0c00044-943d-4217-9ec8-66562d9c5c19,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-59921510-0e7d-4c24-8ea0-6910e6b7163d,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-8877865e-493c-41b7-b92b-08885c71a251,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-d0ad4fd4-5234-428f-9f22-e1d9aa9acd47,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-b1cd3f5a-4e40-4dc7-8acb-b8c09a2b42cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-924ee2d0-2b9e-46a3-874b-2ca10be77177,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-b5c6c813-563f-4974-8251-5a4891c589c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-6d7f86c8-6928-4e31-a5b7-1c64eb000102,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1153813369-172.17.0.8-1597677044788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45546,DS-d85bd92c-1c2a-449e-a4ab-bc99b8f6c290,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-d747f627-d3a0-4a0c-a48b-bae0fada7031,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-16a97f5b-ac95-4aa5-adda-a3608b43a660,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-2e3aa806-759b-4fe7-870a-14136329e424,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-5181c569-d986-41fe-a85b-b58e0fcd207b,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-46b400ea-75b3-4366-b37e-f3e55321b2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-2ad5cde8-4c0e-4e5c-a98d-d3470a7368ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-092a22d5-13c1-4720-97ca-02e60114d6cc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1153813369-172.17.0.8-1597677044788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45546,DS-d85bd92c-1c2a-449e-a4ab-bc99b8f6c290,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-d747f627-d3a0-4a0c-a48b-bae0fada7031,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-16a97f5b-ac95-4aa5-adda-a3608b43a660,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-2e3aa806-759b-4fe7-870a-14136329e424,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-5181c569-d986-41fe-a85b-b58e0fcd207b,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-46b400ea-75b3-4366-b37e-f3e55321b2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-2ad5cde8-4c0e-4e5c-a98d-d3470a7368ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-092a22d5-13c1-4720-97ca-02e60114d6cc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1242071234-172.17.0.8-1597677240835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33245,DS-cd69cca4-456d-412f-acee-26030d44070c,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-852e1433-860c-4986-8fb8-d74f8ab9702d,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-71beabbf-3359-4b69-9b8a-229f387237ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-4ae617d4-d845-43bc-896a-6f8187e0a742,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-6db91748-ff1b-4d2e-bef2-cf60a6c3bc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-3bb5b551-6599-4c8a-84db-3a11c0002088,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-1731201e-dfe5-4699-ab0c-252af7815a81,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-c0d0be60-d44b-49fb-9f1f-8954c627e76b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1242071234-172.17.0.8-1597677240835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33245,DS-cd69cca4-456d-412f-acee-26030d44070c,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-852e1433-860c-4986-8fb8-d74f8ab9702d,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-71beabbf-3359-4b69-9b8a-229f387237ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-4ae617d4-d845-43bc-896a-6f8187e0a742,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-6db91748-ff1b-4d2e-bef2-cf60a6c3bc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-3bb5b551-6599-4c8a-84db-3a11c0002088,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-1731201e-dfe5-4699-ab0c-252af7815a81,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-c0d0be60-d44b-49fb-9f1f-8954c627e76b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-265874381-172.17.0.8-1597677279300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37505,DS-ad23d6b8-ae25-449b-bd5a-3b47946f624f,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-094cf630-0864-4f89-a0a5-731261ffb4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-394e0b34-e311-48da-92ee-ffad1de5db4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-79904e54-4d84-4bad-b13a-344234959067,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-82bba8b0-330f-416a-b6af-c57e37e7b015,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-2cfb5a42-0110-47a1-8ad9-67f9039f86b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-0e0ee444-2982-4782-8832-a4fe5eefbab6,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-9b277b87-1777-4a84-a5db-eb0aac7b446d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-265874381-172.17.0.8-1597677279300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37505,DS-ad23d6b8-ae25-449b-bd5a-3b47946f624f,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-094cf630-0864-4f89-a0a5-731261ffb4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-394e0b34-e311-48da-92ee-ffad1de5db4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-79904e54-4d84-4bad-b13a-344234959067,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-82bba8b0-330f-416a-b6af-c57e37e7b015,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-2cfb5a42-0110-47a1-8ad9-67f9039f86b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-0e0ee444-2982-4782-8832-a4fe5eefbab6,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-9b277b87-1777-4a84-a5db-eb0aac7b446d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-170186563-172.17.0.8-1597677322313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35590,DS-8991200a-d111-4b08-a783-dfea75e18c44,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-2c21b827-ea61-46fc-ae6e-12c1a3724b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-2e314a76-f605-47e5-b48c-124af6dbff11,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-98b92f8d-2243-453b-9419-d16fac63a512,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-4b792a53-b793-43d7-9743-64c7b4c40030,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-c9a4f029-5bca-442f-9b36-2a64896a6482,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-692f7fc8-c9d1-4b93-8fe9-bdda9fc1ae49,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-0c4bf946-205e-4c4f-8e61-d66d16e5f6db,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-170186563-172.17.0.8-1597677322313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35590,DS-8991200a-d111-4b08-a783-dfea75e18c44,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-2c21b827-ea61-46fc-ae6e-12c1a3724b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-2e314a76-f605-47e5-b48c-124af6dbff11,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-98b92f8d-2243-453b-9419-d16fac63a512,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-4b792a53-b793-43d7-9743-64c7b4c40030,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-c9a4f029-5bca-442f-9b36-2a64896a6482,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-692f7fc8-c9d1-4b93-8fe9-bdda9fc1ae49,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-0c4bf946-205e-4c4f-8e61-d66d16e5f6db,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-876052103-172.17.0.8-1597677396735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38965,DS-314bdee0-808c-4023-88d2-b87fd77b9812,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-ab96ba26-88d4-46ed-91b8-a70f1bbf7a52,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-dbadd019-480e-4f12-90a2-26ec45e00b45,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-74185a28-c978-4067-9732-9425e63b6d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-5e1e5428-ea45-4abb-9c4e-363d5d53016f,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-db92937e-c85a-4d18-965a-a48ea14be41d,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-c5a8d301-4c5d-4f08-ab4b-5db7e32e9e77,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-0aaa92b1-07c5-4236-a485-5841bd3325fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-876052103-172.17.0.8-1597677396735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38965,DS-314bdee0-808c-4023-88d2-b87fd77b9812,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-ab96ba26-88d4-46ed-91b8-a70f1bbf7a52,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-dbadd019-480e-4f12-90a2-26ec45e00b45,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-74185a28-c978-4067-9732-9425e63b6d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-5e1e5428-ea45-4abb-9c4e-363d5d53016f,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-db92937e-c85a-4d18-965a-a48ea14be41d,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-c5a8d301-4c5d-4f08-ab4b-5db7e32e9e77,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-0aaa92b1-07c5-4236-a485-5841bd3325fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092499323-172.17.0.8-1597677668726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46174,DS-f111fbf9-6365-491a-a57d-c8801a78be65,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-254e54df-394b-4211-ad16-9de9573216b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-840b15f2-13df-4326-80b5-622cca964510,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-f079b01d-6adb-4072-a204-c1edca5fe7db,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-40c420f2-5c35-4e6e-b9cc-0d789af619fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-5094ad9a-f0dd-4578-bccd-119556ffeee3,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-1653ad4c-c334-414f-ad0c-30768d57fdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-f20d5901-2a13-4822-933f-f7a4c4f61e5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092499323-172.17.0.8-1597677668726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46174,DS-f111fbf9-6365-491a-a57d-c8801a78be65,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-254e54df-394b-4211-ad16-9de9573216b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-840b15f2-13df-4326-80b5-622cca964510,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-f079b01d-6adb-4072-a204-c1edca5fe7db,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-40c420f2-5c35-4e6e-b9cc-0d789af619fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-5094ad9a-f0dd-4578-bccd-119556ffeee3,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-1653ad4c-c334-414f-ad0c-30768d57fdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-f20d5901-2a13-4822-933f-f7a4c4f61e5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503591490-172.17.0.8-1597677931638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46633,DS-fcf89a96-bbe4-4362-b896-848f855186e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-aa1a7ec5-4981-497c-981f-544558bdc7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-fbacef1d-b4dd-4e81-860d-ecd087fbd387,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-8967225a-f729-48c6-b435-071b4b5bec30,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-6ef062bb-519d-49af-891e-600294c33393,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-d97f1d41-bcbe-48ba-b209-9ac1239ccb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-353dc08c-2266-47c3-9fbe-9765ce666a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-edacb15c-7ec1-4c6c-9159-45d6bbebce84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503591490-172.17.0.8-1597677931638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46633,DS-fcf89a96-bbe4-4362-b896-848f855186e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-aa1a7ec5-4981-497c-981f-544558bdc7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-fbacef1d-b4dd-4e81-860d-ecd087fbd387,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-8967225a-f729-48c6-b435-071b4b5bec30,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-6ef062bb-519d-49af-891e-600294c33393,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-d97f1d41-bcbe-48ba-b209-9ac1239ccb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-353dc08c-2266-47c3-9fbe-9765ce666a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-edacb15c-7ec1-4c6c-9159-45d6bbebce84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-548200774-172.17.0.8-1597677961281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45536,DS-4179fee2-8a5a-4e58-a1ff-7d3eafe3994c,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-9f7497bf-7892-47a4-a867-8bcf73e49129,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-6549eb57-b691-41fe-8d1b-d1c64f0f89da,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-5fbc05f3-81de-4507-948d-853428d6da68,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-67e93bd0-8651-4a65-8cc7-7287934f2d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-8867be23-2a23-418f-a689-a98ebca6748f,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-726f3e5d-7af9-4508-8a46-6b7c2b77b3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-4dfffc21-3fa7-4ad6-8369-109fde4ed9e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-548200774-172.17.0.8-1597677961281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45536,DS-4179fee2-8a5a-4e58-a1ff-7d3eafe3994c,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-9f7497bf-7892-47a4-a867-8bcf73e49129,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-6549eb57-b691-41fe-8d1b-d1c64f0f89da,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-5fbc05f3-81de-4507-948d-853428d6da68,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-67e93bd0-8651-4a65-8cc7-7287934f2d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-8867be23-2a23-418f-a689-a98ebca6748f,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-726f3e5d-7af9-4508-8a46-6b7c2b77b3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-4dfffc21-3fa7-4ad6-8369-109fde4ed9e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1280266515-172.17.0.8-1597678274919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45466,DS-fff6e355-9fd9-4360-a2de-3364fffd01cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-5e1939f1-a614-43d2-9e23-0208fff8709f,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-f5235988-dab3-46a7-9ae2-ec8f5bcd7fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-77b9b319-8ea7-45e7-bdf4-b31f8ad6b479,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-0e740e36-8272-4c7d-9ec8-e8b5064647e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-151d50cb-d6e1-41e3-8c4c-91a85db86435,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-dd160cc5-9bd0-422a-a9ba-509df217ed31,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-04ec24ce-6729-4e8b-a4ea-59c526eaa9a2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1280266515-172.17.0.8-1597678274919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45466,DS-fff6e355-9fd9-4360-a2de-3364fffd01cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-5e1939f1-a614-43d2-9e23-0208fff8709f,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-f5235988-dab3-46a7-9ae2-ec8f5bcd7fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-77b9b319-8ea7-45e7-bdf4-b31f8ad6b479,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-0e740e36-8272-4c7d-9ec8-e8b5064647e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-151d50cb-d6e1-41e3-8c4c-91a85db86435,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-dd160cc5-9bd0-422a-a9ba-509df217ed31,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-04ec24ce-6729-4e8b-a4ea-59c526eaa9a2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-159977737-172.17.0.8-1597678319187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35522,DS-3c8257af-d08f-43b7-ae07-d16d7f16865f,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-16e61f45-b6e8-4a6d-921a-a40e3f09b7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34218,DS-53f9badf-1bbb-425c-aacd-89aab24cb601,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-d9f7ac4a-ee03-4e39-ac4d-4ea694593388,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-fa48a346-c1a9-4386-81b8-957d9afb6c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-df836036-7241-4eef-9ada-98d4d9266d78,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-b6088efc-32d3-41a9-a3bd-98cd6a761fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44306,DS-4744e058-3cc0-4b6a-a63d-6a6735c08f2b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-159977737-172.17.0.8-1597678319187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35522,DS-3c8257af-d08f-43b7-ae07-d16d7f16865f,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-16e61f45-b6e8-4a6d-921a-a40e3f09b7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34218,DS-53f9badf-1bbb-425c-aacd-89aab24cb601,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-d9f7ac4a-ee03-4e39-ac4d-4ea694593388,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-fa48a346-c1a9-4386-81b8-957d9afb6c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-df836036-7241-4eef-9ada-98d4d9266d78,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-b6088efc-32d3-41a9-a3bd-98cd6a761fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44306,DS-4744e058-3cc0-4b6a-a63d-6a6735c08f2b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-581656289-172.17.0.8-1597678363487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38583,DS-e7484877-8a26-4408-9fab-82fe7454596d,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-a07d3224-bfbd-4cb1-bb01-3e080cdaa327,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-3c4036a3-f5a2-4d3e-9acb-3b4fa007f14f,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-dc5c67ac-4690-431e-aa06-f9fad5e266bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-d6624a48-4454-481b-9de7-a20c561807f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-382a80b3-42c3-42d6-8b17-a34fd277e776,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-b2353a54-6e3d-4e40-ace2-b5a970eee8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-56ebb907-5f67-45df-8585-6e893f54e0da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-581656289-172.17.0.8-1597678363487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38583,DS-e7484877-8a26-4408-9fab-82fe7454596d,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-a07d3224-bfbd-4cb1-bb01-3e080cdaa327,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-3c4036a3-f5a2-4d3e-9acb-3b4fa007f14f,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-dc5c67ac-4690-431e-aa06-f9fad5e266bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-d6624a48-4454-481b-9de7-a20c561807f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-382a80b3-42c3-42d6-8b17-a34fd277e776,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-b2353a54-6e3d-4e40-ace2-b5a970eee8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-56ebb907-5f67-45df-8585-6e893f54e0da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2137711868-172.17.0.8-1597678438210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38401,DS-1cc48893-c7f1-4e6f-8e0d-4a7063cbaa9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-a870d03c-5c59-410e-ae7f-bd493e904d20,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-fe7bfd58-151a-4c79-8ffe-cbba135b8fec,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-1f2b3dd7-9073-4af9-ae19-c6ca0500a08e,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-27b15f9a-8590-4f05-9e64-cdd0b2baff43,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-224a5501-eb8c-4483-8dc4-724b534faa4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-70a09a5f-b742-43da-ba45-8e85811816d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-0a54d21b-d304-46c9-9110-a4f192012f40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2137711868-172.17.0.8-1597678438210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38401,DS-1cc48893-c7f1-4e6f-8e0d-4a7063cbaa9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-a870d03c-5c59-410e-ae7f-bd493e904d20,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-fe7bfd58-151a-4c79-8ffe-cbba135b8fec,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-1f2b3dd7-9073-4af9-ae19-c6ca0500a08e,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-27b15f9a-8590-4f05-9e64-cdd0b2baff43,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-224a5501-eb8c-4483-8dc4-724b534faa4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-70a09a5f-b742-43da-ba45-8e85811816d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-0a54d21b-d304-46c9-9110-a4f192012f40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-16091930-172.17.0.8-1597678849780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35936,DS-dbe9ac9d-0e51-479b-bd30-7959cc7ef21d,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-ced8fbe5-826d-4f83-8cf3-bf0fe460a455,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-e01ebda4-da8c-4e70-8c1d-aae0b5dc3b07,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-f72d0734-ec7b-4ef7-a444-f88acf0169a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-b3940e18-8c66-40c0-b3b6-35916472b3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-7d5d504d-6fab-4faa-b4a5-ac40e25377c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-d9695d77-8cd9-4208-bb67-449d3fc940f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-849d957c-4bf1-45c9-b728-847acf6de4a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-16091930-172.17.0.8-1597678849780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35936,DS-dbe9ac9d-0e51-479b-bd30-7959cc7ef21d,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-ced8fbe5-826d-4f83-8cf3-bf0fe460a455,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-e01ebda4-da8c-4e70-8c1d-aae0b5dc3b07,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-f72d0734-ec7b-4ef7-a444-f88acf0169a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-b3940e18-8c66-40c0-b3b6-35916472b3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-7d5d504d-6fab-4faa-b4a5-ac40e25377c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-d9695d77-8cd9-4208-bb67-449d3fc940f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-849d957c-4bf1-45c9-b728-847acf6de4a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1644139913-172.17.0.8-1597679222980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43781,DS-2bdea1ea-9425-46f3-97ce-271103049c57,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-0f1c68d6-c035-4ea5-b361-23b4bfdb447e,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-921bc12c-11b4-4800-ab5f-74b95d087ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-99ce24d3-b6ce-47de-b35b-693e4b404caf,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-413d64d5-7172-4a45-b6f1-52c54eb029ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-33f6570d-5488-4276-a3b7-ccd9a197f132,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-7022a4f6-04bf-410c-9fe3-64cf93da41e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-dd1ae6f6-94b0-4007-823e-4893f587cb04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1644139913-172.17.0.8-1597679222980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43781,DS-2bdea1ea-9425-46f3-97ce-271103049c57,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-0f1c68d6-c035-4ea5-b361-23b4bfdb447e,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-921bc12c-11b4-4800-ab5f-74b95d087ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-99ce24d3-b6ce-47de-b35b-693e4b404caf,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-413d64d5-7172-4a45-b6f1-52c54eb029ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-33f6570d-5488-4276-a3b7-ccd9a197f132,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-7022a4f6-04bf-410c-9fe3-64cf93da41e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-dd1ae6f6-94b0-4007-823e-4893f587cb04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1514552632-172.17.0.8-1597679468911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33452,DS-bcdb0621-bc61-433b-bb0c-fc7c1d52a67e,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-8988d22a-9b80-4c38-bfff-f9d5a77afa9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-7aa991a8-3775-4cda-99aa-63a8adc11164,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-b22d7695-f281-400d-be19-477546cd1f30,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-2f082b92-30b9-44d3-8e9d-6340bcf1262a,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-705be094-4c75-421b-b92e-c3b99768d07f,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-3d407598-fa94-49ef-b730-b2c514554481,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-e3f48c24-4b97-471d-b1a1-03addd5045e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1514552632-172.17.0.8-1597679468911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33452,DS-bcdb0621-bc61-433b-bb0c-fc7c1d52a67e,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-8988d22a-9b80-4c38-bfff-f9d5a77afa9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-7aa991a8-3775-4cda-99aa-63a8adc11164,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-b22d7695-f281-400d-be19-477546cd1f30,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-2f082b92-30b9-44d3-8e9d-6340bcf1262a,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-705be094-4c75-421b-b92e-c3b99768d07f,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-3d407598-fa94-49ef-b730-b2c514554481,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-e3f48c24-4b97-471d-b1a1-03addd5045e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-686815566-172.17.0.8-1597679572075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38425,DS-51050d3f-638f-42f6-ad86-4428a2f2ff31,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-383a4217-7ef4-4be1-8a35-884a2638eba8,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-27f84ef2-963f-4b98-bf2f-cfb6ab728ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-96ab911f-06d7-4b51-ae8c-2fd441a4dc07,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-aeafe6ec-d177-48cc-a600-81738d3ad7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-11834f1d-f286-41f6-b67b-caa69506c07e,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-54d96ff2-d9e6-4bb7-8b55-d18a1098c236,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-e8e36762-2b8b-4022-9162-22b8e587aa0c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-686815566-172.17.0.8-1597679572075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38425,DS-51050d3f-638f-42f6-ad86-4428a2f2ff31,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-383a4217-7ef4-4be1-8a35-884a2638eba8,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-27f84ef2-963f-4b98-bf2f-cfb6ab728ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-96ab911f-06d7-4b51-ae8c-2fd441a4dc07,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-aeafe6ec-d177-48cc-a600-81738d3ad7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-11834f1d-f286-41f6-b67b-caa69506c07e,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-54d96ff2-d9e6-4bb7-8b55-d18a1098c236,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-e8e36762-2b8b-4022-9162-22b8e587aa0c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850767809-172.17.0.8-1597679641207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41189,DS-dcb2c034-056e-420d-9695-87f620914cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-17e10fef-13c1-4ef5-8473-76871bd87445,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-d84cea31-407a-42ee-bbe8-25c696c5ed37,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-e6d20cf4-258a-4bb8-8ce3-725fe679a464,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-cbf0fb60-1cd5-4411-b714-19a23d985af1,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-3775acd3-26f4-4749-8483-586c2a4225e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-71278a88-efe5-4a14-b23f-de2f63d9f20c,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-8e9a4a7a-b678-4f8e-abd2-acd3910563d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850767809-172.17.0.8-1597679641207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41189,DS-dcb2c034-056e-420d-9695-87f620914cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-17e10fef-13c1-4ef5-8473-76871bd87445,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-d84cea31-407a-42ee-bbe8-25c696c5ed37,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-e6d20cf4-258a-4bb8-8ce3-725fe679a464,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-cbf0fb60-1cd5-4411-b714-19a23d985af1,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-3775acd3-26f4-4749-8483-586c2a4225e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-71278a88-efe5-4a14-b23f-de2f63d9f20c,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-8e9a4a7a-b678-4f8e-abd2-acd3910563d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-23951613-172.17.0.8-1597679679752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34134,DS-6b7d6e8a-b324-4564-aab4-4a12e697f12a,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-1740b43a-afde-434a-b05f-9881b22a49a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-c5ac76ee-6c90-445b-8cf2-df065d758904,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-c34de4fd-7822-427f-bae4-247e50fc7ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:33853,DS-583ea12c-29a5-4f52-9e81-5ab37d018486,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-0876024f-a9c4-41d5-b445-4f899bfc5333,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-43182211-2513-4878-a1e3-b53ef965dde6,DISK], DatanodeInfoWithStorage[127.0.0.1:33263,DS-e0b79048-433f-433e-a835-f84bcabe73a4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-23951613-172.17.0.8-1597679679752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34134,DS-6b7d6e8a-b324-4564-aab4-4a12e697f12a,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-1740b43a-afde-434a-b05f-9881b22a49a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-c5ac76ee-6c90-445b-8cf2-df065d758904,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-c34de4fd-7822-427f-bae4-247e50fc7ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:33853,DS-583ea12c-29a5-4f52-9e81-5ab37d018486,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-0876024f-a9c4-41d5-b445-4f899bfc5333,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-43182211-2513-4878-a1e3-b53ef965dde6,DISK], DatanodeInfoWithStorage[127.0.0.1:33263,DS-e0b79048-433f-433e-a835-f84bcabe73a4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692733326-172.17.0.8-1597679753048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34265,DS-bbf2afde-9ec0-411e-a916-240410efe240,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-384fb8bc-b1ed-4afb-b9de-d0db562582ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-61498201-5dec-4eba-a99b-9c083c736cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-deb21ef4-2760-4f56-841c-77f47fb5393b,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-9cbc858b-e797-4c8f-957e-dbb66e655559,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-8e0c513e-fef0-45a4-8340-c203450a42d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-6471e63e-08b2-4466-ab38-760bf68176e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-73509b94-a435-458d-9427-4c5477d3a3da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692733326-172.17.0.8-1597679753048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34265,DS-bbf2afde-9ec0-411e-a916-240410efe240,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-384fb8bc-b1ed-4afb-b9de-d0db562582ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-61498201-5dec-4eba-a99b-9c083c736cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-deb21ef4-2760-4f56-841c-77f47fb5393b,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-9cbc858b-e797-4c8f-957e-dbb66e655559,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-8e0c513e-fef0-45a4-8340-c203450a42d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-6471e63e-08b2-4466-ab38-760bf68176e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-73509b94-a435-458d-9427-4c5477d3a3da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152930522-172.17.0.8-1597679945374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35410,DS-a4c57a44-13c9-4c4c-be8e-c3ad141bd7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-250fa479-6637-4855-b882-5739970eb33c,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-a185fc30-01d2-4743-bc20-0a7febcdeec7,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-ba79bf6a-82ea-4aeb-bf1c-71a59dcf3ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-484cd275-b60b-474a-af05-618463e8e5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-50c4df15-f0da-40bb-aaa9-7899bd4d6d95,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-75d955e5-93e7-4e19-92e1-b51241793819,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-312843ec-6fa4-43e7-8c8d-6bb1b3152cd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152930522-172.17.0.8-1597679945374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35410,DS-a4c57a44-13c9-4c4c-be8e-c3ad141bd7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-250fa479-6637-4855-b882-5739970eb33c,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-a185fc30-01d2-4743-bc20-0a7febcdeec7,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-ba79bf6a-82ea-4aeb-bf1c-71a59dcf3ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-484cd275-b60b-474a-af05-618463e8e5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-50c4df15-f0da-40bb-aaa9-7899bd4d6d95,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-75d955e5-93e7-4e19-92e1-b51241793819,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-312843ec-6fa4-43e7-8c8d-6bb1b3152cd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-232424818-172.17.0.8-1597680218262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34831,DS-72b873e7-d17f-412e-b748-67db34e11310,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-163064c0-36c7-4aba-92c8-8d39932fb935,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-c0bade33-d5ff-40bd-8b95-dc833525ecbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-26e948e1-110b-437d-8f4f-b8ef3f20543b,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-4a15304e-ab90-4d8e-a417-d2d4b3bf4436,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-ca34dbe4-bb56-49f8-8c47-a36f42d56bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-48ca7e92-38fe-4d2d-abad-6ecd631cb84b,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-5743fff8-dee1-465e-8058-17b41b25b599,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-232424818-172.17.0.8-1597680218262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34831,DS-72b873e7-d17f-412e-b748-67db34e11310,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-163064c0-36c7-4aba-92c8-8d39932fb935,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-c0bade33-d5ff-40bd-8b95-dc833525ecbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-26e948e1-110b-437d-8f4f-b8ef3f20543b,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-4a15304e-ab90-4d8e-a417-d2d4b3bf4436,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-ca34dbe4-bb56-49f8-8c47-a36f42d56bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-48ca7e92-38fe-4d2d-abad-6ecd631cb84b,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-5743fff8-dee1-465e-8058-17b41b25b599,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756089912-172.17.0.8-1597680336074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45313,DS-bdb9a687-325a-4cdb-817f-faeb2f17b8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-ad479e5c-ba0b-437d-b115-15ba10e09ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-6c98d444-a61f-483b-a70c-c4c2d787304e,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-6f5ca59d-5161-4734-b52c-2e88b3dd639e,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-38aded67-2fba-4833-b648-0bb488c2d4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-60474bb1-20df-4749-8e2a-57cce349f5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-d2502b61-4930-43b1-b7de-b2b09a0d13aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-0258a6fc-e274-48b2-b573-a2af17a0b4dd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756089912-172.17.0.8-1597680336074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45313,DS-bdb9a687-325a-4cdb-817f-faeb2f17b8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-ad479e5c-ba0b-437d-b115-15ba10e09ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-6c98d444-a61f-483b-a70c-c4c2d787304e,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-6f5ca59d-5161-4734-b52c-2e88b3dd639e,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-38aded67-2fba-4833-b648-0bb488c2d4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-60474bb1-20df-4749-8e2a-57cce349f5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-d2502b61-4930-43b1-b7de-b2b09a0d13aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-0258a6fc-e274-48b2-b573-a2af17a0b4dd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1280277525-172.17.0.8-1597680406702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37219,DS-6d7bb5a1-e578-4bff-91bb-7181b72c56bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-8a04f014-ce08-47df-abf2-a4d88794f04b,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-3190a0d7-6403-482e-98b6-528a5c23f88d,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-de72ac84-4c51-4efe-9903-8f698294c64c,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-4f67daeb-0585-4ab4-b9b4-4ebb38df0fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-bc3137a3-5b1f-4231-804d-a33d5ca547ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-b4026486-1809-493f-9f1f-d777004b670b,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-aedfa066-319a-4f88-b2c9-ff8db28522de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1280277525-172.17.0.8-1597680406702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37219,DS-6d7bb5a1-e578-4bff-91bb-7181b72c56bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-8a04f014-ce08-47df-abf2-a4d88794f04b,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-3190a0d7-6403-482e-98b6-528a5c23f88d,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-de72ac84-4c51-4efe-9903-8f698294c64c,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-4f67daeb-0585-4ab4-b9b4-4ebb38df0fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-bc3137a3-5b1f-4231-804d-a33d5ca547ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-b4026486-1809-493f-9f1f-d777004b670b,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-aedfa066-319a-4f88-b2c9-ff8db28522de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-683415813-172.17.0.8-1597680940808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42071,DS-ceb78675-136b-4ac0-ad2c-828548f0b0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-2aad4220-d007-4016-ad47-e65b7764e6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-913b9b02-14b4-4e5b-8dc4-6fc8c4bcb012,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-99533752-4c04-4749-91d9-a54914f964b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-1bc6d972-8103-4f85-9aa0-82bf3be81efd,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-3c0e7974-13fd-4540-85f8-e1684a748641,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-14df9f41-56e9-4954-b9c9-40e333714e19,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-c8dc1569-8735-4dfa-8f06-d6295779d4b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-683415813-172.17.0.8-1597680940808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42071,DS-ceb78675-136b-4ac0-ad2c-828548f0b0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-2aad4220-d007-4016-ad47-e65b7764e6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-913b9b02-14b4-4e5b-8dc4-6fc8c4bcb012,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-99533752-4c04-4749-91d9-a54914f964b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-1bc6d972-8103-4f85-9aa0-82bf3be81efd,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-3c0e7974-13fd-4540-85f8-e1684a748641,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-14df9f41-56e9-4954-b9c9-40e333714e19,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-c8dc1569-8735-4dfa-8f06-d6295779d4b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1333072458-172.17.0.8-1597681167260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40153,DS-7f920d27-c824-4ba9-a366-0ab685df3221,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-41f4c917-1760-4425-81c5-24e4c31891b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-989354d2-02a6-4369-86da-fb85e89ba74f,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-afe123c7-f93b-4ac5-a51a-f2b48720f9be,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-661b2280-cdff-4dc0-b3dc-66f1d5b96cff,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-6ed4724c-4b19-4028-a033-9366efd6d8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-5b8c209f-c76c-400c-9dd7-db9dd221a0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-a99c7c8e-4886-4dad-9e82-bfcde04935d4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1333072458-172.17.0.8-1597681167260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40153,DS-7f920d27-c824-4ba9-a366-0ab685df3221,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-41f4c917-1760-4425-81c5-24e4c31891b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-989354d2-02a6-4369-86da-fb85e89ba74f,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-afe123c7-f93b-4ac5-a51a-f2b48720f9be,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-661b2280-cdff-4dc0-b3dc-66f1d5b96cff,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-6ed4724c-4b19-4028-a033-9366efd6d8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-5b8c209f-c76c-400c-9dd7-db9dd221a0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-a99c7c8e-4886-4dad-9e82-bfcde04935d4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1717174208-172.17.0.8-1597681465663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43854,DS-f21b9d0c-7488-4d97-929c-7b0f77d2808c,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-d6313c48-f4b4-43e4-adfc-cdb58c3744a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-896bc54a-39f6-44aa-9713-b9700b87ad1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-7c2af3aa-c11b-43d7-861b-011a02484732,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-f98f5b10-f667-4c8d-857d-83aba5fa1334,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-9cffa924-19b9-4f1b-8523-0c3bfe9904ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-a0207fd2-ad72-426e-ab99-6c3251c595d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-1ad1fc15-db73-4c56-ad4a-025ff48d01fd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1717174208-172.17.0.8-1597681465663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43854,DS-f21b9d0c-7488-4d97-929c-7b0f77d2808c,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-d6313c48-f4b4-43e4-adfc-cdb58c3744a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-896bc54a-39f6-44aa-9713-b9700b87ad1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-7c2af3aa-c11b-43d7-861b-011a02484732,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-f98f5b10-f667-4c8d-857d-83aba5fa1334,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-9cffa924-19b9-4f1b-8523-0c3bfe9904ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-a0207fd2-ad72-426e-ab99-6c3251c595d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-1ad1fc15-db73-4c56-ad4a-025ff48d01fd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1459851354-172.17.0.8-1597681538291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36774,DS-66dbdbed-2b58-41b0-a43d-ec97ec481c50,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-edd68787-f492-4dd0-b68b-3a5a78d3b7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-7f39fe2a-d0b5-4e23-b61e-b52c17de0e06,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-546b4bfb-11f9-4e5d-a5f1-5bd1d881a55b,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-b3578b41-d17d-41c7-b7ad-e2209f9a81d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-e7653e54-69fb-42ca-abd1-86014495dd44,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-83cbabe1-2fc7-4ce9-9acc-b760253ac21b,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-2f8f01e8-112a-4950-a6fa-64651f43bf85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1459851354-172.17.0.8-1597681538291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36774,DS-66dbdbed-2b58-41b0-a43d-ec97ec481c50,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-edd68787-f492-4dd0-b68b-3a5a78d3b7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-7f39fe2a-d0b5-4e23-b61e-b52c17de0e06,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-546b4bfb-11f9-4e5d-a5f1-5bd1d881a55b,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-b3578b41-d17d-41c7-b7ad-e2209f9a81d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-e7653e54-69fb-42ca-abd1-86014495dd44,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-83cbabe1-2fc7-4ce9-9acc-b760253ac21b,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-2f8f01e8-112a-4950-a6fa-64651f43bf85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1132305338-172.17.0.8-1597681650742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40604,DS-045f6fe2-0259-4287-bb6b-9b68caf216c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-ae85c599-b617-4269-a7e3-369f8f8902cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-d2acdebf-c442-46f0-be17-df2170be1059,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-bc73edb9-f528-4345-8f4f-0b9a8713575b,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-a62d38d8-c18b-451c-8d6c-32dc59a1824c,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-189b8a25-caaf-4bc5-a864-3b326e14c6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-9ad263c4-964c-4e48-a6d1-cdb53c026712,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-26982094-711b-4bb1-8a2b-916292587d59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1132305338-172.17.0.8-1597681650742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40604,DS-045f6fe2-0259-4287-bb6b-9b68caf216c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-ae85c599-b617-4269-a7e3-369f8f8902cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-d2acdebf-c442-46f0-be17-df2170be1059,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-bc73edb9-f528-4345-8f4f-0b9a8713575b,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-a62d38d8-c18b-451c-8d6c-32dc59a1824c,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-189b8a25-caaf-4bc5-a864-3b326e14c6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37121,DS-9ad263c4-964c-4e48-a6d1-cdb53c026712,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-26982094-711b-4bb1-8a2b-916292587d59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756621263-172.17.0.8-1597681718521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33366,DS-c8747638-e5dc-45ba-a74a-56d4ed4bd4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-e620da53-f593-4361-9c2b-725fbec0b868,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-48864cc4-1b21-43b6-9589-3f271b8f33be,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-20f3d177-addb-40ed-b53f-93c42fae5ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-59dbbe6f-2204-47b2-8d5d-fa6adcd2c233,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-ef2fffd1-123c-4584-9a25-24c948ada31a,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-9ce82143-f1a7-41b5-a859-7e2888f0b94e,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-32984e7e-8df8-44a3-9433-4a2c36b784ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756621263-172.17.0.8-1597681718521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33366,DS-c8747638-e5dc-45ba-a74a-56d4ed4bd4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-e620da53-f593-4361-9c2b-725fbec0b868,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-48864cc4-1b21-43b6-9589-3f271b8f33be,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-20f3d177-addb-40ed-b53f-93c42fae5ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-59dbbe6f-2204-47b2-8d5d-fa6adcd2c233,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-ef2fffd1-123c-4584-9a25-24c948ada31a,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-9ce82143-f1a7-41b5-a859-7e2888f0b94e,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-32984e7e-8df8-44a3-9433-4a2c36b784ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-708491966-172.17.0.8-1597681760646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42035,DS-d65cac9e-3c24-4c0b-892e-d9cae4a380b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-af8630da-43a0-497d-b64f-ef30b67eb59b,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-55d64686-baa9-46d8-82f0-2ca6f1252348,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-75fd5c80-b102-4efd-bb4e-11afe216bead,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-cd2e4ee1-5f0d-4554-a98b-fb7dbe8d5aca,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-1c514d55-55da-4d9d-b18c-3f9a57bb0a63,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-9a2fa6a3-41c1-4761-a400-75ea776d3bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-309451d9-320b-4719-91e4-0912e66bce73,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-708491966-172.17.0.8-1597681760646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42035,DS-d65cac9e-3c24-4c0b-892e-d9cae4a380b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-af8630da-43a0-497d-b64f-ef30b67eb59b,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-55d64686-baa9-46d8-82f0-2ca6f1252348,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-75fd5c80-b102-4efd-bb4e-11afe216bead,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-cd2e4ee1-5f0d-4554-a98b-fb7dbe8d5aca,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-1c514d55-55da-4d9d-b18c-3f9a57bb0a63,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-9a2fa6a3-41c1-4761-a400-75ea776d3bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-309451d9-320b-4719-91e4-0912e66bce73,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 5757
