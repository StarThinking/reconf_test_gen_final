reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561814606-172.17.0.9-1597464651555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33947,DS-b230deee-ec01-4768-a137-e33d60e4f1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-8cc077ad-21ef-4932-8f15-cdda4ac4a561,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-ee248c9d-8356-4293-862d-d1492e6e9514,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-68db1eb5-7215-462a-8cd6-9f459928fffb,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-203ee8cd-3e5b-4bdc-8de9-80521d7a0f68,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-c1d78e3f-f650-4060-b6ca-db5fb80acbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-d6d956ed-395c-4853-9830-a64547c0f5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-6bc9db9e-3927-4ee2-a124-67c453582af5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561814606-172.17.0.9-1597464651555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33947,DS-b230deee-ec01-4768-a137-e33d60e4f1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-8cc077ad-21ef-4932-8f15-cdda4ac4a561,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-ee248c9d-8356-4293-862d-d1492e6e9514,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-68db1eb5-7215-462a-8cd6-9f459928fffb,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-203ee8cd-3e5b-4bdc-8de9-80521d7a0f68,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-c1d78e3f-f650-4060-b6ca-db5fb80acbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-d6d956ed-395c-4853-9830-a64547c0f5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-6bc9db9e-3927-4ee2-a124-67c453582af5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117604158-172.17.0.9-1597465765909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42681,DS-fa59e56b-fa68-464e-8de3-a565d59c8394,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-d2e72252-3aa0-41d7-95cc-7df021433b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-153a0097-98ee-45f1-af87-5f6d2e752588,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-7204bd59-b207-4930-ac5c-d96fd4db1336,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-edc65795-09fa-419f-94dc-09877b554205,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-0c10fe89-a9f8-4dab-a114-03e853f13428,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-f4ff651d-a518-4b4b-adcc-29a9c91e3a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-331358ef-bc5d-4b7a-ad0f-7e843b34dc16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117604158-172.17.0.9-1597465765909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42681,DS-fa59e56b-fa68-464e-8de3-a565d59c8394,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-d2e72252-3aa0-41d7-95cc-7df021433b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-153a0097-98ee-45f1-af87-5f6d2e752588,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-7204bd59-b207-4930-ac5c-d96fd4db1336,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-edc65795-09fa-419f-94dc-09877b554205,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-0c10fe89-a9f8-4dab-a114-03e853f13428,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-f4ff651d-a518-4b4b-adcc-29a9c91e3a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-331358ef-bc5d-4b7a-ad0f-7e843b34dc16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612228324-172.17.0.9-1597465802508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37870,DS-ecb5bd35-1bb1-4401-a416-f10bbb42d76c,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-04261e6d-85c6-4ee2-8ce3-8c3f4786456f,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-e055ff9f-b2dc-47ff-bd2c-b483d4e3107a,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-17aba5ac-51f8-408d-b696-4ef016f1dcfe,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-bde12b1f-3d28-4e04-b6a6-123959d2665f,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-2036989f-356b-4ca5-80dd-e2922f34b557,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-5a20e45c-d856-4424-b102-02bf1491bb40,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-0d94a199-7493-4854-ba4f-3223d707d07f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612228324-172.17.0.9-1597465802508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37870,DS-ecb5bd35-1bb1-4401-a416-f10bbb42d76c,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-04261e6d-85c6-4ee2-8ce3-8c3f4786456f,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-e055ff9f-b2dc-47ff-bd2c-b483d4e3107a,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-17aba5ac-51f8-408d-b696-4ef016f1dcfe,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-bde12b1f-3d28-4e04-b6a6-123959d2665f,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-2036989f-356b-4ca5-80dd-e2922f34b557,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-5a20e45c-d856-4424-b102-02bf1491bb40,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-0d94a199-7493-4854-ba4f-3223d707d07f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1839166215-172.17.0.9-1597465882938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34583,DS-2f6d4ee3-3be7-4f60-b082-7b61c807d0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-466d9d7f-214f-4c10-86b6-60eb1552a350,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-c7a62bf5-a3ca-4791-a8d5-c17b11e938c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-f225e1e0-3a91-4bb4-9280-23caa6162899,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-bc849c1b-b1a9-4d06-aa8f-d4216e90224b,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-cd6b02a6-ead1-49e7-8409-dd64b36730b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-a8b4d5d5-c1ab-4d28-a6a1-360db22af635,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-95fe688e-231c-4086-9272-27343ba13b8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1839166215-172.17.0.9-1597465882938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34583,DS-2f6d4ee3-3be7-4f60-b082-7b61c807d0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-466d9d7f-214f-4c10-86b6-60eb1552a350,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-c7a62bf5-a3ca-4791-a8d5-c17b11e938c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-f225e1e0-3a91-4bb4-9280-23caa6162899,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-bc849c1b-b1a9-4d06-aa8f-d4216e90224b,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-cd6b02a6-ead1-49e7-8409-dd64b36730b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-a8b4d5d5-c1ab-4d28-a6a1-360db22af635,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-95fe688e-231c-4086-9272-27343ba13b8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1798951252-172.17.0.9-1597466227289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40655,DS-0ee594c4-6dc7-45ca-b78c-56ba1a552b18,DISK], DatanodeInfoWithStorage[127.0.0.1:41658,DS-9dbee30c-645b-49e9-abe9-f1e2a90b85eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-ccb9fbf3-56e0-4b92-88a4-78a8f413427f,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-73b37acf-f996-4031-9653-be5b3eb2b132,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-af2ab9e4-46e9-4df2-9e30-b9a51b9ac912,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-cff5f0d6-e329-40d8-bd51-6b20aecc45bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-1f86d570-b8b8-4e54-816b-3b843aee905a,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-346d40cb-1595-4587-a354-03edef09d616,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1798951252-172.17.0.9-1597466227289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40655,DS-0ee594c4-6dc7-45ca-b78c-56ba1a552b18,DISK], DatanodeInfoWithStorage[127.0.0.1:41658,DS-9dbee30c-645b-49e9-abe9-f1e2a90b85eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-ccb9fbf3-56e0-4b92-88a4-78a8f413427f,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-73b37acf-f996-4031-9653-be5b3eb2b132,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-af2ab9e4-46e9-4df2-9e30-b9a51b9ac912,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-cff5f0d6-e329-40d8-bd51-6b20aecc45bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-1f86d570-b8b8-4e54-816b-3b843aee905a,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-346d40cb-1595-4587-a354-03edef09d616,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1661785144-172.17.0.9-1597466759486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38647,DS-459561cf-76be-451a-b57f-661bc0ba54ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-3d8d9290-5c77-4791-a7fa-11bf02e543a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-39d3142e-bd34-487e-9767-fa70ec249eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-18a1907b-9fba-486b-802c-8eb45cb1c6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-6fc435c7-7875-4190-a025-7756abc833d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-892215d4-59e0-49bb-91a1-65cc55899ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-b1ee957e-f019-4bfa-9a67-65418a9853eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-28b5ff4e-68ab-49da-8f29-890ec0916698,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1661785144-172.17.0.9-1597466759486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38647,DS-459561cf-76be-451a-b57f-661bc0ba54ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-3d8d9290-5c77-4791-a7fa-11bf02e543a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-39d3142e-bd34-487e-9767-fa70ec249eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-18a1907b-9fba-486b-802c-8eb45cb1c6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-6fc435c7-7875-4190-a025-7756abc833d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-892215d4-59e0-49bb-91a1-65cc55899ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-b1ee957e-f019-4bfa-9a67-65418a9853eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-28b5ff4e-68ab-49da-8f29-890ec0916698,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1857719284-172.17.0.9-1597467279020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33784,DS-fe06e0bf-c697-422a-aa15-1844794da268,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-0b728483-44bf-4436-bb34-b48b0d174f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-3beff7e9-93df-40c7-b0e6-db7b061e8962,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-3f6d8058-ef26-4dd0-8ad7-0a6e5fc63b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-869b326e-a985-487e-9d0b-b8ba367685f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-9c4be56b-c78b-46d9-87ce-36209df6c7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-75b46742-cd0f-445e-bb56-0a307c395544,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-8873e44b-a112-4e5f-b8db-49f3aa1715c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1857719284-172.17.0.9-1597467279020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33784,DS-fe06e0bf-c697-422a-aa15-1844794da268,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-0b728483-44bf-4436-bb34-b48b0d174f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-3beff7e9-93df-40c7-b0e6-db7b061e8962,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-3f6d8058-ef26-4dd0-8ad7-0a6e5fc63b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-869b326e-a985-487e-9d0b-b8ba367685f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-9c4be56b-c78b-46d9-87ce-36209df6c7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-75b46742-cd0f-445e-bb56-0a307c395544,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-8873e44b-a112-4e5f-b8db-49f3aa1715c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803045710-172.17.0.9-1597467718537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46821,DS-92370f8d-47e8-477b-affc-5c3989500614,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-d5a513f9-9e36-4b6d-81e9-ad3eb8eb7b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-053651b3-6242-45ad-a167-c75c799b1129,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-8610517a-b381-4595-bdec-dc8c997612ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-71826565-5f42-4fbb-bea1-55243c55e33f,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-0e65ca34-20ee-4594-a2f8-89ab19070b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-7c32b810-41ff-40bd-a289-f790637501a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-115f67dc-3d89-497e-8c4b-aff6316ed82d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803045710-172.17.0.9-1597467718537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46821,DS-92370f8d-47e8-477b-affc-5c3989500614,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-d5a513f9-9e36-4b6d-81e9-ad3eb8eb7b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-053651b3-6242-45ad-a167-c75c799b1129,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-8610517a-b381-4595-bdec-dc8c997612ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-71826565-5f42-4fbb-bea1-55243c55e33f,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-0e65ca34-20ee-4594-a2f8-89ab19070b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-7c32b810-41ff-40bd-a289-f790637501a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-115f67dc-3d89-497e-8c4b-aff6316ed82d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382406228-172.17.0.9-1597467757560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46753,DS-6deefe38-7f11-497c-9617-6ee5de239314,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-d3bfcc3a-d17c-4b0c-9389-786694176353,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-00f710bb-489a-4043-bc07-003d8c90e814,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-924284e5-4700-4e8b-8707-74e5f3a46f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-48922430-99c0-44d2-b320-fbff9742d779,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-59bef5e3-166a-4071-8ec6-da0b081af3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-0f2bd355-d36d-43bd-9977-1ddd26fb6ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-9f57ada6-8b7b-4ba3-996b-2fdbe24ec771,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382406228-172.17.0.9-1597467757560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46753,DS-6deefe38-7f11-497c-9617-6ee5de239314,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-d3bfcc3a-d17c-4b0c-9389-786694176353,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-00f710bb-489a-4043-bc07-003d8c90e814,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-924284e5-4700-4e8b-8707-74e5f3a46f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-48922430-99c0-44d2-b320-fbff9742d779,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-59bef5e3-166a-4071-8ec6-da0b081af3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-0f2bd355-d36d-43bd-9977-1ddd26fb6ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-9f57ada6-8b7b-4ba3-996b-2fdbe24ec771,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571361060-172.17.0.9-1597467865608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39142,DS-63233e67-b96a-4661-9aa7-b658cd58546d,DISK], DatanodeInfoWithStorage[127.0.0.1:46799,DS-cf2cfae5-e6e2-4c2a-8fc4-24c79bc3ede1,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-82789328-f230-4693-9056-2e7ae52e9d36,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-4cd50363-1c18-4010-9e80-529715b1c970,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-86104efd-0d7e-4f96-b284-6c223dfaf3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-7c03bcca-4744-498f-acb3-ff05c2eb2307,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-381d265e-6a9b-47b5-a9b0-19219136c763,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-09b80cfc-285f-46b9-b6c6-2f5a021e1ac7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571361060-172.17.0.9-1597467865608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39142,DS-63233e67-b96a-4661-9aa7-b658cd58546d,DISK], DatanodeInfoWithStorage[127.0.0.1:46799,DS-cf2cfae5-e6e2-4c2a-8fc4-24c79bc3ede1,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-82789328-f230-4693-9056-2e7ae52e9d36,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-4cd50363-1c18-4010-9e80-529715b1c970,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-86104efd-0d7e-4f96-b284-6c223dfaf3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-7c03bcca-4744-498f-acb3-ff05c2eb2307,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-381d265e-6a9b-47b5-a9b0-19219136c763,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-09b80cfc-285f-46b9-b6c6-2f5a021e1ac7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-457195551-172.17.0.9-1597468113787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33154,DS-35a920ab-d801-43dd-a499-83a1c95ee571,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-f8decbee-9654-4107-b935-a9743a2ada32,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-c2179383-f406-41f8-bbce-93c22b8ec97b,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-21250afb-30a4-49d0-bda8-d196515a0ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-b2ca48a8-3129-450c-b813-21294a8f2a89,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-409a7674-4f71-4c87-9166-fc93869defb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-cd83485b-1a0a-4284-a7ec-ba90f363e0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-3abe8f91-9f39-48c6-b3d0-a60023b0fc60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-457195551-172.17.0.9-1597468113787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33154,DS-35a920ab-d801-43dd-a499-83a1c95ee571,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-f8decbee-9654-4107-b935-a9743a2ada32,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-c2179383-f406-41f8-bbce-93c22b8ec97b,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-21250afb-30a4-49d0-bda8-d196515a0ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-b2ca48a8-3129-450c-b813-21294a8f2a89,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-409a7674-4f71-4c87-9166-fc93869defb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-cd83485b-1a0a-4284-a7ec-ba90f363e0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-3abe8f91-9f39-48c6-b3d0-a60023b0fc60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5825
