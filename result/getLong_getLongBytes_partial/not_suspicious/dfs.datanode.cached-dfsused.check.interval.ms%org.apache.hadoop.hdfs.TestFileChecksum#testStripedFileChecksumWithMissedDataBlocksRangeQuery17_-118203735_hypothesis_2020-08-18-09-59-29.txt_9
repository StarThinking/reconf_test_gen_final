reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2003871887-172.17.0.11-1597744787247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43856,DS-8d2f57e0-05ae-43c3-8a72-f180abb775fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-c53b7a07-09eb-4172-9e07-2f4ebc441aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-d298f258-1d35-46f8-b03c-2cd6480fe125,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-3d809a33-d53d-4b7a-b3bc-1a0098414e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-8b91e178-a8e1-4dab-abab-9d04e5f978d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-f1e45831-5e65-498d-8407-63ae51016f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-2e86700e-5693-4b94-8b3a-6d9f6f499d38,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-9ea9045c-4903-4947-9b67-507b36f5c4ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2003871887-172.17.0.11-1597744787247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43856,DS-8d2f57e0-05ae-43c3-8a72-f180abb775fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-c53b7a07-09eb-4172-9e07-2f4ebc441aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-d298f258-1d35-46f8-b03c-2cd6480fe125,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-3d809a33-d53d-4b7a-b3bc-1a0098414e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-8b91e178-a8e1-4dab-abab-9d04e5f978d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-f1e45831-5e65-498d-8407-63ae51016f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-2e86700e-5693-4b94-8b3a-6d9f6f499d38,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-9ea9045c-4903-4947-9b67-507b36f5c4ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-707101119-172.17.0.11-1597745201684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45213,DS-06e917fb-8992-4194-b4d8-344ee28a2271,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-25026836-f512-49fa-9eec-9d5799f1e631,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-14a84513-d877-4ba8-ac62-8aa8d01ce3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-bb16dda9-9f57-47e5-a57f-a8106ae29ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-7b39c910-c9a2-4078-8d33-e8e58fb97fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-de25e162-7fe8-4e71-8b76-597b0ede8203,DISK], DatanodeInfoWithStorage[127.0.0.1:35739,DS-ac3368a0-77f5-4daf-87b2-d6e0c9e3bb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-0039c373-d9e7-417f-992a-18b496c00cbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-707101119-172.17.0.11-1597745201684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45213,DS-06e917fb-8992-4194-b4d8-344ee28a2271,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-25026836-f512-49fa-9eec-9d5799f1e631,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-14a84513-d877-4ba8-ac62-8aa8d01ce3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-bb16dda9-9f57-47e5-a57f-a8106ae29ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-7b39c910-c9a2-4078-8d33-e8e58fb97fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-de25e162-7fe8-4e71-8b76-597b0ede8203,DISK], DatanodeInfoWithStorage[127.0.0.1:35739,DS-ac3368a0-77f5-4daf-87b2-d6e0c9e3bb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-0039c373-d9e7-417f-992a-18b496c00cbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1823716493-172.17.0.11-1597745771666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38518,DS-a401abff-b5d6-40ba-be2f-57fba4237856,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-5667248b-bb1b-48a8-a9a8-14eaf2174d19,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-ed91b617-b381-432b-a1f8-aef390b6113f,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-ddcd0a50-a506-446a-b904-d840854615d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-69470b89-aab9-4a02-ae6c-f203a73619b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-64bff552-f410-442e-a20e-01abd1ac6cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-d35e0ebf-654f-4268-b092-680b0240626a,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-d33e69ea-2884-4d50-849f-b28992a2898e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1823716493-172.17.0.11-1597745771666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38518,DS-a401abff-b5d6-40ba-be2f-57fba4237856,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-5667248b-bb1b-48a8-a9a8-14eaf2174d19,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-ed91b617-b381-432b-a1f8-aef390b6113f,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-ddcd0a50-a506-446a-b904-d840854615d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-69470b89-aab9-4a02-ae6c-f203a73619b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-64bff552-f410-442e-a20e-01abd1ac6cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-d35e0ebf-654f-4268-b092-680b0240626a,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-d33e69ea-2884-4d50-849f-b28992a2898e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1527719311-172.17.0.11-1597746751500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33724,DS-4ff6bcb2-1135-47ed-86fc-6b493818aed7,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-1c9dded3-ec17-4daf-a87f-59b1f298b458,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-7c2cc060-2f73-4901-9df6-a81bf4fccdbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-ddbba6d5-c89d-4dcf-b08c-9402d2c7f5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-139223dc-2827-4dbd-bd19-04d0acc26fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-1e14b476-a815-4343-ac4f-2cb7a4c93216,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-f014313f-5a71-43e9-aa0c-4eb35804511b,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-457d519a-2589-406c-9c95-62bc0cdfea90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1527719311-172.17.0.11-1597746751500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33724,DS-4ff6bcb2-1135-47ed-86fc-6b493818aed7,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-1c9dded3-ec17-4daf-a87f-59b1f298b458,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-7c2cc060-2f73-4901-9df6-a81bf4fccdbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-ddbba6d5-c89d-4dcf-b08c-9402d2c7f5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-139223dc-2827-4dbd-bd19-04d0acc26fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-1e14b476-a815-4343-ac4f-2cb7a4c93216,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-f014313f-5a71-43e9-aa0c-4eb35804511b,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-457d519a-2589-406c-9c95-62bc0cdfea90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1147161465-172.17.0.11-1597747482217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44111,DS-cd92f1f7-732f-4019-83d2-dd91914260ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-04dd3226-7d54-4b5c-8a66-2313c1c38a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-c00fd531-bd56-45d5-abdb-31a6cb52aa00,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-66abdf6c-ef41-4b34-8cd9-7feeb84ee722,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-f6967187-603a-4e95-999d-da0d99066936,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-7a1b7c67-1f9d-4c7c-9509-0531b89a88fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-20ff7b7c-8c33-4515-b70d-1c5d6940c126,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-019a64b5-96d1-4fb7-b157-b748d1980bd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1147161465-172.17.0.11-1597747482217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44111,DS-cd92f1f7-732f-4019-83d2-dd91914260ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-04dd3226-7d54-4b5c-8a66-2313c1c38a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-c00fd531-bd56-45d5-abdb-31a6cb52aa00,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-66abdf6c-ef41-4b34-8cd9-7feeb84ee722,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-f6967187-603a-4e95-999d-da0d99066936,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-7a1b7c67-1f9d-4c7c-9509-0531b89a88fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-20ff7b7c-8c33-4515-b70d-1c5d6940c126,DISK], DatanodeInfoWithStorage[127.0.0.1:37428,DS-019a64b5-96d1-4fb7-b157-b748d1980bd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1113677760-172.17.0.11-1597748235167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39031,DS-098380e2-7dd2-41dc-bca2-13a84d02063d,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-6ad7655e-740d-48c9-a84c-1055a43ca441,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-9543c60d-3a8b-45c5-bbdc-3d8cf219814e,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-15675e8c-3664-49db-b3f2-6dc0c0671bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-a2481e44-1702-44fe-98ee-695e1d4315fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-d7915226-5148-4416-9c5f-c5d08b58b4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-c19c1a06-122c-4561-bb16-7548e873331d,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-253ad6a7-6402-4f1c-8eeb-96ab678a032b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1113677760-172.17.0.11-1597748235167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39031,DS-098380e2-7dd2-41dc-bca2-13a84d02063d,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-6ad7655e-740d-48c9-a84c-1055a43ca441,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-9543c60d-3a8b-45c5-bbdc-3d8cf219814e,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-15675e8c-3664-49db-b3f2-6dc0c0671bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-a2481e44-1702-44fe-98ee-695e1d4315fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-d7915226-5148-4416-9c5f-c5d08b58b4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-c19c1a06-122c-4561-bb16-7548e873331d,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-253ad6a7-6402-4f1c-8eeb-96ab678a032b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1707177748-172.17.0.11-1597748418599:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36839,DS-e8bbe9ef-9718-4010-accc-0c166f6932e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-6aefa47b-2528-41b9-9bcf-b1f2ba171e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-6848de59-fe27-4143-a6c1-d8da7fb9d620,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-f48a5c19-7cbb-41b9-ae26-a94f94a124be,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-f54171cf-378d-4507-a706-5b422756ba43,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-aee8a34f-fdf0-4722-a707-c4d2508075ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-0a195748-778a-4d33-aea4-d22ab7bce104,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-be091a15-b7cd-4fb8-b030-cf3e907af5e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1707177748-172.17.0.11-1597748418599:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36839,DS-e8bbe9ef-9718-4010-accc-0c166f6932e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-6aefa47b-2528-41b9-9bcf-b1f2ba171e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-6848de59-fe27-4143-a6c1-d8da7fb9d620,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-f48a5c19-7cbb-41b9-ae26-a94f94a124be,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-f54171cf-378d-4507-a706-5b422756ba43,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-aee8a34f-fdf0-4722-a707-c4d2508075ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-0a195748-778a-4d33-aea4-d22ab7bce104,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-be091a15-b7cd-4fb8-b030-cf3e907af5e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1182301233-172.17.0.11-1597748660822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37318,DS-271d2bf8-3e35-4e6a-99f8-fffe69e3feda,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-e79a1ed7-fe68-40e9-ad6a-d9089603c9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-f6917445-1647-49ec-b0ac-95c3fbaea09a,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-56a7f95b-da6a-4531-b1f4-b52d1faecb61,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-75525e32-622b-4683-a479-3fed64a706b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-ff9da2a4-ea40-4f61-baa0-9c8640ea17f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-9c933d8e-e34e-4b2f-be0d-05e101a99184,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-416632b9-bce3-48b5-9a3e-e97d37c0461e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1182301233-172.17.0.11-1597748660822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37318,DS-271d2bf8-3e35-4e6a-99f8-fffe69e3feda,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-e79a1ed7-fe68-40e9-ad6a-d9089603c9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-f6917445-1647-49ec-b0ac-95c3fbaea09a,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-56a7f95b-da6a-4531-b1f4-b52d1faecb61,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-75525e32-622b-4683-a479-3fed64a706b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-ff9da2a4-ea40-4f61-baa0-9c8640ea17f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-9c933d8e-e34e-4b2f-be0d-05e101a99184,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-416632b9-bce3-48b5-9a3e-e97d37c0461e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-480871690-172.17.0.11-1597748860475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37995,DS-2e59b108-d9df-4f7f-86ba-ab0b3c55359f,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-036afc05-6756-4264-9dec-a5db160500d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-312120d1-ffa1-49fd-bd75-8fe4892087e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-c86da6ed-aa14-41c0-b6bf-bca5f0cdc7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-6ee45092-3403-4b9c-8356-82b54cac2ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-5010113b-5719-439e-b888-a391f213d841,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-5b6a6dfd-c35f-42b4-8cb0-902f3210fe57,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-c798a0cb-d976-4993-8778-d97a8fc1cca8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-480871690-172.17.0.11-1597748860475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37995,DS-2e59b108-d9df-4f7f-86ba-ab0b3c55359f,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-036afc05-6756-4264-9dec-a5db160500d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-312120d1-ffa1-49fd-bd75-8fe4892087e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-c86da6ed-aa14-41c0-b6bf-bca5f0cdc7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-6ee45092-3403-4b9c-8356-82b54cac2ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-5010113b-5719-439e-b888-a391f213d841,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-5b6a6dfd-c35f-42b4-8cb0-902f3210fe57,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-c798a0cb-d976-4993-8778-d97a8fc1cca8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-422624493-172.17.0.11-1597749602988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43224,DS-9319a6a9-85ef-400c-a9bf-f0c451b3f9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-c4ca4c27-2fcd-411d-ae19-44cdd07de097,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-4910d131-0945-4103-8a43-aebb8eca7a32,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-dade963d-b70c-467e-bc92-e244a73ad3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-bb8e11d0-b27c-4c0a-9166-3e937a816fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-d54d473b-919a-4305-b9d6-31b3bfdd1368,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-ffa1b5a1-1030-4eb6-bf5d-3f4fad53c509,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-c232e389-6ae1-4f6a-a60a-c0ed08041560,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-422624493-172.17.0.11-1597749602988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43224,DS-9319a6a9-85ef-400c-a9bf-f0c451b3f9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-c4ca4c27-2fcd-411d-ae19-44cdd07de097,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-4910d131-0945-4103-8a43-aebb8eca7a32,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-dade963d-b70c-467e-bc92-e244a73ad3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-bb8e11d0-b27c-4c0a-9166-3e937a816fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-d54d473b-919a-4305-b9d6-31b3bfdd1368,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-ffa1b5a1-1030-4eb6-bf5d-3f4fad53c509,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-c232e389-6ae1-4f6a-a60a-c0ed08041560,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-685233872-172.17.0.11-1597750153548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38770,DS-71c7e0f9-da61-4ba6-9b2d-fcd39ffc3f22,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-ae711009-a6b0-4e9f-b902-9ad92822ae0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-c9ec52f1-696e-4746-bf07-872f5f153fec,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-c03dd25c-d92f-499b-8a56-40cc6491eea3,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-c1702b14-ca73-476d-a13b-6c7f379399df,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-802cee43-3893-4070-b144-c33645ea4622,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-b29b8084-71a5-4f8d-bb36-0ab7f8c89208,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-e4bb219d-7591-4459-8801-481c2f129abe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-685233872-172.17.0.11-1597750153548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38770,DS-71c7e0f9-da61-4ba6-9b2d-fcd39ffc3f22,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-ae711009-a6b0-4e9f-b902-9ad92822ae0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-c9ec52f1-696e-4746-bf07-872f5f153fec,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-c03dd25c-d92f-499b-8a56-40cc6491eea3,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-c1702b14-ca73-476d-a13b-6c7f379399df,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-802cee43-3893-4070-b144-c33645ea4622,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-b29b8084-71a5-4f8d-bb36-0ab7f8c89208,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-e4bb219d-7591-4459-8801-481c2f129abe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1521647785-172.17.0.11-1597750220021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43311,DS-2ce57506-b980-49bf-84f3-ac40148b7802,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-a635a264-0ab6-43e1-88ff-7fb5fe978f00,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-0e7dc320-9c59-4b41-b2f4-d3ee7f31fa5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-81df2352-4d16-478a-a4b0-b71cbfd86bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-4267194e-de79-4899-a5e8-7ccf8ec79aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-da1a2728-5ee7-4fe7-a2a6-59df689c93dd,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-da4b2f56-3b09-4cec-82e2-b195ec3d39cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-16615e11-cc5c-4fe5-af59-3d362d20cb5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1521647785-172.17.0.11-1597750220021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43311,DS-2ce57506-b980-49bf-84f3-ac40148b7802,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-a635a264-0ab6-43e1-88ff-7fb5fe978f00,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-0e7dc320-9c59-4b41-b2f4-d3ee7f31fa5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-81df2352-4d16-478a-a4b0-b71cbfd86bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-4267194e-de79-4899-a5e8-7ccf8ec79aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-da1a2728-5ee7-4fe7-a2a6-59df689c93dd,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-da4b2f56-3b09-4cec-82e2-b195ec3d39cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-16615e11-cc5c-4fe5-af59-3d362d20cb5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5546
