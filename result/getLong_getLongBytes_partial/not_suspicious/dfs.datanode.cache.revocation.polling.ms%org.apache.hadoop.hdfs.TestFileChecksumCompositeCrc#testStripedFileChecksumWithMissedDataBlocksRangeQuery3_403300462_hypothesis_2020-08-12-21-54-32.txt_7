reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892329954-172.17.0.21-1597269585637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33483,DS-cebb50a7-6850-44cd-bba0-1b33fdb68914,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-c1e1b189-0d47-4b81-a47b-bfdf979f0f82,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-8bdb36ae-970b-4162-b1e0-0313a5ad3d95,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-c436385a-211f-4a01-a82c-1a34918c96dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-593faa55-96fe-49be-93f6-61b742ec7ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-b2d486ca-2211-4922-9f8e-9fc36e93378b,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-c91e3443-8549-43f2-8e5a-679539204366,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-cae81b02-0af5-4b27-b3a1-dad12cda5abb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892329954-172.17.0.21-1597269585637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33483,DS-cebb50a7-6850-44cd-bba0-1b33fdb68914,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-c1e1b189-0d47-4b81-a47b-bfdf979f0f82,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-8bdb36ae-970b-4162-b1e0-0313a5ad3d95,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-c436385a-211f-4a01-a82c-1a34918c96dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-593faa55-96fe-49be-93f6-61b742ec7ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-b2d486ca-2211-4922-9f8e-9fc36e93378b,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-c91e3443-8549-43f2-8e5a-679539204366,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-cae81b02-0af5-4b27-b3a1-dad12cda5abb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1249236455-172.17.0.21-1597269817094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45125,DS-7072e5d6-ee50-4ae9-a2d0-f652931e1793,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-d0af7adf-4ede-4a1b-82ca-b04a927dbe58,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-c7998c68-5900-4e8c-9418-32a5a36ed465,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-187189df-dd46-4b6d-aaa1-1b72605e7c37,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-f0438e67-97b0-435a-a311-38b05bb1275f,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-9686ee93-4bad-4489-8901-4ad37a905c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-3f0afd9d-0371-419a-a481-20b4a17423f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-c85b9771-3843-4e73-970b-a3f40f0b4593,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1249236455-172.17.0.21-1597269817094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45125,DS-7072e5d6-ee50-4ae9-a2d0-f652931e1793,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-d0af7adf-4ede-4a1b-82ca-b04a927dbe58,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-c7998c68-5900-4e8c-9418-32a5a36ed465,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-187189df-dd46-4b6d-aaa1-1b72605e7c37,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-f0438e67-97b0-435a-a311-38b05bb1275f,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-9686ee93-4bad-4489-8901-4ad37a905c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-3f0afd9d-0371-419a-a481-20b4a17423f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-c85b9771-3843-4e73-970b-a3f40f0b4593,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-798650493-172.17.0.21-1597270139402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38690,DS-2dfa8dd2-1146-4d4e-a6d0-640dd8ebfa96,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-75e3f885-6115-4be5-9e11-a14041298fda,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-d1c38df9-1072-4c3e-a238-514549f9406a,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-929984b8-6825-43d7-a45c-473c7c9782d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-4f6db1ea-899e-43dd-8cae-6c4d4fd8561e,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-af75b5cd-2af9-4f82-acb1-741a50d6fcbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-b48557a6-200a-4704-8bd5-a716f2313b83,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-f5200f89-c07d-4c88-9f56-8d552c4e4f77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-798650493-172.17.0.21-1597270139402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38690,DS-2dfa8dd2-1146-4d4e-a6d0-640dd8ebfa96,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-75e3f885-6115-4be5-9e11-a14041298fda,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-d1c38df9-1072-4c3e-a238-514549f9406a,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-929984b8-6825-43d7-a45c-473c7c9782d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-4f6db1ea-899e-43dd-8cae-6c4d4fd8561e,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-af75b5cd-2af9-4f82-acb1-741a50d6fcbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-b48557a6-200a-4704-8bd5-a716f2313b83,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-f5200f89-c07d-4c88-9f56-8d552c4e4f77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-331309918-172.17.0.21-1597270487864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36660,DS-b4112535-fb40-417c-875f-3459afba1c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-fd971bba-09af-429a-b98a-af4404f16a22,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-f7994aca-62a1-4b2e-ac89-34c2a4281b36,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-07efa2f0-1272-4b5e-b15c-adc93bb29223,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-4651c8e3-81de-4bd0-9dad-7e227cef4ede,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-133041bb-92f7-4266-8839-c57e0de593a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-91532f7f-15b9-455c-9f7c-7c5c3367d0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-ed9fdf3f-a82c-4db6-ab19-520c450dde62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-331309918-172.17.0.21-1597270487864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36660,DS-b4112535-fb40-417c-875f-3459afba1c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-fd971bba-09af-429a-b98a-af4404f16a22,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-f7994aca-62a1-4b2e-ac89-34c2a4281b36,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-07efa2f0-1272-4b5e-b15c-adc93bb29223,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-4651c8e3-81de-4bd0-9dad-7e227cef4ede,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-133041bb-92f7-4266-8839-c57e0de593a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-91532f7f-15b9-455c-9f7c-7c5c3367d0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-ed9fdf3f-a82c-4db6-ab19-520c450dde62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1606738048-172.17.0.21-1597271071475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42422,DS-8f98fb74-811b-4256-9578-2029aa0520f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-afdf8d34-9199-4926-b649-c614941a32a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-53dcc01f-b311-4739-a612-bfd9d467e752,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-0b87148b-4917-453d-933b-54586e18f192,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-37fb17cb-a1fc-40b4-b612-047a4305c84f,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-24496b78-1ae7-4dbf-9ee1-55cf6a822074,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-7e9a073a-6ba0-43b2-8dfc-7a4b40683f29,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-4b5db5bf-3bfb-4dc2-a880-ccf2048f37e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1606738048-172.17.0.21-1597271071475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42422,DS-8f98fb74-811b-4256-9578-2029aa0520f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-afdf8d34-9199-4926-b649-c614941a32a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-53dcc01f-b311-4739-a612-bfd9d467e752,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-0b87148b-4917-453d-933b-54586e18f192,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-37fb17cb-a1fc-40b4-b612-047a4305c84f,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-24496b78-1ae7-4dbf-9ee1-55cf6a822074,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-7e9a073a-6ba0-43b2-8dfc-7a4b40683f29,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-4b5db5bf-3bfb-4dc2-a880-ccf2048f37e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-773291749-172.17.0.21-1597271108169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33004,DS-7543ede9-7c1b-4a40-9126-d4d4f06c3091,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-f40a49d7-4042-402c-a2c5-70659e4e0967,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-470096b9-ae71-4310-b68c-be8bb4d3b4da,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-fd8ef030-9fc9-4519-b0fb-9efc3c07e61d,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-f09be824-6943-4a7d-884b-433c6dca46dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-cab413b5-9520-421a-8eff-54f98c03ff60,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-5f168aac-09af-4090-956c-b1a8c2b3869f,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-56cb1a47-73a3-4bdd-8f09-2b9cd660319d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-773291749-172.17.0.21-1597271108169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33004,DS-7543ede9-7c1b-4a40-9126-d4d4f06c3091,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-f40a49d7-4042-402c-a2c5-70659e4e0967,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-470096b9-ae71-4310-b68c-be8bb4d3b4da,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-fd8ef030-9fc9-4519-b0fb-9efc3c07e61d,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-f09be824-6943-4a7d-884b-433c6dca46dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-cab413b5-9520-421a-8eff-54f98c03ff60,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-5f168aac-09af-4090-956c-b1a8c2b3869f,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-56cb1a47-73a3-4bdd-8f09-2b9cd660319d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1635401218-172.17.0.21-1597271188434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46062,DS-15124162-7709-464e-bca0-012b9a24815d,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-9a7afd0b-778c-4ef6-b825-4b2c5710341e,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-586fdabc-970f-47d1-9359-74da58156f89,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-d8a10528-fc80-4f0c-b5c1-406cfe3e0af2,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-acd76abb-b762-47c7-9305-783cf3a90afd,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-c7cb26bb-1b22-430a-b114-a9ea20f2b512,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-e2981bfb-471b-49b9-be91-06d649c9653e,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-00808de5-b373-4b1c-9209-7130ff474db0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1635401218-172.17.0.21-1597271188434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46062,DS-15124162-7709-464e-bca0-012b9a24815d,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-9a7afd0b-778c-4ef6-b825-4b2c5710341e,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-586fdabc-970f-47d1-9359-74da58156f89,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-d8a10528-fc80-4f0c-b5c1-406cfe3e0af2,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-acd76abb-b762-47c7-9305-783cf3a90afd,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-c7cb26bb-1b22-430a-b114-a9ea20f2b512,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-e2981bfb-471b-49b9-be91-06d649c9653e,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-00808de5-b373-4b1c-9209-7130ff474db0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568567963-172.17.0.21-1597271458481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41919,DS-538ab3cc-2687-4e96-927f-f6e013959ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-925f9304-2489-4749-8cfa-e17d53a48374,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-6bb0a5fd-bf9c-4e4d-987c-6787235375c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-70988b91-bc74-4505-b24d-39f37467dcfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-ee8e1565-2efe-48ff-85e2-01fd22543248,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-f246aec4-94e3-4602-a044-45a0a8fc4bac,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-bf0abb0e-89cd-448e-9ad6-9d573ca282cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-3f50ad64-7616-4361-a494-cb50fb062263,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568567963-172.17.0.21-1597271458481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41919,DS-538ab3cc-2687-4e96-927f-f6e013959ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-925f9304-2489-4749-8cfa-e17d53a48374,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-6bb0a5fd-bf9c-4e4d-987c-6787235375c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-70988b91-bc74-4505-b24d-39f37467dcfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-ee8e1565-2efe-48ff-85e2-01fd22543248,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-f246aec4-94e3-4602-a044-45a0a8fc4bac,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-bf0abb0e-89cd-448e-9ad6-9d573ca282cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-3f50ad64-7616-4361-a494-cb50fb062263,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108606433-172.17.0.21-1597271530092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35263,DS-963d6b46-48d1-4ca6-ab84-51b019f437ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-c5a71646-3f63-47fb-9967-59775248f882,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-941f02e2-63d9-43fc-9c17-4e2b1b64dfdf,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-a005e31d-68eb-4ee2-be4d-647fb7b058e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-64097450-bebb-4033-b3c7-a9b71cb2bc95,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-8e47f35c-9008-4e65-bf24-14bc2bd66f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43476,DS-71daa1e2-92f7-444e-a942-89cec16e9ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-f88c76b5-d53c-4866-beeb-630c15b45c85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108606433-172.17.0.21-1597271530092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35263,DS-963d6b46-48d1-4ca6-ab84-51b019f437ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-c5a71646-3f63-47fb-9967-59775248f882,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-941f02e2-63d9-43fc-9c17-4e2b1b64dfdf,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-a005e31d-68eb-4ee2-be4d-647fb7b058e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-64097450-bebb-4033-b3c7-a9b71cb2bc95,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-8e47f35c-9008-4e65-bf24-14bc2bd66f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43476,DS-71daa1e2-92f7-444e-a942-89cec16e9ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-f88c76b5-d53c-4866-beeb-630c15b45c85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1239172531-172.17.0.21-1597271604782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43836,DS-5a7d5295-1024-4476-ade6-d4edcb462422,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-52b83838-3f54-4993-8609-2b056e26a838,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-66c80cfc-c5c9-4de5-ade2-81fb8f1912b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-56e7f93c-eb25-401e-b90d-7f3c2ff7173c,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-3f54e348-1851-4041-8a5e-b4a2e578cac6,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-bba9563e-b18e-4423-b110-44cd21b6f308,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-adf3b41e-b98f-480f-8eb6-8a83f8bd8cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-b75cfa20-2491-485e-ba8e-5bd7629a6d3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1239172531-172.17.0.21-1597271604782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43836,DS-5a7d5295-1024-4476-ade6-d4edcb462422,DISK], DatanodeInfoWithStorage[127.0.0.1:33539,DS-52b83838-3f54-4993-8609-2b056e26a838,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-66c80cfc-c5c9-4de5-ade2-81fb8f1912b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-56e7f93c-eb25-401e-b90d-7f3c2ff7173c,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-3f54e348-1851-4041-8a5e-b4a2e578cac6,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-bba9563e-b18e-4423-b110-44cd21b6f308,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-adf3b41e-b98f-480f-8eb6-8a83f8bd8cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-b75cfa20-2491-485e-ba8e-5bd7629a6d3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-841079368-172.17.0.21-1597272152642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34693,DS-96734352-a536-40ee-9149-796cc8c18a83,DISK], DatanodeInfoWithStorage[127.0.0.1:42858,DS-52b7185a-ce93-4f07-887d-e1e964584fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-5b8c37e9-bd94-4bbe-920f-76507e4d4f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-7c609e44-d7fa-4849-a26a-2b5a78d72985,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-a45f654f-ff33-45ce-b15a-daf79b95f69f,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-bbf50d93-f097-4cf0-ab8d-21cb491c0213,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-bd43fb68-af7a-47a8-8f25-d5c57744de05,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-addb61f8-f6e0-40f3-806a-89bd2ee9caca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-841079368-172.17.0.21-1597272152642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34693,DS-96734352-a536-40ee-9149-796cc8c18a83,DISK], DatanodeInfoWithStorage[127.0.0.1:42858,DS-52b7185a-ce93-4f07-887d-e1e964584fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-5b8c37e9-bd94-4bbe-920f-76507e4d4f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-7c609e44-d7fa-4849-a26a-2b5a78d72985,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-a45f654f-ff33-45ce-b15a-daf79b95f69f,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-bbf50d93-f097-4cf0-ab8d-21cb491c0213,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-bd43fb68-af7a-47a8-8f25-d5c57744de05,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-addb61f8-f6e0-40f3-806a-89bd2ee9caca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-688103099-172.17.0.21-1597272189894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36042,DS-1f85e4bd-1dc9-45c5-84a9-70d8412a09bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-e42028f5-fc4b-44d1-b992-6fb39882e5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-ddab99e3-7e4b-477f-9454-850d342208e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-f7e8b5fe-9cee-43e7-aee3-aeef5c33baf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-6fc97355-249c-48dd-9eac-b0f8b9423062,DISK], DatanodeInfoWithStorage[127.0.0.1:38183,DS-fe942797-6cae-4dc7-a09a-0da730d285ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-a770a6da-c10d-4812-938d-ddefb5e13bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-4f38967a-027f-46f9-b29a-4cb1cd68cb99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-688103099-172.17.0.21-1597272189894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36042,DS-1f85e4bd-1dc9-45c5-84a9-70d8412a09bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-e42028f5-fc4b-44d1-b992-6fb39882e5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-ddab99e3-7e4b-477f-9454-850d342208e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-f7e8b5fe-9cee-43e7-aee3-aeef5c33baf7,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-6fc97355-249c-48dd-9eac-b0f8b9423062,DISK], DatanodeInfoWithStorage[127.0.0.1:38183,DS-fe942797-6cae-4dc7-a09a-0da730d285ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-a770a6da-c10d-4812-938d-ddefb5e13bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-4f38967a-027f-46f9-b29a-4cb1cd68cb99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929388654-172.17.0.21-1597272335054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46017,DS-79fd002e-93e6-4d29-8487-9b1ac1e847b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-11801b26-f002-4fec-8f4f-13b863651b39,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-d09c4567-47d8-45e5-a902-9b422bff2287,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-45de7dc5-5a8c-4ef8-b455-7e94c96ee48f,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-5fe7fc38-05e6-448f-965f-1ff014f5d835,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-4f1f5af5-e298-44f6-9832-25cbb22e0ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-34231287-1775-4a43-a224-393540645dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-ebdd2798-35a2-4f42-a26e-e9f3856d5745,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929388654-172.17.0.21-1597272335054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46017,DS-79fd002e-93e6-4d29-8487-9b1ac1e847b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-11801b26-f002-4fec-8f4f-13b863651b39,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-d09c4567-47d8-45e5-a902-9b422bff2287,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-45de7dc5-5a8c-4ef8-b455-7e94c96ee48f,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-5fe7fc38-05e6-448f-965f-1ff014f5d835,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-4f1f5af5-e298-44f6-9832-25cbb22e0ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-34231287-1775-4a43-a224-393540645dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-ebdd2798-35a2-4f42-a26e-e9f3856d5745,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1067279877-172.17.0.21-1597272701081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45877,DS-8908d04f-aeb0-492f-bb2a-e9d392dbf15d,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-fd594288-a768-4e9a-8d34-b6dbc8c56009,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-37a4f164-6fcb-4383-b683-f2ba17480b45,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-2bb37b36-4ad7-4bde-a540-a79ae58c69c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-b8a13e75-89a8-4ecb-9f1b-aee4c0e0abc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-158858e0-a55e-40e0-906e-133f032047e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-70a774cd-49f3-4ff2-ac18-abfa33196da6,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-d3e8d4fe-78f6-43c8-bfec-78f3a6101fb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1067279877-172.17.0.21-1597272701081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45877,DS-8908d04f-aeb0-492f-bb2a-e9d392dbf15d,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-fd594288-a768-4e9a-8d34-b6dbc8c56009,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-37a4f164-6fcb-4383-b683-f2ba17480b45,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-2bb37b36-4ad7-4bde-a540-a79ae58c69c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-b8a13e75-89a8-4ecb-9f1b-aee4c0e0abc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-158858e0-a55e-40e0-906e-133f032047e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-70a774cd-49f3-4ff2-ac18-abfa33196da6,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-d3e8d4fe-78f6-43c8-bfec-78f3a6101fb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246268054-172.17.0.21-1597273218190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34612,DS-1dcc0c24-8363-44ff-ba43-46cd3034c21d,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-11a757a2-9aa8-4b14-ac39-c21a0317df73,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-fb4087ac-acf8-4a76-a13f-033f08479510,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-9e809c85-9ba6-4e26-ab00-c611facec692,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-b81196fe-e04d-457c-8a4b-eb53ff0a3c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-5317f028-bc77-421f-bd45-52c6d330d7df,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-d5fbd664-6a2c-4b14-b864-e6dfa98c60cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-939f22d2-f966-43ff-a17a-cee69c5322fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246268054-172.17.0.21-1597273218190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34612,DS-1dcc0c24-8363-44ff-ba43-46cd3034c21d,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-11a757a2-9aa8-4b14-ac39-c21a0317df73,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-fb4087ac-acf8-4a76-a13f-033f08479510,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-9e809c85-9ba6-4e26-ab00-c611facec692,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-b81196fe-e04d-457c-8a4b-eb53ff0a3c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-5317f028-bc77-421f-bd45-52c6d330d7df,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-d5fbd664-6a2c-4b14-b864-e6dfa98c60cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-939f22d2-f966-43ff-a17a-cee69c5322fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1715102619-172.17.0.21-1597273382517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40265,DS-9797fcf0-6330-4f63-aed6-f6146e07ca84,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-5cd77e56-6b85-4ac3-9744-084d15591fab,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-44dace1e-104f-4381-94de-c6daa50f2c70,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-c54dd01c-1923-4c44-9a6e-09d3526e364d,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-b6511f46-91f4-48fd-a631-0340cd1c595a,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-a9e8a6eb-bd34-4fb7-86be-b5f4122dfd4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-76cb249e-5ceb-4b45-9f7d-e99972bc99cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-452ffe90-0628-438f-8eee-acfca2e88ec6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1715102619-172.17.0.21-1597273382517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40265,DS-9797fcf0-6330-4f63-aed6-f6146e07ca84,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-5cd77e56-6b85-4ac3-9744-084d15591fab,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-44dace1e-104f-4381-94de-c6daa50f2c70,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-c54dd01c-1923-4c44-9a6e-09d3526e364d,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-b6511f46-91f4-48fd-a631-0340cd1c595a,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-a9e8a6eb-bd34-4fb7-86be-b5f4122dfd4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-76cb249e-5ceb-4b45-9f7d-e99972bc99cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-452ffe90-0628-438f-8eee-acfca2e88ec6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049157613-172.17.0.21-1597273714465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42184,DS-6546f1ea-322a-4fde-b058-e4cfa7655269,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-315fd76c-7f03-4644-84c8-d219dc80d743,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-4fe358f8-597d-4832-92ae-69d4c0f4e106,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-b690818d-3a9c-4027-b718-28974886500c,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-b10be125-5ae1-416e-9f12-b723b168d6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-df8c1748-cd1b-49cf-9de1-3a01fa3cfc44,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-be29f542-36ab-4ecb-8290-d0d3f7bc5921,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-5a9e86c0-7578-4c93-8ed5-542e10994221,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049157613-172.17.0.21-1597273714465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42184,DS-6546f1ea-322a-4fde-b058-e4cfa7655269,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-315fd76c-7f03-4644-84c8-d219dc80d743,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-4fe358f8-597d-4832-92ae-69d4c0f4e106,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-b690818d-3a9c-4027-b718-28974886500c,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-b10be125-5ae1-416e-9f12-b723b168d6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-df8c1748-cd1b-49cf-9de1-3a01fa3cfc44,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-be29f542-36ab-4ecb-8290-d0d3f7bc5921,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-5a9e86c0-7578-4c93-8ed5-542e10994221,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1547401286-172.17.0.21-1597274125833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45418,DS-557a0568-b48b-4775-b0eb-c4d7b8b1c060,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-59309e3d-cd27-4bd4-8069-dedc4899e9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-0e044e63-175b-4893-8409-b5b5a7dc42d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-328d9518-8df9-40d6-adab-0a6fe415170e,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-ca9d24a5-e634-483a-87c4-769c0f65d947,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-59845aa1-df81-42ba-886c-5cbefc816f34,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-92795590-6c82-477f-8137-46d86d73be62,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-227d54ed-a9e4-4f2a-9a0c-59bcf3ffd73b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1547401286-172.17.0.21-1597274125833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45418,DS-557a0568-b48b-4775-b0eb-c4d7b8b1c060,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-59309e3d-cd27-4bd4-8069-dedc4899e9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-0e044e63-175b-4893-8409-b5b5a7dc42d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-328d9518-8df9-40d6-adab-0a6fe415170e,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-ca9d24a5-e634-483a-87c4-769c0f65d947,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-59845aa1-df81-42ba-886c-5cbefc816f34,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-92795590-6c82-477f-8137-46d86d73be62,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-227d54ed-a9e4-4f2a-9a0c-59bcf3ffd73b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1981482494-172.17.0.21-1597274243591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43290,DS-8f2b50e2-f69c-427e-a0c9-fb274ac9b314,DISK], DatanodeInfoWithStorage[127.0.0.1:38901,DS-eead9e1e-5f02-4348-b95b-e08f2b7a8d88,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-19391f1a-2862-4a77-90e5-28f4fcd91a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-86592eea-332c-4b89-857c-29fd07d95a75,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-b4d67e10-060e-4c98-a169-6b5aa7d357ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-80406832-f420-43a3-9e5f-1d2ab4ed06ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-74f55ea8-5585-4bc2-bfee-d3b5685406aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-51ca3348-cdd1-49d0-88ef-2ba976d8af10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1981482494-172.17.0.21-1597274243591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43290,DS-8f2b50e2-f69c-427e-a0c9-fb274ac9b314,DISK], DatanodeInfoWithStorage[127.0.0.1:38901,DS-eead9e1e-5f02-4348-b95b-e08f2b7a8d88,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-19391f1a-2862-4a77-90e5-28f4fcd91a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-86592eea-332c-4b89-857c-29fd07d95a75,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-b4d67e10-060e-4c98-a169-6b5aa7d357ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-80406832-f420-43a3-9e5f-1d2ab4ed06ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-74f55ea8-5585-4bc2-bfee-d3b5685406aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-51ca3348-cdd1-49d0-88ef-2ba976d8af10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-841334044-172.17.0.21-1597275082187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33097,DS-81730355-26a8-4db3-9d86-74989fe3f62a,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-8f473249-1dd5-425d-b766-fbf8c5ba9cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-f66cdd1c-35b3-4cd1-84c3-c5b2f712c793,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-73988326-22c0-4522-99a3-3b156e6a5ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-10e441a2-5b19-4674-86ee-e384276a4df3,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-4ec4d816-b228-4f4c-8653-a5460dd2e5de,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-eec0f0a3-3b34-4f5d-ad20-bd460b054512,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-4df69ffb-e769-49a4-97b8-a0fe5e908937,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-841334044-172.17.0.21-1597275082187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33097,DS-81730355-26a8-4db3-9d86-74989fe3f62a,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-8f473249-1dd5-425d-b766-fbf8c5ba9cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-f66cdd1c-35b3-4cd1-84c3-c5b2f712c793,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-73988326-22c0-4522-99a3-3b156e6a5ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-10e441a2-5b19-4674-86ee-e384276a4df3,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-4ec4d816-b228-4f4c-8653-a5460dd2e5de,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-eec0f0a3-3b34-4f5d-ad20-bd460b054512,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-4df69ffb-e769-49a4-97b8-a0fe5e908937,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5875
