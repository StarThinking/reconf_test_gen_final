reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1991059136-172.17.0.8-1597363102639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42480,DS-8aa0c939-676d-4490-9c8e-5d2747b5fb37,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-b1ea3f38-025f-422f-ac85-4fce9d796ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-ad67fbd0-cdeb-4ff8-a02c-b89979a20b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-a509dc42-c914-4163-8248-6ded18685ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-df2da9ee-4fda-4a8e-a24a-5eed0ba826b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-4cf1e70f-5492-4e58-a95c-02e0f5136247,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-c72ea939-a598-4ed2-8225-2fe264fc1454,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-6ba4ce20-4d23-40a2-9cf1-03e1aac1e2b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1991059136-172.17.0.8-1597363102639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42480,DS-8aa0c939-676d-4490-9c8e-5d2747b5fb37,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-b1ea3f38-025f-422f-ac85-4fce9d796ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-ad67fbd0-cdeb-4ff8-a02c-b89979a20b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-a509dc42-c914-4163-8248-6ded18685ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-df2da9ee-4fda-4a8e-a24a-5eed0ba826b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-4cf1e70f-5492-4e58-a95c-02e0f5136247,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-c72ea939-a598-4ed2-8225-2fe264fc1454,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-6ba4ce20-4d23-40a2-9cf1-03e1aac1e2b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-624877959-172.17.0.8-1597363281494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39961,DS-d3e98b44-d406-4011-822f-f96f61dbf74d,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-d6b98d4b-5abf-4e56-b2c0-aa89cd511873,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-aa3e7289-1477-4293-9ef8-555a7f59cb06,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-6cbe111d-4496-43b3-89bf-d95f329edd51,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-48f4c2e7-81ec-44cd-841a-0cf74945891c,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-cfa0276f-fb8e-46a9-b7b6-a1123580c182,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-0b2b43ee-935a-40d8-b89f-9d8d3bbff303,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-229aaf11-7beb-4769-83dd-69f348cdeadc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-624877959-172.17.0.8-1597363281494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39961,DS-d3e98b44-d406-4011-822f-f96f61dbf74d,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-d6b98d4b-5abf-4e56-b2c0-aa89cd511873,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-aa3e7289-1477-4293-9ef8-555a7f59cb06,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-6cbe111d-4496-43b3-89bf-d95f329edd51,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-48f4c2e7-81ec-44cd-841a-0cf74945891c,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-cfa0276f-fb8e-46a9-b7b6-a1123580c182,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-0b2b43ee-935a-40d8-b89f-9d8d3bbff303,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-229aaf11-7beb-4769-83dd-69f348cdeadc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1070509959-172.17.0.8-1597363752378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39881,DS-fe3a8e98-1928-41ee-9127-451554385224,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-46723838-9c73-4d35-91b4-d084d8a7580f,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-46a51c18-6ad1-49c8-863a-26e446a5b938,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-cdb6096b-d080-4a09-9a83-b6e75c9a4db7,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-251fa815-df20-4f47-ae2c-f015d78514c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-d510d722-13df-4717-8785-545c066e3ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-ba823961-ce81-457f-9c52-5da0a0cb47f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-3da9fae4-eb85-45cb-819a-2d54769f657b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1070509959-172.17.0.8-1597363752378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39881,DS-fe3a8e98-1928-41ee-9127-451554385224,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-46723838-9c73-4d35-91b4-d084d8a7580f,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-46a51c18-6ad1-49c8-863a-26e446a5b938,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-cdb6096b-d080-4a09-9a83-b6e75c9a4db7,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-251fa815-df20-4f47-ae2c-f015d78514c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-d510d722-13df-4717-8785-545c066e3ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-ba823961-ce81-457f-9c52-5da0a0cb47f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-3da9fae4-eb85-45cb-819a-2d54769f657b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-166325232-172.17.0.8-1597364267325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33082,DS-03992c48-7792-4904-b9e5-f1b8433623da,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-44a8ed10-c1b0-445e-8435-e8714b9b1219,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-31d73818-0007-4236-b2d9-97e1161ec362,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-a63e410e-1af7-4c2c-873d-ddfd6e6f663a,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-dd1d5fd4-e6e7-40f0-a065-62b46ae0e7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-3358fc23-1234-4d2f-90e2-9722135b5a49,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-0985ad18-8436-4a0f-83d3-4cdfa7414349,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-00c3755b-ffca-462e-8a34-61f09c6f2bfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-166325232-172.17.0.8-1597364267325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33082,DS-03992c48-7792-4904-b9e5-f1b8433623da,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-44a8ed10-c1b0-445e-8435-e8714b9b1219,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-31d73818-0007-4236-b2d9-97e1161ec362,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-a63e410e-1af7-4c2c-873d-ddfd6e6f663a,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-dd1d5fd4-e6e7-40f0-a065-62b46ae0e7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-3358fc23-1234-4d2f-90e2-9722135b5a49,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-0985ad18-8436-4a0f-83d3-4cdfa7414349,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-00c3755b-ffca-462e-8a34-61f09c6f2bfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381974244-172.17.0.8-1597364382700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41523,DS-22ff74bf-191d-47cf-821d-b8ca7083f29e,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-c3c29323-1436-444d-895c-fa8b04514a36,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-488c854e-a3a8-4393-92b5-7aef6a114e57,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-e67a70ce-16f1-4441-a7c9-f8e2fb64a586,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-bd4c1ddd-750e-4a45-bd6a-408729a75515,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-ec30baba-3369-4e7e-800b-4d94bf6bd742,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-085a53d9-2ddd-4e0a-aedd-46221d2ce088,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-e3b9e907-380f-4d9f-8937-44054fb7bf95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381974244-172.17.0.8-1597364382700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41523,DS-22ff74bf-191d-47cf-821d-b8ca7083f29e,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-c3c29323-1436-444d-895c-fa8b04514a36,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-488c854e-a3a8-4393-92b5-7aef6a114e57,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-e67a70ce-16f1-4441-a7c9-f8e2fb64a586,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-bd4c1ddd-750e-4a45-bd6a-408729a75515,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-ec30baba-3369-4e7e-800b-4d94bf6bd742,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-085a53d9-2ddd-4e0a-aedd-46221d2ce088,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-e3b9e907-380f-4d9f-8937-44054fb7bf95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1660888808-172.17.0.8-1597364495028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43408,DS-daba088a-6566-4678-9f5f-3bad05eb48ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-51eedd9a-bd95-4948-ba35-cfbf5a5efa62,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-1340d13d-343a-449b-ac4e-e906f0759ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:35303,DS-f8b8c601-e25e-47ab-920e-ff7e66b63d84,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-75b511dd-9485-42cb-a604-5f9b082970da,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-a8b0abd2-9055-4c40-8118-f0ec2f25afe3,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-fb90460c-540f-49ea-9d67-b754493d6b22,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-c5abacd3-c1ca-4277-809a-c5dc76cfd49c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1660888808-172.17.0.8-1597364495028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43408,DS-daba088a-6566-4678-9f5f-3bad05eb48ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-51eedd9a-bd95-4948-ba35-cfbf5a5efa62,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-1340d13d-343a-449b-ac4e-e906f0759ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:35303,DS-f8b8c601-e25e-47ab-920e-ff7e66b63d84,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-75b511dd-9485-42cb-a604-5f9b082970da,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-a8b0abd2-9055-4c40-8118-f0ec2f25afe3,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-fb90460c-540f-49ea-9d67-b754493d6b22,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-c5abacd3-c1ca-4277-809a-c5dc76cfd49c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325810510-172.17.0.8-1597364536240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36568,DS-d7fd9540-34a3-44bc-98c6-1fe56a92e6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39406,DS-41468bb8-a4cf-475f-b8a3-c0e1905258c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-1633bfb9-14b3-42df-a0d3-36475ac82d77,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-17786a0a-5599-4e68-aa95-79cd41b7ed54,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-c2b0d626-592f-4694-8e52-43d5112b22ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-6a77ca27-0049-4665-91fc-3e502a4003ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-cd3ffbfc-131e-4b84-bbde-4776c7fe8002,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-4f10da81-762a-4773-b7d5-c79f7c21a7a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325810510-172.17.0.8-1597364536240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36568,DS-d7fd9540-34a3-44bc-98c6-1fe56a92e6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39406,DS-41468bb8-a4cf-475f-b8a3-c0e1905258c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-1633bfb9-14b3-42df-a0d3-36475ac82d77,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-17786a0a-5599-4e68-aa95-79cd41b7ed54,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-c2b0d626-592f-4694-8e52-43d5112b22ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-6a77ca27-0049-4665-91fc-3e502a4003ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-cd3ffbfc-131e-4b84-bbde-4776c7fe8002,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-4f10da81-762a-4773-b7d5-c79f7c21a7a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-783879405-172.17.0.8-1597364686729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44637,DS-12eb0eb4-d2bb-46d9-a739-e58797654457,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-c19d44d7-4297-44fe-a7ec-f6c369f7d559,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-e68f0b23-fcea-40c1-b64c-ce619687a721,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-538d7a1c-d220-4aff-b95e-acec13476b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-6834a423-80fd-4db2-985e-c8eadd90ad77,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-08f27afc-de13-4f94-91c9-c63344ca163c,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-79f6530a-4534-4f75-8be0-e891e37a0559,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-9bc37bfe-c8a1-4748-be7d-f467db5634cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-783879405-172.17.0.8-1597364686729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44637,DS-12eb0eb4-d2bb-46d9-a739-e58797654457,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-c19d44d7-4297-44fe-a7ec-f6c369f7d559,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-e68f0b23-fcea-40c1-b64c-ce619687a721,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-538d7a1c-d220-4aff-b95e-acec13476b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-6834a423-80fd-4db2-985e-c8eadd90ad77,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-08f27afc-de13-4f94-91c9-c63344ca163c,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-79f6530a-4534-4f75-8be0-e891e37a0559,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-9bc37bfe-c8a1-4748-be7d-f467db5634cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514382256-172.17.0.8-1597364961893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33088,DS-470c6cdd-77fb-4932-9344-250d660852fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-d5a7f78e-9616-44e3-bf30-eda44696d2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-bebc7962-af33-42e0-8428-ad1c881ee32c,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-13db6691-91d3-473f-bcd1-f9cafa44e37c,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-e3efa514-405b-4319-82d2-be5d80f99589,DISK], DatanodeInfoWithStorage[127.0.0.1:40927,DS-8930d2f0-beb8-484c-bb60-1494d8b39d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-c9ff29f2-c399-4a05-950f-05dd0da505a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-5b155420-b299-4bfd-929b-35d20758eb1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514382256-172.17.0.8-1597364961893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33088,DS-470c6cdd-77fb-4932-9344-250d660852fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-d5a7f78e-9616-44e3-bf30-eda44696d2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-bebc7962-af33-42e0-8428-ad1c881ee32c,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-13db6691-91d3-473f-bcd1-f9cafa44e37c,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-e3efa514-405b-4319-82d2-be5d80f99589,DISK], DatanodeInfoWithStorage[127.0.0.1:40927,DS-8930d2f0-beb8-484c-bb60-1494d8b39d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-c9ff29f2-c399-4a05-950f-05dd0da505a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-5b155420-b299-4bfd-929b-35d20758eb1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-688924271-172.17.0.8-1597366219505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39570,DS-983786e0-f9d7-4264-ba64-bc664737950f,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-23b58f3a-1530-4118-b4b4-0ee622acf4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-04adb616-1bbc-483c-8f23-3d2523609019,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-e0ca651d-9514-4c37-8dcc-32cb2376cbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-422c62df-4689-4eaa-8b10-1c75610dab46,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-209f380f-a897-4717-bba1-c33832a0cbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-b264e00e-769f-4ecd-b30c-63c83f48f5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-57c598b2-abcf-4957-b878-42a49158bcde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-688924271-172.17.0.8-1597366219505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39570,DS-983786e0-f9d7-4264-ba64-bc664737950f,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-23b58f3a-1530-4118-b4b4-0ee622acf4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-04adb616-1bbc-483c-8f23-3d2523609019,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-e0ca651d-9514-4c37-8dcc-32cb2376cbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-422c62df-4689-4eaa-8b10-1c75610dab46,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-209f380f-a897-4717-bba1-c33832a0cbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-b264e00e-769f-4ecd-b30c-63c83f48f5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-57c598b2-abcf-4957-b878-42a49158bcde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1994520663-172.17.0.8-1597366297026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45691,DS-f30ed228-2cc7-4989-93d1-de6a9da0d974,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-720973f0-7f9c-4d27-b353-49689960bdbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-b24d7001-92ab-436b-8a8f-0a20155820b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-95f88b99-73db-46d2-b7c0-e0e3491b175f,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-0f0ca03c-9be3-4248-818e-aa3def05506f,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-4ae3737e-9248-42ab-87c8-9986c795a5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-feab1aea-fba9-45ea-9d71-b18a374507f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-477d7559-c907-44d1-8311-4e46738d9a1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1994520663-172.17.0.8-1597366297026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45691,DS-f30ed228-2cc7-4989-93d1-de6a9da0d974,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-720973f0-7f9c-4d27-b353-49689960bdbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-b24d7001-92ab-436b-8a8f-0a20155820b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-95f88b99-73db-46d2-b7c0-e0e3491b175f,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-0f0ca03c-9be3-4248-818e-aa3def05506f,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-4ae3737e-9248-42ab-87c8-9986c795a5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-feab1aea-fba9-45ea-9d71-b18a374507f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-477d7559-c907-44d1-8311-4e46738d9a1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1838518265-172.17.0.8-1597366564839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36556,DS-cfb5676b-6c61-4186-8640-8d1629c7d174,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-9304c0f7-3628-4688-af9a-e47d3e68935a,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-34d5cde5-c01c-40a0-b0c0-b7789972865b,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-363d5b64-5a82-445c-9f8e-7e0f8dceea0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-098c082f-c095-4a78-a7c1-7a4f319e5601,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-e13eb27d-3b7d-4416-aed8-7733577a00db,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-bed743c1-f573-422d-bc57-8b91da493e40,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-a5abadb4-2b32-46e3-8f12-5166ca28908b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1838518265-172.17.0.8-1597366564839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36556,DS-cfb5676b-6c61-4186-8640-8d1629c7d174,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-9304c0f7-3628-4688-af9a-e47d3e68935a,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-34d5cde5-c01c-40a0-b0c0-b7789972865b,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-363d5b64-5a82-445c-9f8e-7e0f8dceea0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-098c082f-c095-4a78-a7c1-7a4f319e5601,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-e13eb27d-3b7d-4416-aed8-7733577a00db,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-bed743c1-f573-422d-bc57-8b91da493e40,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-a5abadb4-2b32-46e3-8f12-5166ca28908b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997190420-172.17.0.8-1597367765747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45710,DS-c181ab4b-acd7-4b86-96fa-a6dbdfab32f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-cf76f539-e951-4f36-9607-178ce2c14e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-17fa1255-8816-44f9-9787-ed73db9b456a,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-e24e978d-c43e-4995-84b6-aa1b6ca56c92,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-373a4a3c-43d1-45f3-8d3e-df065d7d489b,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-5389f356-b705-4e3c-93e9-6caa33c330bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-50fdcc09-e976-42d9-b2ed-35863ace5537,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-40d5f487-ce05-482e-9758-69e740ad99cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997190420-172.17.0.8-1597367765747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45710,DS-c181ab4b-acd7-4b86-96fa-a6dbdfab32f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-cf76f539-e951-4f36-9607-178ce2c14e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-17fa1255-8816-44f9-9787-ed73db9b456a,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-e24e978d-c43e-4995-84b6-aa1b6ca56c92,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-373a4a3c-43d1-45f3-8d3e-df065d7d489b,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-5389f356-b705-4e3c-93e9-6caa33c330bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-50fdcc09-e976-42d9-b2ed-35863ace5537,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-40d5f487-ce05-482e-9758-69e740ad99cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-333544109-172.17.0.8-1597367846019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38497,DS-1a09f33d-d641-4060-80e6-775d304b129e,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-6a6d3c7c-a9d0-418b-8c28-7440d18a6e72,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-60a8d415-95b3-4a52-859b-ef3deecef3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-65822de9-8d00-4bce-88f1-68ebc2057191,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-5be06732-0d5b-4ed4-a1ab-c95a4e71523e,DISK], DatanodeInfoWithStorage[127.0.0.1:44550,DS-fb46498d-18f1-4d1e-be67-9996ac61305b,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-08d1ed47-23a0-4912-81b6-9ac589de9b40,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-1ae60ac7-90c6-4fff-a731-6f010e86f741,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-333544109-172.17.0.8-1597367846019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38497,DS-1a09f33d-d641-4060-80e6-775d304b129e,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-6a6d3c7c-a9d0-418b-8c28-7440d18a6e72,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-60a8d415-95b3-4a52-859b-ef3deecef3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-65822de9-8d00-4bce-88f1-68ebc2057191,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-5be06732-0d5b-4ed4-a1ab-c95a4e71523e,DISK], DatanodeInfoWithStorage[127.0.0.1:44550,DS-fb46498d-18f1-4d1e-be67-9996ac61305b,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-08d1ed47-23a0-4912-81b6-9ac589de9b40,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-1ae60ac7-90c6-4fff-a731-6f010e86f741,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184155213-172.17.0.8-1597367955210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42046,DS-edd452ed-c366-42a8-bf61-048526eec3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-9ed00612-15c0-415f-afdb-94d3dabfe1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-a50c3df8-b189-4dce-b134-56ef498eb0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-d27fb830-9fef-4599-9fa9-4424d62aff7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-b53bd845-e359-459f-97eb-7fdbed66993d,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-77fdb48d-41bc-44d5-a975-034273fcd019,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-db5d4415-8ad0-45d9-93f9-f5dba10a0dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-164a4b20-6f99-404d-aa1e-40a29086abe9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184155213-172.17.0.8-1597367955210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42046,DS-edd452ed-c366-42a8-bf61-048526eec3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-9ed00612-15c0-415f-afdb-94d3dabfe1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-a50c3df8-b189-4dce-b134-56ef498eb0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-d27fb830-9fef-4599-9fa9-4424d62aff7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-b53bd845-e359-459f-97eb-7fdbed66993d,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-77fdb48d-41bc-44d5-a975-034273fcd019,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-db5d4415-8ad0-45d9-93f9-f5dba10a0dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-164a4b20-6f99-404d-aa1e-40a29086abe9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1978543378-172.17.0.8-1597368227923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35080,DS-093fa4a7-8897-4c40-bd97-2f527adfa163,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-73613ae9-4fcb-40d4-ba6f-b5dc21bcd48d,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-66fd2d3c-313a-4bd1-bfa5-7956bdd30a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-7808bd64-a79c-4d08-b2b8-6afce9920537,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-f2d3e0c0-ad06-4d75-9f77-0bcf9a7a196e,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-c8fa1303-a360-407f-96a1-5433e3ba4981,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-00fdca41-d448-4515-925a-6e43f1ac35e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-67b8cf2e-1574-45f5-bcc4-b8419d7b5832,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1978543378-172.17.0.8-1597368227923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35080,DS-093fa4a7-8897-4c40-bd97-2f527adfa163,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-73613ae9-4fcb-40d4-ba6f-b5dc21bcd48d,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-66fd2d3c-313a-4bd1-bfa5-7956bdd30a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-7808bd64-a79c-4d08-b2b8-6afce9920537,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-f2d3e0c0-ad06-4d75-9f77-0bcf9a7a196e,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-c8fa1303-a360-407f-96a1-5433e3ba4981,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-00fdca41-d448-4515-925a-6e43f1ac35e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-67b8cf2e-1574-45f5-bcc4-b8419d7b5832,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034183459-172.17.0.8-1597368358983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33349,DS-84e3095c-b8a4-48ee-b67e-1eacd41a9e22,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-95a9c6b0-a928-46c1-82e4-fd125af055bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-5a48e7ca-7932-4373-9ea7-4b2e5ce7d83e,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-955b546f-fe32-42d2-b53f-6cc75fd7038e,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-099464ae-6ea7-4c44-9186-ac67643d8292,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-b7dff1c7-2416-4710-ad0f-a5ae73f6bc93,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-e14c41eb-077b-4028-b212-d2c1f38a3c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-5c271c32-e02e-4ee3-9998-9259fa38500a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034183459-172.17.0.8-1597368358983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33349,DS-84e3095c-b8a4-48ee-b67e-1eacd41a9e22,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-95a9c6b0-a928-46c1-82e4-fd125af055bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-5a48e7ca-7932-4373-9ea7-4b2e5ce7d83e,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-955b546f-fe32-42d2-b53f-6cc75fd7038e,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-099464ae-6ea7-4c44-9186-ac67643d8292,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-b7dff1c7-2416-4710-ad0f-a5ae73f6bc93,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-e14c41eb-077b-4028-b212-d2c1f38a3c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-5c271c32-e02e-4ee3-9998-9259fa38500a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 10
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1023511720-172.17.0.8-1597368440531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37359,DS-fe0872b8-f44c-42f3-8673-a3025243841e,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-259437ab-c0c7-4156-8509-3a55d6fdcebe,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-d1ef0e6e-fe6e-4678-a05c-18d277a82499,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-b54e7c61-c32b-49bf-9bbf-6434a2614f38,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-42082431-80b7-45d2-885f-8704eb533fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-d8e85430-7370-44bc-b12f-7149eb228460,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-50ae2c75-19c9-4b4a-acb7-cc1c2027dc60,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-df7d7c3d-bbfd-407f-ab1a-a606809fc688,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1023511720-172.17.0.8-1597368440531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37359,DS-fe0872b8-f44c-42f3-8673-a3025243841e,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-259437ab-c0c7-4156-8509-3a55d6fdcebe,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-d1ef0e6e-fe6e-4678-a05c-18d277a82499,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-b54e7c61-c32b-49bf-9bbf-6434a2614f38,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-42082431-80b7-45d2-885f-8704eb533fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-d8e85430-7370-44bc-b12f-7149eb228460,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-50ae2c75-19c9-4b4a-acb7-cc1c2027dc60,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-df7d7c3d-bbfd-407f-ab1a-a606809fc688,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5817
