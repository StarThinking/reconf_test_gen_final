reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1975201602-172.17.0.9-1597735749609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46058,DS-f322009e-f9db-4ade-97c3-d9527a997a79,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-716a1ffb-5688-4c18-bde0-e88afccecbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-b18e1ec4-ddea-4102-9b5a-a77dc056985a,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-cb7d2f72-fd8b-4ac7-8158-042795d8403a,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-da19a611-5642-49a5-90e4-03bbdfd78141,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-cc3bd39e-1550-4afb-bc85-af6596aab88a,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-28edeb81-4151-4983-941d-c07e88f6678d,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-80486f29-04aa-4d8b-b6ed-3aaf1d3c031d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1975201602-172.17.0.9-1597735749609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46058,DS-f322009e-f9db-4ade-97c3-d9527a997a79,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-716a1ffb-5688-4c18-bde0-e88afccecbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-b18e1ec4-ddea-4102-9b5a-a77dc056985a,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-cb7d2f72-fd8b-4ac7-8158-042795d8403a,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-da19a611-5642-49a5-90e4-03bbdfd78141,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-cc3bd39e-1550-4afb-bc85-af6596aab88a,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-28edeb81-4151-4983-941d-c07e88f6678d,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-80486f29-04aa-4d8b-b6ed-3aaf1d3c031d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1876511118-172.17.0.9-1597735807846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33462,DS-8728afef-40be-4fd9-a1fb-91c62ec963d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-617ae231-6ae9-49ee-89d1-927cf9e426fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-cc50fbfa-284a-40c5-8b16-4c821de7c269,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-5d353c05-a311-4b18-9ee1-92e161c0bc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-dbbc476f-4a98-4b99-b1cf-27485de7f403,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-cbb6f9db-05f8-4519-8d92-db22746a9ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-ce4386c2-c505-4d42-8d05-98ebee631b36,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-3abaeed0-f6b6-4cbe-804b-7d41ac15caa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1876511118-172.17.0.9-1597735807846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33462,DS-8728afef-40be-4fd9-a1fb-91c62ec963d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-617ae231-6ae9-49ee-89d1-927cf9e426fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-cc50fbfa-284a-40c5-8b16-4c821de7c269,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-5d353c05-a311-4b18-9ee1-92e161c0bc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-dbbc476f-4a98-4b99-b1cf-27485de7f403,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-cbb6f9db-05f8-4519-8d92-db22746a9ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-ce4386c2-c505-4d42-8d05-98ebee631b36,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-3abaeed0-f6b6-4cbe-804b-7d41ac15caa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1302710926-172.17.0.9-1597735941521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45378,DS-dd39b378-b169-4042-8ba0-6ef53df31fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-1b23b15d-059e-442a-873c-27403df2d9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-76b3f02a-2fc4-46d4-bfc3-9293b30de263,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-3f6d6e5b-2a75-4c85-a59b-90ed2730a6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-08a38fc3-b5f3-422d-8a8f-fcd074661b56,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-79d5907f-1842-4fb1-b9b0-cc59950a5ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-70048451-1299-49a4-a737-929f30da1fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-34be0dec-5dc2-457e-916d-984c855827c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1302710926-172.17.0.9-1597735941521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45378,DS-dd39b378-b169-4042-8ba0-6ef53df31fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-1b23b15d-059e-442a-873c-27403df2d9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-76b3f02a-2fc4-46d4-bfc3-9293b30de263,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-3f6d6e5b-2a75-4c85-a59b-90ed2730a6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-08a38fc3-b5f3-422d-8a8f-fcd074661b56,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-79d5907f-1842-4fb1-b9b0-cc59950a5ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-70048451-1299-49a4-a737-929f30da1fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-34be0dec-5dc2-457e-916d-984c855827c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1958796680-172.17.0.9-1597735984532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39586,DS-5266329c-59fa-45f1-80fc-ecf21107d9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-be0948e5-9ac3-43d7-a56f-989f1541703d,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-1e5c92e8-953c-49a7-ba3b-03e9e945f6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-594ec1e2-f9ad-40cd-ae10-28e61d452832,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-0c4ec695-21f4-479a-aae5-30e0948a3914,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-38d1e42d-6903-44f1-b268-ce49c8d5c90f,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-1e293b24-cb45-4c33-8fbb-38611f26bd51,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-3fbafb62-419e-46ff-b973-27c8fb711210,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1958796680-172.17.0.9-1597735984532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39586,DS-5266329c-59fa-45f1-80fc-ecf21107d9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-be0948e5-9ac3-43d7-a56f-989f1541703d,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-1e5c92e8-953c-49a7-ba3b-03e9e945f6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-594ec1e2-f9ad-40cd-ae10-28e61d452832,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-0c4ec695-21f4-479a-aae5-30e0948a3914,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-38d1e42d-6903-44f1-b268-ce49c8d5c90f,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-1e293b24-cb45-4c33-8fbb-38611f26bd51,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-3fbafb62-419e-46ff-b973-27c8fb711210,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1898746445-172.17.0.9-1597736034125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40178,DS-9dd73f16-c853-4c30-ba79-a81caacb52f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-b4ad1b5a-786e-4724-a3bb-0bb71955a623,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-56c5d442-a430-4788-bffa-6ca6c543adba,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-a2864053-8fd2-4c48-899d-1b455d05c3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-7ae1ff43-af54-4b90-a460-6ab318ca03c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-68514315-2b92-4ad5-80cf-2730acce3ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-5161629e-14d8-481f-abc5-e96919b590dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-f2bee87a-84cc-4bbc-af6d-07368a772e1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1898746445-172.17.0.9-1597736034125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40178,DS-9dd73f16-c853-4c30-ba79-a81caacb52f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-b4ad1b5a-786e-4724-a3bb-0bb71955a623,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-56c5d442-a430-4788-bffa-6ca6c543adba,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-a2864053-8fd2-4c48-899d-1b455d05c3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-7ae1ff43-af54-4b90-a460-6ab318ca03c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-68514315-2b92-4ad5-80cf-2730acce3ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-5161629e-14d8-481f-abc5-e96919b590dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-f2bee87a-84cc-4bbc-af6d-07368a772e1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509869696-172.17.0.9-1597736470097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39095,DS-9ce5c519-1eff-44c0-a16b-6dc354b2a37b,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-c56f5ea3-2d24-4b76-afcc-94aaa2f4f278,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-cd4fe1df-9f60-4d54-98d7-9c3eb8d6fd46,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-f7af7acd-77a6-4bae-8116-47a0d3313408,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-8bce8f95-319c-45a2-9a6c-2ae4e041d7df,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-900551a7-95a7-472e-94c9-3cac4f26fb13,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-3990e5b0-f1a6-4c27-bad1-e725b5c95bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42149,DS-dcca8bd3-2c0a-443f-b771-d062539286bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509869696-172.17.0.9-1597736470097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39095,DS-9ce5c519-1eff-44c0-a16b-6dc354b2a37b,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-c56f5ea3-2d24-4b76-afcc-94aaa2f4f278,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-cd4fe1df-9f60-4d54-98d7-9c3eb8d6fd46,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-f7af7acd-77a6-4bae-8116-47a0d3313408,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-8bce8f95-319c-45a2-9a6c-2ae4e041d7df,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-900551a7-95a7-472e-94c9-3cac4f26fb13,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-3990e5b0-f1a6-4c27-bad1-e725b5c95bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42149,DS-dcca8bd3-2c0a-443f-b771-d062539286bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-236604384-172.17.0.9-1597736520935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38595,DS-f8045f09-7e7d-487b-8622-dc1023d0a11d,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-48b6eca1-16dc-4580-ab42-b4ed32cc2819,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-b9108977-448b-4b74-af16-41fa7640bfd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-ff03ba36-addc-4004-bba6-6df67ee8ab0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-d53c1f78-b0f8-465e-ae2a-43642cc0bf88,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-fe40d27a-2840-41b6-91eb-7d1034834dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-ca630bb8-1266-4e2a-9b7f-77ff1e5fa1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-0d8e07de-530b-4ec6-aa8e-3c8bf122be99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-236604384-172.17.0.9-1597736520935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38595,DS-f8045f09-7e7d-487b-8622-dc1023d0a11d,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-48b6eca1-16dc-4580-ab42-b4ed32cc2819,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-b9108977-448b-4b74-af16-41fa7640bfd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-ff03ba36-addc-4004-bba6-6df67ee8ab0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-d53c1f78-b0f8-465e-ae2a-43642cc0bf88,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-fe40d27a-2840-41b6-91eb-7d1034834dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-ca630bb8-1266-4e2a-9b7f-77ff1e5fa1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-0d8e07de-530b-4ec6-aa8e-3c8bf122be99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-414694414-172.17.0.9-1597736620515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36994,DS-8ed800bd-fd68-4a4e-8bdb-aee2435e930e,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-38658a11-9dcc-431b-b085-3a936e3090ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-c7bde0f4-f01b-4177-a24d-529356d3df2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-00e25252-1693-469e-9d74-80d828292957,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-cbf9eedb-5c5c-4109-9dc2-bb80a4a03355,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-b7728ce3-9981-448a-8529-ce1567ec952a,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-588b6cad-94de-446e-9d0d-3d38b8f64700,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-b99c25e5-c9f0-40a2-9362-7d7aaf0f62ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-414694414-172.17.0.9-1597736620515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36994,DS-8ed800bd-fd68-4a4e-8bdb-aee2435e930e,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-38658a11-9dcc-431b-b085-3a936e3090ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-c7bde0f4-f01b-4177-a24d-529356d3df2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-00e25252-1693-469e-9d74-80d828292957,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-cbf9eedb-5c5c-4109-9dc2-bb80a4a03355,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-b7728ce3-9981-448a-8529-ce1567ec952a,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-588b6cad-94de-446e-9d0d-3d38b8f64700,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-b99c25e5-c9f0-40a2-9362-7d7aaf0f62ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052620520-172.17.0.9-1597736669178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39471,DS-62b8d932-ea82-4a05-9098-16decc3bdb60,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-e0649153-f120-4514-bc2b-6570896f8ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-4eef588d-55d3-4b88-a1b6-7ab65c7e4cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-7a24677b-b20e-4586-a61f-241f6a3aa106,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-87bffc0f-a02d-45d2-9954-2bd7d6e06fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-2c8d68c2-d6fc-4d4f-8b66-a0597abf619e,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-b467cb11-c5a9-45c3-95d5-f4d4acd35e02,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-b062d79b-30e7-4da6-8a78-49dfdd8a7e5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052620520-172.17.0.9-1597736669178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39471,DS-62b8d932-ea82-4a05-9098-16decc3bdb60,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-e0649153-f120-4514-bc2b-6570896f8ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-4eef588d-55d3-4b88-a1b6-7ab65c7e4cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-7a24677b-b20e-4586-a61f-241f6a3aa106,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-87bffc0f-a02d-45d2-9954-2bd7d6e06fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-2c8d68c2-d6fc-4d4f-8b66-a0597abf619e,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-b467cb11-c5a9-45c3-95d5-f4d4acd35e02,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-b062d79b-30e7-4da6-8a78-49dfdd8a7e5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1826972327-172.17.0.9-1597736718257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34603,DS-6aba8b7e-aea9-4a84-bba9-3269364b3756,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-3c45e1c9-2270-4546-af0a-4cc02c974ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-8e70b560-4a13-4f29-8c14-6d81d5f0a290,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-4f336db3-5f0f-4aa3-ac17-399dca75bff8,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-a83c799d-09d9-4ff1-863f-7d7ae16e3335,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-465f8ee2-d453-403d-a68e-79b59142584c,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-8d475217-ef95-4bbc-9659-8ff503530464,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-34c91a68-64be-448c-89df-17b3a6821993,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1826972327-172.17.0.9-1597736718257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34603,DS-6aba8b7e-aea9-4a84-bba9-3269364b3756,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-3c45e1c9-2270-4546-af0a-4cc02c974ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-8e70b560-4a13-4f29-8c14-6d81d5f0a290,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-4f336db3-5f0f-4aa3-ac17-399dca75bff8,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-a83c799d-09d9-4ff1-863f-7d7ae16e3335,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-465f8ee2-d453-403d-a68e-79b59142584c,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-8d475217-ef95-4bbc-9659-8ff503530464,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-34c91a68-64be-448c-89df-17b3a6821993,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-725967837-172.17.0.9-1597737054576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41003,DS-deb05779-e5f3-4ae7-bdf9-c39b3c1ec61a,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-8dc0193a-465d-4c58-ab54-2bd00eeb5e27,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-1306728e-2cc7-452d-accd-6ed8b379fb52,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-16d12139-2dba-4ae9-93a3-7bbad761ad66,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-24632533-1d23-49ea-9a64-7ed8e4276340,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-8023bf6b-3936-423b-b768-1932f7aaff15,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-51ff56e6-44ff-4143-81df-70ac8137598d,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-a307a624-a9e0-4713-8970-1b31f6562257,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-725967837-172.17.0.9-1597737054576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41003,DS-deb05779-e5f3-4ae7-bdf9-c39b3c1ec61a,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-8dc0193a-465d-4c58-ab54-2bd00eeb5e27,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-1306728e-2cc7-452d-accd-6ed8b379fb52,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-16d12139-2dba-4ae9-93a3-7bbad761ad66,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-24632533-1d23-49ea-9a64-7ed8e4276340,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-8023bf6b-3936-423b-b768-1932f7aaff15,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-51ff56e6-44ff-4143-81df-70ac8137598d,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-a307a624-a9e0-4713-8970-1b31f6562257,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1601841117-172.17.0.9-1597737102080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37495,DS-42161e30-d696-4bd7-8c9f-f4c5609798fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-3790de4f-e6c6-4819-a8bd-79d7dfa2371e,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-053a3dbc-0f13-4323-b13b-21636f029413,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-b33fb4a2-b111-4283-b995-50a49e4516f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-6c512add-3de5-4902-b920-0babf82b0c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-82c8dcb6-f8dd-469d-98f0-53589df161de,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-38bf854e-fb1f-4c96-906e-f1ffb8150727,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-3d74af4f-25f3-4263-bdd5-ec705da0a8df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1601841117-172.17.0.9-1597737102080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37495,DS-42161e30-d696-4bd7-8c9f-f4c5609798fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-3790de4f-e6c6-4819-a8bd-79d7dfa2371e,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-053a3dbc-0f13-4323-b13b-21636f029413,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-b33fb4a2-b111-4283-b995-50a49e4516f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-6c512add-3de5-4902-b920-0babf82b0c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-82c8dcb6-f8dd-469d-98f0-53589df161de,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-38bf854e-fb1f-4c96-906e-f1ffb8150727,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-3d74af4f-25f3-4263-bdd5-ec705da0a8df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780278924-172.17.0.9-1597737160404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37359,DS-1660c8b1-b563-4174-b7fa-7930d774bffd,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-8f0185c9-e22b-47e7-a4fa-31f0220f27c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-12ac2e6f-51e3-4898-b20f-adeca615d180,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-43d8813c-7a60-4dfa-b003-47b92e2dba1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-39a5b09e-d6af-481d-b22a-982e59ff7203,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-f6e878b8-ad28-420f-9fe3-98e3f4684044,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-db08daeb-88ac-4799-b22f-638ebf06c70f,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-b439a646-69bd-403d-9756-6f5297629444,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780278924-172.17.0.9-1597737160404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37359,DS-1660c8b1-b563-4174-b7fa-7930d774bffd,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-8f0185c9-e22b-47e7-a4fa-31f0220f27c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-12ac2e6f-51e3-4898-b20f-adeca615d180,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-43d8813c-7a60-4dfa-b003-47b92e2dba1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-39a5b09e-d6af-481d-b22a-982e59ff7203,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-f6e878b8-ad28-420f-9fe3-98e3f4684044,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-db08daeb-88ac-4799-b22f-638ebf06c70f,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-b439a646-69bd-403d-9756-6f5297629444,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553097937-172.17.0.9-1597737285661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42715,DS-5a9cea3d-86f1-45d5-a960-b89cfaaff0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-1f73a988-4c4f-4a70-8339-79e08e6c7fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-d8e040f1-1469-4320-bc3a-9f15f7f1a620,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-305dd055-af19-4b87-82c8-2e72397690f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-24ec1d0e-f696-4f07-9c55-449b9fdaa8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34767,DS-e1ddf622-8e00-4c8a-8ba3-ac117773b35c,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-d4e7398c-52c4-479b-a5aa-7847ffb937eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-1ac05d32-5e56-4ed1-87ba-cccf783fff86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553097937-172.17.0.9-1597737285661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42715,DS-5a9cea3d-86f1-45d5-a960-b89cfaaff0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-1f73a988-4c4f-4a70-8339-79e08e6c7fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-d8e040f1-1469-4320-bc3a-9f15f7f1a620,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-305dd055-af19-4b87-82c8-2e72397690f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-24ec1d0e-f696-4f07-9c55-449b9fdaa8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34767,DS-e1ddf622-8e00-4c8a-8ba3-ac117773b35c,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-d4e7398c-52c4-479b-a5aa-7847ffb937eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-1ac05d32-5e56-4ed1-87ba-cccf783fff86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-231207716-172.17.0.9-1597737376971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36336,DS-298a3de9-d70c-4dfc-a712-0fcab6fe5e04,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-cb246d61-db46-49fd-9616-a1d16b915685,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-8c105494-e2c4-4a2b-9c19-01a478d620a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-5271dd5a-2050-4ea2-b20b-d8fab2e8b840,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-7f8a6e12-951b-42be-a0b5-7b088a8d33f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-16d6005d-62b7-4fcb-962f-eb2e074e0873,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-177fb272-8988-48f2-9e41-f9a2710186f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-2f100ad9-7362-4a9e-bb17-87551a6ac323,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-231207716-172.17.0.9-1597737376971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36336,DS-298a3de9-d70c-4dfc-a712-0fcab6fe5e04,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-cb246d61-db46-49fd-9616-a1d16b915685,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-8c105494-e2c4-4a2b-9c19-01a478d620a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-5271dd5a-2050-4ea2-b20b-d8fab2e8b840,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-7f8a6e12-951b-42be-a0b5-7b088a8d33f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-16d6005d-62b7-4fcb-962f-eb2e074e0873,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-177fb272-8988-48f2-9e41-f9a2710186f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-2f100ad9-7362-4a9e-bb17-87551a6ac323,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2113971081-172.17.0.9-1597737692689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38646,DS-89ba9942-7075-49fd-80a5-62794049759c,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-2b2daf3a-5f2d-4350-8680-fc5cc4878786,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-455d78c9-51bd-4d68-ba9e-249004ac2331,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-2015dc38-6526-44d1-a0bc-e15630df84b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-1133dc01-bb6f-40ff-ba78-85576c57ae32,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-7c092a89-1f13-4586-ae24-9f4febef34b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-68d50dd0-5b6f-41a3-8a72-1729992415f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-7bd6afec-be2f-4704-aa6a-264c7e872e92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2113971081-172.17.0.9-1597737692689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38646,DS-89ba9942-7075-49fd-80a5-62794049759c,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-2b2daf3a-5f2d-4350-8680-fc5cc4878786,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-455d78c9-51bd-4d68-ba9e-249004ac2331,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-2015dc38-6526-44d1-a0bc-e15630df84b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-1133dc01-bb6f-40ff-ba78-85576c57ae32,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-7c092a89-1f13-4586-ae24-9f4febef34b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-68d50dd0-5b6f-41a3-8a72-1729992415f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-7bd6afec-be2f-4704-aa6a-264c7e872e92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396878641-172.17.0.9-1597737965871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36735,DS-8f675f31-3ce6-402e-851f-9e316664e923,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-6840031d-dfd5-4275-bd4d-fca335ea88d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-8338f92a-30c1-4b30-9942-7f64014caa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-eb30bcb7-804e-4e44-8a6d-513a93e19655,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-52c2c0ae-76be-4ff1-9623-cca4202cbebf,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-233f5048-590c-495d-91fa-dec8952a5e48,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-4a3097a9-1c92-4d6e-aa79-97bcca1dda90,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-d4f33def-23e8-422e-962e-a15dc49facef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396878641-172.17.0.9-1597737965871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36735,DS-8f675f31-3ce6-402e-851f-9e316664e923,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-6840031d-dfd5-4275-bd4d-fca335ea88d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-8338f92a-30c1-4b30-9942-7f64014caa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-eb30bcb7-804e-4e44-8a6d-513a93e19655,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-52c2c0ae-76be-4ff1-9623-cca4202cbebf,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-233f5048-590c-495d-91fa-dec8952a5e48,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-4a3097a9-1c92-4d6e-aa79-97bcca1dda90,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-d4f33def-23e8-422e-962e-a15dc49facef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-260524036-172.17.0.9-1597738049792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41530,DS-ffdc1805-2a1b-4b74-ad08-c0a1364cce58,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-5742f7b8-ccdc-49ab-9c9a-a1635772be3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-ca7fb8b2-8e75-48bc-86f4-c37a0b2985b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-576bbe74-b7d4-447b-b50e-b53d74496fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-ce7466e5-f1ea-4672-9730-c3569501dd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-1339eaba-274d-42ec-b5f6-54843715ca51,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-d101e863-f066-4683-8ea4-78c11508931d,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-45919d29-d6e7-459f-9f2e-de24c522b8c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-260524036-172.17.0.9-1597738049792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41530,DS-ffdc1805-2a1b-4b74-ad08-c0a1364cce58,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-5742f7b8-ccdc-49ab-9c9a-a1635772be3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-ca7fb8b2-8e75-48bc-86f4-c37a0b2985b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-576bbe74-b7d4-447b-b50e-b53d74496fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-ce7466e5-f1ea-4672-9730-c3569501dd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-1339eaba-274d-42ec-b5f6-54843715ca51,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-d101e863-f066-4683-8ea4-78c11508931d,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-45919d29-d6e7-459f-9f2e-de24c522b8c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-713973439-172.17.0.9-1597738306121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41741,DS-5f16fb8a-eb8e-4461-a5ae-e35676f1e736,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-6d308786-f152-4b02-a53c-572ee6b56184,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-a6ac3ab9-3bc7-4ba0-b91f-003aa597201d,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-f321fdc5-d082-443d-80a6-5713622ba7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-cb231953-d0fc-4190-be1e-94d33bc81def,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-c2f0dfaa-78db-4d14-ae15-47ed06d002ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-04ad42d2-71f5-4b6f-8eef-435da35ff93c,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-3a959645-896a-4ea2-a023-64f201e3cd36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-713973439-172.17.0.9-1597738306121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41741,DS-5f16fb8a-eb8e-4461-a5ae-e35676f1e736,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-6d308786-f152-4b02-a53c-572ee6b56184,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-a6ac3ab9-3bc7-4ba0-b91f-003aa597201d,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-f321fdc5-d082-443d-80a6-5713622ba7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-cb231953-d0fc-4190-be1e-94d33bc81def,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-c2f0dfaa-78db-4d14-ae15-47ed06d002ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-04ad42d2-71f5-4b6f-8eef-435da35ff93c,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-3a959645-896a-4ea2-a023-64f201e3cd36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1381730513-172.17.0.9-1597738449651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40504,DS-df1ee56b-3217-4ff0-b91c-4befb30abad4,DISK], DatanodeInfoWithStorage[127.0.0.1:37321,DS-d5277578-8246-47a9-944c-aaff2b45f6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-cef8762e-33af-4d86-970d-dfc4961a3fee,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-cb0e69a8-fcb3-4ae1-9d70-bae3ef9d91bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-b2d41711-2bfb-422e-9a39-1b183998605c,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-3f73e8ed-154d-4e76-b84f-5d698beb4f99,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-87a1ca09-315e-4a35-aa8f-52392393cdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-adfa178e-0956-4578-8181-ce8b6472b1bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1381730513-172.17.0.9-1597738449651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40504,DS-df1ee56b-3217-4ff0-b91c-4befb30abad4,DISK], DatanodeInfoWithStorage[127.0.0.1:37321,DS-d5277578-8246-47a9-944c-aaff2b45f6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-cef8762e-33af-4d86-970d-dfc4961a3fee,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-cb0e69a8-fcb3-4ae1-9d70-bae3ef9d91bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-b2d41711-2bfb-422e-9a39-1b183998605c,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-3f73e8ed-154d-4e76-b84f-5d698beb4f99,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-87a1ca09-315e-4a35-aa8f-52392393cdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-adfa178e-0956-4578-8181-ce8b6472b1bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1958394366-172.17.0.9-1597738495467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38698,DS-ac8a94f7-46a3-4ab3-94d2-1f5d47091ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-46af9535-ee53-46a8-a3fa-400180ea2424,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-9566740a-a8fc-48b8-b9e6-f3ab80e68528,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-2ea9c0ee-3728-46c7-b446-82ac005c7dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-11da8450-f9d5-4004-9614-f84dd1e7348d,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-30b194cb-f2e1-48af-bf8a-3b90486644be,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-89b4bb64-ec4b-4eee-ad1c-e2495c8c0c15,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-a1723754-5637-45da-99ec-aa3beb5e7000,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1958394366-172.17.0.9-1597738495467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38698,DS-ac8a94f7-46a3-4ab3-94d2-1f5d47091ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-46af9535-ee53-46a8-a3fa-400180ea2424,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-9566740a-a8fc-48b8-b9e6-f3ab80e68528,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-2ea9c0ee-3728-46c7-b446-82ac005c7dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-11da8450-f9d5-4004-9614-f84dd1e7348d,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-30b194cb-f2e1-48af-bf8a-3b90486644be,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-89b4bb64-ec4b-4eee-ad1c-e2495c8c0c15,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-a1723754-5637-45da-99ec-aa3beb5e7000,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1180270172-172.17.0.9-1597738544640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32792,DS-5b0b2770-bb64-4062-8b15-b1c5e1c4fd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-6c24c314-95b1-4639-b2ee-ff4340d9a6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-a8bcd137-bb69-4a6c-b495-118543c092f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-53e0e337-2477-4b39-9a39-c6d4b4fd1b48,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-91a762a9-e05a-4c06-95aa-338feda439e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-cb86010a-72a5-4916-a57e-30b321a8545a,DISK], DatanodeInfoWithStorage[127.0.0.1:46690,DS-25e19b68-9937-4d0d-9760-6a12cc0d5d76,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-d19a7458-516d-48c7-ba82-d1e676b08309,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1180270172-172.17.0.9-1597738544640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32792,DS-5b0b2770-bb64-4062-8b15-b1c5e1c4fd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-6c24c314-95b1-4639-b2ee-ff4340d9a6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-a8bcd137-bb69-4a6c-b495-118543c092f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-53e0e337-2477-4b39-9a39-c6d4b4fd1b48,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-91a762a9-e05a-4c06-95aa-338feda439e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-cb86010a-72a5-4916-a57e-30b321a8545a,DISK], DatanodeInfoWithStorage[127.0.0.1:46690,DS-25e19b68-9937-4d0d-9760-6a12cc0d5d76,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-d19a7458-516d-48c7-ba82-d1e676b08309,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305500361-172.17.0.9-1597738674578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39277,DS-c966c565-3e3e-43fd-b5f3-e9106dc843db,DISK], DatanodeInfoWithStorage[127.0.0.1:46106,DS-8d3dcd02-3216-42c9-a6db-25859a26b93f,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-e7305812-7472-4bf5-9a23-e02f917d4238,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-37f89e66-0485-41ce-9d1b-5cc77bf8d8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-1e1cfcc3-faf3-42fb-a6c4-0d957ecea8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-5706a85d-cc9e-4e22-b54a-3c130081b024,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-1936187d-c332-4d76-9473-3f64475eb4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41733,DS-5218a098-542d-4cca-ab57-49b4d57a68a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305500361-172.17.0.9-1597738674578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39277,DS-c966c565-3e3e-43fd-b5f3-e9106dc843db,DISK], DatanodeInfoWithStorage[127.0.0.1:46106,DS-8d3dcd02-3216-42c9-a6db-25859a26b93f,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-e7305812-7472-4bf5-9a23-e02f917d4238,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-37f89e66-0485-41ce-9d1b-5cc77bf8d8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-1e1cfcc3-faf3-42fb-a6c4-0d957ecea8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-5706a85d-cc9e-4e22-b54a-3c130081b024,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-1936187d-c332-4d76-9473-3f64475eb4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41733,DS-5218a098-542d-4cca-ab57-49b4d57a68a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430993079-172.17.0.9-1597738975031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44139,DS-0101d328-4d7c-49ef-acaf-41d970096146,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-afdc2305-b4d6-4814-b21b-5669045ebf6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-49612b06-962b-4519-b5d1-e36cd6fcaaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-96045f5b-f249-42da-af0c-f0f093f2b3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-db1066cc-eb41-473b-9a36-6a4f30a80282,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-a1e73d5f-a729-4145-b871-623abe25babe,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-76513530-ba9b-46d2-a87a-fd90423f59e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-6c4e4474-8d1b-4dc4-aca4-317e5e47a4ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430993079-172.17.0.9-1597738975031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44139,DS-0101d328-4d7c-49ef-acaf-41d970096146,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-afdc2305-b4d6-4814-b21b-5669045ebf6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-49612b06-962b-4519-b5d1-e36cd6fcaaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-96045f5b-f249-42da-af0c-f0f093f2b3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-db1066cc-eb41-473b-9a36-6a4f30a80282,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-a1e73d5f-a729-4145-b871-623abe25babe,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-76513530-ba9b-46d2-a87a-fd90423f59e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-6c4e4474-8d1b-4dc4-aca4-317e5e47a4ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1523514628-172.17.0.9-1597739061885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35358,DS-d77a11ac-f5dd-4c66-873b-1e0c1faec420,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-a0a1bb26-9b12-4ce2-8bdc-3c39b6d24caf,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-bcb84ee6-428c-439b-9b69-1b0884d65afc,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-8fcde02a-035a-4ff5-a1b0-c7a31b3eeb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-b4e6c499-ed52-4054-a30a-56b745d1f035,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-e5a63ebb-07db-4ad6-ae32-925021e3f122,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-cb25246d-3267-4922-93b4-f8311d316756,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-a9704e42-c6c0-4bd2-aaaf-accaab7d87ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1523514628-172.17.0.9-1597739061885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35358,DS-d77a11ac-f5dd-4c66-873b-1e0c1faec420,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-a0a1bb26-9b12-4ce2-8bdc-3c39b6d24caf,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-bcb84ee6-428c-439b-9b69-1b0884d65afc,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-8fcde02a-035a-4ff5-a1b0-c7a31b3eeb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-b4e6c499-ed52-4054-a30a-56b745d1f035,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-e5a63ebb-07db-4ad6-ae32-925021e3f122,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-cb25246d-3267-4922-93b4-f8311d316756,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-a9704e42-c6c0-4bd2-aaaf-accaab7d87ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369637636-172.17.0.9-1597739229717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36829,DS-4ed6cc9b-81ae-4ad9-9234-7210297f9893,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-d9f04b92-c422-489c-b209-56fbd0aaf68b,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-497fef94-562b-4f77-9c05-806fc574de99,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-67147986-505b-4a2b-9e0f-e3b86f833147,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-3ddcc1f2-12bc-4eca-a04a-72d5e36e8593,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-65887ae8-3ac4-41ad-8899-c88b1158c744,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-c984bcd6-e74d-4463-aa1a-5c8eadbec0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-f4073a1e-c827-4053-b9d6-44292e318e57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369637636-172.17.0.9-1597739229717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36829,DS-4ed6cc9b-81ae-4ad9-9234-7210297f9893,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-d9f04b92-c422-489c-b209-56fbd0aaf68b,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-497fef94-562b-4f77-9c05-806fc574de99,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-67147986-505b-4a2b-9e0f-e3b86f833147,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-3ddcc1f2-12bc-4eca-a04a-72d5e36e8593,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-65887ae8-3ac4-41ad-8899-c88b1158c744,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-c984bcd6-e74d-4463-aa1a-5c8eadbec0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-f4073a1e-c827-4053-b9d6-44292e318e57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1834866042-172.17.0.9-1597739741271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42315,DS-0cc5def4-02c1-4526-a56b-8fa17142546c,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-1b312e1c-d983-4f54-97d4-0eb358364ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-da85cb62-4b68-4bc1-81d6-1e98ce0b5bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-de015aec-99a0-47e8-89a1-26dcd4fc3699,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-5b1419a5-8259-411d-b885-e1d37dd92000,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-aba2a856-a780-4458-86a4-5fa784fc35a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-298ea1f0-8bf3-4dba-8c82-6e0e63b20b60,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-a3dbb33f-a5a1-4bbb-a9f4-53b64302c9db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1834866042-172.17.0.9-1597739741271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42315,DS-0cc5def4-02c1-4526-a56b-8fa17142546c,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-1b312e1c-d983-4f54-97d4-0eb358364ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-da85cb62-4b68-4bc1-81d6-1e98ce0b5bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-de015aec-99a0-47e8-89a1-26dcd4fc3699,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-5b1419a5-8259-411d-b885-e1d37dd92000,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-aba2a856-a780-4458-86a4-5fa784fc35a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-298ea1f0-8bf3-4dba-8c82-6e0e63b20b60,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-a3dbb33f-a5a1-4bbb-a9f4-53b64302c9db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216096831-172.17.0.9-1597739868904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33842,DS-fc5becb9-b3ce-4493-bc3c-81ee0635bc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-3df861e1-96b1-4795-a507-d75dac7e0f55,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-e37de2d3-6b00-47bf-a20e-0e7c1c8d62a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-9e6ea5b7-ef50-4b59-8c87-b55a2880cd46,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-ae9d6c88-2b91-4b71-88e9-71e8d9ed079a,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-ef9ae9cb-8960-484e-8f00-0f64abbaa675,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-f5a27dcc-8505-4ac0-817f-48c708e1fc61,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-3822104b-0602-450e-be9f-7faa1ed223bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216096831-172.17.0.9-1597739868904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33842,DS-fc5becb9-b3ce-4493-bc3c-81ee0635bc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-3df861e1-96b1-4795-a507-d75dac7e0f55,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-e37de2d3-6b00-47bf-a20e-0e7c1c8d62a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-9e6ea5b7-ef50-4b59-8c87-b55a2880cd46,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-ae9d6c88-2b91-4b71-88e9-71e8d9ed079a,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-ef9ae9cb-8960-484e-8f00-0f64abbaa675,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-f5a27dcc-8505-4ac0-817f-48c708e1fc61,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-3822104b-0602-450e-be9f-7faa1ed223bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1590110789-172.17.0.9-1597741560023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40978,DS-eac5b89d-6309-48c3-9636-e8798b68bc75,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-73d1f74b-4a1a-4f17-91b0-bec3fe03cc46,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-eef8400d-11a8-4eb2-ab5e-3cf430637cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-f5ff0279-2dcd-443c-a9fe-5f63247b0e06,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-2c304800-d3d5-4de5-949f-33fe11e8a89a,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-7a01f3f5-c6a1-4fc9-bd2b-a6ad35bc68f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-e15d7b42-74f7-41fe-8795-a5165cfce8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-c9080beb-a929-41cf-8027-231aa4125476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1590110789-172.17.0.9-1597741560023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40978,DS-eac5b89d-6309-48c3-9636-e8798b68bc75,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-73d1f74b-4a1a-4f17-91b0-bec3fe03cc46,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-eef8400d-11a8-4eb2-ab5e-3cf430637cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-f5ff0279-2dcd-443c-a9fe-5f63247b0e06,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-2c304800-d3d5-4de5-949f-33fe11e8a89a,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-7a01f3f5-c6a1-4fc9-bd2b-a6ad35bc68f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-e15d7b42-74f7-41fe-8795-a5165cfce8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-c9080beb-a929-41cf-8027-231aa4125476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560226320-172.17.0.9-1597741608344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33687,DS-fba2e1d0-1915-47c4-9fcd-e72e357d0115,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-217d401c-1be7-49e3-9ea3-7af98c69e5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-0452e1a2-c625-4b15-a0fc-3296584fc304,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-bd81afc0-4748-49f4-9fca-d4ab5085aadd,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-ff7797c5-0324-4cc5-8ce2-a1d99ed8f6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-e99c7fac-7fd2-4662-821d-0da56a0ecd65,DISK], DatanodeInfoWithStorage[127.0.0.1:38986,DS-ade23a22-7837-4d19-b190-7e6341b9b6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-657a763e-fada-45a7-a283-33dc0ba6bb15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560226320-172.17.0.9-1597741608344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33687,DS-fba2e1d0-1915-47c4-9fcd-e72e357d0115,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-217d401c-1be7-49e3-9ea3-7af98c69e5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-0452e1a2-c625-4b15-a0fc-3296584fc304,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-bd81afc0-4748-49f4-9fca-d4ab5085aadd,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-ff7797c5-0324-4cc5-8ce2-a1d99ed8f6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-e99c7fac-7fd2-4662-821d-0da56a0ecd65,DISK], DatanodeInfoWithStorage[127.0.0.1:38986,DS-ade23a22-7837-4d19-b190-7e6341b9b6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-657a763e-fada-45a7-a283-33dc0ba6bb15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 5m
v2: 10485760
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346921005-172.17.0.9-1597741699367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42867,DS-5d7f1992-1759-4579-95b7-1717854854ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-29e1a7c5-3449-4373-90a3-ab6c27ddf6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-b8cfc1e7-2bf7-492b-8cdc-b49fea468a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-b303fc9c-50cb-4ee8-b400-e50003bb4fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-1be6bb23-31cc-477a-83c3-5b83de64aada,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-1fdf72e2-9a0d-4da6-b691-0d75db581e78,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-be949bd2-e246-446c-ab41-84f3394680e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-6e39e2df-e91c-4cf3-a942-fa78c0c1fa0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346921005-172.17.0.9-1597741699367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42867,DS-5d7f1992-1759-4579-95b7-1717854854ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-29e1a7c5-3449-4373-90a3-ab6c27ddf6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-b8cfc1e7-2bf7-492b-8cdc-b49fea468a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-b303fc9c-50cb-4ee8-b400-e50003bb4fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-1be6bb23-31cc-477a-83c3-5b83de64aada,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-1fdf72e2-9a0d-4da6-b691-0d75db581e78,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-be949bd2-e246-446c-ab41-84f3394680e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-6e39e2df-e91c-4cf3-a942-fa78c0c1fa0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 6717
