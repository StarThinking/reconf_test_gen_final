reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 1000
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 1000
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1484900243-172.17.0.19-1597727876288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37394,DS-383e59d8-ba53-413d-999c-1a20a78643c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-fc4ae838-daf2-4db9-971d-b0751a97f289,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-c32ea795-d9aa-4091-89a5-2fedb7c4f231,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-c7c3835d-601b-457e-aaec-0171fd4fc0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-9546c807-acd4-483f-b0e1-d6349cd35264,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-2ce9e583-a276-4d85-85db-00f7b1f4e473,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-1dce7f60-64d2-4e4f-86d3-4a47b02cf1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-54e9a099-f7e6-4194-9ea0-776ba0405cf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1484900243-172.17.0.19-1597727876288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37394,DS-383e59d8-ba53-413d-999c-1a20a78643c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-fc4ae838-daf2-4db9-971d-b0751a97f289,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-c32ea795-d9aa-4091-89a5-2fedb7c4f231,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-c7c3835d-601b-457e-aaec-0171fd4fc0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-9546c807-acd4-483f-b0e1-d6349cd35264,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-2ce9e583-a276-4d85-85db-00f7b1f4e473,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-1dce7f60-64d2-4e4f-86d3-4a47b02cf1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-54e9a099-f7e6-4194-9ea0-776ba0405cf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 1000
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-382843754-172.17.0.19-1597727910587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41860,DS-1cc54347-af2c-4559-9839-ddb92adfede8,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-85a8ad4b-06f9-4b6c-afb1-50c30e48df27,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-bfdf90a1-8b92-43fc-8c38-b0fd7280134d,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-3a5e1a51-c33e-452c-8a9c-5a1c0edb8a02,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-0b4156ac-10af-4be7-a276-024994389d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42961,DS-bd70724d-24e9-4981-90d1-f989a188578a,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-a97c98ec-7d65-447c-9edb-ce5c88f54ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-5cc74f8d-4d6f-468e-9b8f-5f6a006ff11c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-382843754-172.17.0.19-1597727910587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41860,DS-1cc54347-af2c-4559-9839-ddb92adfede8,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-85a8ad4b-06f9-4b6c-afb1-50c30e48df27,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-bfdf90a1-8b92-43fc-8c38-b0fd7280134d,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-3a5e1a51-c33e-452c-8a9c-5a1c0edb8a02,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-0b4156ac-10af-4be7-a276-024994389d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42961,DS-bd70724d-24e9-4981-90d1-f989a188578a,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-a97c98ec-7d65-447c-9edb-ce5c88f54ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-5cc74f8d-4d6f-468e-9b8f-5f6a006ff11c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 1000
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-166225017-172.17.0.19-1597728535488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33945,DS-bec76bf1-40d5-4af5-8219-ecf91bf9db6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-3007f6a9-00e6-4390-a763-5a214339eaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-d69af969-e70c-4df1-a319-e29ab9f6f33e,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-8153c19d-88e2-488b-9519-814218952635,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-9fcedf23-062d-4531-af40-e690ec756b46,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-763dc560-73ce-43b7-838d-7eebe8b04056,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-67e30c69-2f8d-4aa7-8281-d2d594584a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-4281e320-6ba8-4997-9964-48148e25178f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-166225017-172.17.0.19-1597728535488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33945,DS-bec76bf1-40d5-4af5-8219-ecf91bf9db6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-3007f6a9-00e6-4390-a763-5a214339eaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-d69af969-e70c-4df1-a319-e29ab9f6f33e,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-8153c19d-88e2-488b-9519-814218952635,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-9fcedf23-062d-4531-af40-e690ec756b46,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-763dc560-73ce-43b7-838d-7eebe8b04056,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-67e30c69-2f8d-4aa7-8281-d2d594584a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-4281e320-6ba8-4997-9964-48148e25178f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 1000
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1112416130-172.17.0.19-1597728887087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38358,DS-543a929d-d68b-45c3-bbb1-0ede9124974a,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-31332d0b-e876-40ea-a211-562d1620ceb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-03de3e3f-4e5b-4bbb-9e60-e39a39382c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-61dfd006-344c-4fe0-8539-2f02ff857a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-1661006e-9220-4530-8688-4e9df8b017f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-a5c7d033-7f9b-40e7-ac6b-bfe8db5ca0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-16a8e9fe-4a87-4233-9734-f1912fff6d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-e8d3288a-3f4e-46d6-b6cc-0d1e8a004ccd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1112416130-172.17.0.19-1597728887087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38358,DS-543a929d-d68b-45c3-bbb1-0ede9124974a,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-31332d0b-e876-40ea-a211-562d1620ceb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-03de3e3f-4e5b-4bbb-9e60-e39a39382c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-61dfd006-344c-4fe0-8539-2f02ff857a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-1661006e-9220-4530-8688-4e9df8b017f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-a5c7d033-7f9b-40e7-ac6b-bfe8db5ca0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-16a8e9fe-4a87-4233-9734-f1912fff6d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-e8d3288a-3f4e-46d6-b6cc-0d1e8a004ccd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 1000
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1702977754-172.17.0.19-1597729425597:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35058,DS-e03e4096-2107-4655-aec9-05b1ccc8fca1,DISK], DatanodeInfoWithStorage[127.0.0.1:35943,DS-02c3dab3-a362-470d-9ba0-47ad58454311,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-97fb9d04-76bc-41eb-8ee7-dae909da758a,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-da483438-28e2-4d6c-8120-01e0a795bf32,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-1280d258-c526-4c0d-ae2f-0d3d5c2b8d80,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-dc66ac29-13a8-407d-b815-c6f0fcc24b89,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-9f26537c-2d3f-481b-9c15-34541e158cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-4da50d08-60f6-4a5a-9073-2737f11fd1ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1702977754-172.17.0.19-1597729425597:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35058,DS-e03e4096-2107-4655-aec9-05b1ccc8fca1,DISK], DatanodeInfoWithStorage[127.0.0.1:35943,DS-02c3dab3-a362-470d-9ba0-47ad58454311,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-97fb9d04-76bc-41eb-8ee7-dae909da758a,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-da483438-28e2-4d6c-8120-01e0a795bf32,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-1280d258-c526-4c0d-ae2f-0d3d5c2b8d80,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-dc66ac29-13a8-407d-b815-c6f0fcc24b89,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-9f26537c-2d3f-481b-9c15-34541e158cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-4da50d08-60f6-4a5a-9073-2737f11fd1ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 1000
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-477263452-172.17.0.19-1597729464786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41750,DS-df559140-f455-4f68-8a1d-420b6d099b90,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-eb23f08d-8e1e-4fad-9de0-a641c350568b,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-ee791d33-ab4c-4c1e-9987-b167667a21d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-d4ae046e-5e3f-4fb4-ad7c-d3e70c742dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-0b935a7f-a26d-41c5-a4ec-ff2eec907911,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-321af2b1-b6c0-4259-a70c-b35ab32a1e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-8bb788bb-9590-4d42-860c-0993c11daec7,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-4944b3e7-6702-482f-9e3f-f4cd33cec507,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-477263452-172.17.0.19-1597729464786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41750,DS-df559140-f455-4f68-8a1d-420b6d099b90,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-eb23f08d-8e1e-4fad-9de0-a641c350568b,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-ee791d33-ab4c-4c1e-9987-b167667a21d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-d4ae046e-5e3f-4fb4-ad7c-d3e70c742dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-0b935a7f-a26d-41c5-a4ec-ff2eec907911,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-321af2b1-b6c0-4259-a70c-b35ab32a1e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-8bb788bb-9590-4d42-860c-0993c11daec7,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-4944b3e7-6702-482f-9e3f-f4cd33cec507,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 1000
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-919300803-172.17.0.19-1597729755172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34818,DS-105a6591-7dc7-45dc-ab3a-5fe9cda43b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-caf508da-40b6-4a29-9846-4dcf24e7fb74,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-741932f8-1cb1-4da9-8a90-346c408127c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-47c00080-fd2f-4d63-b5f5-a134740e8f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-11097b91-d3b2-47a6-bd84-a71b937b1da0,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-e94d2593-b059-4617-9109-29813e1e6991,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-85add7a2-d399-4ae6-b9cf-955c1bf83720,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-4076b703-e250-4e11-8445-46ebd8944f45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-919300803-172.17.0.19-1597729755172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34818,DS-105a6591-7dc7-45dc-ab3a-5fe9cda43b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-caf508da-40b6-4a29-9846-4dcf24e7fb74,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-741932f8-1cb1-4da9-8a90-346c408127c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-47c00080-fd2f-4d63-b5f5-a134740e8f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-11097b91-d3b2-47a6-bd84-a71b937b1da0,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-e94d2593-b059-4617-9109-29813e1e6991,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-85add7a2-d399-4ae6-b9cf-955c1bf83720,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-4076b703-e250-4e11-8445-46ebd8944f45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 1000
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2145897735-172.17.0.19-1597729793346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38785,DS-c8a8238d-29b5-4b5e-8989-1d68b7be016a,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-af8807cf-e5e4-4460-a607-d1833d169c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-715fb58e-372f-45c3-b799-83715be42dde,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-66cec37d-2a67-4638-b1c8-0e9328f2c1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-2211ae3a-de6f-40c3-8bcf-4ec1c2b9bc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-89b88644-28b9-4614-9dc2-c811b61f4792,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-5c34e32e-0feb-4a4b-807b-7774511b2275,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-eb39a7ec-50a4-4a8e-aafd-759f83edb44a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2145897735-172.17.0.19-1597729793346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38785,DS-c8a8238d-29b5-4b5e-8989-1d68b7be016a,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-af8807cf-e5e4-4460-a607-d1833d169c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-715fb58e-372f-45c3-b799-83715be42dde,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-66cec37d-2a67-4638-b1c8-0e9328f2c1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-2211ae3a-de6f-40c3-8bcf-4ec1c2b9bc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-89b88644-28b9-4614-9dc2-c811b61f4792,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-5c34e32e-0feb-4a4b-807b-7774511b2275,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-eb39a7ec-50a4-4a8e-aafd-759f83edb44a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 1000
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-915178215-172.17.0.19-1597729890472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34993,DS-3100e54b-dc8c-4b1a-b42c-eaa37bf09d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-306522d8-2ae0-41bf-8df5-b34ba117ac41,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-a25f230c-bc75-45fd-9b9f-fc04ff27e6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-eb9003a5-a12a-44d3-a321-7ecf70d01d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-81013838-4cf7-4ec5-9903-c25fa1c66a41,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-eb0aa6bc-7750-44b5-9036-096bfee56e89,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-bea9235a-502d-4efd-a4a3-cba024c2ad26,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-01bcf53e-5a47-45ba-860a-c5aa79716fa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-915178215-172.17.0.19-1597729890472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34993,DS-3100e54b-dc8c-4b1a-b42c-eaa37bf09d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-306522d8-2ae0-41bf-8df5-b34ba117ac41,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-a25f230c-bc75-45fd-9b9f-fc04ff27e6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-eb9003a5-a12a-44d3-a321-7ecf70d01d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-81013838-4cf7-4ec5-9903-c25fa1c66a41,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-eb0aa6bc-7750-44b5-9036-096bfee56e89,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-bea9235a-502d-4efd-a4a3-cba024c2ad26,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-01bcf53e-5a47-45ba-860a-c5aa79716fa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 1000
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1183714428-172.17.0.19-1597730919786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34552,DS-dfc0b187-6dc5-4b86-ad09-e93c77909284,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-9f3ce637-f02c-48f1-8e89-58750ccdc7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-403d36a6-6f59-41e4-b65e-6edd7c6951fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-37078a8f-a77b-4cca-a40d-953bd7492190,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-bfffd68d-57ae-4b6d-977f-febb1a571ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-d36f67ac-6cb8-491f-8bcc-3a370b92094d,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-f5291ae5-0532-4ce6-9966-a7e588f5990c,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-b0378f09-2502-4210-ad71-74a61e6bc605,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1183714428-172.17.0.19-1597730919786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34552,DS-dfc0b187-6dc5-4b86-ad09-e93c77909284,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-9f3ce637-f02c-48f1-8e89-58750ccdc7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-403d36a6-6f59-41e4-b65e-6edd7c6951fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-37078a8f-a77b-4cca-a40d-953bd7492190,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-bfffd68d-57ae-4b6d-977f-febb1a571ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-d36f67ac-6cb8-491f-8bcc-3a370b92094d,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-f5291ae5-0532-4ce6-9966-a7e588f5990c,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-b0378f09-2502-4210-ad71-74a61e6bc605,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 1000
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1163209839-172.17.0.19-1597731276662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43671,DS-44b10f73-864d-4c4c-a893-b48d508ea26c,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-70e93aeb-900f-4b26-a79c-ecde53f8c97f,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-5902ee7c-7ae5-4ed1-8659-7e509e7a3801,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-37b2cc11-f1f5-4257-971b-a4ea415eba7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-7607c0cb-ff41-40bd-85cf-da5e0e226bad,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-27c32451-9c71-4379-a835-1f55a83abc99,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-24247725-0c1e-430c-a008-4d31dfa6c646,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-2cdd6a49-8381-49a0-8487-612ab6fc61b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1163209839-172.17.0.19-1597731276662:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43671,DS-44b10f73-864d-4c4c-a893-b48d508ea26c,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-70e93aeb-900f-4b26-a79c-ecde53f8c97f,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-5902ee7c-7ae5-4ed1-8659-7e509e7a3801,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-37b2cc11-f1f5-4257-971b-a4ea415eba7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-7607c0cb-ff41-40bd-85cf-da5e0e226bad,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-27c32451-9c71-4379-a835-1f55a83abc99,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-24247725-0c1e-430c-a008-4d31dfa6c646,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-2cdd6a49-8381-49a0-8487-612ab6fc61b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 1000
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-750053825-172.17.0.19-1597731355443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36504,DS-e62989a0-8ffc-489b-8cd7-f980833c01cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-bc8299e5-8123-45df-aab9-6969c9fa69bc,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-c73a4226-fd33-4b0e-93ed-a558da13fc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-8a7b6e7a-141f-475a-aeee-aca24298f7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-ba33651f-010a-4e8e-aa7d-f0668ac9805b,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-a669da6a-aad6-4cf8-b184-7d8790eee898,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-344aed99-809b-482f-8668-e8452a813c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-71369cfc-b98c-4b7f-bbb5-4c86dae3bd49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-750053825-172.17.0.19-1597731355443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36504,DS-e62989a0-8ffc-489b-8cd7-f980833c01cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-bc8299e5-8123-45df-aab9-6969c9fa69bc,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-c73a4226-fd33-4b0e-93ed-a558da13fc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-8a7b6e7a-141f-475a-aeee-aca24298f7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-ba33651f-010a-4e8e-aa7d-f0668ac9805b,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-a669da6a-aad6-4cf8-b184-7d8790eee898,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-344aed99-809b-482f-8668-e8452a813c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-71369cfc-b98c-4b7f-bbb5-4c86dae3bd49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 1000
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-302863564-172.17.0.19-1597731776720:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37485,DS-532d1256-4a57-440f-89ae-388914b58629,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-54c5c2d9-061f-4441-9cef-a737fa39038a,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-f23930b7-a652-44f3-9428-8853306ac034,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-5b9d6222-2e8b-4d5a-9752-9e35cd75d334,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-b7d52845-6858-424b-94e2-8ee2d4409ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-55baedbc-b5a7-4538-8371-99faabf021b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-100d752d-3724-43de-b9eb-ac3509db8502,DISK], DatanodeInfoWithStorage[127.0.0.1:34646,DS-8ffdfb2d-1f52-4580-8385-0da0dc82782f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-302863564-172.17.0.19-1597731776720:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37485,DS-532d1256-4a57-440f-89ae-388914b58629,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-54c5c2d9-061f-4441-9cef-a737fa39038a,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-f23930b7-a652-44f3-9428-8853306ac034,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-5b9d6222-2e8b-4d5a-9752-9e35cd75d334,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-b7d52845-6858-424b-94e2-8ee2d4409ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-55baedbc-b5a7-4538-8371-99faabf021b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-100d752d-3724-43de-b9eb-ac3509db8502,DISK], DatanodeInfoWithStorage[127.0.0.1:34646,DS-8ffdfb2d-1f52-4580-8385-0da0dc82782f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 1000
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-352573635-172.17.0.19-1597731945999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33759,DS-e981e3b1-5136-4cfa-9f22-06095571ad7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-e84742e9-99b0-4ff7-95f2-4c3d98d848ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-51967990-dec2-43f8-977e-95cce5e67576,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-f3ade6b1-e1d3-4e97-bf88-e70683ab332d,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-1841d3ef-2a63-439e-b786-63877b4e8281,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-c1c222af-c7a8-4d4b-a758-e228c9dc4f61,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-e187b057-9882-4434-8119-5bf0e24c82cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-26214d46-885c-41df-aa72-475efccce21e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-352573635-172.17.0.19-1597731945999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33759,DS-e981e3b1-5136-4cfa-9f22-06095571ad7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-e84742e9-99b0-4ff7-95f2-4c3d98d848ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-51967990-dec2-43f8-977e-95cce5e67576,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-f3ade6b1-e1d3-4e97-bf88-e70683ab332d,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-1841d3ef-2a63-439e-b786-63877b4e8281,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-c1c222af-c7a8-4d4b-a758-e228c9dc4f61,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-e187b057-9882-4434-8119-5bf0e24c82cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-26214d46-885c-41df-aa72-475efccce21e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 1000
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1094008130-172.17.0.19-1597732017546:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43093,DS-96c8eab7-cc5c-40a2-9059-9af6f5219adf,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-212b724c-e751-45e0-8fbd-8ff9995318f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-b2ed091b-b8d9-4f19-9e36-52e5db706698,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-2d50943c-35cd-4701-a744-c838f37d278b,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-a39c072d-72ec-45e4-9a75-9c6a996ef24f,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-1676d11a-c89d-4070-98f5-81d76208b68f,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-59c2626b-5de9-4eae-af31-ca2f3b1134f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40749,DS-c2764ea4-1cbd-4426-a3c3-c298a1407291,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1094008130-172.17.0.19-1597732017546:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43093,DS-96c8eab7-cc5c-40a2-9059-9af6f5219adf,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-212b724c-e751-45e0-8fbd-8ff9995318f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-b2ed091b-b8d9-4f19-9e36-52e5db706698,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-2d50943c-35cd-4701-a744-c838f37d278b,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-a39c072d-72ec-45e4-9a75-9c6a996ef24f,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-1676d11a-c89d-4070-98f5-81d76208b68f,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-59c2626b-5de9-4eae-af31-ca2f3b1134f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40749,DS-c2764ea4-1cbd-4426-a3c3-c298a1407291,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 1000
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1805807577-172.17.0.19-1597732090596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36907,DS-921ff3fb-8d69-4c99-bc93-4f089ecb1c18,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-2b36aa63-bcbd-422f-8684-1bdf2b756dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-c1e28ac6-8397-4da6-bd60-9180784f8a66,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-3baa0be8-17ad-4684-9b54-4a5c7f999d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-fc326aec-7528-4e42-8e9f-3491a30d9fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-9b487244-47d9-47ea-9aa1-fd3fe73f109a,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-9f3a3901-a088-49b4-865f-3e4fb649b194,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-10b74a70-34ab-4060-9bd6-04e484246a5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1805807577-172.17.0.19-1597732090596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36907,DS-921ff3fb-8d69-4c99-bc93-4f089ecb1c18,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-2b36aa63-bcbd-422f-8684-1bdf2b756dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-c1e28ac6-8397-4da6-bd60-9180784f8a66,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-3baa0be8-17ad-4684-9b54-4a5c7f999d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-fc326aec-7528-4e42-8e9f-3491a30d9fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-9b487244-47d9-47ea-9aa1-fd3fe73f109a,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-9f3a3901-a088-49b4-865f-3e4fb649b194,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-10b74a70-34ab-4060-9bd6-04e484246a5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 1000
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-115324281-172.17.0.19-1597732126109:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36380,DS-11a503a9-2603-46db-89ce-e04592291663,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-e8bf6e24-7d35-4fcf-a645-b7d17d0a60bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-e05953a2-cdf3-4295-aec0-e56b293458d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-35af8c6d-c1bb-4e13-a8cb-c98dab81bc57,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-267a2a40-5225-470d-a1ca-3c2f74cc4f34,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-0d351e05-211a-4a82-95a1-39cda34e7b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-82672507-e0f0-41f5-98bd-604ecd3296bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-7fdb75a0-3519-4851-ae45-a4371084bf1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-115324281-172.17.0.19-1597732126109:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36380,DS-11a503a9-2603-46db-89ce-e04592291663,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-e8bf6e24-7d35-4fcf-a645-b7d17d0a60bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-e05953a2-cdf3-4295-aec0-e56b293458d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-35af8c6d-c1bb-4e13-a8cb-c98dab81bc57,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-267a2a40-5225-470d-a1ca-3c2f74cc4f34,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-0d351e05-211a-4a82-95a1-39cda34e7b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-82672507-e0f0-41f5-98bd-604ecd3296bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-7fdb75a0-3519-4851-ae45-a4371084bf1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 1000
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1262443573-172.17.0.19-1597732388916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37114,DS-b4786f91-dfa7-4c56-a99b-929ec4a5f90a,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-4e6a951f-d346-4314-aa01-74db2eb0fc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-078e519b-57e1-45e9-9e8f-3d9b54039441,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-c6723ac0-70c1-491d-b764-9a24eb0764cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-a94fca24-a339-4d44-83de-a2e57f6dfaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-f37a6064-77b0-4587-93e6-0089e6241040,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-d2a80388-9cde-4026-a4ac-7cc6bb2a22b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-68bd1115-1263-45a0-8b15-f47adeac67ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1262443573-172.17.0.19-1597732388916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37114,DS-b4786f91-dfa7-4c56-a99b-929ec4a5f90a,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-4e6a951f-d346-4314-aa01-74db2eb0fc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-078e519b-57e1-45e9-9e8f-3d9b54039441,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-c6723ac0-70c1-491d-b764-9a24eb0764cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-a94fca24-a339-4d44-83de-a2e57f6dfaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-f37a6064-77b0-4587-93e6-0089e6241040,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-d2a80388-9cde-4026-a4ac-7cc6bb2a22b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-68bd1115-1263-45a0-8b15-f47adeac67ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 1000
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2021377081-172.17.0.19-1597732531127:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42065,DS-bb635d70-be03-4eec-9d73-e4a5fdc53d61,DISK], DatanodeInfoWithStorage[127.0.0.1:42591,DS-f9944176-705e-4103-818b-d78b89ba68cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-f24cb03b-7eb8-4426-9434-fe3f49b4ffd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-392fb7cb-c9cd-4ed8-97ae-af103ad87677,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-99207cba-b7e8-4147-a1f7-9cc6649dc835,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-d3c8148c-29a0-4b8d-8ca0-4b5110902656,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-767bf2ab-a9de-4e54-be94-6fa47d82ed46,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-eaba48ea-f805-47d0-8b79-879eaf8497f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2021377081-172.17.0.19-1597732531127:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42065,DS-bb635d70-be03-4eec-9d73-e4a5fdc53d61,DISK], DatanodeInfoWithStorage[127.0.0.1:42591,DS-f9944176-705e-4103-818b-d78b89ba68cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-f24cb03b-7eb8-4426-9434-fe3f49b4ffd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-392fb7cb-c9cd-4ed8-97ae-af103ad87677,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-99207cba-b7e8-4147-a1f7-9cc6649dc835,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-d3c8148c-29a0-4b8d-8ca0-4b5110902656,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-767bf2ab-a9de-4e54-be94-6fa47d82ed46,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-eaba48ea-f805-47d0-8b79-879eaf8497f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 1000
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-991514787-172.17.0.19-1597732593296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36137,DS-f1960a18-67d1-47e5-97ef-05b8b0df0e88,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-cb0027b5-b571-4ae3-816d-2623fbf22f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-ec86f656-ce59-4713-840a-18abd35354da,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-46f8b766-a55f-4192-a621-93f896d7d10f,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-fa50b110-3ee5-4140-824a-7b49f37bcd43,DISK], DatanodeInfoWithStorage[127.0.0.1:40065,DS-6ab5342e-eb02-4d9c-a72a-4397e76f9e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-45aa5515-1841-47b0-9f2b-2a93ac3bc956,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-dfbc18e8-3c36-41f2-b552-e378e503fc08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-991514787-172.17.0.19-1597732593296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36137,DS-f1960a18-67d1-47e5-97ef-05b8b0df0e88,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-cb0027b5-b571-4ae3-816d-2623fbf22f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-ec86f656-ce59-4713-840a-18abd35354da,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-46f8b766-a55f-4192-a621-93f896d7d10f,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-fa50b110-3ee5-4140-824a-7b49f37bcd43,DISK], DatanodeInfoWithStorage[127.0.0.1:40065,DS-6ab5342e-eb02-4d9c-a72a-4397e76f9e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-45aa5515-1841-47b0-9f2b-2a93ac3bc956,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-dfbc18e8-3c36-41f2-b552-e378e503fc08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 1000
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325877372-172.17.0.19-1597732883171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33474,DS-b0c7eded-f1ee-46cb-94cf-accccd8b81cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-07786cd2-aa1d-47de-8d8d-e45ac6fec4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-026dfa82-ee27-4180-88c9-b90ead54da66,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-376ed9bc-519d-45cc-8b77-c5857f3d7af1,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-490a6c89-8949-48f6-805f-5a1dc734f235,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-b9d61576-2c6c-4d74-8fa0-2fda7d194231,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-5022317d-2f59-4e5f-97fc-14b9aaad2491,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-9a90904a-19ff-4d27-bee3-3caf60841cea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325877372-172.17.0.19-1597732883171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33474,DS-b0c7eded-f1ee-46cb-94cf-accccd8b81cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-07786cd2-aa1d-47de-8d8d-e45ac6fec4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-026dfa82-ee27-4180-88c9-b90ead54da66,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-376ed9bc-519d-45cc-8b77-c5857f3d7af1,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-490a6c89-8949-48f6-805f-5a1dc734f235,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-b9d61576-2c6c-4d74-8fa0-2fda7d194231,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-5022317d-2f59-4e5f-97fc-14b9aaad2491,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-9a90904a-19ff-4d27-bee3-3caf60841cea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5185
