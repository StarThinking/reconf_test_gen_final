reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1696574171-172.17.0.11-1597714036279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37012,DS-e874b5bc-af23-457a-b811-14dc919b5d36,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-958641de-8390-4b2d-97c1-e60e7a577909,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-2ea18508-8abb-40d3-b9cd-1ab540e9b0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-46a569b7-b33c-4eed-a826-21df8ac84a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-03866dd8-2ec7-477e-85c7-0bbedd3ba50f,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-f6a239cc-ef66-4f4d-86e8-77cdc77d107f,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-4e103baf-8961-4b10-acf1-428d0cc4cf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-23f7756c-aadf-4fe2-b4b7-f88142599b63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1696574171-172.17.0.11-1597714036279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37012,DS-e874b5bc-af23-457a-b811-14dc919b5d36,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-958641de-8390-4b2d-97c1-e60e7a577909,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-2ea18508-8abb-40d3-b9cd-1ab540e9b0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-46a569b7-b33c-4eed-a826-21df8ac84a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-03866dd8-2ec7-477e-85c7-0bbedd3ba50f,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-f6a239cc-ef66-4f4d-86e8-77cdc77d107f,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-4e103baf-8961-4b10-acf1-428d0cc4cf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-23f7756c-aadf-4fe2-b4b7-f88142599b63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-305919356-172.17.0.11-1597714154447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34470,DS-2bb9ca4d-4665-4568-b5c0-51d4b4cd7d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-d73be302-86ba-4930-bb90-1443078763d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-9e7d7e35-521b-4d6f-8214-3b96c0103dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-ade4092c-b0be-457e-acbd-d829a61b9dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-523eb46c-6a19-4143-bdf4-997b43b3cc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-b930070a-ec9d-4897-9591-61a27c9ceae6,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-310fa02c-7a32-4d5a-8299-02b548f4a84d,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-a1e42bcb-33f0-4a5e-b086-d9154d19a8b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-305919356-172.17.0.11-1597714154447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34470,DS-2bb9ca4d-4665-4568-b5c0-51d4b4cd7d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-d73be302-86ba-4930-bb90-1443078763d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-9e7d7e35-521b-4d6f-8214-3b96c0103dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-ade4092c-b0be-457e-acbd-d829a61b9dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-523eb46c-6a19-4143-bdf4-997b43b3cc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-b930070a-ec9d-4897-9591-61a27c9ceae6,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-310fa02c-7a32-4d5a-8299-02b548f4a84d,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-a1e42bcb-33f0-4a5e-b086-d9154d19a8b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-461012274-172.17.0.11-1597714187797:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42268,DS-9e769195-4d00-4485-a4c9-057d5d988ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-2113af2f-770c-4eee-8359-978d201f3185,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-54ac905e-31ac-4f5b-a659-c6dce15d725c,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-cbc03e3b-083c-43f9-9217-94954ad68887,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-efae7357-0c64-4e8c-869a-f3762869a6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-748ecbb5-4364-4db7-b60f-96d53fd15711,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-863f31c8-97d5-4063-8c4d-3ed9c4de47c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-006f7c42-62e9-457a-a3c9-4f12fe658549,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-461012274-172.17.0.11-1597714187797:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42268,DS-9e769195-4d00-4485-a4c9-057d5d988ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-2113af2f-770c-4eee-8359-978d201f3185,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-54ac905e-31ac-4f5b-a659-c6dce15d725c,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-cbc03e3b-083c-43f9-9217-94954ad68887,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-efae7357-0c64-4e8c-869a-f3762869a6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-748ecbb5-4364-4db7-b60f-96d53fd15711,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-863f31c8-97d5-4063-8c4d-3ed9c4de47c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-006f7c42-62e9-457a-a3c9-4f12fe658549,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-376017784-172.17.0.11-1597715245555:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41854,DS-ac00ec43-3106-4bec-8dd4-74093a8b1f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-e77e8a21-60b3-4851-beba-50cbafa07eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-78872574-39de-485d-8abb-e3241d653644,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-60c446be-324f-4551-a6c4-958898e21cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-e29fe421-d753-4524-bb2f-31e8e1199419,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-95a024e7-9459-4fa7-85f4-e1d47f658c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-32b66bbe-852a-4352-91f3-afbd02bb9b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-709d0b91-b308-44cf-a503-219ee227d93b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-376017784-172.17.0.11-1597715245555:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41854,DS-ac00ec43-3106-4bec-8dd4-74093a8b1f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-e77e8a21-60b3-4851-beba-50cbafa07eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-78872574-39de-485d-8abb-e3241d653644,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-60c446be-324f-4551-a6c4-958898e21cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-e29fe421-d753-4524-bb2f-31e8e1199419,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-95a024e7-9459-4fa7-85f4-e1d47f658c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-32b66bbe-852a-4352-91f3-afbd02bb9b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-709d0b91-b308-44cf-a503-219ee227d93b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1420942321-172.17.0.11-1597715557698:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40081,DS-170c09e5-0c36-413e-a9b6-f854748e9f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-161068e2-911a-406e-83c8-773ea075c3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-e705fe4f-491f-45ae-b69a-cc7300e2a489,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-6ccf98a4-847d-45ab-83d3-b55e5fc355a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-9cbbd479-a7c1-4d07-b729-1de53adde997,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-690c03ec-a996-4dcb-8c38-1010d51b5519,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-7741a6b0-c109-43ce-baf7-9148726c8953,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-0ccdae38-5f01-47d6-adf4-070856a15094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1420942321-172.17.0.11-1597715557698:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40081,DS-170c09e5-0c36-413e-a9b6-f854748e9f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-161068e2-911a-406e-83c8-773ea075c3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-e705fe4f-491f-45ae-b69a-cc7300e2a489,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-6ccf98a4-847d-45ab-83d3-b55e5fc355a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-9cbbd479-a7c1-4d07-b729-1de53adde997,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-690c03ec-a996-4dcb-8c38-1010d51b5519,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-7741a6b0-c109-43ce-baf7-9148726c8953,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-0ccdae38-5f01-47d6-adf4-070856a15094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-151203708-172.17.0.11-1597716154085:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37651,DS-4eb3316f-8204-4e84-b01a-038b20d8487d,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-56886a0d-72bf-4d62-b559-fe363b62366f,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-ac529984-d478-49b4-b374-d06e85fff1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-c1223bd4-2032-47cb-9840-f34c2294bd5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-9e7c708c-584e-4517-9cf7-ae487c97f8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-131d922b-f544-49fe-b4d5-cf4644429b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-2d1c8d28-14d2-44b8-bfdd-beff2517d174,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-a5282ca0-196f-4fe7-844f-4a4dec8f306e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-151203708-172.17.0.11-1597716154085:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37651,DS-4eb3316f-8204-4e84-b01a-038b20d8487d,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-56886a0d-72bf-4d62-b559-fe363b62366f,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-ac529984-d478-49b4-b374-d06e85fff1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-c1223bd4-2032-47cb-9840-f34c2294bd5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-9e7c708c-584e-4517-9cf7-ae487c97f8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-131d922b-f544-49fe-b4d5-cf4644429b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-2d1c8d28-14d2-44b8-bfdd-beff2517d174,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-a5282ca0-196f-4fe7-844f-4a4dec8f306e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1493551491-172.17.0.11-1597716355022:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46077,DS-380e85ee-caca-40c9-8f42-a8a7ab993cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-80a5d4d1-44d4-4183-99af-cad602efbcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-3c61d76a-8ce8-4832-ad8a-8ab417ad169b,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-f1072d8c-6d7e-4215-b817-4c21af45fc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-499a26e7-2363-4fa4-9b34-5079f69c98b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-0af4967c-7a6a-4de7-9cdf-e249c2e46d28,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-7fd3c89d-dcad-4124-bf4d-15f6949439c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-c9091ca3-249c-48fe-912a-f21479262ab5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1493551491-172.17.0.11-1597716355022:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46077,DS-380e85ee-caca-40c9-8f42-a8a7ab993cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-80a5d4d1-44d4-4183-99af-cad602efbcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-3c61d76a-8ce8-4832-ad8a-8ab417ad169b,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-f1072d8c-6d7e-4215-b817-4c21af45fc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-499a26e7-2363-4fa4-9b34-5079f69c98b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-0af4967c-7a6a-4de7-9cdf-e249c2e46d28,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-7fd3c89d-dcad-4124-bf4d-15f6949439c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-c9091ca3-249c-48fe-912a-f21479262ab5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1878284037-172.17.0.11-1597716712799:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46752,DS-f00298ee-182c-423f-be35-2b6b1cf1398e,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-7895abaa-e66f-46bd-8f79-0e1538292137,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-76a02dee-d6c6-4a64-9dbd-a63fd05ecea1,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-6ba49492-b61f-4741-b1d1-5421f1775be5,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-7a33784d-01ad-4291-a079-8d8d362b6827,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-2e835dac-c107-4e2d-a6b5-e31f2cfa9f60,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-fbc0219b-4271-48a5-aeba-6b5ef62980cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-6167910c-d708-45a2-863e-c4d8c679fb96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1878284037-172.17.0.11-1597716712799:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46752,DS-f00298ee-182c-423f-be35-2b6b1cf1398e,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-7895abaa-e66f-46bd-8f79-0e1538292137,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-76a02dee-d6c6-4a64-9dbd-a63fd05ecea1,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-6ba49492-b61f-4741-b1d1-5421f1775be5,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-7a33784d-01ad-4291-a079-8d8d362b6827,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-2e835dac-c107-4e2d-a6b5-e31f2cfa9f60,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-fbc0219b-4271-48a5-aeba-6b5ef62980cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-6167910c-d708-45a2-863e-c4d8c679fb96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1854144131-172.17.0.11-1597716821435:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36363,DS-111b53c8-07ab-4f4d-b379-8db2467396ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-8bac8d38-42b9-4480-b4fd-0952c95f9af9,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-a44f1ee1-9ca4-4a39-8a88-48a7f7719315,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-3463e348-6a0c-4ce2-ba91-dc89cb74a895,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-65b9dd04-0548-4829-99e5-c4fb2b4cdc24,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-bb1a35f8-5b4c-4074-92ee-e5742045d3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-fc83274a-d549-4fc1-bc25-5ef6df92a83d,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-62af1075-c8c7-44d3-9611-255ab4f6a232,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1854144131-172.17.0.11-1597716821435:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36363,DS-111b53c8-07ab-4f4d-b379-8db2467396ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-8bac8d38-42b9-4480-b4fd-0952c95f9af9,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-a44f1ee1-9ca4-4a39-8a88-48a7f7719315,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-3463e348-6a0c-4ce2-ba91-dc89cb74a895,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-65b9dd04-0548-4829-99e5-c4fb2b4cdc24,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-bb1a35f8-5b4c-4074-92ee-e5742045d3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-fc83274a-d549-4fc1-bc25-5ef6df92a83d,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-62af1075-c8c7-44d3-9611-255ab4f6a232,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-58123167-172.17.0.11-1597717165325:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40035,DS-0f268054-973f-4979-bf89-066815ccc105,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-74d9e4a8-fca0-4ad7-838d-8a1c4e23adfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-7d64570f-c7ad-4176-93f5-0c8f9d173372,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-e78a905c-f01d-4f40-81e4-4856cdb57cce,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-bff90a91-bba4-497c-83ae-dc99615e5af9,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-6d293a9b-679f-45db-945b-a0423bf5ab62,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-f59778bc-b50c-4073-9949-128feb5aba21,DISK], DatanodeInfoWithStorage[127.0.0.1:37954,DS-e46c5ab8-c247-4bf9-9af8-e81c2b47f976,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-58123167-172.17.0.11-1597717165325:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40035,DS-0f268054-973f-4979-bf89-066815ccc105,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-74d9e4a8-fca0-4ad7-838d-8a1c4e23adfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-7d64570f-c7ad-4176-93f5-0c8f9d173372,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-e78a905c-f01d-4f40-81e4-4856cdb57cce,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-bff90a91-bba4-497c-83ae-dc99615e5af9,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-6d293a9b-679f-45db-945b-a0423bf5ab62,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-f59778bc-b50c-4073-9949-128feb5aba21,DISK], DatanodeInfoWithStorage[127.0.0.1:37954,DS-e46c5ab8-c247-4bf9-9af8-e81c2b47f976,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1472997407-172.17.0.11-1597717945007:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35525,DS-ef2ef792-43fa-4578-8c92-d1034d9e4697,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-923c98e8-8f9e-4160-8a41-2dbfa841580f,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-0c4a4851-9ff4-4bf4-80a8-c4e3895932e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-3a9b867c-4515-4a90-a104-312349cbc103,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-dcf7b308-3235-4429-b55b-5725ec28783b,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-5f13b509-2048-469d-822e-d60b4b6b11f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-5c0a419c-2bb5-4abf-861c-7038893d1775,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-4f534363-94be-4201-84bd-b0d6a503e541,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1472997407-172.17.0.11-1597717945007:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35525,DS-ef2ef792-43fa-4578-8c92-d1034d9e4697,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-923c98e8-8f9e-4160-8a41-2dbfa841580f,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-0c4a4851-9ff4-4bf4-80a8-c4e3895932e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-3a9b867c-4515-4a90-a104-312349cbc103,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-dcf7b308-3235-4429-b55b-5725ec28783b,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-5f13b509-2048-469d-822e-d60b4b6b11f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-5c0a419c-2bb5-4abf-861c-7038893d1775,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-4f534363-94be-4201-84bd-b0d6a503e541,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-233032126-172.17.0.11-1597718268436:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32851,DS-ec57247c-ab65-43be-8174-d68d8ccfff0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-f7cd487c-3d23-4daf-bd4b-3d49d14fa972,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-0a28b388-8227-426a-94ad-fa866fecabba,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-6f33738b-245b-4417-8a70-3314128c000a,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-d041fa84-4fad-49ad-84cc-6d9a6c18de2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-76567963-f37e-446a-8f54-e18eed016b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-0b9dc39d-bed7-4c69-ac83-dbee78e0417e,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-3e5b7478-5c8a-43d5-b081-3e965ec1e50e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-233032126-172.17.0.11-1597718268436:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32851,DS-ec57247c-ab65-43be-8174-d68d8ccfff0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-f7cd487c-3d23-4daf-bd4b-3d49d14fa972,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-0a28b388-8227-426a-94ad-fa866fecabba,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-6f33738b-245b-4417-8a70-3314128c000a,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-d041fa84-4fad-49ad-84cc-6d9a6c18de2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-76567963-f37e-446a-8f54-e18eed016b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-0b9dc39d-bed7-4c69-ac83-dbee78e0417e,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-3e5b7478-5c8a-43d5-b081-3e965ec1e50e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1924977598-172.17.0.11-1597718428273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41780,DS-7a7867f0-01f4-4ca1-89ec-55f82095bde5,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-5ec62305-39cc-4769-bdb9-49dc0c9629ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-92ba4dea-6c3a-4e81-8508-84b832ad49f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-3148093b-24a8-42a6-876f-debde1aeef57,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-771611ab-27ff-4472-8f21-b679a462b4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-4d35f055-f248-40cd-84b4-887778c9cd21,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-e4d122cb-38c1-47c7-ae6a-022523c13825,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-4344384a-cad5-4802-a960-cb19f481841a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1924977598-172.17.0.11-1597718428273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41780,DS-7a7867f0-01f4-4ca1-89ec-55f82095bde5,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-5ec62305-39cc-4769-bdb9-49dc0c9629ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-92ba4dea-6c3a-4e81-8508-84b832ad49f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-3148093b-24a8-42a6-876f-debde1aeef57,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-771611ab-27ff-4472-8f21-b679a462b4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-4d35f055-f248-40cd-84b4-887778c9cd21,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-e4d122cb-38c1-47c7-ae6a-022523c13825,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-4344384a-cad5-4802-a960-cb19f481841a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970896140-172.17.0.11-1597718464696:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43091,DS-42625b8a-e79d-49a5-b9ca-179c95a76b02,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-944dbafd-644a-4868-a7e9-0146198ad22c,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-f8e5049e-b3b1-4969-be4b-29c54b9977e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-a058c4b2-3c99-4279-9bcc-69e14dbffa95,DISK], DatanodeInfoWithStorage[127.0.0.1:33086,DS-31d2b85b-8c3a-4764-a5b6-a50d0f48a4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-412460d6-8413-499c-9ee3-27a03a8fb0be,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-a3e879fd-4ad4-49e2-92e1-b265bf9658c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-bc7cc491-16d8-4228-9f58-6bcfebb03e47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970896140-172.17.0.11-1597718464696:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43091,DS-42625b8a-e79d-49a5-b9ca-179c95a76b02,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-944dbafd-644a-4868-a7e9-0146198ad22c,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-f8e5049e-b3b1-4969-be4b-29c54b9977e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-a058c4b2-3c99-4279-9bcc-69e14dbffa95,DISK], DatanodeInfoWithStorage[127.0.0.1:33086,DS-31d2b85b-8c3a-4764-a5b6-a50d0f48a4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-412460d6-8413-499c-9ee3-27a03a8fb0be,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-a3e879fd-4ad4-49e2-92e1-b265bf9658c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-bc7cc491-16d8-4228-9f58-6bcfebb03e47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-632311995-172.17.0.11-1597718854950:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42048,DS-b3c77da1-aa55-4651-94b0-6cf2334eda2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-60421bde-4d48-4734-b356-ef7ad63d55f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-818ba7a2-552c-4dfd-95c4-900614432aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-0907b152-98cb-44d3-94b9-3b60ee091f41,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-c56cfeb4-eba1-4638-a5c1-01ed8060afe9,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-d46bf787-9f6f-4f7e-b93b-d406bcc2dedb,DISK], DatanodeInfoWithStorage[127.0.0.1:35651,DS-bdab85d5-65ae-4f06-b627-f017315487c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-86d17797-2819-4f71-9d56-56ccee7db8ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-632311995-172.17.0.11-1597718854950:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42048,DS-b3c77da1-aa55-4651-94b0-6cf2334eda2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-60421bde-4d48-4734-b356-ef7ad63d55f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-818ba7a2-552c-4dfd-95c4-900614432aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-0907b152-98cb-44d3-94b9-3b60ee091f41,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-c56cfeb4-eba1-4638-a5c1-01ed8060afe9,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-d46bf787-9f6f-4f7e-b93b-d406bcc2dedb,DISK], DatanodeInfoWithStorage[127.0.0.1:35651,DS-bdab85d5-65ae-4f06-b627-f017315487c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-86d17797-2819-4f71-9d56-56ccee7db8ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1949003553-172.17.0.11-1597719290885:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44917,DS-9c0d80d0-7f5d-4cc3-b031-8b460851b4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-f6713f39-b339-40c8-baf5-862a5f9fea2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-c103caea-4f22-4a0e-b97d-55972bef2b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-c2afe88d-8e3e-4f31-89ba-3ceca4c1b500,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-497ad4a7-49e0-4f34-a664-2396b3ee46e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-01825a38-444e-465d-b070-a516d4eb9bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-62f48a0d-4bb2-4286-8d2e-2669f8305cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-62386241-82e1-4f25-905e-23615e907b64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1949003553-172.17.0.11-1597719290885:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44917,DS-9c0d80d0-7f5d-4cc3-b031-8b460851b4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-f6713f39-b339-40c8-baf5-862a5f9fea2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-c103caea-4f22-4a0e-b97d-55972bef2b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-c2afe88d-8e3e-4f31-89ba-3ceca4c1b500,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-497ad4a7-49e0-4f34-a664-2396b3ee46e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-01825a38-444e-465d-b070-a516d4eb9bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-62f48a0d-4bb2-4286-8d2e-2669f8305cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-62386241-82e1-4f25-905e-23615e907b64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2063286709-172.17.0.11-1597719328318:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38064,DS-8c029245-9ddf-472b-bf15-687ec7522db7,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-9b7d34a5-b6a0-4594-907f-432008748dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-de9f6db8-8cd8-4f4f-a9ac-d3c1f965a9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-06d2de77-d975-40a4-b76a-80877e32b8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-b06c973b-5d68-438f-9b7f-8bb62794ea5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-413ed314-672b-493c-a572-685288ffc0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-40e0b633-a176-43cf-9adb-4c63e22774d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-49bf586a-9256-4cce-9571-f3bf017e7ef8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2063286709-172.17.0.11-1597719328318:blk_-9223372036854775776_1002; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38064,DS-8c029245-9ddf-472b-bf15-687ec7522db7,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-9b7d34a5-b6a0-4594-907f-432008748dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-de9f6db8-8cd8-4f4f-a9ac-d3c1f965a9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-06d2de77-d975-40a4-b76a-80877e32b8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-b06c973b-5d68-438f-9b7f-8bb62794ea5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-413ed314-672b-493c-a572-685288ffc0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-40e0b633-a176-43cf-9adb-4c63e22774d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-49bf586a-9256-4cce-9571-f3bf017e7ef8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:NameNode
v1: 6291456
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1952132161-172.17.0.11-1597719371753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40840,DS-98fffecc-4986-46f5-b051-0149102633cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-555fd664-6735-4c75-a835-cf79b112a29b,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-be45a905-2502-43d7-9d43-b932750758cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-14367287-3301-4254-8e0d-bf8126510d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-e80eb587-6c15-4393-bbc9-1a7a0afe10dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-dd31c0fb-16d5-4993-903a-68cf90de0690,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-c1443a6a-81cb-430e-81b3-7778ada25421,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-5c49dd04-bc99-4f06-aebb-19f28cfa2214,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1952132161-172.17.0.11-1597719371753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40840,DS-98fffecc-4986-46f5-b051-0149102633cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-555fd664-6735-4c75-a835-cf79b112a29b,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-be45a905-2502-43d7-9d43-b932750758cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-14367287-3301-4254-8e0d-bf8126510d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39883,DS-e80eb587-6c15-4393-bbc9-1a7a0afe10dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-dd31c0fb-16d5-4993-903a-68cf90de0690,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-c1443a6a-81cb-430e-81b3-7778ada25421,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-5c49dd04-bc99-4f06-aebb-19f28cfa2214,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5782
