reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328258774-172.17.0.17-1597642123377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40466,DS-0b002bff-d418-4a14-aa6f-49b7441dd334,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-014eca6f-9926-49fe-9298-05daf4c759e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-4dae05ab-2429-40ce-97e5-0d8baeddd028,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-f680966d-9126-4f20-b744-18b936f8945d,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-e2b7b3c6-ccd6-493e-89cd-82a7b42a151e,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-dcdcd465-5f32-4e7c-bba4-b5ef195dea22,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-22b1c2fc-a9aa-4e82-b933-6ab397781e57,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-8ca4873c-57b0-463f-9965-c25ffd2c5310,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328258774-172.17.0.17-1597642123377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40466,DS-0b002bff-d418-4a14-aa6f-49b7441dd334,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-014eca6f-9926-49fe-9298-05daf4c759e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-4dae05ab-2429-40ce-97e5-0d8baeddd028,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-f680966d-9126-4f20-b744-18b936f8945d,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-e2b7b3c6-ccd6-493e-89cd-82a7b42a151e,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-dcdcd465-5f32-4e7c-bba4-b5ef195dea22,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-22b1c2fc-a9aa-4e82-b933-6ab397781e57,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-8ca4873c-57b0-463f-9965-c25ffd2c5310,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-113684682-172.17.0.17-1597642242434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34780,DS-86898c23-108a-4ed4-b836-6eeedf86d167,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-9bccc114-f11f-410c-ada8-1b7916dec061,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-12c8b6ec-61b4-4f98-9101-d74f2606a4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-60e1dd84-aa05-4988-b8de-5192e04b15e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-2c95d8ed-1a47-4770-999e-e5e409b05339,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-9e3bc32f-0aa7-4461-a120-1b4fa06e1bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-03e57324-d417-40aa-955b-e2fff7b13086,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-368bdb5e-790c-474c-b8e9-06cbed7820ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-113684682-172.17.0.17-1597642242434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34780,DS-86898c23-108a-4ed4-b836-6eeedf86d167,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-9bccc114-f11f-410c-ada8-1b7916dec061,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-12c8b6ec-61b4-4f98-9101-d74f2606a4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-60e1dd84-aa05-4988-b8de-5192e04b15e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-2c95d8ed-1a47-4770-999e-e5e409b05339,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-9e3bc32f-0aa7-4461-a120-1b4fa06e1bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-03e57324-d417-40aa-955b-e2fff7b13086,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-368bdb5e-790c-474c-b8e9-06cbed7820ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1048532937-172.17.0.17-1597642285946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42430,DS-ca412310-1df4-424d-8ad3-8c1f6e011f48,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-0bcdc644-dd2a-4714-a3b9-d314fe7eda74,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-bd1ef67a-0ade-4557-b4ca-91d68bfc4504,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-9d9e6bf9-27fa-4bf0-9f1b-62bc71f95151,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-8fe031b0-45bd-4b91-9e15-75acb3755381,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-4c62cf80-9657-41af-87f5-2687038144b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-0dbd668b-39fb-4e9b-a9c0-ce15b735db8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-fab96564-61e0-4024-b2c6-fc2ea601b17a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1048532937-172.17.0.17-1597642285946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42430,DS-ca412310-1df4-424d-8ad3-8c1f6e011f48,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-0bcdc644-dd2a-4714-a3b9-d314fe7eda74,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-bd1ef67a-0ade-4557-b4ca-91d68bfc4504,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-9d9e6bf9-27fa-4bf0-9f1b-62bc71f95151,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-8fe031b0-45bd-4b91-9e15-75acb3755381,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-4c62cf80-9657-41af-87f5-2687038144b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-0dbd668b-39fb-4e9b-a9c0-ce15b735db8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-fab96564-61e0-4024-b2c6-fc2ea601b17a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514756179-172.17.0.17-1597642396686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41409,DS-6c7ce456-3098-4c3b-b56c-8fc8e204a009,DISK], DatanodeInfoWithStorage[127.0.0.1:34491,DS-d5e87980-5f08-4fe8-8902-5084d2d48c51,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-3263fba3-bfdc-4e79-b16f-2cbec20dcf29,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-20076bfc-a4c4-4f40-9949-7a7bddfd5b93,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-2ee5f6b9-b3d4-4b1f-84c4-0a48c1405268,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-e4a6aba8-9bd3-4661-bb18-a784bc8509fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-ab2917b7-c8a6-4046-8205-997ba8752966,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-1ddcefb0-392d-4b39-9bde-8e4b3cf6b6f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514756179-172.17.0.17-1597642396686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41409,DS-6c7ce456-3098-4c3b-b56c-8fc8e204a009,DISK], DatanodeInfoWithStorage[127.0.0.1:34491,DS-d5e87980-5f08-4fe8-8902-5084d2d48c51,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-3263fba3-bfdc-4e79-b16f-2cbec20dcf29,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-20076bfc-a4c4-4f40-9949-7a7bddfd5b93,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-2ee5f6b9-b3d4-4b1f-84c4-0a48c1405268,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-e4a6aba8-9bd3-4661-bb18-a784bc8509fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-ab2917b7-c8a6-4046-8205-997ba8752966,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-1ddcefb0-392d-4b39-9bde-8e4b3cf6b6f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1969036054-172.17.0.17-1597642585690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36365,DS-7427ec9e-9227-4663-bbfc-f7613fa0cea4,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-241938b7-edc1-4b74-b089-3480b30240d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-35527f96-c54c-48fc-95d7-0eedbae22c14,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-2b42f881-eab9-4455-bd58-f93ce528059b,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-666337fd-015c-4b5b-a25d-43b0eadff3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-a018969b-d162-4009-8f89-a662d46651cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-13b39e2a-c21f-4e7b-8604-51cdc9b8f212,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-7ab1c6f3-025a-49ec-8494-2718ad6fb155,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1969036054-172.17.0.17-1597642585690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36365,DS-7427ec9e-9227-4663-bbfc-f7613fa0cea4,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-241938b7-edc1-4b74-b089-3480b30240d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-35527f96-c54c-48fc-95d7-0eedbae22c14,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-2b42f881-eab9-4455-bd58-f93ce528059b,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-666337fd-015c-4b5b-a25d-43b0eadff3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-a018969b-d162-4009-8f89-a662d46651cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-13b39e2a-c21f-4e7b-8604-51cdc9b8f212,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-7ab1c6f3-025a-49ec-8494-2718ad6fb155,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-823012952-172.17.0.17-1597642960463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34217,DS-24ba0cb1-84ae-42c2-a81b-83362ea84e73,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-6038e537-7f86-4ebd-992d-3021b546d834,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-d25ba9ed-c974-409a-beec-af44bc446bad,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-604172bd-7b38-4810-bf41-14784226b7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-fcf8f0f2-94ac-4fc1-b184-6400299b7219,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-109a7785-85fb-4464-bdd4-76befad2473a,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-dbe331ed-6d1f-4853-a5fd-410340378cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-e9277cfa-bfcb-4d73-aff2-974182183a8a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-823012952-172.17.0.17-1597642960463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34217,DS-24ba0cb1-84ae-42c2-a81b-83362ea84e73,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-6038e537-7f86-4ebd-992d-3021b546d834,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-d25ba9ed-c974-409a-beec-af44bc446bad,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-604172bd-7b38-4810-bf41-14784226b7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-fcf8f0f2-94ac-4fc1-b184-6400299b7219,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-109a7785-85fb-4464-bdd4-76befad2473a,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-dbe331ed-6d1f-4853-a5fd-410340378cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-e9277cfa-bfcb-4d73-aff2-974182183a8a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-504425013-172.17.0.17-1597643033764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38551,DS-fdb91229-0546-4315-ac45-f9b38462a97f,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-ef3194e0-f184-49a3-a35f-66ea1b19ecc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-d4df9dfd-9efd-4a0b-bceb-65c717ecfc14,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-fd75e329-ea89-4f3c-95d6-7aa87c7083b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-5ff1b9fe-2153-4fdb-ac26-68acad72b4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-b8e296aa-1d84-48b3-a654-a440050c08d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-1644a4e8-4ad1-42f2-8d4c-fb2024500949,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-535ef5e8-4f44-40fc-8ce9-ccd1976c522b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-504425013-172.17.0.17-1597643033764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38551,DS-fdb91229-0546-4315-ac45-f9b38462a97f,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-ef3194e0-f184-49a3-a35f-66ea1b19ecc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-d4df9dfd-9efd-4a0b-bceb-65c717ecfc14,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-fd75e329-ea89-4f3c-95d6-7aa87c7083b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-5ff1b9fe-2153-4fdb-ac26-68acad72b4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-b8e296aa-1d84-48b3-a654-a440050c08d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-1644a4e8-4ad1-42f2-8d4c-fb2024500949,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-535ef5e8-4f44-40fc-8ce9-ccd1976c522b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343461641-172.17.0.17-1597643287234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46646,DS-b2aabb99-a69d-4905-9db0-dee44924806f,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-155f5022-4af5-47ab-a33d-72df3666bebe,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-7c735cd4-d453-4d7c-8031-7d87a328060e,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-8c2a9901-985b-4e35-83b4-2ebfcd595c57,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-8a02ad18-2d13-4f99-a4c9-bb6d7e281478,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-917acb27-8af5-45e7-b7b0-b0e7212a32a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-961b3130-9079-44a1-8053-79e8fb1145aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-529db6b8-bf42-4dd4-a7d7-6ac7282c2b04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343461641-172.17.0.17-1597643287234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46646,DS-b2aabb99-a69d-4905-9db0-dee44924806f,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-155f5022-4af5-47ab-a33d-72df3666bebe,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-7c735cd4-d453-4d7c-8031-7d87a328060e,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-8c2a9901-985b-4e35-83b4-2ebfcd595c57,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-8a02ad18-2d13-4f99-a4c9-bb6d7e281478,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-917acb27-8af5-45e7-b7b0-b0e7212a32a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-961b3130-9079-44a1-8053-79e8fb1145aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-529db6b8-bf42-4dd4-a7d7-6ac7282c2b04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-313922146-172.17.0.17-1597643368698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37226,DS-27add7b3-ef9a-4b83-9dc6-0de1f8af9c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-36794c07-85b3-40ff-a2c9-680b8a720164,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-a18a62e5-f6ad-4721-8664-c90d8bc6c95f,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-2ab4ef2d-9b95-47c7-ba3c-ccb1466035ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-32bd07f3-a40f-4328-bb0d-2f5dc61b945c,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-d43560c4-3fb1-43ba-98a8-2d8972134dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-64cb4056-0c0d-40ac-a8cd-ea81d1a97ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-92197a24-685e-4ba0-aab5-cca72c13bdeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-313922146-172.17.0.17-1597643368698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37226,DS-27add7b3-ef9a-4b83-9dc6-0de1f8af9c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-36794c07-85b3-40ff-a2c9-680b8a720164,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-a18a62e5-f6ad-4721-8664-c90d8bc6c95f,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-2ab4ef2d-9b95-47c7-ba3c-ccb1466035ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-32bd07f3-a40f-4328-bb0d-2f5dc61b945c,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-d43560c4-3fb1-43ba-98a8-2d8972134dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-64cb4056-0c0d-40ac-a8cd-ea81d1a97ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-92197a24-685e-4ba0-aab5-cca72c13bdeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-703305331-172.17.0.17-1597644100926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41761,DS-938faad2-b3e5-42ed-8ef0-1e7480876c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-8c8d22c4-053e-4521-a7ab-06f1f271f89d,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-77150316-b75b-402d-a8f2-058726c936e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-c9f167ed-ee34-4efe-a68d-3f7e7cbde9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-78b23d41-cac0-4641-86a1-3b08685334bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33616,DS-d517afe2-355e-42a5-aef6-f94b903e10a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-101681e0-0c51-43d6-aa23-98fc9b46c628,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-b9503423-1c5f-4bc7-9220-25192c0dc4ce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-703305331-172.17.0.17-1597644100926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41761,DS-938faad2-b3e5-42ed-8ef0-1e7480876c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-8c8d22c4-053e-4521-a7ab-06f1f271f89d,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-77150316-b75b-402d-a8f2-058726c936e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-c9f167ed-ee34-4efe-a68d-3f7e7cbde9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-78b23d41-cac0-4641-86a1-3b08685334bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33616,DS-d517afe2-355e-42a5-aef6-f94b903e10a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-101681e0-0c51-43d6-aa23-98fc9b46c628,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-b9503423-1c5f-4bc7-9220-25192c0dc4ce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1578168065-172.17.0.17-1597644213862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39956,DS-e1be14c3-70cd-4975-8069-76c87f5f5477,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-7f72cd9b-b9a5-4675-bb86-4da3a48a2fde,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-e6bfe457-a072-48ea-a91d-3faba99f5542,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-04681f9d-6e9e-417b-abed-e31ae150b06e,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-03c1b396-f4c7-4057-b94e-0347e0176644,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-49bb7d3d-9456-449d-9a65-2d64598f305f,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-fa9a3dfd-9187-4524-9b0a-e6e6fc61af72,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-8ffc20f0-d654-4b15-983d-8f8d055e19e3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1578168065-172.17.0.17-1597644213862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39956,DS-e1be14c3-70cd-4975-8069-76c87f5f5477,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-7f72cd9b-b9a5-4675-bb86-4da3a48a2fde,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-e6bfe457-a072-48ea-a91d-3faba99f5542,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-04681f9d-6e9e-417b-abed-e31ae150b06e,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-03c1b396-f4c7-4057-b94e-0347e0176644,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-49bb7d3d-9456-449d-9a65-2d64598f305f,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-fa9a3dfd-9187-4524-9b0a-e6e6fc61af72,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-8ffc20f0-d654-4b15-983d-8f8d055e19e3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-565373221-172.17.0.17-1597644572252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46194,DS-a35a9f74-8d96-4810-80a2-c72dc9e11294,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-7f9e9489-3583-42fe-9b44-4ab319406b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-065c77c3-d26b-4315-b89d-9c70bb5ce37d,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-5ec7e0f4-b4a1-47d5-bee4-cf733b6b2b75,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-880750ef-4848-45f4-b337-bffed54977c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-ac06a3db-6baa-42a1-88cf-67181d444bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-ae79a782-c794-446a-8f81-3bed223971d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-506df33b-87be-4a7e-9a17-74c3d51854aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-565373221-172.17.0.17-1597644572252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46194,DS-a35a9f74-8d96-4810-80a2-c72dc9e11294,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-7f9e9489-3583-42fe-9b44-4ab319406b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-065c77c3-d26b-4315-b89d-9c70bb5ce37d,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-5ec7e0f4-b4a1-47d5-bee4-cf733b6b2b75,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-880750ef-4848-45f4-b337-bffed54977c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-ac06a3db-6baa-42a1-88cf-67181d444bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-ae79a782-c794-446a-8f81-3bed223971d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-506df33b-87be-4a7e-9a17-74c3d51854aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712406399-172.17.0.17-1597644645375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34987,DS-9d7d5c01-07e7-44dd-8037-bc7e281d49fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-6c58b481-cefe-4424-97ca-b4933be8976e,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-0a1c9750-ba41-44a5-89f4-15d89952fc04,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-5b02b42e-5ddb-42a3-ae3b-41a93d9eeec3,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-7389d48a-7110-465a-8282-53d97182ab27,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-2c9fe67e-6529-42f2-8a57-9f3fb74937a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-cc3d36d4-691a-4f90-ab64-632a8a5c252b,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-2d012766-2649-463d-9d11-2785f2b5f0fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712406399-172.17.0.17-1597644645375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34987,DS-9d7d5c01-07e7-44dd-8037-bc7e281d49fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-6c58b481-cefe-4424-97ca-b4933be8976e,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-0a1c9750-ba41-44a5-89f4-15d89952fc04,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-5b02b42e-5ddb-42a3-ae3b-41a93d9eeec3,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-7389d48a-7110-465a-8282-53d97182ab27,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-2c9fe67e-6529-42f2-8a57-9f3fb74937a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-cc3d36d4-691a-4f90-ab64-632a8a5c252b,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-2d012766-2649-463d-9d11-2785f2b5f0fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817124805-172.17.0.17-1597644922791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34766,DS-1ca83d0f-48c8-4ffe-a579-ccd506306586,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-77d4a3cc-6468-42a7-975d-4fe0019afc35,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-094193e6-574a-4d51-8933-154f15fc88e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-fbd10bbd-d887-4231-8317-4ebcb39b1e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-0d0e1266-1af1-466f-bee3-78c5f3f1caba,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-cf3ba31f-a9db-4e61-b557-9d5aa450990f,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-6d2405fc-c90c-4707-9b1c-881099d6c8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37011,DS-ea856ba3-59a9-4332-aee8-58ee2c172fbe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817124805-172.17.0.17-1597644922791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34766,DS-1ca83d0f-48c8-4ffe-a579-ccd506306586,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-77d4a3cc-6468-42a7-975d-4fe0019afc35,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-094193e6-574a-4d51-8933-154f15fc88e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-fbd10bbd-d887-4231-8317-4ebcb39b1e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-0d0e1266-1af1-466f-bee3-78c5f3f1caba,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-cf3ba31f-a9db-4e61-b557-9d5aa450990f,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-6d2405fc-c90c-4707-9b1c-881099d6c8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37011,DS-ea856ba3-59a9-4332-aee8-58ee2c172fbe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-729026544-172.17.0.17-1597645072794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36631,DS-52c87fe8-a193-4387-83bc-bc096f7884df,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-5b7c2a99-07b6-4a38-ab1e-b76a3ca7616d,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-cd070040-17a3-477d-8be3-e678af763f02,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-0ae9b6fb-d6de-460b-b606-e6a7364c77fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-5cf97842-f156-4791-b4ee-2e35bcec403a,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-2c0bb0b0-4864-458e-8511-8550d5825616,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-c499d36f-bc99-4f09-b9dd-fa1607d713bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-64cddb9b-0556-4a93-8f71-41e6c7722107,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-729026544-172.17.0.17-1597645072794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36631,DS-52c87fe8-a193-4387-83bc-bc096f7884df,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-5b7c2a99-07b6-4a38-ab1e-b76a3ca7616d,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-cd070040-17a3-477d-8be3-e678af763f02,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-0ae9b6fb-d6de-460b-b606-e6a7364c77fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-5cf97842-f156-4791-b4ee-2e35bcec403a,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-2c0bb0b0-4864-458e-8511-8550d5825616,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-c499d36f-bc99-4f09-b9dd-fa1607d713bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-64cddb9b-0556-4a93-8f71-41e6c7722107,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1286124260-172.17.0.17-1597645208205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40187,DS-631eb585-329c-4332-b71c-98ad6e6154bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-b777f239-570f-434a-b955-61c050bfca47,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-5248a55b-ccba-41c5-9057-354b97487b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-c1470e05-c42e-4337-ac14-cdb276de510b,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-2ad159ae-3c6a-44b8-b367-081ef2ca8584,DISK], DatanodeInfoWithStorage[127.0.0.1:38183,DS-173f1efa-653e-4c6c-a125-7cb1286ede56,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-6ad88ac1-57ff-4d0d-8baa-e87b056306d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-b5a8a08e-003a-444b-8b8d-935e489f07de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1286124260-172.17.0.17-1597645208205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40187,DS-631eb585-329c-4332-b71c-98ad6e6154bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-b777f239-570f-434a-b955-61c050bfca47,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-5248a55b-ccba-41c5-9057-354b97487b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-c1470e05-c42e-4337-ac14-cdb276de510b,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-2ad159ae-3c6a-44b8-b367-081ef2ca8584,DISK], DatanodeInfoWithStorage[127.0.0.1:38183,DS-173f1efa-653e-4c6c-a125-7cb1286ede56,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-6ad88ac1-57ff-4d0d-8baa-e87b056306d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-b5a8a08e-003a-444b-8b8d-935e489f07de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-370961757-172.17.0.17-1597645476346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45686,DS-7038a5f2-303f-45ef-b910-fbb411e91fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-653bb164-8cb9-471f-959b-61c9fecdad5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-0006f14f-700c-476e-af0a-cf7e93267d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-f9fc23f5-cd08-4e4a-b18e-04a239cd50ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-e0b8ffac-512c-4100-9e4f-21c303026e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-cdc6591b-ec89-4714-9857-c7fa3de345b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-2d3b9996-b149-4f5a-a880-e454cfcede8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-5d5e0dc2-4232-435f-8324-1f82eb70e167,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-370961757-172.17.0.17-1597645476346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45686,DS-7038a5f2-303f-45ef-b910-fbb411e91fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-653bb164-8cb9-471f-959b-61c9fecdad5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-0006f14f-700c-476e-af0a-cf7e93267d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-f9fc23f5-cd08-4e4a-b18e-04a239cd50ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-e0b8ffac-512c-4100-9e4f-21c303026e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-cdc6591b-ec89-4714-9857-c7fa3de345b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-2d3b9996-b149-4f5a-a880-e454cfcede8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-5d5e0dc2-4232-435f-8324-1f82eb70e167,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146957029-172.17.0.17-1597645553857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34061,DS-c5814919-f4e0-4852-9463-e0a24292c28f,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-13940cdc-bcd3-4410-996a-3de540e59e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-a39f24db-2739-4b61-bee4-e5c565cdbfd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-1f5deda5-afd2-42ed-9f1f-dd5d309de607,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-2b36a922-d069-4df7-89ec-aab42493cbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-741ae9f1-fd1c-4e55-8cd7-5b83aa8f5dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-528b7365-47de-4aad-b60e-842a9d7fc800,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-1cde9418-9043-45bb-a7f2-cbd4a5cce1a1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146957029-172.17.0.17-1597645553857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34061,DS-c5814919-f4e0-4852-9463-e0a24292c28f,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-13940cdc-bcd3-4410-996a-3de540e59e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-a39f24db-2739-4b61-bee4-e5c565cdbfd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-1f5deda5-afd2-42ed-9f1f-dd5d309de607,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-2b36a922-d069-4df7-89ec-aab42493cbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-741ae9f1-fd1c-4e55-8cd7-5b83aa8f5dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-528b7365-47de-4aad-b60e-842a9d7fc800,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-1cde9418-9043-45bb-a7f2-cbd4a5cce1a1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864863821-172.17.0.17-1597645671254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34940,DS-93e61fea-e47a-4fa0-9ef6-fd325b0ae02e,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-2381ee59-b017-477b-805a-7db4fa07637a,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-b09c919f-5282-411b-a473-cde4a99d026e,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-5280ab3f-1f1a-4de0-8a6e-5222fbc35879,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-58ec1800-6e8b-45b2-8f1a-c9b10e1c8657,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-e415ed43-4baf-4802-838d-1872aabc0be2,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-f08f8753-4cea-49f1-a958-1608f35b8990,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-373eeb33-5ebe-47a1-8fde-2ca3b26323be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864863821-172.17.0.17-1597645671254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34940,DS-93e61fea-e47a-4fa0-9ef6-fd325b0ae02e,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-2381ee59-b017-477b-805a-7db4fa07637a,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-b09c919f-5282-411b-a473-cde4a99d026e,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-5280ab3f-1f1a-4de0-8a6e-5222fbc35879,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-58ec1800-6e8b-45b2-8f1a-c9b10e1c8657,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-e415ed43-4baf-4802-838d-1872aabc0be2,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-f08f8753-4cea-49f1-a958-1608f35b8990,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-373eeb33-5ebe-47a1-8fde-2ca3b26323be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052697130-172.17.0.17-1597645781927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34361,DS-99da2a4b-d472-40d1-9bbf-fb65b052293c,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-40eeced3-2249-4d4e-ab72-51e173b67bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-fa61257c-c289-40a2-b86a-96aa69aaa585,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-100085be-18bc-43cb-a189-91824edd92cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-99aa9f29-51eb-45c8-a1ee-1ab09b950247,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-016f15e1-a9fe-486d-aa32-90e281e70a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-299e2c09-66df-40bf-b0d3-097230cae14c,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-bc70f04a-f94c-4838-b326-a477ded5eb61,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052697130-172.17.0.17-1597645781927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34361,DS-99da2a4b-d472-40d1-9bbf-fb65b052293c,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-40eeced3-2249-4d4e-ab72-51e173b67bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-fa61257c-c289-40a2-b86a-96aa69aaa585,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-100085be-18bc-43cb-a189-91824edd92cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-99aa9f29-51eb-45c8-a1ee-1ab09b950247,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-016f15e1-a9fe-486d-aa32-90e281e70a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-299e2c09-66df-40bf-b0d3-097230cae14c,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-bc70f04a-f94c-4838-b326-a477ded5eb61,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1300636715-172.17.0.17-1597646052745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33440,DS-5c08eabb-93e6-493b-bc1b-b5fa5cf633a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-ff0906b3-fec5-45b7-8f7a-5d34d77db2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-eed1ee2b-7479-4943-a053-6023f77f5198,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-79df9f08-6b02-46d4-ac32-d6190800ec4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40996,DS-e6135db3-fa1f-4ded-bb22-f3f528e149f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-29a21946-4d80-4d27-92c8-8e03d3ed811c,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-561e2be5-70e6-428a-bd2e-0cdace992a23,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-620f6d62-1269-477c-a0b8-dc0ed7c46574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1300636715-172.17.0.17-1597646052745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33440,DS-5c08eabb-93e6-493b-bc1b-b5fa5cf633a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-ff0906b3-fec5-45b7-8f7a-5d34d77db2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-eed1ee2b-7479-4943-a053-6023f77f5198,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-79df9f08-6b02-46d4-ac32-d6190800ec4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40996,DS-e6135db3-fa1f-4ded-bb22-f3f528e149f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-29a21946-4d80-4d27-92c8-8e03d3ed811c,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-561e2be5-70e6-428a-bd2e-0cdace992a23,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-620f6d62-1269-477c-a0b8-dc0ed7c46574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1831641603-172.17.0.17-1597646155719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33549,DS-c6ab64f1-4444-48db-bdb3-78eeb121a028,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-c4834a8d-796e-4754-9279-fd7209e3a501,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-97901cf6-adac-44b6-bc3d-afcecbc67b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-35552593-487d-48b9-bf92-432aee7ab172,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-76ed20e2-b35b-47be-ad7a-3e7128421e69,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-be1d0d3c-6591-4caf-b027-d371929aeef0,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-a15db066-54a1-4f00-8847-ef140c78afea,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-f685dac1-6d24-41d3-a3b3-53a139592862,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1831641603-172.17.0.17-1597646155719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33549,DS-c6ab64f1-4444-48db-bdb3-78eeb121a028,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-c4834a8d-796e-4754-9279-fd7209e3a501,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-97901cf6-adac-44b6-bc3d-afcecbc67b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-35552593-487d-48b9-bf92-432aee7ab172,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-76ed20e2-b35b-47be-ad7a-3e7128421e69,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-be1d0d3c-6591-4caf-b027-d371929aeef0,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-a15db066-54a1-4f00-8847-ef140c78afea,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-f685dac1-6d24-41d3-a3b3-53a139592862,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395351199-172.17.0.17-1597646269497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42364,DS-1757d1d4-1382-4bdd-8b69-bec0f174c3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-1e5799fd-da5c-4789-bf7d-98287c6ed1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-3517da61-352b-47d8-808e-76f7099d3421,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-e6d8bd0c-12d6-4e1a-9ed6-ffc534f1139c,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-60b590a3-0b90-4f0d-9df7-747151fd667b,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-f99291fe-d50c-4599-8719-b48dc62a01dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-9c631a10-31d9-4bb6-a940-6214d5ec26fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-21703211-421f-430f-a405-7a786e57e20c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395351199-172.17.0.17-1597646269497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42364,DS-1757d1d4-1382-4bdd-8b69-bec0f174c3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-1e5799fd-da5c-4789-bf7d-98287c6ed1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-3517da61-352b-47d8-808e-76f7099d3421,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-e6d8bd0c-12d6-4e1a-9ed6-ffc534f1139c,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-60b590a3-0b90-4f0d-9df7-747151fd667b,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-f99291fe-d50c-4599-8719-b48dc62a01dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-9c631a10-31d9-4bb6-a940-6214d5ec26fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-21703211-421f-430f-a405-7a786e57e20c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1207716893-172.17.0.17-1597646298567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38772,DS-cef65319-0c13-4999-84d4-9a1225843879,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-bc136407-be07-4f8a-8e38-1e61ccfba75a,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-9f594457-9ade-4460-9a52-7ef1404694b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-b1f17b9b-c96f-4632-a871-81a5c8d56040,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-fa184209-9d05-480a-a98b-595a5eea1e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-d051c6bc-edbd-4446-a6dc-0fac34aadd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-5218d41d-063d-454c-ab68-6c5e6b450d81,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-445be2c1-9a11-448d-8117-1ef2c7320296,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1207716893-172.17.0.17-1597646298567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38772,DS-cef65319-0c13-4999-84d4-9a1225843879,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-bc136407-be07-4f8a-8e38-1e61ccfba75a,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-9f594457-9ade-4460-9a52-7ef1404694b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-b1f17b9b-c96f-4632-a871-81a5c8d56040,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-fa184209-9d05-480a-a98b-595a5eea1e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-d051c6bc-edbd-4446-a6dc-0fac34aadd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-5218d41d-063d-454c-ab68-6c5e6b450d81,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-445be2c1-9a11-448d-8117-1ef2c7320296,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337709431-172.17.0.17-1597646335873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45274,DS-a0cf157a-ff9f-46b5-9089-cf466c323d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-9589edd5-bc2a-4b77-8a24-f79938d40309,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-5d0c3245-5b63-45be-bf95-94e790225504,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-f8953061-a687-403d-8ae6-05e5dea91ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-6ca196d1-1f97-40a1-83d5-35cc82e86be3,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-4426b39a-6223-4244-a685-edd682ca6c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-2c6c9fc5-82dd-422d-a44b-2c30c98427a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-4d9112fd-b481-4080-99ce-5c87c6bcece1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337709431-172.17.0.17-1597646335873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45274,DS-a0cf157a-ff9f-46b5-9089-cf466c323d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-9589edd5-bc2a-4b77-8a24-f79938d40309,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-5d0c3245-5b63-45be-bf95-94e790225504,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-f8953061-a687-403d-8ae6-05e5dea91ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-6ca196d1-1f97-40a1-83d5-35cc82e86be3,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-4426b39a-6223-4244-a685-edd682ca6c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-2c6c9fc5-82dd-422d-a44b-2c30c98427a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-4d9112fd-b481-4080-99ce-5c87c6bcece1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-542068745-172.17.0.17-1597646374927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38992,DS-d964383f-59eb-47c3-a838-3e328aa666b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-2eac653b-61bb-484f-a4be-d8c1fc506f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-a4f2312b-0a2b-4466-b064-5d9871a01ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-4012d79f-f7a9-4e95-965c-f77f6abd77fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-b1af49ab-ebf1-44df-b6ee-6aaad6bbc254,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-6e0d674c-1a29-468b-8ab9-628a0bf23292,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-644ea318-a3a4-4e59-9a3a-174282c24e75,DISK], DatanodeInfoWithStorage[127.0.0.1:37817,DS-fa000c8a-cd37-432e-ac3f-e62360205f70,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-542068745-172.17.0.17-1597646374927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38992,DS-d964383f-59eb-47c3-a838-3e328aa666b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-2eac653b-61bb-484f-a4be-d8c1fc506f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-a4f2312b-0a2b-4466-b064-5d9871a01ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-4012d79f-f7a9-4e95-965c-f77f6abd77fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-b1af49ab-ebf1-44df-b6ee-6aaad6bbc254,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-6e0d674c-1a29-468b-8ab9-628a0bf23292,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-644ea318-a3a4-4e59-9a3a-174282c24e75,DISK], DatanodeInfoWithStorage[127.0.0.1:37817,DS-fa000c8a-cd37-432e-ac3f-e62360205f70,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749244527-172.17.0.17-1597646572902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36857,DS-bb6c2229-c543-4bf5-831d-61a6e6671e86,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-ad2bb127-5212-4579-b2d5-bf7f5377a0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-d297eca1-f7da-4c27-91a3-52375aa37529,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-09c3a125-2fb3-45bf-a9f5-4e3eeb1b05c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-b8996814-093e-40f2-b13a-99f32ff3901a,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-50a2ff01-0e08-44a1-88ab-0dfd029e17a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-5eec1951-8ec2-43f6-9d1e-aa596f022d18,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-132ea5ea-eaba-430c-ba8a-92290f04e835,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749244527-172.17.0.17-1597646572902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36857,DS-bb6c2229-c543-4bf5-831d-61a6e6671e86,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-ad2bb127-5212-4579-b2d5-bf7f5377a0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-d297eca1-f7da-4c27-91a3-52375aa37529,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-09c3a125-2fb3-45bf-a9f5-4e3eeb1b05c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-b8996814-093e-40f2-b13a-99f32ff3901a,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-50a2ff01-0e08-44a1-88ab-0dfd029e17a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-5eec1951-8ec2-43f6-9d1e-aa596f022d18,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-132ea5ea-eaba-430c-ba8a-92290f04e835,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-972323080-172.17.0.17-1597646650274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45418,DS-a40fe183-d727-4e88-8f19-b58725a70862,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-4d9db280-6560-44c8-a1cb-d664a1a5d81d,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-17ba0cec-cabc-4f4b-9d84-f8221d6c7eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-4bfa3239-58b0-4a6d-8a17-4fe73e2edd35,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-89315af8-faa0-446c-90fe-43d0e7363bda,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-a068e0b5-74c9-411c-91be-61e948b284c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-1ca876b6-1baf-4896-bed8-95ba142017cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-954762ae-1b7c-444a-8354-f5012b070b2c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-972323080-172.17.0.17-1597646650274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45418,DS-a40fe183-d727-4e88-8f19-b58725a70862,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-4d9db280-6560-44c8-a1cb-d664a1a5d81d,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-17ba0cec-cabc-4f4b-9d84-f8221d6c7eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-4bfa3239-58b0-4a6d-8a17-4fe73e2edd35,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-89315af8-faa0-446c-90fe-43d0e7363bda,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-a068e0b5-74c9-411c-91be-61e948b284c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-1ca876b6-1baf-4896-bed8-95ba142017cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-954762ae-1b7c-444a-8354-f5012b070b2c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1737215438-172.17.0.17-1597646914187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46617,DS-e0303d51-0a35-4586-86c2-4c6459dc5686,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-38c73ab4-9334-406a-84fc-2d2bc7c22975,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-ea200ef3-7216-4b14-b550-463ad0270473,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-70d814fc-fb56-4a52-9f13-097e9992125f,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-a4bb24cf-5b33-47fa-b5b9-f19522dd3431,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-3ad56c1f-6a47-40a3-8089-36f151107dda,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-1632684e-2bed-4762-8b8b-479fd8a43cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-01459c03-b56b-4cf1-b9f2-f7d29aea6557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1737215438-172.17.0.17-1597646914187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46617,DS-e0303d51-0a35-4586-86c2-4c6459dc5686,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-38c73ab4-9334-406a-84fc-2d2bc7c22975,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-ea200ef3-7216-4b14-b550-463ad0270473,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-70d814fc-fb56-4a52-9f13-097e9992125f,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-a4bb24cf-5b33-47fa-b5b9-f19522dd3431,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-3ad56c1f-6a47-40a3-8089-36f151107dda,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-1632684e-2bed-4762-8b8b-479fd8a43cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-01459c03-b56b-4cf1-b9f2-f7d29aea6557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850547402-172.17.0.17-1597647063644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39954,DS-15ee74c2-5a6a-4cb5-9b6c-2748236a4703,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-18e0d975-25ab-456b-9eeb-52ba10e32c78,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-d3d54640-dee5-418d-aa87-d371813f804a,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-f43ab527-e65c-478a-be36-3551aebc280f,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-6a109741-d9bf-4fd2-b6bc-61caa9ae9e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-4cdafc85-8ba2-4b92-b850-5a8fec56bfcc,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-3f316ce0-42f3-4cd8-9c60-76992505bbac,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-80ef4b81-ae56-4642-8903-160ba6041016,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850547402-172.17.0.17-1597647063644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39954,DS-15ee74c2-5a6a-4cb5-9b6c-2748236a4703,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-18e0d975-25ab-456b-9eeb-52ba10e32c78,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-d3d54640-dee5-418d-aa87-d371813f804a,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-f43ab527-e65c-478a-be36-3551aebc280f,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-6a109741-d9bf-4fd2-b6bc-61caa9ae9e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-4cdafc85-8ba2-4b92-b850-5a8fec56bfcc,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-3f316ce0-42f3-4cd8-9c60-76992505bbac,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-80ef4b81-ae56-4642-8903-160ba6041016,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731398929-172.17.0.17-1597647149536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34932,DS-5a4e3704-0647-4969-bb02-084a1ea8bb02,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-08282632-3446-40e6-a7f5-e359dd0657cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-916a97e9-5ad1-4221-8393-7958a2385a95,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-f8d02e15-d0f4-404c-ba8a-012129f73801,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-7c607747-9108-4d36-8c83-275d342021b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-a164925a-918e-4686-bcc9-b55acda59b94,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-9cc7199c-0cb4-4802-bdd6-b305503f09e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-439896e4-65f1-4a87-a50a-8abe3d7f936c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731398929-172.17.0.17-1597647149536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34932,DS-5a4e3704-0647-4969-bb02-084a1ea8bb02,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-08282632-3446-40e6-a7f5-e359dd0657cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-916a97e9-5ad1-4221-8393-7958a2385a95,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-f8d02e15-d0f4-404c-ba8a-012129f73801,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-7c607747-9108-4d36-8c83-275d342021b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-a164925a-918e-4686-bcc9-b55acda59b94,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-9cc7199c-0cb4-4802-bdd6-b305503f09e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-439896e4-65f1-4a87-a50a-8abe3d7f936c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1728237716-172.17.0.17-1597647259200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36510,DS-53bd5ca8-4230-444e-bcc2-ee901662b965,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-bab54b0b-21eb-45cd-9133-4bd08337676e,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-74c2f73c-155c-4e7f-a2f1-dc3c9b146642,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-d2a12323-fda1-4f12-b6f9-ee21d48406d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-5baca273-17ea-4191-811e-26f1dcb51bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-3c4b10e3-a650-453d-8c55-524c583fceca,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-cabfd749-31db-4fc2-bb46-9c27a6a4249b,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-695d3d4f-9c39-4fb1-96a7-ba80a9051821,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1728237716-172.17.0.17-1597647259200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36510,DS-53bd5ca8-4230-444e-bcc2-ee901662b965,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-bab54b0b-21eb-45cd-9133-4bd08337676e,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-74c2f73c-155c-4e7f-a2f1-dc3c9b146642,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-d2a12323-fda1-4f12-b6f9-ee21d48406d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-5baca273-17ea-4191-811e-26f1dcb51bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-3c4b10e3-a650-453d-8c55-524c583fceca,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-cabfd749-31db-4fc2-bb46-9c27a6a4249b,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-695d3d4f-9c39-4fb1-96a7-ba80a9051821,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 5658
