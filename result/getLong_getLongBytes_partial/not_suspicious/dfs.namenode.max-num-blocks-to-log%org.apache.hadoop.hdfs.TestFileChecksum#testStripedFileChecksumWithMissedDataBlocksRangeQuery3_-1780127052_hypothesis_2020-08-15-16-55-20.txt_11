reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-882200580-172.17.0.15-1597510644810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39994,DS-81c3aa17-73f2-4b22-857a-01ef767baa73,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-356df64d-a791-4cb1-ba0b-947d81ce8d02,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-fe505fc0-f726-4fed-9af0-ed7f2752135d,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-27ffb9d1-c337-4441-93f3-cf566908c91f,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-f4e833e6-253b-42d6-be49-68fc0caa8da0,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-7bee109d-5f77-4237-aa95-aec1f74b0f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-baf13346-abd6-4fd1-b30c-7334d09d047d,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-0e6fa37e-540f-403e-91a3-f5c1d5d3f64c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-882200580-172.17.0.15-1597510644810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39994,DS-81c3aa17-73f2-4b22-857a-01ef767baa73,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-356df64d-a791-4cb1-ba0b-947d81ce8d02,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-fe505fc0-f726-4fed-9af0-ed7f2752135d,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-27ffb9d1-c337-4441-93f3-cf566908c91f,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-f4e833e6-253b-42d6-be49-68fc0caa8da0,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-7bee109d-5f77-4237-aa95-aec1f74b0f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-baf13346-abd6-4fd1-b30c-7334d09d047d,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-0e6fa37e-540f-403e-91a3-f5c1d5d3f64c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1806790097-172.17.0.15-1597510780629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39423,DS-75d18e9a-0349-42bc-8298-fd02e1133c47,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-fdec3314-eaf3-49ac-a80f-cdcabb462429,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-39ed8f1c-34db-4b1a-a64d-694ba680010a,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-a7f2e5a9-5cc5-4ad7-9a03-08992383f171,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-bba558e1-5336-4f0c-ac16-fb4eb5bdc234,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-4f67a129-4084-49a8-a8b5-70242a0f3d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-ef9e0878-330a-4fd8-bb5c-2b13fa5fd3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-33415c37-db06-435c-9fab-a82d724e7023,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1806790097-172.17.0.15-1597510780629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39423,DS-75d18e9a-0349-42bc-8298-fd02e1133c47,DISK], DatanodeInfoWithStorage[127.0.0.1:46326,DS-fdec3314-eaf3-49ac-a80f-cdcabb462429,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-39ed8f1c-34db-4b1a-a64d-694ba680010a,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-a7f2e5a9-5cc5-4ad7-9a03-08992383f171,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-bba558e1-5336-4f0c-ac16-fb4eb5bdc234,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-4f67a129-4084-49a8-a8b5-70242a0f3d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-ef9e0878-330a-4fd8-bb5c-2b13fa5fd3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-33415c37-db06-435c-9fab-a82d724e7023,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041375807-172.17.0.15-1597510811303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44730,DS-e94928e2-5172-44f7-9453-1bdf9d41dbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-273dc389-7f99-44ba-a0d5-d393db64ef55,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-1680a33b-84f6-4765-b013-910ae78bc612,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-cab211ac-2f8d-4ad8-a271-bfa718aafef1,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-1ab5b377-0096-4c68-be7b-4b68196ccc04,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-85856fc9-9200-4df8-9f38-7a6ca5eb77a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-9e1ae7cc-2126-4261-87f3-3cd43d65d40b,DISK], DatanodeInfoWithStorage[127.0.0.1:33783,DS-b15acd62-abca-4edc-a778-9ee947e26993,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041375807-172.17.0.15-1597510811303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44730,DS-e94928e2-5172-44f7-9453-1bdf9d41dbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-273dc389-7f99-44ba-a0d5-d393db64ef55,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-1680a33b-84f6-4765-b013-910ae78bc612,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-cab211ac-2f8d-4ad8-a271-bfa718aafef1,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-1ab5b377-0096-4c68-be7b-4b68196ccc04,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-85856fc9-9200-4df8-9f38-7a6ca5eb77a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-9e1ae7cc-2126-4261-87f3-3cd43d65d40b,DISK], DatanodeInfoWithStorage[127.0.0.1:33783,DS-b15acd62-abca-4edc-a778-9ee947e26993,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-864141338-172.17.0.15-1597511545237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37555,DS-6ccfda3a-fb33-40ad-9b7c-bd4f8608784a,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-da226052-1f04-4552-ac1d-557440e1d173,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-7b82082d-cad7-4341-92a3-b274dfa77c79,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-36e28a78-44d5-4bed-ae56-6c7de6be09ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-82402ab8-8b2f-4f8b-8a49-d5ab80afd864,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-1490d5c3-e211-495d-934b-1b24258b2497,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-823977e5-b59c-440e-8e86-fd1415bd8223,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-4da313e0-9d9e-4d12-b4fc-a67ee8532dc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-864141338-172.17.0.15-1597511545237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37555,DS-6ccfda3a-fb33-40ad-9b7c-bd4f8608784a,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-da226052-1f04-4552-ac1d-557440e1d173,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-7b82082d-cad7-4341-92a3-b274dfa77c79,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-36e28a78-44d5-4bed-ae56-6c7de6be09ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-82402ab8-8b2f-4f8b-8a49-d5ab80afd864,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-1490d5c3-e211-495d-934b-1b24258b2497,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-823977e5-b59c-440e-8e86-fd1415bd8223,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-4da313e0-9d9e-4d12-b4fc-a67ee8532dc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-862785430-172.17.0.15-1597511761326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37603,DS-8398b1c2-6e70-4563-9e5b-b03d621081bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-aebb25fc-3419-43f2-97d3-8de7606b7968,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-3c306792-4610-420b-abe1-5123d0f38391,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-20b863f9-89f3-4275-95aa-9dc298ecf361,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-814cab8c-8dac-4f16-9386-5e0cf91e0d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-1d054c24-e5ee-4ac3-8921-c1f12a3863d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-7ae703f1-7b5c-45db-8647-43223e68d8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-4833701c-8cf7-45d4-b1c6-4f98238eac07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-862785430-172.17.0.15-1597511761326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37603,DS-8398b1c2-6e70-4563-9e5b-b03d621081bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-aebb25fc-3419-43f2-97d3-8de7606b7968,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-3c306792-4610-420b-abe1-5123d0f38391,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-20b863f9-89f3-4275-95aa-9dc298ecf361,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-814cab8c-8dac-4f16-9386-5e0cf91e0d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-1d054c24-e5ee-4ac3-8921-c1f12a3863d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-7ae703f1-7b5c-45db-8647-43223e68d8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-4833701c-8cf7-45d4-b1c6-4f98238eac07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2047884403-172.17.0.15-1597511916324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35327,DS-b850cdb5-8921-4ab9-aa6d-9c643c32ed20,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-33d3caec-0120-447f-9828-fc00042b1f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-8ff6a631-0908-4e84-9fd8-30aabe5741b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-c09d1489-22f5-4dfb-a20f-840730d0d590,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-34b6557f-d8e3-45d0-8144-c98ad1010560,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-5082c27e-fdab-42de-98ca-30846c6ed5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-d2768797-20cb-4bf1-9037-a19e4edb0ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-cc1ae485-499e-4f83-84dc-e880eabb7783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2047884403-172.17.0.15-1597511916324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35327,DS-b850cdb5-8921-4ab9-aa6d-9c643c32ed20,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-33d3caec-0120-447f-9828-fc00042b1f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-8ff6a631-0908-4e84-9fd8-30aabe5741b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-c09d1489-22f5-4dfb-a20f-840730d0d590,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-34b6557f-d8e3-45d0-8144-c98ad1010560,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-5082c27e-fdab-42de-98ca-30846c6ed5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-d2768797-20cb-4bf1-9037-a19e4edb0ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-cc1ae485-499e-4f83-84dc-e880eabb7783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1163056710-172.17.0.15-1597512903250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41146,DS-e45750ac-d69c-4316-8017-4f04893884a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-0334ecc4-fc1e-4b18-af67-d7b5bafded77,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-83f61042-d322-440a-9ec1-56acd67a205c,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-cadef82d-6999-4b31-aa49-0334d6433403,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-ecd4cbf7-0361-4098-8198-14e9d48e020f,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-901c4904-b59b-491d-a71f-eb719804d740,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-718387f7-3541-4d78-9e34-ea1dbf267a71,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-86b02475-dfe0-481d-b557-54c24e9459db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1163056710-172.17.0.15-1597512903250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41146,DS-e45750ac-d69c-4316-8017-4f04893884a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-0334ecc4-fc1e-4b18-af67-d7b5bafded77,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-83f61042-d322-440a-9ec1-56acd67a205c,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-cadef82d-6999-4b31-aa49-0334d6433403,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-ecd4cbf7-0361-4098-8198-14e9d48e020f,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-901c4904-b59b-491d-a71f-eb719804d740,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-718387f7-3541-4d78-9e34-ea1dbf267a71,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-86b02475-dfe0-481d-b557-54c24e9459db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1730711112-172.17.0.15-1597513178243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41614,DS-5a0749ce-fa66-4b2a-abd6-3b0ae6cf576a,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-b6dcc910-35a4-496f-a2eb-5ac94db8d113,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-9d077fd7-729c-4e40-86e2-c05c58b02f41,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-596972c8-6d52-4e42-bcc1-86d6b60129cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-b3ef0473-c573-4935-ac4d-838931d78fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-69284744-faee-4f7e-85b1-eeaee9c31270,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-7f370491-806e-4361-b7a2-8dbe4b24e785,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-b9fa6d22-d938-4e4a-881d-bc6c6f9f4ccd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1730711112-172.17.0.15-1597513178243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41614,DS-5a0749ce-fa66-4b2a-abd6-3b0ae6cf576a,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-b6dcc910-35a4-496f-a2eb-5ac94db8d113,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-9d077fd7-729c-4e40-86e2-c05c58b02f41,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-596972c8-6d52-4e42-bcc1-86d6b60129cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-b3ef0473-c573-4935-ac4d-838931d78fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-69284744-faee-4f7e-85b1-eeaee9c31270,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-7f370491-806e-4361-b7a2-8dbe4b24e785,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-b9fa6d22-d938-4e4a-881d-bc6c6f9f4ccd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1205894639-172.17.0.15-1597513350930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43410,DS-d71c5c89-321f-468e-9e64-a913cd82980c,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-a1d0b54d-215b-4be9-9b9f-b585259003ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-cb1d59a1-f841-4a0c-b01d-346755b61e53,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-295e441d-061e-4f48-8daa-b94690552920,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-d50d6e47-5914-4898-82e6-0999d4d3358a,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-1dd7471d-ee3f-4b9c-a84c-c72968d542fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-3610a802-7f95-481f-84d5-4ec6b409d03a,DISK], DatanodeInfoWithStorage[127.0.0.1:45977,DS-676ee71d-59ef-4fc3-b5c5-df1636314ec6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1205894639-172.17.0.15-1597513350930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43410,DS-d71c5c89-321f-468e-9e64-a913cd82980c,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-a1d0b54d-215b-4be9-9b9f-b585259003ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-cb1d59a1-f841-4a0c-b01d-346755b61e53,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-295e441d-061e-4f48-8daa-b94690552920,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-d50d6e47-5914-4898-82e6-0999d4d3358a,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-1dd7471d-ee3f-4b9c-a84c-c72968d542fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-3610a802-7f95-481f-84d5-4ec6b409d03a,DISK], DatanodeInfoWithStorage[127.0.0.1:45977,DS-676ee71d-59ef-4fc3-b5c5-df1636314ec6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337029021-172.17.0.15-1597513630671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46433,DS-1b45ecfe-001d-4a0a-89e4-b5c6accf94b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-62e9d62e-6a06-44e1-a042-e3cf29de0a08,DISK], DatanodeInfoWithStorage[127.0.0.1:39215,DS-746b4d03-22f6-452d-bac4-f34b4e392586,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-c8fa1f92-b8d6-4116-8e4f-1a8ed0d8ac36,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-fb506925-4828-4293-81a4-5a53bec8ecd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-ef2af38a-0f66-49db-9149-95a58b7a5cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-571ccbda-e125-405f-9ffc-1199db7719a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35743,DS-47e8baf8-e1ea-40d5-b238-3650b1ce5f34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337029021-172.17.0.15-1597513630671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46433,DS-1b45ecfe-001d-4a0a-89e4-b5c6accf94b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-62e9d62e-6a06-44e1-a042-e3cf29de0a08,DISK], DatanodeInfoWithStorage[127.0.0.1:39215,DS-746b4d03-22f6-452d-bac4-f34b4e392586,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-c8fa1f92-b8d6-4116-8e4f-1a8ed0d8ac36,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-fb506925-4828-4293-81a4-5a53bec8ecd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-ef2af38a-0f66-49db-9149-95a58b7a5cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-571ccbda-e125-405f-9ffc-1199db7719a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35743,DS-47e8baf8-e1ea-40d5-b238-3650b1ce5f34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1732990737-172.17.0.15-1597514150740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35445,DS-85d32fbc-9312-4b1b-ba82-205b5eff055b,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-10a5ece9-8652-4027-909c-f9cd915cdfac,DISK], DatanodeInfoWithStorage[127.0.0.1:45849,DS-96aca5df-791e-46b0-9ccd-b8848843535a,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-6e7fed22-b69e-42b5-a683-0a60ab645555,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-1aab949e-4eee-45c7-8b16-36502f1ccf32,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-74b9e40e-e5b7-491e-ad89-4291141ee095,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-85b0c1c3-e1a2-450b-aaca-ec8714f2a0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-bf51fb75-5fc2-452b-af79-5fd5d2845132,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1732990737-172.17.0.15-1597514150740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35445,DS-85d32fbc-9312-4b1b-ba82-205b5eff055b,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-10a5ece9-8652-4027-909c-f9cd915cdfac,DISK], DatanodeInfoWithStorage[127.0.0.1:45849,DS-96aca5df-791e-46b0-9ccd-b8848843535a,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-6e7fed22-b69e-42b5-a683-0a60ab645555,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-1aab949e-4eee-45c7-8b16-36502f1ccf32,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-74b9e40e-e5b7-491e-ad89-4291141ee095,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-85b0c1c3-e1a2-450b-aaca-ec8714f2a0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-bf51fb75-5fc2-452b-af79-5fd5d2845132,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1355627581-172.17.0.15-1597514613884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34060,DS-6485b8d8-aa90-464c-a071-475cdb276880,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-1f73057b-d33c-46e7-a400-5476bcdeed17,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-8f32d873-64a6-409c-9e34-2d4e607ac0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-88f62357-1120-4767-bede-2dca79fab7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-aca8b493-2c96-4937-9131-db4d71614e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-ab028abf-99d8-47c3-9717-08123d29620d,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-a9db3425-32b5-460b-81c4-f63ff5de67df,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-d0ba59f7-0a00-4461-a46a-ad5611cc6ed2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1355627581-172.17.0.15-1597514613884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34060,DS-6485b8d8-aa90-464c-a071-475cdb276880,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-1f73057b-d33c-46e7-a400-5476bcdeed17,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-8f32d873-64a6-409c-9e34-2d4e607ac0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-88f62357-1120-4767-bede-2dca79fab7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-aca8b493-2c96-4937-9131-db4d71614e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-ab028abf-99d8-47c3-9717-08123d29620d,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-a9db3425-32b5-460b-81c4-f63ff5de67df,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-d0ba59f7-0a00-4461-a46a-ad5611cc6ed2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-434397393-172.17.0.15-1597514940476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33069,DS-a3b07280-053d-45d0-b411-678153f2944a,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-5b663a2e-be9f-4d89-8d07-593187b8006d,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-15162909-ad02-4163-8bdc-b0555c8f65ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-9132586e-1c01-4ec9-8ef3-8951c184455c,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-d8294aa3-76cc-46e1-8c64-bce80c11488b,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-24b98f15-4a3d-459f-839f-55822d910382,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-13f57359-160b-44ea-996a-7953997c2162,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-51c5149b-49a6-4fae-9bd7-24a2b34e3af0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-434397393-172.17.0.15-1597514940476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33069,DS-a3b07280-053d-45d0-b411-678153f2944a,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-5b663a2e-be9f-4d89-8d07-593187b8006d,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-15162909-ad02-4163-8bdc-b0555c8f65ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-9132586e-1c01-4ec9-8ef3-8951c184455c,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-d8294aa3-76cc-46e1-8c64-bce80c11488b,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-24b98f15-4a3d-459f-839f-55822d910382,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-13f57359-160b-44ea-996a-7953997c2162,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-51c5149b-49a6-4fae-9bd7-24a2b34e3af0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940532657-172.17.0.15-1597515151533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46482,DS-9a3c3722-1a5d-45b4-97db-b4ecb226b64b,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-782b7556-5cc0-4b36-aad7-acbb8a284f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-166c2032-e72a-4484-80f4-ba8b177878e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-07e96b15-bbf6-4ccc-8a8d-fc4afa525696,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-4e50c1f3-52a3-41ea-a2d6-6ed885a8fcb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-747dde78-cbf9-4ac1-bb76-c0026a575eca,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-822c86ee-1a7a-4871-84d2-1463881c7cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-8306297b-70ba-42e1-869c-208d0dffb9f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-940532657-172.17.0.15-1597515151533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46482,DS-9a3c3722-1a5d-45b4-97db-b4ecb226b64b,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-782b7556-5cc0-4b36-aad7-acbb8a284f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-166c2032-e72a-4484-80f4-ba8b177878e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-07e96b15-bbf6-4ccc-8a8d-fc4afa525696,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-4e50c1f3-52a3-41ea-a2d6-6ed885a8fcb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-747dde78-cbf9-4ac1-bb76-c0026a575eca,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-822c86ee-1a7a-4871-84d2-1463881c7cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-8306297b-70ba-42e1-869c-208d0dffb9f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124781081-172.17.0.15-1597515502754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36424,DS-c974bf97-5720-40a3-8809-c1a8b357ab2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-098f6a6c-5512-4ce0-868d-88edd7dd3eab,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-04f26d83-5be9-4127-9840-406391120575,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-aa71f4d7-eb45-459e-9d5f-c4e0515d2a61,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-50bcd4f5-ecfb-4297-a7fd-4126939dd5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-e051e01d-24b0-4c76-889f-a6bd07979838,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-09fd2a96-69c2-4fed-b1b2-5880b32bff61,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-c1d4f314-61cf-4ce7-bd4a-c6fc5dffdc91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124781081-172.17.0.15-1597515502754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36424,DS-c974bf97-5720-40a3-8809-c1a8b357ab2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-098f6a6c-5512-4ce0-868d-88edd7dd3eab,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-04f26d83-5be9-4127-9840-406391120575,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-aa71f4d7-eb45-459e-9d5f-c4e0515d2a61,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-50bcd4f5-ecfb-4297-a7fd-4126939dd5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-e051e01d-24b0-4c76-889f-a6bd07979838,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-09fd2a96-69c2-4fed-b1b2-5880b32bff61,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-c1d4f314-61cf-4ce7-bd4a-c6fc5dffdc91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1399993825-172.17.0.15-1597515683288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34680,DS-eebc24d7-98f3-4ac7-a521-105157e4e882,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-7b0dbfd5-518f-4bb0-9fc6-f210ae95c216,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-dc28daa2-56df-4050-a13c-d9ec0e3b2d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-8669bbe4-351b-4a39-948e-cbc78d0b35ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-299a20b6-64db-4847-9be0-9dc3392de1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-f0d601a7-2a75-4a40-818c-6df4742318ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-7f195e28-8ce6-469c-ae25-60d64dc1939a,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-fc538ca2-2a1a-44f0-99ac-9319c4156ca9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1399993825-172.17.0.15-1597515683288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34680,DS-eebc24d7-98f3-4ac7-a521-105157e4e882,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-7b0dbfd5-518f-4bb0-9fc6-f210ae95c216,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-dc28daa2-56df-4050-a13c-d9ec0e3b2d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-8669bbe4-351b-4a39-948e-cbc78d0b35ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-299a20b6-64db-4847-9be0-9dc3392de1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-f0d601a7-2a75-4a40-818c-6df4742318ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-7f195e28-8ce6-469c-ae25-60d64dc1939a,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-fc538ca2-2a1a-44f0-99ac-9319c4156ca9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1933021302-172.17.0.15-1597515713345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45072,DS-bc1f130d-4410-4645-89a7-84e47fcddc70,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-1cb9988d-017d-4c7d-9855-37fe576e39b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-962f9a03-4e71-45e6-ac94-43d22a0bf0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-dae3cec2-088e-49f0-9106-c1c61e61587f,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-4cc85158-f79b-40cc-ae2b-093ad9e8b3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-4ff54324-eb99-4216-9cad-3bb1d6da92d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-7e5f5371-32af-4890-9568-304110281e63,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-794a6d0b-56bf-43e6-9042-e74eb5e24aac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1933021302-172.17.0.15-1597515713345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45072,DS-bc1f130d-4410-4645-89a7-84e47fcddc70,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-1cb9988d-017d-4c7d-9855-37fe576e39b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-962f9a03-4e71-45e6-ac94-43d22a0bf0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-dae3cec2-088e-49f0-9106-c1c61e61587f,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-4cc85158-f79b-40cc-ae2b-093ad9e8b3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-4ff54324-eb99-4216-9cad-3bb1d6da92d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-7e5f5371-32af-4890-9568-304110281e63,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-794a6d0b-56bf-43e6-9042-e74eb5e24aac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1142746846-172.17.0.15-1597515790379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36155,DS-e8b027aa-84f7-4217-b373-56dc30b6b25b,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-cc3052f1-c5b9-4607-a822-371af4e44791,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-ada5a8d3-2365-4df8-9c0b-b17515b95a08,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-8fe0da17-e4cd-4c62-b6f7-2b5d72fefdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-00bfa5f6-3a4d-42cc-a3d0-d967a8c83633,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-823501d2-f35f-4774-8562-50112a3e1074,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-ca321a78-640a-4220-9cca-7398367cf750,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-25b27616-2e64-407c-8ef7-41c611004be6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1142746846-172.17.0.15-1597515790379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36155,DS-e8b027aa-84f7-4217-b373-56dc30b6b25b,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-cc3052f1-c5b9-4607-a822-371af4e44791,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-ada5a8d3-2365-4df8-9c0b-b17515b95a08,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-8fe0da17-e4cd-4c62-b6f7-2b5d72fefdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-00bfa5f6-3a4d-42cc-a3d0-d967a8c83633,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-823501d2-f35f-4774-8562-50112a3e1074,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-ca321a78-640a-4220-9cca-7398367cf750,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-25b27616-2e64-407c-8ef7-41c611004be6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5330
