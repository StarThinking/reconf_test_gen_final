reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1531494863-172.17.0.9-1597717427513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40163,DS-88979e81-b784-4786-b3fd-02a402d068fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-78ac15c0-b4a0-40c4-9e8d-ad22e690b785,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-51f81b79-7c94-4a7b-817e-c0bc6f6ac3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-45ec4202-3c51-473f-ba8f-9c3354b4eb74,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-c8706003-afa1-4338-a7a6-f34a0380e8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-f6fc437f-bec8-4ef6-a75a-119e31f1709b,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-d3fa1e26-d9ff-48d9-877f-ce6c91f37d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-8808a9ab-0ff7-4feb-b765-c09ba91228f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1531494863-172.17.0.9-1597717427513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40163,DS-88979e81-b784-4786-b3fd-02a402d068fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-78ac15c0-b4a0-40c4-9e8d-ad22e690b785,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-51f81b79-7c94-4a7b-817e-c0bc6f6ac3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-45ec4202-3c51-473f-ba8f-9c3354b4eb74,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-c8706003-afa1-4338-a7a6-f34a0380e8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-f6fc437f-bec8-4ef6-a75a-119e31f1709b,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-d3fa1e26-d9ff-48d9-877f-ce6c91f37d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-8808a9ab-0ff7-4feb-b765-c09ba91228f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486486582-172.17.0.9-1597717861870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36533,DS-89f7ab91-7a8d-4838-9e3a-310c216ccf68,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-19fc8273-7957-4c5f-8ba9-7d98cec0b707,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-3b0ac89d-b494-4277-baaf-b3b60e19df12,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-89f51a60-f43f-4b2a-8113-500fa6fe71e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-cde0d6a3-92e7-4d44-8b3e-1d6d759c5372,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-3b6baf95-fb1e-4d28-b9e5-6aca00a03b27,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-9f9fd256-0645-4009-942d-e6a7a8d8e8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-28834c36-08c1-4c93-9df3-f7618863d56c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486486582-172.17.0.9-1597717861870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36533,DS-89f7ab91-7a8d-4838-9e3a-310c216ccf68,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-19fc8273-7957-4c5f-8ba9-7d98cec0b707,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-3b0ac89d-b494-4277-baaf-b3b60e19df12,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-89f51a60-f43f-4b2a-8113-500fa6fe71e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-cde0d6a3-92e7-4d44-8b3e-1d6d759c5372,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-3b6baf95-fb1e-4d28-b9e5-6aca00a03b27,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-9f9fd256-0645-4009-942d-e6a7a8d8e8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-28834c36-08c1-4c93-9df3-f7618863d56c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616919262-172.17.0.9-1597717935348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40315,DS-f8b58cbc-71e6-4b34-b78f-faac0c72f790,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-5c426472-4a77-43d2-a1d9-50956cb55b11,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-b101a183-7989-4949-8b0b-9b1695e1990b,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-22e6d1cb-b092-4be6-a8c2-08807e1ceea0,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-3934c894-738c-4863-9142-b6fda54b08e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-8ea34afc-6105-4d21-b66c-473d7c0c778d,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-46f2fd66-b49c-41a6-a671-cb59a38706b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-782bd83a-4f39-4630-a0b2-95857ba3bb41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616919262-172.17.0.9-1597717935348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40315,DS-f8b58cbc-71e6-4b34-b78f-faac0c72f790,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-5c426472-4a77-43d2-a1d9-50956cb55b11,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-b101a183-7989-4949-8b0b-9b1695e1990b,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-22e6d1cb-b092-4be6-a8c2-08807e1ceea0,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-3934c894-738c-4863-9142-b6fda54b08e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-8ea34afc-6105-4d21-b66c-473d7c0c778d,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-46f2fd66-b49c-41a6-a671-cb59a38706b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-782bd83a-4f39-4630-a0b2-95857ba3bb41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1764167047-172.17.0.9-1597718080262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38895,DS-b1867704-29d9-4fa3-930b-f9306678355d,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-e0dc6f6b-1246-4a7f-8c80-3739bc52f8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-1cf7030b-3ae9-45d8-8adb-1b8558ea10ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-036e58af-8957-4bfc-ab06-d23300eb9e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-30bd9f60-60c0-48f2-a5f5-ae66a608b256,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-06e2c383-37de-484d-958d-716ebfb39e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-819f900c-2ae3-46df-a7c6-3c62dfaab3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-42d5974f-bf9d-497a-96a0-7c8aaa93b15b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1764167047-172.17.0.9-1597718080262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38895,DS-b1867704-29d9-4fa3-930b-f9306678355d,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-e0dc6f6b-1246-4a7f-8c80-3739bc52f8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-1cf7030b-3ae9-45d8-8adb-1b8558ea10ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-036e58af-8957-4bfc-ab06-d23300eb9e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-30bd9f60-60c0-48f2-a5f5-ae66a608b256,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-06e2c383-37de-484d-958d-716ebfb39e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-819f900c-2ae3-46df-a7c6-3c62dfaab3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-42d5974f-bf9d-497a-96a0-7c8aaa93b15b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929933319-172.17.0.9-1597718119088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34412,DS-c1bac9b8-30f1-48a4-a01d-0af70b5d41f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-a94739c3-41ca-43e9-b7aa-b1ad2add3021,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-6ee71065-ab93-4b56-bebe-140a5fb7652f,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-451884b2-51c2-4e1f-baa4-aed3dfa41425,DISK], DatanodeInfoWithStorage[127.0.0.1:36598,DS-c9388320-18fa-4295-9d3b-5f38a20d1f38,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-9877b459-df88-469f-a4bb-1c72771ebb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-5408e4b9-8c2e-480b-b048-1d957a0384b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-c4838f82-05bb-4a43-9763-c9f5ddf4ed2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929933319-172.17.0.9-1597718119088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34412,DS-c1bac9b8-30f1-48a4-a01d-0af70b5d41f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-a94739c3-41ca-43e9-b7aa-b1ad2add3021,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-6ee71065-ab93-4b56-bebe-140a5fb7652f,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-451884b2-51c2-4e1f-baa4-aed3dfa41425,DISK], DatanodeInfoWithStorage[127.0.0.1:36598,DS-c9388320-18fa-4295-9d3b-5f38a20d1f38,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-9877b459-df88-469f-a4bb-1c72771ebb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-5408e4b9-8c2e-480b-b048-1d957a0384b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-c4838f82-05bb-4a43-9763-c9f5ddf4ed2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939976185-172.17.0.9-1597718201600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42323,DS-0205101e-0fd5-4e3a-a504-1212e3ddfd63,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-724ea68e-a9ff-4d8b-a093-77f929282626,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-23b4eb0d-8b61-4e1b-99d2-1a469d94892b,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-565eb0ed-46e8-4134-8e87-9bdd6e0775c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-706ef9e3-8868-4e71-b988-2c468a7dfc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-149e1d83-b043-49c3-a894-fd6bd10a5f40,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-1becd568-42e7-4098-9c85-108a5c639cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-00c87611-9c5a-4c27-820f-6b51539d7555,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939976185-172.17.0.9-1597718201600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42323,DS-0205101e-0fd5-4e3a-a504-1212e3ddfd63,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-724ea68e-a9ff-4d8b-a093-77f929282626,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-23b4eb0d-8b61-4e1b-99d2-1a469d94892b,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-565eb0ed-46e8-4134-8e87-9bdd6e0775c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-706ef9e3-8868-4e71-b988-2c468a7dfc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-149e1d83-b043-49c3-a894-fd6bd10a5f40,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-1becd568-42e7-4098-9c85-108a5c639cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-00c87611-9c5a-4c27-820f-6b51539d7555,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-3930076-172.17.0.9-1597718711030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42564,DS-e0860878-fe8c-48fc-812b-a7dbd77937b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-fee7567f-72df-41c6-8057-9a946363dc17,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-ecd005b6-487a-4721-be97-1c0e65855436,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-2dd046d0-8b7e-42b7-9e44-a25780a3cbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-98bd98b1-ed16-4a55-bc8b-1e28f4772d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-dca60767-99e0-42a7-9160-436fbce5589e,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-12dd2665-9557-4b91-8159-c398d89d4371,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-5ea7a21b-297f-4b50-933a-455ac01b5c40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-3930076-172.17.0.9-1597718711030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42564,DS-e0860878-fe8c-48fc-812b-a7dbd77937b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-fee7567f-72df-41c6-8057-9a946363dc17,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-ecd005b6-487a-4721-be97-1c0e65855436,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-2dd046d0-8b7e-42b7-9e44-a25780a3cbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-98bd98b1-ed16-4a55-bc8b-1e28f4772d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-dca60767-99e0-42a7-9160-436fbce5589e,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-12dd2665-9557-4b91-8159-c398d89d4371,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-5ea7a21b-297f-4b50-933a-455ac01b5c40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510970708-172.17.0.9-1597719125474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39576,DS-b7b242da-8098-4c19-b0bd-51727e70089a,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-179d4e40-e8ef-4a38-9920-f98c7aebfd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-4691d638-eb53-4ef5-95dc-68e48821ecda,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-d0dbcd39-96c1-47a2-bc1d-d4f6638c765e,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-a2e7a9c3-4d25-4cd4-87c1-448989342c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-8319cd3f-68bd-4f79-a062-e879a6f88cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-77011587-726f-4bfc-bd80-abeb74152de6,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-3b20279d-7702-4609-b833-4349325dd0dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510970708-172.17.0.9-1597719125474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39576,DS-b7b242da-8098-4c19-b0bd-51727e70089a,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-179d4e40-e8ef-4a38-9920-f98c7aebfd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-4691d638-eb53-4ef5-95dc-68e48821ecda,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-d0dbcd39-96c1-47a2-bc1d-d4f6638c765e,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-a2e7a9c3-4d25-4cd4-87c1-448989342c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45303,DS-8319cd3f-68bd-4f79-a062-e879a6f88cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-77011587-726f-4bfc-bd80-abeb74152de6,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-3b20279d-7702-4609-b833-4349325dd0dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1074763152-172.17.0.9-1597719429775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42636,DS-7bbdc2da-5b29-4e29-8f0d-fed01359abfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-8c3a53c7-3afc-4512-9db9-1d5978df6050,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-12b1c5bf-9251-46cc-b8fc-cd5910de80e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-03810b92-888f-41fd-8be4-9ddff7486c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-afce6d32-94c3-4190-a4c4-6fc6b820bb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-f4dcfb74-225a-4042-80af-af2bb9001266,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-29e1450a-8904-4985-a1a7-07b046e39365,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-24c6e463-7251-49ed-a9e7-5a8c7a726ba4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1074763152-172.17.0.9-1597719429775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42636,DS-7bbdc2da-5b29-4e29-8f0d-fed01359abfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-8c3a53c7-3afc-4512-9db9-1d5978df6050,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-12b1c5bf-9251-46cc-b8fc-cd5910de80e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-03810b92-888f-41fd-8be4-9ddff7486c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-afce6d32-94c3-4190-a4c4-6fc6b820bb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-f4dcfb74-225a-4042-80af-af2bb9001266,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-29e1450a-8904-4985-a1a7-07b046e39365,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-24c6e463-7251-49ed-a9e7-5a8c7a726ba4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-61853472-172.17.0.9-1597720450737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39295,DS-5b933b85-c666-465a-a276-417918d7e88c,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-b2b69ea3-dfa1-4846-9acd-b9cf0c802b26,DISK], DatanodeInfoWithStorage[127.0.0.1:39999,DS-07ee4d4c-cb67-470d-bcd1-a311d6cd33b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-0ebfa193-6955-41fe-8ff1-fd145964e7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-1cf0446d-163f-4c85-b1ca-7d8d1f1334b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-6ed831b2-f679-4ce6-bf68-c8d615f533c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-66e8455b-c62b-4cb7-87e7-ee61d539c7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37744,DS-d1c991e2-d4a9-4aaf-8c2b-c334432b4e94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-61853472-172.17.0.9-1597720450737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39295,DS-5b933b85-c666-465a-a276-417918d7e88c,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-b2b69ea3-dfa1-4846-9acd-b9cf0c802b26,DISK], DatanodeInfoWithStorage[127.0.0.1:39999,DS-07ee4d4c-cb67-470d-bcd1-a311d6cd33b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-0ebfa193-6955-41fe-8ff1-fd145964e7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-1cf0446d-163f-4c85-b1ca-7d8d1f1334b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-6ed831b2-f679-4ce6-bf68-c8d615f533c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-66e8455b-c62b-4cb7-87e7-ee61d539c7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37744,DS-d1c991e2-d4a9-4aaf-8c2b-c334432b4e94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1282285203-172.17.0.9-1597720648260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38264,DS-54253f42-0487-4595-91ad-60523f9e9ade,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-9ba29f36-d6c2-4cef-96f7-b2fabbc4f88e,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-59a946aa-d72a-445d-8929-46cb0dd722ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-d911e61e-d6ad-4f48-b1d0-b32d95dec1be,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-3385f44a-69c5-467b-90cf-5ca155810374,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-0dcf8c7e-11fc-4730-8009-6606a12d4504,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-366d0316-2cc7-496e-9949-4fc1c62e62ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-d25e4481-e5ce-41b4-a029-49a6ca846e6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1282285203-172.17.0.9-1597720648260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38264,DS-54253f42-0487-4595-91ad-60523f9e9ade,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-9ba29f36-d6c2-4cef-96f7-b2fabbc4f88e,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-59a946aa-d72a-445d-8929-46cb0dd722ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-d911e61e-d6ad-4f48-b1d0-b32d95dec1be,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-3385f44a-69c5-467b-90cf-5ca155810374,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-0dcf8c7e-11fc-4730-8009-6606a12d4504,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-366d0316-2cc7-496e-9949-4fc1c62e62ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-d25e4481-e5ce-41b4-a029-49a6ca846e6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1265732125-172.17.0.9-1597720692924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35567,DS-3f686a03-1b4d-4b14-996b-4faa69e88414,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-14159d48-9164-43bc-9cac-21f8fa218d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-3fe1ebc0-bf07-447e-bcb4-607d1dc68383,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-1593f814-85a0-4dc0-9c61-8d86bfc36483,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-ce00c6d2-7e30-4482-b6fa-6c68e1be298f,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-ea35b6dd-60a3-44be-9aa3-8922555f5201,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-e5002926-86d2-4f29-bd6d-1088f6ff90eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-0fe0b069-a141-49fb-84de-50d0bcd94eab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1265732125-172.17.0.9-1597720692924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35567,DS-3f686a03-1b4d-4b14-996b-4faa69e88414,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-14159d48-9164-43bc-9cac-21f8fa218d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-3fe1ebc0-bf07-447e-bcb4-607d1dc68383,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-1593f814-85a0-4dc0-9c61-8d86bfc36483,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-ce00c6d2-7e30-4482-b6fa-6c68e1be298f,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-ea35b6dd-60a3-44be-9aa3-8922555f5201,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-e5002926-86d2-4f29-bd6d-1088f6ff90eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-0fe0b069-a141-49fb-84de-50d0bcd94eab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1719625127-172.17.0.9-1597721030536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36208,DS-8d7ab436-4b14-4301-9f8f-e706e9f90ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-ae99d0c1-18de-41d3-a557-115f42441a72,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-fb10c01d-4de4-4d80-b6e4-261e90e2a6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-548391d7-2f79-4ac6-a82d-5187949c2931,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-a25aad87-ac55-44e1-9207-8ae684ecf3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-504ee487-3706-4e79-88e2-cb57da4fef7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-5b20e489-2309-4df0-82cd-f763fdc08308,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-07bddbb5-84f0-4ac3-9a77-d282f6f21c91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1719625127-172.17.0.9-1597721030536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36208,DS-8d7ab436-4b14-4301-9f8f-e706e9f90ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-ae99d0c1-18de-41d3-a557-115f42441a72,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-fb10c01d-4de4-4d80-b6e4-261e90e2a6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-548391d7-2f79-4ac6-a82d-5187949c2931,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-a25aad87-ac55-44e1-9207-8ae684ecf3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-504ee487-3706-4e79-88e2-cb57da4fef7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-5b20e489-2309-4df0-82cd-f763fdc08308,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-07bddbb5-84f0-4ac3-9a77-d282f6f21c91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-521653973-172.17.0.9-1597721076327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46839,DS-93a7d7a1-26c7-4a85-89c9-d26f58d8e0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-489f9055-e21a-4364-bda5-64ebb5dde0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-6c936fbc-285f-466c-ae6a-2cfcf75f86a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-3cdea826-41d5-411b-91ca-bd9f9adcb1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-a1d5f28c-290a-4a3c-91ec-e41cecee9ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-74fc0ff3-d34d-4040-907a-a1b7a4f70bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38697,DS-f9fe2ba8-291c-4106-a2fd-8f9f61a0049c,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-055cbb4d-fd81-4f56-b120-102c266a8e99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-521653973-172.17.0.9-1597721076327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46839,DS-93a7d7a1-26c7-4a85-89c9-d26f58d8e0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-489f9055-e21a-4364-bda5-64ebb5dde0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-6c936fbc-285f-466c-ae6a-2cfcf75f86a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-3cdea826-41d5-411b-91ca-bd9f9adcb1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-a1d5f28c-290a-4a3c-91ec-e41cecee9ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-74fc0ff3-d34d-4040-907a-a1b7a4f70bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38697,DS-f9fe2ba8-291c-4106-a2fd-8f9f61a0049c,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-055cbb4d-fd81-4f56-b120-102c266a8e99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1363297433-172.17.0.9-1597721407463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34119,DS-f276423b-be83-4033-9677-8d6918bcc898,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-df94ec16-bbd9-48f8-aa63-eadaade4f44e,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-2569f1ea-4c65-4c57-9611-71384618bcdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-128ae53f-7da0-4155-8bfc-d43014d65246,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-418ca574-44d9-4a27-9c17-e182c18c7821,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-b5174e2c-5473-44ab-b18d-ac2d43bb24e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-3f3abf6c-ec78-4249-9da0-deaf6466ea70,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-a51a13bd-3cfa-4112-a654-b0176e226710,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1363297433-172.17.0.9-1597721407463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34119,DS-f276423b-be83-4033-9677-8d6918bcc898,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-df94ec16-bbd9-48f8-aa63-eadaade4f44e,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-2569f1ea-4c65-4c57-9611-71384618bcdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-128ae53f-7da0-4155-8bfc-d43014d65246,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-418ca574-44d9-4a27-9c17-e182c18c7821,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-b5174e2c-5473-44ab-b18d-ac2d43bb24e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-3f3abf6c-ec78-4249-9da0-deaf6466ea70,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-a51a13bd-3cfa-4112-a654-b0176e226710,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.renew-interval
component: hdfs:NameNode
v1: 86400000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-139344409-172.17.0.9-1597721649845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44152,DS-134cf410-53ac-4911-881b-723c718d8f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-ffb419b7-ff89-43f0-a8cf-f53f711f6661,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-8dd0b00a-ca44-43f4-9430-604c5aa9a04e,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-9ada58d5-724b-49d1-8e31-38445e7d7015,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-912b16f8-6ef3-4784-9a3d-c9fe38b16112,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-de5cb7da-f67e-405f-bedb-134bc7a72a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-ae26d1ea-08bc-42a5-b26b-119b3ecd2ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-6cfea31b-5dd0-4a3a-8c24-639ce862a495,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-139344409-172.17.0.9-1597721649845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44152,DS-134cf410-53ac-4911-881b-723c718d8f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-ffb419b7-ff89-43f0-a8cf-f53f711f6661,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-8dd0b00a-ca44-43f4-9430-604c5aa9a04e,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-9ada58d5-724b-49d1-8e31-38445e7d7015,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-912b16f8-6ef3-4784-9a3d-c9fe38b16112,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-de5cb7da-f67e-405f-bedb-134bc7a72a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-ae26d1ea-08bc-42a5-b26b-119b3ecd2ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-6cfea31b-5dd0-4a3a-8c24-639ce862a495,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5605
