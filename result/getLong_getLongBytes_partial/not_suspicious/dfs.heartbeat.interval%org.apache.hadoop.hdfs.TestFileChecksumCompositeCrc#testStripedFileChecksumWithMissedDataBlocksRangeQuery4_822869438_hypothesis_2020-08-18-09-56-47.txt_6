reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-292987069-172.17.0.19-1597745106683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46168,DS-c5ca8eed-a400-40db-9dc4-7f1886f33148,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-9f8e1e48-3192-4ceb-850e-884327e42492,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-d3b23841-741e-4c9d-aa59-506b5a130345,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-ba63d962-132c-43da-918d-108515369959,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-090e0f35-3482-48a5-947c-920b4a0d54d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-124f1263-dbc0-4fae-a254-ee87c8208109,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-782e432b-9bdb-47b8-8eb1-81951f0af60d,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-1323b0d4-60fe-47b4-955a-f4dc15686971,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-292987069-172.17.0.19-1597745106683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46168,DS-c5ca8eed-a400-40db-9dc4-7f1886f33148,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-9f8e1e48-3192-4ceb-850e-884327e42492,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-d3b23841-741e-4c9d-aa59-506b5a130345,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-ba63d962-132c-43da-918d-108515369959,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-090e0f35-3482-48a5-947c-920b4a0d54d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-124f1263-dbc0-4fae-a254-ee87c8208109,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-782e432b-9bdb-47b8-8eb1-81951f0af60d,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-1323b0d4-60fe-47b4-955a-f4dc15686971,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-88455715-172.17.0.19-1597745302665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36028,DS-290c2d3b-706d-4652-ab6f-d47a9168cdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-70d37559-89eb-40a3-9fcd-bcf56261e64b,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-d2ca471a-df23-43ad-84be-c1972c7eb2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-4b34e605-8956-4e26-aa7e-eef08fab5a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-0311b5bc-fc8e-41ed-a274-c1faa810ddae,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-d956f5dc-490a-414f-86e4-12ce7d8d81aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-8cfb0861-7b24-4a22-a80b-8a610878fbce,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-48a6bed4-8b08-4fca-9e7f-772cd958e63c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-88455715-172.17.0.19-1597745302665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36028,DS-290c2d3b-706d-4652-ab6f-d47a9168cdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-70d37559-89eb-40a3-9fcd-bcf56261e64b,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-d2ca471a-df23-43ad-84be-c1972c7eb2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-4b34e605-8956-4e26-aa7e-eef08fab5a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-0311b5bc-fc8e-41ed-a274-c1faa810ddae,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-d956f5dc-490a-414f-86e4-12ce7d8d81aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-8cfb0861-7b24-4a22-a80b-8a610878fbce,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-48a6bed4-8b08-4fca-9e7f-772cd958e63c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960538286-172.17.0.19-1597745550260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41493,DS-b9ac4fa6-a2cd-4562-89bf-77d31316eabe,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-444fcc9d-ab0f-4a21-9dcd-e6344d762129,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-685e0ba8-a798-46ae-9193-5a25979343c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-78fe39be-552d-4ce8-ba37-1afacfc8c5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-e97b8836-a763-4f5d-98ca-852bbff3c5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-e8e0791a-6a81-4224-9994-e760d8dbda7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-36001d14-348a-4cba-b616-7fb2c2af4253,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-abd199b4-f59c-4505-a424-6891fa808b2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960538286-172.17.0.19-1597745550260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41493,DS-b9ac4fa6-a2cd-4562-89bf-77d31316eabe,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-444fcc9d-ab0f-4a21-9dcd-e6344d762129,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-685e0ba8-a798-46ae-9193-5a25979343c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-78fe39be-552d-4ce8-ba37-1afacfc8c5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-e97b8836-a763-4f5d-98ca-852bbff3c5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-e8e0791a-6a81-4224-9994-e760d8dbda7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-36001d14-348a-4cba-b616-7fb2c2af4253,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-abd199b4-f59c-4505-a424-6891fa808b2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664264816-172.17.0.19-1597745825628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43934,DS-2c222e09-0f87-411b-ab3f-7c13e159fa14,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-f8d43b41-8bda-42ce-b474-bb44c822517f,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-2a7ebe05-b6f5-4f1a-a2f5-28d87a03ab83,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-8017f70d-5698-4985-8ce8-6601bae39d40,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-3597e5da-94ce-4f2e-b0c6-a94ad79dcd08,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-d83d2ad3-efbb-4999-b88a-f563df01784e,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-4cd881e0-8e21-4915-aede-5386ab3c4f34,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-91402648-77e2-49bc-a712-c0fb8af739cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664264816-172.17.0.19-1597745825628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43934,DS-2c222e09-0f87-411b-ab3f-7c13e159fa14,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-f8d43b41-8bda-42ce-b474-bb44c822517f,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-2a7ebe05-b6f5-4f1a-a2f5-28d87a03ab83,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-8017f70d-5698-4985-8ce8-6601bae39d40,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-3597e5da-94ce-4f2e-b0c6-a94ad79dcd08,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-d83d2ad3-efbb-4999-b88a-f563df01784e,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-4cd881e0-8e21-4915-aede-5386ab3c4f34,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-91402648-77e2-49bc-a712-c0fb8af739cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2129056055-172.17.0.19-1597746431105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40196,DS-f93e2b5d-e709-496d-afa3-52e901c50a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-753a4337-604f-4c8d-b119-dbc1c5700427,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-99d31e1d-9d43-42c7-a596-57b6381334fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-293281a9-2126-4a67-9c59-88e9ba44ec66,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-e930f8e2-1d76-4bf5-8bc4-0df53e0ee3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-e20ec312-07a1-48f2-8f3b-8ec5210d5d39,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-673e7225-0492-4011-bea4-9b6ee2500182,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-d1440504-b4c9-4baa-a829-9e1d07d244d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2129056055-172.17.0.19-1597746431105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40196,DS-f93e2b5d-e709-496d-afa3-52e901c50a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-753a4337-604f-4c8d-b119-dbc1c5700427,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-99d31e1d-9d43-42c7-a596-57b6381334fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-293281a9-2126-4a67-9c59-88e9ba44ec66,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-e930f8e2-1d76-4bf5-8bc4-0df53e0ee3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-e20ec312-07a1-48f2-8f3b-8ec5210d5d39,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-673e7225-0492-4011-bea4-9b6ee2500182,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-d1440504-b4c9-4baa-a829-9e1d07d244d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-745938930-172.17.0.19-1597746702805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33465,DS-41cab1e8-427e-4ae0-afbe-c781b54c50f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-5b4d1de7-6e9e-478f-8722-fd9c40c3dec0,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-4ac60717-0c2e-4c56-bcde-fd37ed3f80fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-23795f6b-7ead-4e0a-af8f-005cfd8dc478,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-6cc98513-1998-406e-91cc-31d58e17f749,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-57ef0b2e-9290-4d3c-9335-b9f3391edfaf,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-a1d7b949-9a08-49ba-87f7-f5cf6b5accf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-189194a3-5c06-4ffe-a7e9-e7be7cb44e81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-745938930-172.17.0.19-1597746702805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33465,DS-41cab1e8-427e-4ae0-afbe-c781b54c50f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-5b4d1de7-6e9e-478f-8722-fd9c40c3dec0,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-4ac60717-0c2e-4c56-bcde-fd37ed3f80fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-23795f6b-7ead-4e0a-af8f-005cfd8dc478,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-6cc98513-1998-406e-91cc-31d58e17f749,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-57ef0b2e-9290-4d3c-9335-b9f3391edfaf,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-a1d7b949-9a08-49ba-87f7-f5cf6b5accf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-189194a3-5c06-4ffe-a7e9-e7be7cb44e81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950588200-172.17.0.19-1597747388764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44414,DS-ea4be039-e7ad-41e3-8f4f-34e3e57c54c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-8f84c021-9280-4a65-9c69-6bec8561a368,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-993ce79f-d05a-4052-9d1d-01ca88ce3568,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-b874a018-cf1d-4b2f-a627-3dcc46f17939,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-7d0e3ce8-5088-407e-9a7e-25d2e8732c55,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-3793bcfb-a370-41a8-84fa-5b659aff2484,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-ac7785f8-1b3a-4a3f-b7f9-509f52c2d457,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-ae34224e-dd7e-4f93-a8d7-7aad5bde4840,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950588200-172.17.0.19-1597747388764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44414,DS-ea4be039-e7ad-41e3-8f4f-34e3e57c54c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-8f84c021-9280-4a65-9c69-6bec8561a368,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-993ce79f-d05a-4052-9d1d-01ca88ce3568,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-b874a018-cf1d-4b2f-a627-3dcc46f17939,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-7d0e3ce8-5088-407e-9a7e-25d2e8732c55,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-3793bcfb-a370-41a8-84fa-5b659aff2484,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-ac7785f8-1b3a-4a3f-b7f9-509f52c2d457,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-ae34224e-dd7e-4f93-a8d7-7aad5bde4840,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-468859481-172.17.0.19-1597747789620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41270,DS-42faceb6-d809-4d4d-af8c-cbfa2111c589,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-bec8fd8a-6c3b-4d71-b012-0cb2bbfac5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-54c24176-76ce-41c3-b849-edd04bc583f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-e4ebd82d-ac3e-4390-8412-20f84ecf6027,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-03e4ba66-7c77-434f-b3a7-7834bb1a9828,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-6ea75970-c03b-4bfd-9725-adc3fce9586c,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-6f0ec551-cb73-4ff1-a453-6a02e42e4835,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-bbedfc73-1ba7-4b60-9d79-9832a89f65b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-468859481-172.17.0.19-1597747789620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41270,DS-42faceb6-d809-4d4d-af8c-cbfa2111c589,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-bec8fd8a-6c3b-4d71-b012-0cb2bbfac5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-54c24176-76ce-41c3-b849-edd04bc583f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-e4ebd82d-ac3e-4390-8412-20f84ecf6027,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-03e4ba66-7c77-434f-b3a7-7834bb1a9828,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-6ea75970-c03b-4bfd-9725-adc3fce9586c,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-6f0ec551-cb73-4ff1-a453-6a02e42e4835,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-bbedfc73-1ba7-4b60-9d79-9832a89f65b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976279629-172.17.0.19-1597747891846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39949,DS-563514a2-30b9-4385-9d36-7468dbabe335,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-d2091d42-7272-43c7-a7f4-91349ce4f236,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-35d15754-beeb-42a7-a30c-a586e94be3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-64d75532-301f-4982-8524-663299895da6,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-c6cc6771-5c01-43cc-9b76-a2e98179b79e,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-0a1707d8-d8a1-4077-b8ae-b6045caf2c29,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-54c9c735-481b-47d8-965b-79fb5aa1f598,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-8e662839-a1ce-48e4-aac3-7588d27651d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976279629-172.17.0.19-1597747891846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39949,DS-563514a2-30b9-4385-9d36-7468dbabe335,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-d2091d42-7272-43c7-a7f4-91349ce4f236,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-35d15754-beeb-42a7-a30c-a586e94be3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-64d75532-301f-4982-8524-663299895da6,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-c6cc6771-5c01-43cc-9b76-a2e98179b79e,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-0a1707d8-d8a1-4077-b8ae-b6045caf2c29,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-54c9c735-481b-47d8-965b-79fb5aa1f598,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-8e662839-a1ce-48e4-aac3-7588d27651d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1006322740-172.17.0.19-1597748004773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34375,DS-e5dc75aa-3d25-4daa-93e0-ef30f32f7e44,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-ca7e1cb6-d117-455a-94e3-7ed98ca21bef,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-fd4b3378-f8a6-477e-8388-6b16e12e9a10,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-e181c76d-9b60-4c1e-8a97-21a513943953,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-6ae938e0-1469-4692-994e-281f76e96eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-31e73383-3368-4870-84a6-272c325cd31f,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-4d058c04-4038-4969-9a01-3c6f1eed4eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-e5b6d3f3-4221-48db-85fb-d783de41c52c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1006322740-172.17.0.19-1597748004773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34375,DS-e5dc75aa-3d25-4daa-93e0-ef30f32f7e44,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-ca7e1cb6-d117-455a-94e3-7ed98ca21bef,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-fd4b3378-f8a6-477e-8388-6b16e12e9a10,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-e181c76d-9b60-4c1e-8a97-21a513943953,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-6ae938e0-1469-4692-994e-281f76e96eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-31e73383-3368-4870-84a6-272c325cd31f,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-4d058c04-4038-4969-9a01-3c6f1eed4eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-e5b6d3f3-4221-48db-85fb-d783de41c52c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603287440-172.17.0.19-1597748452365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37807,DS-f11e0719-c9be-4f85-86f2-c2e3245b811d,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-fbb81e4b-a3b8-49c1-bd5a-d5f560966441,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-59d32bdc-686e-47cf-98cd-9c3d46454a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-a1e715c0-dd61-4c01-8ca3-2e2cef63a908,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-6371a03b-362f-4c3a-b3ba-a6d98e0cc6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-23a854f8-6f7e-47b4-93c6-155477c71211,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-457cf9ca-8d2f-4102-894b-3b1b34584fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-452bc566-5e30-4f78-8544-579308ddb899,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603287440-172.17.0.19-1597748452365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37807,DS-f11e0719-c9be-4f85-86f2-c2e3245b811d,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-fbb81e4b-a3b8-49c1-bd5a-d5f560966441,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-59d32bdc-686e-47cf-98cd-9c3d46454a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-a1e715c0-dd61-4c01-8ca3-2e2cef63a908,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-6371a03b-362f-4c3a-b3ba-a6d98e0cc6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-23a854f8-6f7e-47b4-93c6-155477c71211,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-457cf9ca-8d2f-4102-894b-3b1b34584fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-452bc566-5e30-4f78-8544-579308ddb899,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1873751435-172.17.0.19-1597749037794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33744,DS-531166ea-65a0-4ceb-b2b6-129f8a5be6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-e862a2e9-c929-4f71-a760-618403a99acb,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-fe172535-a355-489e-9221-6a0904fdf7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-207665aa-2d48-4ac1-b34d-94e1e4b6ea65,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-bfdf1c46-494c-41d0-9106-68e5454a9435,DISK], DatanodeInfoWithStorage[127.0.0.1:37651,DS-64ce2cc1-fee7-47c3-bc19-17c92f61c37d,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-088f716d-7a0a-47f6-b599-50204b6d9d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-6443af4f-02bd-40af-99ab-b4ea31c22c25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1873751435-172.17.0.19-1597749037794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33744,DS-531166ea-65a0-4ceb-b2b6-129f8a5be6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-e862a2e9-c929-4f71-a760-618403a99acb,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-fe172535-a355-489e-9221-6a0904fdf7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-207665aa-2d48-4ac1-b34d-94e1e4b6ea65,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-bfdf1c46-494c-41d0-9106-68e5454a9435,DISK], DatanodeInfoWithStorage[127.0.0.1:37651,DS-64ce2cc1-fee7-47c3-bc19-17c92f61c37d,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-088f716d-7a0a-47f6-b599-50204b6d9d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-6443af4f-02bd-40af-99ab-b4ea31c22c25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-715015172-172.17.0.19-1597750017216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36195,DS-8407de5f-cf97-4a02-9f46-cfb6e93a882a,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-478741e5-958b-4ea6-9dde-e0d465d6331a,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-8d022b08-6435-44d6-a0d8-160660ebe516,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-cdd4e935-edb5-46c3-b4f6-b58b7d30b00d,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-b98ff54e-f048-4ead-a2fc-250d26f6955b,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-6754ba27-9219-4bc2-8dab-38de60c3b214,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-40b95e8d-45c2-4439-b648-7aac443d6fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-00ce690e-1c9f-4959-8e44-3f2d57092094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-715015172-172.17.0.19-1597750017216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36195,DS-8407de5f-cf97-4a02-9f46-cfb6e93a882a,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-478741e5-958b-4ea6-9dde-e0d465d6331a,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-8d022b08-6435-44d6-a0d8-160660ebe516,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-cdd4e935-edb5-46c3-b4f6-b58b7d30b00d,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-b98ff54e-f048-4ead-a2fc-250d26f6955b,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-6754ba27-9219-4bc2-8dab-38de60c3b214,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-40b95e8d-45c2-4439-b648-7aac443d6fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-00ce690e-1c9f-4959-8e44-3f2d57092094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5628
