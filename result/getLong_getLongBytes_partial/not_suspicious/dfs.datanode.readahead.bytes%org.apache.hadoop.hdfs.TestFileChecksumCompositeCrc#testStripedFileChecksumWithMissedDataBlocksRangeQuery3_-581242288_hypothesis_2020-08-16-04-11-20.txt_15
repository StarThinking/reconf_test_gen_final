reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-982562162-172.17.0.17-1597551322683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41995,DS-4732b95b-b878-43b9-a629-dd6818435a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-7d0bc4dc-71d1-4a5f-b5b1-9325812be1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-c2368bfa-a8a0-4ba4-b0c8-7ceae3e8341e,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-d56dcf20-d5e4-4cf5-952f-6555ced834c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-a9b1f0db-99c3-4960-bc9b-fc34912ded0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-65bbf67f-458d-4425-910c-2597ccdb1442,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-c85a7579-1b48-4828-b932-7aa56b78ffd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-d7456093-98df-418a-bc86-d3ed81c57b82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-982562162-172.17.0.17-1597551322683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41995,DS-4732b95b-b878-43b9-a629-dd6818435a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-7d0bc4dc-71d1-4a5f-b5b1-9325812be1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-c2368bfa-a8a0-4ba4-b0c8-7ceae3e8341e,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-d56dcf20-d5e4-4cf5-952f-6555ced834c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-a9b1f0db-99c3-4960-bc9b-fc34912ded0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-65bbf67f-458d-4425-910c-2597ccdb1442,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-c85a7579-1b48-4828-b932-7aa56b78ffd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-d7456093-98df-418a-bc86-d3ed81c57b82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-532911162-172.17.0.17-1597551458804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37879,DS-2dbd3fb0-d494-492d-a583-248f504246df,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-55c68767-916d-4db6-af35-1fa6ed65cc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-2bcab7dc-e710-4453-806e-9ff700877145,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-1c2e5be6-01be-4121-a6f0-1d49a4384b62,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-3fbd931d-2393-4baf-9e35-b90d117140b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-0ee8816d-7ac0-4ce8-a76c-574f4227e3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-40d72b22-cd0d-476f-bc16-6f43f8302106,DISK], DatanodeInfoWithStorage[127.0.0.1:37352,DS-c04b6810-e7e9-4abb-b961-56d9604599f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-532911162-172.17.0.17-1597551458804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37879,DS-2dbd3fb0-d494-492d-a583-248f504246df,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-55c68767-916d-4db6-af35-1fa6ed65cc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-2bcab7dc-e710-4453-806e-9ff700877145,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-1c2e5be6-01be-4121-a6f0-1d49a4384b62,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-3fbd931d-2393-4baf-9e35-b90d117140b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-0ee8816d-7ac0-4ce8-a76c-574f4227e3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-40d72b22-cd0d-476f-bc16-6f43f8302106,DISK], DatanodeInfoWithStorage[127.0.0.1:37352,DS-c04b6810-e7e9-4abb-b961-56d9604599f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1713763229-172.17.0.17-1597551502945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42550,DS-c5b448c4-b988-4c1d-9cae-c71d5d01991d,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-fb27af55-e722-4b22-9739-0d9c228e35c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-31a28bed-888e-411c-a741-33cd235b0bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-72b2a61d-522e-4cdb-84c6-f458b981050f,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-eeb53456-e84b-4c5c-b3ed-6452369acb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-9dcb4717-1133-4558-86f9-bf013f767081,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-ee7fae29-2d73-47b7-8b27-9e0c26c52f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-8dd5635f-18a9-4a28-876e-085d7f03f7cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1713763229-172.17.0.17-1597551502945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42550,DS-c5b448c4-b988-4c1d-9cae-c71d5d01991d,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-fb27af55-e722-4b22-9739-0d9c228e35c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-31a28bed-888e-411c-a741-33cd235b0bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-72b2a61d-522e-4cdb-84c6-f458b981050f,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-eeb53456-e84b-4c5c-b3ed-6452369acb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-9dcb4717-1133-4558-86f9-bf013f767081,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-ee7fae29-2d73-47b7-8b27-9e0c26c52f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-8dd5635f-18a9-4a28-876e-085d7f03f7cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-266636595-172.17.0.17-1597552058902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35211,DS-61c5e4f1-1f53-45fc-8cbe-9af2889d2c34,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-fb4a53c5-df87-4f9c-906a-8ead8e2456a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-18669053-0288-493c-816d-daf0f0b51a39,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-1ff12523-913d-446c-9877-ea9584125f97,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-34e02561-27fe-4513-8839-67e71b1d054d,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-df7e142a-8293-4add-afcf-b07787bc0140,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-19f69b2b-9b9e-4a0c-8a8c-8feec8c86f80,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-c2546788-0e49-428a-b573-23319c99acfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-266636595-172.17.0.17-1597552058902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35211,DS-61c5e4f1-1f53-45fc-8cbe-9af2889d2c34,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-fb4a53c5-df87-4f9c-906a-8ead8e2456a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-18669053-0288-493c-816d-daf0f0b51a39,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-1ff12523-913d-446c-9877-ea9584125f97,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-34e02561-27fe-4513-8839-67e71b1d054d,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-df7e142a-8293-4add-afcf-b07787bc0140,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-19f69b2b-9b9e-4a0c-8a8c-8feec8c86f80,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-c2546788-0e49-428a-b573-23319c99acfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258453338-172.17.0.17-1597552146798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37781,DS-c095a19f-4471-4e99-8da6-fd7c5142983c,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-2ea57a1a-75cc-4d67-be0e-ca7285883c64,DISK], DatanodeInfoWithStorage[127.0.0.1:44013,DS-21be1a33-90dc-4406-b053-21446697f632,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-8a0beac8-97a8-4b0b-b886-9cc17802880c,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-6b4e2c05-ea9e-4984-934d-533f8449aa95,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-46aff774-7afc-43a4-8a1c-5958f9f5d7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-8cfa1850-2dd6-463e-89f7-52fdc0797ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-9870427f-5fe1-4679-907b-f52f19097667,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258453338-172.17.0.17-1597552146798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37781,DS-c095a19f-4471-4e99-8da6-fd7c5142983c,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-2ea57a1a-75cc-4d67-be0e-ca7285883c64,DISK], DatanodeInfoWithStorage[127.0.0.1:44013,DS-21be1a33-90dc-4406-b053-21446697f632,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-8a0beac8-97a8-4b0b-b886-9cc17802880c,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-6b4e2c05-ea9e-4984-934d-533f8449aa95,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-46aff774-7afc-43a4-8a1c-5958f9f5d7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-8cfa1850-2dd6-463e-89f7-52fdc0797ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-9870427f-5fe1-4679-907b-f52f19097667,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1464384241-172.17.0.17-1597552634173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37436,DS-fd77f7da-d752-4bcb-9f24-d8e8ccd15ada,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-7b2c8464-7cc4-4784-a33a-ffc7c0e0ebde,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-2dd560ea-47a2-4d54-9d75-4e227b6dcfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-aa498e4d-a243-4beb-9e5c-18377f48e1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-2501f8dd-439c-46cc-a87e-6ba5c85d8537,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-44cb1ae2-2a0f-4a92-80e8-0e4f30622cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-aa69e77e-be7d-4ccc-a211-61904c7f72f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33595,DS-95ccbafc-f31a-4461-a6a8-8ebe9619d60c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1464384241-172.17.0.17-1597552634173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37436,DS-fd77f7da-d752-4bcb-9f24-d8e8ccd15ada,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-7b2c8464-7cc4-4784-a33a-ffc7c0e0ebde,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-2dd560ea-47a2-4d54-9d75-4e227b6dcfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-aa498e4d-a243-4beb-9e5c-18377f48e1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-2501f8dd-439c-46cc-a87e-6ba5c85d8537,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-44cb1ae2-2a0f-4a92-80e8-0e4f30622cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42093,DS-aa69e77e-be7d-4ccc-a211-61904c7f72f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33595,DS-95ccbafc-f31a-4461-a6a8-8ebe9619d60c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1484269219-172.17.0.17-1597552922960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33600,DS-212b5e63-15f9-496e-96ad-44b7e99291fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-ccbf2abb-9d30-4e09-bb7b-920560e876c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-89c6e802-6259-48cb-a204-ae91c8b01c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-23e25fda-485d-4cdd-aaee-b5f94fc22e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-db7ab881-67d8-4af5-b799-b87612df481a,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-246ad2d5-283f-4df9-a1aa-4362db1ed89c,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-6ca64054-e596-4a62-b85b-a4aed284c3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-33234a5d-1aca-47e8-acc9-1d7e8d240e52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1484269219-172.17.0.17-1597552922960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33600,DS-212b5e63-15f9-496e-96ad-44b7e99291fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-ccbf2abb-9d30-4e09-bb7b-920560e876c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-89c6e802-6259-48cb-a204-ae91c8b01c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35962,DS-23e25fda-485d-4cdd-aaee-b5f94fc22e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-db7ab881-67d8-4af5-b799-b87612df481a,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-246ad2d5-283f-4df9-a1aa-4362db1ed89c,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-6ca64054-e596-4a62-b85b-a4aed284c3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-33234a5d-1aca-47e8-acc9-1d7e8d240e52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204817760-172.17.0.17-1597552962845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39911,DS-59025c8b-1931-4606-ac1e-96b5ea447f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-c992d897-31d0-4b25-af59-3832c54bbe4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-fe636938-b75b-4ff6-9560-0e582cea53c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-9af74c8e-36b2-4c93-8818-f72072812730,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-d4b77def-f404-4b72-a199-81e71e8a449c,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-c2f0e0ff-22a0-44d1-988f-01ce6ade546c,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-2639468c-593a-41df-b704-2f72bd28f16d,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-0bad3d31-c34f-41e8-b0a9-67a26a7c9487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204817760-172.17.0.17-1597552962845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39911,DS-59025c8b-1931-4606-ac1e-96b5ea447f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-c992d897-31d0-4b25-af59-3832c54bbe4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-fe636938-b75b-4ff6-9560-0e582cea53c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-9af74c8e-36b2-4c93-8818-f72072812730,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-d4b77def-f404-4b72-a199-81e71e8a449c,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-c2f0e0ff-22a0-44d1-988f-01ce6ade546c,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-2639468c-593a-41df-b704-2f72bd28f16d,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-0bad3d31-c34f-41e8-b0a9-67a26a7c9487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1230440817-172.17.0.17-1597553052425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40607,DS-34e42f73-fe0b-4a74-841a-09aa0ebd9e58,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-4d3717fb-8202-4045-8eab-5e8249efe964,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-b79c605a-6b30-45ee-91d3-11928ea6813f,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-08aa9276-8d88-4c9f-b7e5-f41cb9859656,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-ec74f1c8-edbe-47d9-b196-b213ec85ff9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-b0615718-b319-4332-a89b-9fcf41c0380f,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-1fcdc916-b1e1-40ef-abf9-9aa1c666e616,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-4b61a03b-d5f8-420f-a6c8-b7d90d42530e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1230440817-172.17.0.17-1597553052425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40607,DS-34e42f73-fe0b-4a74-841a-09aa0ebd9e58,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-4d3717fb-8202-4045-8eab-5e8249efe964,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-b79c605a-6b30-45ee-91d3-11928ea6813f,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-08aa9276-8d88-4c9f-b7e5-f41cb9859656,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-ec74f1c8-edbe-47d9-b196-b213ec85ff9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-b0615718-b319-4332-a89b-9fcf41c0380f,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-1fcdc916-b1e1-40ef-abf9-9aa1c666e616,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-4b61a03b-d5f8-420f-a6c8-b7d90d42530e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1627351047-172.17.0.17-1597553928259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40403,DS-dc8cf701-e6ac-427b-8ac6-05f06c769bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-c67ab534-3d02-45ad-bcff-06ad05f63784,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-a3ad182f-9e06-46d6-97b2-1b3a6877aa37,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-c9911728-7f54-4ca8-924a-7a868272d297,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-56b78181-fd67-405f-97e7-2c012d586b51,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-4615fc18-3aa5-44d2-abae-6b2fb1ee6786,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-8510c0ef-69da-4ac4-802b-2156a4dd9d74,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-c3b81e03-230f-4567-8459-813e2727eca9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1627351047-172.17.0.17-1597553928259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40403,DS-dc8cf701-e6ac-427b-8ac6-05f06c769bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-c67ab534-3d02-45ad-bcff-06ad05f63784,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-a3ad182f-9e06-46d6-97b2-1b3a6877aa37,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-c9911728-7f54-4ca8-924a-7a868272d297,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-56b78181-fd67-405f-97e7-2c012d586b51,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-4615fc18-3aa5-44d2-abae-6b2fb1ee6786,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-8510c0ef-69da-4ac4-802b-2156a4dd9d74,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-c3b81e03-230f-4567-8459-813e2727eca9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-5701992-172.17.0.17-1597554075323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34657,DS-225f68fc-9b0a-4205-877f-325728b6f79d,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-d98d8d16-32fa-4d4e-8af4-8345748cc327,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-f87ee98a-8154-43fc-8e79-cd2117f24e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-60714118-0b23-40bc-8b77-f5fd346fbe98,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-b0f17ee0-4897-4a48-8b92-de040b1a29e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-6804a9bb-64e2-457a-8d57-7b0ec72f41c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-38f0951d-6e39-440e-b3bb-6f4855756176,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-8d267022-a1f3-40cb-9c98-da0867b1257c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-5701992-172.17.0.17-1597554075323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34657,DS-225f68fc-9b0a-4205-877f-325728b6f79d,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-d98d8d16-32fa-4d4e-8af4-8345748cc327,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-f87ee98a-8154-43fc-8e79-cd2117f24e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-60714118-0b23-40bc-8b77-f5fd346fbe98,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-b0f17ee0-4897-4a48-8b92-de040b1a29e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-6804a9bb-64e2-457a-8d57-7b0ec72f41c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-38f0951d-6e39-440e-b3bb-6f4855756176,DISK], DatanodeInfoWithStorage[127.0.0.1:46828,DS-8d267022-a1f3-40cb-9c98-da0867b1257c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1030198259-172.17.0.17-1597554221543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41428,DS-117b773f-6a17-46c0-bd94-1a0ddb410aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-7ec7f9b0-2a3c-4327-8b09-14aa04a578f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-bb69303d-9bc2-496f-92e0-fb43ce17754c,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-508078db-e25c-4bf1-afc9-742a63df462e,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-b7bfc9b5-a720-4213-9544-3c368cd7e569,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-17dc2f07-2181-4050-85c3-98cf719abe28,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-c4086c57-06a6-4a75-8c54-f99b9a5931da,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-8cd7b11e-7053-4ea0-ab94-631db63fdc50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1030198259-172.17.0.17-1597554221543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41428,DS-117b773f-6a17-46c0-bd94-1a0ddb410aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-7ec7f9b0-2a3c-4327-8b09-14aa04a578f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-bb69303d-9bc2-496f-92e0-fb43ce17754c,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-508078db-e25c-4bf1-afc9-742a63df462e,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-b7bfc9b5-a720-4213-9544-3c368cd7e569,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-17dc2f07-2181-4050-85c3-98cf719abe28,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-c4086c57-06a6-4a75-8c54-f99b9a5931da,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-8cd7b11e-7053-4ea0-ab94-631db63fdc50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964241288-172.17.0.17-1597554369814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41380,DS-ead8e723-e3b4-42de-a8dd-5533e8c660ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-0424ff2d-9ca0-48d4-bf72-eaab05ad353e,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-05937514-4adf-419c-b177-566bd8eaa3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-c2ecca04-966c-4d9b-ab0a-75d2308faeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-db68d2ad-438b-4f00-ba59-45d93339ce07,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-be496499-28c1-4755-b543-9ef8f3bbd6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-51f5e636-a2ab-45c7-a722-5aaa9f2ca4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-01e272f5-b5a8-4444-b2c8-8caeea1f2ae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964241288-172.17.0.17-1597554369814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41380,DS-ead8e723-e3b4-42de-a8dd-5533e8c660ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-0424ff2d-9ca0-48d4-bf72-eaab05ad353e,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-05937514-4adf-419c-b177-566bd8eaa3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-c2ecca04-966c-4d9b-ab0a-75d2308faeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-db68d2ad-438b-4f00-ba59-45d93339ce07,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-be496499-28c1-4755-b543-9ef8f3bbd6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-51f5e636-a2ab-45c7-a722-5aaa9f2ca4f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-01e272f5-b5a8-4444-b2c8-8caeea1f2ae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765150602-172.17.0.17-1597554933206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36353,DS-5c7c5b75-3b78-4ab7-b0e1-81bcf7d06ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-b95a0ac6-f48f-4b4b-9a81-eeb14088566b,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-dff1e7fa-2a18-4b3b-8ec9-7156fe9146de,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-c1463773-c5c5-4b4c-aa85-77d7e9470ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-5d3775ae-a1b1-45a5-af25-99c2a5bad772,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-dd5ad569-a238-47e6-9317-51ae607c0cde,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-7e55e90e-0a6e-4113-9207-9c7a81d08546,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-856d44e3-5d69-417e-b2f6-dc0536413135,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765150602-172.17.0.17-1597554933206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36353,DS-5c7c5b75-3b78-4ab7-b0e1-81bcf7d06ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-b95a0ac6-f48f-4b4b-9a81-eeb14088566b,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-dff1e7fa-2a18-4b3b-8ec9-7156fe9146de,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-c1463773-c5c5-4b4c-aa85-77d7e9470ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-5d3775ae-a1b1-45a5-af25-99c2a5bad772,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-dd5ad569-a238-47e6-9317-51ae607c0cde,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-7e55e90e-0a6e-4113-9207-9c7a81d08546,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-856d44e3-5d69-417e-b2f6-dc0536413135,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488555366-172.17.0.17-1597555641552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45221,DS-5816125d-a776-4778-8cf8-f151902ea0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-6ddaaff2-b352-4a58-b5bc-09c4713770b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-f56fc25d-4378-4094-a9d6-d1b2d32b16fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-52ec7f82-b014-40c0-9d26-80585d822194,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-febd66de-b793-4b87-b31c-3754947b33b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-f9aec652-7925-4d54-bf70-5e1930437c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-252c218b-5300-4f36-a2e7-47f1a68e87c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-fcda7478-a9f9-455a-8bb8-8a622f1644cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488555366-172.17.0.17-1597555641552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45221,DS-5816125d-a776-4778-8cf8-f151902ea0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-6ddaaff2-b352-4a58-b5bc-09c4713770b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-f56fc25d-4378-4094-a9d6-d1b2d32b16fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-52ec7f82-b014-40c0-9d26-80585d822194,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-febd66de-b793-4b87-b31c-3754947b33b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-f9aec652-7925-4d54-bf70-5e1930437c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-252c218b-5300-4f36-a2e7-47f1a68e87c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-fcda7478-a9f9-455a-8bb8-8a622f1644cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1196095712-172.17.0.17-1597555843331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40177,DS-101c0a36-1578-4d92-a21c-25c723c4e894,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-0fb0df33-c6a6-429a-8805-58d86074844a,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-ba6f6e1a-14d0-4d63-969e-28cdec0a9bad,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-2f2a3d2c-11e4-4ad1-9b8a-3f0984cb6c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-9bf558a2-e96e-4495-b45b-767b0dcf04f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-15990612-6a93-4582-9a47-2f5b19bd1173,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-3e34ca3b-a087-4a3b-9c85-f842c701e8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-18f8a878-69d6-4a9e-9f3e-c4c04de07df5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1196095712-172.17.0.17-1597555843331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40177,DS-101c0a36-1578-4d92-a21c-25c723c4e894,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-0fb0df33-c6a6-429a-8805-58d86074844a,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-ba6f6e1a-14d0-4d63-969e-28cdec0a9bad,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-2f2a3d2c-11e4-4ad1-9b8a-3f0984cb6c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-9bf558a2-e96e-4495-b45b-767b0dcf04f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-15990612-6a93-4582-9a47-2f5b19bd1173,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-3e34ca3b-a087-4a3b-9c85-f842c701e8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-18f8a878-69d6-4a9e-9f3e-c4c04de07df5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029259432-172.17.0.17-1597556209855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42132,DS-49e2cd3b-fff7-41b3-bb5b-84deab1e7974,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-b465d512-fc34-4517-bf72-c99f7c352b12,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-c0c0a9e3-87e7-4e65-a235-25bb02e6b3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-72793ef9-d287-45c5-bdf9-8037b37b893f,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-ff8d6ee0-89a3-49ed-a489-3c5434127f16,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-dc2117b9-6eac-4eff-9863-d0702c32f433,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-767ac1a4-6bf7-4dee-877a-91c6d275d051,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-a8290f46-f61f-4525-a1f4-7c1fa1b028b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029259432-172.17.0.17-1597556209855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42132,DS-49e2cd3b-fff7-41b3-bb5b-84deab1e7974,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-b465d512-fc34-4517-bf72-c99f7c352b12,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-c0c0a9e3-87e7-4e65-a235-25bb02e6b3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-72793ef9-d287-45c5-bdf9-8037b37b893f,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-ff8d6ee0-89a3-49ed-a489-3c5434127f16,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-dc2117b9-6eac-4eff-9863-d0702c32f433,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-767ac1a4-6bf7-4dee-877a-91c6d275d051,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-a8290f46-f61f-4525-a1f4-7c1fa1b028b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1073857599-172.17.0.17-1597556295368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34264,DS-647a0587-0284-45ed-a913-52d60553497a,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-b7f1b6c6-65bf-4558-9304-470dd8188607,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-14e139af-53ab-4b11-b962-27827982a225,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-8aa3fe4b-d133-4490-9bd3-2a673d8d2546,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-db82c19c-667d-4529-8647-e9d1dbf89466,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-2b56ca39-be82-49c3-852e-3bfca7ab5e04,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-ccf1840e-fb98-42ff-b7a6-0827669dd5da,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-b9ed1ac1-9024-4c8a-a4cf-7f4f8e0c6c4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1073857599-172.17.0.17-1597556295368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34264,DS-647a0587-0284-45ed-a913-52d60553497a,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-b7f1b6c6-65bf-4558-9304-470dd8188607,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-14e139af-53ab-4b11-b962-27827982a225,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-8aa3fe4b-d133-4490-9bd3-2a673d8d2546,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-db82c19c-667d-4529-8647-e9d1dbf89466,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-2b56ca39-be82-49c3-852e-3bfca7ab5e04,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-ccf1840e-fb98-42ff-b7a6-0827669dd5da,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-b9ed1ac1-9024-4c8a-a4cf-7f4f8e0c6c4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-872830685-172.17.0.17-1597556624505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40403,DS-35092871-2d41-4995-ac8e-0479525bba62,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-05cac05c-b19c-4c72-b32c-f50baf472040,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-1c38051d-0bb4-46f7-aa29-240db6ff7f10,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-eb2a2666-0e22-48c8-8f2c-8cc53a1fd5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-42dabd4f-7e92-4822-b141-1fec592101ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-233830a3-1474-4490-81bb-490d32c1df0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-2f9cb873-135a-43d7-958f-8dd5239fd3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-4f30bd3d-5f1c-4667-90c4-dd0916a3cfed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-872830685-172.17.0.17-1597556624505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40403,DS-35092871-2d41-4995-ac8e-0479525bba62,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-05cac05c-b19c-4c72-b32c-f50baf472040,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-1c38051d-0bb4-46f7-aa29-240db6ff7f10,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-eb2a2666-0e22-48c8-8f2c-8cc53a1fd5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-42dabd4f-7e92-4822-b141-1fec592101ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-233830a3-1474-4490-81bb-490d32c1df0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-2f9cb873-135a-43d7-958f-8dd5239fd3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-4f30bd3d-5f1c-4667-90c4-dd0916a3cfed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155640997-172.17.0.17-1597557754124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44142,DS-14fb43f7-9a50-4eda-a1bd-e94c4ff59765,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-3ddc11ad-0c68-44fa-a998-f3f5a752a4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-132ae64c-a317-4799-ad2c-86f894703acc,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-8bfb54c3-3c28-4f18-9de7-932388ef9639,DISK], DatanodeInfoWithStorage[127.0.0.1:38766,DS-b5eb7ef9-96df-423c-aee7-b8e4c7404066,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-6749b502-37c7-433d-b6ff-c7114133dfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-d3328e88-90b7-4781-8e19-54a049eba3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-ae6f1018-4316-4389-a9df-43d6ee591072,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155640997-172.17.0.17-1597557754124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44142,DS-14fb43f7-9a50-4eda-a1bd-e94c4ff59765,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-3ddc11ad-0c68-44fa-a998-f3f5a752a4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-132ae64c-a317-4799-ad2c-86f894703acc,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-8bfb54c3-3c28-4f18-9de7-932388ef9639,DISK], DatanodeInfoWithStorage[127.0.0.1:38766,DS-b5eb7ef9-96df-423c-aee7-b8e4c7404066,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-6749b502-37c7-433d-b6ff-c7114133dfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-d3328e88-90b7-4781-8e19-54a049eba3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-ae6f1018-4316-4389-a9df-43d6ee591072,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 6789
