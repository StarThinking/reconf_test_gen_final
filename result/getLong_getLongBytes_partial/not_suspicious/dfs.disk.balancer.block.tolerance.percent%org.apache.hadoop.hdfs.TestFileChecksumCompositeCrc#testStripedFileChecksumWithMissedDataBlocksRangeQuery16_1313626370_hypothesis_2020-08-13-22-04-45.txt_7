reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1764809640-172.17.0.15-1597357970324:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40840,DS-8a3707e1-056e-4cdd-9d1e-8a617e95bc91,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-1175b9d8-8954-4433-9314-62990fe4e12a,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-e4855912-9744-4631-9447-ba966508a363,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-ecdde448-a4c3-4415-9cc3-0b9bf5b01ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-45a9c09e-7297-4a7d-9036-15fccad5ccf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-1c98ca30-7397-44fa-8c8c-e6266a814f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-e058a29c-2e14-48a3-8e68-58e030700f86,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-0e84f332-8533-4409-a57a-251747dacf86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1764809640-172.17.0.15-1597357970324:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40840,DS-8a3707e1-056e-4cdd-9d1e-8a617e95bc91,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-1175b9d8-8954-4433-9314-62990fe4e12a,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-e4855912-9744-4631-9447-ba966508a363,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-ecdde448-a4c3-4415-9cc3-0b9bf5b01ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-45a9c09e-7297-4a7d-9036-15fccad5ccf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-1c98ca30-7397-44fa-8c8c-e6266a814f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-e058a29c-2e14-48a3-8e68-58e030700f86,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-0e84f332-8533-4409-a57a-251747dacf86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-252440793-172.17.0.15-1597358144008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45581,DS-419d111b-bb63-429a-8d3f-e4dcdfb1686a,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-22724291-4d20-4fe1-923b-52ac50f227a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-c24ca782-f3d5-4092-bc27-c98a871e63cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-f4b55663-ec6e-4e7c-bfb8-ba513a57e363,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-2e608748-fc49-4dbf-9e98-8e3040f1f0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-23ad7c54-64b6-4651-9f0f-ffe08aa835ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-d8f8491f-947d-4be9-8cda-5c9106a1786e,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-3c306547-90b8-4841-8cb9-bbbae4aeccf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-252440793-172.17.0.15-1597358144008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45581,DS-419d111b-bb63-429a-8d3f-e4dcdfb1686a,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-22724291-4d20-4fe1-923b-52ac50f227a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-c24ca782-f3d5-4092-bc27-c98a871e63cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-f4b55663-ec6e-4e7c-bfb8-ba513a57e363,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-2e608748-fc49-4dbf-9e98-8e3040f1f0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-23ad7c54-64b6-4651-9f0f-ffe08aa835ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-d8f8491f-947d-4be9-8cda-5c9106a1786e,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-3c306547-90b8-4841-8cb9-bbbae4aeccf8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-672490651-172.17.0.15-1597358724158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32812,DS-618dc3d8-0808-4b57-91fa-9331ec9b6101,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-05d56a39-31c4-4c77-87ce-a5d209024879,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-a167fa3b-ecfb-4c2e-99fe-a97e41184017,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-42223bfc-9cd6-4ffe-8f64-d8d5b154512e,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-f59b4338-7e4d-4ff5-bcf0-d7ba001fbc65,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-c9e35537-48bc-48eb-bbb7-b07d0f336676,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-32579b66-daba-4a74-bb9d-d2a2395620c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-802a9d4e-7b69-4666-be83-837072ac6178,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-672490651-172.17.0.15-1597358724158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32812,DS-618dc3d8-0808-4b57-91fa-9331ec9b6101,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-05d56a39-31c4-4c77-87ce-a5d209024879,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-a167fa3b-ecfb-4c2e-99fe-a97e41184017,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-42223bfc-9cd6-4ffe-8f64-d8d5b154512e,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-f59b4338-7e4d-4ff5-bcf0-d7ba001fbc65,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-c9e35537-48bc-48eb-bbb7-b07d0f336676,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-32579b66-daba-4a74-bb9d-d2a2395620c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-802a9d4e-7b69-4666-be83-837072ac6178,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-434941055-172.17.0.15-1597358771360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43717,DS-694f751f-c1ec-4aa7-87fc-3ac821ef11d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-e8a13555-6d01-4524-a3c0-71177331d145,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-ce451d19-c967-4d1f-8fe9-c7fec7ed3de5,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-37ea41a8-e474-4941-842e-24da9d613d48,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-7ba056df-f4ee-4d30-a584-6d2082e9fe63,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-c3990ea6-48a8-4ced-9338-2e21b8f4fb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-b3ee1a7e-00b7-439e-97e2-405a2eddf9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-97f944f2-e683-4be1-be31-4e607c4b3b52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-434941055-172.17.0.15-1597358771360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43717,DS-694f751f-c1ec-4aa7-87fc-3ac821ef11d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-e8a13555-6d01-4524-a3c0-71177331d145,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-ce451d19-c967-4d1f-8fe9-c7fec7ed3de5,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-37ea41a8-e474-4941-842e-24da9d613d48,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-7ba056df-f4ee-4d30-a584-6d2082e9fe63,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-c3990ea6-48a8-4ced-9338-2e21b8f4fb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-b3ee1a7e-00b7-439e-97e2-405a2eddf9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-97f944f2-e683-4be1-be31-4e607c4b3b52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1775371194-172.17.0.15-1597359181606:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46169,DS-6910f3d8-cfcc-49bb-88d0-82ff8ffde06b,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-c7b59567-c5a2-429e-aa74-d2686d53fecc,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-2d53190f-2955-404d-bc08-7b9a14ae3680,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-745b8552-6e2b-4168-b7fa-62ac9615a75e,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-92d501d5-8983-4dff-8cdf-d7fc5050c2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-536581de-26d6-435b-9f91-a9978b46fe90,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-66f99aa2-b60a-48c4-a136-e4397e21e41b,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-7041fc94-c275-4b93-8651-9519a3e08fa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1775371194-172.17.0.15-1597359181606:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46169,DS-6910f3d8-cfcc-49bb-88d0-82ff8ffde06b,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-c7b59567-c5a2-429e-aa74-d2686d53fecc,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-2d53190f-2955-404d-bc08-7b9a14ae3680,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-745b8552-6e2b-4168-b7fa-62ac9615a75e,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-92d501d5-8983-4dff-8cdf-d7fc5050c2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-536581de-26d6-435b-9f91-a9978b46fe90,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-66f99aa2-b60a-48c4-a136-e4397e21e41b,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-7041fc94-c275-4b93-8651-9519a3e08fa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-159920354-172.17.0.15-1597359567435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34277,DS-4a6a28e8-02b7-4a40-99bc-3366e622f673,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-72766915-12a5-4a53-be3c-a12ccb780b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-b45df9d3-f72b-457c-b178-07af269401f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-3f1ab115-d73a-4dbd-a8fc-d1b947927917,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-32166024-dee7-4e07-89ab-0c0d972752d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-956e37c9-3b52-408d-a521-20a966adc23a,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-4529e14c-7a54-4a2a-9364-2120b0d28243,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-8e10ce5a-404f-4584-bdac-1d67a56e63ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-159920354-172.17.0.15-1597359567435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34277,DS-4a6a28e8-02b7-4a40-99bc-3366e622f673,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-72766915-12a5-4a53-be3c-a12ccb780b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-b45df9d3-f72b-457c-b178-07af269401f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-3f1ab115-d73a-4dbd-a8fc-d1b947927917,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-32166024-dee7-4e07-89ab-0c0d972752d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-956e37c9-3b52-408d-a521-20a966adc23a,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-4529e14c-7a54-4a2a-9364-2120b0d28243,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-8e10ce5a-404f-4584-bdac-1d67a56e63ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1152962678-172.17.0.15-1597359645664:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34475,DS-b5634a25-22e7-4f65-aacc-4112cce2da69,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-05ec42c1-fe50-4da9-bc6b-ba17b80dd547,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-effe1fc3-0de1-4ca8-80e6-0af3d9333f70,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-a3b0aca7-6eac-4c56-bfc2-eb0460fb9aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-28015c99-ee2c-4cbf-9736-3682414b8d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-42b1c0a1-42eb-4266-90db-bc94fe770338,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-21b63904-9eb0-4ff0-94d3-05d5db28b704,DISK], DatanodeInfoWithStorage[127.0.0.1:45871,DS-dbf49abb-bf8e-4971-b9ff-148b08cd4e14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1152962678-172.17.0.15-1597359645664:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34475,DS-b5634a25-22e7-4f65-aacc-4112cce2da69,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-05ec42c1-fe50-4da9-bc6b-ba17b80dd547,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-effe1fc3-0de1-4ca8-80e6-0af3d9333f70,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-a3b0aca7-6eac-4c56-bfc2-eb0460fb9aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-28015c99-ee2c-4cbf-9736-3682414b8d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-42b1c0a1-42eb-4266-90db-bc94fe770338,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-21b63904-9eb0-4ff0-94d3-05d5db28b704,DISK], DatanodeInfoWithStorage[127.0.0.1:45871,DS-dbf49abb-bf8e-4971-b9ff-148b08cd4e14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-188834229-172.17.0.15-1597360124902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45323,DS-cc6c70ad-edc8-4669-a76d-fbedb20055d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-e5f8c3cf-6583-4cc0-9dcd-562d1f31a71c,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-8696805b-2472-4669-98a6-aa999a9dc288,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-343abc60-3903-44e0-ac93-618f15bf530c,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-b102f812-8e87-4b18-8a2e-76c4287d127f,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-6976e5a6-fa05-4691-8d79-7dd654f5cb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-be0b3a1e-542e-40d5-a00c-183fe7a8fd74,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-54373ede-1518-4f4c-bcb5-da0ccc4f6ff7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-188834229-172.17.0.15-1597360124902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45323,DS-cc6c70ad-edc8-4669-a76d-fbedb20055d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-e5f8c3cf-6583-4cc0-9dcd-562d1f31a71c,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-8696805b-2472-4669-98a6-aa999a9dc288,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-343abc60-3903-44e0-ac93-618f15bf530c,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-b102f812-8e87-4b18-8a2e-76c4287d127f,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-6976e5a6-fa05-4691-8d79-7dd654f5cb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-be0b3a1e-542e-40d5-a00c-183fe7a8fd74,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-54373ede-1518-4f4c-bcb5-da0ccc4f6ff7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-690647080-172.17.0.15-1597360287578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35577,DS-1a0eca1d-fb42-4991-9d1c-98cb726ecce4,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-a531894e-99db-445a-b6d8-a06a56bbe9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-cdbaa4a3-6a9b-406c-8495-843257caaa1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-f1138c41-e8f7-4ea8-a176-9e442c52259c,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-8e877d42-1a24-4e75-9365-b1a69c6b50a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-1b4cf332-9249-4c67-afad-5f4305b5c27d,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-fc8c6f8d-e4a7-405c-8f98-6c12ad931569,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-89d2582d-695a-48f6-9184-d7d5384c8c7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-690647080-172.17.0.15-1597360287578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35577,DS-1a0eca1d-fb42-4991-9d1c-98cb726ecce4,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-a531894e-99db-445a-b6d8-a06a56bbe9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-cdbaa4a3-6a9b-406c-8495-843257caaa1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-f1138c41-e8f7-4ea8-a176-9e442c52259c,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-8e877d42-1a24-4e75-9365-b1a69c6b50a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-1b4cf332-9249-4c67-afad-5f4305b5c27d,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-fc8c6f8d-e4a7-405c-8f98-6c12ad931569,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-89d2582d-695a-48f6-9184-d7d5384c8c7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1288344634-172.17.0.15-1597360659549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40732,DS-4eaff53a-b8f5-41f9-b1c2-243734839991,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-c9d7bfe6-3a62-40b3-a676-71400f98967b,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-574deb49-6810-4ab0-9073-ac0027bf1f12,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-9404eaa0-7569-4dc3-a223-fddd0d96473f,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-d4444921-db31-4260-a71e-3542f67d35dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-dc4b0604-8b26-4bb3-8901-43894725ac0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-530d809b-4b3b-4d4c-bb1e-e312ddb023ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-807b690b-f124-434f-998b-3b8cc2667e06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1288344634-172.17.0.15-1597360659549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40732,DS-4eaff53a-b8f5-41f9-b1c2-243734839991,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-c9d7bfe6-3a62-40b3-a676-71400f98967b,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-574deb49-6810-4ab0-9073-ac0027bf1f12,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-9404eaa0-7569-4dc3-a223-fddd0d96473f,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-d4444921-db31-4260-a71e-3542f67d35dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-dc4b0604-8b26-4bb3-8901-43894725ac0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-530d809b-4b3b-4d4c-bb1e-e312ddb023ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-807b690b-f124-434f-998b-3b8cc2667e06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1457365686-172.17.0.15-1597361351400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44358,DS-4a01b374-0bd9-419b-9742-c77e776606ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-24dcbfdc-ffad-4adb-92aa-863706291894,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-e70c4aa0-3ccb-4591-8237-0bc0654ee6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-fe323c41-6ffd-495b-b175-0d27d9ae110c,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-5a473d31-0d2a-4c7e-988b-2ce36eed9211,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-eeb2cf7c-511f-4eb8-b713-2350de585cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-43ffb640-756e-43aa-9ea4-00030e39ed47,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-ab735b2c-2859-4fca-80db-813cde305f95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1457365686-172.17.0.15-1597361351400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44358,DS-4a01b374-0bd9-419b-9742-c77e776606ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-24dcbfdc-ffad-4adb-92aa-863706291894,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-e70c4aa0-3ccb-4591-8237-0bc0654ee6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-fe323c41-6ffd-495b-b175-0d27d9ae110c,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-5a473d31-0d2a-4c7e-988b-2ce36eed9211,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-eeb2cf7c-511f-4eb8-b713-2350de585cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-43ffb640-756e-43aa-9ea4-00030e39ed47,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-ab735b2c-2859-4fca-80db-813cde305f95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-345616167-172.17.0.15-1597361390910:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41163,DS-bfabbf80-3844-432a-b750-a178f22a6ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-a8753673-0ecd-47a6-a33e-f6c52ae20d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-c9fe4dcf-8cfa-42d7-88db-5894b9351497,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-bd6c4192-0ba7-48d4-af1a-c7b138198574,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-fa30ebd5-0387-492f-b4bb-215dfcf67258,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-772e1306-ec62-4a54-8f19-adb5e5a3f551,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-4471205b-acee-4fab-a457-e5d8b29aad77,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-42ad5123-ff5b-4fcd-99d7-83d02a7c251a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-345616167-172.17.0.15-1597361390910:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41163,DS-bfabbf80-3844-432a-b750-a178f22a6ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-a8753673-0ecd-47a6-a33e-f6c52ae20d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-c9fe4dcf-8cfa-42d7-88db-5894b9351497,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-bd6c4192-0ba7-48d4-af1a-c7b138198574,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-fa30ebd5-0387-492f-b4bb-215dfcf67258,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-772e1306-ec62-4a54-8f19-adb5e5a3f551,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-4471205b-acee-4fab-a457-e5d8b29aad77,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-42ad5123-ff5b-4fcd-99d7-83d02a7c251a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-364584207-172.17.0.15-1597361488398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35788,DS-626a5d67-1aad-43f4-886b-0b5705d6fb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38868,DS-51faadbc-3e28-41dc-8c88-090f9ac1c4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-7b366764-e2ad-4fab-933c-f418e104a729,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-2c78d290-d7dc-4fda-8021-6e679ae53d39,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-1b64c83f-0917-46b5-99cb-cb6eae3d2960,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-56c53d50-d943-4c4b-acc3-f8d70b49f9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-6ee932cd-7bb9-42b9-bc6e-0cc4f8b1d485,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-c6615bef-22b0-4ab9-a72c-bd2cbc1e909e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-364584207-172.17.0.15-1597361488398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35788,DS-626a5d67-1aad-43f4-886b-0b5705d6fb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38868,DS-51faadbc-3e28-41dc-8c88-090f9ac1c4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-7b366764-e2ad-4fab-933c-f418e104a729,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-2c78d290-d7dc-4fda-8021-6e679ae53d39,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-1b64c83f-0917-46b5-99cb-cb6eae3d2960,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-56c53d50-d943-4c4b-acc3-f8d70b49f9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-6ee932cd-7bb9-42b9-bc6e-0cc4f8b1d485,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-c6615bef-22b0-4ab9-a72c-bd2cbc1e909e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693273972-172.17.0.15-1597361927373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41057,DS-c8fd2130-d4ab-4022-9e80-5ebea4bd73f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-d0851243-664a-477a-bd7b-746250da6234,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-d2976c65-7fa3-4680-ae47-fb2264eb20c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-891306a6-8c95-4dc9-b7a4-e9a260b38e91,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-849a02d8-287f-4836-8310-352e154bf236,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-55a38503-4863-414a-9b74-298085c264dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-6e58eb9e-2255-44d4-80dc-dc09770cd3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-6bce9111-09df-44ab-a2b9-e7f3b30205a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693273972-172.17.0.15-1597361927373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41057,DS-c8fd2130-d4ab-4022-9e80-5ebea4bd73f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-d0851243-664a-477a-bd7b-746250da6234,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-d2976c65-7fa3-4680-ae47-fb2264eb20c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-891306a6-8c95-4dc9-b7a4-e9a260b38e91,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-849a02d8-287f-4836-8310-352e154bf236,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-55a38503-4863-414a-9b74-298085c264dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-6e58eb9e-2255-44d4-80dc-dc09770cd3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-6bce9111-09df-44ab-a2b9-e7f3b30205a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 6652
