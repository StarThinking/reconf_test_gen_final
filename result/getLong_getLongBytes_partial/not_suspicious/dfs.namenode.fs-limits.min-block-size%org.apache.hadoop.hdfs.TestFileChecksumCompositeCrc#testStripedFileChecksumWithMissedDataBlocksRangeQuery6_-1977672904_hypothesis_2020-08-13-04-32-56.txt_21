reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1509216955-172.17.0.3-1597293747689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42964,DS-d1a808b7-6913-47d1-9c97-5424b0630175,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-5e6301ff-4114-46fd-be32-88154fc02ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-f2f47610-5b0d-4739-9a19-7d965cced263,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-cdd1e53a-ee3d-4699-9b64-ebd5c762556a,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-47512146-136c-4dbf-987c-4ca4d48f4cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-05754af0-78cf-4bca-8277-2fdebee59922,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-1f367ff6-7bba-4d8b-9fd9-10e22cfcd967,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-3115a994-2ae3-454e-bc11-09f5d47aef70,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1509216955-172.17.0.3-1597293747689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42964,DS-d1a808b7-6913-47d1-9c97-5424b0630175,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-5e6301ff-4114-46fd-be32-88154fc02ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-f2f47610-5b0d-4739-9a19-7d965cced263,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-cdd1e53a-ee3d-4699-9b64-ebd5c762556a,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-47512146-136c-4dbf-987c-4ca4d48f4cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-05754af0-78cf-4bca-8277-2fdebee59922,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-1f367ff6-7bba-4d8b-9fd9-10e22cfcd967,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-3115a994-2ae3-454e-bc11-09f5d47aef70,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1003001758-172.17.0.3-1597293887480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41601,DS-f3acbaf8-53e8-447f-b227-9cd6e9a048df,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-14af9131-dcd7-4297-a47e-2b7a4977addc,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-4ccaa789-6c50-4225-8634-eda064e9bf66,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-50d35892-919f-429e-b55d-5dd2269f4096,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-44f2d80a-1f55-46c7-b1d9-cc5096808939,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-88d1ee13-d34b-403f-a153-069dcfde71ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-32180845-f168-4246-ae77-eb2b723acf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-b6d8a399-942a-4cc3-b3f8-dc7cd2e86c54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1003001758-172.17.0.3-1597293887480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41601,DS-f3acbaf8-53e8-447f-b227-9cd6e9a048df,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-14af9131-dcd7-4297-a47e-2b7a4977addc,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-4ccaa789-6c50-4225-8634-eda064e9bf66,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-50d35892-919f-429e-b55d-5dd2269f4096,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-44f2d80a-1f55-46c7-b1d9-cc5096808939,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-88d1ee13-d34b-403f-a153-069dcfde71ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-32180845-f168-4246-ae77-eb2b723acf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-b6d8a399-942a-4cc3-b3f8-dc7cd2e86c54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-816423061-172.17.0.3-1597293932655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34333,DS-4e02dfb5-26ae-4408-bc7e-188f526c4fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-9265465e-49de-4066-8bf1-c6f6c79b55ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-d6ae9ab4-7e04-4ba4-960d-8dd912c55b59,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-55e013fb-fd5e-48c2-be15-1567857da622,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-722255ad-6703-4264-8c09-7acdccf22c26,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-4ec8d84b-eafb-4a7c-a4aa-f2826e2c33db,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-8d78e8f7-fa90-49f0-8807-9fc4f004584e,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-bd86da1e-e35c-4810-b00d-373b2856e3c5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-816423061-172.17.0.3-1597293932655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34333,DS-4e02dfb5-26ae-4408-bc7e-188f526c4fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-9265465e-49de-4066-8bf1-c6f6c79b55ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-d6ae9ab4-7e04-4ba4-960d-8dd912c55b59,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-55e013fb-fd5e-48c2-be15-1567857da622,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-722255ad-6703-4264-8c09-7acdccf22c26,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-4ec8d84b-eafb-4a7c-a4aa-f2826e2c33db,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-8d78e8f7-fa90-49f0-8807-9fc4f004584e,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-bd86da1e-e35c-4810-b00d-373b2856e3c5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-295096333-172.17.0.3-1597293981468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33971,DS-69efbf8f-eb76-4d17-b051-f5c3f6f6862c,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-09fa74a5-78a9-4156-939c-a3e867e2762c,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-e83b7d32-b286-4ed0-952b-b1fd14f07c54,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-773da215-fef1-4acc-87f2-12d93bfd3fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-3151c15f-20b0-4e70-9b40-ac9b176dbf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-8ce026ef-ebe9-46e5-baa7-ad9a38858840,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-cf900432-a6cd-4f47-9c60-0ed89741e6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-d0acfed0-1d48-45d9-a037-a6cd20105f47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-295096333-172.17.0.3-1597293981468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33971,DS-69efbf8f-eb76-4d17-b051-f5c3f6f6862c,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-09fa74a5-78a9-4156-939c-a3e867e2762c,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-e83b7d32-b286-4ed0-952b-b1fd14f07c54,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-773da215-fef1-4acc-87f2-12d93bfd3fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-3151c15f-20b0-4e70-9b40-ac9b176dbf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-8ce026ef-ebe9-46e5-baa7-ad9a38858840,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-cf900432-a6cd-4f47-9c60-0ed89741e6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-d0acfed0-1d48-45d9-a037-a6cd20105f47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-942441061-172.17.0.3-1597294039320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38785,DS-3578903a-32db-484c-9215-fd81e7285c61,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-bca29e1a-2192-4ddb-aa7c-e9f031c84414,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-319059c6-e732-4e0b-bd51-486709ce777c,DISK], DatanodeInfoWithStorage[127.0.0.1:34191,DS-ad065598-4f70-43f9-841e-31cd93cf58d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-25128899-66e4-4dd9-89d2-d359dd1952c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-b67f28e4-56f4-454d-9d5f-dc0fb7b8268a,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-ed5ed18d-3163-40ca-9ea6-51ae9a15eaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-8a15c420-bf29-4a2d-a755-0654e3c73913,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-942441061-172.17.0.3-1597294039320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38785,DS-3578903a-32db-484c-9215-fd81e7285c61,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-bca29e1a-2192-4ddb-aa7c-e9f031c84414,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-319059c6-e732-4e0b-bd51-486709ce777c,DISK], DatanodeInfoWithStorage[127.0.0.1:34191,DS-ad065598-4f70-43f9-841e-31cd93cf58d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-25128899-66e4-4dd9-89d2-d359dd1952c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-b67f28e4-56f4-454d-9d5f-dc0fb7b8268a,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-ed5ed18d-3163-40ca-9ea6-51ae9a15eaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-8a15c420-bf29-4a2d-a755-0654e3c73913,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688853231-172.17.0.3-1597294176854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44178,DS-9cf23b5f-208e-4f86-9681-c3d99691be27,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-99b58055-0c27-41aa-934a-d56c5a3dead1,DISK], DatanodeInfoWithStorage[127.0.0.1:43840,DS-f54b57f9-2b46-43c7-bf66-c73acac54a07,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-d4052f99-c190-4f24-8551-3cf846cff957,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-03d47fb4-48e9-4d53-affa-0139f076d2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-385c209d-179c-41fb-b1c6-a695ad877878,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-41175a6b-a546-416d-85ed-8d14d96e38c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-d11a774f-0ae9-4392-8d6a-e689df81ccd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688853231-172.17.0.3-1597294176854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44178,DS-9cf23b5f-208e-4f86-9681-c3d99691be27,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-99b58055-0c27-41aa-934a-d56c5a3dead1,DISK], DatanodeInfoWithStorage[127.0.0.1:43840,DS-f54b57f9-2b46-43c7-bf66-c73acac54a07,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-d4052f99-c190-4f24-8551-3cf846cff957,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-03d47fb4-48e9-4d53-affa-0139f076d2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-385c209d-179c-41fb-b1c6-a695ad877878,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-41175a6b-a546-416d-85ed-8d14d96e38c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-d11a774f-0ae9-4392-8d6a-e689df81ccd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-129856452-172.17.0.3-1597294768322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34355,DS-88faf897-8caa-4c71-ad4a-c1d98dc983c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-18c271e0-89e3-455c-9c96-52b0fdefbdbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-34fd9281-9e54-4830-a866-b3985c6f2c89,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-646ec44f-0f26-4264-be5c-4ad264430072,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-e5eed36f-1842-451d-85cb-bf364cfe2579,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-ce396c1f-9f8a-4691-a3f4-04d6fcc3bc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-a61d82cd-e5a5-4597-abb7-ca306afa4720,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-31c6570d-6023-4370-922c-f550204de954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-129856452-172.17.0.3-1597294768322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34355,DS-88faf897-8caa-4c71-ad4a-c1d98dc983c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-18c271e0-89e3-455c-9c96-52b0fdefbdbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-34fd9281-9e54-4830-a866-b3985c6f2c89,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-646ec44f-0f26-4264-be5c-4ad264430072,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-e5eed36f-1842-451d-85cb-bf364cfe2579,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-ce396c1f-9f8a-4691-a3f4-04d6fcc3bc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-a61d82cd-e5a5-4597-abb7-ca306afa4720,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-31c6570d-6023-4370-922c-f550204de954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-294751506-172.17.0.3-1597294909109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35258,DS-28c522b7-7a11-4491-a4ab-11392ebf65b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-058f7640-3890-49e0-8dec-61f98c5ebf43,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-1139ab13-4637-4fad-a5ca-7c567be55ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-c4eba7c4-96e3-49b4-b511-f56dcceca5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-2015ad88-4261-4cdf-9ee9-2bb043e8a351,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-e6028d29-96bf-4f82-9720-01e8f3f50dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-01994423-6dcb-4abc-b56b-8cf152e54e03,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-d77a074c-0f77-4942-96b1-1c93e97a17d8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-294751506-172.17.0.3-1597294909109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35258,DS-28c522b7-7a11-4491-a4ab-11392ebf65b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-058f7640-3890-49e0-8dec-61f98c5ebf43,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-1139ab13-4637-4fad-a5ca-7c567be55ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-c4eba7c4-96e3-49b4-b511-f56dcceca5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-2015ad88-4261-4cdf-9ee9-2bb043e8a351,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-e6028d29-96bf-4f82-9720-01e8f3f50dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-01994423-6dcb-4abc-b56b-8cf152e54e03,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-d77a074c-0f77-4942-96b1-1c93e97a17d8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1644184480-172.17.0.3-1597295151978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34720,DS-f2a0fb6a-716a-4bdd-92a9-12080da712ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-67e1f78f-b5cc-4897-b4db-fe18a8414f29,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-acab3344-c05a-402b-b353-3f5449254f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-eaa42f32-705a-4fb5-8e74-446092fe3fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-618c32af-cffa-480f-b24a-4b309bc871a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-7ef194dd-ed8d-42ba-903f-55de6098f7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-41ae4f9a-2100-4c89-91aa-498866fb160a,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-67b35c7c-bb0b-4bc9-bdaa-b475f5a92fbf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1644184480-172.17.0.3-1597295151978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34720,DS-f2a0fb6a-716a-4bdd-92a9-12080da712ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-67e1f78f-b5cc-4897-b4db-fe18a8414f29,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-acab3344-c05a-402b-b353-3f5449254f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-eaa42f32-705a-4fb5-8e74-446092fe3fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-618c32af-cffa-480f-b24a-4b309bc871a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-7ef194dd-ed8d-42ba-903f-55de6098f7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-41ae4f9a-2100-4c89-91aa-498866fb160a,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-67b35c7c-bb0b-4bc9-bdaa-b475f5a92fbf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-528226222-172.17.0.3-1597295336160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37774,DS-e18313f4-d1e8-48b9-b543-26991bc08315,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-a0528d29-003a-4f2c-9258-619af45b80c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-14123a78-aad9-46cc-8c8a-16a03041f776,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-030a6552-75b0-4aed-bfb9-5cf4fa325613,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-44d09835-b90f-435c-ad6e-9dfaa5c0467f,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-20de78ac-3072-47da-b71f-147cfcba9824,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-2bbef7ec-b85e-4906-bb28-7ba8d0c691b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-4d41ccf1-a309-489e-ad17-efec731b2f28,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-528226222-172.17.0.3-1597295336160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37774,DS-e18313f4-d1e8-48b9-b543-26991bc08315,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-a0528d29-003a-4f2c-9258-619af45b80c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-14123a78-aad9-46cc-8c8a-16a03041f776,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-030a6552-75b0-4aed-bfb9-5cf4fa325613,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-44d09835-b90f-435c-ad6e-9dfaa5c0467f,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-20de78ac-3072-47da-b71f-147cfcba9824,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-2bbef7ec-b85e-4906-bb28-7ba8d0c691b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-4d41ccf1-a309-489e-ad17-efec731b2f28,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-372173514-172.17.0.3-1597295651302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45247,DS-373d6951-b4bb-4405-bd34-04af4a2ce687,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-4afbcb5d-1fe8-4e15-a6dc-a74076120e33,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-b4f985d0-8f83-400e-8216-bdba88319bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-258e387a-7ca7-4fc6-adbd-da28204dc148,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-33d95ef9-cdfe-4fc7-909b-b175735489d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-4fb95149-438d-43ff-989a-956a2b82c854,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-3640a2a1-f6a8-4a3f-99ee-69ddc6894bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-ae0bc112-4b1a-43e9-9a80-cfebdaa59f0f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-372173514-172.17.0.3-1597295651302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45247,DS-373d6951-b4bb-4405-bd34-04af4a2ce687,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-4afbcb5d-1fe8-4e15-a6dc-a74076120e33,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-b4f985d0-8f83-400e-8216-bdba88319bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-258e387a-7ca7-4fc6-adbd-da28204dc148,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-33d95ef9-cdfe-4fc7-909b-b175735489d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-4fb95149-438d-43ff-989a-956a2b82c854,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-3640a2a1-f6a8-4a3f-99ee-69ddc6894bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-ae0bc112-4b1a-43e9-9a80-cfebdaa59f0f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1481182398-172.17.0.3-1597296058142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32950,DS-4712c34f-7c8c-4de6-8963-6cc0880d51bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-52eb031f-66a2-43eb-96d0-71466465aa96,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-96920966-3371-4d10-b52f-8a2d14e816cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-677df694-9d51-4b80-8896-1623d68283f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-54184903-6e34-4271-ac6d-d07d15bf5685,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-9d1758ea-300c-4014-ac2d-8fac5a547969,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-111db4e1-efac-4033-b96b-426eb33c1941,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-1277678b-2583-42bd-9e15-164582a41f00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1481182398-172.17.0.3-1597296058142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32950,DS-4712c34f-7c8c-4de6-8963-6cc0880d51bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-52eb031f-66a2-43eb-96d0-71466465aa96,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-96920966-3371-4d10-b52f-8a2d14e816cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-677df694-9d51-4b80-8896-1623d68283f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-54184903-6e34-4271-ac6d-d07d15bf5685,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-9d1758ea-300c-4014-ac2d-8fac5a547969,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-111db4e1-efac-4033-b96b-426eb33c1941,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-1277678b-2583-42bd-9e15-164582a41f00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192347029-172.17.0.3-1597296146357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42823,DS-26c685fe-8af5-4178-aad2-a23dba5bfdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-31f38452-595e-4e1c-af9a-55627d4e7a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-cccfe002-bdf1-448f-a22a-c7c270d5c6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-f330e793-5a4c-456f-84d2-f85ca21f1d26,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-2d283623-a505-4b24-917e-6cd257f1b4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-7671ad46-487a-4847-9b5b-99c016c0e2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-04075858-0c30-4288-8f2f-0de7dce2bbda,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-8408a763-bcd1-40d1-8524-caf3f1ac0565,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192347029-172.17.0.3-1597296146357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42823,DS-26c685fe-8af5-4178-aad2-a23dba5bfdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-31f38452-595e-4e1c-af9a-55627d4e7a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-cccfe002-bdf1-448f-a22a-c7c270d5c6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-f330e793-5a4c-456f-84d2-f85ca21f1d26,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-2d283623-a505-4b24-917e-6cd257f1b4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-7671ad46-487a-4847-9b5b-99c016c0e2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-04075858-0c30-4288-8f2f-0de7dce2bbda,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-8408a763-bcd1-40d1-8524-caf3f1ac0565,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-809570064-172.17.0.3-1597296193584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37976,DS-076a413d-2f53-4a95-9015-845d4e8d42e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-af89131b-2b56-4795-8a52-d5465e7de3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-c46378bd-7f49-4a19-8be2-c9902f4c3a95,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-e9039290-9fc7-486a-89ad-246b40ece820,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-0c6743a1-c6dd-46df-8bf9-bab802d4e0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-b94f8b30-18d7-483b-8b54-067d55042099,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-3b0a8bf3-ded3-420d-84aa-2718c0823646,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-c4d93f49-2041-48c9-b282-9b000f55c1f1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-809570064-172.17.0.3-1597296193584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37976,DS-076a413d-2f53-4a95-9015-845d4e8d42e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-af89131b-2b56-4795-8a52-d5465e7de3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-c46378bd-7f49-4a19-8be2-c9902f4c3a95,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-e9039290-9fc7-486a-89ad-246b40ece820,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-0c6743a1-c6dd-46df-8bf9-bab802d4e0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-b94f8b30-18d7-483b-8b54-067d55042099,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-3b0a8bf3-ded3-420d-84aa-2718c0823646,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-c4d93f49-2041-48c9-b282-9b000f55c1f1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-317857577-172.17.0.3-1597296237736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39262,DS-f592df9b-c476-4b98-82aa-ecd23575d0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-4e74838d-d5e8-4209-be8a-d9ff226f5dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-7ecc2e6f-9ffd-4f4e-91cc-930077d5ea46,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-04e6f06d-fd47-46eb-8520-62ba8cead2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-48d0d564-6788-4150-811b-0be2c595d99c,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-49d58c68-0f83-47ff-976d-beab356d9b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-df98acdb-8b94-4909-81e7-cdb049412bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-20e8406c-7a7b-47ce-927d-4366933ad4e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-317857577-172.17.0.3-1597296237736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39262,DS-f592df9b-c476-4b98-82aa-ecd23575d0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41170,DS-4e74838d-d5e8-4209-be8a-d9ff226f5dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-7ecc2e6f-9ffd-4f4e-91cc-930077d5ea46,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-04e6f06d-fd47-46eb-8520-62ba8cead2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-48d0d564-6788-4150-811b-0be2c595d99c,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-49d58c68-0f83-47ff-976d-beab356d9b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-df98acdb-8b94-4909-81e7-cdb049412bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-20e8406c-7a7b-47ce-927d-4366933ad4e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1677937236-172.17.0.3-1597296368925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33199,DS-9791f3b1-15ad-4e4e-aeb9-8204c19b2fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-ffec01bf-bee4-496c-908b-d865cc4c86e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-c5c1819d-f4fb-4f31-89ad-6664083f076c,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-924ab412-6f46-491f-a2dd-b03a264cfd97,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-1aae20f5-a677-41a3-87e3-8e94a1fd679a,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-e9f1be8a-5e45-4f56-9241-0a002d17bd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-97f3acdd-b7c0-480b-8bd4-b596f95ad9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-8d8e0c8c-7cbf-4604-b52d-f2cb578f0f83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1677937236-172.17.0.3-1597296368925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33199,DS-9791f3b1-15ad-4e4e-aeb9-8204c19b2fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-ffec01bf-bee4-496c-908b-d865cc4c86e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-c5c1819d-f4fb-4f31-89ad-6664083f076c,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-924ab412-6f46-491f-a2dd-b03a264cfd97,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-1aae20f5-a677-41a3-87e3-8e94a1fd679a,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-e9f1be8a-5e45-4f56-9241-0a002d17bd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-97f3acdd-b7c0-480b-8bd4-b596f95ad9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-8d8e0c8c-7cbf-4604-b52d-f2cb578f0f83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609105562-172.17.0.3-1597296451720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37640,DS-28a6070f-d40b-4180-bdd4-01c23d3927ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-edd81b3a-661e-4977-af56-882ced602786,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-9bca6f12-7897-40c5-a965-d9c6e1469496,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-95f8693a-b1f1-4dc3-accc-019feb08ad66,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-37a08d81-b395-4d0b-ac27-0e759f8a5134,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-dfe4a231-99bf-4193-a711-e703dbff6761,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-1239bec5-943a-41a2-8428-f953ce5d3eee,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-5553312e-b7d5-49d5-91f8-bfd9809f9b29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609105562-172.17.0.3-1597296451720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37640,DS-28a6070f-d40b-4180-bdd4-01c23d3927ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-edd81b3a-661e-4977-af56-882ced602786,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-9bca6f12-7897-40c5-a965-d9c6e1469496,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-95f8693a-b1f1-4dc3-accc-019feb08ad66,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-37a08d81-b395-4d0b-ac27-0e759f8a5134,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-dfe4a231-99bf-4193-a711-e703dbff6761,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-1239bec5-943a-41a2-8428-f953ce5d3eee,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-5553312e-b7d5-49d5-91f8-bfd9809f9b29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293706345-172.17.0.3-1597296694577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40933,DS-776dc1ce-67a0-4db7-9b90-ff235414be4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-1684568a-34df-4fe5-b5e0-47574dd6e65f,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-d300193a-e1a7-4185-a45a-248621da30c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-800af01a-b986-4d05-bba3-b5529f5a69fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-14e65fdb-8e35-41e5-bb16-ac1d33aaccbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-f7c873f2-8a34-48b6-80d6-310db4464eea,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-6c3810b2-1117-433f-9ac0-c50881e9d985,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-fbf2dfa5-3aa1-48d6-9cf8-209e43b4986c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293706345-172.17.0.3-1597296694577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40933,DS-776dc1ce-67a0-4db7-9b90-ff235414be4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-1684568a-34df-4fe5-b5e0-47574dd6e65f,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-d300193a-e1a7-4185-a45a-248621da30c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-800af01a-b986-4d05-bba3-b5529f5a69fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-14e65fdb-8e35-41e5-bb16-ac1d33aaccbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-f7c873f2-8a34-48b6-80d6-310db4464eea,DISK], DatanodeInfoWithStorage[127.0.0.1:45635,DS-6c3810b2-1117-433f-9ac0-c50881e9d985,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-fbf2dfa5-3aa1-48d6-9cf8-209e43b4986c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1241781829-172.17.0.3-1597296790692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37699,DS-2833a45e-a6ee-4f1f-bdaa-6e442f0ee333,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-62f536f1-1a5c-4d96-a39f-68fa7cddb3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-7e4708a6-21ae-4fd9-be97-b9f2e8724013,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-2e44fc18-2f45-450a-9a87-b5f96efbcfe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-e4fab95c-c87a-4edf-b1d7-d433873e5804,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-da29083b-c8d0-4dfb-b0b5-93c6fdc96662,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-ecf9b080-28dc-4b24-9cb0-a91c7e52aaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-e843ba65-69c4-4738-8fac-487e7187b4cc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1241781829-172.17.0.3-1597296790692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37699,DS-2833a45e-a6ee-4f1f-bdaa-6e442f0ee333,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-62f536f1-1a5c-4d96-a39f-68fa7cddb3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-7e4708a6-21ae-4fd9-be97-b9f2e8724013,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-2e44fc18-2f45-450a-9a87-b5f96efbcfe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-e4fab95c-c87a-4edf-b1d7-d433873e5804,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-da29083b-c8d0-4dfb-b0b5-93c6fdc96662,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-ecf9b080-28dc-4b24-9cb0-a91c7e52aaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-e843ba65-69c4-4738-8fac-487e7187b4cc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1288022457-172.17.0.3-1597296928914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39930,DS-82dbf2c1-81de-4343-96d7-bd09d219ac21,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-58fc8dd6-b04b-44ec-8ca2-aef5ebf461ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-5eb401ba-f56c-4108-b950-2f7fcdf2718b,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-2da80d17-81e2-4241-af3e-5b6d1745e24c,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-a6352493-193a-4e96-8ca5-f6db9f576512,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-8b9dfe1b-5f1d-48e7-a778-bb40c0196ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-f7ecacd9-fc83-493c-91fb-09424c8bb188,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-8b2195d0-b00c-414d-91f0-e2180fc1cdab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1288022457-172.17.0.3-1597296928914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39930,DS-82dbf2c1-81de-4343-96d7-bd09d219ac21,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-58fc8dd6-b04b-44ec-8ca2-aef5ebf461ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-5eb401ba-f56c-4108-b950-2f7fcdf2718b,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-2da80d17-81e2-4241-af3e-5b6d1745e24c,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-a6352493-193a-4e96-8ca5-f6db9f576512,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-8b9dfe1b-5f1d-48e7-a778-bb40c0196ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-f7ecacd9-fc83-493c-91fb-09424c8bb188,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-8b2195d0-b00c-414d-91f0-e2180fc1cdab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-932678591-172.17.0.3-1597297021963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41427,DS-b8d2d77e-3fce-49e6-b03d-678f1ba2be2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-34afeaad-0903-4fa7-b7e6-4947e0e5fae6,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-0552e7a4-5d90-4cfe-8184-477dbc5eab1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-2d04206f-36bb-4744-b1bd-b20a1712fabc,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-cdf178b6-6b80-4a8a-959a-bb312bc3c1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-0257aa5a-506b-4530-b84c-c791e89d0a60,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-39d0e810-e571-43d2-bfb4-e218fb44973a,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-68c0a77d-6f0f-4742-b08f-26bcbc5cd550,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-932678591-172.17.0.3-1597297021963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41427,DS-b8d2d77e-3fce-49e6-b03d-678f1ba2be2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-34afeaad-0903-4fa7-b7e6-4947e0e5fae6,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-0552e7a4-5d90-4cfe-8184-477dbc5eab1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-2d04206f-36bb-4744-b1bd-b20a1712fabc,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-cdf178b6-6b80-4a8a-959a-bb312bc3c1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-0257aa5a-506b-4530-b84c-c791e89d0a60,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-39d0e810-e571-43d2-bfb4-e218fb44973a,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-68c0a77d-6f0f-4742-b08f-26bcbc5cd550,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1007475668-172.17.0.3-1597297114121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36189,DS-561adcbe-6174-497b-844b-9844a7ebc78d,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-42ac2f76-a465-4fac-9da5-e060f9a5692b,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-e597536a-db60-4842-b90d-a002824429f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-2b6d8a80-cb28-4297-b1e9-551570eac876,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-e141f34f-8be8-4a36-808c-dc49bf4b8b51,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-e2de9293-07ed-4b56-84a0-b40c233cc888,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-4e9cd585-9459-4d95-abe6-a3bfa62b81c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40395,DS-316174df-c0c4-4c87-bc1e-0daeac175065,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1007475668-172.17.0.3-1597297114121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36189,DS-561adcbe-6174-497b-844b-9844a7ebc78d,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-42ac2f76-a465-4fac-9da5-e060f9a5692b,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-e597536a-db60-4842-b90d-a002824429f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-2b6d8a80-cb28-4297-b1e9-551570eac876,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-e141f34f-8be8-4a36-808c-dc49bf4b8b51,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-e2de9293-07ed-4b56-84a0-b40c233cc888,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-4e9cd585-9459-4d95-abe6-a3bfa62b81c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40395,DS-316174df-c0c4-4c87-bc1e-0daeac175065,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107883250-172.17.0.3-1597297358526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38920,DS-ac789771-4631-41a4-a497-7116208f3e89,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-b0483d2f-66fe-48af-a5f3-359d10ebb753,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-e4cfaaca-90a5-4019-abec-9f897e61e04f,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-878c4caf-92b0-4a68-8c05-6214f0bf61af,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-7974c34f-9dd7-46b2-9069-659fb11b3810,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-5cfef8a8-b828-4f02-9ef7-26655176ac3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-59cb77e8-6082-494f-92b2-cfede3921151,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-c9fecb7e-3cc3-4a1c-ba64-ced4162e4d8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107883250-172.17.0.3-1597297358526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38920,DS-ac789771-4631-41a4-a497-7116208f3e89,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-b0483d2f-66fe-48af-a5f3-359d10ebb753,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-e4cfaaca-90a5-4019-abec-9f897e61e04f,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-878c4caf-92b0-4a68-8c05-6214f0bf61af,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-7974c34f-9dd7-46b2-9069-659fb11b3810,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-5cfef8a8-b828-4f02-9ef7-26655176ac3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-59cb77e8-6082-494f-92b2-cfede3921151,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-c9fecb7e-3cc3-4a1c-ba64-ced4162e4d8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-201007827-172.17.0.3-1597297453318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34376,DS-4cfe6058-8685-45fd-abf6-6bf82e75e3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-51901ab8-2cc7-4905-abd4-30a55bbb37c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38360,DS-fd327905-fa74-4aab-919b-54d99c4a517f,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-348d5552-b17e-4ea7-a0fa-511687a2e154,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-a565775c-5db8-4215-ae1d-6c73b9498b72,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-28f359c7-39e8-4b9e-84df-45ccf4404a83,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-73a234f2-e2ab-4851-ae68-275563b52b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-a07c9edf-ee59-45cb-b2ce-acfefcabdf0e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-201007827-172.17.0.3-1597297453318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34376,DS-4cfe6058-8685-45fd-abf6-6bf82e75e3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-51901ab8-2cc7-4905-abd4-30a55bbb37c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38360,DS-fd327905-fa74-4aab-919b-54d99c4a517f,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-348d5552-b17e-4ea7-a0fa-511687a2e154,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-a565775c-5db8-4215-ae1d-6c73b9498b72,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-28f359c7-39e8-4b9e-84df-45ccf4404a83,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-73a234f2-e2ab-4851-ae68-275563b52b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-a07c9edf-ee59-45cb-b2ce-acfefcabdf0e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54160936-172.17.0.3-1597297743522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41397,DS-d821676f-59bc-4218-aa6a-087b5c1babb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-1224e5ef-421e-4d42-b8d7-0aba70ae36c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-15423385-293c-4ce8-ab84-76c3dccaeb41,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-7313c951-a5fa-48c5-ac26-ad82e2db45ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-35626175-3826-4bf4-ac5c-804c488123a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-d85c43fa-7383-47f2-bf6f-4882c236e922,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-7d923cb8-02a4-4817-9700-a835e7881d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-f3e6cc69-e1f4-4bea-b055-aa7348dfa2e2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54160936-172.17.0.3-1597297743522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41397,DS-d821676f-59bc-4218-aa6a-087b5c1babb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-1224e5ef-421e-4d42-b8d7-0aba70ae36c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-15423385-293c-4ce8-ab84-76c3dccaeb41,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-7313c951-a5fa-48c5-ac26-ad82e2db45ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-35626175-3826-4bf4-ac5c-804c488123a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-d85c43fa-7383-47f2-bf6f-4882c236e922,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-7d923cb8-02a4-4817-9700-a835e7881d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-f3e6cc69-e1f4-4bea-b055-aa7348dfa2e2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-389536468-172.17.0.3-1597297998158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37096,DS-e3b77aa8-4589-4397-ab11-53664e5b8bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-5bc84fe2-a22f-4c43-b49d-dc3dab476de3,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-789d1713-be91-4482-b33a-fae637299f51,DISK], DatanodeInfoWithStorage[127.0.0.1:34770,DS-af42978b-9def-40e0-86d0-457472a0226a,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-5124c50f-20fa-4d06-9c35-e0dd313e6a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-4c5f1712-e238-49e9-99a7-bcc9dedd3443,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-0fdb8460-a9d1-4d04-949b-578d83138694,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-69660b84-b49a-4890-86fb-7c393dc45719,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-389536468-172.17.0.3-1597297998158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37096,DS-e3b77aa8-4589-4397-ab11-53664e5b8bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-5bc84fe2-a22f-4c43-b49d-dc3dab476de3,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-789d1713-be91-4482-b33a-fae637299f51,DISK], DatanodeInfoWithStorage[127.0.0.1:34770,DS-af42978b-9def-40e0-86d0-457472a0226a,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-5124c50f-20fa-4d06-9c35-e0dd313e6a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-4c5f1712-e238-49e9-99a7-bcc9dedd3443,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-0fdb8460-a9d1-4d04-949b-578d83138694,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-69660b84-b49a-4890-86fb-7c393dc45719,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391949599-172.17.0.3-1597298086502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38071,DS-e998b088-4b71-4d4b-a46f-2c35b2b6cd38,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-d0a86a9b-1794-4106-8bb1-6a717b21cd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-79fb0e7f-69f0-4e33-ace3-07c98e34599e,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-a15cd8a0-21dc-44f8-9b49-47331d07db47,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-f28cbbf0-c7c6-4b65-bb69-f9f470dda844,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-99c54ee0-c9a5-4ff1-86c7-ee3738030c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-0891edb8-4de8-44e4-8398-7eafbf5cf1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38206,DS-89d25689-ca08-45fb-aea0-8ffca0eaafaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391949599-172.17.0.3-1597298086502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38071,DS-e998b088-4b71-4d4b-a46f-2c35b2b6cd38,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-d0a86a9b-1794-4106-8bb1-6a717b21cd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-79fb0e7f-69f0-4e33-ace3-07c98e34599e,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-a15cd8a0-21dc-44f8-9b49-47331d07db47,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-f28cbbf0-c7c6-4b65-bb69-f9f470dda844,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-99c54ee0-c9a5-4ff1-86c7-ee3738030c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-0891edb8-4de8-44e4-8398-7eafbf5cf1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38206,DS-89d25689-ca08-45fb-aea0-8ffca0eaafaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-447219682-172.17.0.3-1597298232732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45331,DS-59c9d018-709c-4b7a-a84d-bb2f062c9691,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-2b77a313-cf65-4b15-a84a-ff9a3f7072e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-2ad38d3c-597a-4baa-8e67-846b603ea0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38318,DS-e9b9afc5-2bce-4702-8ee4-6fa0e7b7122b,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-3dea0cbb-bb76-4c2f-89c3-4d4a866728f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-f5341523-6fa0-4f88-9321-c52f7397c151,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-eb361e78-8b62-47d2-bac3-71efc048c9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-1ba3ff0b-d29e-4763-a63b-79bc0c3895f8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-447219682-172.17.0.3-1597298232732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45331,DS-59c9d018-709c-4b7a-a84d-bb2f062c9691,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-2b77a313-cf65-4b15-a84a-ff9a3f7072e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-2ad38d3c-597a-4baa-8e67-846b603ea0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38318,DS-e9b9afc5-2bce-4702-8ee4-6fa0e7b7122b,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-3dea0cbb-bb76-4c2f-89c3-4d4a866728f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-f5341523-6fa0-4f88-9321-c52f7397c151,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-eb361e78-8b62-47d2-bac3-71efc048c9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-1ba3ff0b-d29e-4763-a63b-79bc0c3895f8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-834267660-172.17.0.3-1597298459711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42625,DS-eda0d0e6-1840-4dbb-9db7-83ae576c94bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-8da69951-9d5a-4971-8267-5348a3dbd60f,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-9cc20243-aaa9-45fb-8472-96a723591f11,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-bafd6ff7-4ef6-4d5e-b9bd-811a84844f69,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-fda8df70-ec4d-46c2-881e-7579a7786f94,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-127c4a7d-e112-4736-8b2b-3315d37aa5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-c3dcd328-6d22-49c3-a6b9-15aba69e388a,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-dd970766-0346-494e-b3c9-63798aa842e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-834267660-172.17.0.3-1597298459711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42625,DS-eda0d0e6-1840-4dbb-9db7-83ae576c94bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-8da69951-9d5a-4971-8267-5348a3dbd60f,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-9cc20243-aaa9-45fb-8472-96a723591f11,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-bafd6ff7-4ef6-4d5e-b9bd-811a84844f69,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-fda8df70-ec4d-46c2-881e-7579a7786f94,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-127c4a7d-e112-4736-8b2b-3315d37aa5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-c3dcd328-6d22-49c3-a6b9-15aba69e388a,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-dd970766-0346-494e-b3c9-63798aa842e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-280135741-172.17.0.3-1597298595386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38700,DS-abf73895-455e-4b59-80a0-00e8067624fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-3daa2ccb-ee0c-4d1a-aa98-92677bb3be95,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-76047fc4-a363-4aaa-88e6-313b19c0ddc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-c8a83684-3e5b-45d9-b921-5bc18369dfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-d7a7e2c1-74d2-408b-944b-1129c5d53bac,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-ad98a9d7-8e75-4dcd-9112-319e0b18cba2,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-2b07e82e-9b2a-4fcb-92aa-0430cf522220,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-dfc1d2f0-5c1f-4511-9a57-de97ef119c63,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-280135741-172.17.0.3-1597298595386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38700,DS-abf73895-455e-4b59-80a0-00e8067624fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-3daa2ccb-ee0c-4d1a-aa98-92677bb3be95,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-76047fc4-a363-4aaa-88e6-313b19c0ddc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-c8a83684-3e5b-45d9-b921-5bc18369dfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-d7a7e2c1-74d2-408b-944b-1129c5d53bac,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-ad98a9d7-8e75-4dcd-9112-319e0b18cba2,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-2b07e82e-9b2a-4fcb-92aa-0430cf522220,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-dfc1d2f0-5c1f-4511-9a57-de97ef119c63,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-496582572-172.17.0.3-1597298639179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43872,DS-4e4224a6-4ed3-41f2-92b8-081abb9f6a12,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-30b36ac7-34b3-464c-896a-e9930d93a183,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-a4bf66c0-cd6e-4f3f-b7b8-d6e1f9e988fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-a101f2e7-4e64-4d21-adc3-90e3cf0cbb70,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-9fce5c70-c31b-48cc-b5f7-5e6ea57d81d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-60cc6428-b10f-4188-886c-8f3485177fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-41b6c5d3-69a1-4acd-b8c4-5104ebfa5d52,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-d2c071e9-689b-4694-8dc3-4eb740afbfd9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-496582572-172.17.0.3-1597298639179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43872,DS-4e4224a6-4ed3-41f2-92b8-081abb9f6a12,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-30b36ac7-34b3-464c-896a-e9930d93a183,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-a4bf66c0-cd6e-4f3f-b7b8-d6e1f9e988fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-a101f2e7-4e64-4d21-adc3-90e3cf0cbb70,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-9fce5c70-c31b-48cc-b5f7-5e6ea57d81d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-60cc6428-b10f-4188-886c-8f3485177fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-41b6c5d3-69a1-4acd-b8c4-5104ebfa5d52,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-d2c071e9-689b-4694-8dc3-4eb740afbfd9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203794191-172.17.0.3-1597299117057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34594,DS-c1ae35e2-e17c-481a-9a8e-4f589e0801ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-bf8eb61e-2675-4bf1-8670-f27f4c192480,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-cdb671ed-854d-4a40-9103-3cc3739c2315,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-afeeec06-1af3-472c-bade-8d9b05eee836,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-c1df81b0-c289-48a1-bb0e-ee0727598937,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-c1bf1131-ee0d-4542-a526-8c23dc6bf5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-d52a0660-0944-43dd-9019-98f879ac5f53,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-d6f944a9-be03-4f2c-a3bc-d714b79ffded,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203794191-172.17.0.3-1597299117057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34594,DS-c1ae35e2-e17c-481a-9a8e-4f589e0801ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-bf8eb61e-2675-4bf1-8670-f27f4c192480,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-cdb671ed-854d-4a40-9103-3cc3739c2315,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-afeeec06-1af3-472c-bade-8d9b05eee836,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-c1df81b0-c289-48a1-bb0e-ee0727598937,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-c1bf1131-ee0d-4542-a526-8c23dc6bf5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-d52a0660-0944-43dd-9019-98f879ac5f53,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-d6f944a9-be03-4f2c-a3bc-d714b79ffded,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-250047600-172.17.0.3-1597299510757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36633,DS-6bf55767-3dca-4546-8de4-2cdfbe5cc4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-751e493b-f1e2-4d7c-baa4-56c9197c8870,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-17cd39fe-1ada-411d-a520-d03cc10d771d,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-72bd112f-95f9-48f4-831c-4d5327570b66,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-16f4ccc4-8b2c-4fab-bfbd-bdc30032b8da,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-822da00a-162e-4432-9b0a-f6233ccab18a,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-70773bde-1c08-4e7c-976d-806b8f0d9c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-fc490d67-1e19-4a73-85d3-f3b8250fb934,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-250047600-172.17.0.3-1597299510757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36633,DS-6bf55767-3dca-4546-8de4-2cdfbe5cc4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-751e493b-f1e2-4d7c-baa4-56c9197c8870,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-17cd39fe-1ada-411d-a520-d03cc10d771d,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-72bd112f-95f9-48f4-831c-4d5327570b66,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-16f4ccc4-8b2c-4fab-bfbd-bdc30032b8da,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-822da00a-162e-4432-9b0a-f6233ccab18a,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-70773bde-1c08-4e7c-976d-806b8f0d9c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-fc490d67-1e19-4a73-85d3-f3b8250fb934,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177069773-172.17.0.3-1597299659735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34666,DS-9d91f615-b499-4fe1-81b4-889d52761689,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-77f182e3-bd71-47dd-9698-d73a6c20ee66,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-2fc926c0-bb19-4d62-aedf-67581f6a2585,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-442259ec-bb3d-42e3-8849-83279f281836,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-7992b344-790a-4d8a-89c0-0e70bbc7f828,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-9dad2539-5b74-4610-bc50-4644c3b9514b,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-026f61b6-da33-49f2-8255-d98bdf2d4e66,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-b8c4c15c-f786-4542-8339-507daace175a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177069773-172.17.0.3-1597299659735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34666,DS-9d91f615-b499-4fe1-81b4-889d52761689,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-77f182e3-bd71-47dd-9698-d73a6c20ee66,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-2fc926c0-bb19-4d62-aedf-67581f6a2585,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-442259ec-bb3d-42e3-8849-83279f281836,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-7992b344-790a-4d8a-89c0-0e70bbc7f828,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-9dad2539-5b74-4610-bc50-4644c3b9514b,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-026f61b6-da33-49f2-8255-d98bdf2d4e66,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-b8c4c15c-f786-4542-8339-507daace175a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-966364593-172.17.0.3-1597299762257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46685,DS-d30de19b-ac6c-4659-913f-3d0b44e822bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-00499509-67cc-4fb9-857a-cac69d9c3ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-536e1da0-0f1c-4da0-83af-b019cf269a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-5e9fbedf-def8-4c49-9b08-dba14129024e,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-2ba3efd4-8d37-499c-8708-30dc7b5afbfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-c244350f-8794-4960-ae29-32d6b12e9542,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-61f54b67-c2c9-470b-804b-594094dbffaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-58e9e1d0-4467-48db-80d4-2a8d55c148a7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-966364593-172.17.0.3-1597299762257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46685,DS-d30de19b-ac6c-4659-913f-3d0b44e822bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-00499509-67cc-4fb9-857a-cac69d9c3ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-536e1da0-0f1c-4da0-83af-b019cf269a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-5e9fbedf-def8-4c49-9b08-dba14129024e,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-2ba3efd4-8d37-499c-8708-30dc7b5afbfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-c244350f-8794-4960-ae29-32d6b12e9542,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-61f54b67-c2c9-470b-804b-594094dbffaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-58e9e1d0-4467-48db-80d4-2a8d55c148a7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-908193146-172.17.0.3-1597299807477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40126,DS-b63b7cc1-57f3-4778-919d-1986b30cfdea,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-d8296615-6d9f-48c1-b04d-02a3bda1fb15,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-7ca30864-39b4-4799-8b38-5d771e8eeddf,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-d56af8dc-0539-4017-b4c3-06cfb5221703,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-aa3d09b1-b004-44ff-8194-bc0b90457ead,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-edf76080-8382-4321-a279-d9b05050664e,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-8d70b419-5df3-4851-9917-a95e8597c7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-4b4f7a0c-3c9c-4e5a-8bef-b4f731c9c503,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-908193146-172.17.0.3-1597299807477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40126,DS-b63b7cc1-57f3-4778-919d-1986b30cfdea,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-d8296615-6d9f-48c1-b04d-02a3bda1fb15,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-7ca30864-39b4-4799-8b38-5d771e8eeddf,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-d56af8dc-0539-4017-b4c3-06cfb5221703,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-aa3d09b1-b004-44ff-8194-bc0b90457ead,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-edf76080-8382-4321-a279-d9b05050664e,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-8d70b419-5df3-4851-9917-a95e8597c7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-4b4f7a0c-3c9c-4e5a-8bef-b4f731c9c503,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.min-block-size
component: hdfs:NameNode
v1: 0
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943857470-172.17.0.3-1597300037902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42355,DS-d05ac7b4-afc4-4bd6-ad9b-d9b01cfd5c85,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-4dda7706-778c-4e94-a365-2e60b9e651d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41063,DS-abcb801d-4abd-4ad2-b95e-eb14d8fdff5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-4d756355-5cbd-4b95-9c55-f1a4693fd7ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-4ec71dc6-0182-4322-9d9d-ec897b4a11fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-a9ce3fa9-bef9-4467-aba8-8aff8750fc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-b5542a5e-c615-40e4-a993-210bc468ed9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-3a870f2b-3093-4582-8070-c9bf863f5865,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943857470-172.17.0.3-1597300037902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42355,DS-d05ac7b4-afc4-4bd6-ad9b-d9b01cfd5c85,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-4dda7706-778c-4e94-a365-2e60b9e651d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41063,DS-abcb801d-4abd-4ad2-b95e-eb14d8fdff5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-4d756355-5cbd-4b95-9c55-f1a4693fd7ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-4ec71dc6-0182-4322-9d9d-ec897b4a11fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-a9ce3fa9-bef9-4467-aba8-8aff8750fc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-b5542a5e-c615-40e4-a993-210bc468ed9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-3a870f2b-3093-4582-8070-c9bf863f5865,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 17 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 7144
