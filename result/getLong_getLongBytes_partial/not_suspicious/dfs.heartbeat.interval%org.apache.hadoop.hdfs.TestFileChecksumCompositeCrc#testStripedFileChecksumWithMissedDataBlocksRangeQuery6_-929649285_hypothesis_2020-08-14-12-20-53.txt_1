reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2010796082-172.17.0.15-1597407720703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46513,DS-fc9fa1f9-b8c4-4580-8759-cf1e6b08f1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-3097c520-f9e6-47e4-b6e3-884fed72768a,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-a26f56f7-2065-453e-b597-d6779cd262c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-45002210-b141-45d0-b30b-1270b91de2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-6ac724e7-a6c0-4fa0-85bb-804b26435cec,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-a9c493fb-9c3a-439e-b3a0-7acc25a665e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-8ca7ee41-7376-404b-bcce-bdad5bc206e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-961710d5-5588-4d71-aed2-c54ebd43c6bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2010796082-172.17.0.15-1597407720703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46513,DS-fc9fa1f9-b8c4-4580-8759-cf1e6b08f1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-3097c520-f9e6-47e4-b6e3-884fed72768a,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-a26f56f7-2065-453e-b597-d6779cd262c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-45002210-b141-45d0-b30b-1270b91de2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-6ac724e7-a6c0-4fa0-85bb-804b26435cec,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-a9c493fb-9c3a-439e-b3a0-7acc25a665e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-8ca7ee41-7376-404b-bcce-bdad5bc206e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-961710d5-5588-4d71-aed2-c54ebd43c6bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-299114511-172.17.0.15-1597407862127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42488,DS-edb0afc9-093b-4dff-b6ab-93d7b6460178,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-dc0f3587-129d-47ff-9130-03c0bcffb9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-8b56c005-ab55-4bfd-834c-b4a06781cc46,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-1dd4c30a-5069-4f3b-98f5-bccfe3bafd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-f628ddd0-ffc5-419d-898e-8ee974f8e7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-961393c7-4bbd-49ea-82f2-98bdd03f34c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-0cc70fb3-cdae-4000-8e79-0387fd43abda,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-7df9914d-d368-4855-943e-b032888274aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-299114511-172.17.0.15-1597407862127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42488,DS-edb0afc9-093b-4dff-b6ab-93d7b6460178,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-dc0f3587-129d-47ff-9130-03c0bcffb9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-8b56c005-ab55-4bfd-834c-b4a06781cc46,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-1dd4c30a-5069-4f3b-98f5-bccfe3bafd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-f628ddd0-ffc5-419d-898e-8ee974f8e7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-961393c7-4bbd-49ea-82f2-98bdd03f34c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-0cc70fb3-cdae-4000-8e79-0387fd43abda,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-7df9914d-d368-4855-943e-b032888274aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1502455042-172.17.0.15-1597408424894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46219,DS-e6d9b80a-23a4-43f9-8961-7a50273c66bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-4874ede8-af78-4caa-b613-b72533ef6478,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-07b53dd5-df0a-41e0-a8b5-efb793579dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-154e41ba-a0d8-4785-9f81-3665b62852b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-b19f2c38-02b1-4041-995f-6974739fe538,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-f6c717b8-da81-45c1-b455-25f6e50da038,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-45b3fc83-1756-468a-952e-3873f1a36d21,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-84fa096c-6ab0-495c-bbcd-64a7ad101774,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1502455042-172.17.0.15-1597408424894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46219,DS-e6d9b80a-23a4-43f9-8961-7a50273c66bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-4874ede8-af78-4caa-b613-b72533ef6478,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-07b53dd5-df0a-41e0-a8b5-efb793579dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-154e41ba-a0d8-4785-9f81-3665b62852b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-b19f2c38-02b1-4041-995f-6974739fe538,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-f6c717b8-da81-45c1-b455-25f6e50da038,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-45b3fc83-1756-468a-952e-3873f1a36d21,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-84fa096c-6ab0-495c-bbcd-64a7ad101774,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561884463-172.17.0.15-1597408560683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45757,DS-9e284946-23d5-4d6d-a18b-1e167fa9ddaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-68241b83-8e9d-4e2d-ab72-f79d05d5b32e,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-a3ca994c-5311-4b44-854f-d4ddbc1cbd84,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-4a31a462-04d2-4d2c-92d2-2ac4a10118fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-1e0997a2-3750-4c25-af17-9f885d4c63ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-0698ad16-9a12-4155-b1df-ece282f0ca01,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-b5f258ea-41e4-49cc-a866-734893d17bff,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-141acadf-c148-4dd1-a2f3-29c0b06cdd31,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561884463-172.17.0.15-1597408560683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45757,DS-9e284946-23d5-4d6d-a18b-1e167fa9ddaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-68241b83-8e9d-4e2d-ab72-f79d05d5b32e,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-a3ca994c-5311-4b44-854f-d4ddbc1cbd84,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-4a31a462-04d2-4d2c-92d2-2ac4a10118fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-1e0997a2-3750-4c25-af17-9f885d4c63ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-0698ad16-9a12-4155-b1df-ece282f0ca01,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-b5f258ea-41e4-49cc-a866-734893d17bff,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-141acadf-c148-4dd1-a2f3-29c0b06cdd31,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-234731124-172.17.0.15-1597408652756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42437,DS-5d3c68b3-a975-473e-8817-0c5589f0c3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-66d14201-f16f-482d-8143-c00fe96cea41,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-3df74656-47bd-461f-a7b2-ea06bb8cac7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-40e98376-60e1-4885-b4f9-cd60ecfc27be,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-23529bfc-a83c-4a7b-b6fd-aa5210b71b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-2d60be9f-0225-4c8c-9d25-d2908ada8038,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-84cef477-dab5-4811-b576-c76b9f0d96c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-bff8e0e8-00f6-4f5f-b7fd-483a80c30cbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-234731124-172.17.0.15-1597408652756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42437,DS-5d3c68b3-a975-473e-8817-0c5589f0c3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-66d14201-f16f-482d-8143-c00fe96cea41,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-3df74656-47bd-461f-a7b2-ea06bb8cac7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-40e98376-60e1-4885-b4f9-cd60ecfc27be,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-23529bfc-a83c-4a7b-b6fd-aa5210b71b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-2d60be9f-0225-4c8c-9d25-d2908ada8038,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-84cef477-dab5-4811-b576-c76b9f0d96c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-bff8e0e8-00f6-4f5f-b7fd-483a80c30cbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1139614207-172.17.0.15-1597408853405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41378,DS-3ad520e5-01dd-485c-a512-7317b9abdf9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-2aa403d5-ded0-4d9c-8811-6a15e17e4829,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-ab3ea1b3-0738-46e0-a133-fb052d1860fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-57a30f3b-e240-4835-8367-dce29db906ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-7ef60010-6e8a-419b-977f-8f5b19fb7c75,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-02e97a07-54d7-4f1b-aff8-8d6a1d46c492,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-d245ccb4-2529-4037-b5f4-712db12e6578,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-d25f3f07-f16b-416b-8985-a6c527d4a0e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1139614207-172.17.0.15-1597408853405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41378,DS-3ad520e5-01dd-485c-a512-7317b9abdf9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-2aa403d5-ded0-4d9c-8811-6a15e17e4829,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-ab3ea1b3-0738-46e0-a133-fb052d1860fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-57a30f3b-e240-4835-8367-dce29db906ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-7ef60010-6e8a-419b-977f-8f5b19fb7c75,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-02e97a07-54d7-4f1b-aff8-8d6a1d46c492,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-d245ccb4-2529-4037-b5f4-712db12e6578,DISK], DatanodeInfoWithStorage[127.0.0.1:38551,DS-d25f3f07-f16b-416b-8985-a6c527d4a0e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1111930007-172.17.0.15-1597409176615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37593,DS-0df82c48-0346-4755-b191-ee22a17ac539,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-2a8d68fe-dbec-4056-9f65-8349a68511ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-c82b5917-7543-476c-a4ea-4cdce4be073c,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-b9fd1c98-d5b0-43df-a406-920517fdb125,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-19558c0d-2751-45c0-8027-720bb276bb69,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-4c85efdd-cca1-4c3d-b3aa-8afa6254f860,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-95329293-c170-4b86-bb93-4433c46bc14d,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-0c5b17b9-c866-4390-a852-6e03cc5f1b1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1111930007-172.17.0.15-1597409176615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37593,DS-0df82c48-0346-4755-b191-ee22a17ac539,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-2a8d68fe-dbec-4056-9f65-8349a68511ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-c82b5917-7543-476c-a4ea-4cdce4be073c,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-b9fd1c98-d5b0-43df-a406-920517fdb125,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-19558c0d-2751-45c0-8027-720bb276bb69,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-4c85efdd-cca1-4c3d-b3aa-8afa6254f860,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-95329293-c170-4b86-bb93-4433c46bc14d,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-0c5b17b9-c866-4390-a852-6e03cc5f1b1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-750349916-172.17.0.15-1597409228679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37991,DS-b7179693-2978-438b-92d9-23806c80dc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-f4e5cba3-5f27-496b-a8b8-52cc3b2531d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-9c98090e-53f0-4718-8f6e-ea215f6ed577,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-245b8aa9-6859-4b8e-97af-73a559f8099a,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-2647d7c9-daf6-475e-b80f-1f550fab7e89,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-027b0796-d681-4e8d-bf61-0e9a18d71b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-ccfda867-3bed-4459-940d-71d111e08304,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-a8693db9-6536-4b0b-8da7-d63e38c4eda9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-750349916-172.17.0.15-1597409228679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37991,DS-b7179693-2978-438b-92d9-23806c80dc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-f4e5cba3-5f27-496b-a8b8-52cc3b2531d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-9c98090e-53f0-4718-8f6e-ea215f6ed577,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-245b8aa9-6859-4b8e-97af-73a559f8099a,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-2647d7c9-daf6-475e-b80f-1f550fab7e89,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-027b0796-d681-4e8d-bf61-0e9a18d71b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-ccfda867-3bed-4459-940d-71d111e08304,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-a8693db9-6536-4b0b-8da7-d63e38c4eda9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456597843-172.17.0.15-1597409269728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35035,DS-b24fa74b-119e-4b5d-b744-8715975f7c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-0cf7f3f3-052b-4fcc-a419-2e42db2b8b10,DISK], DatanodeInfoWithStorage[127.0.0.1:38234,DS-52e70ca4-bdb7-439d-ad0e-fb16ed880159,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-c6706e61-b1ed-497b-943f-22c367808985,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-b4094f2d-ec2d-4924-bdf9-232648c3d804,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-6d583b90-93e9-442f-993d-832430c03a08,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-fd203f9f-acbf-48c8-b506-703f923c95ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-b5304f5d-43e5-475c-b68a-fd33edc5e8f2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456597843-172.17.0.15-1597409269728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35035,DS-b24fa74b-119e-4b5d-b744-8715975f7c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-0cf7f3f3-052b-4fcc-a419-2e42db2b8b10,DISK], DatanodeInfoWithStorage[127.0.0.1:38234,DS-52e70ca4-bdb7-439d-ad0e-fb16ed880159,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-c6706e61-b1ed-497b-943f-22c367808985,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-b4094f2d-ec2d-4924-bdf9-232648c3d804,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-6d583b90-93e9-442f-993d-832430c03a08,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-fd203f9f-acbf-48c8-b506-703f923c95ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-b5304f5d-43e5-475c-b68a-fd33edc5e8f2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976282461-172.17.0.15-1597409761963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34573,DS-065bb1c6-ac19-4425-89f9-b16bdc0fd744,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-c9683b80-e064-44f5-b330-7d126fd989e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-abab8539-09de-4266-bded-6ad0f0fc2d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-45edb8da-f73a-4ee8-b981-69ee2cd017f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-25f71555-4262-478d-9282-486538c7726e,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-0dae6d90-56f3-45bc-a216-4b2df705bc20,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-c293dc4c-785c-41e5-8b58-cf345e71c8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-55b1d3a1-e6f4-475b-8f91-7c622f738a2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976282461-172.17.0.15-1597409761963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34573,DS-065bb1c6-ac19-4425-89f9-b16bdc0fd744,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-c9683b80-e064-44f5-b330-7d126fd989e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-abab8539-09de-4266-bded-6ad0f0fc2d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-45edb8da-f73a-4ee8-b981-69ee2cd017f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-25f71555-4262-478d-9282-486538c7726e,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-0dae6d90-56f3-45bc-a216-4b2df705bc20,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-c293dc4c-785c-41e5-8b58-cf345e71c8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-55b1d3a1-e6f4-475b-8f91-7c622f738a2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1242135150-172.17.0.15-1597410328094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42930,DS-cb1b58d4-7e6d-4a86-b933-e3d9000812f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-4d9baf5c-b6a1-4e4d-aa49-f90dce390435,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-f20ff20b-073f-4d14-82a4-2dd33f2444dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-7ea4808c-540d-4fc7-a7f5-1ac4e56448bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-930b6010-0dae-4aef-acc1-032992fd85a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-36283aea-454f-4f5a-baad-71dd908e0fad,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-6f2dec4d-b0c6-4fa5-9483-45e66f1f71a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-58f8e627-c0ee-4c44-8581-96a631f14d6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1242135150-172.17.0.15-1597410328094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42930,DS-cb1b58d4-7e6d-4a86-b933-e3d9000812f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-4d9baf5c-b6a1-4e4d-aa49-f90dce390435,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-f20ff20b-073f-4d14-82a4-2dd33f2444dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-7ea4808c-540d-4fc7-a7f5-1ac4e56448bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-930b6010-0dae-4aef-acc1-032992fd85a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-36283aea-454f-4f5a-baad-71dd908e0fad,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-6f2dec4d-b0c6-4fa5-9483-45e66f1f71a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-58f8e627-c0ee-4c44-8581-96a631f14d6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871500363-172.17.0.15-1597410423339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43788,DS-42dfa9cb-43f4-4a5e-bc4b-ec2081ec21f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-4183709c-2692-4f71-92c2-d59faaa4645a,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-b3c30b7c-1fb9-46e6-96fb-0d584fe58552,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-fcc9cc55-60e8-4ec3-a0ed-e4d8063adea1,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-9162dfec-e772-4fc1-8a27-87ea9d0bd9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-d326b482-6f08-4033-abde-b9a3ad4a2dea,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-e2e0329d-ba6c-4a2e-84c9-4a7eeb4d7451,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-67ff50ea-8b46-437e-afb9-a8b03613f2f4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871500363-172.17.0.15-1597410423339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43788,DS-42dfa9cb-43f4-4a5e-bc4b-ec2081ec21f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-4183709c-2692-4f71-92c2-d59faaa4645a,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-b3c30b7c-1fb9-46e6-96fb-0d584fe58552,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-fcc9cc55-60e8-4ec3-a0ed-e4d8063adea1,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-9162dfec-e772-4fc1-8a27-87ea9d0bd9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-d326b482-6f08-4033-abde-b9a3ad4a2dea,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-e2e0329d-ba6c-4a2e-84c9-4a7eeb4d7451,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-67ff50ea-8b46-437e-afb9-a8b03613f2f4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-597824848-172.17.0.15-1597410568155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39615,DS-12c2e935-05b4-466c-8ed7-e1249503546d,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-c9792377-8dd4-4c82-9b48-987fd0dacbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-01d26a1e-9aa5-481d-bbff-78eb8302908b,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-df2f7fd4-ebf5-4dc9-94d5-844a2e9b859f,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-5df61894-2e0b-45b0-8375-45fc34dfc161,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-97aec285-1984-4f5d-a949-52a95ea447d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-b620db20-c458-47d6-a196-34694c408306,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-c6c9dde6-1f7c-41b7-8a08-0f09661ea2d1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-597824848-172.17.0.15-1597410568155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39615,DS-12c2e935-05b4-466c-8ed7-e1249503546d,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-c9792377-8dd4-4c82-9b48-987fd0dacbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-01d26a1e-9aa5-481d-bbff-78eb8302908b,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-df2f7fd4-ebf5-4dc9-94d5-844a2e9b859f,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-5df61894-2e0b-45b0-8375-45fc34dfc161,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-97aec285-1984-4f5d-a949-52a95ea447d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-b620db20-c458-47d6-a196-34694c408306,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-c6c9dde6-1f7c-41b7-8a08-0f09661ea2d1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134082121-172.17.0.15-1597410720722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42642,DS-7da0af4f-e43f-466d-955a-88cdf37dbd41,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-54769a5f-82a5-4730-96be-747dc9d5445e,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-5d69d476-6994-463e-b493-f2c33cf104fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-99a599c1-34b8-4bfb-8d22-90f9d8974962,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-ac7a8704-0be3-4718-91d5-1e01595da259,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-d7912bfb-3ca2-4a71-9352-65cb5ad08f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-f7c2205d-c435-463a-814b-0d838f9e9dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-6f33bb17-0185-40e4-9da0-92d5bcdb6df5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134082121-172.17.0.15-1597410720722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42642,DS-7da0af4f-e43f-466d-955a-88cdf37dbd41,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-54769a5f-82a5-4730-96be-747dc9d5445e,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-5d69d476-6994-463e-b493-f2c33cf104fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-99a599c1-34b8-4bfb-8d22-90f9d8974962,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-ac7a8704-0be3-4718-91d5-1e01595da259,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-d7912bfb-3ca2-4a71-9352-65cb5ad08f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-f7c2205d-c435-463a-814b-0d838f9e9dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-6f33bb17-0185-40e4-9da0-92d5bcdb6df5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-147369159-172.17.0.15-1597410765102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39942,DS-cd5145d6-7e68-42a1-95a0-39fbab6c9d51,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-710893cb-6965-44aa-a179-a18ce8564285,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-3055bfcf-5fcb-49b3-a7d3-9796f494aba2,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-7f6c9083-4ac6-45d1-8fe3-7bd6d3eb9b10,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-75d9a5e5-0b49-4ef7-8ed7-19453c7db2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-1c5ebdd4-78fd-4fb0-b5e4-e82a3185c7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-30683541-401f-4201-aba7-f7ca7f9e95b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-9973ae13-3cc5-4e9d-961c-1857a2d90f2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-147369159-172.17.0.15-1597410765102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39942,DS-cd5145d6-7e68-42a1-95a0-39fbab6c9d51,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-710893cb-6965-44aa-a179-a18ce8564285,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-3055bfcf-5fcb-49b3-a7d3-9796f494aba2,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-7f6c9083-4ac6-45d1-8fe3-7bd6d3eb9b10,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-75d9a5e5-0b49-4ef7-8ed7-19453c7db2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-1c5ebdd4-78fd-4fb0-b5e4-e82a3185c7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-30683541-401f-4201-aba7-f7ca7f9e95b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-9973ae13-3cc5-4e9d-961c-1857a2d90f2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822525923-172.17.0.15-1597410900918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33682,DS-43b7a1f9-7ce8-4228-83e3-8e2dc5224bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-035a1f53-9930-402d-9fb6-3671fc870d58,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-675dcab8-75fe-4969-b408-f8b94dcc3b29,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-2ca178ee-8c01-4038-b32f-3f7dffe9e158,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-84befd17-dd24-44ea-93bd-982cc8a8dcec,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-45ae53a7-e3d4-4472-82c0-cf001eed2e15,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-cb20027b-fc6e-456f-87e2-cb9276e4afbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-f24d90f8-8277-4ca1-ad82-b4f5aa0d3f28,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822525923-172.17.0.15-1597410900918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33682,DS-43b7a1f9-7ce8-4228-83e3-8e2dc5224bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-035a1f53-9930-402d-9fb6-3671fc870d58,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-675dcab8-75fe-4969-b408-f8b94dcc3b29,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-2ca178ee-8c01-4038-b32f-3f7dffe9e158,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-84befd17-dd24-44ea-93bd-982cc8a8dcec,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-45ae53a7-e3d4-4472-82c0-cf001eed2e15,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-cb20027b-fc6e-456f-87e2-cb9276e4afbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-f24d90f8-8277-4ca1-ad82-b4f5aa0d3f28,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1407262509-172.17.0.15-1597410968920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44919,DS-366fb483-28f3-4445-8458-806c2308e3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-7d99d7ef-0acc-407f-ab65-2346d25af42b,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-b4e6c8bd-c3e9-4002-bc2c-e68c12c1875e,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-9b8500fe-63e3-4a86-b5f2-5018b4c4dee0,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-b0ed4049-2208-4442-865c-c58e405c1dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-7a4cec15-9f03-4d01-a605-052af2e23d05,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-fbaf9fd2-1b7b-4d58-8228-26f597194da9,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-a3f54580-d906-4c65-aff0-5517c32cf28e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1407262509-172.17.0.15-1597410968920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44919,DS-366fb483-28f3-4445-8458-806c2308e3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-7d99d7ef-0acc-407f-ab65-2346d25af42b,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-b4e6c8bd-c3e9-4002-bc2c-e68c12c1875e,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-9b8500fe-63e3-4a86-b5f2-5018b4c4dee0,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-b0ed4049-2208-4442-865c-c58e405c1dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-7a4cec15-9f03-4d01-a605-052af2e23d05,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-fbaf9fd2-1b7b-4d58-8228-26f597194da9,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-a3f54580-d906-4c65-aff0-5517c32cf28e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1655089153-172.17.0.15-1597411364437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38333,DS-4575dba8-e312-4c98-a7be-168ed64a7047,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-e5cb98eb-5d80-4066-8bf4-ac13c1df7a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-ad002536-9c41-4a5c-9e5f-d8b2a6aabe10,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-bf164f3a-8c3c-414a-96b2-a95fed0ce1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-4716b588-3d8d-4c86-9583-8306b8941764,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-e6c4d342-e71c-4bcc-8437-6adf266711fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-baeed732-700e-4290-a186-8b69309c0e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-3d827d2e-2eef-431e-92b4-d21048ed088d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1655089153-172.17.0.15-1597411364437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38333,DS-4575dba8-e312-4c98-a7be-168ed64a7047,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-e5cb98eb-5d80-4066-8bf4-ac13c1df7a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-ad002536-9c41-4a5c-9e5f-d8b2a6aabe10,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-bf164f3a-8c3c-414a-96b2-a95fed0ce1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-4716b588-3d8d-4c86-9583-8306b8941764,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-e6c4d342-e71c-4bcc-8437-6adf266711fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-baeed732-700e-4290-a186-8b69309c0e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-3d827d2e-2eef-431e-92b4-d21048ed088d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1036200046-172.17.0.15-1597411702268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43602,DS-271b43dd-74c9-4e08-a63c-3ed202bc16ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-3c8e1f26-76c5-40c6-8cae-6defff8d4147,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-2f4cd649-74f3-478b-bd00-c56266aca254,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-8c3b8275-9e41-4aab-8aed-f00ac4f8345c,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-c3473289-4be1-4238-b74b-bd3dbf769658,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-24b1532e-83dd-41fe-b3d2-6b4cbc9e2462,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-261e3b75-1729-4af7-9fc1-2529da8dd7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-401832e8-40eb-4c61-abe8-78db4464f728,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1036200046-172.17.0.15-1597411702268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43602,DS-271b43dd-74c9-4e08-a63c-3ed202bc16ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-3c8e1f26-76c5-40c6-8cae-6defff8d4147,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-2f4cd649-74f3-478b-bd00-c56266aca254,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-8c3b8275-9e41-4aab-8aed-f00ac4f8345c,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-c3473289-4be1-4238-b74b-bd3dbf769658,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-24b1532e-83dd-41fe-b3d2-6b4cbc9e2462,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-261e3b75-1729-4af7-9fc1-2529da8dd7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-401832e8-40eb-4c61-abe8-78db4464f728,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-872235570-172.17.0.15-1597411931986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38634,DS-3f1e2686-647f-4cc1-8777-8c8c68343ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-9bddea6d-f025-4848-9a56-efaa7bb36739,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-9c035ac9-6fcb-4135-9463-112b1593ac69,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-df616442-640b-4ee4-a8bc-ff9c0167e156,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-d2765c3c-9920-491a-8846-47fb320c0974,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-1fd37e88-e69a-46dc-84e3-13c8602146c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-fd8520bb-9372-4e61-af26-e5ca6bcbdde2,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-c94df5c5-6ef8-4dd3-87b9-e07153ab238d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-872235570-172.17.0.15-1597411931986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38634,DS-3f1e2686-647f-4cc1-8777-8c8c68343ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-9bddea6d-f025-4848-9a56-efaa7bb36739,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-9c035ac9-6fcb-4135-9463-112b1593ac69,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-df616442-640b-4ee4-a8bc-ff9c0167e156,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-d2765c3c-9920-491a-8846-47fb320c0974,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-1fd37e88-e69a-46dc-84e3-13c8602146c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-fd8520bb-9372-4e61-af26-e5ca6bcbdde2,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-c94df5c5-6ef8-4dd3-87b9-e07153ab238d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1387022030-172.17.0.15-1597411982114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44981,DS-681fa9fc-f5c4-404e-8020-92a6dd79e377,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-c5092b89-838f-4c68-aa88-7d48748e2656,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-d81a933b-334e-44d0-937c-62e3e4007a44,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-1442e234-e4e4-468c-b08c-a20a9ba8a3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-2000b990-8522-498f-a3e4-2430bebe8cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-cc1363be-1025-4f68-a28a-5925101d0ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-e87b0b87-a71e-4608-b36e-3911808c62b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-0da0549b-6c95-492b-86e1-0706457ded4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1387022030-172.17.0.15-1597411982114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44981,DS-681fa9fc-f5c4-404e-8020-92a6dd79e377,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-c5092b89-838f-4c68-aa88-7d48748e2656,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-d81a933b-334e-44d0-937c-62e3e4007a44,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-1442e234-e4e4-468c-b08c-a20a9ba8a3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-2000b990-8522-498f-a3e4-2430bebe8cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-cc1363be-1025-4f68-a28a-5925101d0ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-e87b0b87-a71e-4608-b36e-3911808c62b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-0da0549b-6c95-492b-86e1-0706457ded4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-205640170-172.17.0.15-1597412085190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33729,DS-fc8c976e-5f06-4055-8a54-17eb39f31c40,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-65bb36f5-c3b8-45b9-aa90-a6f9336858b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-696ce845-6800-4ba2-b26f-5d59ad44c01f,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-792e4a8e-ab53-41c4-a6e7-23f7c04bc813,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-69cbf666-4786-4acc-92e2-11eaf1ded789,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-1e9cda9d-060f-4374-a05f-767c2c25f099,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-cbe7d27a-8fc7-4194-bffd-c22529c17cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-f11daa2f-639f-4b48-bc5a-fbe015378b7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-205640170-172.17.0.15-1597412085190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33729,DS-fc8c976e-5f06-4055-8a54-17eb39f31c40,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-65bb36f5-c3b8-45b9-aa90-a6f9336858b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-696ce845-6800-4ba2-b26f-5d59ad44c01f,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-792e4a8e-ab53-41c4-a6e7-23f7c04bc813,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-69cbf666-4786-4acc-92e2-11eaf1ded789,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-1e9cda9d-060f-4374-a05f-767c2c25f099,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-cbe7d27a-8fc7-4194-bffd-c22529c17cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-f11daa2f-639f-4b48-bc5a-fbe015378b7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1079026831-172.17.0.15-1597412227666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44567,DS-aa6257d5-e438-4f45-8862-ab7c55ef1fee,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-6cce8e97-623e-4cdb-83ef-4cda899adf95,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-3d6b108a-4bbe-4980-b76f-b19c16b853fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-926ef374-0df6-4b2b-802a-43b724f403e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-f501e1ec-209a-4456-bd3a-d2f54ccfe129,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-05bc857a-0f9d-4718-9bf4-26fcecbd33dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-a27fc294-4eed-4995-9f80-ac6e8846af17,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-772d5e38-36c3-4c73-a5a5-c1f57f4b1f90,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1079026831-172.17.0.15-1597412227666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44567,DS-aa6257d5-e438-4f45-8862-ab7c55ef1fee,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-6cce8e97-623e-4cdb-83ef-4cda899adf95,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-3d6b108a-4bbe-4980-b76f-b19c16b853fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-926ef374-0df6-4b2b-802a-43b724f403e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-f501e1ec-209a-4456-bd3a-d2f54ccfe129,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-05bc857a-0f9d-4718-9bf4-26fcecbd33dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-a27fc294-4eed-4995-9f80-ac6e8846af17,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-772d5e38-36c3-4c73-a5a5-c1f57f4b1f90,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1448635310-172.17.0.15-1597412558791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45517,DS-47de3735-01ab-4fae-87e3-c9c21804883c,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-5610f623-fbda-4c85-946c-6dbb07733173,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-bd2820de-49c0-416a-8e9f-829e0d6f1130,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-135a67ac-b159-4178-8a4c-521663ac4896,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-62832e3e-8341-446f-befa-b250ee343135,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-1c0323a3-7691-4e15-bbe9-0f297942e63a,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-b947e7dc-8eb5-4b34-9409-c1f3ad028a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-75d11b3f-66d0-4ca8-a963-b0662978fb05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1448635310-172.17.0.15-1597412558791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45517,DS-47de3735-01ab-4fae-87e3-c9c21804883c,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-5610f623-fbda-4c85-946c-6dbb07733173,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-bd2820de-49c0-416a-8e9f-829e0d6f1130,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-135a67ac-b159-4178-8a4c-521663ac4896,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-62832e3e-8341-446f-befa-b250ee343135,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-1c0323a3-7691-4e15-bbe9-0f297942e63a,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-b947e7dc-8eb5-4b34-9409-c1f3ad028a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-75d11b3f-66d0-4ca8-a963-b0662978fb05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310884129-172.17.0.15-1597412604854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36298,DS-ee4de8e5-fec4-418d-a997-d0a6d05661a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-8eb5a6e2-ab52-43ff-95f9-a28991f4246b,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-36292242-0b94-4f46-a0a7-04ed88964855,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-e9abb0d0-c15e-40eb-9d63-05224dcd8e67,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-fd099333-85e5-4ddd-b246-7b9f6ee1bbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-56fa33b1-5196-4058-b06d-0bea59d18081,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-4129151d-36a6-4c10-a689-1add8dbfe272,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-81e66de2-1402-44b8-aaaf-f62ac57b9282,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310884129-172.17.0.15-1597412604854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36298,DS-ee4de8e5-fec4-418d-a997-d0a6d05661a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-8eb5a6e2-ab52-43ff-95f9-a28991f4246b,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-36292242-0b94-4f46-a0a7-04ed88964855,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-e9abb0d0-c15e-40eb-9d63-05224dcd8e67,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-fd099333-85e5-4ddd-b246-7b9f6ee1bbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-56fa33b1-5196-4058-b06d-0bea59d18081,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-4129151d-36a6-4c10-a689-1add8dbfe272,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-81e66de2-1402-44b8-aaaf-f62ac57b9282,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-232736654-172.17.0.15-1597412662441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40606,DS-1e01b677-6c07-432a-b59b-efd2d5a5fb43,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-1e9b2a46-8af5-4eaa-9b5c-41e13d598e01,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-657f6087-912c-48c7-a6ca-ab77e2b1e0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-8e30fdee-d8d9-40ba-9fb5-072f41751cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-7bff6f91-b0ed-4a8c-821e-290d236fc9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-c611b04c-9f60-4e13-ac24-b25c4cde2c44,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-6257dfb4-e332-4447-bec2-f89cdf521e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-b6c92d5d-1df2-440f-bc9e-3d4fc90925a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-232736654-172.17.0.15-1597412662441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40606,DS-1e01b677-6c07-432a-b59b-efd2d5a5fb43,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-1e9b2a46-8af5-4eaa-9b5c-41e13d598e01,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-657f6087-912c-48c7-a6ca-ab77e2b1e0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-8e30fdee-d8d9-40ba-9fb5-072f41751cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-7bff6f91-b0ed-4a8c-821e-290d236fc9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-c611b04c-9f60-4e13-ac24-b25c4cde2c44,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-6257dfb4-e332-4447-bec2-f89cdf521e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-b6c92d5d-1df2-440f-bc9e-3d4fc90925a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-718836026-172.17.0.15-1597412744005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43955,DS-7c217810-a306-429e-9d4c-33544ce44ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-81e0d006-5b25-4f9d-a159-1ea2445b45ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-f4ef6fbb-171c-4ec4-9e3e-06b05ae742a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-96f60695-fdc2-48b6-b191-e6551f1fc703,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-05a7fc73-fbd6-4264-8ace-2476da3607bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-62342913-9c6c-47bc-aa42-b9ce3fd1a276,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-c3470cbb-e61a-48d3-9f41-e4afcd23ebaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-7b5145af-7809-40ae-af6a-0e8663ef98e1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-718836026-172.17.0.15-1597412744005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43955,DS-7c217810-a306-429e-9d4c-33544ce44ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-81e0d006-5b25-4f9d-a159-1ea2445b45ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-f4ef6fbb-171c-4ec4-9e3e-06b05ae742a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-96f60695-fdc2-48b6-b191-e6551f1fc703,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-05a7fc73-fbd6-4264-8ace-2476da3607bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-62342913-9c6c-47bc-aa42-b9ce3fd1a276,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-c3470cbb-e61a-48d3-9f41-e4afcd23ebaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-7b5145af-7809-40ae-af6a-0e8663ef98e1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1936856551-172.17.0.15-1597412985379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42055,DS-5a6522c2-6f0b-4258-951b-8ee91e3eeef4,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-e7a6d382-070f-47c9-8ebc-2e3c9a8b62c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-453bb299-b31c-4cd4-bb21-02dc9cf05c49,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-970406e4-386b-473c-861f-aea961bcf843,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-d6774bc3-b29c-4b93-b44f-885573182918,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-8c43e6b7-b242-4965-a511-56d281364b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-418b4f79-952b-4dda-b15c-694d2c7ad65e,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-1b2adb52-fc93-4d8b-a3f4-80044b3139f9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1936856551-172.17.0.15-1597412985379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42055,DS-5a6522c2-6f0b-4258-951b-8ee91e3eeef4,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-e7a6d382-070f-47c9-8ebc-2e3c9a8b62c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-453bb299-b31c-4cd4-bb21-02dc9cf05c49,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-970406e4-386b-473c-861f-aea961bcf843,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-d6774bc3-b29c-4b93-b44f-885573182918,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-8c43e6b7-b242-4965-a511-56d281364b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-418b4f79-952b-4dda-b15c-694d2c7ad65e,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-1b2adb52-fc93-4d8b-a3f4-80044b3139f9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-898869450-172.17.0.15-1597413073537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42344,DS-d8c45c6d-5e7a-48bc-aa74-886ee7382055,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-a15da279-290f-4b0c-bf24-9d701d59aae9,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-3612b056-cf84-4646-97b7-e769dfa99c21,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-5136524f-65a2-451c-b3ba-84c8589f12e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-fe596584-5796-4a11-baff-4adf83c88f21,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-7df27f9e-bf21-43d4-8d68-6499ae7c90b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-bf8298c9-24cd-4305-9fea-508bf07815e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-6ee39448-bc50-4ede-bb15-c6cf078521fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-898869450-172.17.0.15-1597413073537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42344,DS-d8c45c6d-5e7a-48bc-aa74-886ee7382055,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-a15da279-290f-4b0c-bf24-9d701d59aae9,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-3612b056-cf84-4646-97b7-e769dfa99c21,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-5136524f-65a2-451c-b3ba-84c8589f12e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-fe596584-5796-4a11-baff-4adf83c88f21,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-7df27f9e-bf21-43d4-8d68-6499ae7c90b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-bf8298c9-24cd-4305-9fea-508bf07815e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-6ee39448-bc50-4ede-bb15-c6cf078521fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707479995-172.17.0.15-1597413449348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33813,DS-2fb94011-135b-419c-b062-44cfab99052f,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-7f5727d0-b5b1-477d-9237-cc39ab4bc135,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-de46541d-70b2-4482-9cf4-d7a1275c9e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-0a4071d3-6199-440e-8daf-b5b955038692,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-a69a4eff-c8fb-4bc6-8b73-f8aa6d41c95c,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-85cb0fd7-bec1-49d7-83b1-3c15997b6541,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-0313ef90-fd31-4a59-90e0-436cdb6497f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-2753cc4e-223a-49bd-b145-ce3a56b70ed2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707479995-172.17.0.15-1597413449348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33813,DS-2fb94011-135b-419c-b062-44cfab99052f,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-7f5727d0-b5b1-477d-9237-cc39ab4bc135,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-de46541d-70b2-4482-9cf4-d7a1275c9e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-0a4071d3-6199-440e-8daf-b5b955038692,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-a69a4eff-c8fb-4bc6-8b73-f8aa6d41c95c,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-85cb0fd7-bec1-49d7-83b1-3c15997b6541,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-0313ef90-fd31-4a59-90e0-436cdb6497f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-2753cc4e-223a-49bd-b145-ce3a56b70ed2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-181166396-172.17.0.15-1597413547808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45621,DS-89cc9313-b586-4784-8ba2-3dbb2a673ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-856f138c-cb3d-472c-aeb2-6d8190260eac,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-f237e485-8c53-44d5-a24a-1090ab71ec75,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-5e5e56f1-f4f9-4feb-8457-f61c91e01536,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-398c0065-0c2d-41c1-ba78-a0d82b6e837a,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-4c0a6853-10ad-43ef-ad2f-0056fc0115cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-95dac755-8000-490b-ab37-2a1cb5023458,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-a61e8542-1c10-4bdf-9b89-63922934a1d0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-181166396-172.17.0.15-1597413547808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45621,DS-89cc9313-b586-4784-8ba2-3dbb2a673ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-856f138c-cb3d-472c-aeb2-6d8190260eac,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-f237e485-8c53-44d5-a24a-1090ab71ec75,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-5e5e56f1-f4f9-4feb-8457-f61c91e01536,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-398c0065-0c2d-41c1-ba78-a0d82b6e837a,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-4c0a6853-10ad-43ef-ad2f-0056fc0115cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-95dac755-8000-490b-ab37-2a1cb5023458,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-a61e8542-1c10-4bdf-9b89-63922934a1d0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1671574411-172.17.0.15-1597413903898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33309,DS-51bfffc6-117c-4b5e-8637-6070c7679dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-26048952-b1a3-4fec-b760-0e6bf4993628,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-be84883a-0308-4eca-b854-204a31656981,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-4087934a-4c8d-4c93-b45c-3cf4b82a317b,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-1b5a460b-9bd4-4372-a907-966d8d7228cf,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-99ae31be-aa40-4579-8e31-a570dd00b3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-3d79ee2a-b001-4a35-848a-bde90af50fce,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-0ceec0a7-97d8-4815-9aa5-a828a0293093,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1671574411-172.17.0.15-1597413903898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33309,DS-51bfffc6-117c-4b5e-8637-6070c7679dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-26048952-b1a3-4fec-b760-0e6bf4993628,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-be84883a-0308-4eca-b854-204a31656981,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-4087934a-4c8d-4c93-b45c-3cf4b82a317b,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-1b5a460b-9bd4-4372-a907-966d8d7228cf,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-99ae31be-aa40-4579-8e31-a570dd00b3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-3d79ee2a-b001-4a35-848a-bde90af50fce,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-0ceec0a7-97d8-4815-9aa5-a828a0293093,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561361133-172.17.0.15-1597414193396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46344,DS-e3491d8c-3f6d-4ef7-bc1e-afc276842cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-a9deb296-31db-4b78-a460-073e80ddb6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-880c2594-d5ea-48a9-96dd-be991820b4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-ab61a55e-e6eb-4c1b-95ca-355fd5608eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-84d281c5-6740-48b2-9dd5-56054fbbd23d,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-4458d866-b417-4b97-9bf6-71467d9ea503,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-5e313317-6425-4ebf-a542-6b0f89b02b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-f7bdcbe8-9c74-4ddb-9bab-a245c06c886b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561361133-172.17.0.15-1597414193396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46344,DS-e3491d8c-3f6d-4ef7-bc1e-afc276842cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-a9deb296-31db-4b78-a460-073e80ddb6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-880c2594-d5ea-48a9-96dd-be991820b4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-ab61a55e-e6eb-4c1b-95ca-355fd5608eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-84d281c5-6740-48b2-9dd5-56054fbbd23d,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-4458d866-b417-4b97-9bf6-71467d9ea503,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-5e313317-6425-4ebf-a542-6b0f89b02b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-f7bdcbe8-9c74-4ddb-9bab-a245c06c886b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1562102349-172.17.0.15-1597414429493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43031,DS-25602575-cf3a-4443-ab98-d91214ad61fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-963b4c05-e8ff-4795-8946-eb5c0425b608,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-b2e5e37b-cb44-4086-b8b2-7292166a90fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-531cef12-09f0-4a19-9437-b981ccdb4039,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-0fd76836-1c5a-4851-be52-24e6a1c586ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-68832f28-9cea-463c-ad25-f8eee1486d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-3bb538ff-60d3-4a5d-bd63-3f34c499945d,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-46960d4e-2d22-475f-b66b-bef609d6b5f2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1562102349-172.17.0.15-1597414429493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43031,DS-25602575-cf3a-4443-ab98-d91214ad61fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-963b4c05-e8ff-4795-8946-eb5c0425b608,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-b2e5e37b-cb44-4086-b8b2-7292166a90fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-531cef12-09f0-4a19-9437-b981ccdb4039,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-0fd76836-1c5a-4851-be52-24e6a1c586ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-68832f28-9cea-463c-ad25-f8eee1486d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-3bb538ff-60d3-4a5d-bd63-3f34c499945d,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-46960d4e-2d22-475f-b66b-bef609d6b5f2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-30665005-172.17.0.15-1597414728341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46761,DS-53708f6b-05b5-41c4-bb61-84c3bb083101,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-ab84e4a3-a094-40a8-8716-01b24a093bba,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-31442e64-3553-4cad-8e1b-ae15c630cfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-f8c86798-243a-4423-95a4-808b0d82e1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-4d5d9ade-eb3d-49c4-9c36-e3e96a906841,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-432aa6ee-a294-4f5c-b9af-ff9880d956f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-90ad2757-4fa0-496c-87e9-edbda4a5ba7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-201728c4-857b-4ec9-805f-a2b18811cc46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-30665005-172.17.0.15-1597414728341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46761,DS-53708f6b-05b5-41c4-bb61-84c3bb083101,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-ab84e4a3-a094-40a8-8716-01b24a093bba,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-31442e64-3553-4cad-8e1b-ae15c630cfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-f8c86798-243a-4423-95a4-808b0d82e1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-4d5d9ade-eb3d-49c4-9c36-e3e96a906841,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-432aa6ee-a294-4f5c-b9af-ff9880d956f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-90ad2757-4fa0-496c-87e9-edbda4a5ba7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-201728c4-857b-4ec9-805f-a2b18811cc46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 25 out of 50
result: false positive !!!
Total execution time in seconds : 7146
