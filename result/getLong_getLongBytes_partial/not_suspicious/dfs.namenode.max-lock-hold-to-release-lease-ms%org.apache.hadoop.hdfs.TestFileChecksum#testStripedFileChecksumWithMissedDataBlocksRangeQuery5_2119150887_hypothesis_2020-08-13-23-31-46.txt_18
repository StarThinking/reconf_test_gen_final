reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 250
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 250
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1285836658-172.17.0.8-1597361944497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37030,DS-cc315b2c-2c08-4ecd-9747-b3b1732cd7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-9f3c5996-4f3d-4398-9692-fca0073205b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-894c8e28-6058-47c9-b372-e9af4fb8232d,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-037cd513-2c89-4164-8552-8b55d022e86e,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-ba0ba76e-480a-4ae1-aca5-a5b6b8e42de4,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-4ff73f51-cfb0-46da-a0d6-cf032e7bd36f,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-d8e4dccb-9c11-486a-9424-8816452c056a,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-b1c7596f-7c45-47dd-96f9-97aac235931e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1285836658-172.17.0.8-1597361944497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37030,DS-cc315b2c-2c08-4ecd-9747-b3b1732cd7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-9f3c5996-4f3d-4398-9692-fca0073205b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-894c8e28-6058-47c9-b372-e9af4fb8232d,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-037cd513-2c89-4164-8552-8b55d022e86e,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-ba0ba76e-480a-4ae1-aca5-a5b6b8e42de4,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-4ff73f51-cfb0-46da-a0d6-cf032e7bd36f,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-d8e4dccb-9c11-486a-9424-8816452c056a,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-b1c7596f-7c45-47dd-96f9-97aac235931e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 250
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1335470873-172.17.0.8-1597361985449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35482,DS-9c45520a-6222-4b72-9049-43823d163c47,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-500da0a3-c0b0-41dc-8d50-49433d4c1173,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-9e9dc720-48cb-4555-b9e6-3a65d6728cab,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-028f64b4-77dc-496d-b2d8-21fad029cb12,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-fc6a95b2-9369-4923-a6d8-17617f8cf175,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-5d412bc0-f36d-45bd-a8ff-794a0cfe8351,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-c2cde23f-b695-4a73-980e-e7b45d190781,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-f9a13f08-81a8-4f9f-99ba-fad268cce4f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1335470873-172.17.0.8-1597361985449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35482,DS-9c45520a-6222-4b72-9049-43823d163c47,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-500da0a3-c0b0-41dc-8d50-49433d4c1173,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-9e9dc720-48cb-4555-b9e6-3a65d6728cab,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-028f64b4-77dc-496d-b2d8-21fad029cb12,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-fc6a95b2-9369-4923-a6d8-17617f8cf175,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-5d412bc0-f36d-45bd-a8ff-794a0cfe8351,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-c2cde23f-b695-4a73-980e-e7b45d190781,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-f9a13f08-81a8-4f9f-99ba-fad268cce4f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 250
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077111544-172.17.0.8-1597362029226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35752,DS-fcd51d7f-f3e2-4b96-b0be-06c69a7128be,DISK], DatanodeInfoWithStorage[127.0.0.1:44132,DS-64add9d9-49af-48ae-a5fb-d3654d7edf6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-b08a9843-aec0-4b73-b28b-7054edf11d53,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-8cb009a1-ba0a-48ff-88e0-1905189b6551,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-9eefaf94-a55a-4115-bd59-a52e8ae8ca1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-4aff107e-016b-448a-86fd-cd5c81fbfef2,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-c154c65a-e638-45eb-a92d-c425f9529afa,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-f064ac31-c5ca-4f25-adc7-628e251fbcc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077111544-172.17.0.8-1597362029226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35752,DS-fcd51d7f-f3e2-4b96-b0be-06c69a7128be,DISK], DatanodeInfoWithStorage[127.0.0.1:44132,DS-64add9d9-49af-48ae-a5fb-d3654d7edf6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-b08a9843-aec0-4b73-b28b-7054edf11d53,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-8cb009a1-ba0a-48ff-88e0-1905189b6551,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-9eefaf94-a55a-4115-bd59-a52e8ae8ca1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-4aff107e-016b-448a-86fd-cd5c81fbfef2,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-c154c65a-e638-45eb-a92d-c425f9529afa,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-f064ac31-c5ca-4f25-adc7-628e251fbcc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 250
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369845366-172.17.0.8-1597362075296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40991,DS-268a587e-995a-4dc2-b008-ebcb3a255fea,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-891d24da-893d-4cfb-9d38-44fc43be3f01,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-9240d4c0-5c46-4762-90ae-e1fe2c055c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-2d3800e1-5b89-457f-b2a9-85397224f61c,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-f00d2bc7-b5a1-4dc9-ab84-fa95a3efb5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-f055eba1-092b-4fd8-9a47-b6dac25d1379,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-e2c74944-cbdb-4727-9988-878084e397b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-f18974f6-c7a7-421f-b644-6382c816823b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369845366-172.17.0.8-1597362075296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40991,DS-268a587e-995a-4dc2-b008-ebcb3a255fea,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-891d24da-893d-4cfb-9d38-44fc43be3f01,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-9240d4c0-5c46-4762-90ae-e1fe2c055c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-2d3800e1-5b89-457f-b2a9-85397224f61c,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-f00d2bc7-b5a1-4dc9-ab84-fa95a3efb5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-f055eba1-092b-4fd8-9a47-b6dac25d1379,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-e2c74944-cbdb-4727-9988-878084e397b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-f18974f6-c7a7-421f-b644-6382c816823b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 250
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854296669-172.17.0.8-1597362914290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38708,DS-38515e32-2521-492b-bd0c-85e782d80916,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-8c80baa0-954a-4a9e-82fb-562735cc0ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-2e1b29ff-ed2a-4c4c-9333-edbfb5c644bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-df3ef321-9096-4c6e-8941-27fb2377ff59,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-ce8fabff-191a-494c-80a3-247f43f09a99,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-824a3d82-4961-4e3e-8476-5d62200c825c,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-8f0fa392-e995-4341-aaa6-e43f29783911,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-1ad17bed-5027-4052-a742-0a86485715f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854296669-172.17.0.8-1597362914290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38708,DS-38515e32-2521-492b-bd0c-85e782d80916,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-8c80baa0-954a-4a9e-82fb-562735cc0ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-2e1b29ff-ed2a-4c4c-9333-edbfb5c644bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-df3ef321-9096-4c6e-8941-27fb2377ff59,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-ce8fabff-191a-494c-80a3-247f43f09a99,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-824a3d82-4961-4e3e-8476-5d62200c825c,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-8f0fa392-e995-4341-aaa6-e43f29783911,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-1ad17bed-5027-4052-a742-0a86485715f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 250
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701755301-172.17.0.8-1597363086797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43152,DS-df62b2c8-29d1-4345-a6d3-adddeaf1628e,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-9bb82514-2361-4e3d-98ca-3251d59b558f,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-62489601-d9a2-4b01-8ce2-85b3ab68bafd,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-07f8549b-7697-42d5-b271-c9b272d192b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-88a98fc3-e425-4a55-86d1-6889bc3ca45a,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-d0d83c73-8620-4dc4-a845-fefe183d9e81,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-bcb4d2c0-d02c-4466-878d-ee7190728365,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-2e0dd4da-3102-4b02-bb3b-9e24515061be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701755301-172.17.0.8-1597363086797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43152,DS-df62b2c8-29d1-4345-a6d3-adddeaf1628e,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-9bb82514-2361-4e3d-98ca-3251d59b558f,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-62489601-d9a2-4b01-8ce2-85b3ab68bafd,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-07f8549b-7697-42d5-b271-c9b272d192b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-88a98fc3-e425-4a55-86d1-6889bc3ca45a,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-d0d83c73-8620-4dc4-a845-fefe183d9e81,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-bcb4d2c0-d02c-4466-878d-ee7190728365,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-2e0dd4da-3102-4b02-bb3b-9e24515061be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 250
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1408262351-172.17.0.8-1597363262886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34395,DS-494afd7e-8d81-45fe-9e21-4aa4b2ad4cde,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-288414b6-771f-41b3-afb0-036b22443c86,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-3d99420a-7eb4-4a89-aebc-d35c14422242,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-6749e727-d9e7-41c2-ac91-3da9791de97f,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-40e94f92-066c-4ce6-96e0-40fdd68fc295,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-312d7f3d-dc82-46fe-a671-0b7819da035c,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-677f36e1-9608-4c4e-b56a-7942d95a3bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-2ce12402-be9d-447a-9b34-a7e51739824c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1408262351-172.17.0.8-1597363262886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34395,DS-494afd7e-8d81-45fe-9e21-4aa4b2ad4cde,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-288414b6-771f-41b3-afb0-036b22443c86,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-3d99420a-7eb4-4a89-aebc-d35c14422242,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-6749e727-d9e7-41c2-ac91-3da9791de97f,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-40e94f92-066c-4ce6-96e0-40fdd68fc295,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-312d7f3d-dc82-46fe-a671-0b7819da035c,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-677f36e1-9608-4c4e-b56a-7942d95a3bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46871,DS-2ce12402-be9d-447a-9b34-a7e51739824c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 250
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144243617-172.17.0.8-1597363540406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38881,DS-96dc44e9-5ad9-4eb3-b7c9-a982af70b27d,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-6d2aa5b1-0be7-4c70-8392-8d976bccc859,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-10b26ea8-f0eb-4bdf-9b08-e39d72bed8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-063a3144-a327-473f-9789-67d311a2dbce,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-452de72b-d801-41a4-9aa8-40a99b88d3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-dccaccf3-16f9-41a4-ae32-65b9f464986c,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-1bdb5dc1-a9d4-4a3a-9600-918d24c0a884,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-fcc7e8ce-75ef-40be-bc2e-44885f269fb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144243617-172.17.0.8-1597363540406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38881,DS-96dc44e9-5ad9-4eb3-b7c9-a982af70b27d,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-6d2aa5b1-0be7-4c70-8392-8d976bccc859,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-10b26ea8-f0eb-4bdf-9b08-e39d72bed8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-063a3144-a327-473f-9789-67d311a2dbce,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-452de72b-d801-41a4-9aa8-40a99b88d3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-dccaccf3-16f9-41a4-ae32-65b9f464986c,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-1bdb5dc1-a9d4-4a3a-9600-918d24c0a884,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-fcc7e8ce-75ef-40be-bc2e-44885f269fb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 250
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-573003357-172.17.0.8-1597363628748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37853,DS-b2b0c792-4184-478f-b7ce-a99bf1c7ff60,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-799bd5d4-8501-4adf-9900-cb5145330f37,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-b788aca6-de20-4289-b514-828eafc7eb39,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-8a876223-3590-44e7-a360-800dfc2d282c,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-5075699f-efcd-45cc-bbaf-0443865f0dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-21e7bd55-9459-4572-bfab-464b1726c385,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-831b3b5c-7478-415b-96e5-342701574ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-badb8a84-9b0f-4730-aef4-830d5e41de0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-573003357-172.17.0.8-1597363628748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37853,DS-b2b0c792-4184-478f-b7ce-a99bf1c7ff60,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-799bd5d4-8501-4adf-9900-cb5145330f37,DISK], DatanodeInfoWithStorage[127.0.0.1:41208,DS-b788aca6-de20-4289-b514-828eafc7eb39,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-8a876223-3590-44e7-a360-800dfc2d282c,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-5075699f-efcd-45cc-bbaf-0443865f0dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-21e7bd55-9459-4572-bfab-464b1726c385,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-831b3b5c-7478-415b-96e5-342701574ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-badb8a84-9b0f-4730-aef4-830d5e41de0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 250
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-631390235-172.17.0.8-1597363768399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43677,DS-a615b2ff-f5a3-47f3-ab1d-bbf71a6050a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-a194f4af-d0a0-47ec-9e59-129386812543,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-dd4073c6-00bf-4c29-ba33-33757ebd6232,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-dfbe6db2-ed11-42ae-b158-5e83d65979dd,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-4e5f0c41-9ff7-4aad-85d3-d978434dd215,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-fa81c230-0e24-45bf-9439-bd3df782cfc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-2cd5f3b7-4803-4f5f-bed8-2b2e160bda3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-6753f2c2-0db0-4656-b177-338a7632aabb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-631390235-172.17.0.8-1597363768399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43677,DS-a615b2ff-f5a3-47f3-ab1d-bbf71a6050a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-a194f4af-d0a0-47ec-9e59-129386812543,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-dd4073c6-00bf-4c29-ba33-33757ebd6232,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-dfbe6db2-ed11-42ae-b158-5e83d65979dd,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-4e5f0c41-9ff7-4aad-85d3-d978434dd215,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-fa81c230-0e24-45bf-9439-bd3df782cfc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-2cd5f3b7-4803-4f5f-bed8-2b2e160bda3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-6753f2c2-0db0-4656-b177-338a7632aabb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 250
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1080848567-172.17.0.8-1597364133113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40655,DS-87ead81d-05a4-4a92-bb6d-bdc215eea5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-86a0a26f-c5be-41b2-a10b-1bc5498539a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-5fba9bdd-d629-4d32-b65d-c68125616d93,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-7bdf613f-02d5-4210-90a7-c27b00416f71,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-55e40762-c620-4e69-9677-523316a9e0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-571a1eb8-3308-4f47-a296-6008a3c5da4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-5bccb129-a4cc-40a9-977a-094fd7340ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-592ad602-fa1d-4d55-8739-40de6bbb783c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1080848567-172.17.0.8-1597364133113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40655,DS-87ead81d-05a4-4a92-bb6d-bdc215eea5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-86a0a26f-c5be-41b2-a10b-1bc5498539a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-5fba9bdd-d629-4d32-b65d-c68125616d93,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-7bdf613f-02d5-4210-90a7-c27b00416f71,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-55e40762-c620-4e69-9677-523316a9e0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-571a1eb8-3308-4f47-a296-6008a3c5da4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-5bccb129-a4cc-40a9-977a-094fd7340ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-592ad602-fa1d-4d55-8739-40de6bbb783c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 250
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841391538-172.17.0.8-1597364263630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34146,DS-d4bb9949-bf26-4015-a862-b185fb7ec398,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-19577849-dee8-47c9-bc9c-8050612dc7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-38600d2a-1338-4bdc-9672-9c7066865026,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-0b5e965c-2557-4a3b-a8ff-810f1e25bc71,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-3dd200dd-2e4e-4e5d-89d6-b1724263896e,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-bfa8f830-7089-4c19-8f7b-0b965e299acd,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-1de56154-3867-493a-8aa0-83ed8fc6c718,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-2763b8c7-dbdd-417e-a730-aa5b56fa9f5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841391538-172.17.0.8-1597364263630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34146,DS-d4bb9949-bf26-4015-a862-b185fb7ec398,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-19577849-dee8-47c9-bc9c-8050612dc7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-38600d2a-1338-4bdc-9672-9c7066865026,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-0b5e965c-2557-4a3b-a8ff-810f1e25bc71,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-3dd200dd-2e4e-4e5d-89d6-b1724263896e,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-bfa8f830-7089-4c19-8f7b-0b965e299acd,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-1de56154-3867-493a-8aa0-83ed8fc6c718,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-2763b8c7-dbdd-417e-a730-aa5b56fa9f5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 250
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526011958-172.17.0.8-1597364385136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44488,DS-a785f1bf-3e4d-4388-a2f1-c8ba771bac4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-f7b7f894-3bf9-4240-b82d-dc2facf2a110,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-f1b2cd91-661b-4cc2-9373-1866bc279a06,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-16ae6725-4df2-4376-bbb1-7a271b799aea,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-18a24ceb-8dc1-435b-8b13-8e77989255af,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-1b8283a1-2594-40c9-a7eb-a862858defb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-3b90ef92-9278-44bd-89f7-aec90d3ead5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-677ff269-3047-4483-85da-4563ea794d80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526011958-172.17.0.8-1597364385136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44488,DS-a785f1bf-3e4d-4388-a2f1-c8ba771bac4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-f7b7f894-3bf9-4240-b82d-dc2facf2a110,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-f1b2cd91-661b-4cc2-9373-1866bc279a06,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-16ae6725-4df2-4376-bbb1-7a271b799aea,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-18a24ceb-8dc1-435b-8b13-8e77989255af,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-1b8283a1-2594-40c9-a7eb-a862858defb6,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-3b90ef92-9278-44bd-89f7-aec90d3ead5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-677ff269-3047-4483-85da-4563ea794d80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 250
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892208524-172.17.0.8-1597364631899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45524,DS-0bd50f24-47f5-4502-90c4-c0dbfe895ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-d7fff747-3b0b-46f0-b660-44709219bbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-792be5ca-0706-484d-aa8a-e77388223777,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-f336dfb3-fee8-453d-bbd7-29e6910f4e95,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-aa560437-61ed-41e6-8413-740f127be62d,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-e114558a-23c6-45e8-8dec-0a3377db6d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-4e1226c4-e486-49ec-996f-883595db40ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-46cd1a49-fc24-424c-adf1-e359ddc457bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892208524-172.17.0.8-1597364631899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45524,DS-0bd50f24-47f5-4502-90c4-c0dbfe895ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-d7fff747-3b0b-46f0-b660-44709219bbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-792be5ca-0706-484d-aa8a-e77388223777,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-f336dfb3-fee8-453d-bbd7-29e6910f4e95,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-aa560437-61ed-41e6-8413-740f127be62d,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-e114558a-23c6-45e8-8dec-0a3377db6d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-4e1226c4-e486-49ec-996f-883595db40ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-46cd1a49-fc24-424c-adf1-e359ddc457bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 250
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1034166741-172.17.0.8-1597365049521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42509,DS-d9c83814-4782-4d57-bd87-df332eb52d35,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-54e6ee61-e61e-4b8e-814d-599a9cb100b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-09d083d7-a762-46eb-b4c3-561645f93d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-7b4a4ebb-c2b1-4d16-8e2d-b78c21e3f514,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-9e35bb2f-0d25-4a40-af65-774e38160b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-2e02532c-495b-461c-9843-3be62c3f53f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-682f7a93-5b17-4abd-94b9-2104ba781124,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-536628cd-4013-4f11-b602-f2e51a10db21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1034166741-172.17.0.8-1597365049521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42509,DS-d9c83814-4782-4d57-bd87-df332eb52d35,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-54e6ee61-e61e-4b8e-814d-599a9cb100b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-09d083d7-a762-46eb-b4c3-561645f93d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-7b4a4ebb-c2b1-4d16-8e2d-b78c21e3f514,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-9e35bb2f-0d25-4a40-af65-774e38160b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-2e02532c-495b-461c-9843-3be62c3f53f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-682f7a93-5b17-4abd-94b9-2104ba781124,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-536628cd-4013-4f11-b602-f2e51a10db21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 250
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-866146478-172.17.0.8-1597365407201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39454,DS-0f6e5686-c135-4655-9993-dfdccdfc107f,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-1e9f2a31-d412-4fd3-b70e-3d64ffe81992,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-7c9e2d3e-5f82-4c94-a0d8-aed3be2393b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-8bbb9b81-82d5-4ed6-8c57-379c3a62c7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-e22f053b-78cb-4c94-b1c9-7e080ee33c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-8b241fa1-2b28-4e86-b2f6-c97bd1bb346f,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-1e02959b-2187-4b8c-8876-3e800495390a,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-be222817-6ea2-4bf5-b68e-72af18755845,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-866146478-172.17.0.8-1597365407201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39454,DS-0f6e5686-c135-4655-9993-dfdccdfc107f,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-1e9f2a31-d412-4fd3-b70e-3d64ffe81992,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-7c9e2d3e-5f82-4c94-a0d8-aed3be2393b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-8bbb9b81-82d5-4ed6-8c57-379c3a62c7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-e22f053b-78cb-4c94-b1c9-7e080ee33c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-8b241fa1-2b28-4e86-b2f6-c97bd1bb346f,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-1e02959b-2187-4b8c-8876-3e800495390a,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-be222817-6ea2-4bf5-b68e-72af18755845,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 250
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388558959-172.17.0.8-1597365817051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42605,DS-71d9d377-08a1-4bff-bc40-b9d481530136,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-3063e50b-ca72-4805-bbc6-b1cb4015c034,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-464363b8-2ff2-4e3a-90c7-d33dcf2990de,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-dc92bec0-3f70-4f4c-b519-0443f8d9c5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-06ec5699-a8c0-4d18-b5c2-162d155d05c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-359301ab-e0d3-4d6f-834c-6d321557f01b,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-736de244-fbba-4275-aa31-9212e4a54a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-63abdfdf-9a06-4945-a155-6fb5677ab613,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388558959-172.17.0.8-1597365817051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42605,DS-71d9d377-08a1-4bff-bc40-b9d481530136,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-3063e50b-ca72-4805-bbc6-b1cb4015c034,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-464363b8-2ff2-4e3a-90c7-d33dcf2990de,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-dc92bec0-3f70-4f4c-b519-0443f8d9c5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-06ec5699-a8c0-4d18-b5c2-162d155d05c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-359301ab-e0d3-4d6f-834c-6d321557f01b,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-736de244-fbba-4275-aa31-9212e4a54a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-63abdfdf-9a06-4945-a155-6fb5677ab613,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 250
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-238820427-172.17.0.8-1597366006378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45576,DS-1fcc374a-0d07-4474-b8c8-bffda19daded,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-b622c871-f6f9-48c5-b5b7-51b64af3126b,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-df346b9a-3bfa-4cf9-9607-eaa7f93521c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-8ddd5d8c-8ca7-4c43-b093-89f152721c08,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-6da4769a-4244-41ff-9e18-cf4937c74697,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-2fba3760-e579-4469-9b5a-ddb6e2d316f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-16185c64-a613-406b-a0af-bd434ba2153c,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-588da3eb-40be-4d7a-8b68-d9f43dec8ad2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-238820427-172.17.0.8-1597366006378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45576,DS-1fcc374a-0d07-4474-b8c8-bffda19daded,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-b622c871-f6f9-48c5-b5b7-51b64af3126b,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-df346b9a-3bfa-4cf9-9607-eaa7f93521c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-8ddd5d8c-8ca7-4c43-b093-89f152721c08,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-6da4769a-4244-41ff-9e18-cf4937c74697,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-2fba3760-e579-4469-9b5a-ddb6e2d316f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-16185c64-a613-406b-a0af-bd434ba2153c,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-588da3eb-40be-4d7a-8b68-d9f43dec8ad2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 250
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089581321-172.17.0.8-1597366307203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36207,DS-78768012-d64b-41c4-a19e-502e89eee03b,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-d23a5f42-5c8b-4037-9116-9adaa8f4ddb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-41e6f4f7-881d-4229-9874-e2277d323b34,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-3d9e761b-5b60-4abb-a00b-b06c1213b823,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-daeaaf7c-4226-4f04-adbc-67d49d4405af,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-a83853e6-327a-4ff0-8dd8-a17d803e6a03,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-0f2a905e-5041-44d2-bbfe-5687675a1d50,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-9bbce715-3010-419b-ba85-64e757b201fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089581321-172.17.0.8-1597366307203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36207,DS-78768012-d64b-41c4-a19e-502e89eee03b,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-d23a5f42-5c8b-4037-9116-9adaa8f4ddb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-41e6f4f7-881d-4229-9874-e2277d323b34,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-3d9e761b-5b60-4abb-a00b-b06c1213b823,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-daeaaf7c-4226-4f04-adbc-67d49d4405af,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-a83853e6-327a-4ff0-8dd8-a17d803e6a03,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-0f2a905e-5041-44d2-bbfe-5687675a1d50,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-9bbce715-3010-419b-ba85-64e757b201fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 250
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1815285304-172.17.0.8-1597366483894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37182,DS-50a8bc6b-e41a-4745-90eb-397d48ba2e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-63b5bd3d-3b13-473f-aca4-ac9852759423,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-f052e7a4-39ad-4d67-aeac-6f4e3670a5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-e3e05936-2d7a-428b-ba62-4630d3a8c9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-a1c4af26-b34b-457f-b889-4f346c524fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43398,DS-ea06c422-3368-4aeb-b247-334f31963c85,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-60e12d2a-d131-464c-9afe-f270d4fe1ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-fb631c6f-6f2a-4a26-8d1c-8bb97d9a41d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1815285304-172.17.0.8-1597366483894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37182,DS-50a8bc6b-e41a-4745-90eb-397d48ba2e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-63b5bd3d-3b13-473f-aca4-ac9852759423,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-f052e7a4-39ad-4d67-aeac-6f4e3670a5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-e3e05936-2d7a-428b-ba62-4630d3a8c9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-a1c4af26-b34b-457f-b889-4f346c524fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43398,DS-ea06c422-3368-4aeb-b247-334f31963c85,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-60e12d2a-d131-464c-9afe-f270d4fe1ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-fb631c6f-6f2a-4a26-8d1c-8bb97d9a41d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 250
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-883776917-172.17.0.8-1597366623510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41802,DS-a0e07321-434e-40aa-87b2-f70f9186a91a,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-d3099c4c-e21e-4f9d-b7da-717edd0676ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-7bdd5461-94b4-4abb-9525-c5077148dcac,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-67d2424d-69c7-4eb6-9c14-3c43906b2c69,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-02374959-6846-4f3d-b788-0b6d907eb57d,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-0c94bcdd-884f-4415-9b6a-9d73c3ecff8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-f5b5cb68-705d-4662-b87d-0b63ea52db7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-5e9a177e-4ff7-485e-804c-294500add802,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-883776917-172.17.0.8-1597366623510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41802,DS-a0e07321-434e-40aa-87b2-f70f9186a91a,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-d3099c4c-e21e-4f9d-b7da-717edd0676ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-7bdd5461-94b4-4abb-9525-c5077148dcac,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-67d2424d-69c7-4eb6-9c14-3c43906b2c69,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-02374959-6846-4f3d-b788-0b6d907eb57d,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-0c94bcdd-884f-4415-9b6a-9d73c3ecff8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-f5b5cb68-705d-4662-b87d-0b63ea52db7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-5e9a177e-4ff7-485e-804c-294500add802,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 250
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1298898788-172.17.0.8-1597367067098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40768,DS-12145fa4-5013-4028-97c8-24e72e4a8df1,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-1e9b07e9-5906-4f38-ae83-bc4e605487bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-7855d517-e760-4df8-ba69-6ac99780f0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-6f61ee89-241a-48c3-8e35-3ef664fe6f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-34ef100a-8f89-455b-ab89-d68184f66167,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-79f40019-7580-4b67-8d4c-1ad68b753aba,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-299ff6dc-18ef-4ee1-b528-1ce4cd7a7133,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-f3d98301-c88e-4407-a31c-37ed226318dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1298898788-172.17.0.8-1597367067098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40768,DS-12145fa4-5013-4028-97c8-24e72e4a8df1,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-1e9b07e9-5906-4f38-ae83-bc4e605487bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-7855d517-e760-4df8-ba69-6ac99780f0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-6f61ee89-241a-48c3-8e35-3ef664fe6f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-34ef100a-8f89-455b-ab89-d68184f66167,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-79f40019-7580-4b67-8d4c-1ad68b753aba,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-299ff6dc-18ef-4ee1-b528-1ce4cd7a7133,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-f3d98301-c88e-4407-a31c-37ed226318dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 250
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-666472467-172.17.0.8-1597367182990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33194,DS-c27dd220-99c1-47f7-b04c-1b233907d990,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-97faa831-c449-41c2-a7d7-d803da73d010,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-7fa0556f-11a9-4c9b-af7a-a5322ca0bb74,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-afd9a1e5-aff5-413d-bc56-578ab2fb5edf,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-aaeb6d7f-220e-45be-883c-afb4ff898cba,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-d3be8990-ac52-4238-91e4-f8eb668c5241,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-61ce06ff-aaba-49fc-be26-38f7186fa134,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-4b1241da-035c-4163-9db1-ce8b5dd3094c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-666472467-172.17.0.8-1597367182990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33194,DS-c27dd220-99c1-47f7-b04c-1b233907d990,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-97faa831-c449-41c2-a7d7-d803da73d010,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-7fa0556f-11a9-4c9b-af7a-a5322ca0bb74,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-afd9a1e5-aff5-413d-bc56-578ab2fb5edf,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-aaeb6d7f-220e-45be-883c-afb4ff898cba,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-d3be8990-ac52-4238-91e4-f8eb668c5241,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-61ce06ff-aaba-49fc-be26-38f7186fa134,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-4b1241da-035c-4163-9db1-ce8b5dd3094c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 250
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-834343861-172.17.0.8-1597367239419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37047,DS-0d1ccae3-a389-4163-a59b-69ee0db72511,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-e7c341a0-ffc7-4bcb-bc39-a30be0a44ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-828dbe3d-4e4a-4db6-b514-1b652a806850,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-576e3ea6-7aa5-4348-8197-a125a3468fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-5458811a-d8b6-4a61-9d60-529d9123501e,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-a41e7a20-3a74-4612-a88b-fa5a746b06c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-28ae3483-1c94-49f0-bd51-3f64101cc026,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-a1da9c4a-a9f4-46f2-8300-2a905e297a4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-834343861-172.17.0.8-1597367239419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37047,DS-0d1ccae3-a389-4163-a59b-69ee0db72511,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-e7c341a0-ffc7-4bcb-bc39-a30be0a44ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-828dbe3d-4e4a-4db6-b514-1b652a806850,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-576e3ea6-7aa5-4348-8197-a125a3468fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-5458811a-d8b6-4a61-9d60-529d9123501e,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-a41e7a20-3a74-4612-a88b-fa5a746b06c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-28ae3483-1c94-49f0-bd51-3f64101cc026,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-a1da9c4a-a9f4-46f2-8300-2a905e297a4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 250
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1309366704-172.17.0.8-1597367842116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46791,DS-577df78b-27c0-459b-ae95-871939ad93bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-d077fec6-8539-4846-9940-0c09344fe6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-f9f9611a-f849-4b74-821b-8c0c12cee351,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-3aac1647-dbeb-4622-8a59-6fbb268b1954,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-3f697361-d668-4207-84fc-2d8610ed8b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-9a9ca68a-2480-4420-bb45-93cedd50c961,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-e05fe580-e535-4ddb-958e-090e69250bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-dc1a9dc4-aa47-46d8-a073-c80c64057820,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1309366704-172.17.0.8-1597367842116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46791,DS-577df78b-27c0-459b-ae95-871939ad93bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-d077fec6-8539-4846-9940-0c09344fe6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-f9f9611a-f849-4b74-821b-8c0c12cee351,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-3aac1647-dbeb-4622-8a59-6fbb268b1954,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-3f697361-d668-4207-84fc-2d8610ed8b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-9a9ca68a-2480-4420-bb45-93cedd50c961,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-e05fe580-e535-4ddb-958e-090e69250bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-dc1a9dc4-aa47-46d8-a073-c80c64057820,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 250
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-843254225-172.17.0.8-1597367925200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35685,DS-d9c30d3f-7c7a-41d2-9d26-933ff22735e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46805,DS-72a7d6d5-c018-409d-9a89-0fb2fd1405c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-716d9393-3ae7-4095-8ec2-4e65a62058d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-666c2c72-20c0-48f3-9cf2-ab7039dfe52b,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-a3aca7c9-c37f-435f-9e38-bcf5386a66c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-8d85fdb6-8359-4fe6-904a-800a93516749,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-4b75f974-0741-4de7-97df-521b28b96665,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-f2639cf9-26ee-4f73-98c2-b236eefd1889,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-843254225-172.17.0.8-1597367925200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35685,DS-d9c30d3f-7c7a-41d2-9d26-933ff22735e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46805,DS-72a7d6d5-c018-409d-9a89-0fb2fd1405c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-716d9393-3ae7-4095-8ec2-4e65a62058d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-666c2c72-20c0-48f3-9cf2-ab7039dfe52b,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-a3aca7c9-c37f-435f-9e38-bcf5386a66c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-8d85fdb6-8359-4fe6-904a-800a93516749,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-4b75f974-0741-4de7-97df-521b28b96665,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-f2639cf9-26ee-4f73-98c2-b236eefd1889,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 25
v2: 250
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1830494239-172.17.0.8-1597368028400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38680,DS-4fa3dee1-70fc-4fff-a287-9f76c8fd7d64,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-b5b608ed-39fd-4b38-906f-5c37ebb356e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35942,DS-c9204625-0c08-4a1b-881b-6daa470e3102,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-c85c45a0-4edb-4285-9f7a-c72a72d279b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-81d662cb-b708-41fc-b8a6-90513be103ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-76c416ef-f353-4c6b-a776-be3ffcafef8c,DISK], DatanodeInfoWithStorage[127.0.0.1:32882,DS-cba46974-eaad-4df7-89c8-b8db333e1d72,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-8ca7175a-6a13-46f2-8f2d-83562fb76a7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1830494239-172.17.0.8-1597368028400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38680,DS-4fa3dee1-70fc-4fff-a287-9f76c8fd7d64,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-b5b608ed-39fd-4b38-906f-5c37ebb356e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35942,DS-c9204625-0c08-4a1b-881b-6daa470e3102,DISK], DatanodeInfoWithStorage[127.0.0.1:39351,DS-c85c45a0-4edb-4285-9f7a-c72a72d279b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-81d662cb-b708-41fc-b8a6-90513be103ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-76c416ef-f353-4c6b-a776-be3ffcafef8c,DISK], DatanodeInfoWithStorage[127.0.0.1:32882,DS-cba46974-eaad-4df7-89c8-b8db333e1d72,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-8ca7175a-6a13-46f2-8f2d-83562fb76a7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 6727
