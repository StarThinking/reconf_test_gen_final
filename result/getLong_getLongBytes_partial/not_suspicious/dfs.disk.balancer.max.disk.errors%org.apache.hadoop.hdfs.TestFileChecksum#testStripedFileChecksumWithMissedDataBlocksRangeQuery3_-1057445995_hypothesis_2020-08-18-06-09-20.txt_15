reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-762145804-172.17.0.8-1597731407797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40721,DS-126ae920-1e4a-4f1f-bd65-00462f63d836,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-d95c070e-bebc-43c5-ab8c-7bf86f5e47a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-8d8f1f2b-a180-48bd-9fa0-6268b5ec7d63,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-c9b2f117-3e4a-4474-8f8f-93ba1b667f08,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-bcdc9bff-aa83-4532-a5b0-107ed68e1df5,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-370268af-c013-4add-9eaa-2022c44a9b37,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-88a4e6d7-3203-404d-bd5c-bb9b0566c838,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-06b1b168-9b65-49d6-963f-53ba19d93982,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-762145804-172.17.0.8-1597731407797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40721,DS-126ae920-1e4a-4f1f-bd65-00462f63d836,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-d95c070e-bebc-43c5-ab8c-7bf86f5e47a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-8d8f1f2b-a180-48bd-9fa0-6268b5ec7d63,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-c9b2f117-3e4a-4474-8f8f-93ba1b667f08,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-bcdc9bff-aa83-4532-a5b0-107ed68e1df5,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-370268af-c013-4add-9eaa-2022c44a9b37,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-88a4e6d7-3203-404d-bd5c-bb9b0566c838,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-06b1b168-9b65-49d6-963f-53ba19d93982,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-185490018-172.17.0.8-1597731756174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40963,DS-3e76e8c6-d3d3-4b37-95ee-a954590326ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-0331a4fc-12be-4a6f-a09c-5b8358bc4f38,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-0f3be0e7-6c10-4e3f-a4b0-ffe009933a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-8954f67d-2317-4201-8cb9-9d01bc748211,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-ce2d5c05-34fe-4996-9d12-6c36805b8bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-02fdb877-18f5-4a73-b3d4-f20ce8e3b51e,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-b0283cc7-4499-42b6-b990-43e13d34c366,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-837a8ebc-8d96-44f6-a060-c06356959488,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-185490018-172.17.0.8-1597731756174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40963,DS-3e76e8c6-d3d3-4b37-95ee-a954590326ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-0331a4fc-12be-4a6f-a09c-5b8358bc4f38,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-0f3be0e7-6c10-4e3f-a4b0-ffe009933a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-8954f67d-2317-4201-8cb9-9d01bc748211,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-ce2d5c05-34fe-4996-9d12-6c36805b8bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-02fdb877-18f5-4a73-b3d4-f20ce8e3b51e,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-b0283cc7-4499-42b6-b990-43e13d34c366,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-837a8ebc-8d96-44f6-a060-c06356959488,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770360896-172.17.0.8-1597732021868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46860,DS-2978ca34-b507-4b4c-a027-9af184c22149,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-ed3eafe9-6af6-418c-926b-efe233382ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-718d4164-ea1c-4c06-90c7-1662971bc32e,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-a24079f2-9584-4016-89b8-c0c753f21852,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-2ad66891-b95c-48af-bd72-5b41a18264b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-94150558-d620-41cb-842d-bfb477b4df55,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-ba4dbe70-a2d2-4265-86de-0679f12a202a,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-bb09c8d6-36c4-44ee-b7e4-2544634f4acd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770360896-172.17.0.8-1597732021868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46860,DS-2978ca34-b507-4b4c-a027-9af184c22149,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-ed3eafe9-6af6-418c-926b-efe233382ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-718d4164-ea1c-4c06-90c7-1662971bc32e,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-a24079f2-9584-4016-89b8-c0c753f21852,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-2ad66891-b95c-48af-bd72-5b41a18264b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-94150558-d620-41cb-842d-bfb477b4df55,DISK], DatanodeInfoWithStorage[127.0.0.1:38808,DS-ba4dbe70-a2d2-4265-86de-0679f12a202a,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-bb09c8d6-36c4-44ee-b7e4-2544634f4acd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1200940479-172.17.0.8-1597732585062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36941,DS-d016c863-da2c-423c-b4b2-dbc9a2f0f625,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-d7e68792-db71-49a4-bd97-df9a96e4e15e,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-3732c274-86fc-4040-861c-6265dcbf502c,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-7e4de957-b85f-4018-87b4-66e59e0c6009,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-a6b9ade8-3fb2-46d6-9e89-c1fd4192c890,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-2b470c6c-2d5c-4cb6-b620-8801b7cfb352,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-9472c4ed-99cc-4c78-bf58-23f5af0a0087,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-5ef9d41a-a27b-49e3-ae13-81c1fe957c40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1200940479-172.17.0.8-1597732585062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36941,DS-d016c863-da2c-423c-b4b2-dbc9a2f0f625,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-d7e68792-db71-49a4-bd97-df9a96e4e15e,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-3732c274-86fc-4040-861c-6265dcbf502c,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-7e4de957-b85f-4018-87b4-66e59e0c6009,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-a6b9ade8-3fb2-46d6-9e89-c1fd4192c890,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-2b470c6c-2d5c-4cb6-b620-8801b7cfb352,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-9472c4ed-99cc-4c78-bf58-23f5af0a0087,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-5ef9d41a-a27b-49e3-ae13-81c1fe957c40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910674029-172.17.0.8-1597733275416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39856,DS-006f7b5d-d024-44c8-9dca-a3a2f486af7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45528,DS-1daac9b2-d2ba-4225-8d81-e31d93339859,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-ada09014-5fb6-4f56-9d36-9c09781cac76,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-7c948b0b-d8bf-4577-959c-929106b561ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-c4afa313-88d1-4986-a531-353c81ccd74c,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-06a8e2b6-f6f8-4fb6-a618-5da1f5407471,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-fd68932c-0ed1-4453-a0f2-60e0b6543f98,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-1eeec1c4-202c-49f7-bda2-0b94de60bcb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910674029-172.17.0.8-1597733275416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39856,DS-006f7b5d-d024-44c8-9dca-a3a2f486af7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45528,DS-1daac9b2-d2ba-4225-8d81-e31d93339859,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-ada09014-5fb6-4f56-9d36-9c09781cac76,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-7c948b0b-d8bf-4577-959c-929106b561ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-c4afa313-88d1-4986-a531-353c81ccd74c,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-06a8e2b6-f6f8-4fb6-a618-5da1f5407471,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-fd68932c-0ed1-4453-a0f2-60e0b6543f98,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-1eeec1c4-202c-49f7-bda2-0b94de60bcb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-773680152-172.17.0.8-1597733356494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39028,DS-ae182cc3-acfd-43fa-b6eb-a0e712b45796,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-6520e2ab-ac32-4288-a71c-7e409f7ce4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-284ab6cb-105f-4f0e-8b9e-d400ec3c6b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-2cfba99d-c4a7-4154-acb1-8e3ab6fbd254,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-4c5704c6-e14b-4c98-adf2-f6937eed3c71,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-d57774be-b8ea-43c8-8b85-772407eef110,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-c452c3dd-8a04-459b-93ba-dfd8074b6378,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-a3b529a1-dd0e-4a34-bf22-e019f9a2eb0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-773680152-172.17.0.8-1597733356494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39028,DS-ae182cc3-acfd-43fa-b6eb-a0e712b45796,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-6520e2ab-ac32-4288-a71c-7e409f7ce4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-284ab6cb-105f-4f0e-8b9e-d400ec3c6b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-2cfba99d-c4a7-4154-acb1-8e3ab6fbd254,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-4c5704c6-e14b-4c98-adf2-f6937eed3c71,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-d57774be-b8ea-43c8-8b85-772407eef110,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-c452c3dd-8a04-459b-93ba-dfd8074b6378,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-a3b529a1-dd0e-4a34-bf22-e019f9a2eb0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1968732001-172.17.0.8-1597733474464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34795,DS-fe3c0f9c-6039-4bd9-a520-d425d62e1991,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-e4e45b07-60d4-44f6-b284-d2fee21bb0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-64e62451-39e9-4e96-8e4a-1d4e1903b364,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-f20e6a48-f1e4-42bb-ae2c-089f61ede16b,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-c1f19630-8d6a-4c29-876d-9a4fae8a6054,DISK], DatanodeInfoWithStorage[127.0.0.1:42723,DS-b24587d9-d1e9-4c60-a2f4-4de8a5757fad,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-a6b834bc-e6f6-4634-8d49-caa42e00df75,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-c92e58cc-2a4a-45ff-b3da-f0fce1225512,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1968732001-172.17.0.8-1597733474464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34795,DS-fe3c0f9c-6039-4bd9-a520-d425d62e1991,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-e4e45b07-60d4-44f6-b284-d2fee21bb0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-64e62451-39e9-4e96-8e4a-1d4e1903b364,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-f20e6a48-f1e4-42bb-ae2c-089f61ede16b,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-c1f19630-8d6a-4c29-876d-9a4fae8a6054,DISK], DatanodeInfoWithStorage[127.0.0.1:42723,DS-b24587d9-d1e9-4c60-a2f4-4de8a5757fad,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-a6b834bc-e6f6-4634-8d49-caa42e00df75,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-c92e58cc-2a4a-45ff-b3da-f0fce1225512,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-863125292-172.17.0.8-1597733546960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34842,DS-faba6ca9-ea07-466c-908c-11f0408c4198,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-030a29f9-b62e-41a9-ba51-3ca45d9a743f,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-bacb51e4-36b0-4633-9284-962b1fd9b62c,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-3008c902-3f80-45bf-9a49-529cf46185ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-68516c96-dd83-4b32-9c45-333e13c7eed9,DISK], DatanodeInfoWithStorage[127.0.0.1:40834,DS-defac617-79c8-47b4-93b0-550df0ece942,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-6e8d25ed-f820-479c-8d19-80e8413b02f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-9dc91a69-cbcc-4142-9d6c-994ad7b3a2d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-863125292-172.17.0.8-1597733546960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34842,DS-faba6ca9-ea07-466c-908c-11f0408c4198,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-030a29f9-b62e-41a9-ba51-3ca45d9a743f,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-bacb51e4-36b0-4633-9284-962b1fd9b62c,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-3008c902-3f80-45bf-9a49-529cf46185ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-68516c96-dd83-4b32-9c45-333e13c7eed9,DISK], DatanodeInfoWithStorage[127.0.0.1:40834,DS-defac617-79c8-47b4-93b0-550df0ece942,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-6e8d25ed-f820-479c-8d19-80e8413b02f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-9dc91a69-cbcc-4142-9d6c-994ad7b3a2d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2129284645-172.17.0.8-1597733779415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35427,DS-3f89fdcf-5a24-49ca-80f0-ed79d007d0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-f42c01ca-868e-4a58-9b0d-307067f8f80a,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-7ab1f166-0852-419a-a34f-bde89564264e,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-8c0d831f-208f-490d-b3d6-031819b1b51d,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-3658f780-bdbb-47b3-9fd6-a484d0799e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-a20bc4a3-a14f-4365-8b95-c5c8eb71a21f,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-a372e72d-8f6b-41a8-bea2-7b0116979278,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-ba19452a-9a4b-4ecb-af02-76e20c973369,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2129284645-172.17.0.8-1597733779415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35427,DS-3f89fdcf-5a24-49ca-80f0-ed79d007d0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-f42c01ca-868e-4a58-9b0d-307067f8f80a,DISK], DatanodeInfoWithStorage[127.0.0.1:33591,DS-7ab1f166-0852-419a-a34f-bde89564264e,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-8c0d831f-208f-490d-b3d6-031819b1b51d,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-3658f780-bdbb-47b3-9fd6-a484d0799e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-a20bc4a3-a14f-4365-8b95-c5c8eb71a21f,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-a372e72d-8f6b-41a8-bea2-7b0116979278,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-ba19452a-9a4b-4ecb-af02-76e20c973369,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-57149371-172.17.0.8-1597733891833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39474,DS-1aea3379-bfc2-419d-94af-6e487d406a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-70652bec-efb9-4a63-96c0-58015edd0515,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-8f86041d-d2e4-4227-9369-0155475c52d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45202,DS-afd11e6f-3993-4b54-9bbf-7d4866794f86,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-7684f0e8-dc9d-4767-bf23-8746ad53fb78,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-b485c547-ebc6-4b27-8a7b-2beef7fc20c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-a0984555-a223-45ac-86ad-1b9f62919557,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-209ed1bb-6e1e-4a12-80c2-a66bb3bfa7d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-57149371-172.17.0.8-1597733891833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39474,DS-1aea3379-bfc2-419d-94af-6e487d406a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-70652bec-efb9-4a63-96c0-58015edd0515,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-8f86041d-d2e4-4227-9369-0155475c52d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45202,DS-afd11e6f-3993-4b54-9bbf-7d4866794f86,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-7684f0e8-dc9d-4767-bf23-8746ad53fb78,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-b485c547-ebc6-4b27-8a7b-2beef7fc20c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-a0984555-a223-45ac-86ad-1b9f62919557,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-209ed1bb-6e1e-4a12-80c2-a66bb3bfa7d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1696497537-172.17.0.8-1597734148212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38897,DS-a4f1cc0a-a7a7-411e-abe8-d6274475d725,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-918011b2-5414-460b-b0af-bfb51f9d290a,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-55beb715-2a3d-4126-9733-5c4ca1b1f26b,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-b2bd7116-adfc-478b-a2ef-039170a48c78,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-e5990966-f7e6-494c-a728-ad5937106834,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-02240754-c652-4502-85b1-f029d1b4d8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-d77772fd-f703-4d97-bc61-891f8191412c,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-43b0b96c-4dd8-46fd-a27d-c30e3ce2f57b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1696497537-172.17.0.8-1597734148212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38897,DS-a4f1cc0a-a7a7-411e-abe8-d6274475d725,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-918011b2-5414-460b-b0af-bfb51f9d290a,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-55beb715-2a3d-4126-9733-5c4ca1b1f26b,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-b2bd7116-adfc-478b-a2ef-039170a48c78,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-e5990966-f7e6-494c-a728-ad5937106834,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-02240754-c652-4502-85b1-f029d1b4d8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-d77772fd-f703-4d97-bc61-891f8191412c,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-43b0b96c-4dd8-46fd-a27d-c30e3ce2f57b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1635367343-172.17.0.8-1597734327090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34603,DS-412924b1-898c-47c0-ab3e-ee72404dcf3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-276ae3a0-4341-452d-a5d8-bb4001c97ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-be6e06a8-db70-4d59-ac59-ab504c4d6832,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-749b3957-1600-44b1-b091-13b98a928278,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-5d378539-7aca-4205-8313-6a59379487e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-0669b4e0-1f1a-4142-9ff1-9022661ed142,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-fc038f02-8dd8-49f8-b6d3-6353aac85c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-e52c7c15-0450-443d-a756-4177eaf9cf54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1635367343-172.17.0.8-1597734327090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34603,DS-412924b1-898c-47c0-ab3e-ee72404dcf3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-276ae3a0-4341-452d-a5d8-bb4001c97ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-be6e06a8-db70-4d59-ac59-ab504c4d6832,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-749b3957-1600-44b1-b091-13b98a928278,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-5d378539-7aca-4205-8313-6a59379487e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-0669b4e0-1f1a-4142-9ff1-9022661ed142,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-fc038f02-8dd8-49f8-b6d3-6353aac85c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-e52c7c15-0450-443d-a756-4177eaf9cf54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1821261513-172.17.0.8-1597734845581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46099,DS-7a226ab3-b251-4bf0-a572-229060b2e751,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-2fddc5b6-982f-4618-8dfe-d2f144251b65,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-cf3e4b53-d326-4980-a322-b79c78b61569,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-77869ec7-ba8d-40e7-a819-f64012b415e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-9fdaeddb-679a-4209-be7b-2fccb3f049d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-ef2270c2-8f4d-499d-9b1e-302ae68b54a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44749,DS-7f85860f-03f1-48b8-bc08-11456ef9ac94,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-35e65122-7803-43c2-b467-4759fde3b285,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1821261513-172.17.0.8-1597734845581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46099,DS-7a226ab3-b251-4bf0-a572-229060b2e751,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-2fddc5b6-982f-4618-8dfe-d2f144251b65,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-cf3e4b53-d326-4980-a322-b79c78b61569,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-77869ec7-ba8d-40e7-a819-f64012b415e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-9fdaeddb-679a-4209-be7b-2fccb3f049d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-ef2270c2-8f4d-499d-9b1e-302ae68b54a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44749,DS-7f85860f-03f1-48b8-bc08-11456ef9ac94,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-35e65122-7803-43c2-b467-4759fde3b285,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647265990-172.17.0.8-1597735457203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42860,DS-83507d22-7ea4-4115-b37f-5fd432b7b83f,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-14bb01c7-64be-4aea-9d5d-a24e5eb9c1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38318,DS-769cbf6c-ef51-45be-9fa9-60ff73fa26c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-5f3ed6f7-ceb5-40e5-b9b6-31e3d0d6c7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-c1990f54-0c83-427d-a285-23e2c327994f,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-9f4e4bd8-3955-4749-9aa8-ede560bf2763,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-7e1238df-963f-4c27-aad0-663e005baec3,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-ec5c4764-a855-4e97-9f47-c14f219fd10a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647265990-172.17.0.8-1597735457203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42860,DS-83507d22-7ea4-4115-b37f-5fd432b7b83f,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-14bb01c7-64be-4aea-9d5d-a24e5eb9c1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38318,DS-769cbf6c-ef51-45be-9fa9-60ff73fa26c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-5f3ed6f7-ceb5-40e5-b9b6-31e3d0d6c7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-c1990f54-0c83-427d-a285-23e2c327994f,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-9f4e4bd8-3955-4749-9aa8-ede560bf2763,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-7e1238df-963f-4c27-aad0-663e005baec3,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-ec5c4764-a855-4e97-9f47-c14f219fd10a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456472254-172.17.0.8-1597735693547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36168,DS-2569e0f6-d282-4a1b-8d6d-e334d5bdefef,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-da1cf450-045a-4251-8044-000438a3c3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-11610a3a-c948-426a-95db-b3f8dda73240,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-41a53920-21db-4230-9aa2-499293c05977,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-8ecc8452-96b3-4be5-9593-4d14a7c00cec,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-b017cdd4-f915-494b-8fda-87168ce4706c,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-48c02e1a-6293-434e-9608-dfa4eed40a67,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-3648c03b-0320-4a76-8f83-9b4eb0f8977a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456472254-172.17.0.8-1597735693547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36168,DS-2569e0f6-d282-4a1b-8d6d-e334d5bdefef,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-da1cf450-045a-4251-8044-000438a3c3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-11610a3a-c948-426a-95db-b3f8dda73240,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-41a53920-21db-4230-9aa2-499293c05977,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-8ecc8452-96b3-4be5-9593-4d14a7c00cec,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-b017cdd4-f915-494b-8fda-87168ce4706c,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-48c02e1a-6293-434e-9608-dfa4eed40a67,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-3648c03b-0320-4a76-8f83-9b4eb0f8977a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-844389012-172.17.0.8-1597735837058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35010,DS-794fdf3d-8d81-4644-b45a-035b3f2d71a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-dd241810-a5b7-4132-8a1f-39e33e39fd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-89155237-87e3-461b-b625-1d95b8c46b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-8e83fd57-47b4-463a-a7ce-758a2b54fe3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-f41346b3-d27b-40a9-8c82-fc4b6078bc22,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-d97c7d40-15fe-4c25-b42e-3b4fc65092e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-f783e692-8bfb-4141-ab0d-20d5fa4d6f71,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-ce6d4f7d-8a97-47fd-be90-a39b0e8228e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-844389012-172.17.0.8-1597735837058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35010,DS-794fdf3d-8d81-4644-b45a-035b3f2d71a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-dd241810-a5b7-4132-8a1f-39e33e39fd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-89155237-87e3-461b-b625-1d95b8c46b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-8e83fd57-47b4-463a-a7ce-758a2b54fe3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-f41346b3-d27b-40a9-8c82-fc4b6078bc22,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-d97c7d40-15fe-4c25-b42e-3b4fc65092e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-f783e692-8bfb-4141-ab0d-20d5fa4d6f71,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-ce6d4f7d-8a97-47fd-be90-a39b0e8228e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035868755-172.17.0.8-1597736268100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38987,DS-c861d401-4793-4eaa-a22a-2a682b64f86e,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-24045aa5-d837-4992-8edb-d5a72169b2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-6f061a06-030d-4bb5-b183-a3807dba2c46,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-42a1a45b-b836-43e5-b974-0160ff9550c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-5889a145-bd3c-4622-a0e8-6322cb6cc18b,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-176dd059-039c-426f-bfef-5999b7cdf8da,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-da035253-0ad1-45ac-bff9-5fb61392d533,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-4b6fc7b4-142a-4ae8-85b9-f17c2f7bc862,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035868755-172.17.0.8-1597736268100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38987,DS-c861d401-4793-4eaa-a22a-2a682b64f86e,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-24045aa5-d837-4992-8edb-d5a72169b2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-6f061a06-030d-4bb5-b183-a3807dba2c46,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-42a1a45b-b836-43e5-b974-0160ff9550c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-5889a145-bd3c-4622-a0e8-6322cb6cc18b,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-176dd059-039c-426f-bfef-5999b7cdf8da,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-da035253-0ad1-45ac-bff9-5fb61392d533,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-4b6fc7b4-142a-4ae8-85b9-f17c2f7bc862,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5730
