reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-101102748-172.17.0.16-1597675757948:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37700,DS-02fb5eec-f1dd-4ea9-a77d-fbbfa15128cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-bbe2815c-f949-4af7-88d7-5246b25052e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-6519a3e0-3c62-4d65-8042-e991867970f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-79b40570-a02b-4586-9a37-cce002231904,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-c8dd3689-5fc1-4812-969b-9008d4df5f08,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-6e4bb033-abc4-4792-9612-986ed8964502,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-e4bbdbb0-bf61-487f-8405-83c9fcafa236,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-bc0bf6d5-1c06-4de0-939b-a1927ced9704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-101102748-172.17.0.16-1597675757948:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37700,DS-02fb5eec-f1dd-4ea9-a77d-fbbfa15128cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-bbe2815c-f949-4af7-88d7-5246b25052e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-6519a3e0-3c62-4d65-8042-e991867970f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-79b40570-a02b-4586-9a37-cce002231904,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-c8dd3689-5fc1-4812-969b-9008d4df5f08,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-6e4bb033-abc4-4792-9612-986ed8964502,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-e4bbdbb0-bf61-487f-8405-83c9fcafa236,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-bc0bf6d5-1c06-4de0-939b-a1927ced9704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1321457731-172.17.0.16-1597675983667:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34645,DS-62f46d20-122d-4ca4-9acc-86c69de84556,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-c4951853-237b-4653-b191-74a8f678466b,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-b29b3c7c-d8c0-4abf-b9bb-224e003f1170,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-e4e23d66-b420-448a-a8ef-e7c195f1531b,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-51bf36fb-2b03-4171-804a-e90cb3072955,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-43078cb1-90ce-4304-911a-c8e0ff6a113c,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-99cdd82d-f7ce-4a93-b105-ac4108d84250,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-b7b699a6-9cf2-4860-a7a2-96fcfd140ce7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1321457731-172.17.0.16-1597675983667:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34645,DS-62f46d20-122d-4ca4-9acc-86c69de84556,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-c4951853-237b-4653-b191-74a8f678466b,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-b29b3c7c-d8c0-4abf-b9bb-224e003f1170,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-e4e23d66-b420-448a-a8ef-e7c195f1531b,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-51bf36fb-2b03-4171-804a-e90cb3072955,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-43078cb1-90ce-4304-911a-c8e0ff6a113c,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-99cdd82d-f7ce-4a93-b105-ac4108d84250,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-b7b699a6-9cf2-4860-a7a2-96fcfd140ce7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1736795219-172.17.0.16-1597676029364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41218,DS-bd2df32b-65db-41be-8db0-91af076c6e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-bb5a3aa9-c669-4abc-89a0-a9e77aaa1eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-9479f27b-d664-4835-91d4-6df294df5854,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-1ab4d04d-a84e-4366-b885-fd6b916c378a,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-81540302-4a37-4030-8888-b9902481215f,DISK], DatanodeInfoWithStorage[127.0.0.1:32977,DS-95a694ba-abdc-4a47-af56-3f9f62050db5,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-b70287c1-3a9d-475a-b5c6-9e149f906204,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-f4b50699-70fc-41a0-a408-6274c0efdfef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1736795219-172.17.0.16-1597676029364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41218,DS-bd2df32b-65db-41be-8db0-91af076c6e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-bb5a3aa9-c669-4abc-89a0-a9e77aaa1eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-9479f27b-d664-4835-91d4-6df294df5854,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-1ab4d04d-a84e-4366-b885-fd6b916c378a,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-81540302-4a37-4030-8888-b9902481215f,DISK], DatanodeInfoWithStorage[127.0.0.1:32977,DS-95a694ba-abdc-4a47-af56-3f9f62050db5,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-b70287c1-3a9d-475a-b5c6-9e149f906204,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-f4b50699-70fc-41a0-a408-6274c0efdfef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-465520920-172.17.0.16-1597676145398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43631,DS-f583187c-6765-4361-bef1-9fabdb4ea6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-6dc7c1a5-88fe-4956-8ad4-83dd8d16099b,DISK], DatanodeInfoWithStorage[127.0.0.1:45669,DS-66eb782d-00d5-4fbe-814e-09358db34a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-6b5e4596-5486-4179-8b51-f25261ec0cff,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-238f1fcd-5f29-4ff4-97b0-5a7d64a707b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-278e6044-8bc9-47fa-8e5f-50cc9aae84e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-1979522d-5c7d-44b9-a006-e2bb19908878,DISK], DatanodeInfoWithStorage[127.0.0.1:46082,DS-ccffffe0-9af2-4161-829c-65a2f5c07180,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-465520920-172.17.0.16-1597676145398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43631,DS-f583187c-6765-4361-bef1-9fabdb4ea6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-6dc7c1a5-88fe-4956-8ad4-83dd8d16099b,DISK], DatanodeInfoWithStorage[127.0.0.1:45669,DS-66eb782d-00d5-4fbe-814e-09358db34a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-6b5e4596-5486-4179-8b51-f25261ec0cff,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-238f1fcd-5f29-4ff4-97b0-5a7d64a707b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-278e6044-8bc9-47fa-8e5f-50cc9aae84e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-1979522d-5c7d-44b9-a006-e2bb19908878,DISK], DatanodeInfoWithStorage[127.0.0.1:46082,DS-ccffffe0-9af2-4161-829c-65a2f5c07180,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1773765382-172.17.0.16-1597676234077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33913,DS-ff33c958-d0d4-4d9b-9be7-e1eaf911f216,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-15c59079-553c-4b65-be43-6cc270cb9fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-f4062817-20d7-429a-af8d-d2b3cc35aa70,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-a7e4e449-3287-4636-a896-492b68d1c4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-7a824a8a-057d-4d00-9325-ebd2e009bd91,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-7037628b-87c4-435a-b771-0b026e3bb758,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-30a1b9a3-2a1f-48df-8556-ac9c8b289b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-999a3ff7-c5af-4697-8de8-0abb53ba31e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1773765382-172.17.0.16-1597676234077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33913,DS-ff33c958-d0d4-4d9b-9be7-e1eaf911f216,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-15c59079-553c-4b65-be43-6cc270cb9fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-f4062817-20d7-429a-af8d-d2b3cc35aa70,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-a7e4e449-3287-4636-a896-492b68d1c4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-7a824a8a-057d-4d00-9325-ebd2e009bd91,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-7037628b-87c4-435a-b771-0b026e3bb758,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-30a1b9a3-2a1f-48df-8556-ac9c8b289b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-999a3ff7-c5af-4697-8de8-0abb53ba31e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1033578846-172.17.0.16-1597679130721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34731,DS-9557c1ae-0f02-4205-a4fb-7174a60e5274,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-cc5a249e-09ce-43cb-8bf0-1b15e7e5c32f,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-e69b755a-c3f4-4acd-b681-eb5fe5516818,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-91be3925-bf60-4c47-b49b-aefd144c3db2,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-ff16213c-3373-4bc2-b2f5-5b19d9255fad,DISK], DatanodeInfoWithStorage[127.0.0.1:41733,DS-39b07cb9-d7f8-4ceb-8b63-b42908a7b526,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-7c3307ff-29b2-4c87-b3a0-ea581172d330,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-8cdd95ce-8494-4dfc-92ec-f1e6a01e52ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1033578846-172.17.0.16-1597679130721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34731,DS-9557c1ae-0f02-4205-a4fb-7174a60e5274,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-cc5a249e-09ce-43cb-8bf0-1b15e7e5c32f,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-e69b755a-c3f4-4acd-b681-eb5fe5516818,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-91be3925-bf60-4c47-b49b-aefd144c3db2,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-ff16213c-3373-4bc2-b2f5-5b19d9255fad,DISK], DatanodeInfoWithStorage[127.0.0.1:41733,DS-39b07cb9-d7f8-4ceb-8b63-b42908a7b526,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-7c3307ff-29b2-4c87-b3a0-ea581172d330,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-8cdd95ce-8494-4dfc-92ec-f1e6a01e52ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2102079181-172.17.0.16-1597679518423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40230,DS-a329421d-9d5b-4579-8c3e-53a62109c1de,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-f74eaaea-b2f4-4d74-9f4f-36307ec66922,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-0edaafb9-bb2c-495f-a253-b7ba2348f802,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-143153d7-3e90-4fed-885e-83462cd4f38d,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-faac23fb-8470-4c5c-bab2-b823f920a506,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-9dad2767-00a7-4627-9ade-2a4a1ce6e4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-c20d8e66-7ba1-4e0a-ab51-07a40d2cdeee,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-58830581-88d8-4cd5-a376-17fa041cb542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2102079181-172.17.0.16-1597679518423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40230,DS-a329421d-9d5b-4579-8c3e-53a62109c1de,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-f74eaaea-b2f4-4d74-9f4f-36307ec66922,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-0edaafb9-bb2c-495f-a253-b7ba2348f802,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-143153d7-3e90-4fed-885e-83462cd4f38d,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-faac23fb-8470-4c5c-bab2-b823f920a506,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-9dad2767-00a7-4627-9ade-2a4a1ce6e4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-c20d8e66-7ba1-4e0a-ab51-07a40d2cdeee,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-58830581-88d8-4cd5-a376-17fa041cb542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1168329099-172.17.0.16-1597679559781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40598,DS-3581f60b-87d0-46b1-9abe-1b44f2491e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-7e6247c7-e53b-4c7c-8e61-1d52645894b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-83233d6f-2433-49af-80c7-14146c208ece,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-22b5df57-4869-4320-9a5d-53e657bc99f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-2dca51d3-1c11-4a9e-aa66-555f7f5340d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-3bf9609c-751e-4613-bf7b-caa59f301579,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-83665638-aad7-4fe1-85cb-8ba7e5c77d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-e6c94a05-66b0-46fc-adba-d28a1cbca77a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1168329099-172.17.0.16-1597679559781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40598,DS-3581f60b-87d0-46b1-9abe-1b44f2491e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-7e6247c7-e53b-4c7c-8e61-1d52645894b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-83233d6f-2433-49af-80c7-14146c208ece,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-22b5df57-4869-4320-9a5d-53e657bc99f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-2dca51d3-1c11-4a9e-aa66-555f7f5340d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-3bf9609c-751e-4613-bf7b-caa59f301579,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-83665638-aad7-4fe1-85cb-8ba7e5c77d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-e6c94a05-66b0-46fc-adba-d28a1cbca77a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1526950714-172.17.0.16-1597679600482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43929,DS-e591a10e-58a9-4321-9c19-bcca0ad3a1df,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-e6d7cce4-0eef-4468-9e83-277f6c55a280,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-316b4260-6d7d-4657-b810-cd7752a13fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-73f59b42-0804-4d60-be41-0334ec235ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-73f4f301-993e-4023-972e-244ebf53b22a,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-ccd81255-d5a3-4db1-8d18-0ce07bdf7e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-9a63436b-d9fd-448a-b246-c9f06560bc39,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-aa10bbf3-e71f-414f-8ecc-13bf972c1ca1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1526950714-172.17.0.16-1597679600482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43929,DS-e591a10e-58a9-4321-9c19-bcca0ad3a1df,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-e6d7cce4-0eef-4468-9e83-277f6c55a280,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-316b4260-6d7d-4657-b810-cd7752a13fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-73f59b42-0804-4d60-be41-0334ec235ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-73f4f301-993e-4023-972e-244ebf53b22a,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-ccd81255-d5a3-4db1-8d18-0ce07bdf7e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-9a63436b-d9fd-448a-b246-c9f06560bc39,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-aa10bbf3-e71f-414f-8ecc-13bf972c1ca1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1306470939-172.17.0.16-1597679646249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40015,DS-2f0c7e26-15ec-4ac8-ab1e-350e88466c81,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-69696e54-650c-4a65-80ef-7f5c3a530d57,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-fdcb12b7-4fc6-4e74-a163-20db2421869a,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-6f667ea5-ed4b-43d6-96c8-20d7df1d078f,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-e8634deb-9014-4cc7-9250-771d14f67683,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-08bf16ac-6f34-4b6d-ad89-cf128941444e,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-98b9d8f1-1e37-49df-a020-0616b74ecbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-f5da6f2e-281d-4d99-b72b-c7443621b8b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1306470939-172.17.0.16-1597679646249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40015,DS-2f0c7e26-15ec-4ac8-ab1e-350e88466c81,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-69696e54-650c-4a65-80ef-7f5c3a530d57,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-fdcb12b7-4fc6-4e74-a163-20db2421869a,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-6f667ea5-ed4b-43d6-96c8-20d7df1d078f,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-e8634deb-9014-4cc7-9250-771d14f67683,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-08bf16ac-6f34-4b6d-ad89-cf128941444e,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-98b9d8f1-1e37-49df-a020-0616b74ecbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-f5da6f2e-281d-4d99-b72b-c7443621b8b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-467085770-172.17.0.16-1597680213139:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45258,DS-f9274657-c80c-49fb-a963-713bef03907f,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-db8c0fb8-d6f7-43ec-b9f5-e3a434bd90b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-5513085c-b9a7-4e30-afcc-20fd967ef359,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-e9629c50-9d46-465b-8c84-dfdf1a232798,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-ef972b1a-1adb-4532-8a87-34b89056e047,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-3aa4c9c8-44c5-462c-b3d7-8968feb4a9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-5ce5e443-689c-4742-b09f-73b56f11e895,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-d8e2b512-92ae-455b-bb63-79fdbdd7db36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-467085770-172.17.0.16-1597680213139:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45258,DS-f9274657-c80c-49fb-a963-713bef03907f,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-db8c0fb8-d6f7-43ec-b9f5-e3a434bd90b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-5513085c-b9a7-4e30-afcc-20fd967ef359,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-e9629c50-9d46-465b-8c84-dfdf1a232798,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-ef972b1a-1adb-4532-8a87-34b89056e047,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-3aa4c9c8-44c5-462c-b3d7-8968feb4a9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-5ce5e443-689c-4742-b09f-73b56f11e895,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-d8e2b512-92ae-455b-bb63-79fdbdd7db36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-273046523-172.17.0.16-1597680312499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34423,DS-9e4de2d9-e2a3-4f0c-92ca-9538a1ba4b93,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-867b3a90-04d2-4f9d-8b5f-de15cba7c1af,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-d9f71298-2a65-470b-a0bd-d1148c96c030,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-d9fb7ad4-81ee-4846-8409-ee449b7ee40f,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-a3c6f7c4-41d6-4b2e-95a2-ef4df3d69290,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-aac3c646-296f-4d85-bb7e-f9fe2d41ce5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-307e2ccf-dc81-4413-ad68-0ee24d9f2e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-d2197aa2-0a8b-48c6-8f54-841c0635fb94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-273046523-172.17.0.16-1597680312499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34423,DS-9e4de2d9-e2a3-4f0c-92ca-9538a1ba4b93,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-867b3a90-04d2-4f9d-8b5f-de15cba7c1af,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-d9f71298-2a65-470b-a0bd-d1148c96c030,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-d9fb7ad4-81ee-4846-8409-ee449b7ee40f,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-a3c6f7c4-41d6-4b2e-95a2-ef4df3d69290,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-aac3c646-296f-4d85-bb7e-f9fe2d41ce5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-307e2ccf-dc81-4413-ad68-0ee24d9f2e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-d2197aa2-0a8b-48c6-8f54-841c0635fb94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2103409670-172.17.0.16-1597680634377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35034,DS-76bcc306-6eab-40ec-b948-0f3af446dbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-6461b3c0-6651-45d4-bf2c-5bbb268b7124,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-fa6fbce3-c167-4032-8782-6dce70ace863,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-a8009e57-c6f5-4815-bf84-815e854aa673,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-62e56afb-18b3-4ac2-9d82-49ff0d249c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-09f8168b-2286-4bac-a788-9bf8e82eca99,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-f666fa80-4802-4d04-a39b-da7b3324fbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-f08e255f-790d-4e2e-b262-7dcbe356f842,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2103409670-172.17.0.16-1597680634377:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35034,DS-76bcc306-6eab-40ec-b948-0f3af446dbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-6461b3c0-6651-45d4-bf2c-5bbb268b7124,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-fa6fbce3-c167-4032-8782-6dce70ace863,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-a8009e57-c6f5-4815-bf84-815e854aa673,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-62e56afb-18b3-4ac2-9d82-49ff0d249c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-09f8168b-2286-4bac-a788-9bf8e82eca99,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-f666fa80-4802-4d04-a39b-da7b3324fbfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-f08e255f-790d-4e2e-b262-7dcbe356f842,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1269178069-172.17.0.16-1597680920583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40784,DS-63d9b07f-fceb-41d3-b8d4-0fc206ae7505,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-ed5cadf8-82ab-4c2a-a5b6-6e2fd9cf145b,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-10263370-cc01-4e37-802f-f4dfc890d80e,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-2b6ac1d8-b57d-4f38-90d7-5c27cae15820,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-e34d6bbe-dc4e-483f-9e8a-6a312c2b1c88,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-78642c1d-c586-43d9-909b-53a0841d4cad,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-ae1267e1-f9fe-48f2-bd81-4c043394dbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-34b13616-1d71-4aee-8ad1-db34b422ab26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1269178069-172.17.0.16-1597680920583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40784,DS-63d9b07f-fceb-41d3-b8d4-0fc206ae7505,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-ed5cadf8-82ab-4c2a-a5b6-6e2fd9cf145b,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-10263370-cc01-4e37-802f-f4dfc890d80e,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-2b6ac1d8-b57d-4f38-90d7-5c27cae15820,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-e34d6bbe-dc4e-483f-9e8a-6a312c2b1c88,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-78642c1d-c586-43d9-909b-53a0841d4cad,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-ae1267e1-f9fe-48f2-bd81-4c043394dbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-34b13616-1d71-4aee-8ad1-db34b422ab26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-807626837-172.17.0.16-1597681345276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46800,DS-216a71cc-7440-4ae0-a6c9-bacb6ba93af0,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-900f13cb-897b-4746-8980-afb9af6fad34,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-159c0614-e1ab-4955-a9b7-cf60a558da06,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-bb06ab42-1ef0-4fbe-8361-aae4f3a8a8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-b5a93e33-21bf-4f7a-b638-388becd3b88d,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-9752b14a-ef17-4c17-987b-c82531b27075,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-c26a1502-0ab1-4f98-8c8d-d8b183941060,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-da2c8cf4-207a-4be1-b9ea-2382c511c0df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-807626837-172.17.0.16-1597681345276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46800,DS-216a71cc-7440-4ae0-a6c9-bacb6ba93af0,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-900f13cb-897b-4746-8980-afb9af6fad34,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-159c0614-e1ab-4955-a9b7-cf60a558da06,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-bb06ab42-1ef0-4fbe-8361-aae4f3a8a8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-b5a93e33-21bf-4f7a-b638-388becd3b88d,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-9752b14a-ef17-4c17-987b-c82531b27075,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-c26a1502-0ab1-4f98-8c8d-d8b183941060,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-da2c8cf4-207a-4be1-b9ea-2382c511c0df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.exclude.nodes.cache.expiry.interval.millis
component: hdfs:NameNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1106019188-172.17.0.16-1597681596536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37678,DS-a4307f39-515d-4c09-96c1-1b0ca14ab97c,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-4d4a5231-c42c-469c-b7f5-c9cbc1e532fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-ef5b9fe1-e2c5-41f4-926f-fb6f8ddf8fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-70419182-1ddf-47c4-9925-4fe90fffcd60,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-25a27504-352f-4d9a-b0ee-035a2f17ec28,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-73a40f7c-2bbc-4ad6-83be-49fbb10b6562,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-83496d07-7c28-4ff4-997a-2aabe6aee269,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-052377ec-ea3a-4626-a7f2-a0bfa0c21c78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1106019188-172.17.0.16-1597681596536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37678,DS-a4307f39-515d-4c09-96c1-1b0ca14ab97c,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-4d4a5231-c42c-469c-b7f5-c9cbc1e532fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-ef5b9fe1-e2c5-41f4-926f-fb6f8ddf8fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-70419182-1ddf-47c4-9925-4fe90fffcd60,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-25a27504-352f-4d9a-b0ee-035a2f17ec28,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-73a40f7c-2bbc-4ad6-83be-49fbb10b6562,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-83496d07-7c28-4ff4-997a-2aabe6aee269,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-052377ec-ea3a-4626-a7f2-a0bfa0c21c78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 7162
