reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1289720851-172.17.0.14-1597646402298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40355,DS-9d6be588-40cc-4016-b1e7-dc41f0a8bce0,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-3a4cfe28-2a3e-4288-b039-0099341f57ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-c05f54ee-7a55-48fb-bb49-f54ba6b2e8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-0a7c6480-f2af-4c92-9841-746c8c27ddd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-7d11ec03-3a57-432c-92b0-0ca9f2d57448,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-a8eb3652-7a5c-4843-9585-91a62cb0d3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-2e178938-3890-4ea3-9277-c0ec4efbc132,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-aec8e896-1454-4aeb-8fca-d66a8905ab5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1289720851-172.17.0.14-1597646402298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40355,DS-9d6be588-40cc-4016-b1e7-dc41f0a8bce0,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-3a4cfe28-2a3e-4288-b039-0099341f57ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-c05f54ee-7a55-48fb-bb49-f54ba6b2e8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-0a7c6480-f2af-4c92-9841-746c8c27ddd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-7d11ec03-3a57-432c-92b0-0ca9f2d57448,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-a8eb3652-7a5c-4843-9585-91a62cb0d3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-2e178938-3890-4ea3-9277-c0ec4efbc132,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-aec8e896-1454-4aeb-8fca-d66a8905ab5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2063454683-172.17.0.14-1597646547540:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39649,DS-4fb2955e-1683-43fc-be7a-bf8f98136750,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-eaea78dc-159d-44cc-af33-78abbc25b01a,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-ed0b95fb-3153-4d6d-9fd9-eba09ab24125,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-d19edd9b-7efd-4af3-af76-317e87fd9864,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-702f81ea-36b0-40db-8897-2831db4b2afd,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-9d70acb2-2dd4-4564-8a95-6b8d678317a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-accdfe75-f050-476a-8a51-2be4f6a7b38d,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-bda067ba-84e1-4b33-a234-c60e9c6e0c02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2063454683-172.17.0.14-1597646547540:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39649,DS-4fb2955e-1683-43fc-be7a-bf8f98136750,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-eaea78dc-159d-44cc-af33-78abbc25b01a,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-ed0b95fb-3153-4d6d-9fd9-eba09ab24125,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-d19edd9b-7efd-4af3-af76-317e87fd9864,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-702f81ea-36b0-40db-8897-2831db4b2afd,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-9d70acb2-2dd4-4564-8a95-6b8d678317a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-accdfe75-f050-476a-8a51-2be4f6a7b38d,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-bda067ba-84e1-4b33-a234-c60e9c6e0c02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1116529816-172.17.0.14-1597646885991:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33844,DS-0bf7682b-b260-4696-a4e6-e10d8794f929,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-34920544-1d59-407f-bb96-d9e09f132ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-f8bca791-0737-461c-9505-c28e3128730c,DISK], DatanodeInfoWithStorage[127.0.0.1:45749,DS-b9a006e3-778a-4b7e-8821-0c836778b61c,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-40b875e2-b077-4fe2-bbaf-bc47cfaab8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-4c4a70ec-2515-4823-b071-dffad7c4dda3,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-14969640-fbe1-4d0d-9c47-33021193631d,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-52c5c3b5-9bd4-476e-bfe6-fd5a0eaee158,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1116529816-172.17.0.14-1597646885991:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33844,DS-0bf7682b-b260-4696-a4e6-e10d8794f929,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-34920544-1d59-407f-bb96-d9e09f132ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-f8bca791-0737-461c-9505-c28e3128730c,DISK], DatanodeInfoWithStorage[127.0.0.1:45749,DS-b9a006e3-778a-4b7e-8821-0c836778b61c,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-40b875e2-b077-4fe2-bbaf-bc47cfaab8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-4c4a70ec-2515-4823-b071-dffad7c4dda3,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-14969640-fbe1-4d0d-9c47-33021193631d,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-52c5c3b5-9bd4-476e-bfe6-fd5a0eaee158,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1437563948-172.17.0.14-1597647381832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44916,DS-b02382b5-de62-48ca-9ee5-b3388b6e30bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-1c69275a-b37b-4e86-ab8a-e5eaa1c74465,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-20cbf5b4-2d63-422e-b369-81cd21d2ea92,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-8aa44e5d-8871-4da1-b8fc-8d1ff86d5268,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-d0cfff03-75d0-4f86-8421-8305a35c245b,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-583edc8c-2fc0-4c33-b5ad-6fa2f4ac28aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-ca5d994b-14df-4873-9ae1-3bc9893d3440,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-ef4b76ca-ee7c-4606-9d16-ba8af42e2095,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1437563948-172.17.0.14-1597647381832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44916,DS-b02382b5-de62-48ca-9ee5-b3388b6e30bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-1c69275a-b37b-4e86-ab8a-e5eaa1c74465,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-20cbf5b4-2d63-422e-b369-81cd21d2ea92,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-8aa44e5d-8871-4da1-b8fc-8d1ff86d5268,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-d0cfff03-75d0-4f86-8421-8305a35c245b,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-583edc8c-2fc0-4c33-b5ad-6fa2f4ac28aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-ca5d994b-14df-4873-9ae1-3bc9893d3440,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-ef4b76ca-ee7c-4606-9d16-ba8af42e2095,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1439739644-172.17.0.14-1597647486166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32944,DS-89b7896b-a32a-45e9-8799-fc7a48c79178,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-b7fb04f1-66ef-4ac3-b67a-2dc95bd1075b,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-7d883530-61ce-4af6-8818-ed7b6cc267f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-14072739-5653-41bf-a3af-dcb2fc326e57,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-cb613d12-d091-4815-a9c0-121c638073f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-166af819-8203-4fdb-a56c-9d04549339b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-074ca2e8-84a0-45ea-b7d4-8430f38908e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-c4a9aa9a-59d7-4ccb-93df-d0251e850b32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1439739644-172.17.0.14-1597647486166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32944,DS-89b7896b-a32a-45e9-8799-fc7a48c79178,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-b7fb04f1-66ef-4ac3-b67a-2dc95bd1075b,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-7d883530-61ce-4af6-8818-ed7b6cc267f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-14072739-5653-41bf-a3af-dcb2fc326e57,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-cb613d12-d091-4815-a9c0-121c638073f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-166af819-8203-4fdb-a56c-9d04549339b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-074ca2e8-84a0-45ea-b7d4-8430f38908e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-c4a9aa9a-59d7-4ccb-93df-d0251e850b32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-26652584-172.17.0.14-1597647523755:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46238,DS-599efcd2-d6f0-4901-8fc0-01a774f7ab5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-4b5c34cb-4d6c-47e3-8497-85555144dc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-7a285f81-59bd-48b6-961f-2ed1d56fa60d,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-b37f17a2-4f5c-4524-a521-0e6d2604c744,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-f97cadb7-30bf-4261-ad43-a5c410558222,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-e7e97a72-8829-4750-aa05-81428d1b7dde,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-9eb50a6f-4296-4b67-9cc2-89f307a7c60d,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-603fbed8-da81-46bd-8421-2e67fb0d2702,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-26652584-172.17.0.14-1597647523755:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46238,DS-599efcd2-d6f0-4901-8fc0-01a774f7ab5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-4b5c34cb-4d6c-47e3-8497-85555144dc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-7a285f81-59bd-48b6-961f-2ed1d56fa60d,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-b37f17a2-4f5c-4524-a521-0e6d2604c744,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-f97cadb7-30bf-4261-ad43-a5c410558222,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-e7e97a72-8829-4750-aa05-81428d1b7dde,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-9eb50a6f-4296-4b67-9cc2-89f307a7c60d,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-603fbed8-da81-46bd-8421-2e67fb0d2702,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2091109780-172.17.0.14-1597647843257:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39072,DS-ca36e1cc-2057-4d5c-9558-70617ef0646a,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-94d70d18-9237-448d-a057-5b4a7e79e738,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-8c0714eb-b56d-4dd5-acd1-0338923899fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37703,DS-aafbd986-3c9a-4c10-b9bc-605f5d9a2cae,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-d78531cb-45b8-4efb-a5ac-211db027d68f,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-ab43e65c-1e97-4f8f-86c1-3cc7df932718,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-13656e17-3d51-4f7a-ab2a-eb039f3487fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-40096408-d99d-4223-85df-2b7c5b533828,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2091109780-172.17.0.14-1597647843257:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39072,DS-ca36e1cc-2057-4d5c-9558-70617ef0646a,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-94d70d18-9237-448d-a057-5b4a7e79e738,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-8c0714eb-b56d-4dd5-acd1-0338923899fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37703,DS-aafbd986-3c9a-4c10-b9bc-605f5d9a2cae,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-d78531cb-45b8-4efb-a5ac-211db027d68f,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-ab43e65c-1e97-4f8f-86c1-3cc7df932718,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-13656e17-3d51-4f7a-ab2a-eb039f3487fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-40096408-d99d-4223-85df-2b7c5b533828,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1869878081-172.17.0.14-1597647880055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43796,DS-30c5a6dd-2095-4755-8ddc-630762ee87af,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-a3e83efc-f06d-46f6-8518-6fc131095c62,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-4755b394-0f79-4440-811d-7fbaf5933649,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-f3053506-3b23-4ad7-9999-8cd2e1845ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-e67918c5-3bbf-451a-8af9-6b5f860b4afa,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-bd4d256d-4865-4ad9-aefb-c50f53a5f76f,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-7e8bd674-83e3-4019-a59c-86e51097b14d,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-543f28d9-62d9-47a0-9732-0e421f3099b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1869878081-172.17.0.14-1597647880055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43796,DS-30c5a6dd-2095-4755-8ddc-630762ee87af,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-a3e83efc-f06d-46f6-8518-6fc131095c62,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-4755b394-0f79-4440-811d-7fbaf5933649,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-f3053506-3b23-4ad7-9999-8cd2e1845ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-e67918c5-3bbf-451a-8af9-6b5f860b4afa,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-bd4d256d-4865-4ad9-aefb-c50f53a5f76f,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-7e8bd674-83e3-4019-a59c-86e51097b14d,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-543f28d9-62d9-47a0-9732-0e421f3099b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-731142891-172.17.0.14-1597647919800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44512,DS-dbde6a80-c671-4d38-8ffc-63bc7be5fb77,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-e68441f0-677e-4fb2-b0c9-1f58b83cfaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-12af7b8f-f079-4e15-966d-191ab06ff8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-2466025e-8bb8-441a-8709-6aad0fd06690,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-b956a2ca-2e7f-4e70-a447-2f2a173a6c05,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-ef5c93bf-8bef-40ea-977e-9e6868e8d03e,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-538fdd2b-f83a-4aaf-b174-f3e0d3151a93,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-0e5ad6b9-3de0-45e0-b990-bea31584195c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-731142891-172.17.0.14-1597647919800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44512,DS-dbde6a80-c671-4d38-8ffc-63bc7be5fb77,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-e68441f0-677e-4fb2-b0c9-1f58b83cfaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-12af7b8f-f079-4e15-966d-191ab06ff8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-2466025e-8bb8-441a-8709-6aad0fd06690,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-b956a2ca-2e7f-4e70-a447-2f2a173a6c05,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-ef5c93bf-8bef-40ea-977e-9e6868e8d03e,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-538fdd2b-f83a-4aaf-b174-f3e0d3151a93,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-0e5ad6b9-3de0-45e0-b990-bea31584195c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1290675501-172.17.0.14-1597648299801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45320,DS-f4ca60a5-c358-4bf1-9714-18a5b44600d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-d23880ee-c212-438e-ac3a-0cc36015de14,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-050f49f0-989e-4917-a8e9-b2ad9781c66c,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-6119056d-4301-4895-a59f-53a057715720,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-4c711a4f-4cc5-4e1f-855e-c69ff512ee58,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-dcbb9143-2a70-41ee-ba00-fe0641e9cdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-34d23369-b782-4ad2-bc94-dcc393a699e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-5158ff87-a01e-4bf9-8824-6f4c44240b88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1290675501-172.17.0.14-1597648299801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45320,DS-f4ca60a5-c358-4bf1-9714-18a5b44600d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-d23880ee-c212-438e-ac3a-0cc36015de14,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-050f49f0-989e-4917-a8e9-b2ad9781c66c,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-6119056d-4301-4895-a59f-53a057715720,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-4c711a4f-4cc5-4e1f-855e-c69ff512ee58,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-dcbb9143-2a70-41ee-ba00-fe0641e9cdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-34d23369-b782-4ad2-bc94-dcc393a699e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-5158ff87-a01e-4bf9-8824-6f4c44240b88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1634957743-172.17.0.14-1597649098393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33710,DS-2b819c01-7579-4946-b6ce-0ab48b657670,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-b03d8d16-843b-4466-8236-b27608aff451,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-15b80868-b3aa-4d74-8535-46628f7f0384,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-44cdc48e-6dfe-4c7d-aaad-034e9d767941,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-1ccd4529-627d-405f-b11e-c721513b7b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-09e3943f-2ab3-423b-8f5e-6a7e58b4e018,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-d6ba6ca6-89ea-4417-a4b0-9a9c12aad521,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-8081acd8-6d45-475c-aa52-d77271ab3862,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1634957743-172.17.0.14-1597649098393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33710,DS-2b819c01-7579-4946-b6ce-0ab48b657670,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-b03d8d16-843b-4466-8236-b27608aff451,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-15b80868-b3aa-4d74-8535-46628f7f0384,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-44cdc48e-6dfe-4c7d-aaad-034e9d767941,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-1ccd4529-627d-405f-b11e-c721513b7b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-09e3943f-2ab3-423b-8f5e-6a7e58b4e018,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-d6ba6ca6-89ea-4417-a4b0-9a9c12aad521,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-8081acd8-6d45-475c-aa52-d77271ab3862,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1706113252-172.17.0.14-1597649547166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43609,DS-0b9f1a51-e22d-48ad-811a-8f20446f087a,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-87d58db9-8f62-40ec-b011-933eae223f07,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-c5a8300a-67e1-4b23-b593-99aacf5f72cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-dd35b947-5efa-47fa-b7c4-81ec30c27130,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-e2826964-63b1-484f-80fc-e66d9b2a7f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-ce13578c-2a48-467c-977b-56ae9122a97f,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-4daca694-03e6-4c70-aa7b-2e1dba8b684a,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-7ac8e213-9089-4c88-865b-765c101dfd15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1706113252-172.17.0.14-1597649547166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43609,DS-0b9f1a51-e22d-48ad-811a-8f20446f087a,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-87d58db9-8f62-40ec-b011-933eae223f07,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-c5a8300a-67e1-4b23-b593-99aacf5f72cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-dd35b947-5efa-47fa-b7c4-81ec30c27130,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-e2826964-63b1-484f-80fc-e66d9b2a7f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-ce13578c-2a48-467c-977b-56ae9122a97f,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-4daca694-03e6-4c70-aa7b-2e1dba8b684a,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-7ac8e213-9089-4c88-865b-765c101dfd15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-538437799-172.17.0.14-1597649923041:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34394,DS-1a9a974b-155a-4945-85fc-de119c274636,DISK], DatanodeInfoWithStorage[127.0.0.1:44663,DS-56d0210b-06b9-4d30-9183-5a6b6d08d254,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-2c730b25-091d-4b53-a1b2-dcfc4e85ed18,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-ad8e868a-4709-48a7-a4e0-4bf57a543cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-f87aa22d-6c61-4da9-bc74-09f72af6fd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-b4fbe9ab-6757-44a2-92cd-02210929103a,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-e8c6f6da-52ea-434d-b8d0-32997197456b,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-da380ebb-5fac-4258-b62d-c27e6b69afac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-538437799-172.17.0.14-1597649923041:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34394,DS-1a9a974b-155a-4945-85fc-de119c274636,DISK], DatanodeInfoWithStorage[127.0.0.1:44663,DS-56d0210b-06b9-4d30-9183-5a6b6d08d254,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-2c730b25-091d-4b53-a1b2-dcfc4e85ed18,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-ad8e868a-4709-48a7-a4e0-4bf57a543cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-f87aa22d-6c61-4da9-bc74-09f72af6fd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-b4fbe9ab-6757-44a2-92cd-02210929103a,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-e8c6f6da-52ea-434d-b8d0-32997197456b,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-da380ebb-5fac-4258-b62d-c27e6b69afac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2115281903-172.17.0.14-1597650495227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46331,DS-89777c23-ab37-46b8-9202-0bba9c33e7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-dbf072df-ad67-4237-881a-969c3ebf4c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-20c944e8-9b1b-42ef-bd14-1200d4c710d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-e7d3b1ce-08f5-40b7-859d-ed73a76daac4,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-03f61fb2-f32c-404b-8e78-ed523bad724a,DISK], DatanodeInfoWithStorage[127.0.0.1:34447,DS-d9e63079-63f4-4d4e-b7c4-4dd97e9e9b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-7a0f2d33-1887-4a3b-a93c-138c3d816034,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-96531962-0ec1-4e64-bc93-c42019af0f30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2115281903-172.17.0.14-1597650495227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46331,DS-89777c23-ab37-46b8-9202-0bba9c33e7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-dbf072df-ad67-4237-881a-969c3ebf4c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-20c944e8-9b1b-42ef-bd14-1200d4c710d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-e7d3b1ce-08f5-40b7-859d-ed73a76daac4,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-03f61fb2-f32c-404b-8e78-ed523bad724a,DISK], DatanodeInfoWithStorage[127.0.0.1:34447,DS-d9e63079-63f4-4d4e-b7c4-4dd97e9e9b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-7a0f2d33-1887-4a3b-a93c-138c3d816034,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-96531962-0ec1-4e64-bc93-c42019af0f30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1826939973-172.17.0.14-1597650790787:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38928,DS-db42ecfd-c723-4490-84b3-7e9c81e64c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-81b7ec37-05f4-43e6-a769-bbda4a3e4300,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-37a8cc39-bfca-4fc9-b52e-0c9bbaafbcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-7bd43799-0816-4f20-84e8-6d8fb901cc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-55a6b1d7-33b7-4a96-81f9-b163be9c6b00,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-ffa18cd1-c6fc-4c28-b837-26b8efd1c581,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-a76209b1-e012-41c7-ada1-78d13277f6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-ffe3c120-9d83-463a-80db-7bfe916d9f86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1826939973-172.17.0.14-1597650790787:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38928,DS-db42ecfd-c723-4490-84b3-7e9c81e64c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-81b7ec37-05f4-43e6-a769-bbda4a3e4300,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-37a8cc39-bfca-4fc9-b52e-0c9bbaafbcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-7bd43799-0816-4f20-84e8-6d8fb901cc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-55a6b1d7-33b7-4a96-81f9-b163be9c6b00,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-ffa18cd1-c6fc-4c28-b837-26b8efd1c581,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-a76209b1-e012-41c7-ada1-78d13277f6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-ffe3c120-9d83-463a-80db-7bfe916d9f86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-840896604-172.17.0.14-1597650980185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38899,DS-8947cfce-f3b7-49c3-94d2-0dcdb0d173e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-f4a2dd7e-583f-49d5-a5e7-f93307a0c16e,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-7aede0ac-8fc6-4306-84c4-704de68677f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-bedc5de6-d8ab-4c1d-a427-2c13e3bbb990,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-d80aaa5e-a4e7-4376-ba6c-d20f40d1ec91,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-c913c4c0-a705-44f5-aa66-89eb9ef6bbef,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-9eaa8094-b31b-461e-9f0b-6d243dd4bd70,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-411baa78-0552-4481-a412-40202120bf68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-840896604-172.17.0.14-1597650980185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38899,DS-8947cfce-f3b7-49c3-94d2-0dcdb0d173e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-f4a2dd7e-583f-49d5-a5e7-f93307a0c16e,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-7aede0ac-8fc6-4306-84c4-704de68677f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-bedc5de6-d8ab-4c1d-a427-2c13e3bbb990,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-d80aaa5e-a4e7-4376-ba6c-d20f40d1ec91,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-c913c4c0-a705-44f5-aa66-89eb9ef6bbef,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-9eaa8094-b31b-461e-9f0b-6d243dd4bd70,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-411baa78-0552-4481-a412-40202120bf68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 268435456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1435701407-172.17.0.14-1597651704674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33278,DS-69ae1b93-3b05-47a2-a071-95a2bef8d25b,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-388a1c8f-1e41-4434-bd35-9bbfd2c164ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-d465c4a6-48b9-4aeb-800e-fb4fd46ea8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-72b3e3d6-88a2-4b3b-9bee-81796a020a17,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-56e4246d-ab53-4c92-9fe8-6230c1e67922,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-77e556d3-196b-4b4a-996c-71e2128d3e16,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-f5d17c02-228d-499e-bb8c-cee218ef8ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-3f1c3630-e36f-4b73-a80b-d067b9c2ea61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1435701407-172.17.0.14-1597651704674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33278,DS-69ae1b93-3b05-47a2-a071-95a2bef8d25b,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-388a1c8f-1e41-4434-bd35-9bbfd2c164ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-d465c4a6-48b9-4aeb-800e-fb4fd46ea8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-72b3e3d6-88a2-4b3b-9bee-81796a020a17,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-56e4246d-ab53-4c92-9fe8-6230c1e67922,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-77e556d3-196b-4b4a-996c-71e2128d3e16,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-f5d17c02-228d-499e-bb8c-cee218ef8ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-3f1c3630-e36f-4b73-a80b-d067b9c2ea61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5423
