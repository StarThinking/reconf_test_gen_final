reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1965958989-172.17.0.17-1597289235553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46369,DS-08047320-480b-442a-9b7f-eb88fbcc95bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-f0cdf904-88f9-4ab6-8ee9-150ee622ff90,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-395779b9-1240-4158-848d-f8ba661398bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-9577bf5d-6673-4719-a7a5-1a6c906d02a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-c4fef236-5fd2-493b-889b-f11d22c2c057,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-b24dd4df-94ae-44ad-a7ee-dd06ad429c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-b7742fa4-a7e9-47bf-a0fa-a09531df8bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-97044bc9-c35c-4c05-b151-94c8a9ec68ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1965958989-172.17.0.17-1597289235553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46369,DS-08047320-480b-442a-9b7f-eb88fbcc95bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-f0cdf904-88f9-4ab6-8ee9-150ee622ff90,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-395779b9-1240-4158-848d-f8ba661398bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-9577bf5d-6673-4719-a7a5-1a6c906d02a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-c4fef236-5fd2-493b-889b-f11d22c2c057,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-b24dd4df-94ae-44ad-a7ee-dd06ad429c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-b7742fa4-a7e9-47bf-a0fa-a09531df8bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-97044bc9-c35c-4c05-b151-94c8a9ec68ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1514745798-172.17.0.17-1597289313790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45971,DS-ad6301d7-c73e-43c9-b3e6-f0956f9bbc15,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-7df6c0f4-b9d0-40e1-8437-0a774b03d55d,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-6c2d2453-106a-47a6-82a6-920206218124,DISK], DatanodeInfoWithStorage[127.0.0.1:33492,DS-5737e3cd-e1b1-4604-8cfd-c87cbb348c34,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-81da6b3c-a2de-45eb-b6d9-66ed477c515a,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-e12a67c7-0231-489b-a85c-8f388b1f0c02,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-ad7ef930-da73-443a-b59c-7c1e9e13aca3,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-8aaebc4b-1348-4a3d-b5dd-bda65d750b07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1514745798-172.17.0.17-1597289313790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45971,DS-ad6301d7-c73e-43c9-b3e6-f0956f9bbc15,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-7df6c0f4-b9d0-40e1-8437-0a774b03d55d,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-6c2d2453-106a-47a6-82a6-920206218124,DISK], DatanodeInfoWithStorage[127.0.0.1:33492,DS-5737e3cd-e1b1-4604-8cfd-c87cbb348c34,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-81da6b3c-a2de-45eb-b6d9-66ed477c515a,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-e12a67c7-0231-489b-a85c-8f388b1f0c02,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-ad7ef930-da73-443a-b59c-7c1e9e13aca3,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-8aaebc4b-1348-4a3d-b5dd-bda65d750b07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664363595-172.17.0.17-1597289461397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40472,DS-e3d37d66-f73f-4aac-a5bf-812a9e59628e,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-deacc7bc-2c08-4c88-a839-778adf0d9bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-dfda821b-9859-4c6f-8fff-b9b3af48cdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-37cd3b29-0e40-4eba-bec3-c4740077514e,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-d2ffc4f5-b08a-415e-99db-47c7d5ac31df,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-7dcd7648-23bb-4df9-bca4-b242a0a6457d,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-c976ca25-0fef-451a-9020-e40ac2149bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-999b2576-8b4a-4ec0-a50b-18d0fa8db9c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664363595-172.17.0.17-1597289461397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40472,DS-e3d37d66-f73f-4aac-a5bf-812a9e59628e,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-deacc7bc-2c08-4c88-a839-778adf0d9bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-dfda821b-9859-4c6f-8fff-b9b3af48cdfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-37cd3b29-0e40-4eba-bec3-c4740077514e,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-d2ffc4f5-b08a-415e-99db-47c7d5ac31df,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-7dcd7648-23bb-4df9-bca4-b242a0a6457d,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-c976ca25-0fef-451a-9020-e40ac2149bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-999b2576-8b4a-4ec0-a50b-18d0fa8db9c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1682888413-172.17.0.17-1597289593108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34552,DS-199b8c62-56f1-4e05-8cb0-ade4cb97f1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-b8e0459d-f92c-4396-bc60-8a082580013e,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-74d4516a-813d-402d-825b-4bea28708cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-d09e7dbb-1e0c-4649-8dcf-5bf1f3251ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-af6a2b41-bb27-4959-8089-49044215f7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-63de2ad4-8da6-4264-a7e9-3408811fd3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-796fb080-d523-4d0f-8984-70abe6638904,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-15e26f7b-34b0-410a-a6d5-fa7c92fe79d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1682888413-172.17.0.17-1597289593108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34552,DS-199b8c62-56f1-4e05-8cb0-ade4cb97f1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-b8e0459d-f92c-4396-bc60-8a082580013e,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-74d4516a-813d-402d-825b-4bea28708cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-d09e7dbb-1e0c-4649-8dcf-5bf1f3251ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-af6a2b41-bb27-4959-8089-49044215f7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-63de2ad4-8da6-4264-a7e9-3408811fd3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-796fb080-d523-4d0f-8984-70abe6638904,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-15e26f7b-34b0-410a-a6d5-fa7c92fe79d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-564377670-172.17.0.17-1597290564727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35651,DS-e97d48e9-e3d7-43ff-964c-d18dbacd672c,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-75588679-9e46-4900-8540-063ea8996b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-57f8ebc0-61cc-4fee-bdd8-694a9b12ddd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-9d7716ea-1add-423f-a64d-ab3d647efccf,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-3db6c220-70c3-4093-807f-0d94bf27efa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-035b83fc-828e-477f-96b4-dcb9c11354d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-ce00635a-85b5-41c3-8524-ebdd2464390f,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-509e2d0a-4ec0-4ba0-9916-1f4824b5a663,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-564377670-172.17.0.17-1597290564727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35651,DS-e97d48e9-e3d7-43ff-964c-d18dbacd672c,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-75588679-9e46-4900-8540-063ea8996b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-57f8ebc0-61cc-4fee-bdd8-694a9b12ddd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-9d7716ea-1add-423f-a64d-ab3d647efccf,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-3db6c220-70c3-4093-807f-0d94bf27efa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-035b83fc-828e-477f-96b4-dcb9c11354d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-ce00635a-85b5-41c3-8524-ebdd2464390f,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-509e2d0a-4ec0-4ba0-9916-1f4824b5a663,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553598129-172.17.0.17-1597290984011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38627,DS-f68f42a3-a661-422f-ae25-d253f6fb5918,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-243b5b2b-0afc-4f96-9f82-92771fc7cdd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-cf327973-ada5-4a7f-9039-30e358746040,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-346963e4-107a-4b9f-81fd-2bf46685fa92,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-7c802a9a-80c9-4f9d-be16-db85bf07d793,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-22d14338-5a9e-48e9-8102-74bba9946868,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-976c9a36-79e1-4b6c-b0dc-823eebaf26a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-6841159f-507e-4925-8094-e7f1faf27279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553598129-172.17.0.17-1597290984011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38627,DS-f68f42a3-a661-422f-ae25-d253f6fb5918,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-243b5b2b-0afc-4f96-9f82-92771fc7cdd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-cf327973-ada5-4a7f-9039-30e358746040,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-346963e4-107a-4b9f-81fd-2bf46685fa92,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-7c802a9a-80c9-4f9d-be16-db85bf07d793,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-22d14338-5a9e-48e9-8102-74bba9946868,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-976c9a36-79e1-4b6c-b0dc-823eebaf26a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-6841159f-507e-4925-8094-e7f1faf27279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1650494212-172.17.0.17-1597291249303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37832,DS-f5d4dbed-2bb1-416e-b4c2-8f0d9344ef88,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-7881601a-e931-42e5-afd0-4bab55e3d607,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-b35a8938-ea74-4094-ae7e-3bede3a14751,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-03f77d46-c7ef-419c-aeba-befc272851e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-8c0b5fb6-37b2-4dc0-b808-16d7404ec55b,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-42ef7202-94c6-4df9-9896-2b084700d432,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-f07ac6ab-456f-409f-ac7d-64adbbea084d,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-febb1b64-288f-437f-b6c9-209ee818af53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1650494212-172.17.0.17-1597291249303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37832,DS-f5d4dbed-2bb1-416e-b4c2-8f0d9344ef88,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-7881601a-e931-42e5-afd0-4bab55e3d607,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-b35a8938-ea74-4094-ae7e-3bede3a14751,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-03f77d46-c7ef-419c-aeba-befc272851e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-8c0b5fb6-37b2-4dc0-b808-16d7404ec55b,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-42ef7202-94c6-4df9-9896-2b084700d432,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-f07ac6ab-456f-409f-ac7d-64adbbea084d,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-febb1b64-288f-437f-b6c9-209ee818af53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-68518132-172.17.0.17-1597291394932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45477,DS-f1383b89-d478-4ea5-b3f1-8dfc6f6c5375,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-e55c00ba-5234-4a71-b634-9197332dcedd,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-1e21fb87-b4f3-486f-bdf1-c5bd2c366322,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-746c083a-3629-4b93-a9b0-28ecf57c5bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-451f5d25-c464-4aa1-8820-cb33acf6d04d,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-f737dddd-1ede-469f-97af-f4c9e352e240,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-f3f2ef9c-f7fd-4e0e-97b9-89550d6e6f56,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-d433119e-0c9b-468b-af07-4c31d8d0de25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-68518132-172.17.0.17-1597291394932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45477,DS-f1383b89-d478-4ea5-b3f1-8dfc6f6c5375,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-e55c00ba-5234-4a71-b634-9197332dcedd,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-1e21fb87-b4f3-486f-bdf1-c5bd2c366322,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-746c083a-3629-4b93-a9b0-28ecf57c5bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-451f5d25-c464-4aa1-8820-cb33acf6d04d,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-f737dddd-1ede-469f-97af-f4c9e352e240,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-f3f2ef9c-f7fd-4e0e-97b9-89550d6e6f56,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-d433119e-0c9b-468b-af07-4c31d8d0de25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950932439-172.17.0.17-1597292051854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45935,DS-ebfd9d9e-b5ea-4c01-9bbc-d4ab0d84dcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-21fc6d7a-a0a2-401a-8cee-c3ab776e6f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-8e717399-23db-455e-86c4-2ba0d4d41636,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-cbb72daa-2f4b-47f5-94a2-0a80a5f9e5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-20d3dc6c-7b1b-451d-be98-5da0562cc977,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-c7d80285-c83f-423f-891f-2dc9e43801a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-6c678412-6614-4874-b333-5c0132a9c127,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-0be0a8ea-4d1b-49e9-9c38-139a3aef4187,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950932439-172.17.0.17-1597292051854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45935,DS-ebfd9d9e-b5ea-4c01-9bbc-d4ab0d84dcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-21fc6d7a-a0a2-401a-8cee-c3ab776e6f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-8e717399-23db-455e-86c4-2ba0d4d41636,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-cbb72daa-2f4b-47f5-94a2-0a80a5f9e5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-20d3dc6c-7b1b-451d-be98-5da0562cc977,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-c7d80285-c83f-423f-891f-2dc9e43801a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-6c678412-6614-4874-b333-5c0132a9c127,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-0be0a8ea-4d1b-49e9-9c38-139a3aef4187,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1192121627-172.17.0.17-1597292336640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33222,DS-8e1293c3-6822-42fe-8742-07df8d7263ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-2167dbbf-fe38-4de0-a6c9-90691c2abb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-7837e2f6-6119-4d41-b422-de2d61c09daa,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-ec5803ce-81d8-420a-9f54-33764876250c,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-e36114a1-5349-4765-bd37-e5c8a2f331b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-b90ea099-e629-4268-a7c1-8fc5c5c4aaea,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-2c6d36d6-a77d-49c3-a74c-94a0d09047bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-e0944ff5-628d-4148-9b52-9e1f6f1a6f62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1192121627-172.17.0.17-1597292336640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33222,DS-8e1293c3-6822-42fe-8742-07df8d7263ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-2167dbbf-fe38-4de0-a6c9-90691c2abb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-7837e2f6-6119-4d41-b422-de2d61c09daa,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-ec5803ce-81d8-420a-9f54-33764876250c,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-e36114a1-5349-4765-bd37-e5c8a2f331b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-b90ea099-e629-4268-a7c1-8fc5c5c4aaea,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-2c6d36d6-a77d-49c3-a74c-94a0d09047bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-e0944ff5-628d-4148-9b52-9e1f6f1a6f62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1956629049-172.17.0.17-1597292375889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42110,DS-bc438a51-29ae-4272-aa3e-ff6fdb64a44f,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-7681702d-6b87-40b1-894d-937da6c4b723,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-8ce8b1f1-ca27-4781-ac99-966a7394c2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-2b9746c6-8ee0-4c9b-b965-a3ce229aa8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-0b4e170e-0d82-4d48-9377-31e24c410e45,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-92ac18b9-28b6-4de7-82bb-87e06c2c5efc,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-1c45e248-46da-4547-9a4e-2a05097a2676,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-bb635333-bec6-46b2-9f09-dea00d1c20ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1956629049-172.17.0.17-1597292375889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42110,DS-bc438a51-29ae-4272-aa3e-ff6fdb64a44f,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-7681702d-6b87-40b1-894d-937da6c4b723,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-8ce8b1f1-ca27-4781-ac99-966a7394c2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-2b9746c6-8ee0-4c9b-b965-a3ce229aa8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-0b4e170e-0d82-4d48-9377-31e24c410e45,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-92ac18b9-28b6-4de7-82bb-87e06c2c5efc,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-1c45e248-46da-4547-9a4e-2a05097a2676,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-bb635333-bec6-46b2-9f09-dea00d1c20ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-239821164-172.17.0.17-1597292453467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45254,DS-3afbb48b-040c-4533-9c9e-7d0291a77a42,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-fba958d2-ad46-4fce-8955-764b3df35f67,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-288d789d-e75e-459a-b8cc-51d0155ec499,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-f626c5a1-fba5-4032-80c9-68d7548e2414,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-de753de0-6169-4ca8-a95d-6af7b93a47f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-9e9e25df-74b9-4e20-a6e0-1dc326db8c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36529,DS-53639df8-dc3b-4913-be04-af10da5aac02,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-6c4dc715-e6b0-406f-b0f6-ee8a9071ef87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-239821164-172.17.0.17-1597292453467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45254,DS-3afbb48b-040c-4533-9c9e-7d0291a77a42,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-fba958d2-ad46-4fce-8955-764b3df35f67,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-288d789d-e75e-459a-b8cc-51d0155ec499,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-f626c5a1-fba5-4032-80c9-68d7548e2414,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-de753de0-6169-4ca8-a95d-6af7b93a47f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-9e9e25df-74b9-4e20-a6e0-1dc326db8c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36529,DS-53639df8-dc3b-4913-be04-af10da5aac02,DISK], DatanodeInfoWithStorage[127.0.0.1:33773,DS-6c4dc715-e6b0-406f-b0f6-ee8a9071ef87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-170538409-172.17.0.17-1597292874327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39214,DS-f97ca33c-093e-4ea4-b3db-0a6c3b85ebc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-67cbd889-1623-4b6b-849b-824ed9560bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-460ef3a0-1030-4439-b2c1-f6d83de3f461,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-3a74416b-ad96-4820-9cda-a00ad1bde6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-63a60e34-80a3-4fb3-b42b-1ec49001f622,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-f4127666-c2b2-4a47-b019-de8af7654729,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-7892b47d-9a5a-48a6-932f-05c044358869,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-acb64966-09a4-467a-ba33-0f23822f8630,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-170538409-172.17.0.17-1597292874327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39214,DS-f97ca33c-093e-4ea4-b3db-0a6c3b85ebc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-67cbd889-1623-4b6b-849b-824ed9560bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-460ef3a0-1030-4439-b2c1-f6d83de3f461,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-3a74416b-ad96-4820-9cda-a00ad1bde6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-63a60e34-80a3-4fb3-b42b-1ec49001f622,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-f4127666-c2b2-4a47-b019-de8af7654729,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-7892b47d-9a5a-48a6-932f-05c044358869,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-acb64966-09a4-467a-ba33-0f23822f8630,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1266657921-172.17.0.17-1597293062704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42842,DS-49960385-5f24-4a7f-a5fb-1251579ead39,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-7f1b7c78-264c-489c-9ebc-8e73fc677c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-0227dd8b-7b2b-4c58-b119-c1822cb37d39,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-8e0c41d0-4afd-473a-80f5-14d2ee728773,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-83d4724d-45ed-48c9-95a8-9b83a3892ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-610bda91-511f-4cd3-a037-3a1fb15a5dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-51efcbad-57ac-4724-91f4-6f5b8f11d0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-3a11f879-dd0a-40d6-a76f-d345a699fa32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1266657921-172.17.0.17-1597293062704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42842,DS-49960385-5f24-4a7f-a5fb-1251579ead39,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-7f1b7c78-264c-489c-9ebc-8e73fc677c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-0227dd8b-7b2b-4c58-b119-c1822cb37d39,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-8e0c41d0-4afd-473a-80f5-14d2ee728773,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-83d4724d-45ed-48c9-95a8-9b83a3892ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-610bda91-511f-4cd3-a037-3a1fb15a5dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-51efcbad-57ac-4724-91f4-6f5b8f11d0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-3a11f879-dd0a-40d6-a76f-d345a699fa32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-485754792-172.17.0.17-1597293098609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36225,DS-2f991976-cd11-4356-ae89-89ce64965f48,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-e5dac912-194c-44f7-8499-ae23a495700b,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-72125848-58d9-4ee0-b732-c7430e8afd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-fa229b37-d526-48da-bb6d-8b52e013bb53,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-793a55ed-a93b-4a92-a5ce-2f6edadfdebd,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-64246f5a-d100-43bb-81fd-26d30cdf099d,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-0f9386fb-6d7e-4f7f-8b16-51964a4d72b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-cff93661-adba-4d00-86b5-edd7bd7bb2ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-485754792-172.17.0.17-1597293098609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36225,DS-2f991976-cd11-4356-ae89-89ce64965f48,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-e5dac912-194c-44f7-8499-ae23a495700b,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-72125848-58d9-4ee0-b732-c7430e8afd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-fa229b37-d526-48da-bb6d-8b52e013bb53,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-793a55ed-a93b-4a92-a5ce-2f6edadfdebd,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-64246f5a-d100-43bb-81fd-26d30cdf099d,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-0f9386fb-6d7e-4f7f-8b16-51964a4d72b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-cff93661-adba-4d00-86b5-edd7bd7bb2ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-201485484-172.17.0.17-1597293334713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35218,DS-f5ab5405-849d-41c6-b5f1-a188a3f6aebf,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-049d5ac3-e666-414e-a8ab-4e4f4786dbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-fc157872-fce6-40a2-a9b5-3eabfa2b7af2,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-e8d62178-da96-4c99-8f9d-895e01c503c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46820,DS-1236a7d7-8e5b-4d6f-a31a-49b504ee4fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-8f909ede-5078-4a08-92e4-94ce1656bca4,DISK], DatanodeInfoWithStorage[127.0.0.1:41796,DS-10cd1a71-5638-43e6-9cc2-1a310b72d91b,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-bbb6d7f6-43fb-41c6-a454-519d943df8bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-201485484-172.17.0.17-1597293334713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35218,DS-f5ab5405-849d-41c6-b5f1-a188a3f6aebf,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-049d5ac3-e666-414e-a8ab-4e4f4786dbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-fc157872-fce6-40a2-a9b5-3eabfa2b7af2,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-e8d62178-da96-4c99-8f9d-895e01c503c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46820,DS-1236a7d7-8e5b-4d6f-a31a-49b504ee4fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-8f909ede-5078-4a08-92e4-94ce1656bca4,DISK], DatanodeInfoWithStorage[127.0.0.1:41796,DS-10cd1a71-5638-43e6-9cc2-1a310b72d91b,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-bbb6d7f6-43fb-41c6-a454-519d943df8bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410963354-172.17.0.17-1597293416339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32927,DS-5f559415-e981-4828-b23e-3eb9fa0e3716,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-56d25f2e-c5ac-4c82-832e-51ebf7ea4f12,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-ec794518-2419-4ce3-ad84-2d55d96dda10,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-2cac4d74-dec0-43d8-bc48-8e572bcdff19,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-98cb5e91-fd55-4aab-af70-a92a7a260f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-009b53a6-c840-41a4-a5cf-84921b40eb12,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-019b22f3-1db7-48d1-a31e-b214a1031d31,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-b4d753ac-8ed5-400f-a2d7-af53301bc6da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-410963354-172.17.0.17-1597293416339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32927,DS-5f559415-e981-4828-b23e-3eb9fa0e3716,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-56d25f2e-c5ac-4c82-832e-51ebf7ea4f12,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-ec794518-2419-4ce3-ad84-2d55d96dda10,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-2cac4d74-dec0-43d8-bc48-8e572bcdff19,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-98cb5e91-fd55-4aab-af70-a92a7a260f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-009b53a6-c840-41a4-a5cf-84921b40eb12,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-019b22f3-1db7-48d1-a31e-b214a1031d31,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-b4d753ac-8ed5-400f-a2d7-af53301bc6da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1447847355-172.17.0.17-1597293573224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40157,DS-f2355342-5301-4ced-9669-4a35776559a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-bdde13a5-c148-45a4-8c23-ac218cff4a27,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-7c577f63-eff9-4509-a794-2a1e1a35a2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-6bd541ad-dc99-46ec-a1be-3cc536ded339,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-237cf809-467a-4610-b655-54e34bb0d256,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-7fef67b8-fdd3-41ec-a4af-2de7f22f3c41,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-b6e34621-a317-40d8-9744-85b1b73dff67,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-7c2e298c-2d02-4d00-b516-d53765faade6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1447847355-172.17.0.17-1597293573224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40157,DS-f2355342-5301-4ced-9669-4a35776559a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-bdde13a5-c148-45a4-8c23-ac218cff4a27,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-7c577f63-eff9-4509-a794-2a1e1a35a2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-6bd541ad-dc99-46ec-a1be-3cc536ded339,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-237cf809-467a-4610-b655-54e34bb0d256,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-7fef67b8-fdd3-41ec-a4af-2de7f22f3c41,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-b6e34621-a317-40d8-9744-85b1b73dff67,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-7c2e298c-2d02-4d00-b516-d53765faade6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-203107558-172.17.0.17-1597294032553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44186,DS-cf853ad5-b452-4b44-92eb-0c2e2351bb76,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-bcb429dd-e4c5-41ad-83f9-aff12d734cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-161e7cfd-ab87-4833-aeb8-741596d4b612,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-1d60205e-8d10-450f-bf83-937bd2bb7228,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-6d9cf80e-58cd-4b95-bcb4-d98dccb316c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-6480adb8-cd82-43cc-834c-674af6228356,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-a52185c4-33ab-407d-a52b-7239de356891,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-d20a4fce-6360-42a3-9431-ea176e6dc352,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-203107558-172.17.0.17-1597294032553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44186,DS-cf853ad5-b452-4b44-92eb-0c2e2351bb76,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-bcb429dd-e4c5-41ad-83f9-aff12d734cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-161e7cfd-ab87-4833-aeb8-741596d4b612,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-1d60205e-8d10-450f-bf83-937bd2bb7228,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-6d9cf80e-58cd-4b95-bcb4-d98dccb316c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-6480adb8-cd82-43cc-834c-674af6228356,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-a52185c4-33ab-407d-a52b-7239de356891,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-d20a4fce-6360-42a3-9431-ea176e6dc352,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144019506-172.17.0.17-1597294137855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41516,DS-8b8e3ff9-cab8-4e58-bd73-e4416aca4ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-ec92b9bd-cf7c-4eb8-8150-b00ce25c7dda,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-b3cd19c6-1216-43e0-923c-2ca42e11ad23,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-a85875bc-4d71-49ba-b135-cd160e5a41b3,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-f8367d13-f382-4803-b910-bc7ea0fb5896,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-2b0cc04d-91f7-4787-a806-c73ca5172b86,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-69a630c6-d211-4adb-983c-064e4ff0d1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-e1cc3e5e-b244-45cd-8775-9fce494d76c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144019506-172.17.0.17-1597294137855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41516,DS-8b8e3ff9-cab8-4e58-bd73-e4416aca4ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-ec92b9bd-cf7c-4eb8-8150-b00ce25c7dda,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-b3cd19c6-1216-43e0-923c-2ca42e11ad23,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-a85875bc-4d71-49ba-b135-cd160e5a41b3,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-f8367d13-f382-4803-b910-bc7ea0fb5896,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-2b0cc04d-91f7-4787-a806-c73ca5172b86,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-69a630c6-d211-4adb-983c-064e4ff0d1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-e1cc3e5e-b244-45cd-8775-9fce494d76c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1766404516-172.17.0.17-1597294292739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37353,DS-b21586e2-4aa3-4a20-887f-9e9da4cfccd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-af192f26-a58a-4510-9fe1-e8af9c07e51b,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-8acbc625-6053-4fa3-a488-a1a327cbe8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-0220e315-50e5-4b0c-8294-6f0639214dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-79453a42-464b-4734-9ba7-a89ac2106f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-54edc022-b37b-4c0c-b831-e8e1ccfb7e75,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-75b18a52-d79b-48e6-a0e5-8116b4e5aa72,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-04f5a09f-495f-4f80-bcf9-5067f07cb65d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1766404516-172.17.0.17-1597294292739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37353,DS-b21586e2-4aa3-4a20-887f-9e9da4cfccd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-af192f26-a58a-4510-9fe1-e8af9c07e51b,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-8acbc625-6053-4fa3-a488-a1a327cbe8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-0220e315-50e5-4b0c-8294-6f0639214dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-79453a42-464b-4734-9ba7-a89ac2106f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-54edc022-b37b-4c0c-b831-e8e1ccfb7e75,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-75b18a52-d79b-48e6-a0e5-8116b4e5aa72,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-04f5a09f-495f-4f80-bcf9-5067f07cb65d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825057808-172.17.0.17-1597294666914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44645,DS-7f34ed5d-2a2d-4a2f-a6a8-eb9de983ba9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-b096e1b1-46b6-4b39-a8e7-0c493792ab1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-d92500e1-be7a-4c43-9ee9-8b0970dad9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-b4c34d5e-f0d7-4478-9c9a-a55280a5de14,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-f353fd22-67e1-46b0-b3e7-eb92566ccf57,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-180a63ec-1bcb-4d1a-a7e4-0c2911c73878,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-c7f3aff2-4cbd-47ed-ab58-764b05c669ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-e2f2fad1-0c53-4556-bb61-ebc477571ba5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825057808-172.17.0.17-1597294666914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44645,DS-7f34ed5d-2a2d-4a2f-a6a8-eb9de983ba9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-b096e1b1-46b6-4b39-a8e7-0c493792ab1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-d92500e1-be7a-4c43-9ee9-8b0970dad9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-b4c34d5e-f0d7-4478-9c9a-a55280a5de14,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-f353fd22-67e1-46b0-b3e7-eb92566ccf57,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-180a63ec-1bcb-4d1a-a7e4-0c2911c73878,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-c7f3aff2-4cbd-47ed-ab58-764b05c669ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-e2f2fad1-0c53-4556-bb61-ebc477571ba5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1500787646-172.17.0.17-1597294744481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42937,DS-c3de8cc0-d057-4dce-9a75-155d6ca449b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-233ea651-6fc3-46d5-8fc0-e2969f223e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-b3180da7-e04f-4c52-a3b9-79057a41e95c,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-02f84745-a3ed-45c7-8f6d-de4b7c64f0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-33373881-a637-44b3-baae-b3ae89a264f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-05fbe4e6-c01a-404d-a7d1-7780650541fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-92602d37-cb12-4588-bb96-30a1f62a2dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-497d5949-6fb5-4ee0-bd93-990a2b509245,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1500787646-172.17.0.17-1597294744481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42937,DS-c3de8cc0-d057-4dce-9a75-155d6ca449b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-233ea651-6fc3-46d5-8fc0-e2969f223e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-b3180da7-e04f-4c52-a3b9-79057a41e95c,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-02f84745-a3ed-45c7-8f6d-de4b7c64f0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-33373881-a637-44b3-baae-b3ae89a264f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-05fbe4e6-c01a-404d-a7d1-7780650541fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-92602d37-cb12-4588-bb96-30a1f62a2dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-497d5949-6fb5-4ee0-bd93-990a2b509245,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5666
