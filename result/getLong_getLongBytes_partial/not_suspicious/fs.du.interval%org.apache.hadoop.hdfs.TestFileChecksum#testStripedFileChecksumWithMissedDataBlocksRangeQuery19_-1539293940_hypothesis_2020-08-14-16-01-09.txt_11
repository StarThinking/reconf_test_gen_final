reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-668048438-172.17.0.19-1597421360972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40682,DS-0cd0da33-dd36-4421-9d64-7dc417059a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-fc76c0d1-407c-4c4f-a266-635f79f56647,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-fa9a59b0-bc54-4660-8c0c-9a154574435f,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-745a0cd1-6330-4e00-b30b-131b5722cba3,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-6095bd6e-d3b6-4666-b16c-63933cb0b00d,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-5c9414b3-ea6f-48ab-a697-e88a663abd99,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-13d65626-c110-4a89-a9fe-1e7de1919fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-6cd96371-fd58-44fc-ad81-aa633cffa1d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-668048438-172.17.0.19-1597421360972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40682,DS-0cd0da33-dd36-4421-9d64-7dc417059a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-fc76c0d1-407c-4c4f-a266-635f79f56647,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-fa9a59b0-bc54-4660-8c0c-9a154574435f,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-745a0cd1-6330-4e00-b30b-131b5722cba3,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-6095bd6e-d3b6-4666-b16c-63933cb0b00d,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-5c9414b3-ea6f-48ab-a697-e88a663abd99,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-13d65626-c110-4a89-a9fe-1e7de1919fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-6cd96371-fd58-44fc-ad81-aa633cffa1d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1284287183-172.17.0.19-1597421521185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44097,DS-ef1bac7c-4fbf-4927-9ca4-f9d513a79351,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-fdbff43b-5b22-462e-bf73-66c1a871bb15,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-4452fea1-2e66-49d9-afb4-b9b7750afefc,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-4be0f597-3741-4329-8564-c2a05b90b537,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-f023c2dd-d193-49be-929d-bf824d57b85d,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-e844b9cb-e2a1-4b45-a7ea-6a569abf3689,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-d49ca763-97d9-4f00-8c99-a72fabeb4fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-63481498-1b37-4e35-a342-ebff349aaa13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1284287183-172.17.0.19-1597421521185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44097,DS-ef1bac7c-4fbf-4927-9ca4-f9d513a79351,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-fdbff43b-5b22-462e-bf73-66c1a871bb15,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-4452fea1-2e66-49d9-afb4-b9b7750afefc,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-4be0f597-3741-4329-8564-c2a05b90b537,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-f023c2dd-d193-49be-929d-bf824d57b85d,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-e844b9cb-e2a1-4b45-a7ea-6a569abf3689,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-d49ca763-97d9-4f00-8c99-a72fabeb4fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-63481498-1b37-4e35-a342-ebff349aaa13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1393385996-172.17.0.19-1597421622350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32970,DS-316edf88-3428-4d14-b0d0-604390e9d220,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-9adb9c8f-a81f-4a33-8d35-f20cdd597d62,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-955b0bc0-e70b-4301-a231-a7d6ef638b40,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-fa198fd8-be56-41b2-8790-70931bbce106,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-cfe5925a-dbb3-4ea7-a5a3-84033ab566a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-f38be627-e9fc-40e4-ae0b-be33152cca42,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-9b1133fc-7a2b-4506-a2ff-ffc2894c8a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-b374c50f-1ba6-4c0c-8cc7-301267a4279f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1393385996-172.17.0.19-1597421622350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32970,DS-316edf88-3428-4d14-b0d0-604390e9d220,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-9adb9c8f-a81f-4a33-8d35-f20cdd597d62,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-955b0bc0-e70b-4301-a231-a7d6ef638b40,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-fa198fd8-be56-41b2-8790-70931bbce106,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-cfe5925a-dbb3-4ea7-a5a3-84033ab566a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-f38be627-e9fc-40e4-ae0b-be33152cca42,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-9b1133fc-7a2b-4506-a2ff-ffc2894c8a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-b374c50f-1ba6-4c0c-8cc7-301267a4279f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2143931004-172.17.0.19-1597422059780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41099,DS-fc96e98a-eefb-49f0-9869-8bb7dcd77ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-0ce8d50c-ffb8-4176-b5d7-7c1d67b03d80,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-7ab4d914-6b54-496a-aed6-f23efe176256,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-1a9fb17d-6870-4f45-b139-5ad0b728e7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-0ea3210d-cd9b-4d30-b75a-8f936f99c7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-b1c4b905-88a7-430c-846a-3f28a1c4a0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-6004d64b-2bd4-4f7e-be58-be080373d513,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-45828d9c-920c-446b-aa5b-c43f7072cdac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2143931004-172.17.0.19-1597422059780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41099,DS-fc96e98a-eefb-49f0-9869-8bb7dcd77ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-0ce8d50c-ffb8-4176-b5d7-7c1d67b03d80,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-7ab4d914-6b54-496a-aed6-f23efe176256,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-1a9fb17d-6870-4f45-b139-5ad0b728e7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-0ea3210d-cd9b-4d30-b75a-8f936f99c7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-b1c4b905-88a7-430c-846a-3f28a1c4a0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-6004d64b-2bd4-4f7e-be58-be080373d513,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-45828d9c-920c-446b-aa5b-c43f7072cdac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2135523830-172.17.0.19-1597422265886:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34000,DS-dc2bdcd4-a1a4-4501-909f-19a256c3d971,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-1f6d012d-1a69-4c51-bae2-125049dfca7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-e4572aa5-fec4-42e6-b8b7-c07d32e4da16,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-3c9c8455-1c70-4f54-88b1-718b0aeb61a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-d8f56a69-e2f4-48cd-b6f8-67fd302f184f,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-fd57f88e-5efb-4b6d-8ece-9fdad7a2f013,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-2aa2a6d4-be56-45e5-8e66-649090330d75,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-cab54e78-15c9-406f-9623-44923daffe57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2135523830-172.17.0.19-1597422265886:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34000,DS-dc2bdcd4-a1a4-4501-909f-19a256c3d971,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-1f6d012d-1a69-4c51-bae2-125049dfca7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-e4572aa5-fec4-42e6-b8b7-c07d32e4da16,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-3c9c8455-1c70-4f54-88b1-718b0aeb61a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-d8f56a69-e2f4-48cd-b6f8-67fd302f184f,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-fd57f88e-5efb-4b6d-8ece-9fdad7a2f013,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-2aa2a6d4-be56-45e5-8e66-649090330d75,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-cab54e78-15c9-406f-9623-44923daffe57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1943320445-172.17.0.19-1597422994442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42955,DS-a20e5f59-479d-4e03-865b-ba1e872d3ede,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-33e3ffc0-009a-4ade-94d6-b967b65d686b,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-cb7ac545-656a-4a38-a3bd-5b74b17af576,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-c4925688-08c8-4338-a280-66492557bda2,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-1a90973b-319a-4813-8398-a07edeb9b52f,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-8297c8a9-27b9-4ac5-8a9c-3c1994aeee5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-354fc9da-b5e6-4832-9069-a4f2667a4df9,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-ded8ca96-1632-45be-aa09-b8cb1f25957c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1943320445-172.17.0.19-1597422994442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42955,DS-a20e5f59-479d-4e03-865b-ba1e872d3ede,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-33e3ffc0-009a-4ade-94d6-b967b65d686b,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-cb7ac545-656a-4a38-a3bd-5b74b17af576,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-c4925688-08c8-4338-a280-66492557bda2,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-1a90973b-319a-4813-8398-a07edeb9b52f,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-8297c8a9-27b9-4ac5-8a9c-3c1994aeee5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-354fc9da-b5e6-4832-9069-a4f2667a4df9,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-ded8ca96-1632-45be-aa09-b8cb1f25957c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2113541397-172.17.0.19-1597423030703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45527,DS-9b091288-2523-4d8c-9cad-f01746a54d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-ea4a8577-fc5e-4c25-a9f7-00f752d9af7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-38ff8375-767b-420f-9351-b80c5713466d,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-043dc3da-c741-4099-b5ab-87ade66203e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-9817d05a-a9e2-42a2-8312-e77a0b2ace05,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-65c8bd40-9609-4b51-b03f-1024440a7d37,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-ddcb4e03-2fb7-4722-905b-a3ea92785607,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-47165561-80f9-44ec-a8aa-783aa7ffeaec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2113541397-172.17.0.19-1597423030703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45527,DS-9b091288-2523-4d8c-9cad-f01746a54d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-ea4a8577-fc5e-4c25-a9f7-00f752d9af7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-38ff8375-767b-420f-9351-b80c5713466d,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-043dc3da-c741-4099-b5ab-87ade66203e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-9817d05a-a9e2-42a2-8312-e77a0b2ace05,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-65c8bd40-9609-4b51-b03f-1024440a7d37,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-ddcb4e03-2fb7-4722-905b-a3ea92785607,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-47165561-80f9-44ec-a8aa-783aa7ffeaec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-981032699-172.17.0.19-1597424300026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39617,DS-4d52a186-2f70-4e46-a9b8-6adae053df7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40996,DS-0583d1e1-3e1b-4290-91a7-74708e5c5eba,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-6796d148-161f-4e4d-91ce-4a62537d8ece,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-e36a20af-5c56-4622-bf18-aad66f036ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-03cfc144-cc65-454b-b8dc-3a80606dc460,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-c555c503-1e91-43d1-b79a-cd345b5818ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-8e0d08f0-a75c-47c6-a36c-74e2840fcde1,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-2bbce738-9048-42e1-8a14-e4e356cdf983,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-981032699-172.17.0.19-1597424300026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39617,DS-4d52a186-2f70-4e46-a9b8-6adae053df7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40996,DS-0583d1e1-3e1b-4290-91a7-74708e5c5eba,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-6796d148-161f-4e4d-91ce-4a62537d8ece,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-e36a20af-5c56-4622-bf18-aad66f036ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-03cfc144-cc65-454b-b8dc-3a80606dc460,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-c555c503-1e91-43d1-b79a-cd345b5818ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-8e0d08f0-a75c-47c6-a36c-74e2840fcde1,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-2bbce738-9048-42e1-8a14-e4e356cdf983,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1106019407-172.17.0.19-1597424529241:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40877,DS-4eff9ebc-6076-408c-8ca4-36ab5e771d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-0965717d-dc0c-40c2-bb9e-e761901d23f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-66bfb3a0-74e0-4bf2-b1ae-46469382cfb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-f0eb5142-b8ad-4b51-95c4-1140bea57485,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-ffb83670-3e24-4c5d-a8ce-aca0ec2e71cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-b03ffd83-571a-4e21-a295-b0a076e6371d,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-5ee83e88-32ee-4630-ae41-ee6729438b20,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-9ba3a822-d9de-48fd-8a0c-38e396f20587,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1106019407-172.17.0.19-1597424529241:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40877,DS-4eff9ebc-6076-408c-8ca4-36ab5e771d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-0965717d-dc0c-40c2-bb9e-e761901d23f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-66bfb3a0-74e0-4bf2-b1ae-46469382cfb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-f0eb5142-b8ad-4b51-95c4-1140bea57485,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-ffb83670-3e24-4c5d-a8ce-aca0ec2e71cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-b03ffd83-571a-4e21-a295-b0a076e6371d,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-5ee83e88-32ee-4630-ae41-ee6729438b20,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-9ba3a822-d9de-48fd-8a0c-38e396f20587,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-670828876-172.17.0.19-1597425151875:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45683,DS-0b6520c2-0203-4dc5-856d-58822f25a2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-745fa2f8-fe17-4687-92b1-c198ab7e8dde,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-a14f03c8-11c6-41cd-91bf-107824005c49,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-deb5d3ff-6e82-4b17-bcc6-71a6b399a8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-0f9b88b8-d9c4-40e8-9060-56d53c295ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-4910ea77-0c57-4ecd-8bba-2d6cd6605008,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-9fce4851-4a9e-4e31-b2b0-634ee4b74ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-968851fc-c332-4774-8512-4305b08e281b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-670828876-172.17.0.19-1597425151875:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45683,DS-0b6520c2-0203-4dc5-856d-58822f25a2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-745fa2f8-fe17-4687-92b1-c198ab7e8dde,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-a14f03c8-11c6-41cd-91bf-107824005c49,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-deb5d3ff-6e82-4b17-bcc6-71a6b399a8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-0f9b88b8-d9c4-40e8-9060-56d53c295ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-4910ea77-0c57-4ecd-8bba-2d6cd6605008,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-9fce4851-4a9e-4e31-b2b0-634ee4b74ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-968851fc-c332-4774-8512-4305b08e281b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2087038555-172.17.0.19-1597425667761:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35755,DS-b01086f9-c44f-4960-8845-5d2985a1a9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-545574f5-59da-4722-9afe-f7b48eee98df,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-fb537b4d-e782-4d35-938d-c7148bb388e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-42bf8419-3ff7-4711-b908-a5ad64aa3968,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-7d447275-9e14-4c51-8c20-5130b6f6ee21,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-778b6886-7e98-434c-aaa9-2e87e2009651,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-c4f396c0-6e97-417e-9c54-4d1458be657e,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-00fcb243-eb0d-4ded-a51c-01dc7e81e3a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2087038555-172.17.0.19-1597425667761:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35755,DS-b01086f9-c44f-4960-8845-5d2985a1a9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-545574f5-59da-4722-9afe-f7b48eee98df,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-fb537b4d-e782-4d35-938d-c7148bb388e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-42bf8419-3ff7-4711-b908-a5ad64aa3968,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-7d447275-9e14-4c51-8c20-5130b6f6ee21,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-778b6886-7e98-434c-aaa9-2e87e2009651,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-c4f396c0-6e97-417e-9c54-4d1458be657e,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-00fcb243-eb0d-4ded-a51c-01dc7e81e3a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1490675635-172.17.0.19-1597425949484:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37398,DS-89881a87-2578-41ce-bbd7-42de2711c17f,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-4c20b4c7-4ee2-4f09-8359-988cc9cfc317,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-e750e252-bd2b-4079-be06-9cbd71e6b09a,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-56829104-c5d0-4bf7-80bf-f545f4126e68,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-bbab113e-011c-470a-acb8-866cf7764214,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-d938336b-c6b6-4301-9774-bbb4f909050e,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-ed31ad4a-5259-4909-be6f-4cd6d3f0b918,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-3c0ce0fc-6f1d-4168-a1b8-ac5ede38ea1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1490675635-172.17.0.19-1597425949484:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37398,DS-89881a87-2578-41ce-bbd7-42de2711c17f,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-4c20b4c7-4ee2-4f09-8359-988cc9cfc317,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-e750e252-bd2b-4079-be06-9cbd71e6b09a,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-56829104-c5d0-4bf7-80bf-f545f4126e68,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-bbab113e-011c-470a-acb8-866cf7764214,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-d938336b-c6b6-4301-9774-bbb4f909050e,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-ed31ad4a-5259-4909-be6f-4cd6d3f0b918,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-3c0ce0fc-6f1d-4168-a1b8-ac5ede38ea1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-240922342-172.17.0.19-1597426416824:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41940,DS-a6905851-38ec-4bc2-82a4-fafe1028ea23,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-e5a171d9-d761-4d2b-a5f3-d6b9c14b96c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-a5bb6a2b-e54c-4d62-ace2-4a0b693446b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34491,DS-f77ebe9b-1caf-40eb-a1ac-5c9e3be622e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-b405b0c2-106d-4599-a68e-579d18449458,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-e0958dea-e7b0-4822-aed2-c42b42f3a594,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-6160142a-d02c-4a31-8a2d-5a8637dce3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35688,DS-e7b51f12-be6e-4795-b588-ce470a4cb4df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-240922342-172.17.0.19-1597426416824:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41940,DS-a6905851-38ec-4bc2-82a4-fafe1028ea23,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-e5a171d9-d761-4d2b-a5f3-d6b9c14b96c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-a5bb6a2b-e54c-4d62-ace2-4a0b693446b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34491,DS-f77ebe9b-1caf-40eb-a1ac-5c9e3be622e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-b405b0c2-106d-4599-a68e-579d18449458,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-e0958dea-e7b0-4822-aed2-c42b42f3a594,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-6160142a-d02c-4a31-8a2d-5a8637dce3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35688,DS-e7b51f12-be6e-4795-b588-ce470a4cb4df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1540585657-172.17.0.19-1597427022864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44006,DS-1534f66a-7487-47c0-8825-d9ee245874dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-ba7c06fb-400e-48e8-8150-29a55431d78d,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-d9ca191e-18dc-4bf3-add7-b8020437d5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-16ef1e60-d59d-4593-a925-996abf61a8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-e06bf099-684d-47ba-a998-6179ddcf7790,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-0e57661e-25bf-4033-8d7e-9134740e2c49,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-2722989b-bbb5-4cda-b201-0cbc7bfa020f,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-a3923927-f43e-44e9-9119-c8760ac7f6c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1540585657-172.17.0.19-1597427022864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44006,DS-1534f66a-7487-47c0-8825-d9ee245874dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-ba7c06fb-400e-48e8-8150-29a55431d78d,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-d9ca191e-18dc-4bf3-add7-b8020437d5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-16ef1e60-d59d-4593-a925-996abf61a8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-e06bf099-684d-47ba-a998-6179ddcf7790,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-0e57661e-25bf-4033-8d7e-9134740e2c49,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-2722989b-bbb5-4cda-b201-0cbc7bfa020f,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-a3923927-f43e-44e9-9119-c8760ac7f6c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1924371223-172.17.0.19-1597427115566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43564,DS-bb9fc81a-6b91-4ad5-9f9d-98404074750c,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-53fe851c-3e61-4e58-9fa0-527fc2f18c82,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-a5617ec3-9148-4f4a-bbbe-0911c3b7aa61,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-cfcb7c22-e10c-42d0-9d7a-6c7c35f94e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-826969a5-0ccf-422b-8e83-bb1a215215d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-8797f9c2-b268-41ce-9951-019f2a4a0eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-174cd292-3045-4491-b625-a1c919d148be,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-df506c96-62bd-4998-bd32-6df86937b7b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1924371223-172.17.0.19-1597427115566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43564,DS-bb9fc81a-6b91-4ad5-9f9d-98404074750c,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-53fe851c-3e61-4e58-9fa0-527fc2f18c82,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-a5617ec3-9148-4f4a-bbbe-0911c3b7aa61,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-cfcb7c22-e10c-42d0-9d7a-6c7c35f94e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-826969a5-0ccf-422b-8e83-bb1a215215d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-8797f9c2-b268-41ce-9951-019f2a4a0eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-174cd292-3045-4491-b625-a1c919d148be,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-df506c96-62bd-4998-bd32-6df86937b7b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2047324482-172.17.0.19-1597427494603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45509,DS-2c50e755-5ac1-449f-b853-12a9ccdc1d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-ce9972c4-361d-4a04-8c84-ca262127282e,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-79956355-4af2-4e76-be3c-c49129d9e96e,DISK], DatanodeInfoWithStorage[127.0.0.1:43715,DS-6ba7f84c-4ade-4d77-8d24-61dd8343d203,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-be94c50a-dd68-4541-aaf2-eb9c2a799e79,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-de65c1f5-8c54-4222-a8c3-8b24d3874129,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-eef9ab6d-00fc-41a3-849c-2d04f77ecff4,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-003f4db8-eea6-4bb3-919f-4cd3be5a0d06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2047324482-172.17.0.19-1597427494603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45509,DS-2c50e755-5ac1-449f-b853-12a9ccdc1d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-ce9972c4-361d-4a04-8c84-ca262127282e,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-79956355-4af2-4e76-be3c-c49129d9e96e,DISK], DatanodeInfoWithStorage[127.0.0.1:43715,DS-6ba7f84c-4ade-4d77-8d24-61dd8343d203,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-be94c50a-dd68-4541-aaf2-eb9c2a799e79,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-de65c1f5-8c54-4222-a8c3-8b24d3874129,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-eef9ab6d-00fc-41a3-849c-2d04f77ecff4,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-003f4db8-eea6-4bb3-919f-4cd3be5a0d06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-350121940-172.17.0.19-1597427737611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39894,DS-68a3505d-4a69-43cc-8ba9-40823f90a1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-166898fc-1545-4695-afc3-5b2d164032a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-39cc8e30-f10b-40b3-a62e-663ed43ddb08,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-db4f4c27-32dd-4d59-a786-0db748cf2ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-10add375-2b18-485f-9ed2-2a4cbb80255c,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-e5fadd73-38a8-47d2-b956-2a757f91e7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-3a7683d0-d9ec-4730-863c-7c1f357e7f62,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-103a601c-e64f-4c7f-b3f2-4df479eb947b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-350121940-172.17.0.19-1597427737611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39894,DS-68a3505d-4a69-43cc-8ba9-40823f90a1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-166898fc-1545-4695-afc3-5b2d164032a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-39cc8e30-f10b-40b3-a62e-663ed43ddb08,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-db4f4c27-32dd-4d59-a786-0db748cf2ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-10add375-2b18-485f-9ed2-2a4cbb80255c,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-e5fadd73-38a8-47d2-b956-2a757f91e7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34798,DS-3a7683d0-d9ec-4730-863c-7c1f357e7f62,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-103a601c-e64f-4c7f-b3f2-4df479eb947b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 70000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-584788747-172.17.0.19-1597427930419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43175,DS-72eb65b8-375a-4287-bff8-774c010ee8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-8c11f022-035d-48e8-b0b6-cff5e0974f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-50b19a90-489b-4a9e-8e63-d19a9ef5f91b,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-3b577048-3b18-4b4a-9594-66f96765558f,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-895dca18-1e32-49b8-bdf5-acccdd5a84da,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-be2aef54-beb1-43f1-ad23-4b493252e3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-887505a7-676f-44a9-bff3-e8ae6537872f,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-e124c125-4088-437a-8bc8-a5e498beb081,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-584788747-172.17.0.19-1597427930419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43175,DS-72eb65b8-375a-4287-bff8-774c010ee8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-8c11f022-035d-48e8-b0b6-cff5e0974f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-50b19a90-489b-4a9e-8e63-d19a9ef5f91b,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-3b577048-3b18-4b4a-9594-66f96765558f,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-895dca18-1e32-49b8-bdf5-acccdd5a84da,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-be2aef54-beb1-43f1-ad23-4b493252e3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-887505a7-676f-44a9-bff3-e8ae6537872f,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-e124c125-4088-437a-8bc8-a5e498beb081,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 7088
