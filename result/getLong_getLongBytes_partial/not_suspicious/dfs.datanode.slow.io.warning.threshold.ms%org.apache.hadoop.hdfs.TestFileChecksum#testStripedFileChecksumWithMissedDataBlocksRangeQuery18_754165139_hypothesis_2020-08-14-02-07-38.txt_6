reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171642668-172.17.0.11-1597370977958:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42918,DS-56b60356-a952-4c62-9ccb-effa278f1f68,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-635004dd-823a-4b68-917b-8d1f81c7f8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-5f022cf6-2e53-4b0f-8874-584082e9ec99,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-e09beaff-4bba-4959-b0b8-408b6b3a0025,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-cf662ee8-dfc7-4ba7-9617-1240d01b76d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-a2d2e99f-c8da-4c4d-8726-804a6fcc6b55,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-16cb1795-0df9-41f7-b0bb-057a2d203a28,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-a543e07e-e0bc-4788-aabe-1d91f6af4656,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171642668-172.17.0.11-1597370977958:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42918,DS-56b60356-a952-4c62-9ccb-effa278f1f68,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-635004dd-823a-4b68-917b-8d1f81c7f8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-5f022cf6-2e53-4b0f-8874-584082e9ec99,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-e09beaff-4bba-4959-b0b8-408b6b3a0025,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-cf662ee8-dfc7-4ba7-9617-1240d01b76d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-a2d2e99f-c8da-4c4d-8726-804a6fcc6b55,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-16cb1795-0df9-41f7-b0bb-057a2d203a28,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-a543e07e-e0bc-4788-aabe-1d91f6af4656,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1095332397-172.17.0.11-1597371731219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45754,DS-1f3da335-2774-4772-a805-57ad22f9eaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-5551315b-833f-435c-8e8c-e71d36dedf97,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-5b528769-8cdf-4eb5-8d63-c0ddeddcc6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-e8f25d43-860b-4d3b-b25c-37a8480b7f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-0432c79f-7ef4-488d-83b0-793415f620d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-57b2f3b8-b7d8-4754-abf5-7b727dfbfed0,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-7a6990ed-e197-47d4-8a45-fc4c270d7126,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-1c2eda2b-60c4-496a-a385-da144d8c3bf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1095332397-172.17.0.11-1597371731219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45754,DS-1f3da335-2774-4772-a805-57ad22f9eaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-5551315b-833f-435c-8e8c-e71d36dedf97,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-5b528769-8cdf-4eb5-8d63-c0ddeddcc6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-e8f25d43-860b-4d3b-b25c-37a8480b7f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-0432c79f-7ef4-488d-83b0-793415f620d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-57b2f3b8-b7d8-4754-abf5-7b727dfbfed0,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-7a6990ed-e197-47d4-8a45-fc4c270d7126,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-1c2eda2b-60c4-496a-a385-da144d8c3bf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274028765-172.17.0.11-1597371983484:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34298,DS-4eab9679-9874-4d98-aeef-2877ead32acc,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-c2865594-e6e2-4ce2-a1e2-5c44fd02de44,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-08000455-93e7-47ce-8a15-cda795612435,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-7ad3def3-64b4-4006-8987-deaf918d7feb,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-5f1020fc-040b-4a42-a8a4-fbe62c14672d,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-9761dfaa-7e84-471b-bafa-a3b6263799de,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-fcccfcf1-20d1-4778-a3e9-e2cdeb200691,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-bc8a9c06-12c8-4671-85da-fee9314aef9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274028765-172.17.0.11-1597371983484:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34298,DS-4eab9679-9874-4d98-aeef-2877ead32acc,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-c2865594-e6e2-4ce2-a1e2-5c44fd02de44,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-08000455-93e7-47ce-8a15-cda795612435,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-7ad3def3-64b4-4006-8987-deaf918d7feb,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-5f1020fc-040b-4a42-a8a4-fbe62c14672d,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-9761dfaa-7e84-471b-bafa-a3b6263799de,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-fcccfcf1-20d1-4778-a3e9-e2cdeb200691,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-bc8a9c06-12c8-4671-85da-fee9314aef9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2029186736-172.17.0.11-1597372124824:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42938,DS-bd0afbd0-2df5-4257-a70c-22fbf9b82ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-9670cacf-fdb9-474d-b986-35c57ac2f6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36743,DS-32dc7d1f-a711-4db6-aa9b-571de818877d,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-b4d855f3-cd3d-443e-bbd8-9bc9fb0bf365,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-d087dcb0-480f-4dec-8a7e-36ec50129a66,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-0d9690c5-6d8b-426e-8c8b-4670ed68b849,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-6e9249ac-b7aa-4e07-904d-991ca32e5103,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-4544f268-c15b-4599-8abe-5dc0cf29bc3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2029186736-172.17.0.11-1597372124824:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42938,DS-bd0afbd0-2df5-4257-a70c-22fbf9b82ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-9670cacf-fdb9-474d-b986-35c57ac2f6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36743,DS-32dc7d1f-a711-4db6-aa9b-571de818877d,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-b4d855f3-cd3d-443e-bbd8-9bc9fb0bf365,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-d087dcb0-480f-4dec-8a7e-36ec50129a66,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-0d9690c5-6d8b-426e-8c8b-4670ed68b849,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-6e9249ac-b7aa-4e07-904d-991ca32e5103,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-4544f268-c15b-4599-8abe-5dc0cf29bc3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-835225650-172.17.0.11-1597372392507:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40138,DS-1c4051ba-d26c-4275-b8cf-7187d8669dda,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-58899edc-6c81-49f9-8d4b-87ee4e2254cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-a33e4a8c-1824-4b74-b840-2de8f5734617,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-16702ba8-af0c-4b5c-93bb-42506306ec81,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-2d962073-3ac8-4747-84cf-e421267b20ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-65d72dce-ef9a-415b-89ee-5bee39572f11,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-4ac23999-de6b-4f4f-8f24-8a6522eeb4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-345151cd-1de7-4e9d-8443-8cf6c8923521,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-835225650-172.17.0.11-1597372392507:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40138,DS-1c4051ba-d26c-4275-b8cf-7187d8669dda,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-58899edc-6c81-49f9-8d4b-87ee4e2254cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-a33e4a8c-1824-4b74-b840-2de8f5734617,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-16702ba8-af0c-4b5c-93bb-42506306ec81,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-2d962073-3ac8-4747-84cf-e421267b20ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-65d72dce-ef9a-415b-89ee-5bee39572f11,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-4ac23999-de6b-4f4f-8f24-8a6522eeb4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-345151cd-1de7-4e9d-8443-8cf6c8923521,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-473297105-172.17.0.11-1597372746280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41880,DS-6361d3b6-90d8-40eb-9fdf-b911a762f456,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-09de6dee-943f-4de5-8c75-570192a17627,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-9f6c4278-805f-47f6-bb54-5364cfc36f23,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-510db4cf-3a78-4ca7-848c-84de259b8e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-e4b26270-05e9-4eed-85f2-77256767375a,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-0e1b24eb-31f4-429e-b7a5-5c3d6ad7cfb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-e42ae68f-b411-4b13-85d0-8a3dac7470c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-cbb7d362-14bd-40e2-bf2d-cd3262127f82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-473297105-172.17.0.11-1597372746280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41880,DS-6361d3b6-90d8-40eb-9fdf-b911a762f456,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-09de6dee-943f-4de5-8c75-570192a17627,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-9f6c4278-805f-47f6-bb54-5364cfc36f23,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-510db4cf-3a78-4ca7-848c-84de259b8e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-e4b26270-05e9-4eed-85f2-77256767375a,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-0e1b24eb-31f4-429e-b7a5-5c3d6ad7cfb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-e42ae68f-b411-4b13-85d0-8a3dac7470c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-cbb7d362-14bd-40e2-bf2d-cd3262127f82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-703157529-172.17.0.11-1597372980999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36840,DS-7068e5cc-dfd9-4c7b-a326-6f54d7ab8e92,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-a8aebf91-9d34-4423-9289-f7f155ec055d,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-6a700c1f-5231-41cd-9a47-a174a18adc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-7ce3d758-9a9a-4c49-bda6-d07fc45fce60,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-917cbd44-42c5-42b4-8263-1b01e8167a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-b3ec9705-de6f-4c49-bd8e-1609ffbda32f,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-8e522aea-32ec-47cd-8f41-1c76435077a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34377,DS-4bc21a33-65f3-4681-a2b9-396687684b23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-703157529-172.17.0.11-1597372980999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36840,DS-7068e5cc-dfd9-4c7b-a326-6f54d7ab8e92,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-a8aebf91-9d34-4423-9289-f7f155ec055d,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-6a700c1f-5231-41cd-9a47-a174a18adc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-7ce3d758-9a9a-4c49-bda6-d07fc45fce60,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-917cbd44-42c5-42b4-8263-1b01e8167a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-b3ec9705-de6f-4c49-bd8e-1609ffbda32f,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-8e522aea-32ec-47cd-8f41-1c76435077a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34377,DS-4bc21a33-65f3-4681-a2b9-396687684b23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-70077811-172.17.0.11-1597373117423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34446,DS-7fe46580-271d-4249-9180-e3cd90e765f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-ee3323e2-b8d3-46fc-8a4f-f0b60a22480f,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-673af42b-a851-4b64-b8df-cbba8325ed9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-1fd880a6-73c4-4e08-b765-65715c07cf56,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-3db8b282-c1e8-4aee-af94-1466a9650aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-2b7226bf-c4a4-49b5-ae59-366ea6de2cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-fdfca84d-e26b-47bc-94a8-37cb044a5f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-d1438198-04a2-4ea9-967e-e4988ab9fcff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-70077811-172.17.0.11-1597373117423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34446,DS-7fe46580-271d-4249-9180-e3cd90e765f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-ee3323e2-b8d3-46fc-8a4f-f0b60a22480f,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-673af42b-a851-4b64-b8df-cbba8325ed9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-1fd880a6-73c4-4e08-b765-65715c07cf56,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-3db8b282-c1e8-4aee-af94-1466a9650aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-2b7226bf-c4a4-49b5-ae59-366ea6de2cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-fdfca84d-e26b-47bc-94a8-37cb044a5f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-d1438198-04a2-4ea9-967e-e4988ab9fcff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696551420-172.17.0.11-1597373425127:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40729,DS-07963240-4c1e-41f5-aa52-d794621ec955,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-83751cb4-ddb7-498e-95b8-e1c84f80a72a,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-de0ebc1a-33fb-44c1-8d35-1a0b31f180c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-30437812-4386-45bd-b7fe-bbb8d38b35ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-e9a75cc3-1a4e-42e2-a82c-7fea79d8ca14,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-00b5fd79-5e21-4770-b2b4-4d430f3fe67b,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-694c7ad4-1327-4f91-bf63-1437e934b41c,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-b6fd4cb5-f9fc-45aa-a8e9-c1a3c79923fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696551420-172.17.0.11-1597373425127:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40729,DS-07963240-4c1e-41f5-aa52-d794621ec955,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-83751cb4-ddb7-498e-95b8-e1c84f80a72a,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-de0ebc1a-33fb-44c1-8d35-1a0b31f180c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-30437812-4386-45bd-b7fe-bbb8d38b35ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-e9a75cc3-1a4e-42e2-a82c-7fea79d8ca14,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-00b5fd79-5e21-4770-b2b4-4d430f3fe67b,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-694c7ad4-1327-4f91-bf63-1437e934b41c,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-b6fd4cb5-f9fc-45aa-a8e9-c1a3c79923fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-800957523-172.17.0.11-1597373526512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41944,DS-3fa2d82c-ef90-41c0-8831-8e9dda3e7235,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-d3ab6ac5-2fd0-4f7c-b6e7-63d6e49df045,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-126df28f-330c-4d1f-8705-97689a091087,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-f20d9e0f-a8d6-460c-855e-9bbf72e34295,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-5e5d4a63-fdc6-4587-8d22-a0b53c088c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45315,DS-1f897186-35d6-4746-9b8c-40311f16de71,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-b1c45e62-5e88-43ef-b957-86cf07f656dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-1cba2736-05a6-488a-a130-b53a05fb1d3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-800957523-172.17.0.11-1597373526512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41944,DS-3fa2d82c-ef90-41c0-8831-8e9dda3e7235,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-d3ab6ac5-2fd0-4f7c-b6e7-63d6e49df045,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-126df28f-330c-4d1f-8705-97689a091087,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-f20d9e0f-a8d6-460c-855e-9bbf72e34295,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-5e5d4a63-fdc6-4587-8d22-a0b53c088c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45315,DS-1f897186-35d6-4746-9b8c-40311f16de71,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-b1c45e62-5e88-43ef-b957-86cf07f656dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-1cba2736-05a6-488a-a130-b53a05fb1d3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-857814968-172.17.0.11-1597374145862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43890,DS-9d0f9e29-8fb7-4211-addf-ff1d6af10d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-45abbf09-33cd-4c64-8ec0-c97c812ade9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-8be3170b-fce2-4856-b88f-80f5a464fba8,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-fb01532f-81d3-406a-a036-398ac4b2bef7,DISK], DatanodeInfoWithStorage[127.0.0.1:34256,DS-2a3406af-3467-49ac-af1d-148bb2564dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-99e161a2-87d7-4185-88ec-0b192f5631f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-f0654803-7091-4491-ac13-b436c8a65706,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-c251bbeb-0476-4f2d-9e50-e9b49aeb91a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-857814968-172.17.0.11-1597374145862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43890,DS-9d0f9e29-8fb7-4211-addf-ff1d6af10d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-45abbf09-33cd-4c64-8ec0-c97c812ade9b,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-8be3170b-fce2-4856-b88f-80f5a464fba8,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-fb01532f-81d3-406a-a036-398ac4b2bef7,DISK], DatanodeInfoWithStorage[127.0.0.1:34256,DS-2a3406af-3467-49ac-af1d-148bb2564dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-99e161a2-87d7-4185-88ec-0b192f5631f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-f0654803-7091-4491-ac13-b436c8a65706,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-c251bbeb-0476-4f2d-9e50-e9b49aeb91a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-359025986-172.17.0.11-1597374537616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34645,DS-7dda17b3-73d8-47a0-ba00-53c608871c94,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-8b8ecf3d-5b1e-448a-a550-dc25ec9ec89a,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-9152f5ce-5687-42b3-b86e-adb19bc466ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-e729be81-7fca-46bc-a376-d108034ae5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42201,DS-b36fe37f-ce18-4c72-a23b-a2db1c058e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-a91fc073-5ff7-4026-9fda-964cede8238a,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-9967dd5d-49b9-4ac8-87af-07f9de613e06,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-657c2a12-a27d-4dd0-81a3-8a531ef8400e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-359025986-172.17.0.11-1597374537616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34645,DS-7dda17b3-73d8-47a0-ba00-53c608871c94,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-8b8ecf3d-5b1e-448a-a550-dc25ec9ec89a,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-9152f5ce-5687-42b3-b86e-adb19bc466ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39557,DS-e729be81-7fca-46bc-a376-d108034ae5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42201,DS-b36fe37f-ce18-4c72-a23b-a2db1c058e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-a91fc073-5ff7-4026-9fda-964cede8238a,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-9967dd5d-49b9-4ac8-87af-07f9de613e06,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-657c2a12-a27d-4dd0-81a3-8a531ef8400e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-883249175-172.17.0.11-1597374881162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42498,DS-81dcfef7-f762-4ef2-bd3a-6ddcf6eabfa4,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-e5e0b84f-6ccf-47d8-a207-6064b2b9b674,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-3d93bca1-b33b-48ba-9c7a-99115fc5e15f,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-c3da07a5-a1e7-406f-ba3c-07b3a5a69ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-3359b968-fb4b-4132-9b21-2bea0ebd3831,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-54226828-b80a-43e3-b0a3-b14b5b8609c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-aac789df-875b-4e9e-b908-00224c5ad829,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-41fcf98d-e58f-4e56-8b41-9ce48771c096,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-883249175-172.17.0.11-1597374881162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42498,DS-81dcfef7-f762-4ef2-bd3a-6ddcf6eabfa4,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-e5e0b84f-6ccf-47d8-a207-6064b2b9b674,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-3d93bca1-b33b-48ba-9c7a-99115fc5e15f,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-c3da07a5-a1e7-406f-ba3c-07b3a5a69ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-3359b968-fb4b-4132-9b21-2bea0ebd3831,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-54226828-b80a-43e3-b0a3-b14b5b8609c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-aac789df-875b-4e9e-b908-00224c5ad829,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-41fcf98d-e58f-4e56-8b41-9ce48771c096,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-135442135-172.17.0.11-1597375076891:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41959,DS-db23a3da-ceaf-4975-866a-1433ce609d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-8ea3223d-86e9-4861-a655-db744fd2a9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-b93dc317-75c4-430f-bf89-24656d585904,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-f4b4e2e5-cbc6-4289-892a-a28f77b06876,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-5c6a91ca-45dc-4898-a201-6533921cbe23,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-34effa6c-7056-479e-bf64-4b2a6831b5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-1beae0a8-5ff2-40ce-8803-03793a157d07,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-b3423401-efd3-4205-b3b6-744157758235,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-135442135-172.17.0.11-1597375076891:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41959,DS-db23a3da-ceaf-4975-866a-1433ce609d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-8ea3223d-86e9-4861-a655-db744fd2a9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-b93dc317-75c4-430f-bf89-24656d585904,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-f4b4e2e5-cbc6-4289-892a-a28f77b06876,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-5c6a91ca-45dc-4898-a201-6533921cbe23,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-34effa6c-7056-479e-bf64-4b2a6831b5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-1beae0a8-5ff2-40ce-8803-03793a157d07,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-b3423401-efd3-4205-b3b6-744157758235,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1649833934-172.17.0.11-1597375326230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35129,DS-23b1517d-200f-44ec-ac73-655458966ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-d3c54080-46c0-42c5-87e3-9bdfd48f73c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-915c2af8-f19a-46fc-b09a-1f86eb34c907,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-e23ebe07-cd3e-4b07-877c-605b4a920d42,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-26785e80-e28c-4b5a-ab52-f9b942e93f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-0904c963-f7de-4184-87bc-5945346574be,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-6ec2abf2-c5cf-4c7c-9331-c70412d4ac56,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-35766b9a-8a3b-4cb8-9b1b-339f41dae2fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1649833934-172.17.0.11-1597375326230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35129,DS-23b1517d-200f-44ec-ac73-655458966ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-d3c54080-46c0-42c5-87e3-9bdfd48f73c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-915c2af8-f19a-46fc-b09a-1f86eb34c907,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-e23ebe07-cd3e-4b07-877c-605b4a920d42,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-26785e80-e28c-4b5a-ab52-f9b942e93f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-0904c963-f7de-4184-87bc-5945346574be,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-6ec2abf2-c5cf-4c7c-9331-c70412d4ac56,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-35766b9a-8a3b-4cb8-9b1b-339f41dae2fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1541293904-172.17.0.11-1597376204873:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38903,DS-77b042a7-484c-408a-9b7f-39891a207640,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-488b333d-04aa-40a4-aad2-0b55dc9dea5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-fbc10aa9-770e-4b92-b8e3-12a660358fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-e1308400-7140-4528-93a8-de59075aee0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-1f6c6ceb-44db-4a5f-af4f-188e0098496b,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-09d1e1db-610d-4e73-8225-5188709736d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-917e5a00-ffe1-44da-abbe-46b5ae6fa739,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-9e1c1fd5-e4f7-4d33-82c7-c15b9df6b28a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1541293904-172.17.0.11-1597376204873:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38903,DS-77b042a7-484c-408a-9b7f-39891a207640,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-488b333d-04aa-40a4-aad2-0b55dc9dea5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-fbc10aa9-770e-4b92-b8e3-12a660358fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-e1308400-7140-4528-93a8-de59075aee0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-1f6c6ceb-44db-4a5f-af4f-188e0098496b,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-09d1e1db-610d-4e73-8225-5188709736d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-917e5a00-ffe1-44da-abbe-46b5ae6fa739,DISK], DatanodeInfoWithStorage[127.0.0.1:44514,DS-9e1c1fd5-e4f7-4d33-82c7-c15b9df6b28a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1918554426-172.17.0.11-1597376245592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34259,DS-4799a79a-3a41-4a3c-9878-d627fd43b38c,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-fb0cf300-f721-4edf-822d-3690b67d4fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-e83aa6ff-5af0-47c9-8a13-4e20758801f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-fbdc1308-b6fb-499e-9204-c7a98ca17e25,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-6fd58f7c-697d-479b-8c5f-4caeae828a50,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-ef430202-04bc-4e18-81e9-f73b8804c354,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-331f1156-de99-4301-af28-086a010fd2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-52b89ce7-80f4-4193-815f-327ffbbb14b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1918554426-172.17.0.11-1597376245592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34259,DS-4799a79a-3a41-4a3c-9878-d627fd43b38c,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-fb0cf300-f721-4edf-822d-3690b67d4fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-e83aa6ff-5af0-47c9-8a13-4e20758801f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-fbdc1308-b6fb-499e-9204-c7a98ca17e25,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-6fd58f7c-697d-479b-8c5f-4caeae828a50,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-ef430202-04bc-4e18-81e9-f73b8804c354,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-331f1156-de99-4301-af28-086a010fd2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-52b89ce7-80f4-4193-815f-327ffbbb14b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1369516108-172.17.0.11-1597376705568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43926,DS-fa50d417-90e7-4096-bae4-50c3d3c96bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-48335127-29d2-4793-96e7-e14156fd3726,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-73e0a0b7-91b5-4202-b8d7-2ee77ff56e52,DISK], DatanodeInfoWithStorage[127.0.0.1:33141,DS-bf974eb5-8e4f-46f9-93cd-75fa75bf9729,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-4312f44d-70d3-4e02-a7f1-71b72888d830,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-6a9632e9-62f9-45e3-a720-42e0c9a83357,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-f5db1067-298d-4d8f-9c9b-813256c33a16,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-605800f5-510c-459d-9663-df7e8e19e592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1369516108-172.17.0.11-1597376705568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43926,DS-fa50d417-90e7-4096-bae4-50c3d3c96bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-48335127-29d2-4793-96e7-e14156fd3726,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-73e0a0b7-91b5-4202-b8d7-2ee77ff56e52,DISK], DatanodeInfoWithStorage[127.0.0.1:33141,DS-bf974eb5-8e4f-46f9-93cd-75fa75bf9729,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-4312f44d-70d3-4e02-a7f1-71b72888d830,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-6a9632e9-62f9-45e3-a720-42e0c9a83357,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-f5db1067-298d-4d8f-9c9b-813256c33a16,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-605800f5-510c-459d-9663-df7e8e19e592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1136653835-172.17.0.11-1597376903899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33291,DS-9647157e-0ac4-4b87-9261-6d1a00ac3052,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-b331e4b9-ec18-4ec5-a363-05755d167e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-eefb7c8f-8e62-41ad-8226-a617bfc4a845,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-c66bacb0-8af4-48b0-81d1-c570c4d92127,DISK], DatanodeInfoWithStorage[127.0.0.1:40604,DS-91010e67-47a0-4fe1-bae3-07d413bbcb52,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-c1e24630-3e15-4046-ae23-aa3ddc1f596e,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-526cc2ee-da49-4611-8fa6-d66108f1d443,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-a582790e-ca58-4063-9828-0097b4f6a39c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1136653835-172.17.0.11-1597376903899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33291,DS-9647157e-0ac4-4b87-9261-6d1a00ac3052,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-b331e4b9-ec18-4ec5-a363-05755d167e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-eefb7c8f-8e62-41ad-8226-a617bfc4a845,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-c66bacb0-8af4-48b0-81d1-c570c4d92127,DISK], DatanodeInfoWithStorage[127.0.0.1:40604,DS-91010e67-47a0-4fe1-bae3-07d413bbcb52,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-c1e24630-3e15-4046-ae23-aa3ddc1f596e,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-526cc2ee-da49-4611-8fa6-d66108f1d443,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-a582790e-ca58-4063-9828-0097b4f6a39c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-814285500-172.17.0.11-1597376988808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32818,DS-25a6af43-a532-4e2d-a23d-04c4db51d9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-1f0aa5f2-9796-460d-8d15-24813646962a,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-3e01de76-e807-48ac-8592-89ae8492ed70,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-6029a559-5ff4-47c4-ab96-62bfe2e25641,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-7a938816-4353-42ae-802e-1b346439041e,DISK], DatanodeInfoWithStorage[127.0.0.1:35561,DS-42047a22-7473-4256-b517-71b63babd7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-470c9321-1162-4e7d-98de-ede9e7fd363b,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-b9f8098d-f9d2-47a3-bd57-ce9ca64f9bbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-814285500-172.17.0.11-1597376988808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32818,DS-25a6af43-a532-4e2d-a23d-04c4db51d9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-1f0aa5f2-9796-460d-8d15-24813646962a,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-3e01de76-e807-48ac-8592-89ae8492ed70,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-6029a559-5ff4-47c4-ab96-62bfe2e25641,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-7a938816-4353-42ae-802e-1b346439041e,DISK], DatanodeInfoWithStorage[127.0.0.1:35561,DS-42047a22-7473-4256-b517-71b63babd7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-470c9321-1162-4e7d-98de-ede9e7fd363b,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-b9f8098d-f9d2-47a3-bd57-ce9ca64f9bbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-230825801-172.17.0.11-1597377321079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37114,DS-56a6456d-a62d-43e6-9a64-03d68a913fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-8817fd06-9552-4a58-8ac1-85f61e6b96a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35069,DS-d92cd83f-6bfb-4a71-8ba0-7993b02eb388,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-bf0e87d5-74b0-4719-97a2-4773047edc86,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-1d05afad-f376-4cf3-ba68-71e8f21d667d,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-59cc65e1-64ce-46cc-914a-93b46ed41eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-805dc660-f1a4-4063-b86a-f195738ab8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-bead7aa0-9ec6-4061-9eb5-9325705a8d90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-230825801-172.17.0.11-1597377321079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37114,DS-56a6456d-a62d-43e6-9a64-03d68a913fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-8817fd06-9552-4a58-8ac1-85f61e6b96a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35069,DS-d92cd83f-6bfb-4a71-8ba0-7993b02eb388,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-bf0e87d5-74b0-4719-97a2-4773047edc86,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-1d05afad-f376-4cf3-ba68-71e8f21d667d,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-59cc65e1-64ce-46cc-914a-93b46ed41eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-805dc660-f1a4-4063-b86a-f195738ab8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-bead7aa0-9ec6-4061-9eb5-9325705a8d90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2103075903-172.17.0.11-1597377410200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37253,DS-3fef5f52-68bd-4bb3-b991-3deb3f5f3113,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-16b1c5bc-37ea-4e8e-b714-f63cf62976fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-c0cc2ca5-677d-4e0f-a637-4754c513554e,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-aaaa0443-3703-4f42-bca1-ddbac668d967,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-ce273426-4a86-42e2-96b3-ea54f5eda912,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-ae6acada-1aef-4b2a-870b-98b871e1ee54,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-28c0cd1d-4ebd-4f06-b5eb-2902b6fdcda2,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-b022c7a2-16ca-4d36-ae68-524ae21bde4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2103075903-172.17.0.11-1597377410200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37253,DS-3fef5f52-68bd-4bb3-b991-3deb3f5f3113,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-16b1c5bc-37ea-4e8e-b714-f63cf62976fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-c0cc2ca5-677d-4e0f-a637-4754c513554e,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-aaaa0443-3703-4f42-bca1-ddbac668d967,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-ce273426-4a86-42e2-96b3-ea54f5eda912,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-ae6acada-1aef-4b2a-870b-98b871e1ee54,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-28c0cd1d-4ebd-4f06-b5eb-2902b6fdcda2,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-b022c7a2-16ca-4d36-ae68-524ae21bde4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 30
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1860352171-172.17.0.11-1597377524210:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46111,DS-cf431b1e-8f82-4518-a80a-aa8c0ae53333,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-9d8c1354-c4dc-421f-950f-eb742484c11d,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-9760e172-cc3d-44cb-9364-f90b25ab8650,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-a7ae1fdc-4c5b-4dc9-8a9e-37217cbdf1da,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-d61d006a-bbba-44f2-8e09-c3a11bc1dc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-ace1b847-903f-49d5-88ff-cd742f30cadf,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-919dbf32-f584-400d-80c1-f0204bc66d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-76f5f220-c921-4b12-b1a1-d6abc5a4e994,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1860352171-172.17.0.11-1597377524210:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46111,DS-cf431b1e-8f82-4518-a80a-aa8c0ae53333,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-9d8c1354-c4dc-421f-950f-eb742484c11d,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-9760e172-cc3d-44cb-9364-f90b25ab8650,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-a7ae1fdc-4c5b-4dc9-8a9e-37217cbdf1da,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-d61d006a-bbba-44f2-8e09-c3a11bc1dc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-ace1b847-903f-49d5-88ff-cd742f30cadf,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-919dbf32-f584-400d-80c1-f0204bc66d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-76f5f220-c921-4b12-b1a1-d6abc5a4e994,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 7145
