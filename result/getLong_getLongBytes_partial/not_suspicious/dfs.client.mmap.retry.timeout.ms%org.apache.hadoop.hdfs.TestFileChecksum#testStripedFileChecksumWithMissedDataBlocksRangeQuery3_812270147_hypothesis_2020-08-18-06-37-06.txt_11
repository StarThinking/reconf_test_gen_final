reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-8211248-172.17.0.3-1597732759804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34070,DS-b8bc082e-e122-4d25-96a4-1ffb65b4ac20,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-53c37f3f-e157-4058-95fa-398dbfec0395,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-73670bfa-1081-4202-8482-02983a304dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-3c160b93-a59a-414f-b091-db205db5cbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-d10d4fe9-eb88-467c-b8c6-6e0c252d5036,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-c140b20d-e8ac-45d4-bd71-50e323596ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-d5519610-8957-448b-a499-360638a63bae,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-877bc01b-ecd6-4d91-9a06-19928632cfd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-8211248-172.17.0.3-1597732759804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34070,DS-b8bc082e-e122-4d25-96a4-1ffb65b4ac20,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-53c37f3f-e157-4058-95fa-398dbfec0395,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-73670bfa-1081-4202-8482-02983a304dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-3c160b93-a59a-414f-b091-db205db5cbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-d10d4fe9-eb88-467c-b8c6-6e0c252d5036,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-c140b20d-e8ac-45d4-bd71-50e323596ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-d5519610-8957-448b-a499-360638a63bae,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-877bc01b-ecd6-4d91-9a06-19928632cfd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235769988-172.17.0.3-1597734324722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33859,DS-6c2b7096-e748-4001-9189-17b9fcfedccd,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-98347065-fb42-470c-85ea-602ba33f2186,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-af3cb349-55c8-4bd5-9455-6febae699672,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-44ec9891-b64f-414c-97eb-53ff06d862d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-8c37312a-5712-4d21-927a-1c6144272814,DISK], DatanodeInfoWithStorage[127.0.0.1:46800,DS-42790ca6-d476-4705-bc42-aed918f1ee38,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-f4e49333-9ba5-4096-b740-804983126007,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-978ef3fc-35d4-4990-8326-879410f2310b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235769988-172.17.0.3-1597734324722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33859,DS-6c2b7096-e748-4001-9189-17b9fcfedccd,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-98347065-fb42-470c-85ea-602ba33f2186,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-af3cb349-55c8-4bd5-9455-6febae699672,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-44ec9891-b64f-414c-97eb-53ff06d862d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-8c37312a-5712-4d21-927a-1c6144272814,DISK], DatanodeInfoWithStorage[127.0.0.1:46800,DS-42790ca6-d476-4705-bc42-aed918f1ee38,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-f4e49333-9ba5-4096-b740-804983126007,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-978ef3fc-35d4-4990-8326-879410f2310b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-973140421-172.17.0.3-1597734412685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41438,DS-dad9bd45-215f-4bfb-a20f-68681b7e0424,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-8a175ba8-838c-4b03-b689-6cb716285cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-4c7097d0-c97f-485f-a110-ae54564e9868,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-6e1995d8-fa6f-491d-ba03-9a766429ddbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-d7501ea4-eed8-4aaf-b628-8e67e67c5ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-de4ef7fd-ce3c-44b0-9805-85acec044e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-68a03237-a2f0-47a3-bcba-cf9f421b4e20,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-8731010b-fde9-44a1-8de9-90ccf60545e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-973140421-172.17.0.3-1597734412685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41438,DS-dad9bd45-215f-4bfb-a20f-68681b7e0424,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-8a175ba8-838c-4b03-b689-6cb716285cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-4c7097d0-c97f-485f-a110-ae54564e9868,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-6e1995d8-fa6f-491d-ba03-9a766429ddbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-d7501ea4-eed8-4aaf-b628-8e67e67c5ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-de4ef7fd-ce3c-44b0-9805-85acec044e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-68a03237-a2f0-47a3-bcba-cf9f421b4e20,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-8731010b-fde9-44a1-8de9-90ccf60545e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1780181814-172.17.0.3-1597734445034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33657,DS-6cf7af82-068e-480b-afc4-4b378c3ff41e,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-ce72378c-dfb7-4edc-bdf4-f04a86c684c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-1a3bb80e-e1a3-46f6-84c4-277604d32f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-a734a735-4c21-4947-81f2-7b427d082e63,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-0a40d301-cfd2-4c49-a2e7-7416dd71d09a,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-56e41e4c-3fc0-449c-9636-71718b6a0462,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-d0f6f910-674c-4e86-83ab-b6ed4239e7db,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-7649f15a-4687-4c5f-96e0-d3ea123d773b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1780181814-172.17.0.3-1597734445034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33657,DS-6cf7af82-068e-480b-afc4-4b378c3ff41e,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-ce72378c-dfb7-4edc-bdf4-f04a86c684c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-1a3bb80e-e1a3-46f6-84c4-277604d32f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-a734a735-4c21-4947-81f2-7b427d082e63,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-0a40d301-cfd2-4c49-a2e7-7416dd71d09a,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-56e41e4c-3fc0-449c-9636-71718b6a0462,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-d0f6f910-674c-4e86-83ab-b6ed4239e7db,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-7649f15a-4687-4c5f-96e0-d3ea123d773b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-17039527-172.17.0.3-1597734547064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43561,DS-6643f1b5-e131-4806-ac06-c21d4de8dafa,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-370dea36-4ff2-493e-bde4-8a1826825e03,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-8be12fa5-3177-4077-949d-dce848b0e7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-30d964c6-9a84-4f11-a5c0-4dc0a39aff53,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-d9cf3579-6b16-42e6-b160-362c8d4e0287,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-726d7196-9fc5-4a19-861a-5e9d280ebf2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-2cc8ee4c-baeb-4d2e-91ef-b4cb65ab1078,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-8e20949d-be3e-4678-841f-f7887c215b1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-17039527-172.17.0.3-1597734547064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43561,DS-6643f1b5-e131-4806-ac06-c21d4de8dafa,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-370dea36-4ff2-493e-bde4-8a1826825e03,DISK], DatanodeInfoWithStorage[127.0.0.1:41972,DS-8be12fa5-3177-4077-949d-dce848b0e7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-30d964c6-9a84-4f11-a5c0-4dc0a39aff53,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-d9cf3579-6b16-42e6-b160-362c8d4e0287,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-726d7196-9fc5-4a19-861a-5e9d280ebf2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-2cc8ee4c-baeb-4d2e-91ef-b4cb65ab1078,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-8e20949d-be3e-4678-841f-f7887c215b1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-536506507-172.17.0.3-1597734736708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45782,DS-0567c6ad-9717-45c5-b25f-ae7897176d96,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-e992d9f9-3d42-44f9-a0fc-46c663703aba,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-f7305fb1-4712-4f68-8ea0-92b3f32f361d,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-65cfd52e-b619-4c1d-9952-77fd9c105e16,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-27827a2f-ccb7-4c42-a2ee-df920606f736,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-f3fe1999-0506-43a8-941b-a972b13b68fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-c40a0bd8-055a-48d6-a932-66a9790c6f54,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-66399426-0986-4ff4-a050-d97e66d44918,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-536506507-172.17.0.3-1597734736708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45782,DS-0567c6ad-9717-45c5-b25f-ae7897176d96,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-e992d9f9-3d42-44f9-a0fc-46c663703aba,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-f7305fb1-4712-4f68-8ea0-92b3f32f361d,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-65cfd52e-b619-4c1d-9952-77fd9c105e16,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-27827a2f-ccb7-4c42-a2ee-df920606f736,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-f3fe1999-0506-43a8-941b-a972b13b68fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-c40a0bd8-055a-48d6-a932-66a9790c6f54,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-66399426-0986-4ff4-a050-d97e66d44918,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-713966369-172.17.0.3-1597734991711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33023,DS-a3663758-b841-49a6-82fb-c9e4d1499a69,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-46588a6a-ee29-4285-9f2f-52b62e44978d,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-967f4b40-316d-4283-a60b-9ea8d82bd863,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-2b3c9f28-2c59-42b8-a9b6-a7d1f9333b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-bd8fb584-fb8b-4f29-90fa-cef3cd72fe11,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-68b48907-278e-4ec8-8b5d-0f5ebd9c1492,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-1c63b5d6-3111-4882-9453-a1b405a1c1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-4d1bf85c-5e78-4980-8fcf-4a13fe0e1733,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-713966369-172.17.0.3-1597734991711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33023,DS-a3663758-b841-49a6-82fb-c9e4d1499a69,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-46588a6a-ee29-4285-9f2f-52b62e44978d,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-967f4b40-316d-4283-a60b-9ea8d82bd863,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-2b3c9f28-2c59-42b8-a9b6-a7d1f9333b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-bd8fb584-fb8b-4f29-90fa-cef3cd72fe11,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-68b48907-278e-4ec8-8b5d-0f5ebd9c1492,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-1c63b5d6-3111-4882-9453-a1b405a1c1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-4d1bf85c-5e78-4980-8fcf-4a13fe0e1733,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1996536064-172.17.0.3-1597735034668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41966,DS-c8f8c82e-65fc-44ef-acce-72ab64aacca6,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-96f5d3c4-3927-45a5-a024-c56e6a05fb01,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-04248b3e-b378-44f7-9a6c-3120d7f0c9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-c91f53fb-d4e1-4de2-9caf-25ada0c51401,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-3caa8839-27fb-4178-b24e-6a3865649e72,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-86a8af2e-3c8f-41e1-91ac-15d3e7ee8d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-b586037e-7b73-43f8-acf3-63368fdff290,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-e6d65432-f932-4247-9ff4-16271675fd0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1996536064-172.17.0.3-1597735034668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41966,DS-c8f8c82e-65fc-44ef-acce-72ab64aacca6,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-96f5d3c4-3927-45a5-a024-c56e6a05fb01,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-04248b3e-b378-44f7-9a6c-3120d7f0c9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-c91f53fb-d4e1-4de2-9caf-25ada0c51401,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-3caa8839-27fb-4178-b24e-6a3865649e72,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-86a8af2e-3c8f-41e1-91ac-15d3e7ee8d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-b586037e-7b73-43f8-acf3-63368fdff290,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-e6d65432-f932-4247-9ff4-16271675fd0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061024992-172.17.0.3-1597735153188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35837,DS-5e7e7146-73cc-4325-ad67-b260dddde9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35561,DS-ead2a95d-dace-439f-a43a-a9c8036148e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-db6fb7d3-7d58-47fd-8e83-afed75cfa3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-2f7bc249-646d-4f7c-8410-102c977ce86d,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-6e0a64ae-12be-4326-8746-fa42ae095bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-f01522fd-58fd-432d-8ed5-8e2b8cfce869,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-359e9f42-ebd6-4fcd-bd3f-99c70d947701,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-db7dc3fc-3941-407a-9159-919cc0e894ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061024992-172.17.0.3-1597735153188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35837,DS-5e7e7146-73cc-4325-ad67-b260dddde9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35561,DS-ead2a95d-dace-439f-a43a-a9c8036148e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-db6fb7d3-7d58-47fd-8e83-afed75cfa3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-2f7bc249-646d-4f7c-8410-102c977ce86d,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-6e0a64ae-12be-4326-8746-fa42ae095bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-f01522fd-58fd-432d-8ed5-8e2b8cfce869,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-359e9f42-ebd6-4fcd-bd3f-99c70d947701,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-db7dc3fc-3941-407a-9159-919cc0e894ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2008378634-172.17.0.3-1597735191240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45212,DS-683dc581-0c6f-43dc-a4e0-9de08523df20,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-1dfee5ba-f944-4020-8115-5344e25bfd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-4cb73bc8-b051-4daa-9330-6f135b3684c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-032da85d-1892-4b73-9603-4f5c10cf643a,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-716eb6b6-68a4-4e13-a36d-108b4efe047b,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-58ee1d91-9372-443e-8748-06afc53f181b,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-ba8fea9b-8cc7-4089-9f98-4ca778a20242,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-513c8e8b-03a3-4043-923f-07aa8e28817d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2008378634-172.17.0.3-1597735191240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45212,DS-683dc581-0c6f-43dc-a4e0-9de08523df20,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-1dfee5ba-f944-4020-8115-5344e25bfd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-4cb73bc8-b051-4daa-9330-6f135b3684c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-032da85d-1892-4b73-9603-4f5c10cf643a,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-716eb6b6-68a4-4e13-a36d-108b4efe047b,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-58ee1d91-9372-443e-8748-06afc53f181b,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-ba8fea9b-8cc7-4089-9f98-4ca778a20242,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-513c8e8b-03a3-4043-923f-07aa8e28817d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-200448808-172.17.0.3-1597735268463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36455,DS-f7f1184c-5167-4096-844b-aff0bad84c37,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-c641c0f9-add4-49a4-9ba2-3057395759f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-dd5649fc-e4f9-4322-be91-3e7f0034bb71,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-8b9d41d2-ab67-4d56-a03f-b997e55e4c59,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-85739b2f-25dd-4019-830e-a3f17bb6f673,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-b6f0adbe-f215-4d37-afc2-54436e5d35c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-785dccce-b25d-4657-9ea5-d2a5e14c3b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-946e3e9e-16e5-456e-840f-87d4d070f2e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-200448808-172.17.0.3-1597735268463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36455,DS-f7f1184c-5167-4096-844b-aff0bad84c37,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-c641c0f9-add4-49a4-9ba2-3057395759f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-dd5649fc-e4f9-4322-be91-3e7f0034bb71,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-8b9d41d2-ab67-4d56-a03f-b997e55e4c59,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-85739b2f-25dd-4019-830e-a3f17bb6f673,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-b6f0adbe-f215-4d37-afc2-54436e5d35c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-785dccce-b25d-4657-9ea5-d2a5e14c3b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-946e3e9e-16e5-456e-840f-87d4d070f2e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105175775-172.17.0.3-1597735761001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46375,DS-6f99204a-464e-4105-b365-f23bb56ff7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-5c4e2069-faab-4513-9f0b-f810706cd70a,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-df5d5c5a-4257-488d-86ed-2807ef8e4d29,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-67ecfaa3-7a58-4f48-9921-80dca7766a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-4a3de6b5-03dd-4834-860c-e0e4efaa33b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-0eacb0f3-b4cb-4a6e-8d9a-c86931e495c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-69da91ea-28c8-4441-8b6f-d990d24048ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-12e95535-a840-4c5e-9320-d19fe7d06ae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105175775-172.17.0.3-1597735761001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46375,DS-6f99204a-464e-4105-b365-f23bb56ff7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-5c4e2069-faab-4513-9f0b-f810706cd70a,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-df5d5c5a-4257-488d-86ed-2807ef8e4d29,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-67ecfaa3-7a58-4f48-9921-80dca7766a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-4a3de6b5-03dd-4834-860c-e0e4efaa33b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-0eacb0f3-b4cb-4a6e-8d9a-c86931e495c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-69da91ea-28c8-4441-8b6f-d990d24048ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-12e95535-a840-4c5e-9320-d19fe7d06ae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-582322278-172.17.0.3-1597735836679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46431,DS-6660f619-b3f0-4061-9f03-1d12f4e186fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-b2382507-f8db-4856-8a26-8dbcd7d238f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-44f414d3-8e57-41d6-a5d8-019a85fa0219,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-7cc09905-39b2-4429-b4bd-ce52c8371f18,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-5ea91bcc-66bb-4cde-8754-24ba3bdb2786,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-baa6296e-a028-40f7-b234-78171cb24508,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-4a335bb3-0582-407f-982d-1ad87918bc79,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-01e40465-9f40-45cc-8b37-80ef0ba93e1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-582322278-172.17.0.3-1597735836679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46431,DS-6660f619-b3f0-4061-9f03-1d12f4e186fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-b2382507-f8db-4856-8a26-8dbcd7d238f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-44f414d3-8e57-41d6-a5d8-019a85fa0219,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-7cc09905-39b2-4429-b4bd-ce52c8371f18,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-5ea91bcc-66bb-4cde-8754-24ba3bdb2786,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-baa6296e-a028-40f7-b234-78171cb24508,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-4a335bb3-0582-407f-982d-1ad87918bc79,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-01e40465-9f40-45cc-8b37-80ef0ba93e1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535076410-172.17.0.3-1597736581708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43016,DS-e017fb39-7217-4a29-bc5a-3687b225e835,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-330cba77-566c-46ee-9b2e-81d09b35acf7,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-111a07dc-1371-4f53-8b87-71e229a1be8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-edfed3f6-9ed5-45db-89ff-cbadc1475fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-e72dda8e-cbbe-4b4c-8c0c-246ab07d7734,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-fba4b72c-b24e-4b53-864a-4908d8d0feb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-8e6e0ef1-936c-49ac-b1ad-f159f68d9c35,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-95f38a57-c096-4f6c-bbc8-7a50fbd25e17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1535076410-172.17.0.3-1597736581708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43016,DS-e017fb39-7217-4a29-bc5a-3687b225e835,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-330cba77-566c-46ee-9b2e-81d09b35acf7,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-111a07dc-1371-4f53-8b87-71e229a1be8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-edfed3f6-9ed5-45db-89ff-cbadc1475fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-e72dda8e-cbbe-4b4c-8c0c-246ab07d7734,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-fba4b72c-b24e-4b53-864a-4908d8d0feb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-8e6e0ef1-936c-49ac-b1ad-f159f68d9c35,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-95f38a57-c096-4f6c-bbc8-7a50fbd25e17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1273968647-172.17.0.3-1597736964123:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32887,DS-a19a7df2-c0a0-4065-b5ff-6844303e9a27,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-d5c253d4-a8b3-456b-acd8-3813c5203ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-5c75c357-cb83-4411-8745-f5001de02fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-81a89d78-126a-4966-ba31-8d78b95a0dde,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-ff9d087c-117b-4102-a9a9-45794963d8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-fa3113d4-2c71-4951-a7f3-eed0d2bb7109,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-b256512f-c1a5-4000-8fa8-c44ba3d43917,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-b5347471-87c4-4b99-9ac6-71f80cc5be28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1273968647-172.17.0.3-1597736964123:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32887,DS-a19a7df2-c0a0-4065-b5ff-6844303e9a27,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-d5c253d4-a8b3-456b-acd8-3813c5203ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-5c75c357-cb83-4411-8745-f5001de02fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-81a89d78-126a-4966-ba31-8d78b95a0dde,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-ff9d087c-117b-4102-a9a9-45794963d8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-fa3113d4-2c71-4951-a7f3-eed0d2bb7109,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-b256512f-c1a5-4000-8fa8-c44ba3d43917,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-b5347471-87c4-4b99-9ac6-71f80cc5be28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1417253244-172.17.0.3-1597737858683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36417,DS-cd893bf3-77ba-4b99-b2b5-a25b84ca470d,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-1d2efcd0-e14f-4a7c-a195-e9d038d1637a,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-5548f9c8-6d6c-407c-95c7-0833b795a603,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-60801641-0f4f-497c-a741-ebc042758bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-30dc6ba3-ffcd-4794-ab5f-2328d551b980,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-68c34a96-ae6b-48ae-9647-14dc2630e649,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-09d1a340-4370-47bb-b1e9-d85eff8c38f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-9d2f6491-3f28-4b12-a941-fe8a79ca271b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1417253244-172.17.0.3-1597737858683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36417,DS-cd893bf3-77ba-4b99-b2b5-a25b84ca470d,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-1d2efcd0-e14f-4a7c-a195-e9d038d1637a,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-5548f9c8-6d6c-407c-95c7-0833b795a603,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-60801641-0f4f-497c-a741-ebc042758bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-30dc6ba3-ffcd-4794-ab5f-2328d551b980,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-68c34a96-ae6b-48ae-9647-14dc2630e649,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-09d1a340-4370-47bb-b1e9-d85eff8c38f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-9d2f6491-3f28-4b12-a941-fe8a79ca271b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 500000
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1329932532-172.17.0.3-1597738078464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41771,DS-c24b13c7-937f-40c8-bd7f-fac976a0ed45,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-a9e2db32-f8e1-4be2-a7bd-eb2fb8f428f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-cba77e70-1c46-45f6-bdfb-ecccce389129,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-cbff5cc5-bf0f-46a5-8112-530a72003a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-634cb02c-aa72-4fac-9ce7-d4042f4bd693,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-1ce984b9-3264-4866-9e28-e6b6d785b320,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-a0245650-4289-4d89-999a-1a55704c4106,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-8a13657c-75f7-4fc3-916c-26f130645e4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1329932532-172.17.0.3-1597738078464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41771,DS-c24b13c7-937f-40c8-bd7f-fac976a0ed45,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-a9e2db32-f8e1-4be2-a7bd-eb2fb8f428f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-cba77e70-1c46-45f6-bdfb-ecccce389129,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-cbff5cc5-bf0f-46a5-8112-530a72003a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-634cb02c-aa72-4fac-9ce7-d4042f4bd693,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-1ce984b9-3264-4866-9e28-e6b6d785b320,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-a0245650-4289-4d89-999a-1a55704c4106,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-8a13657c-75f7-4fc3-916c-26f130645e4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5780
