reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2036474350-172.17.0.15-1597733929615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36048,DS-c8c04e7d-1092-4da7-9aa4-2af2bb8ebc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-294cd170-cdee-44d4-b1f0-547797a2f233,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-1fad778f-ebd2-4dac-bacd-7946a83cb94c,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-533af7b1-93bb-45e4-9a58-ad540803cece,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-81900964-d4aa-475c-8f22-30074073d33a,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-5ae7d7f1-e129-44b9-8ae3-51aadfc08597,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-3e87e83c-22a2-4765-afbf-845c4cb9165d,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-00070c97-c854-4e69-b364-6efe645882c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2036474350-172.17.0.15-1597733929615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36048,DS-c8c04e7d-1092-4da7-9aa4-2af2bb8ebc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-294cd170-cdee-44d4-b1f0-547797a2f233,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-1fad778f-ebd2-4dac-bacd-7946a83cb94c,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-533af7b1-93bb-45e4-9a58-ad540803cece,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-81900964-d4aa-475c-8f22-30074073d33a,DISK], DatanodeInfoWithStorage[127.0.0.1:34810,DS-5ae7d7f1-e129-44b9-8ae3-51aadfc08597,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-3e87e83c-22a2-4765-afbf-845c4cb9165d,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-00070c97-c854-4e69-b364-6efe645882c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-210136329-172.17.0.15-1597734218060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44454,DS-da77c283-366e-46aa-af37-29e96ed247a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-911d6fba-898f-44b8-ba2d-31c88e46b89b,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-827c58ee-2fb7-4085-a1cd-2a5677c8396f,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-cb926306-2a6b-44c0-9904-7b314d9b3223,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-6f46afe6-71ef-460a-bf3a-dffbf0fb02cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-05bc0fc2-8e08-4552-80d6-bd510338a0be,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-ad2092ad-f2c1-41d8-9b1d-73ac331aa629,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-b56e030c-576f-4f44-b52b-9133e614b7a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-210136329-172.17.0.15-1597734218060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44454,DS-da77c283-366e-46aa-af37-29e96ed247a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-911d6fba-898f-44b8-ba2d-31c88e46b89b,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-827c58ee-2fb7-4085-a1cd-2a5677c8396f,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-cb926306-2a6b-44c0-9904-7b314d9b3223,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-6f46afe6-71ef-460a-bf3a-dffbf0fb02cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-05bc0fc2-8e08-4552-80d6-bd510338a0be,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-ad2092ad-f2c1-41d8-9b1d-73ac331aa629,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-b56e030c-576f-4f44-b52b-9133e614b7a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-532060251-172.17.0.15-1597734733232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36715,DS-d829d146-a6d8-41ff-82de-74a982f5e6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-0bf64fab-1921-41af-aff2-d073ad763628,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-8d53da97-3e82-42f6-9ef7-6121f4b7b8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-08ee8f9a-4ac0-41e1-88a4-41c277259bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-1abc791b-91df-4e9d-9f3e-2300deb5df71,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-64da06f9-9c9d-49ba-8619-3439316cbc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-434726c1-1f45-4356-bd67-638d4886cf95,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-2afa8b9c-03cb-4453-a0c6-c9a08ef18d49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-532060251-172.17.0.15-1597734733232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36715,DS-d829d146-a6d8-41ff-82de-74a982f5e6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-0bf64fab-1921-41af-aff2-d073ad763628,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-8d53da97-3e82-42f6-9ef7-6121f4b7b8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-08ee8f9a-4ac0-41e1-88a4-41c277259bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-1abc791b-91df-4e9d-9f3e-2300deb5df71,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-64da06f9-9c9d-49ba-8619-3439316cbc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-434726c1-1f45-4356-bd67-638d4886cf95,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-2afa8b9c-03cb-4453-a0c6-c9a08ef18d49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1744565771-172.17.0.15-1597735091344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43180,DS-59b1232d-c23b-4989-9441-169314fdb3db,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-2eae3451-da7e-480d-8574-bcf3e54fe9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-bc5c8540-e4f4-4dfb-b1dc-6c0d3a948902,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-7c5d5a47-546f-4b03-a5a5-e7516f73af9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-ad6fe4c0-8c1b-40b0-8f19-2f04d6a56322,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-61de9f07-0a9b-479a-840d-91374c717067,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-598265d9-7074-4073-b12e-9523665a7af6,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-c3d3a550-2488-48d3-a665-82792df9fff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1744565771-172.17.0.15-1597735091344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43180,DS-59b1232d-c23b-4989-9441-169314fdb3db,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-2eae3451-da7e-480d-8574-bcf3e54fe9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-bc5c8540-e4f4-4dfb-b1dc-6c0d3a948902,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-7c5d5a47-546f-4b03-a5a5-e7516f73af9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-ad6fe4c0-8c1b-40b0-8f19-2f04d6a56322,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-61de9f07-0a9b-479a-840d-91374c717067,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-598265d9-7074-4073-b12e-9523665a7af6,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-c3d3a550-2488-48d3-a665-82792df9fff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1433741583-172.17.0.15-1597735478582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33257,DS-bd9ad9ec-c4dc-4d13-8e64-8516ae70291a,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-58c5c76a-1e01-4836-8336-75ec0a128495,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-7980d980-03ff-4266-943d-4903a7dc0c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-6587e018-33b8-4dfc-8746-b5673da3cb74,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-3d1a5ef5-e0fb-4b71-b0a1-ac31a3ee9841,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-a479392c-97ca-440d-b042-bd282dee3e51,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-8b9f38eb-15d7-4803-a23a-3a7b9d6fa4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-a0c6d42e-3565-4b3b-83a6-6860216a4aa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1433741583-172.17.0.15-1597735478582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33257,DS-bd9ad9ec-c4dc-4d13-8e64-8516ae70291a,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-58c5c76a-1e01-4836-8336-75ec0a128495,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-7980d980-03ff-4266-943d-4903a7dc0c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-6587e018-33b8-4dfc-8746-b5673da3cb74,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-3d1a5ef5-e0fb-4b71-b0a1-ac31a3ee9841,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-a479392c-97ca-440d-b042-bd282dee3e51,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-8b9f38eb-15d7-4803-a23a-3a7b9d6fa4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-a0c6d42e-3565-4b3b-83a6-6860216a4aa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561500250-172.17.0.15-1597735551992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45627,DS-30fa70ba-9056-4214-99b4-69a24d33d735,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-567c6c67-422f-41da-879a-d2120b675a54,DISK], DatanodeInfoWithStorage[127.0.0.1:40407,DS-67f12cfd-4adb-453c-915e-21b5ca26e7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-cd071a8e-f587-45ef-a7c5-309448d5fb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-3af9f0ab-dd1e-45c6-926d-bbde12e77a31,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-d1d5a15f-8ded-4a15-a1c4-bee5a8f1ea5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-1f58b288-1401-48a2-a21e-721c0aa5d9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-30298735-82a0-45bb-8223-a5f4f4dd4c81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561500250-172.17.0.15-1597735551992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45627,DS-30fa70ba-9056-4214-99b4-69a24d33d735,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-567c6c67-422f-41da-879a-d2120b675a54,DISK], DatanodeInfoWithStorage[127.0.0.1:40407,DS-67f12cfd-4adb-453c-915e-21b5ca26e7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-cd071a8e-f587-45ef-a7c5-309448d5fb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-3af9f0ab-dd1e-45c6-926d-bbde12e77a31,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-d1d5a15f-8ded-4a15-a1c4-bee5a8f1ea5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-1f58b288-1401-48a2-a21e-721c0aa5d9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-30298735-82a0-45bb-8223-a5f4f4dd4c81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1696304141-172.17.0.15-1597735689056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44371,DS-322a808f-ea98-4c09-8ef0-0bf9e300cc73,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-7ae90697-d80d-41aa-8b44-80f406078305,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-25e612d9-e4ca-46d7-a6d9-81e950b3596f,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-dd49f55e-f419-4bb2-90bc-409de0689e31,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-89c8bb63-1414-460e-8163-8852e3811b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-e41298e0-b36b-4e09-ae0b-f35c09239159,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-582087f8-bffe-444c-a6e9-31637172356f,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-ae5efb9d-7bd1-4bfe-939d-2c1bed7ec41c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1696304141-172.17.0.15-1597735689056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44371,DS-322a808f-ea98-4c09-8ef0-0bf9e300cc73,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-7ae90697-d80d-41aa-8b44-80f406078305,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-25e612d9-e4ca-46d7-a6d9-81e950b3596f,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-dd49f55e-f419-4bb2-90bc-409de0689e31,DISK], DatanodeInfoWithStorage[127.0.0.1:36862,DS-89c8bb63-1414-460e-8163-8852e3811b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44364,DS-e41298e0-b36b-4e09-ae0b-f35c09239159,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-582087f8-bffe-444c-a6e9-31637172356f,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-ae5efb9d-7bd1-4bfe-939d-2c1bed7ec41c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1771742236-172.17.0.15-1597736075525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46649,DS-d46a025f-7c33-48de-a1e8-1e02208bfdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-391178f8-b802-42f1-a2e4-22fb3bab8047,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-215a0bdb-081b-40a3-a462-3120ceb43bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-93245740-357c-441b-a4e7-e7dc8544c184,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-de3831eb-187a-45e0-91a1-2812b3677891,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-53a28ed5-c4b5-4783-bfcc-7eea8ca5d702,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-70cbda81-3967-4df4-a3b4-c61b32bd64ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-abea3595-665c-4a3f-bda7-52359f75e46c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1771742236-172.17.0.15-1597736075525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46649,DS-d46a025f-7c33-48de-a1e8-1e02208bfdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-391178f8-b802-42f1-a2e4-22fb3bab8047,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-215a0bdb-081b-40a3-a462-3120ceb43bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-93245740-357c-441b-a4e7-e7dc8544c184,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-de3831eb-187a-45e0-91a1-2812b3677891,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-53a28ed5-c4b5-4783-bfcc-7eea8ca5d702,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-70cbda81-3967-4df4-a3b4-c61b32bd64ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-abea3595-665c-4a3f-bda7-52359f75e46c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040549639-172.17.0.15-1597736338987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34811,DS-e46c3075-3d30-47e7-bec1-0b4ddcb06db6,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-876cc630-66b8-461a-a514-d49ef7264181,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-7cfabf87-aebd-4d8e-9c9d-2d088986804c,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-170bf18c-995d-4278-b649-34aa700a8143,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-5d19706b-d2a0-434b-bbb3-ede9d66dcd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-86b1bbc2-ec3a-4dc9-b607-79a9202783fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-5846aa5d-0ce8-49d9-b28b-942ddadb41e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-f3478c97-d364-4470-861f-db9736a65a80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040549639-172.17.0.15-1597736338987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34811,DS-e46c3075-3d30-47e7-bec1-0b4ddcb06db6,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-876cc630-66b8-461a-a514-d49ef7264181,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-7cfabf87-aebd-4d8e-9c9d-2d088986804c,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-170bf18c-995d-4278-b649-34aa700a8143,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-5d19706b-d2a0-434b-bbb3-ede9d66dcd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-86b1bbc2-ec3a-4dc9-b607-79a9202783fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-5846aa5d-0ce8-49d9-b28b-942ddadb41e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-f3478c97-d364-4470-861f-db9736a65a80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1010148495-172.17.0.15-1597736373197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36903,DS-6803766b-6238-4212-bcab-7d0c33a6f9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-69aaeba7-1b9f-4c84-a1ea-9e8be92a4178,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-dfbf5aeb-df53-46ab-a215-5d3128a150c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-069ed592-b0e0-4310-be93-bb14b2caaefd,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-496b57f5-45ae-4285-8679-a95313ed79d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42986,DS-d718dd25-de60-46c2-9d88-7567ecc5983e,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-533030ff-2d9f-46c0-921d-f835adf666a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-73cc295b-db68-433e-91fc-41fd88ad2afe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1010148495-172.17.0.15-1597736373197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36903,DS-6803766b-6238-4212-bcab-7d0c33a6f9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-69aaeba7-1b9f-4c84-a1ea-9e8be92a4178,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-dfbf5aeb-df53-46ab-a215-5d3128a150c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-069ed592-b0e0-4310-be93-bb14b2caaefd,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-496b57f5-45ae-4285-8679-a95313ed79d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42986,DS-d718dd25-de60-46c2-9d88-7567ecc5983e,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-533030ff-2d9f-46c0-921d-f835adf666a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-73cc295b-db68-433e-91fc-41fd88ad2afe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-105959506-172.17.0.15-1597736711407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43754,DS-0c192256-828d-430f-bf88-a49616578fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38622,DS-c95f1f8f-e04d-4b35-9dd0-0de948d2121f,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-6553f5e5-9f86-420e-9491-a7bbe04b1b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-cbf89eb9-dfc0-4a94-8fcf-91c6a0502633,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-2be68f66-9378-4c71-8202-51f42ac91e63,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-71a11d57-009d-4ba7-ab97-b396cfe9dbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-c6147840-2539-4c88-ac4e-598323c45026,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-b2eb9fba-d24e-411d-95b0-66df93dc7c36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-105959506-172.17.0.15-1597736711407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43754,DS-0c192256-828d-430f-bf88-a49616578fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38622,DS-c95f1f8f-e04d-4b35-9dd0-0de948d2121f,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-6553f5e5-9f86-420e-9491-a7bbe04b1b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-cbf89eb9-dfc0-4a94-8fcf-91c6a0502633,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-2be68f66-9378-4c71-8202-51f42ac91e63,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-71a11d57-009d-4ba7-ab97-b396cfe9dbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-c6147840-2539-4c88-ac4e-598323c45026,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-b2eb9fba-d24e-411d-95b0-66df93dc7c36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356644110-172.17.0.15-1597736747571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38400,DS-5b04fa2b-fd94-44ea-a31c-65096343cfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-517be471-0a4d-4865-8332-3a6452ae3554,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-9f95665e-e639-4492-87b2-c612fe9bc81c,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-6d2a3cef-0a44-484e-be3c-cc995dc8d184,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-24fb8d5e-779a-476b-a6c1-9f0696920081,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-fa3c017b-081e-4688-8e09-c229d581527b,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-9e392009-2b6f-4f75-8368-6ed4dd79e003,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-cb92f03a-bba3-41e4-a649-625568c6ed26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356644110-172.17.0.15-1597736747571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38400,DS-5b04fa2b-fd94-44ea-a31c-65096343cfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-517be471-0a4d-4865-8332-3a6452ae3554,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-9f95665e-e639-4492-87b2-c612fe9bc81c,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-6d2a3cef-0a44-484e-be3c-cc995dc8d184,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-24fb8d5e-779a-476b-a6c1-9f0696920081,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-fa3c017b-081e-4688-8e09-c229d581527b,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-9e392009-2b6f-4f75-8368-6ed4dd79e003,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-cb92f03a-bba3-41e4-a649-625568c6ed26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1543650586-172.17.0.15-1597737080008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36967,DS-42fed636-5ffc-4ea7-9b6d-8ac91071390c,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-f3718ff4-036f-4886-9b76-3e5e1eba5a25,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-e1468150-6a18-4f75-8c85-86e465c89b92,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-1f50c0c0-1e9d-4303-91d6-5f84483a14c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-ee9d265a-49ef-425d-bfd1-7282b69c30a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-b249f1d9-b312-4c56-9ab5-3882c03144fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-6679bcb1-edf5-4234-a2c1-aa192921b4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-baa3f9eb-7032-48ef-8f86-0e28714bf24d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1543650586-172.17.0.15-1597737080008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36967,DS-42fed636-5ffc-4ea7-9b6d-8ac91071390c,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-f3718ff4-036f-4886-9b76-3e5e1eba5a25,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-e1468150-6a18-4f75-8c85-86e465c89b92,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-1f50c0c0-1e9d-4303-91d6-5f84483a14c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-ee9d265a-49ef-425d-bfd1-7282b69c30a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-b249f1d9-b312-4c56-9ab5-3882c03144fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-6679bcb1-edf5-4234-a2c1-aa192921b4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-baa3f9eb-7032-48ef-8f86-0e28714bf24d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1180770800-172.17.0.15-1597737150607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42043,DS-c6f2027a-f8dd-4f38-8cb5-cd20dc38b143,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-605219dd-e2de-486e-94c7-c2092472fb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-04831017-90f0-45f8-aade-8bc45192cc12,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-a89a32a7-fbe0-4f82-903d-d4d020a65f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-e273ee5e-705e-40ee-8e8b-5884f506055a,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-205ebaf2-0c2e-4447-a9f6-de934d683e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-67b157f3-c133-434e-bbd4-f62676d45bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-07e6167b-f237-408e-bbfb-b083ac58bc51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1180770800-172.17.0.15-1597737150607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42043,DS-c6f2027a-f8dd-4f38-8cb5-cd20dc38b143,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-605219dd-e2de-486e-94c7-c2092472fb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-04831017-90f0-45f8-aade-8bc45192cc12,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-a89a32a7-fbe0-4f82-903d-d4d020a65f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-e273ee5e-705e-40ee-8e8b-5884f506055a,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-205ebaf2-0c2e-4447-a9f6-de934d683e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-67b157f3-c133-434e-bbd4-f62676d45bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-07e6167b-f237-408e-bbfb-b083ac58bc51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-118187880-172.17.0.15-1597737446205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44006,DS-1dc0c607-c4c1-4aad-8d29-a4c10020c59a,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-6486f63d-1e05-4e1e-bdd0-6f6a0936a59d,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-c831a6ff-8b0b-47b9-b1a4-012a05458279,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-b7da404d-064e-40ee-8332-8a58848b29de,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-6d507d2c-52b3-4cd4-b95a-c6eef00bda21,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-4e4ec557-e19e-414b-b3e6-696f04691d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-dace9874-b5c9-4e93-b488-4a2ea4257ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-965c2b51-1a2e-4c74-b563-902355fd56dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-118187880-172.17.0.15-1597737446205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44006,DS-1dc0c607-c4c1-4aad-8d29-a4c10020c59a,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-6486f63d-1e05-4e1e-bdd0-6f6a0936a59d,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-c831a6ff-8b0b-47b9-b1a4-012a05458279,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-b7da404d-064e-40ee-8332-8a58848b29de,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-6d507d2c-52b3-4cd4-b95a-c6eef00bda21,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-4e4ec557-e19e-414b-b3e6-696f04691d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-dace9874-b5c9-4e93-b488-4a2ea4257ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-965c2b51-1a2e-4c74-b563-902355fd56dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1718379466-172.17.0.15-1597737523363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35491,DS-2265cf64-c6ee-4d7f-be70-903d85d4e69c,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-198ece8f-220c-4089-9d2b-044e2e701201,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-276b22a8-7c4c-4e1b-ae13-4a4fa38bdc10,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-f2860703-7a57-4a7e-a812-44558044d474,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-43e27080-646a-4f33-83c1-e6ae152eff17,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-4ac6dcf3-96fb-4766-8f1a-b8733d5108db,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-4adf66e7-ce89-42ad-a430-641f401a6287,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-dd277e5f-372d-431a-b455-3efcbf082f7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1718379466-172.17.0.15-1597737523363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35491,DS-2265cf64-c6ee-4d7f-be70-903d85d4e69c,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-198ece8f-220c-4089-9d2b-044e2e701201,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-276b22a8-7c4c-4e1b-ae13-4a4fa38bdc10,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-f2860703-7a57-4a7e-a812-44558044d474,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-43e27080-646a-4f33-83c1-e6ae152eff17,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-4ac6dcf3-96fb-4766-8f1a-b8733d5108db,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-4adf66e7-ce89-42ad-a430-641f401a6287,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-dd277e5f-372d-431a-b455-3efcbf082f7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-986814267-172.17.0.15-1597738026681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44385,DS-1fcdec89-5f74-46f6-9878-58939746bf15,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-9a0558d6-db09-475c-9d4e-d707296cb2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-4fcca2ff-2934-4ef5-b81b-3b3348f083e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-0ad8345b-27a3-4e6c-b702-ddb83128d948,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-79443c4b-0fbe-43d2-bbb6-e96a5b779f10,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-a38dc86a-c833-402e-9bd6-159ab347a855,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-d42218f7-f246-49f4-ba37-bc9d082eb968,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-f02c2168-9b09-42c9-8a8c-04e955d58af8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-986814267-172.17.0.15-1597738026681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44385,DS-1fcdec89-5f74-46f6-9878-58939746bf15,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-9a0558d6-db09-475c-9d4e-d707296cb2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-4fcca2ff-2934-4ef5-b81b-3b3348f083e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-0ad8345b-27a3-4e6c-b702-ddb83128d948,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-79443c4b-0fbe-43d2-bbb6-e96a5b779f10,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-a38dc86a-c833-402e-9bd6-159ab347a855,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-d42218f7-f246-49f4-ba37-bc9d082eb968,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-f02c2168-9b09-42c9-8a8c-04e955d58af8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-680501751-172.17.0.15-1597738526991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37218,DS-4bf10f2d-97c0-4df0-8496-366089494d21,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-ae5a12f2-3b2e-4c7f-bb2d-c5ada369534a,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-319ed72e-8e0d-4990-9aaf-3d931aa07fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-973dd705-214d-4979-9bde-23882b5864dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-a3e4abe3-0673-4cfd-9a8e-16fd15f98758,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-e61640f9-677c-45f1-9106-80ef8c463a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-24a93ee4-cecf-4c97-8e92-3c843b2c19dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-3344c3cc-b4ff-4310-ba06-52fe72e91b92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-680501751-172.17.0.15-1597738526991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37218,DS-4bf10f2d-97c0-4df0-8496-366089494d21,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-ae5a12f2-3b2e-4c7f-bb2d-c5ada369534a,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-319ed72e-8e0d-4990-9aaf-3d931aa07fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-973dd705-214d-4979-9bde-23882b5864dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-a3e4abe3-0673-4cfd-9a8e-16fd15f98758,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-e61640f9-677c-45f1-9106-80ef8c463a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-24a93ee4-cecf-4c97-8e92-3c843b2c19dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-3344c3cc-b4ff-4310-ba06-52fe72e91b92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.path.based.cache.retry.interval.ms
component: hdfs:NameNode
v1: 60000
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148778142-172.17.0.15-1597739206456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35693,DS-2b7199c3-1326-47b5-b421-7b9640ea8bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-145a75ce-bb98-4e67-8ea0-c22fbe2b202d,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-570941fd-a584-4a70-b0bc-56a82bdee0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-bbd68bae-30f4-4b86-a947-e77727066436,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-1c856849-f82e-4d3c-b861-d41682490f76,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-dfb7aafc-ad15-4254-b39d-97aa66239e10,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-d72c8922-79b9-495e-9190-31a6350dc359,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-fb3498bc-26e1-46e4-8e32-e391b4b23313,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148778142-172.17.0.15-1597739206456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35693,DS-2b7199c3-1326-47b5-b421-7b9640ea8bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-145a75ce-bb98-4e67-8ea0-c22fbe2b202d,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-570941fd-a584-4a70-b0bc-56a82bdee0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-bbd68bae-30f4-4b86-a947-e77727066436,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-1c856849-f82e-4d3c-b861-d41682490f76,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-dfb7aafc-ad15-4254-b39d-97aa66239e10,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-d72c8922-79b9-495e-9190-31a6350dc359,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-fb3498bc-26e1-46e4-8e32-e391b4b23313,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5384
