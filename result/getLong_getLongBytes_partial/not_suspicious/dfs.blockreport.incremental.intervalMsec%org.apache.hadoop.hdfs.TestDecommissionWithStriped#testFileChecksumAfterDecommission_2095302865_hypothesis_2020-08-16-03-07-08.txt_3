reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestDecommissionWithStriped#testFileChecksumAfterDecommission
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestDecommissionWithStriped#testFileChecksumAfterDecommission
reconfPoint: -1
result: -1
failureMessage: expected:<9> but was:<10>
stackTrace: java.lang.AssertionError: expected:<9> but was:<10>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.hadoop.hdfs.TestDecommissionWithStriped.testFileChecksumAfterDecommission(TestDecommissionWithStriped.java:304)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestDecommissionWithStriped#testFileChecksumAfterDecommission
reconfPoint: -1
result: -1
failureMessage: expected:<9> but was:<10>
stackTrace: java.lang.AssertionError: expected:<9> but was:<10>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.hadoop.hdfs.TestDecommissionWithStriped.testFileChecksumAfterDecommission(TestDecommissionWithStriped.java:304)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestDecommissionWithStriped#testFileChecksumAfterDecommission
reconfPoint: -1
result: -1
failureMessage: expected:<9> but was:<10>
stackTrace: java.lang.AssertionError: expected:<9> but was:<10>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.hadoop.hdfs.TestDecommissionWithStriped.testFileChecksumAfterDecommission(TestDecommissionWithStriped.java:304)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestDecommissionWithStriped#testFileChecksumAfterDecommission
reconfPoint: -1
result: -1
failureMessage: `/TestDecommissionWithStriped/testFileChecksumAfterDecommission': Fail to get block checksum for LocatedStripedBlock{BP-872825910-172.17.0.18-1597547793755:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43467,DS-c21599ee-29a6-41a5-b267-b1e96b342eff,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-b3d5e8b5-b3b4-4dba-b607-3c4a5f262a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-358243be-c63a-4eca-a919-93d4843ff2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-cb57f634-0812-467e-820c-5e7af46a7eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-8dc2ef76-bbd5-4339-9736-71cf6cecd7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-b23c7dea-5462-432e-99f0-6ca721c7fbec,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-b7cd4357-d400-447c-a07c-db02db74c7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-4a63493f-db53-4529-ab51-9368f34af5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-82a58d45-1d17-420e-934d-99cdb64d70d4,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 3, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/TestDecommissionWithStriped/testFileChecksumAfterDecommission': Fail to get block checksum for LocatedStripedBlock{BP-872825910-172.17.0.18-1597547793755:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43467,DS-c21599ee-29a6-41a5-b267-b1e96b342eff,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-b3d5e8b5-b3b4-4dba-b607-3c4a5f262a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-358243be-c63a-4eca-a919-93d4843ff2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-cb57f634-0812-467e-820c-5e7af46a7eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-8dc2ef76-bbd5-4339-9736-71cf6cecd7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-b23c7dea-5462-432e-99f0-6ca721c7fbec,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-b7cd4357-d400-447c-a07c-db02db74c7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-4a63493f-db53-4529-ab51-9368f34af5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-82a58d45-1d17-420e-934d-99cdb64d70d4,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 3, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestDecommissionWithStriped.testFileChecksumAfterDecommission(TestDecommissionWithStriped.java:298)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestDecommissionWithStriped#testFileChecksumAfterDecommission
reconfPoint: -1
result: -1
failureMessage: expected:<9> but was:<10>
stackTrace: java.lang.AssertionError: expected:<9> but was:<10>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.hadoop.hdfs.TestDecommissionWithStriped.testFileChecksumAfterDecommission(TestDecommissionWithStriped.java:304)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestDecommissionWithStriped#testFileChecksumAfterDecommission
reconfPoint: -1
result: -1
failureMessage: expected:<9> but was:<10>
stackTrace: java.lang.AssertionError: expected:<9> but was:<10>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.hadoop.hdfs.TestDecommissionWithStriped.testFileChecksumAfterDecommission(TestDecommissionWithStriped.java:304)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestDecommissionWithStriped#testFileChecksumAfterDecommission
reconfPoint: -1
result: -1
failureMessage: expected:<9> but was:<10>
stackTrace: java.lang.AssertionError: expected:<9> but was:<10>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.hadoop.hdfs.TestDecommissionWithStriped.testFileChecksumAfterDecommission(TestDecommissionWithStriped.java:304)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestDecommissionWithStriped#testFileChecksumAfterDecommission
reconfPoint: -1
result: -1
failureMessage: `/TestDecommissionWithStriped/testFileChecksumAfterDecommission': Fail to get block checksum for LocatedStripedBlock{BP-974942187-172.17.0.18-1597548863789:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34473,DS-54217125-f1e2-40f2-b5a0-4256c6fa6ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-10548869-05e3-4588-a2ab-170b4f47587d,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-d6a6bc3b-b9dd-4d27-9d0d-b0db3db44c24,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-29bbf689-6816-4f37-9d7b-ec7f225cc5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-32f30b12-c096-4deb-95eb-950f2dad730e,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-84dd6797-51af-4218-9d89-47b77314ced2,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-ee9418f3-b6ed-46df-bbc1-1435719263aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-6093b61b-3c1d-4a7b-8584-49e0d9cece30,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-e23a1cdd-4630-4ba1-a0a4-6e2ee82cdbf7,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8, 1]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/TestDecommissionWithStriped/testFileChecksumAfterDecommission': Fail to get block checksum for LocatedStripedBlock{BP-974942187-172.17.0.18-1597548863789:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34473,DS-54217125-f1e2-40f2-b5a0-4256c6fa6ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-10548869-05e3-4588-a2ab-170b4f47587d,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-d6a6bc3b-b9dd-4d27-9d0d-b0db3db44c24,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-29bbf689-6816-4f37-9d7b-ec7f225cc5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-32f30b12-c096-4deb-95eb-950f2dad730e,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-84dd6797-51af-4218-9d89-47b77314ced2,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-ee9418f3-b6ed-46df-bbc1-1435719263aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-6093b61b-3c1d-4a7b-8584-49e0d9cece30,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-e23a1cdd-4630-4ba1-a0a4-6e2ee82cdbf7,DISK]]; indices=[0, 1, 2, 4, 5, 6, 7, 8, 1]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestDecommissionWithStriped.testFileChecksumAfterDecommission(TestDecommissionWithStriped.java:298)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestDecommissionWithStriped#testFileChecksumAfterDecommission
reconfPoint: -1
result: -1
failureMessage: expected:<9> but was:<11>
stackTrace: java.lang.AssertionError: expected:<9> but was:<11>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.hadoop.hdfs.TestDecommissionWithStriped.testFileChecksumAfterDecommission(TestDecommissionWithStriped.java:304)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestDecommissionWithStriped#testFileChecksumAfterDecommission
reconfPoint: -1
result: -1
failureMessage: expected:<9> but was:<10>
stackTrace: java.lang.AssertionError: expected:<9> but was:<10>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.hadoop.hdfs.TestDecommissionWithStriped.testFileChecksumAfterDecommission(TestDecommissionWithStriped.java:304)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestDecommissionWithStriped#testFileChecksumAfterDecommission
reconfPoint: -1
result: -1
failureMessage: expected:<9> but was:<10>
stackTrace: java.lang.AssertionError: expected:<9> but was:<10>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.hadoop.hdfs.TestDecommissionWithStriped.testFileChecksumAfterDecommission(TestDecommissionWithStriped.java:304)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestDecommissionWithStriped#testFileChecksumAfterDecommission
reconfPoint: -1
result: -1
failureMessage: expected:<9> but was:<10>
stackTrace: java.lang.AssertionError: expected:<9> but was:<10>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.hadoop.hdfs.TestDecommissionWithStriped.testFileChecksumAfterDecommission(TestDecommissionWithStriped.java:304)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestDecommissionWithStriped#testFileChecksumAfterDecommission
reconfPoint: -1
result: -1
failureMessage: expected:<9> but was:<10>
stackTrace: java.lang.AssertionError: expected:<9> but was:<10>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.hadoop.hdfs.TestDecommissionWithStriped.testFileChecksumAfterDecommission(TestDecommissionWithStriped.java:304)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestDecommissionWithStriped#testFileChecksumAfterDecommission
reconfPoint: -1
result: -1
failureMessage: expected:<0> but was:<1>
stackTrace: java.lang.AssertionError: expected:<0> but was:<1>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.hadoop.hdfs.TestDecommissionWithStriped.testFileChecksumAfterDecommission(TestDecommissionWithStriped.java:297)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestDecommissionWithStriped#testFileChecksumAfterDecommission
reconfPoint: -1
result: -1
failureMessage: expected:<9> but was:<10>
stackTrace: java.lang.AssertionError: expected:<9> but was:<10>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.hadoop.hdfs.TestDecommissionWithStriped.testFileChecksumAfterDecommission(TestDecommissionWithStriped.java:304)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestDecommissionWithStriped#testFileChecksumAfterDecommission
reconfPoint: -1
result: -1
failureMessage: expected:<9> but was:<10>
stackTrace: java.lang.AssertionError: expected:<9> but was:<10>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.hadoop.hdfs.TestDecommissionWithStriped.testFileChecksumAfterDecommission(TestDecommissionWithStriped.java:304)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestDecommissionWithStriped#testFileChecksumAfterDecommission
reconfPoint: -1
result: -1
failureMessage: expected:<9> but was:<10>
stackTrace: java.lang.AssertionError: expected:<9> but was:<10>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.hadoop.hdfs.TestDecommissionWithStriped.testFileChecksumAfterDecommission(TestDecommissionWithStriped.java:304)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestDecommissionWithStriped#testFileChecksumAfterDecommission
reconfPoint: -1
result: -1
failureMessage: `/TestDecommissionWithStriped/testFileChecksumAfterDecommission': Fail to get block checksum for LocatedStripedBlock{BP-978373460-172.17.0.18-1597552097838:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39418,DS-768efbeb-8021-4ddd-8c94-89140371e38e,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-0dca28d5-6a83-40f2-9cc6-880b051cd9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-7913a29e-782f-43ef-bb21-edde304efed7,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-e808f741-b29d-4efd-969e-0bf93cd1ad61,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-8e3f345c-e9c0-44a2-b005-1d3ba98ec985,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-388eea2d-2497-445e-9087-168117de39bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-bfe90dbb-fa76-4fdb-8656-6b243b7533cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-73ff32aa-9ca2-4026-b4aa-d7c840bb8b92,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-f0b09a2c-89c9-4899-8210-6aead9bf3b55,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8, 4]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/TestDecommissionWithStriped/testFileChecksumAfterDecommission': Fail to get block checksum for LocatedStripedBlock{BP-978373460-172.17.0.18-1597552097838:blk_-9223372036854775792_1001; getBlockSize()=6291456; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39418,DS-768efbeb-8021-4ddd-8c94-89140371e38e,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-0dca28d5-6a83-40f2-9cc6-880b051cd9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-7913a29e-782f-43ef-bb21-edde304efed7,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-e808f741-b29d-4efd-969e-0bf93cd1ad61,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-8e3f345c-e9c0-44a2-b005-1d3ba98ec985,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-388eea2d-2497-445e-9087-168117de39bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-bfe90dbb-fa76-4fdb-8656-6b243b7533cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-73ff32aa-9ca2-4026-b4aa-d7c840bb8b92,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-f0b09a2c-89c9-4899-8210-6aead9bf3b55,DISK]]; indices=[0, 1, 2, 3, 4, 6, 7, 8, 4]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestDecommissionWithStriped.testFileChecksumAfterDecommission(TestDecommissionWithStriped.java:298)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 10000000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestDecommissionWithStriped#testFileChecksumAfterDecommission
reconfPoint: -1
result: -1
failureMessage: expected:<9> but was:<10>
stackTrace: java.lang.AssertionError: expected:<9> but was:<10>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.hadoop.hdfs.TestDecommissionWithStriped.testFileChecksumAfterDecommission(TestDecommissionWithStriped.java:304)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5375
