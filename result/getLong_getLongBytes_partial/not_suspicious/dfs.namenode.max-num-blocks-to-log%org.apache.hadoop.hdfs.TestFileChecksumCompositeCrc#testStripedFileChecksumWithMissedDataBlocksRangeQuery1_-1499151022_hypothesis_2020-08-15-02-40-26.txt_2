reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1371009111-172.17.0.4-1597459395315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33930,DS-dcd13e06-35e0-4eff-9a45-82c0eb86a08c,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-97cf8349-ef77-40d1-9c2b-f8bbaa8cad4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-a796478c-96fe-45dc-b669-9c8e22b47b90,DISK], DatanodeInfoWithStorage[127.0.0.1:34667,DS-85fb9d8c-668c-4835-a0e5-0c3ac21e7a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-531adfd7-7648-4179-8206-6493a1de4a85,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-08cd52fd-4182-4556-8593-37abc65c87d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-9cdea799-090b-4f72-9b1a-d034e833ffd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-00521872-62f4-49fd-b964-675d6e19b41f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1371009111-172.17.0.4-1597459395315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33930,DS-dcd13e06-35e0-4eff-9a45-82c0eb86a08c,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-97cf8349-ef77-40d1-9c2b-f8bbaa8cad4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-a796478c-96fe-45dc-b669-9c8e22b47b90,DISK], DatanodeInfoWithStorage[127.0.0.1:34667,DS-85fb9d8c-668c-4835-a0e5-0c3ac21e7a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-531adfd7-7648-4179-8206-6493a1de4a85,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-08cd52fd-4182-4556-8593-37abc65c87d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-9cdea799-090b-4f72-9b1a-d034e833ffd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-00521872-62f4-49fd-b964-675d6e19b41f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1420636290-172.17.0.4-1597459620063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40136,DS-b7dde3c0-1496-4536-b99e-07b57c9a7bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-1a75a480-414a-4d73-aa9e-437a0d50d987,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-dfc840cc-078e-4568-94d1-dca51440d939,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-c0a09ddf-75d1-4d3e-974b-71e25f5182b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-98f968fb-9024-4278-ac25-1cded0ff6841,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-361c5340-9580-46a8-a8d7-a164ed8c4d41,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-1937da5f-60b3-4595-a5b8-ba235bb6036f,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-2da046a6-5d9c-4545-b62b-a5603921a8e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1420636290-172.17.0.4-1597459620063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40136,DS-b7dde3c0-1496-4536-b99e-07b57c9a7bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-1a75a480-414a-4d73-aa9e-437a0d50d987,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-dfc840cc-078e-4568-94d1-dca51440d939,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-c0a09ddf-75d1-4d3e-974b-71e25f5182b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-98f968fb-9024-4278-ac25-1cded0ff6841,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-361c5340-9580-46a8-a8d7-a164ed8c4d41,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-1937da5f-60b3-4595-a5b8-ba235bb6036f,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-2da046a6-5d9c-4545-b62b-a5603921a8e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1031544685-172.17.0.4-1597459811403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36417,DS-e6bae886-2623-456f-a38c-369c160b9223,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-b0a619e0-8500-45e3-92e8-164a2a8f13f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-8b6debc7-f6eb-4ebe-a46c-fc096c9d0368,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-18736d48-18ed-450e-9840-e19749b8801f,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-c7150043-e69c-4e3f-b7a9-e2373d753607,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-8a48c61b-4ca1-41cd-96b4-21b62211b117,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-3ea0f203-b3ec-42ca-991d-c71744f88dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-27b17247-e476-4aad-9b7d-53919d180cf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1031544685-172.17.0.4-1597459811403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36417,DS-e6bae886-2623-456f-a38c-369c160b9223,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-b0a619e0-8500-45e3-92e8-164a2a8f13f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-8b6debc7-f6eb-4ebe-a46c-fc096c9d0368,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-18736d48-18ed-450e-9840-e19749b8801f,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-c7150043-e69c-4e3f-b7a9-e2373d753607,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-8a48c61b-4ca1-41cd-96b4-21b62211b117,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-3ea0f203-b3ec-42ca-991d-c71744f88dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-27b17247-e476-4aad-9b7d-53919d180cf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-398958165-172.17.0.4-1597460746575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37123,DS-ce5a8077-4873-4dc4-bb92-2ab6081016fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-c54cbe35-a655-4ea1-b9fe-39e3dff22b64,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-4a2ce0c1-5107-4e8f-8668-5e8bbdfab757,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-8bafeb6c-97bd-4e10-8ec4-6083029100f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-2b8a4d12-260a-4d35-b1c6-2e773c6b3bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-ca27bcc3-a7f5-482b-97c9-8f0d8020a8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34218,DS-1e4eb739-05b6-4a00-9150-b3538f932405,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-3352e2ed-720f-41ed-b200-c86e19739f57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-398958165-172.17.0.4-1597460746575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37123,DS-ce5a8077-4873-4dc4-bb92-2ab6081016fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-c54cbe35-a655-4ea1-b9fe-39e3dff22b64,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-4a2ce0c1-5107-4e8f-8668-5e8bbdfab757,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-8bafeb6c-97bd-4e10-8ec4-6083029100f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-2b8a4d12-260a-4d35-b1c6-2e773c6b3bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-ca27bcc3-a7f5-482b-97c9-8f0d8020a8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34218,DS-1e4eb739-05b6-4a00-9150-b3538f932405,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-3352e2ed-720f-41ed-b200-c86e19739f57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-652331505-172.17.0.4-1597460822748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37351,DS-2c97d23a-39f4-4151-a5f4-7c6d7325a13d,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-f0d43c13-7f8c-40f0-adbe-6c655fde42de,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-70932fec-2aa6-47c9-b26d-ed438bc1cbab,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-e4a9e018-d42f-4d33-bea2-583f9a7d4a89,DISK], DatanodeInfoWithStorage[127.0.0.1:41192,DS-19d93bc5-70dc-4a7d-87a3-2c5bfed7320e,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-649a79e8-f941-49be-b880-1903beb45404,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-294be4e9-a752-44c1-b23b-88e69a554861,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-732f3034-cbfa-4d59-bdb0-ac8efb552233,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-652331505-172.17.0.4-1597460822748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37351,DS-2c97d23a-39f4-4151-a5f4-7c6d7325a13d,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-f0d43c13-7f8c-40f0-adbe-6c655fde42de,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-70932fec-2aa6-47c9-b26d-ed438bc1cbab,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-e4a9e018-d42f-4d33-bea2-583f9a7d4a89,DISK], DatanodeInfoWithStorage[127.0.0.1:41192,DS-19d93bc5-70dc-4a7d-87a3-2c5bfed7320e,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-649a79e8-f941-49be-b880-1903beb45404,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-294be4e9-a752-44c1-b23b-88e69a554861,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-732f3034-cbfa-4d59-bdb0-ac8efb552233,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1495105225-172.17.0.4-1597460972332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35124,DS-25dc3328-de35-4df1-bb87-6a0be9fe6cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-75fdbd67-3f53-44a7-b53c-f705d38c619a,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-fb96faa6-baa9-4a78-bea7-017982cad901,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-c88e7fd6-d431-410f-95ad-408ad802b09f,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-45be016a-5471-440b-82f4-d906a001a6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-4fd3db1c-a6f0-407e-9204-eccf6d2da073,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-5ee0bb80-eace-4b88-8610-bbe51b223dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-3ab3be62-0b31-46ce-aff0-f2e80e4b2db1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1495105225-172.17.0.4-1597460972332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35124,DS-25dc3328-de35-4df1-bb87-6a0be9fe6cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-75fdbd67-3f53-44a7-b53c-f705d38c619a,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-fb96faa6-baa9-4a78-bea7-017982cad901,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-c88e7fd6-d431-410f-95ad-408ad802b09f,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-45be016a-5471-440b-82f4-d906a001a6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-4fd3db1c-a6f0-407e-9204-eccf6d2da073,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-5ee0bb80-eace-4b88-8610-bbe51b223dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-3ab3be62-0b31-46ce-aff0-f2e80e4b2db1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1971675862-172.17.0.4-1597461082688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38421,DS-2ee9c661-47d2-46b7-b160-faae37c7f164,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-1d4c12a9-3250-4fa1-a0d5-8bbe55dc3aad,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-a52b5c78-5645-4868-9f5c-b4bfb8e4b6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-2a390803-95e7-437e-9042-ea74bc7a9314,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-51583078-8501-4303-a44f-582e2f5cda03,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-d05d2f3f-dfd4-499e-86ef-de515c2c9782,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-cdd048da-3d0a-40c9-90e1-a1992d308723,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-aa18fe8c-c080-4460-b1f7-0eb093112bfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1971675862-172.17.0.4-1597461082688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38421,DS-2ee9c661-47d2-46b7-b160-faae37c7f164,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-1d4c12a9-3250-4fa1-a0d5-8bbe55dc3aad,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-a52b5c78-5645-4868-9f5c-b4bfb8e4b6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-2a390803-95e7-437e-9042-ea74bc7a9314,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-51583078-8501-4303-a44f-582e2f5cda03,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-d05d2f3f-dfd4-499e-86ef-de515c2c9782,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-cdd048da-3d0a-40c9-90e1-a1992d308723,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-aa18fe8c-c080-4460-b1f7-0eb093112bfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-597082027-172.17.0.4-1597461754219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41126,DS-5b8e56ec-bf5e-40b2-8e6d-ba6da04cd370,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-0c36b8b2-3c44-4011-88b6-492667d18114,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-eb6e6166-7a43-4e67-a127-e733fc4b55c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-42a0082e-44be-46e9-b082-a0c12ea0ea46,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-b0519460-b22a-45d8-9699-a9d425ee70c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-96d39680-5167-4344-a50a-9a8f75feebaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-f9bac239-62fd-4ce2-b4ce-2577b5c71a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-bcb6b7f5-f401-4a36-a2fb-37fedda55b36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-597082027-172.17.0.4-1597461754219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41126,DS-5b8e56ec-bf5e-40b2-8e6d-ba6da04cd370,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-0c36b8b2-3c44-4011-88b6-492667d18114,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-eb6e6166-7a43-4e67-a127-e733fc4b55c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-42a0082e-44be-46e9-b082-a0c12ea0ea46,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-b0519460-b22a-45d8-9699-a9d425ee70c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-96d39680-5167-4344-a50a-9a8f75feebaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-f9bac239-62fd-4ce2-b4ce-2577b5c71a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-bcb6b7f5-f401-4a36-a2fb-37fedda55b36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-48421288-172.17.0.4-1597461823961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46402,DS-d8abfc1f-feb0-49ba-a1b5-c871ed147138,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-56dc52fd-38ce-431d-b3cd-3fbb83209570,DISK], DatanodeInfoWithStorage[127.0.0.1:39278,DS-52e982ed-0fbe-41ef-8a34-a8b2f73cb78a,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-83892f9c-c556-4e21-92fe-5d9829b03165,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-28a23326-8dea-4e2f-92d8-c05882bd5a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-998bb028-b3c2-4a5c-be2e-03d90ea0be50,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-9f190a96-afe1-4d60-b884-d823559e49ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-6e37e287-96f3-4eb4-903d-0cd02730e206,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-48421288-172.17.0.4-1597461823961:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46402,DS-d8abfc1f-feb0-49ba-a1b5-c871ed147138,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-56dc52fd-38ce-431d-b3cd-3fbb83209570,DISK], DatanodeInfoWithStorage[127.0.0.1:39278,DS-52e982ed-0fbe-41ef-8a34-a8b2f73cb78a,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-83892f9c-c556-4e21-92fe-5d9829b03165,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-28a23326-8dea-4e2f-92d8-c05882bd5a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-998bb028-b3c2-4a5c-be2e-03d90ea0be50,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-9f190a96-afe1-4d60-b884-d823559e49ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-6e37e287-96f3-4eb4-903d-0cd02730e206,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117742461-172.17.0.4-1597462051145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33186,DS-c7ad14fd-083f-4caf-a01e-be987bcdd4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-d953f5f7-cf09-4144-8395-01ed27a0a74f,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-5edec79d-d98f-4b52-875a-e4058f91f723,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-c076b6ce-be53-4c58-8a27-eb96b6c3885b,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-a98fa1aa-28b6-4d0f-beeb-2829e56759bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-ecc43abd-2488-40e0-904b-27f9dab87aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-110bc7c9-7128-4ead-a7b2-157b57673b90,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-17fa0bd0-6171-4870-85d8-a9aea0615dea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117742461-172.17.0.4-1597462051145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33186,DS-c7ad14fd-083f-4caf-a01e-be987bcdd4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-d953f5f7-cf09-4144-8395-01ed27a0a74f,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-5edec79d-d98f-4b52-875a-e4058f91f723,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-c076b6ce-be53-4c58-8a27-eb96b6c3885b,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-a98fa1aa-28b6-4d0f-beeb-2829e56759bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-ecc43abd-2488-40e0-904b-27f9dab87aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-110bc7c9-7128-4ead-a7b2-157b57673b90,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-17fa0bd0-6171-4870-85d8-a9aea0615dea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-14368410-172.17.0.4-1597462274382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46164,DS-c1717ec0-7a89-40d8-aa89-06837425fdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-950089da-f304-4515-bfb7-200abfd2891c,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-362b80ad-c50c-4a92-8697-01016e9051f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-f1e8d7a1-0eca-4acd-911d-92b7ba3f92cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-f41cd5f9-ec70-4ab8-b185-d9d009c615aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-13a918e2-2eeb-48e0-9324-c4a1253f0aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-09a9bdd7-eda6-4903-9bba-19e95fb9d439,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-730a9f60-20d6-4e62-801e-3b7e5118b44e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-14368410-172.17.0.4-1597462274382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46164,DS-c1717ec0-7a89-40d8-aa89-06837425fdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-950089da-f304-4515-bfb7-200abfd2891c,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-362b80ad-c50c-4a92-8697-01016e9051f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-f1e8d7a1-0eca-4acd-911d-92b7ba3f92cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-f41cd5f9-ec70-4ab8-b185-d9d009c615aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-13a918e2-2eeb-48e0-9324-c4a1253f0aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-09a9bdd7-eda6-4903-9bba-19e95fb9d439,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-730a9f60-20d6-4e62-801e-3b7e5118b44e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1342494891-172.17.0.4-1597462561415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43907,DS-5f04503d-2fa5-46f5-976a-0e7ad17edd04,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-05d502cc-b1ff-4cac-bda3-9114790fe629,DISK], DatanodeInfoWithStorage[127.0.0.1:35167,DS-cb4f1cc4-b901-4c66-a521-500c9c2e5478,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-dca773ef-de9e-424a-985d-fc59ddbd315d,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-c7aed9c5-15c8-48b7-85ff-73c07d4c453d,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-0f2ff15c-6b6a-42de-87af-632092d2d49c,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-2b62a3ed-1640-4eae-bfb6-e592eb233b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-6ea7b4e6-60d6-4f51-9650-3b4e680ceb10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1342494891-172.17.0.4-1597462561415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43907,DS-5f04503d-2fa5-46f5-976a-0e7ad17edd04,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-05d502cc-b1ff-4cac-bda3-9114790fe629,DISK], DatanodeInfoWithStorage[127.0.0.1:35167,DS-cb4f1cc4-b901-4c66-a521-500c9c2e5478,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-dca773ef-de9e-424a-985d-fc59ddbd315d,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-c7aed9c5-15c8-48b7-85ff-73c07d4c453d,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-0f2ff15c-6b6a-42de-87af-632092d2d49c,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-2b62a3ed-1640-4eae-bfb6-e592eb233b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-6ea7b4e6-60d6-4f51-9650-3b4e680ceb10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1147281974-172.17.0.4-1597463329933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40254,DS-83a2c6f9-1fc8-48fc-9812-68e369719eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-8b65f4b4-6c56-4810-a256-fce11009c1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-fcb7d102-7675-41cd-888e-80ad79826079,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-d9770bac-c4f4-46e5-8b38-c096364a657a,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-2c006504-171d-442b-8642-f19941413f34,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-397e7ed8-1a60-44db-8ef7-f1eef82ca921,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-3afa53d4-734b-4b7d-af66-e3795552b2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-9a4c336e-31e2-4ee4-8abb-7eded10e20c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1147281974-172.17.0.4-1597463329933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40254,DS-83a2c6f9-1fc8-48fc-9812-68e369719eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-8b65f4b4-6c56-4810-a256-fce11009c1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-fcb7d102-7675-41cd-888e-80ad79826079,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-d9770bac-c4f4-46e5-8b38-c096364a657a,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-2c006504-171d-442b-8642-f19941413f34,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-397e7ed8-1a60-44db-8ef7-f1eef82ca921,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-3afa53d4-734b-4b7d-af66-e3795552b2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-9a4c336e-31e2-4ee4-8abb-7eded10e20c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2062965968-172.17.0.4-1597463823235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35574,DS-4edfb356-b038-40b8-adcb-86559f0c0a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-49d4c09e-0f49-4387-9f21-abca80dffbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-49331eb3-2792-4285-9b79-d81e36d358e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-adf4fb5c-4794-490d-8a93-70a3dbcae4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-cc411678-20d3-4cbe-94fe-8fe8412e13f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-8940d957-6d71-48d6-bfae-17e39071dcc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-1ec70afd-cd5f-4707-b9f8-29144746ade5,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-5da79aad-6459-4a9e-a6d4-75b366470642,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2062965968-172.17.0.4-1597463823235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35574,DS-4edfb356-b038-40b8-adcb-86559f0c0a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-49d4c09e-0f49-4387-9f21-abca80dffbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-49331eb3-2792-4285-9b79-d81e36d358e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-adf4fb5c-4794-490d-8a93-70a3dbcae4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-cc411678-20d3-4cbe-94fe-8fe8412e13f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-8940d957-6d71-48d6-bfae-17e39071dcc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-1ec70afd-cd5f-4707-b9f8-29144746ade5,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-5da79aad-6459-4a9e-a6d4-75b366470642,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1718700925-172.17.0.4-1597464378258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37890,DS-ea6c4a44-78ea-43dc-a1d1-8956377ddc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-1e9a731e-9ccf-48ae-ab89-60ec3e0d12ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-7c4d0a0b-3526-45a8-b096-fc8c5a9738f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-b6286fe0-e65f-436d-8317-35c37b1a2e35,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-a111024b-c651-4f82-af17-bf6d6142dc66,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-a557e0bb-c22e-4d1d-a61a-94fdeb7af38d,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-508c1977-3d50-4d7d-8996-3fd52efbbc98,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-d92a4dd8-9f59-462d-8df8-98527fc61cca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1718700925-172.17.0.4-1597464378258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37890,DS-ea6c4a44-78ea-43dc-a1d1-8956377ddc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44893,DS-1e9a731e-9ccf-48ae-ab89-60ec3e0d12ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-7c4d0a0b-3526-45a8-b096-fc8c5a9738f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-b6286fe0-e65f-436d-8317-35c37b1a2e35,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-a111024b-c651-4f82-af17-bf6d6142dc66,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-a557e0bb-c22e-4d1d-a61a-94fdeb7af38d,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-508c1977-3d50-4d7d-8996-3fd52efbbc98,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-d92a4dd8-9f59-462d-8df8-98527fc61cca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192671021-172.17.0.4-1597464576671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32822,DS-6ea372fb-63f8-41a4-abb5-fea665d87650,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-5297f4f4-7c9a-4150-abb8-a55e16ebf300,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-4a483895-14a8-4afe-b888-56a059eece8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-22eacde3-eb95-4f87-b3c9-f3400758333f,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-60336adc-f6e4-48ac-a930-bcbdc09a3434,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-fdf3af16-fe4f-4732-864b-5f13d6cbac2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-56a210d9-41c7-475a-91a4-aa9464fbb640,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-5b8c477e-8e71-4a1b-8ca6-18780a823db3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192671021-172.17.0.4-1597464576671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32822,DS-6ea372fb-63f8-41a4-abb5-fea665d87650,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-5297f4f4-7c9a-4150-abb8-a55e16ebf300,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-4a483895-14a8-4afe-b888-56a059eece8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-22eacde3-eb95-4f87-b3c9-f3400758333f,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-60336adc-f6e4-48ac-a930-bcbdc09a3434,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-fdf3af16-fe4f-4732-864b-5f13d6cbac2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-56a210d9-41c7-475a-91a4-aa9464fbb640,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-5b8c477e-8e71-4a1b-8ca6-18780a823db3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1581776306-172.17.0.4-1597464758107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34795,DS-9bafaff6-8b3e-4921-be87-72953e7fb4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-7d84cb36-8aa4-4408-81b4-2cbaeeab28cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-69576150-7944-4ac4-a392-1e7c23a93126,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-79c6840b-89d7-4d7d-8823-858d4904d656,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-0ca1c046-3de2-4cc7-bb7c-7054fc2dde54,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-7c0a9f2c-ec72-4d98-a0e8-3054a4e7d0db,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-a75b7096-7c63-4fa6-91c9-4f7142eeab69,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-df69a534-5403-4065-8332-65fcb2e32c34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1581776306-172.17.0.4-1597464758107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34795,DS-9bafaff6-8b3e-4921-be87-72953e7fb4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-7d84cb36-8aa4-4408-81b4-2cbaeeab28cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-69576150-7944-4ac4-a392-1e7c23a93126,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-79c6840b-89d7-4d7d-8823-858d4904d656,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-0ca1c046-3de2-4cc7-bb7c-7054fc2dde54,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-7c0a9f2c-ec72-4d98-a0e8-3054a4e7d0db,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-a75b7096-7c63-4fa6-91c9-4f7142eeab69,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-df69a534-5403-4065-8332-65fcb2e32c34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5635
