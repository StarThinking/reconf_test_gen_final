reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-189315861-172.17.0.3-1597495073137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36788,DS-d90c3668-46d7-44cf-b7ef-2438da82ab5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-42f62e12-ace1-440d-95f7-b0bc04930f08,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-95d54cca-ba3f-4216-b19f-633c2713fdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:41033,DS-01d28521-4643-42b3-ad7d-c7bc75743b66,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-0a6f214b-9a42-46bf-8a9a-0ae8a9bb0cba,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-3461605d-8564-4926-b46d-01d9fd1f0af3,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-e65523d1-2dcf-4b6f-9c12-8f38f0d1eaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-2801bba0-fbb7-4a87-8da4-658aff5a679b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-189315861-172.17.0.3-1597495073137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36788,DS-d90c3668-46d7-44cf-b7ef-2438da82ab5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-42f62e12-ace1-440d-95f7-b0bc04930f08,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-95d54cca-ba3f-4216-b19f-633c2713fdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:41033,DS-01d28521-4643-42b3-ad7d-c7bc75743b66,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-0a6f214b-9a42-46bf-8a9a-0ae8a9bb0cba,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-3461605d-8564-4926-b46d-01d9fd1f0af3,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-e65523d1-2dcf-4b6f-9c12-8f38f0d1eaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-2801bba0-fbb7-4a87-8da4-658aff5a679b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1415614039-172.17.0.3-1597495190348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42110,DS-0d390e41-8899-4b3f-9634-9540b045f409,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-92de38df-7bfe-41ff-a49b-c16bda441286,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-ed752e4e-83d9-4ebf-bebb-17c53c5344b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-5dc4ee67-8083-40d4-84b5-24576a93ec75,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-c9936bb5-0c9d-4037-a099-da02a28c7238,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-ada90ffd-14e4-4d5e-b95e-64ec24f67152,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-05a7b152-d096-4f04-943b-786ffe9dc191,DISK], DatanodeInfoWithStorage[127.0.0.1:41964,DS-dd75fa5c-863a-4646-ba9c-7a5fa90cc87c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1415614039-172.17.0.3-1597495190348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42110,DS-0d390e41-8899-4b3f-9634-9540b045f409,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-92de38df-7bfe-41ff-a49b-c16bda441286,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-ed752e4e-83d9-4ebf-bebb-17c53c5344b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-5dc4ee67-8083-40d4-84b5-24576a93ec75,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-c9936bb5-0c9d-4037-a099-da02a28c7238,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-ada90ffd-14e4-4d5e-b95e-64ec24f67152,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-05a7b152-d096-4f04-943b-786ffe9dc191,DISK], DatanodeInfoWithStorage[127.0.0.1:41964,DS-dd75fa5c-863a-4646-ba9c-7a5fa90cc87c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1280212399-172.17.0.3-1597495297872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34310,DS-642ae1d0-903d-402a-9edf-a125736c8ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-ad20ebd4-9df4-49ce-99bb-6489d3804fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-60655825-05ec-4a04-ac11-046d1dde402c,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-38353822-f68a-4f37-b2d2-92937480703a,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-e343caa5-0a44-4206-83ee-e4dde6bfc1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-c4316aa2-7514-4b86-840d-c5cae02e90ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-e1f6a6fb-2b10-4ae6-84d6-ff61a31b5d52,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-7478580c-576d-4324-ba30-a181eb3d5efd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1280212399-172.17.0.3-1597495297872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34310,DS-642ae1d0-903d-402a-9edf-a125736c8ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-ad20ebd4-9df4-49ce-99bb-6489d3804fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-60655825-05ec-4a04-ac11-046d1dde402c,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-38353822-f68a-4f37-b2d2-92937480703a,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-e343caa5-0a44-4206-83ee-e4dde6bfc1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-c4316aa2-7514-4b86-840d-c5cae02e90ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-e1f6a6fb-2b10-4ae6-84d6-ff61a31b5d52,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-7478580c-576d-4324-ba30-a181eb3d5efd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933230752-172.17.0.3-1597495468427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40552,DS-8d40c883-91a3-4035-bde0-d3c718f02dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-e9c2469c-d469-4f93-aeb0-a0f9f38a5038,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-13893e64-bf08-4811-90b5-6f2853873d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-b55cb9da-6b41-4e07-84ce-d69bfeb4283a,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-0dd2b0bf-ea41-40ff-aa73-d951e6cda391,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-2558d41e-fc9b-4152-a649-8cd44a62ee1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-61cc9ee0-8271-458c-bf92-2a63805cda63,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-120f47f3-fc96-464a-bb2b-435512972cc8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933230752-172.17.0.3-1597495468427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40552,DS-8d40c883-91a3-4035-bde0-d3c718f02dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-e9c2469c-d469-4f93-aeb0-a0f9f38a5038,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-13893e64-bf08-4811-90b5-6f2853873d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-b55cb9da-6b41-4e07-84ce-d69bfeb4283a,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-0dd2b0bf-ea41-40ff-aa73-d951e6cda391,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-2558d41e-fc9b-4152-a649-8cd44a62ee1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-61cc9ee0-8271-458c-bf92-2a63805cda63,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-120f47f3-fc96-464a-bb2b-435512972cc8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1036364509-172.17.0.3-1597495926347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36332,DS-13202d27-45a9-4c0b-8204-2820a847d5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-02685d40-a914-4f4b-968e-20452ec1f7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-1238dbe1-4c6e-4f52-bb16-1459c9acfe1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-6060d819-0ab1-4d78-b95a-ccb6859fb43c,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-2f87d2c8-124a-42bd-8e73-9c4c5c1e0504,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-2842169d-bc55-4d6b-8ebd-dca4cb02af63,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-2bc6944b-a954-4fa8-a6ec-34eddd68ea0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-127d57c3-ce42-4f06-b58c-2bc5d69916dc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1036364509-172.17.0.3-1597495926347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36332,DS-13202d27-45a9-4c0b-8204-2820a847d5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-02685d40-a914-4f4b-968e-20452ec1f7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-1238dbe1-4c6e-4f52-bb16-1459c9acfe1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-6060d819-0ab1-4d78-b95a-ccb6859fb43c,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-2f87d2c8-124a-42bd-8e73-9c4c5c1e0504,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-2842169d-bc55-4d6b-8ebd-dca4cb02af63,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-2bc6944b-a954-4fa8-a6ec-34eddd68ea0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-127d57c3-ce42-4f06-b58c-2bc5d69916dc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580162913-172.17.0.3-1597496348484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33232,DS-7ed96b05-68af-4bc9-9b9b-66db632a63d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-f9249f02-d195-4140-b7ec-f84c333e7444,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-46e86939-d389-4794-a544-5f7279026948,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-b43a369e-80d4-48cd-bbd5-1de04e103daf,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-3dc70da4-8911-49a6-abb6-124d52217c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-36fa6b81-52e7-4560-a943-1760257421b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-0c334386-504e-483e-b53d-c9d794876c32,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-940c1c0a-dc7c-43de-b755-ce2ef9cf77f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580162913-172.17.0.3-1597496348484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33232,DS-7ed96b05-68af-4bc9-9b9b-66db632a63d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-f9249f02-d195-4140-b7ec-f84c333e7444,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-46e86939-d389-4794-a544-5f7279026948,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-b43a369e-80d4-48cd-bbd5-1de04e103daf,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-3dc70da4-8911-49a6-abb6-124d52217c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-36fa6b81-52e7-4560-a943-1760257421b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-0c334386-504e-483e-b53d-c9d794876c32,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-940c1c0a-dc7c-43de-b755-ce2ef9cf77f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-572020386-172.17.0.3-1597496385342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44086,DS-94428579-4b7b-45a4-8740-bc10f87c8c70,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-ef742d72-7942-44b5-bbd1-ebf43ce6ddf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-8064258c-ca1d-4c1d-b67f-01607ad12521,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-11530276-e54e-493d-a387-bab065f8d7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-2004005d-8435-494a-9974-dd6853673876,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-27d45600-d321-4cca-8edd-9b7f1d4af1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-6cbfda5f-2565-497a-9b96-249cb5f135ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-8100782b-0798-44b3-b5c4-1b120928e746,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-572020386-172.17.0.3-1597496385342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44086,DS-94428579-4b7b-45a4-8740-bc10f87c8c70,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-ef742d72-7942-44b5-bbd1-ebf43ce6ddf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-8064258c-ca1d-4c1d-b67f-01607ad12521,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-11530276-e54e-493d-a387-bab065f8d7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-2004005d-8435-494a-9974-dd6853673876,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-27d45600-d321-4cca-8edd-9b7f1d4af1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-6cbfda5f-2565-497a-9b96-249cb5f135ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-8100782b-0798-44b3-b5c4-1b120928e746,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662466813-172.17.0.3-1597496427082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41122,DS-c270df27-6eed-4a97-8a30-ecaa84390445,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-fcd3cc16-5713-471d-bd9f-bc56528ed7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-907d761f-805d-401c-959f-cb928d1a2769,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-e42d20be-f8cc-4f56-9145-4f418df5dfa2,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-a2ed7278-6164-41e0-ae70-26b5e1a08734,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-94c515d4-6757-40f0-a827-1f9018a05354,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-ffeb6113-a556-4d27-ae69-3ccbb4f0e4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-55ee4694-09cb-476e-a703-890a597aceb8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662466813-172.17.0.3-1597496427082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41122,DS-c270df27-6eed-4a97-8a30-ecaa84390445,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-fcd3cc16-5713-471d-bd9f-bc56528ed7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-907d761f-805d-401c-959f-cb928d1a2769,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-e42d20be-f8cc-4f56-9145-4f418df5dfa2,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-a2ed7278-6164-41e0-ae70-26b5e1a08734,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-94c515d4-6757-40f0-a827-1f9018a05354,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-ffeb6113-a556-4d27-ae69-3ccbb4f0e4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-55ee4694-09cb-476e-a703-890a597aceb8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-41566821-172.17.0.3-1597496461632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44267,DS-b2f30888-537c-42d5-87a7-09b91d6766fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-0e3c2934-8d01-4e79-b255-fa5ca167c5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-4c1b051c-28c5-4e21-b0d0-5c898f1f7dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-c4fd27c1-9d05-481d-8c45-69fe7cf506ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-9fb7642c-264c-4e90-bd62-246e93ee3836,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-affc85ad-794e-4195-81e3-79f033bd3513,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-88f17881-4585-44f7-956a-ad4c1fa0fc48,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-83491aee-8060-4315-858d-2d998d05b941,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-41566821-172.17.0.3-1597496461632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44267,DS-b2f30888-537c-42d5-87a7-09b91d6766fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-0e3c2934-8d01-4e79-b255-fa5ca167c5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-4c1b051c-28c5-4e21-b0d0-5c898f1f7dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-c4fd27c1-9d05-481d-8c45-69fe7cf506ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-9fb7642c-264c-4e90-bd62-246e93ee3836,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-affc85ad-794e-4195-81e3-79f033bd3513,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-88f17881-4585-44f7-956a-ad4c1fa0fc48,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-83491aee-8060-4315-858d-2d998d05b941,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-659588089-172.17.0.3-1597496564962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42584,DS-f4b5fa90-06f9-4386-bcd7-05f7214c0cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-ceafa3df-86e1-4025-9f75-9bfb2be5a138,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-255168ef-363b-4abb-a15f-1194c7ca2da2,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-5fba8df1-bcfa-4159-b9a0-d991fc4e5c62,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-ca7aa251-35f6-4f0b-8547-63e70329f093,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-742ef198-3ba6-401b-8bac-de0375949613,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-6bd8b50e-cb48-44ee-b483-7eee0c1c3668,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-9224bfd3-25cf-41be-8f61-e1c5c1e66a30,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-659588089-172.17.0.3-1597496564962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42584,DS-f4b5fa90-06f9-4386-bcd7-05f7214c0cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-ceafa3df-86e1-4025-9f75-9bfb2be5a138,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-255168ef-363b-4abb-a15f-1194c7ca2da2,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-5fba8df1-bcfa-4159-b9a0-d991fc4e5c62,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-ca7aa251-35f6-4f0b-8547-63e70329f093,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-742ef198-3ba6-401b-8bac-de0375949613,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-6bd8b50e-cb48-44ee-b483-7eee0c1c3668,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-9224bfd3-25cf-41be-8f61-e1c5c1e66a30,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-276617414-172.17.0.3-1597496602361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41629,DS-036b3c75-547d-48ad-9f83-71846337f681,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-66a1bddf-fdb8-4b5a-b9d7-6790283e0caf,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-a1c99d63-1feb-42ff-adcc-3534b4942ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-0f1144a4-f370-4a7f-be68-a0be172cc3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-750c4dd1-b937-4aa7-8c31-e705d7baefc8,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-78b83831-d546-4476-bced-ef64243fa3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-2a1f6cfa-13ef-4d35-b276-e3e4024c603f,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-00e35792-be1b-49f1-a2d6-32acb863cbc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-276617414-172.17.0.3-1597496602361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41629,DS-036b3c75-547d-48ad-9f83-71846337f681,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-66a1bddf-fdb8-4b5a-b9d7-6790283e0caf,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-a1c99d63-1feb-42ff-adcc-3534b4942ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-0f1144a4-f370-4a7f-be68-a0be172cc3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-750c4dd1-b937-4aa7-8c31-e705d7baefc8,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-78b83831-d546-4476-bced-ef64243fa3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-2a1f6cfa-13ef-4d35-b276-e3e4024c603f,DISK], DatanodeInfoWithStorage[127.0.0.1:40084,DS-00e35792-be1b-49f1-a2d6-32acb863cbc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-539440620-172.17.0.3-1597496806590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42815,DS-8797c685-bae4-44c6-88d2-d2c777bfbd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-49fdff6b-ecb6-4d59-88ea-fdf42f3dcab1,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-2e0f405e-98a2-40ac-9748-473ba93313d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-552b70b2-98ce-4fb9-8b10-9c0f0b6eb38e,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-5b0e1b62-80b3-4d0d-bbc7-b493871def4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-31adba63-d5c7-4c52-baaf-06605b9769bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-6ce4c5ea-8d31-4b43-abbf-9732aee87459,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-5e9ce7fc-7fe6-4b92-8199-23ba7bccd9b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-539440620-172.17.0.3-1597496806590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42815,DS-8797c685-bae4-44c6-88d2-d2c777bfbd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-49fdff6b-ecb6-4d59-88ea-fdf42f3dcab1,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-2e0f405e-98a2-40ac-9748-473ba93313d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-552b70b2-98ce-4fb9-8b10-9c0f0b6eb38e,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-5b0e1b62-80b3-4d0d-bbc7-b493871def4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-31adba63-d5c7-4c52-baaf-06605b9769bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-6ce4c5ea-8d31-4b43-abbf-9732aee87459,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-5e9ce7fc-7fe6-4b92-8199-23ba7bccd9b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-792811013-172.17.0.3-1597496989653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44383,DS-d3420e30-0da1-4017-b5bc-2ccec1176292,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-c23c5d61-9381-4e10-9d77-39960d36fe9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-f9f9d168-8e3e-4b24-9444-c2dbb5d15fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-0219d421-23b3-4a54-b1ed-236b281a5e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-31f92e22-4f73-4b05-8eb7-8e31c079a33a,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-7de1ccf1-0cad-4875-a12a-e41dce0bdfd2,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-aa00286d-b020-4768-8ffb-0cca5ca6f481,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-c48a90e0-ec68-4ea7-83f6-a596c50660f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-792811013-172.17.0.3-1597496989653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44383,DS-d3420e30-0da1-4017-b5bc-2ccec1176292,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-c23c5d61-9381-4e10-9d77-39960d36fe9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-f9f9d168-8e3e-4b24-9444-c2dbb5d15fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-0219d421-23b3-4a54-b1ed-236b281a5e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-31f92e22-4f73-4b05-8eb7-8e31c079a33a,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-7de1ccf1-0cad-4875-a12a-e41dce0bdfd2,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-aa00286d-b020-4768-8ffb-0cca5ca6f481,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-c48a90e0-ec68-4ea7-83f6-a596c50660f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832584374-172.17.0.3-1597497279013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42139,DS-14a38c32-b582-48fc-9993-9ed1a8e945e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-73ffbbb8-42bd-4a3a-abea-7e6a2dc8f301,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-0bb99c3b-bc2a-47ff-a17f-523a8dffd2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-aa987135-e2da-454f-87ca-4e2217bc3eea,DISK], DatanodeInfoWithStorage[127.0.0.1:44272,DS-69dd7224-e47c-492f-8201-896f6e248ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-3e80d1cc-36cc-4393-893b-a983c62ff1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-4f8632fd-5b5b-4525-b90f-eec53b6cf42d,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-98618054-2d9b-410b-8fab-e62522566fc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832584374-172.17.0.3-1597497279013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42139,DS-14a38c32-b582-48fc-9993-9ed1a8e945e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-73ffbbb8-42bd-4a3a-abea-7e6a2dc8f301,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-0bb99c3b-bc2a-47ff-a17f-523a8dffd2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-aa987135-e2da-454f-87ca-4e2217bc3eea,DISK], DatanodeInfoWithStorage[127.0.0.1:44272,DS-69dd7224-e47c-492f-8201-896f6e248ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-3e80d1cc-36cc-4393-893b-a983c62ff1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-4f8632fd-5b5b-4525-b90f-eec53b6cf42d,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-98618054-2d9b-410b-8fab-e62522566fc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2064226670-172.17.0.3-1597497465655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42571,DS-660a3adf-7678-48b2-90af-fadf6abe9c05,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-9166d215-105c-4440-8c0f-b6194d5a6b75,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-d404ea04-cfa2-4120-a119-4d35612a895d,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-7d14fc99-071c-491a-a17b-ced586e64d06,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-3400d51c-d03f-495a-9cbb-6e07ad837f74,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-f138ef2e-3cc1-4176-a122-c2f4ea7aafe5,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-a9668784-9fdf-491a-a7d8-55e513b744c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-20415c00-b314-4ad8-8d51-4fd76f3da93d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2064226670-172.17.0.3-1597497465655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42571,DS-660a3adf-7678-48b2-90af-fadf6abe9c05,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-9166d215-105c-4440-8c0f-b6194d5a6b75,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-d404ea04-cfa2-4120-a119-4d35612a895d,DISK], DatanodeInfoWithStorage[127.0.0.1:34732,DS-7d14fc99-071c-491a-a17b-ced586e64d06,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-3400d51c-d03f-495a-9cbb-6e07ad837f74,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-f138ef2e-3cc1-4176-a122-c2f4ea7aafe5,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-a9668784-9fdf-491a-a7d8-55e513b744c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-20415c00-b314-4ad8-8d51-4fd76f3da93d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-793940629-172.17.0.3-1597497507839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45322,DS-4d9cca23-88c8-4e91-984e-c159321a8525,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-7ff69223-3ae6-43e4-9650-030c0defad1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-dd89c3db-cd50-4c8c-ad60-edaf3691a73f,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-f0f06eee-a091-4c18-96ea-86bf41102877,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-33c2e858-fd13-4a4c-9c9f-17398e605fca,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-a9dd5759-3fe3-45ce-8f34-fd8365330ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-08ed3a94-2e22-4e16-b41d-a6f88f0c3639,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-1f85dd67-764f-4ed4-825f-c386425c0295,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-793940629-172.17.0.3-1597497507839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45322,DS-4d9cca23-88c8-4e91-984e-c159321a8525,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-7ff69223-3ae6-43e4-9650-030c0defad1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-dd89c3db-cd50-4c8c-ad60-edaf3691a73f,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-f0f06eee-a091-4c18-96ea-86bf41102877,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-33c2e858-fd13-4a4c-9c9f-17398e605fca,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-a9dd5759-3fe3-45ce-8f34-fd8365330ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-08ed3a94-2e22-4e16-b41d-a6f88f0c3639,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-1f85dd67-764f-4ed4-825f-c386425c0295,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726715269-172.17.0.3-1597497714692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39438,DS-01f8e0c7-7b45-415a-829b-27a402d82d54,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-164def30-4a84-450a-9c4d-ecc34a5ed21c,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-14afeb6d-70e7-434e-b7c2-505ed2b2a8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-4721860b-006b-49cc-93ba-1658f9f361d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-b16854fb-57d7-4a5b-9896-faf5bdc655cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-df6412ac-dc5f-49e9-afee-ebad7dd8c450,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-357d350e-f798-4bef-82a9-2509c2181698,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-0b1671e1-7c5c-49fc-a2fb-4f983ab4b831,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726715269-172.17.0.3-1597497714692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39438,DS-01f8e0c7-7b45-415a-829b-27a402d82d54,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-164def30-4a84-450a-9c4d-ecc34a5ed21c,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-14afeb6d-70e7-434e-b7c2-505ed2b2a8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-4721860b-006b-49cc-93ba-1658f9f361d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-b16854fb-57d7-4a5b-9896-faf5bdc655cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-df6412ac-dc5f-49e9-afee-ebad7dd8c450,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-357d350e-f798-4bef-82a9-2509c2181698,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-0b1671e1-7c5c-49fc-a2fb-4f983ab4b831,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-675660278-172.17.0.3-1597497756929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42967,DS-13169cc6-3791-4cef-b9c3-3e92e3001651,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-c65b3037-e574-491f-bf91-4c24a56c36d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-4f6e934c-77a5-4dcf-a9d5-4b3ac25cfe1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41017,DS-725c7a8a-db8d-4c41-9928-8cdd3b2c8848,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-78b81077-76c5-45ee-818b-09ce7df380cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-364fe27c-69e7-4c64-9d62-ad467b48ac3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-a1e3f3a6-82eb-405d-b4db-04ab231e5c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-e50aab77-6426-4ca0-8e8c-8bb7a625f3f0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-675660278-172.17.0.3-1597497756929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42967,DS-13169cc6-3791-4cef-b9c3-3e92e3001651,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-c65b3037-e574-491f-bf91-4c24a56c36d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-4f6e934c-77a5-4dcf-a9d5-4b3ac25cfe1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41017,DS-725c7a8a-db8d-4c41-9928-8cdd3b2c8848,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-78b81077-76c5-45ee-818b-09ce7df380cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-364fe27c-69e7-4c64-9d62-ad467b48ac3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-a1e3f3a6-82eb-405d-b4db-04ab231e5c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-e50aab77-6426-4ca0-8e8c-8bb7a625f3f0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-277935527-172.17.0.3-1597497791889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41505,DS-1ec68bd8-f547-431c-990a-5494ee921132,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-7597e782-c047-4b3d-aa0d-fe6d3abd6585,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-7e6392d6-589a-439b-9451-1b31913b1464,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-c5034852-18a5-4dec-a6be-64d12e7a272d,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-76e7280d-700f-4544-8a18-2bc2d1ef148d,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-0b7f1356-8719-4259-8957-da38430914e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-e72eef91-f421-4285-8ad4-835c3942a6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-8c8813f9-c7df-4244-b3db-78a9c2e58b4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-277935527-172.17.0.3-1597497791889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41505,DS-1ec68bd8-f547-431c-990a-5494ee921132,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-7597e782-c047-4b3d-aa0d-fe6d3abd6585,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-7e6392d6-589a-439b-9451-1b31913b1464,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-c5034852-18a5-4dec-a6be-64d12e7a272d,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-76e7280d-700f-4544-8a18-2bc2d1ef148d,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-0b7f1356-8719-4259-8957-da38430914e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-e72eef91-f421-4285-8ad4-835c3942a6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-8c8813f9-c7df-4244-b3db-78a9c2e58b4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2101106127-172.17.0.3-1597497906630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41738,DS-215b1f94-3818-484e-998d-aad0d3458e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-b0780d27-9747-4bbe-8e08-ca02504d4fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-10246600-d076-4dcb-9f25-7bf6165b88be,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-36aa76bc-cc68-40c7-ba80-d31f2f68aab9,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-3171b265-1cee-41a4-86b6-7a2c66139a45,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-997f6325-d82c-4d05-8736-f5f44c99527a,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-551a5b0b-68bb-4f19-9a1f-ab2924904edb,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-2ac426ca-5ecc-4a7b-8c26-b2c997eebdfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2101106127-172.17.0.3-1597497906630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41738,DS-215b1f94-3818-484e-998d-aad0d3458e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-b0780d27-9747-4bbe-8e08-ca02504d4fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-10246600-d076-4dcb-9f25-7bf6165b88be,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-36aa76bc-cc68-40c7-ba80-d31f2f68aab9,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-3171b265-1cee-41a4-86b6-7a2c66139a45,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-997f6325-d82c-4d05-8736-f5f44c99527a,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-551a5b0b-68bb-4f19-9a1f-ab2924904edb,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-2ac426ca-5ecc-4a7b-8c26-b2c997eebdfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1625195405-172.17.0.3-1597498016415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38632,DS-9d0ed9cc-7a23-472c-a055-acde547e65ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-eb59646d-db1e-43ff-b7f4-abd9a198b16f,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-2bfccfde-362a-4588-8220-28ac8b8c6642,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-ee28750b-223e-473e-822d-ee2218dcf750,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-98fc373f-8817-450b-9620-83a988c1d9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-1cf3b888-a623-4f60-8559-50758951752b,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-5c22170b-af1d-49db-8590-9a762ef518fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-50f49d19-00b7-4922-b172-f1874751bc39,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1625195405-172.17.0.3-1597498016415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38632,DS-9d0ed9cc-7a23-472c-a055-acde547e65ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-eb59646d-db1e-43ff-b7f4-abd9a198b16f,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-2bfccfde-362a-4588-8220-28ac8b8c6642,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-ee28750b-223e-473e-822d-ee2218dcf750,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-98fc373f-8817-450b-9620-83a988c1d9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-1cf3b888-a623-4f60-8559-50758951752b,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-5c22170b-af1d-49db-8590-9a762ef518fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-50f49d19-00b7-4922-b172-f1874751bc39,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-620591232-172.17.0.3-1597498098679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35246,DS-d1bf1313-ee1b-464d-86b3-e75530bc8220,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-b613272c-f387-4ebb-ae97-efe600066554,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-bf0d9361-d675-469d-abb3-e9f3a40b7407,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-19db8e00-264f-471e-a579-1147fb7a5af1,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-be368b28-7e75-46eb-a97d-f64ee4341b94,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-1863a877-4ab3-41da-a7cb-19dbd5d2d173,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-cdc58812-72e8-49bd-ab40-ce4d95996697,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-1ed1867c-01e9-4321-b937-64c1c2d6734d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-620591232-172.17.0.3-1597498098679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35246,DS-d1bf1313-ee1b-464d-86b3-e75530bc8220,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-b613272c-f387-4ebb-ae97-efe600066554,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-bf0d9361-d675-469d-abb3-e9f3a40b7407,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-19db8e00-264f-471e-a579-1147fb7a5af1,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-be368b28-7e75-46eb-a97d-f64ee4341b94,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-1863a877-4ab3-41da-a7cb-19dbd5d2d173,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-cdc58812-72e8-49bd-ab40-ce4d95996697,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-1ed1867c-01e9-4321-b937-64c1c2d6734d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1586495997-172.17.0.3-1597498209719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43912,DS-4e769d4c-f1b8-464a-8227-045c73d4c5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-ec84c267-b66a-4c7c-b1a9-658d9de91dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-7cf8ea44-37b8-4d06-8892-254e4f0358a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-a4b3c7bf-9172-4d5a-9b5f-898765d4f8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-4df34655-545d-418e-9e33-4a42708d93bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-91e3a77c-38f3-4ca2-9b5b-e1f54e81f20d,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-3719aa96-7876-4d7c-9d67-368747a59771,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-9ba25049-5df6-4c98-929d-7d281af1f428,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1586495997-172.17.0.3-1597498209719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43912,DS-4e769d4c-f1b8-464a-8227-045c73d4c5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-ec84c267-b66a-4c7c-b1a9-658d9de91dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-7cf8ea44-37b8-4d06-8892-254e4f0358a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-a4b3c7bf-9172-4d5a-9b5f-898765d4f8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-4df34655-545d-418e-9e33-4a42708d93bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-91e3a77c-38f3-4ca2-9b5b-e1f54e81f20d,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-3719aa96-7876-4d7c-9d67-368747a59771,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-9ba25049-5df6-4c98-929d-7d281af1f428,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1324942319-172.17.0.3-1597498247997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40216,DS-7a1bffb3-1d0e-486b-bc46-386979027243,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-df153670-4dee-49a1-a2b0-c44ea3df88e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-a2f09c3f-d6f2-4320-9584-8e3a1d591efd,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-42b9f623-5283-4cd6-afd1-c63b8706c379,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-d07f7e27-09d0-4012-86e1-6041310bde01,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-d211c335-78f1-4be2-9fff-879de2e22d51,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-65ecd170-824b-43cd-a1a4-c204b9bd705e,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-6b38006e-5650-48a5-b47d-01ab246856d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1324942319-172.17.0.3-1597498247997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40216,DS-7a1bffb3-1d0e-486b-bc46-386979027243,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-df153670-4dee-49a1-a2b0-c44ea3df88e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-a2f09c3f-d6f2-4320-9584-8e3a1d591efd,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-42b9f623-5283-4cd6-afd1-c63b8706c379,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-d07f7e27-09d0-4012-86e1-6041310bde01,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-d211c335-78f1-4be2-9fff-879de2e22d51,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-65ecd170-824b-43cd-a1a4-c204b9bd705e,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-6b38006e-5650-48a5-b47d-01ab246856d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-886448845-172.17.0.3-1597498666702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34354,DS-562b21d3-04fb-4a11-a0e0-caa01df79bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-fc499b83-17d9-4913-9207-38b4d297dafd,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-ca785e4d-b278-4c39-bb7f-2892fe5e16e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-0b529d0f-306d-4ca7-a65a-224b6c5c3c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-5c764615-f9e0-4a9e-ac2a-e31255db3141,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-93d33b87-987b-4299-bc97-648d156a2389,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-67c90da4-8350-4c0c-a2bf-c3fc1e77ea99,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-a6864ee0-07c5-41e7-b6e7-0027c9cebebb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-886448845-172.17.0.3-1597498666702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34354,DS-562b21d3-04fb-4a11-a0e0-caa01df79bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-fc499b83-17d9-4913-9207-38b4d297dafd,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-ca785e4d-b278-4c39-bb7f-2892fe5e16e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-0b529d0f-306d-4ca7-a65a-224b6c5c3c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-5c764615-f9e0-4a9e-ac2a-e31255db3141,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-93d33b87-987b-4299-bc97-648d156a2389,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-67c90da4-8350-4c0c-a2bf-c3fc1e77ea99,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-a6864ee0-07c5-41e7-b6e7-0027c9cebebb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1460452722-172.17.0.3-1597498785639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35695,DS-d67bd661-20dd-4594-b061-56094d068d32,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-8300ec2b-08c6-4cdd-9582-99893389217a,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-8d3f5048-52a2-4d90-9e2d-6452a5916fda,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-67f58cee-a12e-428e-aa54-749d6cfe3238,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-627cb4a8-64f5-4e3c-9ad4-f5a5e059a534,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-12a7b238-79f4-43d6-9081-2e20cfb5773e,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-b5d5a452-38d4-418c-b867-e243c6e679f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-15c28106-2bb7-4934-a22d-e9f46376b1a2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1460452722-172.17.0.3-1597498785639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35695,DS-d67bd661-20dd-4594-b061-56094d068d32,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-8300ec2b-08c6-4cdd-9582-99893389217a,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-8d3f5048-52a2-4d90-9e2d-6452a5916fda,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-67f58cee-a12e-428e-aa54-749d6cfe3238,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-627cb4a8-64f5-4e3c-9ad4-f5a5e059a534,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-12a7b238-79f4-43d6-9081-2e20cfb5773e,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-b5d5a452-38d4-418c-b867-e243c6e679f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-15c28106-2bb7-4934-a22d-e9f46376b1a2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675540653-172.17.0.3-1597498966993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35749,DS-16c22b1c-6668-4c6e-8f4c-881ad09b0bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-569599ce-8cb0-4d47-a01b-4fba7dac3403,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-65365c0a-667a-4fb7-882e-a5701e7fec91,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-1c056f88-4d4c-4236-8594-826149d24823,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-1827467b-921e-4072-b891-585673a5bd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-a8743f56-73ad-4204-af62-3bbd9ec080c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-532c47e4-eb3d-434d-b4ae-d8e9a69207d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-3c5fa3b5-9057-400d-a801-08e0b78ce0d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675540653-172.17.0.3-1597498966993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35749,DS-16c22b1c-6668-4c6e-8f4c-881ad09b0bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-569599ce-8cb0-4d47-a01b-4fba7dac3403,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-65365c0a-667a-4fb7-882e-a5701e7fec91,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-1c056f88-4d4c-4236-8594-826149d24823,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-1827467b-921e-4072-b891-585673a5bd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-a8743f56-73ad-4204-af62-3bbd9ec080c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-532c47e4-eb3d-434d-b4ae-d8e9a69207d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-3c5fa3b5-9057-400d-a801-08e0b78ce0d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596549250-172.17.0.3-1597499006399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42868,DS-85f438c9-db23-4468-bbf2-fa711d08e1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-f9d038e6-8844-4ef6-8fc3-552f419bec98,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-82f111ad-0bc1-4fec-b8c7-55e341921e14,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-6ee8c7b9-0768-4856-82e6-6243d9f5efff,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-c9d50172-647e-44c2-9435-0a74546e245b,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-625ad7c2-1662-4d82-9ba5-085e1ef10c82,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-a7c76bb6-c354-46fb-b193-64448de0153d,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-5c69c262-3424-49e2-a95c-7a720675a7b6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596549250-172.17.0.3-1597499006399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42868,DS-85f438c9-db23-4468-bbf2-fa711d08e1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-f9d038e6-8844-4ef6-8fc3-552f419bec98,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-82f111ad-0bc1-4fec-b8c7-55e341921e14,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-6ee8c7b9-0768-4856-82e6-6243d9f5efff,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-c9d50172-647e-44c2-9435-0a74546e245b,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-625ad7c2-1662-4d82-9ba5-085e1ef10c82,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-a7c76bb6-c354-46fb-b193-64448de0153d,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-5c69c262-3424-49e2-a95c-7a720675a7b6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1126212892-172.17.0.3-1597499239256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40828,DS-53549be3-51ce-493a-af92-7ce2593dd5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-b42fbe7b-e673-40af-b41b-6b8e9eb062b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-1de41782-c360-4b23-933f-e2213e924ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-cbc83fb0-dc71-40fc-97cf-99d88f0d06b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-c8e0c081-5beb-4f85-a630-7783e0f76074,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-62c2259f-0a05-4772-a474-8281e64dd7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-02700170-c999-4b35-8406-d200f5fb42b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-d5dc4296-2903-479a-8db3-ac98fe04dcff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1126212892-172.17.0.3-1597499239256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40828,DS-53549be3-51ce-493a-af92-7ce2593dd5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-b42fbe7b-e673-40af-b41b-6b8e9eb062b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-1de41782-c360-4b23-933f-e2213e924ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-cbc83fb0-dc71-40fc-97cf-99d88f0d06b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-c8e0c081-5beb-4f85-a630-7783e0f76074,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-62c2259f-0a05-4772-a474-8281e64dd7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-02700170-c999-4b35-8406-d200f5fb42b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-d5dc4296-2903-479a-8db3-ac98fe04dcff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1365009583-172.17.0.3-1597499402740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40593,DS-750d197a-feae-4895-8710-f716658d52a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-0e339275-4d98-46f9-bb02-bdecc43a8b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-ce3b8e71-3a71-451c-aea7-8e8835d5419b,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-5ea101c4-10f1-4763-9600-c9a3a1b1bb60,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-30fcb1ff-5e7e-4420-93f8-f1cde3080a59,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-0821541d-f317-4db2-b48b-7aea526516f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-c8d58a69-4bd3-4e3e-93d5-70d2f11fb142,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-4c2e6380-3ecc-4b83-ba7e-206f3e67b079,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1365009583-172.17.0.3-1597499402740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40593,DS-750d197a-feae-4895-8710-f716658d52a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-0e339275-4d98-46f9-bb02-bdecc43a8b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-ce3b8e71-3a71-451c-aea7-8e8835d5419b,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-5ea101c4-10f1-4763-9600-c9a3a1b1bb60,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-30fcb1ff-5e7e-4420-93f8-f1cde3080a59,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-0821541d-f317-4db2-b48b-7aea526516f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-c8d58a69-4bd3-4e3e-93d5-70d2f11fb142,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-4c2e6380-3ecc-4b83-ba7e-206f3e67b079,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-262429188-172.17.0.3-1597499443129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43544,DS-f04085b6-3299-4d6f-80a1-b366507293fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-e16bac40-7116-4121-b6d6-7a22afa54403,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-0aaf34fc-7c99-42d0-8ed9-18fe150e9b96,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-377be6ea-ad4e-458d-b349-ab2e259a3288,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-8cfa09c7-6c0d-440a-9cdd-2755023c1751,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-a26a89d6-6c8d-49a6-8e72-a35ec5f8c3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-b518504e-6c41-496a-bdf8-b3e68fe8192c,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-f7ea0bed-689c-4c5e-9fdc-0278a65a1144,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-262429188-172.17.0.3-1597499443129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43544,DS-f04085b6-3299-4d6f-80a1-b366507293fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-e16bac40-7116-4121-b6d6-7a22afa54403,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-0aaf34fc-7c99-42d0-8ed9-18fe150e9b96,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-377be6ea-ad4e-458d-b349-ab2e259a3288,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-8cfa09c7-6c0d-440a-9cdd-2755023c1751,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-a26a89d6-6c8d-49a6-8e72-a35ec5f8c3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-b518504e-6c41-496a-bdf8-b3e68fe8192c,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-f7ea0bed-689c-4c5e-9fdc-0278a65a1144,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002356921-172.17.0.3-1597499601499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43775,DS-0e93c457-57c6-46a5-a70c-33fc5a19a18e,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-06f90319-a3fc-496c-861c-5508033207e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-becee4d9-d869-41d9-8ea3-ae612ebc34e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-40a56683-e061-4527-9f52-df1b5e699de5,DISK], DatanodeInfoWithStorage[127.0.0.1:41209,DS-fb512313-a505-4ed5-9c47-436d4a130c30,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-f68955c8-521b-45ba-a862-e6142a62749b,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-5646e723-a6b4-4905-912c-54a4ad2fbbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-d22e2423-77e1-4220-a762-910c564a9ff8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002356921-172.17.0.3-1597499601499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43775,DS-0e93c457-57c6-46a5-a70c-33fc5a19a18e,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-06f90319-a3fc-496c-861c-5508033207e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-becee4d9-d869-41d9-8ea3-ae612ebc34e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42184,DS-40a56683-e061-4527-9f52-df1b5e699de5,DISK], DatanodeInfoWithStorage[127.0.0.1:41209,DS-fb512313-a505-4ed5-9c47-436d4a130c30,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-f68955c8-521b-45ba-a862-e6142a62749b,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-5646e723-a6b4-4905-912c-54a4ad2fbbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-d22e2423-77e1-4220-a762-910c564a9ff8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-705789521-172.17.0.3-1597499713868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43581,DS-382572ba-a186-4212-8e5b-76d7a875f879,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-31364d99-01cc-496e-a629-74251692619f,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-8a56c450-d147-4198-ac9e-29b0825f9137,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-e2ee4d83-b698-4323-8e2e-5cb029e9d693,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-cc597d1b-3f16-4dfd-a1bc-6a727e6c0bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-f3bcd92a-d8c1-4951-bcfd-b112363ac090,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-ab0773de-f64b-4ccb-b5ac-8193a7ffa468,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-fa895778-f72e-4305-9661-74dc057b4bc2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-705789521-172.17.0.3-1597499713868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43581,DS-382572ba-a186-4212-8e5b-76d7a875f879,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-31364d99-01cc-496e-a629-74251692619f,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-8a56c450-d147-4198-ac9e-29b0825f9137,DISK], DatanodeInfoWithStorage[127.0.0.1:35162,DS-e2ee4d83-b698-4323-8e2e-5cb029e9d693,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-cc597d1b-3f16-4dfd-a1bc-6a727e6c0bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-f3bcd92a-d8c1-4951-bcfd-b112363ac090,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-ab0773de-f64b-4ccb-b5ac-8193a7ffa468,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-fa895778-f72e-4305-9661-74dc057b4bc2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2013331732-172.17.0.3-1597499751964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37264,DS-70ed9eed-01b9-4fd4-9564-87b02fd6595f,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-b5122c65-3fcb-49de-91dd-c3b4ffba4ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-f7d3cd60-c2e7-43fb-a1e1-12582038ac0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-6f212612-d967-4e2d-b426-aa721194d9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-ae87c1fd-7e0c-472b-986a-042393373e61,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-a0040535-6115-4561-8b18-23124f85535f,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-60ba2a27-dbc5-48b8-918e-53b961a2c3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-08ecb757-b646-4f04-82e5-3c32616f6a63,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2013331732-172.17.0.3-1597499751964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37264,DS-70ed9eed-01b9-4fd4-9564-87b02fd6595f,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-b5122c65-3fcb-49de-91dd-c3b4ffba4ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-f7d3cd60-c2e7-43fb-a1e1-12582038ac0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-6f212612-d967-4e2d-b426-aa721194d9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-ae87c1fd-7e0c-472b-986a-042393373e61,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-a0040535-6115-4561-8b18-23124f85535f,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-60ba2a27-dbc5-48b8-918e-53b961a2c3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-08ecb757-b646-4f04-82e5-3c32616f6a63,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-830065511-172.17.0.3-1597499792549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40555,DS-827eecef-e8f0-43a6-97a3-469fc7f7e2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-5ceac807-9633-45c6-9fbb-06298471e6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-03f9d049-990c-49a4-9eca-2ee726fb7376,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-379cd07a-c5c3-4ac4-8b8d-d9aa89c2f275,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-9846da3b-43b1-4ae3-b68b-4797ef65fccd,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-ddc32bb4-d670-408e-b820-44abae5ef560,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-bcb038f6-8725-4b2f-b1af-7c0723ced8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-2897f382-8747-41b4-a58e-d219b064f74e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-830065511-172.17.0.3-1597499792549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40555,DS-827eecef-e8f0-43a6-97a3-469fc7f7e2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-5ceac807-9633-45c6-9fbb-06298471e6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-03f9d049-990c-49a4-9eca-2ee726fb7376,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-379cd07a-c5c3-4ac4-8b8d-d9aa89c2f275,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-9846da3b-43b1-4ae3-b68b-4797ef65fccd,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-ddc32bb4-d670-408e-b820-44abae5ef560,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-bcb038f6-8725-4b2f-b1af-7c0723ced8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-2897f382-8747-41b4-a58e-d219b064f74e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1698065545-172.17.0.3-1597499902520:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43600,DS-4831e0bb-db2b-46bb-8c2b-711f330b71ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-887f263d-8582-4d52-8fe3-3af5d63b1e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-41e00602-03d0-4d5c-a278-438b75caec30,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-46f1dc94-563e-4d6b-9230-5f944c2caafb,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-602c6b4c-9a44-487a-8b7d-df97b646bc18,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-c57ff190-a0b5-472e-9aa6-26b060936676,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-7b2c4ccd-a7ce-4356-8847-0aaa8d60ed5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-b1c5d7f0-e09c-4c12-8612-3fd03a03fa0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1698065545-172.17.0.3-1597499902520:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43600,DS-4831e0bb-db2b-46bb-8c2b-711f330b71ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-887f263d-8582-4d52-8fe3-3af5d63b1e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-41e00602-03d0-4d5c-a278-438b75caec30,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-46f1dc94-563e-4d6b-9230-5f944c2caafb,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-602c6b4c-9a44-487a-8b7d-df97b646bc18,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-c57ff190-a0b5-472e-9aa6-26b060936676,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-7b2c4ccd-a7ce-4356-8847-0aaa8d60ed5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-b1c5d7f0-e09c-4c12-8612-3fd03a03fa0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1844003358-172.17.0.3-1597499944852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40894,DS-296d3b13-7015-4df9-84bf-af5624fd1b13,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-4bb92eaa-c410-45ae-94b0-2ab3a257caca,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-498cbcfe-477e-4e7c-b66b-1b4f0eb6b3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-96b70df8-d23c-468f-be0e-f1bffcef5cff,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-74240330-676e-49ab-95f5-aec8368df32e,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-04f0c08a-7fba-4a39-ab33-50e005fe0de7,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-325cf345-aca2-4f0b-b908-36d6c757d7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-e40ced4a-731a-4948-91db-c2e7be1bc4d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1844003358-172.17.0.3-1597499944852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40894,DS-296d3b13-7015-4df9-84bf-af5624fd1b13,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-4bb92eaa-c410-45ae-94b0-2ab3a257caca,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-498cbcfe-477e-4e7c-b66b-1b4f0eb6b3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-96b70df8-d23c-468f-be0e-f1bffcef5cff,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-74240330-676e-49ab-95f5-aec8368df32e,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-04f0c08a-7fba-4a39-ab33-50e005fe0de7,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-325cf345-aca2-4f0b-b908-36d6c757d7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-e40ced4a-731a-4948-91db-c2e7be1bc4d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1358349486-172.17.0.3-1597500397081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44675,DS-d1da2260-feab-4521-99ba-3b2f363210f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-be043a5b-a2b2-4fbb-83fa-a4321658cb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-8c726e46-5f3e-48e9-b821-38b376a445cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-e1b3fb7f-5f5c-4954-9057-112769f878b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-f8974add-7def-498f-8f1b-1f1d5146d840,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-245a9fa9-c3d9-4460-aa1a-76883d39093c,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-d40a0ff9-106d-440e-bd00-515785bed243,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-d41af627-196c-4e8c-bc34-b2fef8e27ed2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1358349486-172.17.0.3-1597500397081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44675,DS-d1da2260-feab-4521-99ba-3b2f363210f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-be043a5b-a2b2-4fbb-83fa-a4321658cb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-8c726e46-5f3e-48e9-b821-38b376a445cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-e1b3fb7f-5f5c-4954-9057-112769f878b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-f8974add-7def-498f-8f1b-1f1d5146d840,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-245a9fa9-c3d9-4460-aa1a-76883d39093c,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-d40a0ff9-106d-440e-bd00-515785bed243,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-d41af627-196c-4e8c-bc34-b2fef8e27ed2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.bandwidthPerSec
component: hdfs:DataNode
v1: 10485760
v2: 1m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663727812-172.17.0.3-1597500476104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33810,DS-ccfdd9e4-dcdc-401e-95b4-da4135608627,DISK], DatanodeInfoWithStorage[127.0.0.1:42796,DS-5ef44fb5-b5e3-48d9-936f-6fea57fdf5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-c6d7fa78-412b-47a1-b437-ec4554721766,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-82716361-c482-417e-aa0c-af7175f30f85,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-15afe4de-ef8b-4914-b62b-054585659733,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-3eb036b7-ba09-48e7-8017-5406959c555e,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-c3a58398-39e4-46cf-80b3-576728fa5eca,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-5ee5bb86-a437-41d0-9a39-b5c8430dfc56,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663727812-172.17.0.3-1597500476104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33810,DS-ccfdd9e4-dcdc-401e-95b4-da4135608627,DISK], DatanodeInfoWithStorage[127.0.0.1:42796,DS-5ef44fb5-b5e3-48d9-936f-6fea57fdf5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-c6d7fa78-412b-47a1-b437-ec4554721766,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-82716361-c482-417e-aa0c-af7175f30f85,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-15afe4de-ef8b-4914-b62b-054585659733,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-3eb036b7-ba09-48e7-8017-5406959c555e,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-c3a58398-39e4-46cf-80b3-576728fa5eca,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-5ee5bb86-a437-41d0-9a39-b5c8430dfc56,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 14 out of 50
v1v1v2v2 failed with probability 21 out of 50
result: false positive !!!
Total execution time in seconds : 5706
