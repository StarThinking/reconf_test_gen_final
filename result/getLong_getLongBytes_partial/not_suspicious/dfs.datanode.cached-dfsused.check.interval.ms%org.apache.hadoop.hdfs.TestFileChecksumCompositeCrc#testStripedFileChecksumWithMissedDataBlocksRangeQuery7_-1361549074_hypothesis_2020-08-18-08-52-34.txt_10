reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789576949-172.17.0.11-1597740980331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38231,DS-9bb829fd-e6c6-4786-83df-50165be48e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-1839d650-45f6-4fc0-9a82-a13d49fdf500,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-da1fbb18-96f5-4133-86be-8102d53910d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-79db42eb-e0df-486c-a867-316feb2e3a03,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-03f42b1f-c5c6-4966-af90-d85fb3c0352b,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-6dfb25fb-0a2f-4ff4-925b-180da42ee513,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-c407e08a-5ca8-4fec-9500-dc2912b10c13,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-a9b2e0b6-91d6-45ec-ab60-2332a4a0f626,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789576949-172.17.0.11-1597740980331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38231,DS-9bb829fd-e6c6-4786-83df-50165be48e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-1839d650-45f6-4fc0-9a82-a13d49fdf500,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-da1fbb18-96f5-4133-86be-8102d53910d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-79db42eb-e0df-486c-a867-316feb2e3a03,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-03f42b1f-c5c6-4966-af90-d85fb3c0352b,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-6dfb25fb-0a2f-4ff4-925b-180da42ee513,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-c407e08a-5ca8-4fec-9500-dc2912b10c13,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-a9b2e0b6-91d6-45ec-ab60-2332a4a0f626,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2039598802-172.17.0.11-1597741264721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35705,DS-ad3dfa8b-ef96-4210-945e-e8f9389eeca4,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-0dc51b23-ace2-49b4-bb9a-adfc32a7b620,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-d7082a01-76e5-4a88-a747-d6502bdc4ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-7205db8f-7d28-40a5-9add-759a04ae4109,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-77636e41-9c97-46b0-a8c2-253b48a8cbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-e359872f-09e1-4716-8b9c-06000834253e,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-487ae861-5aee-4633-9d23-8cd5850c64cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-db85eb96-2375-485c-9689-160877e114c8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2039598802-172.17.0.11-1597741264721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35705,DS-ad3dfa8b-ef96-4210-945e-e8f9389eeca4,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-0dc51b23-ace2-49b4-bb9a-adfc32a7b620,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-d7082a01-76e5-4a88-a747-d6502bdc4ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-7205db8f-7d28-40a5-9add-759a04ae4109,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-77636e41-9c97-46b0-a8c2-253b48a8cbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-e359872f-09e1-4716-8b9c-06000834253e,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-487ae861-5aee-4633-9d23-8cd5850c64cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42742,DS-db85eb96-2375-485c-9689-160877e114c8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-207076256-172.17.0.11-1597741596637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38111,DS-e3f1393f-99b5-4665-ac8f-63c110306b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-a773efb9-f3a7-4626-aebd-9e75fd7d677b,DISK], DatanodeInfoWithStorage[127.0.0.1:36915,DS-51d97632-d390-4a6d-99b2-4cf0484bfac5,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-37cffebd-370d-4e98-9354-69158fd85c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-3dd5a7b2-68d2-48fd-a142-13e150f6c455,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-8e71c1e2-fc24-47b4-ad16-b7b6a09b4d53,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-75d47e4e-abf3-4191-8d2a-891f1bbef964,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-1de3a915-7989-44ed-8adf-715a81bac1bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-207076256-172.17.0.11-1597741596637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38111,DS-e3f1393f-99b5-4665-ac8f-63c110306b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-a773efb9-f3a7-4626-aebd-9e75fd7d677b,DISK], DatanodeInfoWithStorage[127.0.0.1:36915,DS-51d97632-d390-4a6d-99b2-4cf0484bfac5,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-37cffebd-370d-4e98-9354-69158fd85c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-3dd5a7b2-68d2-48fd-a142-13e150f6c455,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-8e71c1e2-fc24-47b4-ad16-b7b6a09b4d53,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-75d47e4e-abf3-4191-8d2a-891f1bbef964,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-1de3a915-7989-44ed-8adf-715a81bac1bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-784252479-172.17.0.11-1597741626687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36503,DS-61b50962-531a-4d0f-9439-1823ec72a7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-27cdc893-89fb-47bb-b7ee-3e445fd3b614,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-0c7a69d5-c14e-4491-8eb9-df7bc5242f64,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-aa6542f6-3c41-45dc-bc61-0be2f9131cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-56df0a7b-91a5-48ad-8a8b-e69fe4711676,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-0a55bd40-310a-4578-a42c-2ed7aa8cb5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-0c902850-e8ef-4ff6-ba96-1463a995b9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-60b9224a-80a9-45f2-b1f0-74073a98c198,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-784252479-172.17.0.11-1597741626687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36503,DS-61b50962-531a-4d0f-9439-1823ec72a7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-27cdc893-89fb-47bb-b7ee-3e445fd3b614,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-0c7a69d5-c14e-4491-8eb9-df7bc5242f64,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-aa6542f6-3c41-45dc-bc61-0be2f9131cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-56df0a7b-91a5-48ad-8a8b-e69fe4711676,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-0a55bd40-310a-4578-a42c-2ed7aa8cb5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-0c902850-e8ef-4ff6-ba96-1463a995b9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-60b9224a-80a9-45f2-b1f0-74073a98c198,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726841284-172.17.0.11-1597741848985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43263,DS-089fcdeb-65b7-4c05-a107-b64751efc663,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-d7cf8c5d-e8bf-45cc-ac85-0dd33eecd592,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-02660c20-6023-4b66-85f7-b1cf8ca632d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-c6b487ea-8d3d-4954-9459-898b35831627,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-2db54e7d-c7f1-4217-bb6d-bd031aa50240,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-ebb55529-400b-449b-b4c9-0179219d33cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-e4d3f916-e562-4d54-b80e-19777f29ffe8,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-0c73f928-edaf-4060-837e-46cf32594d6f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726841284-172.17.0.11-1597741848985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43263,DS-089fcdeb-65b7-4c05-a107-b64751efc663,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-d7cf8c5d-e8bf-45cc-ac85-0dd33eecd592,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-02660c20-6023-4b66-85f7-b1cf8ca632d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-c6b487ea-8d3d-4954-9459-898b35831627,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-2db54e7d-c7f1-4217-bb6d-bd031aa50240,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-ebb55529-400b-449b-b4c9-0179219d33cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-e4d3f916-e562-4d54-b80e-19777f29ffe8,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-0c73f928-edaf-4060-837e-46cf32594d6f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1930605477-172.17.0.11-1597742307118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46860,DS-44f9d34f-b9f0-4adf-a563-88ba85f8467d,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-4ff0c976-6b8a-4ec2-8e2d-ff7066e7799a,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-2538b7f5-9dd2-4cda-9f18-44832e62658f,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-fb71564b-4dfc-4afb-842d-209b18cf41d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-11a5ca98-87f8-4498-9b49-1f0b1303e935,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-d90eaea1-5aea-4bb7-acd6-e263e27bbe5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-a59c6391-88cf-4d48-b176-a82a0bcc616d,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-f4f0e417-539d-4bd6-9199-78c8bddcbbfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1930605477-172.17.0.11-1597742307118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46860,DS-44f9d34f-b9f0-4adf-a563-88ba85f8467d,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-4ff0c976-6b8a-4ec2-8e2d-ff7066e7799a,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-2538b7f5-9dd2-4cda-9f18-44832e62658f,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-fb71564b-4dfc-4afb-842d-209b18cf41d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-11a5ca98-87f8-4498-9b49-1f0b1303e935,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-d90eaea1-5aea-4bb7-acd6-e263e27bbe5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-a59c6391-88cf-4d48-b176-a82a0bcc616d,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-f4f0e417-539d-4bd6-9199-78c8bddcbbfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-477888326-172.17.0.11-1597742342866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42740,DS-dac505f0-8463-4355-a6a3-78ae50273de7,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-9fea62cd-2e14-43be-b1a0-d4081f986d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-f717065d-effb-4e58-8f42-84828408634d,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-954233f5-2989-4799-8bb5-9d55cfcc7700,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-9608c291-74e0-47f5-b6b1-25755aa21ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-efbdb424-f146-43b1-aa6c-33663b892ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-0eaf9eac-c50e-4bbb-b3c7-88eedd4401b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-a82ff018-0d71-4cb3-809a-1357bc86490e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-477888326-172.17.0.11-1597742342866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42740,DS-dac505f0-8463-4355-a6a3-78ae50273de7,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-9fea62cd-2e14-43be-b1a0-d4081f986d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-f717065d-effb-4e58-8f42-84828408634d,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-954233f5-2989-4799-8bb5-9d55cfcc7700,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-9608c291-74e0-47f5-b6b1-25755aa21ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-efbdb424-f146-43b1-aa6c-33663b892ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-0eaf9eac-c50e-4bbb-b3c7-88eedd4401b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-a82ff018-0d71-4cb3-809a-1357bc86490e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21305879-172.17.0.11-1597742635937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37845,DS-974e4a1e-666c-487b-919c-42502c01ab05,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-c8359296-6a2c-4d06-95e1-bfde27651579,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-38364467-714e-40ea-976d-98cb70de2900,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-638c07ca-da60-412d-9da7-23928cc3e52b,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-81340f36-d5a0-4bde-a922-86c442536d90,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-f17cc8fb-6cf3-4931-88e9-ca1293b514cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-fb458fb5-127f-400e-b10f-89a3cc0e4add,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-620e62a0-6f98-42e2-a989-00c9d82fa8c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21305879-172.17.0.11-1597742635937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37845,DS-974e4a1e-666c-487b-919c-42502c01ab05,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-c8359296-6a2c-4d06-95e1-bfde27651579,DISK], DatanodeInfoWithStorage[127.0.0.1:39671,DS-38364467-714e-40ea-976d-98cb70de2900,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-638c07ca-da60-412d-9da7-23928cc3e52b,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-81340f36-d5a0-4bde-a922-86c442536d90,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-f17cc8fb-6cf3-4931-88e9-ca1293b514cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-fb458fb5-127f-400e-b10f-89a3cc0e4add,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-620e62a0-6f98-42e2-a989-00c9d82fa8c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-542132391-172.17.0.11-1597742997864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46568,DS-aade9d29-dec9-4551-a378-a9d344a5ce90,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-d83f1738-7353-49fa-ba42-554b3429142c,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-59501f3e-8a7b-40a6-be24-a4b03cf811a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-02afb007-5ddb-48e8-a1a2-49467443ad10,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-12d6b012-c60f-4da0-82e7-d169711d134d,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-9e73e77d-059b-43f0-afdb-b79a4e0932f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-387ea556-23d2-475d-966a-f5663995360b,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-ef6aa642-f00f-4402-b583-ec1a9a50b89f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-542132391-172.17.0.11-1597742997864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46568,DS-aade9d29-dec9-4551-a378-a9d344a5ce90,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-d83f1738-7353-49fa-ba42-554b3429142c,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-59501f3e-8a7b-40a6-be24-a4b03cf811a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-02afb007-5ddb-48e8-a1a2-49467443ad10,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-12d6b012-c60f-4da0-82e7-d169711d134d,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-9e73e77d-059b-43f0-afdb-b79a4e0932f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-387ea556-23d2-475d-966a-f5663995360b,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-ef6aa642-f00f-4402-b583-ec1a9a50b89f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1162525423-172.17.0.11-1597743557568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37234,DS-cd6a1ee3-fee7-433b-bb3e-336094a776fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-e50e5395-2114-40a2-887f-5a8bb38da0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-8915446c-fcf6-4dde-9f99-98e7bb2697ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-90adefc6-cb78-4045-818f-c8bc79d65f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-a7a57d77-4714-4bd9-9812-3c44aa878869,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-827e658b-5f15-489c-812a-16cdf1e9ab0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-23dfbb10-b0ec-46e1-92e6-e8309542af30,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-f83b2826-e87a-4344-8305-59e786f768c6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1162525423-172.17.0.11-1597743557568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37234,DS-cd6a1ee3-fee7-433b-bb3e-336094a776fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-e50e5395-2114-40a2-887f-5a8bb38da0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-8915446c-fcf6-4dde-9f99-98e7bb2697ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-90adefc6-cb78-4045-818f-c8bc79d65f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-a7a57d77-4714-4bd9-9812-3c44aa878869,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-827e658b-5f15-489c-812a-16cdf1e9ab0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-23dfbb10-b0ec-46e1-92e6-e8309542af30,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-f83b2826-e87a-4344-8305-59e786f768c6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759407287-172.17.0.11-1597743596380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43176,DS-ee21279a-2d71-48a8-a1f8-891d1d50452a,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-f279318c-3fda-480d-a971-a1bf34b9eb05,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-a35769e2-ea9a-4d0e-b6b7-1dde796953fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-2616418f-6ab4-4b0c-85f6-b5015d76db64,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-3908e50c-b88e-48ef-aa7e-a6cb1c0c6b30,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-4f2ef568-23af-4cb1-89c0-377095d3e870,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-d72bb6bc-fed4-4665-a05a-f0b372edd8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-eca9766b-06bb-4405-b1f7-3204c9872415,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759407287-172.17.0.11-1597743596380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43176,DS-ee21279a-2d71-48a8-a1f8-891d1d50452a,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-f279318c-3fda-480d-a971-a1bf34b9eb05,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-a35769e2-ea9a-4d0e-b6b7-1dde796953fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-2616418f-6ab4-4b0c-85f6-b5015d76db64,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-3908e50c-b88e-48ef-aa7e-a6cb1c0c6b30,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-4f2ef568-23af-4cb1-89c0-377095d3e870,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-d72bb6bc-fed4-4665-a05a-f0b372edd8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-eca9766b-06bb-4405-b1f7-3204c9872415,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1469146639-172.17.0.11-1597743637747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39482,DS-b3fcf794-5627-465a-ac07-b125fd92faef,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-500b60d2-98ca-4833-9fb2-ba3d0ed95208,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-23f7082f-ec28-4469-8ccf-bf668343c551,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-78892b21-e245-4a2c-be76-f0b607882403,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-a719c077-c02f-4e40-bd0a-a0f811e43441,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-c530d7a6-73e4-4ea2-a278-a7a225adb1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-b6790337-83d9-4879-a53e-57f91ab4b518,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-dd8fe22b-1808-4819-b60b-cb0eaef02630,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1469146639-172.17.0.11-1597743637747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39482,DS-b3fcf794-5627-465a-ac07-b125fd92faef,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-500b60d2-98ca-4833-9fb2-ba3d0ed95208,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-23f7082f-ec28-4469-8ccf-bf668343c551,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-78892b21-e245-4a2c-be76-f0b607882403,DISK], DatanodeInfoWithStorage[127.0.0.1:46068,DS-a719c077-c02f-4e40-bd0a-a0f811e43441,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-c530d7a6-73e4-4ea2-a278-a7a225adb1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-b6790337-83d9-4879-a53e-57f91ab4b518,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-dd8fe22b-1808-4819-b60b-cb0eaef02630,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-935299636-172.17.0.11-1597743919976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45279,DS-cb0cb898-8ba5-4c05-939c-363fe08f7eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-c7088dd6-8bd2-4384-95a4-9af8e482f7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-6339a086-5e6e-4d76-b272-1ec3e6db8ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-0cf79610-88d2-48b6-9747-6af2316e38a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-cf927ce4-112e-4148-9187-23c7e5fc9678,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-29ebe172-6542-45db-adb5-ddc45c37cbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-a6c93995-7c27-43ff-83da-806dd0a73648,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-cbbd1333-093f-4dfb-802b-c85ed6395d59,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-935299636-172.17.0.11-1597743919976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45279,DS-cb0cb898-8ba5-4c05-939c-363fe08f7eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-c7088dd6-8bd2-4384-95a4-9af8e482f7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-6339a086-5e6e-4d76-b272-1ec3e6db8ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-0cf79610-88d2-48b6-9747-6af2316e38a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-cf927ce4-112e-4148-9187-23c7e5fc9678,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-29ebe172-6542-45db-adb5-ddc45c37cbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-a6c93995-7c27-43ff-83da-806dd0a73648,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-cbbd1333-093f-4dfb-802b-c85ed6395d59,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-559983547-172.17.0.11-1597744112470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43537,DS-ee151e62-0deb-49b2-b17e-9f7d2d41f120,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-f672cd99-9c8a-488d-bdda-4af57116153d,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-ef8d959e-e2f4-44a5-aaf3-ff8cd68e2015,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-a60002a6-0cfb-4692-966b-0535f6c07360,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-dedc7791-f0b8-4516-a3fb-9f9d1d2cfb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-a8392fda-379b-45e8-b670-de1f4c2fd5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-b12d16b2-fd66-464d-a30a-67ad05b35d25,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-3a3faca9-3962-4693-b90b-c0e75aa24e60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-559983547-172.17.0.11-1597744112470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43537,DS-ee151e62-0deb-49b2-b17e-9f7d2d41f120,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-f672cd99-9c8a-488d-bdda-4af57116153d,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-ef8d959e-e2f4-44a5-aaf3-ff8cd68e2015,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-a60002a6-0cfb-4692-966b-0535f6c07360,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-dedc7791-f0b8-4516-a3fb-9f9d1d2cfb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-a8392fda-379b-45e8-b670-de1f4c2fd5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-b12d16b2-fd66-464d-a30a-67ad05b35d25,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-3a3faca9-3962-4693-b90b-c0e75aa24e60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443688462-172.17.0.11-1597744283880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36529,DS-ae302913-9d38-44d1-bff6-7d734d97914c,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-e9948f08-d1f3-4f49-ae99-80ad53baacf6,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-c17bc4ec-4f65-4a81-a968-a52bf3dbd98a,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-d16cf167-0457-497c-83a1-7f535b4b7db8,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-93f38c7c-914e-411a-b3c9-3e6011427bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-110b793a-438c-4945-8919-5f13cd018bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-11bd125c-9ad7-459e-abee-3e8cc8e5f978,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-c27ec658-3eee-4630-90df-f2d70cfd5ad2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443688462-172.17.0.11-1597744283880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36529,DS-ae302913-9d38-44d1-bff6-7d734d97914c,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-e9948f08-d1f3-4f49-ae99-80ad53baacf6,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-c17bc4ec-4f65-4a81-a968-a52bf3dbd98a,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-d16cf167-0457-497c-83a1-7f535b4b7db8,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-93f38c7c-914e-411a-b3c9-3e6011427bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-110b793a-438c-4945-8919-5f13cd018bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-11bd125c-9ad7-459e-abee-3e8cc8e5f978,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-c27ec658-3eee-4630-90df-f2d70cfd5ad2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1262855698-172.17.0.11-1597744477964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39342,DS-7674f21f-1c07-49e0-8d23-a2c0ebe78159,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-3f820c1e-6c4a-49e2-b881-d4532a362776,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-eb70530f-7a5f-4905-a344-1b021d546054,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-dcf9934d-46c4-453c-b8b7-76fcfb2b62f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-a2b58a58-2892-41cf-8a3d-5b5e90dc97f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-d1ee9fef-7f19-4885-adf2-cfbfc7e00a99,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-a1e5d5da-9c8a-4cdc-80e5-4288b4681e49,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-27df1cc3-71ef-4d4c-bef6-57ad77a3f65e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1262855698-172.17.0.11-1597744477964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39342,DS-7674f21f-1c07-49e0-8d23-a2c0ebe78159,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-3f820c1e-6c4a-49e2-b881-d4532a362776,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-eb70530f-7a5f-4905-a344-1b021d546054,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-dcf9934d-46c4-453c-b8b7-76fcfb2b62f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-a2b58a58-2892-41cf-8a3d-5b5e90dc97f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-d1ee9fef-7f19-4885-adf2-cfbfc7e00a99,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-a1e5d5da-9c8a-4cdc-80e5-4288b4681e49,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-27df1cc3-71ef-4d4c-bef6-57ad77a3f65e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1171702180-172.17.0.11-1597744518861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36433,DS-991ce055-c0e0-4d5c-8326-5f3fa2772ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-23202390-9a2d-4497-b4a8-1906cf2d993d,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-0fcb9009-2574-4a76-ab1d-0c721f520782,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-1dd3637e-8e72-4fea-b849-4799f33fbfe4,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-d8dabe2b-dd4e-4797-8003-01c2f3d91bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-d274abab-e8f5-4eff-8dc0-0a14eadd32f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-1c7ae13f-084d-4eb4-9776-426aa59b6e03,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-0801437d-f64d-44f6-9687-447dc62b9c83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1171702180-172.17.0.11-1597744518861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36433,DS-991ce055-c0e0-4d5c-8326-5f3fa2772ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-23202390-9a2d-4497-b4a8-1906cf2d993d,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-0fcb9009-2574-4a76-ab1d-0c721f520782,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-1dd3637e-8e72-4fea-b849-4799f33fbfe4,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-d8dabe2b-dd4e-4797-8003-01c2f3d91bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-d274abab-e8f5-4eff-8dc0-0a14eadd32f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-1c7ae13f-084d-4eb4-9776-426aa59b6e03,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-0801437d-f64d-44f6-9687-447dc62b9c83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580616575-172.17.0.11-1597744814515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33797,DS-09042330-8280-4c1a-aace-2a178b92ffb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-8e1b1986-7609-4654-bb37-00d11f4c1b84,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-3cae0403-aab4-4ae6-8915-2e2384d91f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-e6780c8a-b3ee-46ed-b328-ee301b4abe24,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-47250d87-4f5e-4434-9334-c28c320503bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-7069e8bf-4c2f-42e0-90fd-c1acdb8c404a,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-82534293-fe23-4a08-a649-589a1802bb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-2524276b-c48c-4f4e-9be0-5944f3ad739c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580616575-172.17.0.11-1597744814515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33797,DS-09042330-8280-4c1a-aace-2a178b92ffb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-8e1b1986-7609-4654-bb37-00d11f4c1b84,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-3cae0403-aab4-4ae6-8915-2e2384d91f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-e6780c8a-b3ee-46ed-b328-ee301b4abe24,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-47250d87-4f5e-4434-9334-c28c320503bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-7069e8bf-4c2f-42e0-90fd-c1acdb8c404a,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-82534293-fe23-4a08-a649-589a1802bb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-2524276b-c48c-4f4e-9be0-5944f3ad739c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-69969229-172.17.0.11-1597744891507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46532,DS-c112588a-c5b9-43e6-a3d1-7a44a1f52d09,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-45765e49-78cc-46b4-92e7-464c78094416,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-d8ebda3e-2e30-473b-9200-3236521ba9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-3221d81e-9db6-4ed7-8b51-93fc2ff2b9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-f3c20ec9-7381-4c2e-9aa5-7e71626a051f,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-738ea7cb-94c7-4a7e-8081-aeba2f3f6336,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-da959af1-b768-4779-809c-6d89a483a85f,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-ca075deb-c0a3-4ee0-80a8-7c9d92804627,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-69969229-172.17.0.11-1597744891507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46532,DS-c112588a-c5b9-43e6-a3d1-7a44a1f52d09,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-45765e49-78cc-46b4-92e7-464c78094416,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-d8ebda3e-2e30-473b-9200-3236521ba9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-3221d81e-9db6-4ed7-8b51-93fc2ff2b9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-f3c20ec9-7381-4c2e-9aa5-7e71626a051f,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-738ea7cb-94c7-4a7e-8081-aeba2f3f6336,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-da959af1-b768-4779-809c-6d89a483a85f,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-ca075deb-c0a3-4ee0-80a8-7c9d92804627,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1358904946-172.17.0.11-1597745034957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45168,DS-ad88b003-a227-462c-81a0-0d478653abe0,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-bf16abf1-caea-43df-9261-b80a0339edff,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-1ae4122c-92f8-46f8-ac20-ad8c434f55ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-c945479b-9f47-43e3-8ba4-e0ce2dba2cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-3e03ae60-aec1-4a9c-9f99-421a6173c5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-6a56c50b-f272-445f-8942-c23b8bdc8cef,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-47d65891-e0cb-4cf3-8f1b-8791d913dc90,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-e2f64b0f-5a0c-4f7c-b5ce-a12dde257228,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1358904946-172.17.0.11-1597745034957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45168,DS-ad88b003-a227-462c-81a0-0d478653abe0,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-bf16abf1-caea-43df-9261-b80a0339edff,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-1ae4122c-92f8-46f8-ac20-ad8c434f55ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-c945479b-9f47-43e3-8ba4-e0ce2dba2cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-3e03ae60-aec1-4a9c-9f99-421a6173c5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-6a56c50b-f272-445f-8942-c23b8bdc8cef,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-47d65891-e0cb-4cf3-8f1b-8791d913dc90,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-e2f64b0f-5a0c-4f7c-b5ce-a12dde257228,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726974263-172.17.0.11-1597745129563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46468,DS-7b1223ba-08d2-4aac-942e-916162840277,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-39251033-c9da-4f6f-a92f-e6153a3bbec3,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-360c3b5e-11cb-4557-b329-7b781c62ad55,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-21d23bc2-fbb4-493a-920c-5cdd69869f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-a58d1ac1-4124-4e9d-8e83-5d8dfc9c70a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-e2fd99af-61ed-4b54-bb9d-f832b462a25c,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-70091116-e29c-40fb-807c-6238cc07f13a,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-5317bc5c-8966-49b7-9332-d0f526a77a38,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726974263-172.17.0.11-1597745129563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46468,DS-7b1223ba-08d2-4aac-942e-916162840277,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-39251033-c9da-4f6f-a92f-e6153a3bbec3,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-360c3b5e-11cb-4557-b329-7b781c62ad55,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-21d23bc2-fbb4-493a-920c-5cdd69869f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-a58d1ac1-4124-4e9d-8e83-5d8dfc9c70a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-e2fd99af-61ed-4b54-bb9d-f832b462a25c,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-70091116-e29c-40fb-807c-6238cc07f13a,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-5317bc5c-8966-49b7-9332-d0f526a77a38,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1869793756-172.17.0.11-1597745201176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35967,DS-42b2d7be-5c8b-4791-bcb8-565daad3ff0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-c82bd851-8e22-4478-8747-eade0c51a2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-34168995-0f9c-4a23-943a-30fe44741abe,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-11d8315a-a867-4534-a0b2-3187fe15dd44,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-5ff3f8dd-17be-456d-97ff-25166a8cfdb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-5de64ec0-dc8f-46d5-88f4-17822b7dc32b,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-2f652a4b-d38b-4089-8fae-4ddea391ce9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-20e86997-d273-48d1-b947-89520695e678,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1869793756-172.17.0.11-1597745201176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35967,DS-42b2d7be-5c8b-4791-bcb8-565daad3ff0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-c82bd851-8e22-4478-8747-eade0c51a2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-34168995-0f9c-4a23-943a-30fe44741abe,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-11d8315a-a867-4534-a0b2-3187fe15dd44,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-5ff3f8dd-17be-456d-97ff-25166a8cfdb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-5de64ec0-dc8f-46d5-88f4-17822b7dc32b,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-2f652a4b-d38b-4089-8fae-4ddea391ce9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-20e86997-d273-48d1-b947-89520695e678,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980365332-172.17.0.11-1597745657139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45961,DS-2e2b8828-2238-4f29-85ae-f15a51579210,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-5a92bfd9-486a-4f69-b292-dbce7c399515,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-9f7c7fd0-6159-43bb-a655-b256ab0c8420,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-ab9ba0fd-5074-4ed8-87fe-fae77a485979,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-67f64b29-0665-4714-84d0-d5a0494b4a14,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-dc61097d-11dc-4735-a8f7-4a4add56e061,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-6d63e856-812e-4229-896e-fe22c2fc7ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-1b521116-ccf6-4740-8cba-27c4bb7bf08d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980365332-172.17.0.11-1597745657139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45961,DS-2e2b8828-2238-4f29-85ae-f15a51579210,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-5a92bfd9-486a-4f69-b292-dbce7c399515,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-9f7c7fd0-6159-43bb-a655-b256ab0c8420,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-ab9ba0fd-5074-4ed8-87fe-fae77a485979,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-67f64b29-0665-4714-84d0-d5a0494b4a14,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-dc61097d-11dc-4735-a8f7-4a4add56e061,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-6d63e856-812e-4229-896e-fe22c2fc7ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-1b521116-ccf6-4740-8cba-27c4bb7bf08d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061502370-172.17.0.11-1597745810012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44564,DS-bdbe4772-50e3-4eff-b117-e6adbe2cf6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-f9a452e0-a6de-4391-a971-13c0546cf4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-823b3e1c-0f45-4bab-b281-78c7574c0635,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-ccc2ed05-8a21-47d3-9586-cfb4bf3e9302,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-bd19cc10-b2a9-4e7c-bab8-6d7473fa473f,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-65b82b85-09af-43b6-9202-bbc07916fe37,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-d678a405-4fff-4992-904a-f591f3d48139,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-64cbeb3a-755f-44ed-80b0-a0f611d4f591,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061502370-172.17.0.11-1597745810012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44564,DS-bdbe4772-50e3-4eff-b117-e6adbe2cf6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-f9a452e0-a6de-4391-a971-13c0546cf4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-823b3e1c-0f45-4bab-b281-78c7574c0635,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-ccc2ed05-8a21-47d3-9586-cfb4bf3e9302,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-bd19cc10-b2a9-4e7c-bab8-6d7473fa473f,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-65b82b85-09af-43b6-9202-bbc07916fe37,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-d678a405-4fff-4992-904a-f591f3d48139,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-64cbeb3a-755f-44ed-80b0-a0f611d4f591,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-205131144-172.17.0.11-1597745991880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33979,DS-2b3b2f4d-813e-430f-97ff-2ccdefb42975,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-439104ac-543d-49bf-90e1-512a7de5e431,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-2fd15a01-5d02-429e-8c9a-db6f9842c4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-eaf40bbc-1afb-4948-8b72-2cb00566c87c,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-a014d6e1-2812-4c25-9a69-e672e3421d91,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-c6a3bdf4-112c-4347-9149-ea77aee346c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-5c55d497-469b-4c0f-bb80-e29667b540cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-9fc87459-83eb-4e48-9dd9-8234005afab2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-205131144-172.17.0.11-1597745991880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33979,DS-2b3b2f4d-813e-430f-97ff-2ccdefb42975,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-439104ac-543d-49bf-90e1-512a7de5e431,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-2fd15a01-5d02-429e-8c9a-db6f9842c4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-eaf40bbc-1afb-4948-8b72-2cb00566c87c,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-a014d6e1-2812-4c25-9a69-e672e3421d91,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-c6a3bdf4-112c-4347-9149-ea77aee346c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-5c55d497-469b-4c0f-bb80-e29667b540cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-9fc87459-83eb-4e48-9dd9-8234005afab2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1904288117-172.17.0.11-1597746185604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34280,DS-8224155d-8fd6-4c30-b67b-156ce1f90624,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-2e5bd20c-5296-4d92-a827-565c58bdcd65,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-3183725e-d05e-4d3f-9777-37aec66de676,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-2f45c04f-18ca-448a-abf6-70f26fc8881c,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-55c158ec-0108-43fc-a7c8-1fe3684ae366,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-fd20d3a5-cde2-496f-b4de-5c3e8a863982,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-2c72e9b2-930f-4ea3-8205-17bda35f070d,DISK], DatanodeInfoWithStorage[127.0.0.1:34360,DS-5429c1b7-be05-4a0c-a430-d53aac7090b6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1904288117-172.17.0.11-1597746185604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34280,DS-8224155d-8fd6-4c30-b67b-156ce1f90624,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-2e5bd20c-5296-4d92-a827-565c58bdcd65,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-3183725e-d05e-4d3f-9777-37aec66de676,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-2f45c04f-18ca-448a-abf6-70f26fc8881c,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-55c158ec-0108-43fc-a7c8-1fe3684ae366,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-fd20d3a5-cde2-496f-b4de-5c3e8a863982,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-2c72e9b2-930f-4ea3-8205-17bda35f070d,DISK], DatanodeInfoWithStorage[127.0.0.1:34360,DS-5429c1b7-be05-4a0c-a430-d53aac7090b6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274732983-172.17.0.11-1597746225027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35716,DS-5b62a44c-7407-4318-996e-2671247841d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-d8ddef42-fd28-4885-bd83-8c181c28d0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-0caa8b67-b09d-4731-9cd0-511d872cd503,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-ffab964b-de2a-488d-b76b-fb748027f14a,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-07deacb0-7ad9-4156-a4a7-8d0f2797b107,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-02311422-806c-4b44-b9b8-7dc566ac8983,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-f366e59a-8257-4875-bd99-cf9b7f5f92b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-74de6300-829f-4845-9893-75f24701b87b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274732983-172.17.0.11-1597746225027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35716,DS-5b62a44c-7407-4318-996e-2671247841d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-d8ddef42-fd28-4885-bd83-8c181c28d0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-0caa8b67-b09d-4731-9cd0-511d872cd503,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-ffab964b-de2a-488d-b76b-fb748027f14a,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-07deacb0-7ad9-4156-a4a7-8d0f2797b107,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-02311422-806c-4b44-b9b8-7dc566ac8983,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-f366e59a-8257-4875-bd99-cf9b7f5f92b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-74de6300-829f-4845-9893-75f24701b87b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 5537
