reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-959257977-172.17.0.14-1597523337721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40669,DS-a0794367-6100-4125-854e-48c77f36f212,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-1864b312-3327-4fd9-84fa-35ec91ff4875,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-24d74625-9685-487f-b7c1-e9f22c9ad135,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-70349e10-3c8e-440b-b314-1e7a8cf4b1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-bf4e905a-551b-4887-9f6b-6b42695d3e08,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-069b15d2-bbf8-4662-b2c9-cdecdae95dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-fbbf559d-f41d-4bec-a11a-c2e4cf3e7010,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-fe86b72e-c5d0-4bd5-b4b0-474c4d42375a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-959257977-172.17.0.14-1597523337721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40669,DS-a0794367-6100-4125-854e-48c77f36f212,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-1864b312-3327-4fd9-84fa-35ec91ff4875,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-24d74625-9685-487f-b7c1-e9f22c9ad135,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-70349e10-3c8e-440b-b314-1e7a8cf4b1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-bf4e905a-551b-4887-9f6b-6b42695d3e08,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-069b15d2-bbf8-4662-b2c9-cdecdae95dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-fbbf559d-f41d-4bec-a11a-c2e4cf3e7010,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-fe86b72e-c5d0-4bd5-b4b0-474c4d42375a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1552934025-172.17.0.14-1597523573592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36559,DS-59a012fb-e55b-40aa-8c31-5c90d3746c10,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-8f1cd501-f97d-42c8-acdc-8a874975b962,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-51dec34e-e928-4b21-82e8-5fd2f1f1a858,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-0d9e4a05-9f80-4dc9-8aef-645fdfdc2917,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-096c59a2-dd6c-4099-abb9-913e96800c93,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-dd2f889e-d0e5-4d31-9420-548384dfe5de,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-d619eb3f-81d2-411c-9905-adff468cc97d,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-e6fdbcbd-0a43-45c3-bc71-5187995c3da6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1552934025-172.17.0.14-1597523573592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36559,DS-59a012fb-e55b-40aa-8c31-5c90d3746c10,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-8f1cd501-f97d-42c8-acdc-8a874975b962,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-51dec34e-e928-4b21-82e8-5fd2f1f1a858,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-0d9e4a05-9f80-4dc9-8aef-645fdfdc2917,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-096c59a2-dd6c-4099-abb9-913e96800c93,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-dd2f889e-d0e5-4d31-9420-548384dfe5de,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-d619eb3f-81d2-411c-9905-adff468cc97d,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-e6fdbcbd-0a43-45c3-bc71-5187995c3da6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1164893987-172.17.0.14-1597523728296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35270,DS-d5ab4419-a9ec-4925-b656-002bdc751caa,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-94a52cb3-d472-4dc2-b261-1fac3abac274,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-e4c318f1-f2cb-412d-bc2d-f5c22ef51c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-bee6f2e0-c6a4-44eb-bf06-ec1c258c6c23,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-e8fe3c93-8f8c-4a7d-9567-d1d89f828914,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-2b5554d3-e824-453b-b873-20909a4d8f59,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-e6fcbdab-5665-4892-8733-1325358289cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-d5937109-046e-4f58-96d1-8c464799e2da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1164893987-172.17.0.14-1597523728296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35270,DS-d5ab4419-a9ec-4925-b656-002bdc751caa,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-94a52cb3-d472-4dc2-b261-1fac3abac274,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-e4c318f1-f2cb-412d-bc2d-f5c22ef51c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-bee6f2e0-c6a4-44eb-bf06-ec1c258c6c23,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-e8fe3c93-8f8c-4a7d-9567-d1d89f828914,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-2b5554d3-e824-453b-b873-20909a4d8f59,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-e6fcbdab-5665-4892-8733-1325358289cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-d5937109-046e-4f58-96d1-8c464799e2da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1607808017-172.17.0.14-1597524031860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37637,DS-411a97fa-497e-4f62-9111-51216f3f91c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-34ed0d18-89e7-4c7f-88e1-7ed40188c9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-22156c50-69b1-46d1-9b3c-c519d0863415,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-66ffd54e-d0fa-4c19-8743-c505e44e7ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-a7b02b85-fad3-49be-be6f-c415111871a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-c9fecdb4-c100-45ac-85e2-f823f7129b48,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-3f30de37-cdcd-44b9-bed6-e55039003848,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-655ba12a-5fff-408c-8dc3-3d158995055d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1607808017-172.17.0.14-1597524031860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37637,DS-411a97fa-497e-4f62-9111-51216f3f91c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-34ed0d18-89e7-4c7f-88e1-7ed40188c9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-22156c50-69b1-46d1-9b3c-c519d0863415,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-66ffd54e-d0fa-4c19-8743-c505e44e7ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-a7b02b85-fad3-49be-be6f-c415111871a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-c9fecdb4-c100-45ac-85e2-f823f7129b48,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-3f30de37-cdcd-44b9-bed6-e55039003848,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-655ba12a-5fff-408c-8dc3-3d158995055d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-21206014-172.17.0.14-1597524180194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35194,DS-15945d17-264e-4326-861f-9cae4f4b50e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-19fc6bcd-f98e-4135-8942-63db7dc26039,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-37b19119-45d6-451a-830c-375c48f808e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-967b458f-a727-439d-bb2f-5c07fcf92a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-0d0f8315-2413-4e64-b1d5-de64a5f8a71c,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-58f94c8d-c072-4f25-8f0e-b99f232dc9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-8bdc2ebb-9662-4e7f-be87-98716b2da66c,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-0c88643c-f3d3-40d3-b492-4bab54add7c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-21206014-172.17.0.14-1597524180194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35194,DS-15945d17-264e-4326-861f-9cae4f4b50e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-19fc6bcd-f98e-4135-8942-63db7dc26039,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-37b19119-45d6-451a-830c-375c48f808e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-967b458f-a727-439d-bb2f-5c07fcf92a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-0d0f8315-2413-4e64-b1d5-de64a5f8a71c,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-58f94c8d-c072-4f25-8f0e-b99f232dc9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-8bdc2ebb-9662-4e7f-be87-98716b2da66c,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-0c88643c-f3d3-40d3-b492-4bab54add7c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1410727905-172.17.0.14-1597524218262:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33140,DS-9e507f0a-e738-447c-a940-30aeb573eed7,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-269cafa1-7947-4ea6-b314-21a4774e80f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-dee66228-1411-4d39-a497-c90b0413200e,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-d884cc68-6956-4424-9ecf-573963a4c2be,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-0a3a29c6-2c30-4b09-8870-9fbb9ccc3cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-c08362f7-c3c6-4459-b45c-2e70874c991b,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-1d0c7fc9-0f08-4193-95e0-4480f0ef18b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-ec190169-47db-4151-84a3-06ff3a0d9016,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1410727905-172.17.0.14-1597524218262:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33140,DS-9e507f0a-e738-447c-a940-30aeb573eed7,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-269cafa1-7947-4ea6-b314-21a4774e80f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-dee66228-1411-4d39-a497-c90b0413200e,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-d884cc68-6956-4424-9ecf-573963a4c2be,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-0a3a29c6-2c30-4b09-8870-9fbb9ccc3cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-c08362f7-c3c6-4459-b45c-2e70874c991b,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-1d0c7fc9-0f08-4193-95e0-4480f0ef18b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-ec190169-47db-4151-84a3-06ff3a0d9016,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-76145952-172.17.0.14-1597524337440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42870,DS-720bbb52-8ff1-4442-9d17-b2b7c5d1d272,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-7f97a638-1b87-49f5-8230-6cb3b03d62d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-b4b86d51-bc02-4446-b475-a61e8825edce,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-268da508-b67c-4e77-b116-34d2d1b4a3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-3d34f3a2-4ac5-4fd3-be49-a1795f087b40,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-06dc1c71-0580-42c7-81e1-bdac5fff46a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-5cacf9cb-af7a-4fe9-946a-f39a311bc0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-4d52134d-5833-4662-b7f5-49846ef66cbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-76145952-172.17.0.14-1597524337440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42870,DS-720bbb52-8ff1-4442-9d17-b2b7c5d1d272,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-7f97a638-1b87-49f5-8230-6cb3b03d62d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-b4b86d51-bc02-4446-b475-a61e8825edce,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-268da508-b67c-4e77-b116-34d2d1b4a3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-3d34f3a2-4ac5-4fd3-be49-a1795f087b40,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-06dc1c71-0580-42c7-81e1-bdac5fff46a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-5cacf9cb-af7a-4fe9-946a-f39a311bc0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-4d52134d-5833-4662-b7f5-49846ef66cbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-599214792-172.17.0.14-1597524417913:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44779,DS-7f8981f3-8582-4b20-a129-256608dca192,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-a086059d-c1d9-41ba-8f6e-0f2f880ebfac,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-618e4188-72f8-4571-b267-a2bc942f8e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-6297e30c-4fb6-4d8e-9ea5-a4e1b78fe67f,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-f4f8837a-1275-4b76-a310-218f39f76c66,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-4313f633-397f-4cd0-93df-e1e8d63068bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-77e1209e-5f0b-4ea8-bf99-ed7319af6e56,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-f46d12d9-48e3-4ed8-946b-6a9d61c18bde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-599214792-172.17.0.14-1597524417913:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44779,DS-7f8981f3-8582-4b20-a129-256608dca192,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-a086059d-c1d9-41ba-8f6e-0f2f880ebfac,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-618e4188-72f8-4571-b267-a2bc942f8e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-6297e30c-4fb6-4d8e-9ea5-a4e1b78fe67f,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-f4f8837a-1275-4b76-a310-218f39f76c66,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-4313f633-397f-4cd0-93df-e1e8d63068bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-77e1209e-5f0b-4ea8-bf99-ed7319af6e56,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-f46d12d9-48e3-4ed8-946b-6a9d61c18bde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-198570125-172.17.0.14-1597524894518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38904,DS-d20031dc-291f-4a80-96ae-807d0aa2476f,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-fe5ed782-9aa8-4ac7-94a7-462f004652f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-e76f5d0f-52e4-4d3e-991a-dbb9bc35d484,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-3639ce9c-150c-4045-9d2b-b1503496812d,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-7b9054e4-ee55-4b05-b8af-536eb23d8b55,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-04702837-57ea-46d8-b12f-dd1926c5dfe9,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-9c9801e8-4ca0-4614-9ed1-972f335da234,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-e5ed4f5f-d246-4ffa-bdaa-8bf2c70201ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-198570125-172.17.0.14-1597524894518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38904,DS-d20031dc-291f-4a80-96ae-807d0aa2476f,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-fe5ed782-9aa8-4ac7-94a7-462f004652f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-e76f5d0f-52e4-4d3e-991a-dbb9bc35d484,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-3639ce9c-150c-4045-9d2b-b1503496812d,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-7b9054e4-ee55-4b05-b8af-536eb23d8b55,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-04702837-57ea-46d8-b12f-dd1926c5dfe9,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-9c9801e8-4ca0-4614-9ed1-972f335da234,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-e5ed4f5f-d246-4ffa-bdaa-8bf2c70201ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-590260286-172.17.0.14-1597525309833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46033,DS-e0d200cd-3a44-4af2-b7bd-c84215e3497e,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-d9e03a97-4683-4dbb-9992-a26d1a3cd025,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-00efabfa-5cb8-44d2-96f2-e820c9dd17ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-2af6712c-dca0-4ef5-906a-31ae8c5e31a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38240,DS-ac701ddc-105d-464b-8914-3f9936199c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-6ddb8361-1e2b-4b8b-a6e3-95f13717e5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-44dfa4b6-05c3-4dac-b100-d2f6a537b5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-6913a3ab-4bd1-4bed-bb44-c07bc63ad6c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-590260286-172.17.0.14-1597525309833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46033,DS-e0d200cd-3a44-4af2-b7bd-c84215e3497e,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-d9e03a97-4683-4dbb-9992-a26d1a3cd025,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-00efabfa-5cb8-44d2-96f2-e820c9dd17ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-2af6712c-dca0-4ef5-906a-31ae8c5e31a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38240,DS-ac701ddc-105d-464b-8914-3f9936199c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-6ddb8361-1e2b-4b8b-a6e3-95f13717e5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-44dfa4b6-05c3-4dac-b100-d2f6a537b5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-6913a3ab-4bd1-4bed-bb44-c07bc63ad6c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-23975660-172.17.0.14-1597525565821:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42600,DS-0194de26-db81-453a-afc9-352c1dc1a108,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-093dc8fa-4645-447c-8d5b-8a8cee5e26ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-7a904789-59e2-4d72-9d66-ca9d3a2df8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-d0cf0442-20da-4729-8543-ab10fd11c8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-31167a3f-5468-4962-b20d-78a664da0e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-3001d13b-95ec-49eb-a7b1-5e3fbdc9df33,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-d748b2c8-6d53-470d-95da-d680157b8abc,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-f5cd2cf5-f163-4ca2-854e-cdafc9e4894e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-23975660-172.17.0.14-1597525565821:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42600,DS-0194de26-db81-453a-afc9-352c1dc1a108,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-093dc8fa-4645-447c-8d5b-8a8cee5e26ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-7a904789-59e2-4d72-9d66-ca9d3a2df8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-d0cf0442-20da-4729-8543-ab10fd11c8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-31167a3f-5468-4962-b20d-78a664da0e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-3001d13b-95ec-49eb-a7b1-5e3fbdc9df33,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-d748b2c8-6d53-470d-95da-d680157b8abc,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-f5cd2cf5-f163-4ca2-854e-cdafc9e4894e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-239864602-172.17.0.14-1597525819333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35509,DS-daf80463-85c4-41f2-ac48-32a67bad7c78,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-61eddf5d-5655-46eb-a56f-99bb3f7921a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-9884cc33-448b-4fa8-869a-a56aa0697373,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-d7f06d4d-ae94-4de2-9eb4-c50cfd402f01,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-4423d876-e2b8-4b38-bf9f-f50ff3eece6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-c5f3ccdb-9bd4-40fe-a750-6b17d9ff1c58,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-d4f52120-0e96-460d-969e-079542a4768c,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-ce8c90ba-6f41-4f54-b5ac-ca780f69674f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-239864602-172.17.0.14-1597525819333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35509,DS-daf80463-85c4-41f2-ac48-32a67bad7c78,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-61eddf5d-5655-46eb-a56f-99bb3f7921a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-9884cc33-448b-4fa8-869a-a56aa0697373,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-d7f06d4d-ae94-4de2-9eb4-c50cfd402f01,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-4423d876-e2b8-4b38-bf9f-f50ff3eece6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-c5f3ccdb-9bd4-40fe-a750-6b17d9ff1c58,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-d4f52120-0e96-460d-969e-079542a4768c,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-ce8c90ba-6f41-4f54-b5ac-ca780f69674f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-842067649-172.17.0.14-1597525859692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39972,DS-d82d2d6f-368d-4dee-b676-a5bd137fe5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-4e9b1563-85ad-4cae-8d9a-964149f71e05,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-673f6dcc-b4db-43ec-9558-11cc202c5108,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-70d864f0-3e0e-4528-b4c3-41a6307d830a,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-cd352e27-cb9c-4faa-b167-0557fb026a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-be24ce78-87de-4302-aec5-b252913fdccf,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-1019ccb0-b86c-4862-9083-425d228093ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-2a1d8159-e83a-4ce6-a71e-8701333d2c74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-842067649-172.17.0.14-1597525859692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39972,DS-d82d2d6f-368d-4dee-b676-a5bd137fe5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-4e9b1563-85ad-4cae-8d9a-964149f71e05,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-673f6dcc-b4db-43ec-9558-11cc202c5108,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-70d864f0-3e0e-4528-b4c3-41a6307d830a,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-cd352e27-cb9c-4faa-b167-0557fb026a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-be24ce78-87de-4302-aec5-b252913fdccf,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-1019ccb0-b86c-4862-9083-425d228093ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-2a1d8159-e83a-4ce6-a71e-8701333d2c74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-207446832-172.17.0.14-1597526127269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42532,DS-7e31585b-4e0d-41aa-881e-25bb47044d56,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-fc4886e2-4b99-4e87-914f-15ca180a0e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-619158a9-f595-44cb-aecc-019a8df15ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-30fa267b-25cf-4b65-8a29-e4fc4d028b36,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-e4b92abf-5f4c-4990-8f03-6b0503a9d1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-ecd4b4ef-4e7d-49af-8a06-a3165411a08d,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-37b093a0-ea89-4b95-b60a-54f55c38c42e,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-db5bee96-3a24-4d01-8151-4829baefcac5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-207446832-172.17.0.14-1597526127269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42532,DS-7e31585b-4e0d-41aa-881e-25bb47044d56,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-fc4886e2-4b99-4e87-914f-15ca180a0e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-619158a9-f595-44cb-aecc-019a8df15ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:42792,DS-30fa267b-25cf-4b65-8a29-e4fc4d028b36,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-e4b92abf-5f4c-4990-8f03-6b0503a9d1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-ecd4b4ef-4e7d-49af-8a06-a3165411a08d,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-37b093a0-ea89-4b95-b60a-54f55c38c42e,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-db5bee96-3a24-4d01-8151-4829baefcac5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2068788347-172.17.0.14-1597526383381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43440,DS-4c56c431-526c-4d48-a572-91e8bc550c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-f4f27a5b-1535-4967-9640-fa48da937548,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-47c75a38-c0fc-4c09-a71d-88bfe7c8ece3,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-7dee17fa-a09c-4087-8f11-0a3dba3f18f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-68948534-315e-4a67-ab0f-0e0e53fd2a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-00e40240-d216-4cff-a4a6-80206f87feb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-a6af0264-2170-426d-b39d-12bacd2964f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-1544045d-5a77-4512-b44b-9f743e00d2b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2068788347-172.17.0.14-1597526383381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43440,DS-4c56c431-526c-4d48-a572-91e8bc550c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-f4f27a5b-1535-4967-9640-fa48da937548,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-47c75a38-c0fc-4c09-a71d-88bfe7c8ece3,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-7dee17fa-a09c-4087-8f11-0a3dba3f18f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-68948534-315e-4a67-ab0f-0e0e53fd2a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-00e40240-d216-4cff-a4a6-80206f87feb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-a6af0264-2170-426d-b39d-12bacd2964f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-1544045d-5a77-4512-b44b-9f743e00d2b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1592193846-172.17.0.14-1597526420399:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37957,DS-b0f2afbc-5ea2-426e-a9f6-40734fc9757d,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-c88ed451-cbff-4d98-9caf-f47f4e8c24f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-d3ecd3db-251f-461d-9a62-b80719f72017,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-99996f52-b9e5-420a-a408-e55a71264c97,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-aa7ac27a-ceff-4606-bf53-0a5e3f6650a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-57cc7649-998c-45de-aed2-02136be28722,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-da65bebe-8aa2-49bd-a0bd-7519a1a178f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-fc17d604-fbd2-47ac-bcc2-7f11d3f85974,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1592193846-172.17.0.14-1597526420399:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37957,DS-b0f2afbc-5ea2-426e-a9f6-40734fc9757d,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-c88ed451-cbff-4d98-9caf-f47f4e8c24f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-d3ecd3db-251f-461d-9a62-b80719f72017,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-99996f52-b9e5-420a-a408-e55a71264c97,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-aa7ac27a-ceff-4606-bf53-0a5e3f6650a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-57cc7649-998c-45de-aed2-02136be28722,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-da65bebe-8aa2-49bd-a0bd-7519a1a178f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-fc17d604-fbd2-47ac-bcc2-7f11d3f85974,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1261829265-172.17.0.14-1597526495700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38084,DS-27d61e62-0c84-4601-ab4f-b0956893c266,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-de91196f-f7b8-48d6-9399-b30d35c03756,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-3bf25077-46e1-48ce-8425-2f502abe4ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-114dea15-b702-4e0d-9535-caba4129e5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-d47320f0-53f8-4022-86a7-15e6467d21bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-5fc93e24-7426-4061-aee7-dd3512c3e1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-ca64338d-47a2-497f-a970-396430cd7c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-8771928f-deb4-4854-8b73-d90184a6cc5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1261829265-172.17.0.14-1597526495700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38084,DS-27d61e62-0c84-4601-ab4f-b0956893c266,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-de91196f-f7b8-48d6-9399-b30d35c03756,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-3bf25077-46e1-48ce-8425-2f502abe4ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-114dea15-b702-4e0d-9535-caba4129e5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-d47320f0-53f8-4022-86a7-15e6467d21bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-5fc93e24-7426-4061-aee7-dd3512c3e1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-ca64338d-47a2-497f-a970-396430cd7c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-8771928f-deb4-4854-8b73-d90184a6cc5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-763308552-172.17.0.14-1597526909668:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40236,DS-38dae20a-1766-4dd3-89ca-89adc1cf8cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-09443b70-c924-4031-b051-fd823509af48,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-27730837-ab5c-44d0-9736-a8799d9e6e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-911cf8d0-73ee-40e8-a9bd-cd3229f28353,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-bd68f818-ecdf-45b0-838d-1cab9e279e48,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-ca60168e-7b92-4519-b39a-8e445dcdbae9,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-58c360cf-1e5d-4ec9-83c2-2dd90d5c011d,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-8c9bc315-16b3-4754-8d9f-31a8264faeac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-763308552-172.17.0.14-1597526909668:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40236,DS-38dae20a-1766-4dd3-89ca-89adc1cf8cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-09443b70-c924-4031-b051-fd823509af48,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-27730837-ab5c-44d0-9736-a8799d9e6e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-911cf8d0-73ee-40e8-a9bd-cd3229f28353,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-bd68f818-ecdf-45b0-838d-1cab9e279e48,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-ca60168e-7b92-4519-b39a-8e445dcdbae9,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-58c360cf-1e5d-4ec9-83c2-2dd90d5c011d,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-8c9bc315-16b3-4754-8d9f-31a8264faeac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-347638567-172.17.0.14-1597527022106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35187,DS-7a01f481-de88-4d3c-bec1-9924d5472a13,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-169c07af-a4b6-419d-a3fa-00e27a767151,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-58c4c409-6737-455b-aa94-2364a2c820e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-7c14eb98-96ff-4ee5-be7a-c157db3bc9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-1d0f6252-50d1-4e3c-83b8-f05ff5bd0ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-4a82b212-0cc2-409f-aff1-402b6534dd59,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-481bc9c5-6b45-4b87-ae89-96f4f3050316,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-5df34c2b-18e1-4a7b-8636-4a6d8a26bf7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-347638567-172.17.0.14-1597527022106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35187,DS-7a01f481-de88-4d3c-bec1-9924d5472a13,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-169c07af-a4b6-419d-a3fa-00e27a767151,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-58c4c409-6737-455b-aa94-2364a2c820e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-7c14eb98-96ff-4ee5-be7a-c157db3bc9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-1d0f6252-50d1-4e3c-83b8-f05ff5bd0ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-4a82b212-0cc2-409f-aff1-402b6534dd59,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-481bc9c5-6b45-4b87-ae89-96f4f3050316,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-5df34c2b-18e1-4a7b-8636-4a6d8a26bf7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-14298005-172.17.0.14-1597527253624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34140,DS-e8090181-d71f-4800-b9bc-e4a1646bdb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-aecb3830-d1da-411f-a5e8-dbe2bb7c4900,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-0e4afeea-cb02-4f7c-8af4-411741d62d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-0dd247f5-970b-4bdd-be3e-f0bee8596119,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-2610dd22-587a-47b7-ac83-9296b0126378,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-758bc2e9-1557-4d1c-b2ae-2afddda6789e,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-1a9bcd27-06f0-46a6-9d25-e68eacfedf6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-b6a15192-2abb-476b-bc5c-9fb98a11e56f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-14298005-172.17.0.14-1597527253624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34140,DS-e8090181-d71f-4800-b9bc-e4a1646bdb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-aecb3830-d1da-411f-a5e8-dbe2bb7c4900,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-0e4afeea-cb02-4f7c-8af4-411741d62d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-0dd247f5-970b-4bdd-be3e-f0bee8596119,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-2610dd22-587a-47b7-ac83-9296b0126378,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-758bc2e9-1557-4d1c-b2ae-2afddda6789e,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-1a9bcd27-06f0-46a6-9d25-e68eacfedf6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-b6a15192-2abb-476b-bc5c-9fb98a11e56f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-684211688-172.17.0.14-1597527439470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37604,DS-cd385519-bc7c-48b9-9e12-37035ec8cf54,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-951926c6-90ab-4d91-8592-cdb5d501821c,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-95ef9ec1-eb30-4464-a4db-04e0a93be0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-ccf33642-71b7-42c5-b0d2-4335cf8810ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-5a2d379c-3942-400b-af33-5eef9bd6fe9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-f917a781-bca7-4a93-8f34-b842b7e82f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-6615ca71-0dd9-4eef-a62e-ebb3165806c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-c337aa18-42c8-4798-9c65-8fd75ccf8585,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-684211688-172.17.0.14-1597527439470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37604,DS-cd385519-bc7c-48b9-9e12-37035ec8cf54,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-951926c6-90ab-4d91-8592-cdb5d501821c,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-95ef9ec1-eb30-4464-a4db-04e0a93be0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-ccf33642-71b7-42c5-b0d2-4335cf8810ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-5a2d379c-3942-400b-af33-5eef9bd6fe9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-f917a781-bca7-4a93-8f34-b842b7e82f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-6615ca71-0dd9-4eef-a62e-ebb3165806c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-c337aa18-42c8-4798-9c65-8fd75ccf8585,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1512600879-172.17.0.14-1597527588925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37986,DS-18260dff-b166-4802-9e1d-d30ca8b9a8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-4e38f3f7-97b8-422c-9e43-22d6a413ac3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-6da6e753-6c3a-46a6-9fbe-f4c0d0b553b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-d1ec8b74-6ca4-4dce-bfec-ae54fe710c38,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-d15306bf-f6e6-4144-afb8-9309c5dca199,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-1ae1cb06-863d-4d7f-85aa-1deae320cdee,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-4479cf95-fea7-42af-8c7b-f6450909f753,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-2e3eaf43-b450-4e77-ba2c-0df6225ee23e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1512600879-172.17.0.14-1597527588925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37986,DS-18260dff-b166-4802-9e1d-d30ca8b9a8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-4e38f3f7-97b8-422c-9e43-22d6a413ac3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-6da6e753-6c3a-46a6-9fbe-f4c0d0b553b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-d1ec8b74-6ca4-4dce-bfec-ae54fe710c38,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-d15306bf-f6e6-4144-afb8-9309c5dca199,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-1ae1cb06-863d-4d7f-85aa-1deae320cdee,DISK], DatanodeInfoWithStorage[127.0.0.1:43206,DS-4479cf95-fea7-42af-8c7b-f6450909f753,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-2e3eaf43-b450-4e77-ba2c-0df6225ee23e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1133895587-172.17.0.14-1597527666299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38403,DS-d00ac11b-2850-4488-a4e2-c0c383e84b38,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-64eed7a4-d384-48dd-9f8a-3e89713e7ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-5e529ec7-fbd2-4427-a026-7aa451609c33,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-23dbb19e-144f-477f-a1e7-80a669239bae,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-0c46a333-1d47-4dbd-ab5b-04efb31ae369,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-7fea573b-3db6-4f3e-a88e-4a22b5720727,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-48880d55-e82f-42b4-89a2-a5204cf4bcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-82d1ac0f-715e-44e9-be7c-bfda401ed503,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1133895587-172.17.0.14-1597527666299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38403,DS-d00ac11b-2850-4488-a4e2-c0c383e84b38,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-64eed7a4-d384-48dd-9f8a-3e89713e7ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-5e529ec7-fbd2-4427-a026-7aa451609c33,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-23dbb19e-144f-477f-a1e7-80a669239bae,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-0c46a333-1d47-4dbd-ab5b-04efb31ae369,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-7fea573b-3db6-4f3e-a88e-4a22b5720727,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-48880d55-e82f-42b4-89a2-a5204cf4bcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-82d1ac0f-715e-44e9-be7c-bfda401ed503,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1606761671-172.17.0.14-1597527825420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37879,DS-4c200a76-3afb-4ced-84d0-7ad7ffdb3738,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-ed45ac93-e0f5-42e2-aa34-7a87f5e6924a,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-cb7ad32a-c36f-4fac-bc22-239229cb3be2,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-0ab5744f-3616-4053-b6f4-b7cca9ede5be,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-8568c887-4c85-4283-8bc8-d695d58402f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-ec342572-8ca5-4ce4-9a09-bfa033e64728,DISK], DatanodeInfoWithStorage[127.0.0.1:46025,DS-fd283bdc-5564-4a93-93f3-009924206a96,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-76dd1732-c2ef-4ed8-ade9-8873bf06bdfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1606761671-172.17.0.14-1597527825420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37879,DS-4c200a76-3afb-4ced-84d0-7ad7ffdb3738,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-ed45ac93-e0f5-42e2-aa34-7a87f5e6924a,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-cb7ad32a-c36f-4fac-bc22-239229cb3be2,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-0ab5744f-3616-4053-b6f4-b7cca9ede5be,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-8568c887-4c85-4283-8bc8-d695d58402f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-ec342572-8ca5-4ce4-9a09-bfa033e64728,DISK], DatanodeInfoWithStorage[127.0.0.1:46025,DS-fd283bdc-5564-4a93-93f3-009924206a96,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-76dd1732-c2ef-4ed8-ade9-8873bf06bdfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1501778312-172.17.0.14-1597528171270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39921,DS-c21d8571-dea1-434a-bf3a-e91bc027fec0,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-2a5e77d2-d1bb-4557-affe-1b38a55c58ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-364cd675-a595-4a4c-a3a8-b77c237ea8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-e21cb185-4cfd-4b91-b6ea-d3dbf9fe21c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-0b9b3785-eec9-4183-9b34-421e3a325652,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-e3207122-0819-4eac-a31e-31bf7ca8aaab,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-a8673bd4-181e-4b73-8a62-e8290315c0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-7960fd1a-4548-49d6-bd57-eb533e9292e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1501778312-172.17.0.14-1597528171270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39921,DS-c21d8571-dea1-434a-bf3a-e91bc027fec0,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-2a5e77d2-d1bb-4557-affe-1b38a55c58ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-364cd675-a595-4a4c-a3a8-b77c237ea8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-e21cb185-4cfd-4b91-b6ea-d3dbf9fe21c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-0b9b3785-eec9-4183-9b34-421e3a325652,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-e3207122-0819-4eac-a31e-31bf7ca8aaab,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-a8673bd4-181e-4b73-8a62-e8290315c0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-7960fd1a-4548-49d6-bd57-eb533e9292e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.trash.interval
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-811572121-172.17.0.14-1597528285207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38507,DS-5d6a8b03-fd99-448b-ba4d-e06841ed4d09,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-3878c095-c13a-458a-8d0c-3e7318d07366,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-a80add4e-d3cd-4dac-b93b-3dad0cedd0df,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-ba43f855-69b9-4857-849b-60f5226ec2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-54ea9d06-f626-46e0-9cff-b5ef0df237d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-5b4f82ea-e418-4385-94d7-bb0de828ef13,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-e6a779f5-429c-41ba-b1a3-af79c97a781d,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-ae07ae27-52eb-4ce4-80bf-f19f2b005fe1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-811572121-172.17.0.14-1597528285207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38507,DS-5d6a8b03-fd99-448b-ba4d-e06841ed4d09,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-3878c095-c13a-458a-8d0c-3e7318d07366,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-a80add4e-d3cd-4dac-b93b-3dad0cedd0df,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-ba43f855-69b9-4857-849b-60f5226ec2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-54ea9d06-f626-46e0-9cff-b5ef0df237d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-5b4f82ea-e418-4385-94d7-bb0de828ef13,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-e6a779f5-429c-41ba-b1a3-af79c97a781d,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-ae07ae27-52eb-4ce4-80bf-f19f2b005fe1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 21 out of 50
result: false positive !!!
Total execution time in seconds : 5705
