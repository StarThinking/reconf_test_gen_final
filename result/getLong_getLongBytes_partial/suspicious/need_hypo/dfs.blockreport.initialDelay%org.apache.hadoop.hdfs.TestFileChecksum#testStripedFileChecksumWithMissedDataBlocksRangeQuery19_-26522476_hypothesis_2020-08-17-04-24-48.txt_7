reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-810186317-172.17.0.13-1597638420628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33712,DS-84d0deef-3a68-4b75-a441-66bf3b57a9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-701ab0f1-7c31-4b65-b182-e124c8ee062c,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-c64bb1c0-de3f-4d2e-a79e-f1c4c6b407e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-e549dff6-e99c-4899-855a-7d870667d171,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-469dab8f-0c8d-471d-9fd6-44c517c5be32,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-92b61610-619f-4ae7-b2f4-db088a7ca022,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-256a5fd2-c8b3-4d8b-9639-fd0708c59663,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-1afcf73d-712f-4316-b2c3-e45492c39580,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-810186317-172.17.0.13-1597638420628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33712,DS-84d0deef-3a68-4b75-a441-66bf3b57a9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-701ab0f1-7c31-4b65-b182-e124c8ee062c,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-c64bb1c0-de3f-4d2e-a79e-f1c4c6b407e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-e549dff6-e99c-4899-855a-7d870667d171,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-469dab8f-0c8d-471d-9fd6-44c517c5be32,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-92b61610-619f-4ae7-b2f4-db088a7ca022,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-256a5fd2-c8b3-4d8b-9639-fd0708c59663,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-1afcf73d-712f-4316-b2c3-e45492c39580,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1998359450-172.17.0.13-1597638530361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45027,DS-2bb91e36-ce5b-4aaa-a6a7-90bea35eb011,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-8325b860-d019-46aa-a513-a215ece212be,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-42f2e1a0-b5b8-4005-8092-698600510903,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-245d78b2-a345-4dac-b7d4-0d88b97e1bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-1f53ba66-4453-4a34-8e33-4b52bd0a272a,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-15db70d9-0d0c-427b-b7a6-bae26383d22d,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-109fe551-4ad2-4bd0-ad5c-367161c26d45,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-06e3ca38-f518-459f-8ea9-c842dd9090da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1998359450-172.17.0.13-1597638530361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45027,DS-2bb91e36-ce5b-4aaa-a6a7-90bea35eb011,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-8325b860-d019-46aa-a513-a215ece212be,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-42f2e1a0-b5b8-4005-8092-698600510903,DISK], DatanodeInfoWithStorage[127.0.0.1:37511,DS-245d78b2-a345-4dac-b7d4-0d88b97e1bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-1f53ba66-4453-4a34-8e33-4b52bd0a272a,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-15db70d9-0d0c-427b-b7a6-bae26383d22d,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-109fe551-4ad2-4bd0-ad5c-367161c26d45,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-06e3ca38-f518-459f-8ea9-c842dd9090da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2076189263-172.17.0.13-1597638813737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45925,DS-7bd9d072-b169-44bd-81ec-828a86f4bd54,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-d97c56b9-2384-443d-9a95-2835eb988e33,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-b09851b4-b3e6-478e-b6c8-41edd4323ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-384a3e13-1370-43ab-a402-db9965722d40,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-46a662ef-8a32-40ac-8d0d-e1fc82eb0567,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-bdc6fa6b-1109-413f-bba7-cd90e00fc58b,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-c24df6af-4e04-45cc-85f5-869b0621a1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-585d53d8-f493-411f-baca-630ecd71a060,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2076189263-172.17.0.13-1597638813737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45925,DS-7bd9d072-b169-44bd-81ec-828a86f4bd54,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-d97c56b9-2384-443d-9a95-2835eb988e33,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-b09851b4-b3e6-478e-b6c8-41edd4323ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-384a3e13-1370-43ab-a402-db9965722d40,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-46a662ef-8a32-40ac-8d0d-e1fc82eb0567,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-bdc6fa6b-1109-413f-bba7-cd90e00fc58b,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-c24df6af-4e04-45cc-85f5-869b0621a1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-585d53d8-f493-411f-baca-630ecd71a060,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-704113198-172.17.0.13-1597639181203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33107,DS-fe493efe-2996-4850-991e-ba4d25a51833,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-23023919-daf0-4f66-94c9-226928cb4c45,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-6025f029-2128-4ca7-887a-92b5565afe4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-1f83676d-1c4e-4def-b314-fb5b6208f1be,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-dcef3f95-612d-471c-a4d7-74fa3d9e221b,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-2b1fd401-7562-4a6d-b808-df2fc975f203,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-c9ea03b9-c97e-4994-adee-b5341ede212e,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-347fb976-109f-4557-b3f9-525905bb1118,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-704113198-172.17.0.13-1597639181203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33107,DS-fe493efe-2996-4850-991e-ba4d25a51833,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-23023919-daf0-4f66-94c9-226928cb4c45,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-6025f029-2128-4ca7-887a-92b5565afe4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-1f83676d-1c4e-4def-b314-fb5b6208f1be,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-dcef3f95-612d-471c-a4d7-74fa3d9e221b,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-2b1fd401-7562-4a6d-b808-df2fc975f203,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-c9ea03b9-c97e-4994-adee-b5341ede212e,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-347fb976-109f-4557-b3f9-525905bb1118,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1492611002-172.17.0.13-1597639399083:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34357,DS-4b1204bf-f2e6-4e2f-9e72-a68e400b0f43,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-4aeffd76-1cfa-4ca4-8ffe-33aa5365e9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-75d0bb6e-a95a-42ae-a878-20fab18f2616,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-0e1c2f05-cf15-4649-9019-62f31c0b6a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-7dd87719-f0f0-4df9-8122-37fdaea2ae18,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-0fe61b54-0760-4a4a-95c1-ef93ab54cd2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-08a20f9c-d149-44e8-98b4-4878461ba593,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-e19de591-1632-4592-849f-d404137eccd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1492611002-172.17.0.13-1597639399083:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34357,DS-4b1204bf-f2e6-4e2f-9e72-a68e400b0f43,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-4aeffd76-1cfa-4ca4-8ffe-33aa5365e9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-75d0bb6e-a95a-42ae-a878-20fab18f2616,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-0e1c2f05-cf15-4649-9019-62f31c0b6a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-7dd87719-f0f0-4df9-8122-37fdaea2ae18,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-0fe61b54-0760-4a4a-95c1-ef93ab54cd2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-08a20f9c-d149-44e8-98b4-4878461ba593,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-e19de591-1632-4592-849f-d404137eccd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-426102976-172.17.0.13-1597639622288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41594,DS-4511a77a-d561-45e6-8eca-699d34503abe,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-d76f21c8-fce5-4fe9-a767-af6cf62fa787,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-36609c30-9a4b-4ba3-9178-22b72c618d38,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-6d9b0ae8-f8af-4cb8-b060-62d586ba7b26,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-a70b3689-33ec-431d-a814-bce46966958b,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-7cb73e73-6eb7-442d-ab28-a2f03b967ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-70c65d1f-9ae8-4b08-955e-6bf202f518d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-6b73e38c-b28c-4192-85c7-a0a69b2f2121,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-426102976-172.17.0.13-1597639622288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41594,DS-4511a77a-d561-45e6-8eca-699d34503abe,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-d76f21c8-fce5-4fe9-a767-af6cf62fa787,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-36609c30-9a4b-4ba3-9178-22b72c618d38,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-6d9b0ae8-f8af-4cb8-b060-62d586ba7b26,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-a70b3689-33ec-431d-a814-bce46966958b,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-7cb73e73-6eb7-442d-ab28-a2f03b967ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-70c65d1f-9ae8-4b08-955e-6bf202f518d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-6b73e38c-b28c-4192-85c7-a0a69b2f2121,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1809754821-172.17.0.13-1597640173554:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38041,DS-51725b51-b816-419c-a37f-818369d0c14d,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-b6da333e-562a-4b02-8957-d4b115f07ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-14b3075a-dfc1-4263-9cd3-e06a47e421db,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-0974a795-7b32-4013-8974-83270bf58601,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-1edb3695-e381-439d-9387-1235d580e17f,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-81f9326b-fd16-4e9d-b9df-1c7d93f10c12,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-6ce9db66-d801-4481-9e6b-c6e98fdee963,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-46ecf32f-df26-4974-94fc-2ee810e137f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1809754821-172.17.0.13-1597640173554:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38041,DS-51725b51-b816-419c-a37f-818369d0c14d,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-b6da333e-562a-4b02-8957-d4b115f07ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-14b3075a-dfc1-4263-9cd3-e06a47e421db,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-0974a795-7b32-4013-8974-83270bf58601,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-1edb3695-e381-439d-9387-1235d580e17f,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-81f9326b-fd16-4e9d-b9df-1c7d93f10c12,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-6ce9db66-d801-4481-9e6b-c6e98fdee963,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-46ecf32f-df26-4974-94fc-2ee810e137f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2000243686-172.17.0.13-1597640288495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43140,DS-aa345fcb-9a31-4c63-8692-48becf5adbde,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-4a43d820-ea60-4431-b610-2122cda300f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-75f292fc-c855-42f4-9888-50f9d89cb407,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-6ecc6406-99b3-476c-8443-d41d9e73ef30,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-a384ea22-194b-485f-b99b-a0126758ef66,DISK], DatanodeInfoWithStorage[127.0.0.1:37382,DS-7ea09973-56b3-461b-8f25-e77fb0b0d8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-8fb9610c-f8f8-47b1-9445-a633254290b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-38f8b6b4-9de5-40fa-aea5-85a64169d80e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2000243686-172.17.0.13-1597640288495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43140,DS-aa345fcb-9a31-4c63-8692-48becf5adbde,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-4a43d820-ea60-4431-b610-2122cda300f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-75f292fc-c855-42f4-9888-50f9d89cb407,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-6ecc6406-99b3-476c-8443-d41d9e73ef30,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-a384ea22-194b-485f-b99b-a0126758ef66,DISK], DatanodeInfoWithStorage[127.0.0.1:37382,DS-7ea09973-56b3-461b-8f25-e77fb0b0d8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-8fb9610c-f8f8-47b1-9445-a633254290b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-38f8b6b4-9de5-40fa-aea5-85a64169d80e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-881584705-172.17.0.13-1597641145697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40783,DS-2f051cd1-352c-4a46-83f3-79c90eace535,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-c4727c9d-53fb-47da-9643-26ad2b1f3390,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-10d6f90e-8626-4041-a7d9-d398c6968b17,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-1fca42da-bc71-4e4c-81f1-62a88459a905,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-76b49da9-765e-421f-bf46-011f360c8d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-ef7f46d9-9f67-410d-9656-f834c970d5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-9b4b3e56-4cb9-45b4-9c27-d120a60b015e,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-6e12acb6-dba1-4dee-bda2-6a016b976b29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-881584705-172.17.0.13-1597641145697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40783,DS-2f051cd1-352c-4a46-83f3-79c90eace535,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-c4727c9d-53fb-47da-9643-26ad2b1f3390,DISK], DatanodeInfoWithStorage[127.0.0.1:35282,DS-10d6f90e-8626-4041-a7d9-d398c6968b17,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-1fca42da-bc71-4e4c-81f1-62a88459a905,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-76b49da9-765e-421f-bf46-011f360c8d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-ef7f46d9-9f67-410d-9656-f834c970d5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-9b4b3e56-4cb9-45b4-9c27-d120a60b015e,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-6e12acb6-dba1-4dee-bda2-6a016b976b29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1098813506-172.17.0.13-1597641642642:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40655,DS-0909134f-0df0-4f9e-8172-32fdfaea8cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-c8ed337f-1331-4bf9-9f66-86ec8f3d6358,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-75053124-4648-47f3-8099-a5fa1efe9302,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-9bfe816f-c5a5-4052-9993-854da84b1581,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-3039ed8b-19fa-4456-9725-05e0d3a98c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-53173e64-4aa4-4be0-8152-7d7311c907e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-a0c2de06-5049-4763-b236-3f69248f8b29,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-1541fe14-ec7b-4c36-a6d5-c3a6559b1ee1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1098813506-172.17.0.13-1597641642642:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40655,DS-0909134f-0df0-4f9e-8172-32fdfaea8cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-c8ed337f-1331-4bf9-9f66-86ec8f3d6358,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-75053124-4648-47f3-8099-a5fa1efe9302,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-9bfe816f-c5a5-4052-9993-854da84b1581,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-3039ed8b-19fa-4456-9725-05e0d3a98c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-53173e64-4aa4-4be0-8152-7d7311c907e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-a0c2de06-5049-4763-b236-3f69248f8b29,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-1541fe14-ec7b-4c36-a6d5-c3a6559b1ee1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-454285490-172.17.0.13-1597641952421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45000,DS-283bb5e8-d2fc-4608-8cd9-5fc0fa5ccbae,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-af89d170-3159-421c-9e93-6878327667c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-7e58b06e-5f35-4d03-94c3-548f255e2f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-f455f121-7c39-4863-a537-1957b0a3815b,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-b1c477e9-6839-4c36-bc0d-258ac52ac1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-99138590-f887-495a-936a-ced6ef801c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-9b8e655b-8464-43d2-957e-158917c37f71,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-24796254-847e-4133-bb24-084c5e7459ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-454285490-172.17.0.13-1597641952421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45000,DS-283bb5e8-d2fc-4608-8cd9-5fc0fa5ccbae,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-af89d170-3159-421c-9e93-6878327667c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-7e58b06e-5f35-4d03-94c3-548f255e2f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-f455f121-7c39-4863-a537-1957b0a3815b,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-b1c477e9-6839-4c36-bc0d-258ac52ac1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-99138590-f887-495a-936a-ced6ef801c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-9b8e655b-8464-43d2-957e-158917c37f71,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-24796254-847e-4133-bb24-084c5e7459ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-564736584-172.17.0.13-1597642099992:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34130,DS-339e4111-8630-4676-a74f-a509cf10d878,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-973394f4-4c2c-47e8-aea5-b976d4080ead,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-0d936bb1-3c3a-44bb-a1e7-efd568c7da94,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-d25fe0c2-732e-4d3b-bcb5-76f5029e4eed,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-635aaaa7-8373-4da6-bf69-4fc9a578283a,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-9bd8ca6c-7639-49b3-903c-7e1991e68925,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-ef5dda36-f64d-4d82-9e59-f277836eb228,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-dde91f60-6159-4469-a6bd-fa441f6d2019,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-564736584-172.17.0.13-1597642099992:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34130,DS-339e4111-8630-4676-a74f-a509cf10d878,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-973394f4-4c2c-47e8-aea5-b976d4080ead,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-0d936bb1-3c3a-44bb-a1e7-efd568c7da94,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-d25fe0c2-732e-4d3b-bcb5-76f5029e4eed,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-635aaaa7-8373-4da6-bf69-4fc9a578283a,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-9bd8ca6c-7639-49b3-903c-7e1991e68925,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-ef5dda36-f64d-4d82-9e59-f277836eb228,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-dde91f60-6159-4469-a6bd-fa441f6d2019,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-106932794-172.17.0.13-1597642320766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39106,DS-c7507c1a-f8b2-4ba1-a755-bd4fa5a4e6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-f69b2e97-2d87-4b5f-9b57-0174fa1b424e,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-4b0f904d-d6b6-4251-b024-aa5b4e720a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-4ac5e483-4538-4185-83d9-1cf8c3f0f1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-5c32b6a6-e84e-42eb-a692-138bb3ec212f,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-4c97180d-d743-4380-a727-5f14a95797ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-958a2032-be7a-4fe1-b728-737d8f834fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-29e3b5ad-30fd-461f-8628-3a3d6e6c59a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-106932794-172.17.0.13-1597642320766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39106,DS-c7507c1a-f8b2-4ba1-a755-bd4fa5a4e6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-f69b2e97-2d87-4b5f-9b57-0174fa1b424e,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-4b0f904d-d6b6-4251-b024-aa5b4e720a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-4ac5e483-4538-4185-83d9-1cf8c3f0f1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-5c32b6a6-e84e-42eb-a692-138bb3ec212f,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-4c97180d-d743-4380-a727-5f14a95797ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-958a2032-be7a-4fe1-b728-737d8f834fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-29e3b5ad-30fd-461f-8628-3a3d6e6c59a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1983959139-172.17.0.13-1597642511844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39507,DS-0e5391d4-5eb5-4edd-b9a6-ac8ebac90755,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-14958e50-40da-43e3-ae04-a602c61ca346,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-50617f2a-d810-448b-8980-97189da62325,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-a34fc344-ea74-4cb6-9aff-35803cde69dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-8da1b528-b3c9-4e10-bf01-cba197b9593e,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-4b9c3589-6319-454d-9614-57f8ceb23c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-afd538a2-c1d6-4fd4-90a7-14b811af4b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-eb2635ca-26f7-4e2c-a9a2-9de81a7debef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1983959139-172.17.0.13-1597642511844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39507,DS-0e5391d4-5eb5-4edd-b9a6-ac8ebac90755,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-14958e50-40da-43e3-ae04-a602c61ca346,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-50617f2a-d810-448b-8980-97189da62325,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-a34fc344-ea74-4cb6-9aff-35803cde69dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-8da1b528-b3c9-4e10-bf01-cba197b9593e,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-4b9c3589-6319-454d-9614-57f8ceb23c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-afd538a2-c1d6-4fd4-90a7-14b811af4b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-eb2635ca-26f7-4e2c-a9a2-9de81a7debef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-222513192-172.17.0.13-1597643536097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32868,DS-214a0848-7417-477d-83f2-df0be8d7d9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-a7e9f557-7b7b-41fb-9d58-c4661ecda22d,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-3592b7e9-c3ef-4da3-b525-9fff48aa532b,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-4525c9de-06ed-4dcf-a7ab-baac4cf1dbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-ef9f6600-52df-463d-b935-19bab19640da,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-6a8b0d4a-e74f-4df1-9f8b-01debda0b699,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-69dfb583-f0d7-4824-95bf-89efe8c6d2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-3c44837b-60fa-4fbf-964a-1b5a38811dd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-222513192-172.17.0.13-1597643536097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32868,DS-214a0848-7417-477d-83f2-df0be8d7d9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-a7e9f557-7b7b-41fb-9d58-c4661ecda22d,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-3592b7e9-c3ef-4da3-b525-9fff48aa532b,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-4525c9de-06ed-4dcf-a7ab-baac4cf1dbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-ef9f6600-52df-463d-b935-19bab19640da,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-6a8b0d4a-e74f-4df1-9f8b-01debda0b699,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-69dfb583-f0d7-4824-95bf-89efe8c6d2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-3c44837b-60fa-4fbf-964a-1b5a38811dd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 1000ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1099310646-172.17.0.13-1597643760911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46853,DS-2348a49f-94d6-42f5-9a9b-c40c3c1d4ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-3385fa5a-81ca-494b-9c76-991594eb8145,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-fb7beda6-1e3e-4fec-973e-1de7f6760e91,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-d2973973-ea8e-46e7-b75c-19fdb7ce9e41,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-d9b75954-a40d-423d-bd58-a4f06c4c68c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-59bb6c7e-c488-4428-bb53-227d228b7a28,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-e8a3289d-4d6f-48e7-bc4c-a3a9e6792bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-468473ad-0d28-4d4f-bdec-df0204bb99af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1099310646-172.17.0.13-1597643760911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46853,DS-2348a49f-94d6-42f5-9a9b-c40c3c1d4ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-3385fa5a-81ca-494b-9c76-991594eb8145,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-fb7beda6-1e3e-4fec-973e-1de7f6760e91,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-d2973973-ea8e-46e7-b75c-19fdb7ce9e41,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-d9b75954-a40d-423d-bd58-a4f06c4c68c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-59bb6c7e-c488-4428-bb53-227d228b7a28,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-e8a3289d-4d6f-48e7-bc4c-a3a9e6792bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-468473ad-0d28-4d4f-bdec-df0204bb99af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 5495
