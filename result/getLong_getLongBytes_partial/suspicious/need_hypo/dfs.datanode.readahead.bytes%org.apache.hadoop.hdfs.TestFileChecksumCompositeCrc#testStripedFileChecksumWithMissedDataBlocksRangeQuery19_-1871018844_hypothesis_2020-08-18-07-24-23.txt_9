reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 134217728
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 134217728
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-938237427-172.17.0.8-1597735917161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38948,DS-82cda780-5381-4334-bb72-cad9c7458dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-3f9acde8-7ec9-47d4-9c61-a5bdb9297561,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-03ce7e12-02ec-4154-99f9-30392a7fcbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-de40639a-b5d6-4b5e-bef4-436d8bb29a18,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-589c4933-53fd-4a19-b6f8-8b252a0c6462,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-3763b23a-288e-4661-aab0-8c138c337ece,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-03a9365f-e43b-448c-9921-1a9cdd84cb16,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-f1bfda8d-d673-4a2f-84e3-e6383e2a0871,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-938237427-172.17.0.8-1597735917161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38948,DS-82cda780-5381-4334-bb72-cad9c7458dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-3f9acde8-7ec9-47d4-9c61-a5bdb9297561,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-03ce7e12-02ec-4154-99f9-30392a7fcbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-de40639a-b5d6-4b5e-bef4-436d8bb29a18,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-589c4933-53fd-4a19-b6f8-8b252a0c6462,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-3763b23a-288e-4661-aab0-8c138c337ece,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-03a9365f-e43b-448c-9921-1a9cdd84cb16,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-f1bfda8d-d673-4a2f-84e3-e6383e2a0871,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 134217728
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1068574530-172.17.0.8-1597736134286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36603,DS-f9bf59f3-e03c-45c4-88cd-502ca47baf4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-ed297a1c-adc0-42ae-ab73-d8f3fe5b8977,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-79c98cb5-93f8-438d-a07c-1a651de83e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-b5e4fea1-3bfe-4fe7-a50c-b65c8b8612de,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-b6da3c1a-a970-454c-93c7-724db04b21aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-f44dd792-b286-4947-b624-f8411d6135d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-f13c0747-99d0-4f2c-a138-d8e31e82fd93,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-f623c98e-d366-4aca-b5e7-3008a9fcbda7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1068574530-172.17.0.8-1597736134286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36603,DS-f9bf59f3-e03c-45c4-88cd-502ca47baf4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-ed297a1c-adc0-42ae-ab73-d8f3fe5b8977,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-79c98cb5-93f8-438d-a07c-1a651de83e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-b5e4fea1-3bfe-4fe7-a50c-b65c8b8612de,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-b6da3c1a-a970-454c-93c7-724db04b21aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-f44dd792-b286-4947-b624-f8411d6135d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-f13c0747-99d0-4f2c-a138-d8e31e82fd93,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-f623c98e-d366-4aca-b5e7-3008a9fcbda7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 134217728
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1526482584-172.17.0.8-1597736172424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33418,DS-52ebe9ff-25a9-4fda-93f0-d20d69f65074,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-e7093109-1968-4ecf-94fd-f30ffeea6bde,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-c5f1a6d4-2932-44dc-a326-08b2ca0d3f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-349a0555-dce7-47bf-b737-c986d859c13a,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-12ef7313-104a-4f49-8565-030eeee84f19,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-d39cfe09-b071-45b0-9a1b-576a51315cae,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-85896b5d-1048-4773-8a66-3e971a535543,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-fdf15f7c-a821-452f-9127-ed97733866f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1526482584-172.17.0.8-1597736172424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33418,DS-52ebe9ff-25a9-4fda-93f0-d20d69f65074,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-e7093109-1968-4ecf-94fd-f30ffeea6bde,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-c5f1a6d4-2932-44dc-a326-08b2ca0d3f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-349a0555-dce7-47bf-b737-c986d859c13a,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-12ef7313-104a-4f49-8565-030eeee84f19,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-d39cfe09-b071-45b0-9a1b-576a51315cae,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-85896b5d-1048-4773-8a66-3e971a535543,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-fdf15f7c-a821-452f-9127-ed97733866f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 134217728
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1960622130-172.17.0.8-1597736569386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43613,DS-7456051a-fa6e-4d12-beaa-6193d85fa441,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-37fb3a36-7b94-468e-a54f-b4d8586c5058,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-48bae43b-99a5-46e8-a05f-e274ac5d194d,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-5282bd97-f796-4fca-9ccb-25a4a9428290,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-6e349ab5-0dd4-4e4a-9a39-3f46c3d86e94,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-3cf86d96-78d4-409b-94bf-e12ee76fca77,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-690b368d-032a-47bb-87d8-ee6ba975c3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-c30e2d6a-62e8-4170-8890-dae6a2f003e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1960622130-172.17.0.8-1597736569386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43613,DS-7456051a-fa6e-4d12-beaa-6193d85fa441,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-37fb3a36-7b94-468e-a54f-b4d8586c5058,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-48bae43b-99a5-46e8-a05f-e274ac5d194d,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-5282bd97-f796-4fca-9ccb-25a4a9428290,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-6e349ab5-0dd4-4e4a-9a39-3f46c3d86e94,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-3cf86d96-78d4-409b-94bf-e12ee76fca77,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-690b368d-032a-47bb-87d8-ee6ba975c3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-c30e2d6a-62e8-4170-8890-dae6a2f003e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 134217728
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-571143048-172.17.0.8-1597736895830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34643,DS-dd140f12-e2fe-4c16-bceb-31e9904a42da,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-bc93c547-f6fc-43ea-a177-6ac66a0b97ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-db9828ae-aad9-4255-9053-f6c729422830,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-24905423-97f9-4d15-9fac-cffca3933319,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-565f3809-8ba9-4778-bf6c-17d624d694e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-c0c2a7c9-2eda-4403-9ad8-160a608d24ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-30f1b035-27c8-40db-846a-92936ae511ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34784,DS-54755b3f-1ffc-4b91-b75c-5af6b28b7d16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-571143048-172.17.0.8-1597736895830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34643,DS-dd140f12-e2fe-4c16-bceb-31e9904a42da,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-bc93c547-f6fc-43ea-a177-6ac66a0b97ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-db9828ae-aad9-4255-9053-f6c729422830,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-24905423-97f9-4d15-9fac-cffca3933319,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-565f3809-8ba9-4778-bf6c-17d624d694e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-c0c2a7c9-2eda-4403-9ad8-160a608d24ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-30f1b035-27c8-40db-846a-92936ae511ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34784,DS-54755b3f-1ffc-4b91-b75c-5af6b28b7d16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 134217728
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-530103491-172.17.0.8-1597737678787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39937,DS-da40f7bf-1551-465f-b6db-a5f6faa9272a,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-f4ffe423-fb07-4ad2-b23f-2d18aa35cae0,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-8bd1628d-1302-44a4-8a82-0edbf36f7751,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-974bb620-7ffa-4e27-9cb8-0f8e39adb67d,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-def8bf52-0c51-48db-ade6-3b61da692b09,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-f7ed9fa8-e9c4-4f92-9641-88cd741f66fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-52bcf839-f95a-4ba6-8986-e1a08c525731,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-abf2804f-5627-4505-9f96-6ac38a3eb6bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-530103491-172.17.0.8-1597737678787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39937,DS-da40f7bf-1551-465f-b6db-a5f6faa9272a,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-f4ffe423-fb07-4ad2-b23f-2d18aa35cae0,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-8bd1628d-1302-44a4-8a82-0edbf36f7751,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-974bb620-7ffa-4e27-9cb8-0f8e39adb67d,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-def8bf52-0c51-48db-ade6-3b61da692b09,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-f7ed9fa8-e9c4-4f92-9641-88cd741f66fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-52bcf839-f95a-4ba6-8986-e1a08c525731,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-abf2804f-5627-4505-9f96-6ac38a3eb6bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 134217728
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-23180-172.17.0.8-1597738002231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37247,DS-a1240570-ef5c-4b96-8800-fd066fb73543,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-2a2ef1d0-ddb3-4ca7-9352-d5570a9c81f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-6fb2922c-2920-49b7-a2ba-3cb97ef20758,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-ecf4d6b5-0ae6-45d5-b278-3c403250d3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-74974cc6-9307-4fde-99db-071153a28555,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-7b060727-714a-40ff-8c62-13cde35a0b35,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-74738c77-3b09-498c-b500-d0b4212acdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-30cf6ca9-5a1c-48f1-ab34-b9a1966a1fca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-23180-172.17.0.8-1597738002231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37247,DS-a1240570-ef5c-4b96-8800-fd066fb73543,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-2a2ef1d0-ddb3-4ca7-9352-d5570a9c81f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-6fb2922c-2920-49b7-a2ba-3cb97ef20758,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-ecf4d6b5-0ae6-45d5-b278-3c403250d3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-74974cc6-9307-4fde-99db-071153a28555,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-7b060727-714a-40ff-8c62-13cde35a0b35,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-74738c77-3b09-498c-b500-d0b4212acdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-30cf6ca9-5a1c-48f1-ab34-b9a1966a1fca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 134217728
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-412409821-172.17.0.8-1597738434363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33309,DS-f969a59a-5bb8-4bac-92bf-7e1ee3a56afe,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-4ddf7007-56ac-4071-9ec9-93a62ec805a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-3c07192d-8b40-4586-995c-21d61cd2704a,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-f06e0b69-0105-48f1-962b-cf3e3b1744ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-ae860250-87a1-473c-816d-b3bf332f248d,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-9909ad6c-1f6d-4909-ad8d-b30e0f48a140,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-f9ec2257-a2d1-4af2-92ac-7f5a00a5a792,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-d27ee5b9-2a13-404a-8b1e-335da838c8c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-412409821-172.17.0.8-1597738434363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33309,DS-f969a59a-5bb8-4bac-92bf-7e1ee3a56afe,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-4ddf7007-56ac-4071-9ec9-93a62ec805a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-3c07192d-8b40-4586-995c-21d61cd2704a,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-f06e0b69-0105-48f1-962b-cf3e3b1744ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-ae860250-87a1-473c-816d-b3bf332f248d,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-9909ad6c-1f6d-4909-ad8d-b30e0f48a140,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-f9ec2257-a2d1-4af2-92ac-7f5a00a5a792,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-d27ee5b9-2a13-404a-8b1e-335da838c8c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 134217728
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-820234332-172.17.0.8-1597738682799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46046,DS-0a483391-dee8-45e1-952a-66955b0a5628,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-c572a914-f4cb-42ad-9e8b-d5bb7790cb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-4158132b-c01b-4b08-9da8-c31d6350212f,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-0d2645c5-f362-4d1d-a121-5d4fc25d3246,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-3d621273-30ac-4dc9-94c0-7ae37737b16b,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-ad275d8a-dfcf-4527-bcc6-775e0938a058,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-10372239-9ad5-4df8-a49b-3682ac6f5b09,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-a1fc08db-8ea0-4734-b59d-706e8820c1aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-820234332-172.17.0.8-1597738682799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46046,DS-0a483391-dee8-45e1-952a-66955b0a5628,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-c572a914-f4cb-42ad-9e8b-d5bb7790cb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-4158132b-c01b-4b08-9da8-c31d6350212f,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-0d2645c5-f362-4d1d-a121-5d4fc25d3246,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-3d621273-30ac-4dc9-94c0-7ae37737b16b,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-ad275d8a-dfcf-4527-bcc6-775e0938a058,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-10372239-9ad5-4df8-a49b-3682ac6f5b09,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-a1fc08db-8ea0-4734-b59d-706e8820c1aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 134217728
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1664316415-172.17.0.8-1597739129650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44602,DS-142e9325-968e-4231-9867-c1a327d1792b,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-fe19a07f-8629-4822-ae64-5388dac35562,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-74dbe81f-ff4e-47a9-9f52-e7dc9133e2af,DISK], DatanodeInfoWithStorage[127.0.0.1:46412,DS-cdd5a373-7eba-4de1-ab0b-4d4a75d73559,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-1b0587a5-8310-4ef8-874e-89a033e3c97b,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-6d6fa1e8-4445-43c7-993f-fbaf424038a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-045b77f7-9f63-410c-8b8a-c5e63d5e01ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-d9cbebce-cbcd-482c-a294-934c3f82d5a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1664316415-172.17.0.8-1597739129650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44602,DS-142e9325-968e-4231-9867-c1a327d1792b,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-fe19a07f-8629-4822-ae64-5388dac35562,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-74dbe81f-ff4e-47a9-9f52-e7dc9133e2af,DISK], DatanodeInfoWithStorage[127.0.0.1:46412,DS-cdd5a373-7eba-4de1-ab0b-4d4a75d73559,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-1b0587a5-8310-4ef8-874e-89a033e3c97b,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-6d6fa1e8-4445-43c7-993f-fbaf424038a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-045b77f7-9f63-410c-8b8a-c5e63d5e01ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-d9cbebce-cbcd-482c-a294-934c3f82d5a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 134217728
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-216533051-172.17.0.8-1597739201101:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40168,DS-0064e05f-4490-49da-af44-4ca451abdced,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-ffa455cf-f3cf-4554-bea1-c2b545482bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-6e677f09-ae20-4ac0-a55f-f02afaafbd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-51a50206-286c-40c5-b24d-7c044b653905,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-6f7af823-719f-4967-8185-bbff4bd1c0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-5cb53fde-01c2-4601-bff8-37e4c70b88ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-65e649af-ceef-4527-a020-e6928f8d8a65,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-590252c7-502e-401b-8e1f-dead402cac59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-216533051-172.17.0.8-1597739201101:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40168,DS-0064e05f-4490-49da-af44-4ca451abdced,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-ffa455cf-f3cf-4554-bea1-c2b545482bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-6e677f09-ae20-4ac0-a55f-f02afaafbd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-51a50206-286c-40c5-b24d-7c044b653905,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-6f7af823-719f-4967-8185-bbff4bd1c0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-5cb53fde-01c2-4601-bff8-37e4c70b88ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-65e649af-ceef-4527-a020-e6928f8d8a65,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-590252c7-502e-401b-8e1f-dead402cac59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 134217728
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-378533413-172.17.0.8-1597739269818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35634,DS-b40b5aa2-6257-44bb-a3d6-acd514274ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-a28a9e77-18cb-4e14-9d7c-d747d54d7077,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-23847a39-5c48-469d-a8a2-772e84dfb9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-ec824bb2-8128-4a9e-8401-84526cc05305,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-a0db68fd-e965-4b96-b500-4cb46cdf5408,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-d9b65fea-353b-4ea5-8b00-9c6230f196a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-5f6c3a44-7b77-47e9-9a52-51857ce777e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-6e892151-48b9-4547-9e4f-4c79a033f0c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-378533413-172.17.0.8-1597739269818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35634,DS-b40b5aa2-6257-44bb-a3d6-acd514274ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-a28a9e77-18cb-4e14-9d7c-d747d54d7077,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-23847a39-5c48-469d-a8a2-772e84dfb9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-ec824bb2-8128-4a9e-8401-84526cc05305,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-a0db68fd-e965-4b96-b500-4cb46cdf5408,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-d9b65fea-353b-4ea5-8b00-9c6230f196a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-5f6c3a44-7b77-47e9-9a52-51857ce777e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-6e892151-48b9-4547-9e4f-4c79a033f0c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 134217728
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1478969246-172.17.0.8-1597739312616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33417,DS-891d9828-28ac-4fce-a28c-7ffc960159a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-74a5b36a-c726-4f1a-a668-c014c1840182,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-15c71f8d-0e60-4bb1-a2b9-2615e6509d66,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-415365fc-50ac-46e2-a25a-d983a4b905ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-c99f8161-cdf0-426d-a51f-7ac6257b3d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-27d165dc-d3bb-4675-98ba-881f3b9126d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-0dc1a306-fd27-4545-944f-5390ac20c8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-c4c5f599-f296-4d9d-a0d0-df04a0dbcddf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1478969246-172.17.0.8-1597739312616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33417,DS-891d9828-28ac-4fce-a28c-7ffc960159a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-74a5b36a-c726-4f1a-a668-c014c1840182,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-15c71f8d-0e60-4bb1-a2b9-2615e6509d66,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-415365fc-50ac-46e2-a25a-d983a4b905ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-c99f8161-cdf0-426d-a51f-7ac6257b3d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-27d165dc-d3bb-4675-98ba-881f3b9126d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-0dc1a306-fd27-4545-944f-5390ac20c8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41495,DS-c4c5f599-f296-4d9d-a0d0-df04a0dbcddf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 134217728
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-469283288-172.17.0.8-1597739428325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34564,DS-f3afca30-7db2-49f6-969b-bc494b9a50d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-ca05b00b-e056-4b79-abc6-1e7702d8c71b,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-83532a6d-5979-4853-84bf-4b467b5e3d22,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-ac71dc29-6c66-46e2-b980-861a2cff7491,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-9eb4e739-e159-4096-bfd4-d0f0b2db3cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-b8d53301-a708-409a-9862-543703549967,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-99b20039-c440-4d5a-9e90-ae67c59ffddd,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-24ef461f-99f8-4c49-81bf-d7035c8717a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-469283288-172.17.0.8-1597739428325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34564,DS-f3afca30-7db2-49f6-969b-bc494b9a50d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-ca05b00b-e056-4b79-abc6-1e7702d8c71b,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-83532a6d-5979-4853-84bf-4b467b5e3d22,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-ac71dc29-6c66-46e2-b980-861a2cff7491,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-9eb4e739-e159-4096-bfd4-d0f0b2db3cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-b8d53301-a708-409a-9862-543703549967,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-99b20039-c440-4d5a-9e90-ae67c59ffddd,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-24ef461f-99f8-4c49-81bf-d7035c8717a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 134217728
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-62692152-172.17.0.8-1597739902070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34761,DS-5ab026aa-905f-421b-b6fc-29cf7dfa7d09,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-9a1f6a53-db66-4535-a798-cfb862cc6cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-c1f1d8d8-6988-4b8d-9260-ae1a3ddf39f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-240fe214-925d-4ff8-854d-c337e08ce5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-17c9c57d-6cd2-43a3-a773-d991fb4f7f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-1d1e7728-ec1b-4486-a491-9f91fced4376,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-d264ed0c-718d-42b8-bb31-4a09073e4cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-8d197448-4aa9-440e-ab74-a1265b4bdf51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-62692152-172.17.0.8-1597739902070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34761,DS-5ab026aa-905f-421b-b6fc-29cf7dfa7d09,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-9a1f6a53-db66-4535-a798-cfb862cc6cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-c1f1d8d8-6988-4b8d-9260-ae1a3ddf39f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-240fe214-925d-4ff8-854d-c337e08ce5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-17c9c57d-6cd2-43a3-a773-d991fb4f7f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-1d1e7728-ec1b-4486-a491-9f91fced4376,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-d264ed0c-718d-42b8-bb31-4a09073e4cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-8d197448-4aa9-440e-ab74-a1265b4bdf51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 134217728
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-235196472-172.17.0.8-1597740116482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45894,DS-d6a6e6b1-3968-46ed-af0f-f011f81f3584,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-ca535886-532c-4dd7-8484-6db20e4825f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-aa6b9589-5ceb-4f97-8f39-480b96bb4f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-3022d091-efd8-47d9-a7c6-96608a2d5a02,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-f1e51c04-9bdf-40cd-9df4-db4d504f2d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-2d87b081-0919-44d7-b57c-2ac7b5190695,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-ebed753f-72e9-4b9d-b8e2-f7c7d0b669f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-e5506f70-801c-4c93-938f-e013d4cd0e7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-235196472-172.17.0.8-1597740116482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45894,DS-d6a6e6b1-3968-46ed-af0f-f011f81f3584,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-ca535886-532c-4dd7-8484-6db20e4825f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-aa6b9589-5ceb-4f97-8f39-480b96bb4f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-3022d091-efd8-47d9-a7c6-96608a2d5a02,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-f1e51c04-9bdf-40cd-9df4-db4d504f2d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-2d87b081-0919-44d7-b57c-2ac7b5190695,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-ebed753f-72e9-4b9d-b8e2-f7c7d0b669f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-e5506f70-801c-4c93-938f-e013d4cd0e7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 134217728
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-14653485-172.17.0.8-1597740186587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46236,DS-d113cb0a-7079-43b7-bb2e-850e088e7820,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-2068c158-b388-4f68-ba26-86567854b9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-c483fda9-637f-4f88-8b73-c630cc427fce,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-7da2644d-59e3-4b5d-a2a1-2f9b04efc13b,DISK], DatanodeInfoWithStorage[127.0.0.1:41664,DS-f1c84787-a68f-4eb7-befa-f88e2fbe98f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-3c551ee1-bac2-4045-b0d9-40053ffd72dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-481ece94-827c-4514-b97d-c8db3a473cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-d243aed2-1b81-485d-bff8-a8630b810010,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-14653485-172.17.0.8-1597740186587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46236,DS-d113cb0a-7079-43b7-bb2e-850e088e7820,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-2068c158-b388-4f68-ba26-86567854b9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-c483fda9-637f-4f88-8b73-c630cc427fce,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-7da2644d-59e3-4b5d-a2a1-2f9b04efc13b,DISK], DatanodeInfoWithStorage[127.0.0.1:41664,DS-f1c84787-a68f-4eb7-befa-f88e2fbe98f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-3c551ee1-bac2-4045-b0d9-40053ffd72dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-481ece94-827c-4514-b97d-c8db3a473cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-d243aed2-1b81-485d-bff8-a8630b810010,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 134217728
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2115268599-172.17.0.8-1597740520791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45285,DS-a085f5c2-c3b8-466c-ab02-2b2f33b6dfbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-3a247c70-0f94-44f2-b6cb-e58ce158ac32,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-7b5cf513-c341-49dd-955e-b38598cc15c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-63ba6819-25cf-4c07-8fcd-1f4a875c29c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-b30b1f09-ede4-45cf-ad93-c001f428e124,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-d17c5638-d1aa-4f82-a01b-a7b7b73ca857,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-1ee735e2-37e2-4411-87c3-321e26ba9302,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-30c5e3a8-4cfa-4d3b-b93e-67b9e7286333,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2115268599-172.17.0.8-1597740520791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45285,DS-a085f5c2-c3b8-466c-ab02-2b2f33b6dfbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-3a247c70-0f94-44f2-b6cb-e58ce158ac32,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-7b5cf513-c341-49dd-955e-b38598cc15c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-63ba6819-25cf-4c07-8fcd-1f4a875c29c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-b30b1f09-ede4-45cf-ad93-c001f428e124,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-d17c5638-d1aa-4f82-a01b-a7b7b73ca857,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-1ee735e2-37e2-4411-87c3-321e26ba9302,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-30c5e3a8-4cfa-4d3b-b93e-67b9e7286333,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 134217728
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1933237281-172.17.0.8-1597740555854:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44540,DS-28714fd4-48e8-44a3-98cc-221a0905a5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-486f99ca-aef7-41dc-82d3-429bc76b0ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-fb61306d-31e5-4794-b88b-931c83ddd32c,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-68e6e31c-e408-4ea3-a6a0-9d88b2995901,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-1f60d372-7912-4859-b70a-2ab898201c02,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-1573b269-241e-47f5-b700-f849752b15ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-1c54ed42-cbb9-4c13-b89a-cc7161bd45d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-4b130482-cb50-4147-ad90-21b0f1a92067,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1933237281-172.17.0.8-1597740555854:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44540,DS-28714fd4-48e8-44a3-98cc-221a0905a5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-486f99ca-aef7-41dc-82d3-429bc76b0ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-fb61306d-31e5-4794-b88b-931c83ddd32c,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-68e6e31c-e408-4ea3-a6a0-9d88b2995901,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-1f60d372-7912-4859-b70a-2ab898201c02,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-1573b269-241e-47f5-b700-f849752b15ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-1c54ed42-cbb9-4c13-b89a-cc7161bd45d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-4b130482-cb50-4147-ad90-21b0f1a92067,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 134217728
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-26875808-172.17.0.8-1597740837796:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39168,DS-2497d81f-44da-4958-8af8-b29a87b0dfae,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-956bc624-27b6-4532-b4b4-107c650995fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-b89059e0-6546-4e91-9e84-79e4bb7d4e10,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-3bb39fd5-39ba-4ffe-9c32-bc0dc3cd683d,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-acb96663-d586-47c5-9a44-6ecb3ba494ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-0f30ecb4-632f-411c-811d-c2139f73e653,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-f38687d4-9e86-4c5e-a457-da1c7433930e,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-a7fdc7e5-f2b1-4c2f-957d-67448ec0593e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-26875808-172.17.0.8-1597740837796:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39168,DS-2497d81f-44da-4958-8af8-b29a87b0dfae,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-956bc624-27b6-4532-b4b4-107c650995fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-b89059e0-6546-4e91-9e84-79e4bb7d4e10,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-3bb39fd5-39ba-4ffe-9c32-bc0dc3cd683d,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-acb96663-d586-47c5-9a44-6ecb3ba494ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-0f30ecb4-632f-411c-811d-c2139f73e653,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-f38687d4-9e86-4c5e-a457-da1c7433930e,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-a7fdc7e5-f2b1-4c2f-957d-67448ec0593e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 13 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: might be true error
Total execution time in seconds : 5465
