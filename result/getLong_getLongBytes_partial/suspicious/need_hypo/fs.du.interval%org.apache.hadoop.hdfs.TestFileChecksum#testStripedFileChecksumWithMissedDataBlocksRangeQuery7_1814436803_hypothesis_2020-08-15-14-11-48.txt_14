reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1070884454-172.17.0.19-1597501123243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44153,DS-a19dc95c-aab4-427d-981b-8ac5c4d6900d,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-f4b4157c-6de6-4d47-9448-2e47ede60297,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-9359c56b-5e41-4c0e-9cb1-8b756cb6c694,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-a62ae59f-dc90-4c8e-aa95-a7383d0f380a,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-6fb35711-a19d-42a3-82ca-31151458410f,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-93b73dc8-fe3a-4bde-ad0f-2edf9e5f047d,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-93edb007-090f-4bcf-90e9-37d62755a095,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-b7c064b0-08b3-4982-8647-bf93dad0e7aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1070884454-172.17.0.19-1597501123243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44153,DS-a19dc95c-aab4-427d-981b-8ac5c4d6900d,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-f4b4157c-6de6-4d47-9448-2e47ede60297,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-9359c56b-5e41-4c0e-9cb1-8b756cb6c694,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-a62ae59f-dc90-4c8e-aa95-a7383d0f380a,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-6fb35711-a19d-42a3-82ca-31151458410f,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-93b73dc8-fe3a-4bde-ad0f-2edf9e5f047d,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-93edb007-090f-4bcf-90e9-37d62755a095,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-b7c064b0-08b3-4982-8647-bf93dad0e7aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-32283817-172.17.0.19-1597501196879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42402,DS-774f0cad-4f0b-49dd-adc5-a92cbfff0aad,DISK], DatanodeInfoWithStorage[127.0.0.1:36258,DS-d21ee352-267e-4e94-9c8d-69e70955dcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-1168ce4b-65a4-4f19-b176-04468b9a3059,DISK], DatanodeInfoWithStorage[127.0.0.1:42568,DS-38a60f82-f174-4f57-b275-a2e8f7e8525d,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-a670a68c-5568-40ff-95eb-73a7d87be61b,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-fed973c7-df45-4c76-86dc-d97f753c06a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-db035057-6873-497e-85ff-d8fa14b67fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-7c3cea17-1b67-49d1-adce-0744a4cc2459,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-32283817-172.17.0.19-1597501196879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42402,DS-774f0cad-4f0b-49dd-adc5-a92cbfff0aad,DISK], DatanodeInfoWithStorage[127.0.0.1:36258,DS-d21ee352-267e-4e94-9c8d-69e70955dcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-1168ce4b-65a4-4f19-b176-04468b9a3059,DISK], DatanodeInfoWithStorage[127.0.0.1:42568,DS-38a60f82-f174-4f57-b275-a2e8f7e8525d,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-a670a68c-5568-40ff-95eb-73a7d87be61b,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-fed973c7-df45-4c76-86dc-d97f753c06a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-db035057-6873-497e-85ff-d8fa14b67fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-7c3cea17-1b67-49d1-adce-0744a4cc2459,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308238271-172.17.0.19-1597501335620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41785,DS-e5ca15d1-749a-4836-9518-43f3cdef5e30,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-4f92936c-cd48-4c1b-8c96-6974970dac95,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-f895be90-994f-4176-8603-071b1a727966,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-3e47ec82-aa2a-4046-aeb4-0d954544b50d,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-87d015e8-935b-4fa0-8b01-4ccbc7bcf038,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-5e4d7815-0616-4dea-bc71-31e289592644,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-6a50db79-7dda-4f71-8a92-fa9613f7281b,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-e928817f-d815-4a22-91e5-9d9f788f49f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308238271-172.17.0.19-1597501335620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41785,DS-e5ca15d1-749a-4836-9518-43f3cdef5e30,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-4f92936c-cd48-4c1b-8c96-6974970dac95,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-f895be90-994f-4176-8603-071b1a727966,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-3e47ec82-aa2a-4046-aeb4-0d954544b50d,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-87d015e8-935b-4fa0-8b01-4ccbc7bcf038,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-5e4d7815-0616-4dea-bc71-31e289592644,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-6a50db79-7dda-4f71-8a92-fa9613f7281b,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-e928817f-d815-4a22-91e5-9d9f788f49f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-477117744-172.17.0.19-1597501408573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42633,DS-d35188d3-56a0-462b-863c-8600b837463e,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-d37ed50a-363e-418a-9e00-b77a51a1bd96,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-23c7173e-04c1-4df0-9bdf-dbbabded5042,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-9abb75f6-aadd-4189-883c-de9874058b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40604,DS-0b940064-d8c3-4754-9a41-c49b79190333,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-5b629285-4787-455d-b742-5d12ae4c2933,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-ce9df970-0409-478b-bbea-e6131456ce21,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-cecddae6-e586-4706-a73c-e129522fb08b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-477117744-172.17.0.19-1597501408573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42633,DS-d35188d3-56a0-462b-863c-8600b837463e,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-d37ed50a-363e-418a-9e00-b77a51a1bd96,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-23c7173e-04c1-4df0-9bdf-dbbabded5042,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-9abb75f6-aadd-4189-883c-de9874058b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40604,DS-0b940064-d8c3-4754-9a41-c49b79190333,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-5b629285-4787-455d-b742-5d12ae4c2933,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-ce9df970-0409-478b-bbea-e6131456ce21,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-cecddae6-e586-4706-a73c-e129522fb08b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1382569850-172.17.0.19-1597501586681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43990,DS-32f8c617-9e56-4d07-94a2-e632491f5026,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-a6a22f78-3a0a-4d9b-81f6-41d31b77e332,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-ad4ea691-e684-4ea5-8f88-911a4005ea7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45758,DS-97d9b3c6-201c-42c7-8a26-a5d5f413df89,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-7e9ab8b0-1105-4fd3-81fa-ae645fa5368d,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-801313a6-5da3-4037-b7de-8290f110ff0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-147a9b5d-83d0-444c-aea5-f700ae8cf70f,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-437be5f5-e794-488e-a4cb-2e3599fd2f7d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1382569850-172.17.0.19-1597501586681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43990,DS-32f8c617-9e56-4d07-94a2-e632491f5026,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-a6a22f78-3a0a-4d9b-81f6-41d31b77e332,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-ad4ea691-e684-4ea5-8f88-911a4005ea7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45758,DS-97d9b3c6-201c-42c7-8a26-a5d5f413df89,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-7e9ab8b0-1105-4fd3-81fa-ae645fa5368d,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-801313a6-5da3-4037-b7de-8290f110ff0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-147a9b5d-83d0-444c-aea5-f700ae8cf70f,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-437be5f5-e794-488e-a4cb-2e3599fd2f7d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092182890-172.17.0.19-1597501692125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42624,DS-eb443967-6bc9-4a8e-b9c8-8884d0bbdff3,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-273c10a8-697c-48e0-bb63-036a5be71f97,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-5759610a-7dad-4d79-9354-506d2d832092,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-ea131926-ff9b-497b-9d93-8b032d056b46,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-af8e774e-48a3-40bf-a103-7795cbf57d29,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-ade11122-f047-4d68-b9ae-33712f2fd90b,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-6e4630f8-c13c-4c1e-81b3-add780474a80,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-ac1fa4f9-b5f2-4917-b717-c835200177e3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092182890-172.17.0.19-1597501692125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42624,DS-eb443967-6bc9-4a8e-b9c8-8884d0bbdff3,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-273c10a8-697c-48e0-bb63-036a5be71f97,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-5759610a-7dad-4d79-9354-506d2d832092,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-ea131926-ff9b-497b-9d93-8b032d056b46,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-af8e774e-48a3-40bf-a103-7795cbf57d29,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-ade11122-f047-4d68-b9ae-33712f2fd90b,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-6e4630f8-c13c-4c1e-81b3-add780474a80,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-ac1fa4f9-b5f2-4917-b717-c835200177e3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-301166721-172.17.0.19-1597501953804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42387,DS-73a22065-67e2-4332-946f-ffca265bfe77,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-71afdb09-6040-435f-a15c-d09000ecde0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-ead2e00e-8243-453e-807a-8a6c556fe698,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-69bce958-b2f9-4c0e-b89c-9e6d2ce04876,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-a42c50b9-f246-4d08-845e-ef721b647825,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-6dc7d0ca-c84a-464a-b4e5-b3d50310ec22,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-f2886fbd-dcbc-4bb2-8df7-3135926457c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-75b3cf18-e8a3-4f76-8f66-8da24d754478,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-301166721-172.17.0.19-1597501953804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42387,DS-73a22065-67e2-4332-946f-ffca265bfe77,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-71afdb09-6040-435f-a15c-d09000ecde0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-ead2e00e-8243-453e-807a-8a6c556fe698,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-69bce958-b2f9-4c0e-b89c-9e6d2ce04876,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-a42c50b9-f246-4d08-845e-ef721b647825,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-6dc7d0ca-c84a-464a-b4e5-b3d50310ec22,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-f2886fbd-dcbc-4bb2-8df7-3135926457c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-75b3cf18-e8a3-4f76-8f66-8da24d754478,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600311621-172.17.0.19-1597502022298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34999,DS-1d8744f9-1103-4d70-8079-49fa1f73cdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-5db61a41-1757-4f8c-b07f-2b8b08fdc857,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-5cf556fe-fb50-420e-9c16-809070dd0d44,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-9cea745d-997c-48b2-a8c0-1f0e59399a64,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-0bea2c7c-5752-49d4-8070-831cb8771b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-e0364fc9-886b-45fb-8f42-f0b7590c9125,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-a38e3708-a780-44d0-b0fe-c46751a3a7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35184,DS-4ec07a60-e917-4229-9061-d3cb3c2e2794,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600311621-172.17.0.19-1597502022298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34999,DS-1d8744f9-1103-4d70-8079-49fa1f73cdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-5db61a41-1757-4f8c-b07f-2b8b08fdc857,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-5cf556fe-fb50-420e-9c16-809070dd0d44,DISK], DatanodeInfoWithStorage[127.0.0.1:39472,DS-9cea745d-997c-48b2-a8c0-1f0e59399a64,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-0bea2c7c-5752-49d4-8070-831cb8771b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-e0364fc9-886b-45fb-8f42-f0b7590c9125,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-a38e3708-a780-44d0-b0fe-c46751a3a7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35184,DS-4ec07a60-e917-4229-9061-d3cb3c2e2794,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-301402453-172.17.0.19-1597502059055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44636,DS-61996034-48da-4246-b5be-76d92dc41f03,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-9bb0790b-ac3d-4153-b5ba-ec2e611554ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-4baad65b-ce7b-4cf9-b6e7-95d0c317ee3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-45c7e4d4-d95b-4d26-b4d9-36fb021b6878,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-a6865f8d-74a2-4eb9-b383-b26c68a114dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-9b28b2d8-bd43-49de-bda6-f8c14991f859,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-f322db8f-0646-43c0-9888-b7bab8ef8e17,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-9b5b28a1-d091-42e8-b0d3-fb105908e487,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-301402453-172.17.0.19-1597502059055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44636,DS-61996034-48da-4246-b5be-76d92dc41f03,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-9bb0790b-ac3d-4153-b5ba-ec2e611554ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-4baad65b-ce7b-4cf9-b6e7-95d0c317ee3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-45c7e4d4-d95b-4d26-b4d9-36fb021b6878,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-a6865f8d-74a2-4eb9-b383-b26c68a114dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-9b28b2d8-bd43-49de-bda6-f8c14991f859,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-f322db8f-0646-43c0-9888-b7bab8ef8e17,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-9b5b28a1-d091-42e8-b0d3-fb105908e487,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1043961258-172.17.0.19-1597502654014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38684,DS-c2f97d92-25bd-4c5d-8ea1-0c727885f9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-991af5c1-ca71-45ad-a16f-d31443b1ee9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-b71301ab-b829-4478-8160-135a84093a32,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-86bd9a49-a3f2-47fa-9f09-bdf8d3411be2,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-1a64f2de-2d85-4cb8-a006-c82c68f7ed72,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-15bedaeb-833c-4023-adaa-026281370b14,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-d4c9ebda-b9d9-4d5a-97a9-436712d420d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-56f25ea3-abbb-4e1b-8165-3a7994e6ddcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1043961258-172.17.0.19-1597502654014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38684,DS-c2f97d92-25bd-4c5d-8ea1-0c727885f9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-991af5c1-ca71-45ad-a16f-d31443b1ee9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-b71301ab-b829-4478-8160-135a84093a32,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-86bd9a49-a3f2-47fa-9f09-bdf8d3411be2,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-1a64f2de-2d85-4cb8-a006-c82c68f7ed72,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-15bedaeb-833c-4023-adaa-026281370b14,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-d4c9ebda-b9d9-4d5a-97a9-436712d420d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-56f25ea3-abbb-4e1b-8165-3a7994e6ddcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662417343-172.17.0.19-1597502757540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38837,DS-49d00b77-1d35-4f53-bee4-e00bc253eda5,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-5d6ba272-9403-4181-964f-5f1d1184423c,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-aea523cc-c841-4b0d-a480-ade4026f59f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-eab8b0c1-89f5-4d41-a6bb-aa3b1546a53e,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-e9a657e3-ddee-47b3-8b52-2ba1da405056,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-c23e88c6-b1c0-4e94-98be-0596cddee128,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-6b8a5ae8-cdc4-4f15-b657-f9dd1ae8ab6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-22b5e5b4-f089-4008-9f5c-a3dd42fbd657,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662417343-172.17.0.19-1597502757540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38837,DS-49d00b77-1d35-4f53-bee4-e00bc253eda5,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-5d6ba272-9403-4181-964f-5f1d1184423c,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-aea523cc-c841-4b0d-a480-ade4026f59f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-eab8b0c1-89f5-4d41-a6bb-aa3b1546a53e,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-e9a657e3-ddee-47b3-8b52-2ba1da405056,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-c23e88c6-b1c0-4e94-98be-0596cddee128,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-6b8a5ae8-cdc4-4f15-b657-f9dd1ae8ab6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-22b5e5b4-f089-4008-9f5c-a3dd42fbd657,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1536576733-172.17.0.19-1597502869830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38971,DS-751e16c5-4175-487c-8c3a-0b669f6e22c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-036adaff-dc58-4d90-8ea0-25a855bdd89a,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-34215d70-a43f-4a2c-b481-4f13d3b86f56,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-b10c11d3-dcc7-4905-80f1-a2b3b1ede145,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-a757e0c8-d695-400d-9650-00e027cb9805,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-49715281-df40-49d0-a047-0b015c3a1773,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-e1ebf626-3d2d-419b-be52-9e9a3b4cdb31,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-abdc336f-3b92-441e-8e12-c2c595d5fe27,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1536576733-172.17.0.19-1597502869830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38971,DS-751e16c5-4175-487c-8c3a-0b669f6e22c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-036adaff-dc58-4d90-8ea0-25a855bdd89a,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-34215d70-a43f-4a2c-b481-4f13d3b86f56,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-b10c11d3-dcc7-4905-80f1-a2b3b1ede145,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-a757e0c8-d695-400d-9650-00e027cb9805,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-49715281-df40-49d0-a047-0b015c3a1773,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-e1ebf626-3d2d-419b-be52-9e9a3b4cdb31,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-abdc336f-3b92-441e-8e12-c2c595d5fe27,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393177903-172.17.0.19-1597503166836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40737,DS-489ea3f8-43db-4258-95b7-9068bbebc9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-abf8ab04-28bd-4b72-85e6-80eaf36eb15c,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-f6fe51ae-3bf0-444c-8856-7170c2fd5262,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-446fe3ee-0297-4f77-adcc-20f17075a3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-7ac3613e-06d7-4d32-ac10-4741b04f09b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-3d3efb1e-4bf2-4dab-95da-e857e6f6e21c,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-2cdab283-948d-43cf-bf9b-75d02a43a476,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-459d9db9-d870-4916-b8e9-eb53665b0962,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393177903-172.17.0.19-1597503166836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40737,DS-489ea3f8-43db-4258-95b7-9068bbebc9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-abf8ab04-28bd-4b72-85e6-80eaf36eb15c,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-f6fe51ae-3bf0-444c-8856-7170c2fd5262,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-446fe3ee-0297-4f77-adcc-20f17075a3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-7ac3613e-06d7-4d32-ac10-4741b04f09b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-3d3efb1e-4bf2-4dab-95da-e857e6f6e21c,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-2cdab283-948d-43cf-bf9b-75d02a43a476,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-459d9db9-d870-4916-b8e9-eb53665b0962,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2005133597-172.17.0.19-1597503198321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33263,DS-1e2f2641-ffab-4b06-92ad-7a53621a86a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-4ef67c34-62dd-4673-aea3-a03f0f166774,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-159f2aef-666d-4d12-a2e4-bf4b5487cafc,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-1d082e24-fc28-48a3-b4a6-f5e48305be94,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-6a52f8ae-6952-40c4-841b-abe3354ae854,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-0e6779df-6540-44aa-994b-04ef37fcf65c,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-0bae0ee0-5084-49c5-a094-d73391b3efbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-ce792774-379e-4b90-b628-9459e280c047,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2005133597-172.17.0.19-1597503198321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33263,DS-1e2f2641-ffab-4b06-92ad-7a53621a86a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-4ef67c34-62dd-4673-aea3-a03f0f166774,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-159f2aef-666d-4d12-a2e4-bf4b5487cafc,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-1d082e24-fc28-48a3-b4a6-f5e48305be94,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-6a52f8ae-6952-40c4-841b-abe3354ae854,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-0e6779df-6540-44aa-994b-04ef37fcf65c,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-0bae0ee0-5084-49c5-a094-d73391b3efbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-ce792774-379e-4b90-b628-9459e280c047,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1433690258-172.17.0.19-1597503532014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38795,DS-a0923a35-1cc8-4154-a0d0-dfb9c8759c66,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-8d300e5d-1f40-43b2-bd55-94238491963a,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-c990e8e4-9cf1-44d7-bed4-0f2b7446e453,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-58f5e402-70b9-4309-bfb6-09f231d14a87,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-955a8c1c-8e27-496b-9ad3-01e3dccd4461,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-75c5c8bc-3b84-4ac5-8c2f-9caeb814835f,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-b2c52f4a-3f24-4ab7-b940-ea6efdf844e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-c7deeeef-1d72-41f1-b202-2b952618f31e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1433690258-172.17.0.19-1597503532014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38795,DS-a0923a35-1cc8-4154-a0d0-dfb9c8759c66,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-8d300e5d-1f40-43b2-bd55-94238491963a,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-c990e8e4-9cf1-44d7-bed4-0f2b7446e453,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-58f5e402-70b9-4309-bfb6-09f231d14a87,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-955a8c1c-8e27-496b-9ad3-01e3dccd4461,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-75c5c8bc-3b84-4ac5-8c2f-9caeb814835f,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-b2c52f4a-3f24-4ab7-b940-ea6efdf844e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-c7deeeef-1d72-41f1-b202-2b952618f31e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20580551-172.17.0.19-1597503725928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42027,DS-066a55a3-c143-4d90-8f3f-afea38cb3810,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-01fa9c6e-8f9d-45e8-8299-4a82ffbb04c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-66b4d9fa-13b8-4cc5-965d-86b0b4dcbe53,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-a6aca950-877b-4c57-b131-d1c2de4974ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-b606f8b0-f622-4eaf-a7ee-086832922845,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-a6a987f3-e9d7-4f0a-85fe-0203b9b68dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-082198d8-056d-4032-8a81-7b2566dca200,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-ec955c2c-af98-4aea-8698-6c280efe669c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20580551-172.17.0.19-1597503725928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42027,DS-066a55a3-c143-4d90-8f3f-afea38cb3810,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-01fa9c6e-8f9d-45e8-8299-4a82ffbb04c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-66b4d9fa-13b8-4cc5-965d-86b0b4dcbe53,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-a6aca950-877b-4c57-b131-d1c2de4974ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-b606f8b0-f622-4eaf-a7ee-086832922845,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-a6a987f3-e9d7-4f0a-85fe-0203b9b68dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-082198d8-056d-4032-8a81-7b2566dca200,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-ec955c2c-af98-4aea-8698-6c280efe669c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523662494-172.17.0.19-1597503917916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41901,DS-1723d285-3458-4243-8e79-25bbac20fe6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-67b35e9c-5df3-409d-b805-2c2813dec2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-dca9826b-946d-421c-aa9a-d12a818b6d28,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-273f57be-be89-4a47-bf9c-6aba8666d6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-72bb5067-7057-4cf9-a2ae-65d9466144e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-86faf444-8fe6-4cf3-a894-a9f7a98b980b,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-f95e2ea9-546a-40c8-abc8-e91b34733157,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-f7368a43-9259-4426-8cf4-f3805d89d7f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523662494-172.17.0.19-1597503917916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41901,DS-1723d285-3458-4243-8e79-25bbac20fe6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-67b35e9c-5df3-409d-b805-2c2813dec2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-dca9826b-946d-421c-aa9a-d12a818b6d28,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-273f57be-be89-4a47-bf9c-6aba8666d6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-72bb5067-7057-4cf9-a2ae-65d9466144e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-86faf444-8fe6-4cf3-a894-a9f7a98b980b,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-f95e2ea9-546a-40c8-abc8-e91b34733157,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-f7368a43-9259-4426-8cf4-f3805d89d7f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-900635410-172.17.0.19-1597503948217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40093,DS-159fd9d2-8978-4ffb-a439-92080dd2e06e,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-34c884b4-00af-4e8b-9999-e31b77214c53,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-d1002c37-f3e6-42d2-bf89-4f260ce7872b,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-c43c3491-9bdd-45d2-a976-9c1e148eeb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-a7f69450-9c1f-4bc9-b0bc-077650a7d57d,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-a49290cb-114f-4aa1-a380-224afb5143f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-03dabc70-ddd8-46f8-ac20-01344ac12595,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-945d69db-0f81-4e87-8ee4-ce1103433fc9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-900635410-172.17.0.19-1597503948217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40093,DS-159fd9d2-8978-4ffb-a439-92080dd2e06e,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-34c884b4-00af-4e8b-9999-e31b77214c53,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-d1002c37-f3e6-42d2-bf89-4f260ce7872b,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-c43c3491-9bdd-45d2-a976-9c1e148eeb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-a7f69450-9c1f-4bc9-b0bc-077650a7d57d,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-a49290cb-114f-4aa1-a380-224afb5143f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-03dabc70-ddd8-46f8-ac20-01344ac12595,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-945d69db-0f81-4e87-8ee4-ce1103433fc9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-42011759-172.17.0.19-1597504071499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43859,DS-c4ec7580-18f7-40d8-b559-5f08316d3f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-b90bbd30-bac0-4b49-beb7-0366c3555ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-e5ac0901-85de-422f-ac5a-665d255b2ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-337b262b-8160-4dd0-946a-44fe6e5affdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-36060bf1-c673-45ae-9fab-09f4a13f78e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-c896051f-e5cd-41f7-aead-83f15c2c3739,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-643d4e3a-7bbf-49b5-ba0f-332b6734aed9,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-8c27a547-3088-46a0-8037-baa34db256a9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-42011759-172.17.0.19-1597504071499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43859,DS-c4ec7580-18f7-40d8-b559-5f08316d3f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-b90bbd30-bac0-4b49-beb7-0366c3555ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-e5ac0901-85de-422f-ac5a-665d255b2ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-337b262b-8160-4dd0-946a-44fe6e5affdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-36060bf1-c673-45ae-9fab-09f4a13f78e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-c896051f-e5cd-41f7-aead-83f15c2c3739,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-643d4e3a-7bbf-49b5-ba0f-332b6734aed9,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-8c27a547-3088-46a0-8037-baa34db256a9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1207453279-172.17.0.19-1597504289467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43946,DS-043368cb-aeba-40c0-b5c2-eb7b0fc716ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-a05f3ccf-1e2b-46c9-bd92-a3a4b5481874,DISK], DatanodeInfoWithStorage[127.0.0.1:45831,DS-e08cd479-ca8b-44b1-ade4-b51bbe89c7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-f37a1406-cd34-436a-9b31-5e6f86422214,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-c81491e1-373f-4244-a99b-368360efc95b,DISK], DatanodeInfoWithStorage[127.0.0.1:42019,DS-b4067968-8cf3-4bd9-83db-43915807b780,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-0a76f597-dd91-4201-ab8c-87e17aa8b4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-a0868e2e-af35-484f-994a-b5b42a060fbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1207453279-172.17.0.19-1597504289467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43946,DS-043368cb-aeba-40c0-b5c2-eb7b0fc716ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-a05f3ccf-1e2b-46c9-bd92-a3a4b5481874,DISK], DatanodeInfoWithStorage[127.0.0.1:45831,DS-e08cd479-ca8b-44b1-ade4-b51bbe89c7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-f37a1406-cd34-436a-9b31-5e6f86422214,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-c81491e1-373f-4244-a99b-368360efc95b,DISK], DatanodeInfoWithStorage[127.0.0.1:42019,DS-b4067968-8cf3-4bd9-83db-43915807b780,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-0a76f597-dd91-4201-ab8c-87e17aa8b4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-a0868e2e-af35-484f-994a-b5b42a060fbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-500509032-172.17.0.19-1597504461631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41253,DS-702bf7be-675a-49b9-b11f-bc02e15a5ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-22d3d623-50ce-4e77-b246-eeb504c0318b,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-ded315d8-9d34-4297-b19a-94a0e7a994f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-696a206b-8900-451a-8e5e-4ef9112ce237,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-7efb32b2-4100-49a3-a6bd-6df29df9a66b,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-317c33ec-f836-4dd8-a434-b6636de28361,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-af1cdfa3-8946-4a39-8be7-d41b5cb80ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-08085407-6246-42b0-8c8a-515bdaad88c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-500509032-172.17.0.19-1597504461631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41253,DS-702bf7be-675a-49b9-b11f-bc02e15a5ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-22d3d623-50ce-4e77-b246-eeb504c0318b,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-ded315d8-9d34-4297-b19a-94a0e7a994f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-696a206b-8900-451a-8e5e-4ef9112ce237,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-7efb32b2-4100-49a3-a6bd-6df29df9a66b,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-317c33ec-f836-4dd8-a434-b6636de28361,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-af1cdfa3-8946-4a39-8be7-d41b5cb80ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-08085407-6246-42b0-8c8a-515bdaad88c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1624656885-172.17.0.19-1597504641357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40717,DS-b916e097-f476-46c7-8e41-3494f0dcce59,DISK], DatanodeInfoWithStorage[127.0.0.1:43352,DS-fbd60512-9d75-4849-9478-8c2a7d0f3f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-e4ca566d-f092-4e3d-887f-32225004cfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-5b7b4eb4-e46f-4fc6-bee3-0e7f52608e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-ba4873d5-617b-48e0-8b1e-4a533b155eef,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-e2d4e4b6-4662-4e5b-871b-9c2e4b27d0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-c08c089d-ab40-4df7-8f88-741ddd79f514,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-63ef798d-cce6-4427-b750-3bd726dc8952,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1624656885-172.17.0.19-1597504641357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40717,DS-b916e097-f476-46c7-8e41-3494f0dcce59,DISK], DatanodeInfoWithStorage[127.0.0.1:43352,DS-fbd60512-9d75-4849-9478-8c2a7d0f3f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-e4ca566d-f092-4e3d-887f-32225004cfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-5b7b4eb4-e46f-4fc6-bee3-0e7f52608e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-ba4873d5-617b-48e0-8b1e-4a533b155eef,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-e2d4e4b6-4662-4e5b-871b-9c2e4b27d0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-c08c089d-ab40-4df7-8f88-741ddd79f514,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-63ef798d-cce6-4427-b750-3bd726dc8952,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1899161187-172.17.0.19-1597504743108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41615,DS-e87e1a6f-6341-4490-be3b-73bc02398036,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-ecf1624a-fd76-45b6-9eb2-90a2e3e88552,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-42b45850-1a46-4f1d-96b6-b449b374ec34,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-6a605ec0-480f-4f36-b340-2282e09fda69,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-367f05bd-3829-4f55-8b06-e915a60ec523,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-d87366f1-72dd-440f-a6b5-484db8f6ec95,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-c1dceac0-7115-4219-9d2d-e8997313df63,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-49e3b399-e376-45d9-bc63-058845f02196,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1899161187-172.17.0.19-1597504743108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41615,DS-e87e1a6f-6341-4490-be3b-73bc02398036,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-ecf1624a-fd76-45b6-9eb2-90a2e3e88552,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-42b45850-1a46-4f1d-96b6-b449b374ec34,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-6a605ec0-480f-4f36-b340-2282e09fda69,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-367f05bd-3829-4f55-8b06-e915a60ec523,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-d87366f1-72dd-440f-a6b5-484db8f6ec95,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-c1dceac0-7115-4219-9d2d-e8997313df63,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-49e3b399-e376-45d9-bc63-058845f02196,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1161092191-172.17.0.19-1597504888469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41042,DS-fbaa9c11-24d8-4a8d-8cd9-17685e8d0da6,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-2a07180c-2670-4577-90c0-60012cd042eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-bfa217e0-f3b0-412e-a189-3b3405ac309b,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-4de534d5-a9df-49ea-a255-879ae4fa2879,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-26969bb2-219c-45e4-9455-64d436a56b20,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-3fcefaa4-2533-4e38-8c2a-d6a244dcc2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-31793ecd-8707-4ef7-a1b3-b42b36cc9627,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-4d9cbe92-270d-43a6-aa43-1fb26f9f330a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1161092191-172.17.0.19-1597504888469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41042,DS-fbaa9c11-24d8-4a8d-8cd9-17685e8d0da6,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-2a07180c-2670-4577-90c0-60012cd042eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-bfa217e0-f3b0-412e-a189-3b3405ac309b,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-4de534d5-a9df-49ea-a255-879ae4fa2879,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-26969bb2-219c-45e4-9455-64d436a56b20,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-3fcefaa4-2533-4e38-8c2a-d6a244dcc2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-31793ecd-8707-4ef7-a1b3-b42b36cc9627,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-4d9cbe92-270d-43a6-aa43-1fb26f9f330a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-576898021-172.17.0.19-1597504959941:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43060,DS-5c52b196-d85f-4868-abe0-6ac01512e02a,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-469d0227-a026-46c4-903e-18a8cebfdb69,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-f69d0740-ea41-4978-8ecd-26725ab780ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-5c1864f2-43fc-412b-8ddd-45447c40c377,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-8acab4d8-0854-46a6-910d-8ca4e5fb308b,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-d02cb6e6-2d01-4b47-8ff3-b1a314760ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-d7f72988-df16-4fe8-a155-cd72ce510732,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-a45a71f1-4798-48f0-9788-c68d95d0d4f5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-576898021-172.17.0.19-1597504959941:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43060,DS-5c52b196-d85f-4868-abe0-6ac01512e02a,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-469d0227-a026-46c4-903e-18a8cebfdb69,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-f69d0740-ea41-4978-8ecd-26725ab780ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-5c1864f2-43fc-412b-8ddd-45447c40c377,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-8acab4d8-0854-46a6-910d-8ca4e5fb308b,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-d02cb6e6-2d01-4b47-8ff3-b1a314760ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-d7f72988-df16-4fe8-a155-cd72ce510732,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-a45a71f1-4798-48f0-9788-c68d95d0d4f5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-862936114-172.17.0.19-1597505350537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40750,DS-393eb5e8-303b-49cd-b44d-ff1bb7f2e833,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-1216bb2c-ea15-448e-86ff-1f7eb96225f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-944967a7-e55c-41e3-aba5-2d3f1d213740,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-c55fc170-30ef-4b19-8279-33cc039d8410,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-d3770b06-d123-43a3-9366-558f4299aaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-b365f1f9-1f40-447d-a97d-04796dbdee6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-9a36ee91-ecd5-4fa2-b4a3-ee5084f37981,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-767cdfd6-ef39-4113-a941-265ae93051bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-862936114-172.17.0.19-1597505350537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40750,DS-393eb5e8-303b-49cd-b44d-ff1bb7f2e833,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-1216bb2c-ea15-448e-86ff-1f7eb96225f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-944967a7-e55c-41e3-aba5-2d3f1d213740,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-c55fc170-30ef-4b19-8279-33cc039d8410,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-d3770b06-d123-43a3-9366-558f4299aaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-b365f1f9-1f40-447d-a97d-04796dbdee6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-9a36ee91-ecd5-4fa2-b4a3-ee5084f37981,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-767cdfd6-ef39-4113-a941-265ae93051bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-641618469-172.17.0.19-1597505391568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40241,DS-fa729008-b4d8-44a0-a145-f903125b7254,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-b99ba5ec-b3e4-474f-927c-81ff14b589ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-537d52e6-81b1-4956-86c3-d6d1a6254eba,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-9ba8699f-f1b5-4531-b56e-5a1c838b0405,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-2a81152d-c800-4eb1-b4c0-cca538b8af32,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-33eaabdd-d5ea-4581-be23-68b4ab880acd,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-156cfc30-6649-400b-9602-1097c9b40656,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-658ed965-4164-4533-adbd-a94085d46332,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-641618469-172.17.0.19-1597505391568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40241,DS-fa729008-b4d8-44a0-a145-f903125b7254,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-b99ba5ec-b3e4-474f-927c-81ff14b589ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-537d52e6-81b1-4956-86c3-d6d1a6254eba,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-9ba8699f-f1b5-4531-b56e-5a1c838b0405,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-2a81152d-c800-4eb1-b4c0-cca538b8af32,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-33eaabdd-d5ea-4581-be23-68b4ab880acd,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-156cfc30-6649-400b-9602-1097c9b40656,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-658ed965-4164-4533-adbd-a94085d46332,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1292310717-172.17.0.19-1597505556594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39426,DS-9a1badab-ff6f-4a60-bb0e-7016936d9635,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-e1539d87-b3ee-4fd6-8114-c7888a3038b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-866d926a-dd6f-4ed2-ac60-517f24c9c408,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-10554199-f82b-4197-b958-69568cbacf21,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-ec7cec08-327a-4787-b3b3-37e168ba22ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-2c5f2f92-e1b2-4e1b-9227-b37365c0cd96,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-8899d208-954b-4aa2-94d2-cb99b978bf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-8c00b2f6-ca1f-4856-a67d-c816fdbad3b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1292310717-172.17.0.19-1597505556594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39426,DS-9a1badab-ff6f-4a60-bb0e-7016936d9635,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-e1539d87-b3ee-4fd6-8114-c7888a3038b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-866d926a-dd6f-4ed2-ac60-517f24c9c408,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-10554199-f82b-4197-b958-69568cbacf21,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-ec7cec08-327a-4787-b3b3-37e168ba22ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-2c5f2f92-e1b2-4e1b-9227-b37365c0cd96,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-8899d208-954b-4aa2-94d2-cb99b978bf1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-8c00b2f6-ca1f-4856-a67d-c816fdbad3b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1085424723-172.17.0.19-1597505626707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34077,DS-3c131e8c-0a62-460c-86f5-9695a92d6608,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-abefe67e-7c2a-4d28-83ea-6b0af80fb65a,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-41aa7698-f5cd-40c3-8b8e-9c1428495ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-b75f8a65-19f8-4db6-adcd-57b5074f7594,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-626ea50a-6854-483a-b1e9-8966303bd9be,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-b9cebac7-67b9-466f-a813-817748a701b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-18f5ee8f-3db4-4086-a18d-b68d83442eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-f39101f5-6855-4d84-abf9-872615451459,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1085424723-172.17.0.19-1597505626707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34077,DS-3c131e8c-0a62-460c-86f5-9695a92d6608,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-abefe67e-7c2a-4d28-83ea-6b0af80fb65a,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-41aa7698-f5cd-40c3-8b8e-9c1428495ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-b75f8a65-19f8-4db6-adcd-57b5074f7594,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-626ea50a-6854-483a-b1e9-8966303bd9be,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-b9cebac7-67b9-466f-a813-817748a701b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-18f5ee8f-3db4-4086-a18d-b68d83442eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-f39101f5-6855-4d84-abf9-872615451459,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-133815608-172.17.0.19-1597505737437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46383,DS-db61c1ba-6d32-425f-92ab-a73a1463b4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-6d2ce62a-6b44-49bf-a764-ae545326409c,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-471223bd-d2e1-4f22-ab96-a16336f1c4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-978a9b9e-1f33-41a6-a6ca-7230d3858121,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-b340f455-dd54-4572-991b-ab3a6784a676,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-b8f26f09-cc8c-4245-a63a-7aff85cb2f23,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-3845776f-9fdb-479d-a049-091b9a33e5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-a32dd8d5-4fc8-4e56-9fe0-45908758ed5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-133815608-172.17.0.19-1597505737437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46383,DS-db61c1ba-6d32-425f-92ab-a73a1463b4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-6d2ce62a-6b44-49bf-a764-ae545326409c,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-471223bd-d2e1-4f22-ab96-a16336f1c4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-978a9b9e-1f33-41a6-a6ca-7230d3858121,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-b340f455-dd54-4572-991b-ab3a6784a676,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-b8f26f09-cc8c-4245-a63a-7aff85cb2f23,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-3845776f-9fdb-479d-a049-091b9a33e5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-a32dd8d5-4fc8-4e56-9fe0-45908758ed5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-610301228-172.17.0.19-1597505951300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36904,DS-fc35d0a4-d85d-43af-b25f-6e1135f24bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-64493d64-280f-4595-a409-a132aa97d240,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-796d5f5f-2bcb-4d74-910f-40f7be72a89e,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-f7bd9927-af2c-485d-a9a9-578ee805f3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-e6336d83-1331-4111-a245-d2e99fd18c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-533f5f9d-a0f0-48c6-8cd3-4e8e2105dadb,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-b3d10c11-2bdb-4044-b2ce-d812935b34a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-2c1fa87b-f1b1-4aec-abeb-bcb558c26b3d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-610301228-172.17.0.19-1597505951300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36904,DS-fc35d0a4-d85d-43af-b25f-6e1135f24bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-64493d64-280f-4595-a409-a132aa97d240,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-796d5f5f-2bcb-4d74-910f-40f7be72a89e,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-f7bd9927-af2c-485d-a9a9-578ee805f3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-e6336d83-1331-4111-a245-d2e99fd18c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-533f5f9d-a0f0-48c6-8cd3-4e8e2105dadb,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-b3d10c11-2bdb-4044-b2ce-d812935b34a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-2c1fa87b-f1b1-4aec-abeb-bcb558c26b3d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-341447437-172.17.0.19-1597506059830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42454,DS-9264d9ae-dcd1-467e-b5b2-a71102400cca,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-0d972401-0c0a-48f4-8fe5-f0268f6f6e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-4431c269-a327-441f-bfeb-3b3d0cf49525,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-761b617d-b58a-4793-ba8f-03e3879270a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-9506cc83-d947-4e6c-8def-b3641cf8ddf1,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-8ebca7ce-2035-4911-8773-ac3dbd73c918,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-9069dc54-15e3-4147-a81f-f2e7a1459274,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-48c63992-aee5-4604-a0b9-3929f5455e35,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-341447437-172.17.0.19-1597506059830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42454,DS-9264d9ae-dcd1-467e-b5b2-a71102400cca,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-0d972401-0c0a-48f4-8fe5-f0268f6f6e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-4431c269-a327-441f-bfeb-3b3d0cf49525,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-761b617d-b58a-4793-ba8f-03e3879270a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-9506cc83-d947-4e6c-8def-b3641cf8ddf1,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-8ebca7ce-2035-4911-8773-ac3dbd73c918,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-9069dc54-15e3-4147-a81f-f2e7a1459274,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-48c63992-aee5-4604-a0b9-3929f5455e35,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458264893-172.17.0.19-1597506098401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44720,DS-f00d9aeb-593d-498e-a5e3-6eca8e53dd05,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-f252e07b-b986-4c18-8e0b-66703b477619,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-1e3b9031-7c28-40ff-9607-2f34266850c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-149ff7f8-230e-4ad1-a9ea-72625149d6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-eb904ecc-c1dc-421e-b74d-59957c21c3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-4b9a42f5-dc6c-47ec-82fd-3f34a8ea2e77,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-e9cf4ac9-d39b-40f0-8962-a8fa671adbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-b9a15286-76a1-44a2-b5d2-fe95407aa3e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458264893-172.17.0.19-1597506098401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44720,DS-f00d9aeb-593d-498e-a5e3-6eca8e53dd05,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-f252e07b-b986-4c18-8e0b-66703b477619,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-1e3b9031-7c28-40ff-9607-2f34266850c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-149ff7f8-230e-4ad1-a9ea-72625149d6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-eb904ecc-c1dc-421e-b74d-59957c21c3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-4b9a42f5-dc6c-47ec-82fd-3f34a8ea2e77,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-e9cf4ac9-d39b-40f0-8962-a8fa671adbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-b9a15286-76a1-44a2-b5d2-fe95407aa3e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1200996730-172.17.0.19-1597506134041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44143,DS-e87c928c-84e2-4889-891f-0e69bcd45f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-1d23fbf1-5e0e-40a0-885d-caca983a8e94,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-c022b30d-fccb-45ec-a13e-e1468b5f75e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-20739f6d-bedf-47d2-8493-15871936a917,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-9e5b2621-a2af-48ee-924f-cede53cb2392,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-993915c0-b192-445d-9cbe-a4a8db604cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-a3869eda-cd93-4168-8ab4-70cfa4d4159f,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-fab6de3e-1915-4e5f-b770-3c7696e507dc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1200996730-172.17.0.19-1597506134041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44143,DS-e87c928c-84e2-4889-891f-0e69bcd45f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-1d23fbf1-5e0e-40a0-885d-caca983a8e94,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-c022b30d-fccb-45ec-a13e-e1468b5f75e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-20739f6d-bedf-47d2-8493-15871936a917,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-9e5b2621-a2af-48ee-924f-cede53cb2392,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-993915c0-b192-445d-9cbe-a4a8db604cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-a3869eda-cd93-4168-8ab4-70cfa4d4159f,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-fab6de3e-1915-4e5f-b770-3c7696e507dc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 20 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: might be true error
Total execution time in seconds : 5555
