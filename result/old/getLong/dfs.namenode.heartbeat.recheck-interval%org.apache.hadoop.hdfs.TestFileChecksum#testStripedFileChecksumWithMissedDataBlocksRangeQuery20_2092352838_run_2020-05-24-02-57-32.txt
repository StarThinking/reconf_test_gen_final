reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: NameNode
v1: 300000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
fail. do 5 v1v1 v2v2 tests to filter false alarm
failed v1v2 test: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20 v1 300000 v2 3

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v1 and v2v2 succeed for 5 times, it is issue
---------------------------------------full report---------------------------------------------
reconf_parameter: dfs.namenode.heartbeat.recheck-interval
component: NameNode
v1: 300000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-939230342-172.17.0.11-1590289066409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38721,DS-eca53782-1dd3-411e-8441-e0df3ed7a5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-fab59468-5eb0-40e3-baeb-8a6089ff0574,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-8ce752ad-6b30-4ec0-9cd9-a43b90eb7492,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-26e964c9-cfa5-49f9-bc91-16ea806ae286,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-c79c0a6e-858a-4ea1-9af7-66eb9cfea720,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-3da37b95-5a39-4e25-8d26-70490a1de4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-6603a73d-cbb6-4006-8b49-2ef92e84a97d,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-58ba04e2-9634-4fc9-ba85-4e8f5f04cdb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-939230342-172.17.0.11-1590289066409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38721,DS-eca53782-1dd3-411e-8441-e0df3ed7a5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-fab59468-5eb0-40e3-baeb-8a6089ff0574,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-8ce752ad-6b30-4ec0-9cd9-a43b90eb7492,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-26e964c9-cfa5-49f9-bc91-16ea806ae286,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-c79c0a6e-858a-4ea1-9af7-66eb9cfea720,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-3da37b95-5a39-4e25-8d26-70490a1de4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-6603a73d-cbb6-4006-8b49-2ef92e84a97d,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-58ba04e2-9634-4fc9-ba85-4e8f5f04cdb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


Total execution time in seconds : 413
1
