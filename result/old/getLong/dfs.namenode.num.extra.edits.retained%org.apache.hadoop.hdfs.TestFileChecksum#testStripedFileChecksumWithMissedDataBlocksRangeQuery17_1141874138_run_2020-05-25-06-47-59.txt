reconf_parameter: dfs.namenode.num.extra.edits.retained
component: NameNode
v1: 1000000
v2: 100000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
fail. do 5 v1v1 v2v2 tests to filter false alarm
failed v1v2 test: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17 v1 1000000 v2 100000000

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v1 and v2v2 succeed for 5 times, it is issue
---------------------------------------full report---------------------------------------------
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: NameNode
v1: 1000000
v2: 100000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-570586808-172.17.0.17-1590389296433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36300,DS-af15a66f-d2ae-468e-85c1-34f7ace52718,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-c2e915e4-4389-47ac-adef-88ea2b9f098b,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-71003168-7fb5-4aa9-bee3-ca5a6f0b2066,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-935e68bd-c952-429a-8931-53b7efd9c7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-db359007-cec7-4808-babb-b5857b4fdcf8,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-d6c58c47-0c48-4151-a29e-ac333d5fd9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-3aef2aa1-6fad-441b-8191-7651ebebc306,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-097c0280-d202-4f71-98ec-982a74deb366,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-570586808-172.17.0.17-1590389296433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36300,DS-af15a66f-d2ae-468e-85c1-34f7ace52718,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-c2e915e4-4389-47ac-adef-88ea2b9f098b,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-71003168-7fb5-4aa9-bee3-ca5a6f0b2066,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-935e68bd-c952-429a-8931-53b7efd9c7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-db359007-cec7-4808-babb-b5857b4fdcf8,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-d6c58c47-0c48-4151-a29e-ac333d5fd9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-3aef2aa1-6fad-441b-8191-7651ebebc306,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-097c0280-d202-4f71-98ec-982a74deb366,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


Total execution time in seconds : 390
1
