reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: DataNode
v1: 1048576
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: DataNode
v1: 1048576
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1865727005-172.17.0.21-1590297716624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43634,DS-dd1b6d72-1910-4ef2-afd6-ea071f3d0283,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-dce40490-649f-4abc-83e3-cf644f80f629,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-9edbebcf-0922-4c56-a133-d30d6496da42,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-78c6d22c-0a19-4a9c-b9e5-5c17298fed69,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-83d5d2ab-ca96-49b9-bb95-704a6ca36d55,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-00ff1b2c-b1dd-402b-afe5-506f49b80183,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-52249944-62cb-48fa-a796-32d7459cdd40,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-b0fd7730-4939-4285-82c5-524d74353034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1865727005-172.17.0.21-1590297716624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43634,DS-dd1b6d72-1910-4ef2-afd6-ea071f3d0283,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-dce40490-649f-4abc-83e3-cf644f80f629,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-9edbebcf-0922-4c56-a133-d30d6496da42,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-78c6d22c-0a19-4a9c-b9e5-5c17298fed69,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-83d5d2ab-ca96-49b9-bb95-704a6ca36d55,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-00ff1b2c-b1dd-402b-afe5-506f49b80183,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-52249944-62cb-48fa-a796-32d7459cdd40,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-b0fd7730-4939-4285-82c5-524d74353034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: DataNode
v1: 1048576
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1212080755-172.17.0.21-1590297796567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39612,DS-230530ae-42c8-45d7-962e-bf839b5963af,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-fb2ffdd9-5597-4c07-934a-e185a331ee42,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-ff1c1efc-ab0d-4094-88c3-bb8d670e8e69,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-770b11f5-ad4d-4ed4-9a0b-6ffc843e0d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-aa0faf51-35de-4cd8-b25f-3ea00a173714,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-153a83a1-641b-4749-b698-7589e2f87d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-8ce7f55f-3671-4e66-bad1-1f67c638b0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-407a7023-a6ff-44b9-8749-c5769b1f943c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1212080755-172.17.0.21-1590297796567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39612,DS-230530ae-42c8-45d7-962e-bf839b5963af,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-fb2ffdd9-5597-4c07-934a-e185a331ee42,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-ff1c1efc-ab0d-4094-88c3-bb8d670e8e69,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-770b11f5-ad4d-4ed4-9a0b-6ffc843e0d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-aa0faf51-35de-4cd8-b25f-3ea00a173714,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-153a83a1-641b-4749-b698-7589e2f87d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-8ce7f55f-3671-4e66-bad1-1f67c638b0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-407a7023-a6ff-44b9-8749-c5769b1f943c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: DataNode
v1: 1048576
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1999659230-172.17.0.21-1590298116896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36839,DS-9dd6c419-133a-4fa6-a25c-a9122d62c882,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-0ac1099b-4914-4afa-b8e4-8b56ed04568a,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-2e2cf21b-97e1-4721-937d-db5c1c60d8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-a95da7df-bb8a-44b5-9a99-a143f52cad33,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-28518b04-db88-4030-9df5-40a3083b3052,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-7a2fbddd-96e0-429c-aa05-b12c584af655,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-b0468180-2f73-4518-90ba-d3dcdfd0015b,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-7403208a-fd81-4a19-93cd-a787eff7b94c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1999659230-172.17.0.21-1590298116896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36839,DS-9dd6c419-133a-4fa6-a25c-a9122d62c882,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-0ac1099b-4914-4afa-b8e4-8b56ed04568a,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-2e2cf21b-97e1-4721-937d-db5c1c60d8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-a95da7df-bb8a-44b5-9a99-a143f52cad33,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-28518b04-db88-4030-9df5-40a3083b3052,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-7a2fbddd-96e0-429c-aa05-b12c584af655,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-b0468180-2f73-4518-90ba-d3dcdfd0015b,DISK], DatanodeInfoWithStorage[127.0.0.1:39809,DS-7403208a-fd81-4a19-93cd-a787eff7b94c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: DataNode
v1: 1048576
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2141528936-172.17.0.21-1590298416680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46427,DS-a258ef5d-0425-4067-b126-5f300732eae3,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-56cdaa15-653f-43fb-a807-927c1c2c2c22,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-533baae5-a688-436d-ab14-7858f6e6493f,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-6b10ef48-b163-45a8-8388-868f7866610d,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-ca6ab7f4-41b2-473e-9598-ea6650e8cba7,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-e46987fa-2d31-4cf2-8c15-7d56586c885e,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-045fc709-46de-4409-a7a9-9f023a460e57,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-1355c588-ffee-4205-9574-92694628711f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2141528936-172.17.0.21-1590298416680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46427,DS-a258ef5d-0425-4067-b126-5f300732eae3,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-56cdaa15-653f-43fb-a807-927c1c2c2c22,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-533baae5-a688-436d-ab14-7858f6e6493f,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-6b10ef48-b163-45a8-8388-868f7866610d,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-ca6ab7f4-41b2-473e-9598-ea6650e8cba7,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-e46987fa-2d31-4cf2-8c15-7d56586c885e,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-045fc709-46de-4409-a7a9-9f023a460e57,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-1355c588-ffee-4205-9574-92694628711f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: DataNode
v1: 1048576
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1758600648-172.17.0.21-1590298684615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42091,DS-97ab00cf-94b3-4a77-9e80-a56ebba94422,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-718fc7c3-dc35-4823-898a-f62d5832e7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-3474743e-5d36-4720-bdc2-aa098377b7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-bd54baf1-53ff-458e-8a93-4f8e6107998c,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-548a83ad-7bd7-4bb9-873d-dabcf0f99dca,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-97bda6fa-cc58-4512-8dea-ed8343e00bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-932ed8de-10ae-4a0d-ad4f-5e0e1aac5022,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-64b26c66-47af-4ea4-bfb2-275dc45908a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1758600648-172.17.0.21-1590298684615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42091,DS-97ab00cf-94b3-4a77-9e80-a56ebba94422,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-718fc7c3-dc35-4823-898a-f62d5832e7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-3474743e-5d36-4720-bdc2-aa098377b7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-bd54baf1-53ff-458e-8a93-4f8e6107998c,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-548a83ad-7bd7-4bb9-873d-dabcf0f99dca,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-97bda6fa-cc58-4512-8dea-ed8343e00bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-932ed8de-10ae-4a0d-ad4f-5e0e1aac5022,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-64b26c66-47af-4ea4-bfb2-275dc45908a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: DataNode
v1: 1048576
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-147253415-172.17.0.21-1590298724637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45839,DS-6a5fd530-94e5-4243-9038-792b685ce7af,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-526e7cd2-a539-4d9a-978b-71d1eed29fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-578c2154-96f3-41a4-b89d-6114e9918e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-65171e80-5610-4408-a2aa-659aa11cfe94,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-4ba6bdb3-ec29-4748-bb2d-b9cd9db645a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-16a84fd3-f757-4907-a79b-b80c81c874bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-f0c65681-52f3-4e13-9872-f4dd52b13e89,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-8510548e-a897-40b6-9979-e314b34ce806,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-147253415-172.17.0.21-1590298724637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45839,DS-6a5fd530-94e5-4243-9038-792b685ce7af,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-526e7cd2-a539-4d9a-978b-71d1eed29fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-578c2154-96f3-41a4-b89d-6114e9918e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-65171e80-5610-4408-a2aa-659aa11cfe94,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-4ba6bdb3-ec29-4748-bb2d-b9cd9db645a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-16a84fd3-f757-4907-a79b-b80c81c874bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-f0c65681-52f3-4e13-9872-f4dd52b13e89,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-8510548e-a897-40b6-9979-e314b34ce806,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: DataNode
v1: 1048576
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1140845416-172.17.0.21-1590298760595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38020,DS-e6640e21-7ed8-40ef-8cc7-1ebec76a3d34,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-a56fc9da-1aa3-47e6-862e-7e7e4539ed15,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-040a1f8b-140e-4a8d-843b-357fe19cb0de,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-d5fe60f1-e6d0-4c1b-9ec3-a6eaf01eecec,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-0e333599-7d1a-4df9-8134-8d598abf2483,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-92279a63-d9fc-4bdd-b481-bb1683a4177f,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-07d0747b-9581-41ca-9ffd-5236a36c0d85,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-8ab36eb4-da6b-4320-b4f3-b2fd623d2492,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1140845416-172.17.0.21-1590298760595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38020,DS-e6640e21-7ed8-40ef-8cc7-1ebec76a3d34,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-a56fc9da-1aa3-47e6-862e-7e7e4539ed15,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-040a1f8b-140e-4a8d-843b-357fe19cb0de,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-d5fe60f1-e6d0-4c1b-9ec3-a6eaf01eecec,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-0e333599-7d1a-4df9-8134-8d598abf2483,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-92279a63-d9fc-4bdd-b481-bb1683a4177f,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-07d0747b-9581-41ca-9ffd-5236a36c0d85,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-8ab36eb4-da6b-4320-b4f3-b2fd623d2492,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: DataNode
v1: 1048576
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-288297918-172.17.0.21-1590299097990:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44950,DS-e9e1ae06-aee6-4be3-8e3c-71fdcd3a59a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-9930cbcd-1b32-4d66-8a84-8562f667d391,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-19e8b6f8-23f2-4aba-91a9-d1c9436b09d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-e526814e-1363-46a0-bb21-bad9c41c7fae,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-292aa060-a813-4391-919b-27d158c4d947,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-337718d9-42a4-4d5f-8fe6-3078b8e95112,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-0ae40760-d704-4b7f-99a4-41e64c25e209,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-2ad6ddd2-eb99-4f3b-8960-b827d6353ffc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-288297918-172.17.0.21-1590299097990:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44950,DS-e9e1ae06-aee6-4be3-8e3c-71fdcd3a59a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-9930cbcd-1b32-4d66-8a84-8562f667d391,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-19e8b6f8-23f2-4aba-91a9-d1c9436b09d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-e526814e-1363-46a0-bb21-bad9c41c7fae,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-292aa060-a813-4391-919b-27d158c4d947,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-337718d9-42a4-4d5f-8fe6-3078b8e95112,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-0ae40760-d704-4b7f-99a4-41e64c25e209,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-2ad6ddd2-eb99-4f3b-8960-b827d6353ffc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: DataNode
v1: 1048576
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1523462665-172.17.0.21-1590299819469:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46532,DS-a1a2e2e3-2a2f-4054-a189-95fddf8f1c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-8966fa9b-f5ed-427e-a1e0-b5b70d9995a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-5114ace3-ff2b-40b4-82bd-80907de53b01,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-02252eb4-6b6d-498c-ae80-3487f1745df5,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-5db76a48-7e6d-450f-b78d-45c79980b453,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-4014d37e-6764-4d94-ab85-c8f6410d4dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-b0bfb185-58f2-442c-a3be-5d6d185ed0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34491,DS-f151452b-c1de-4097-9041-41f7892e0488,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1523462665-172.17.0.21-1590299819469:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46532,DS-a1a2e2e3-2a2f-4054-a189-95fddf8f1c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-8966fa9b-f5ed-427e-a1e0-b5b70d9995a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-5114ace3-ff2b-40b4-82bd-80907de53b01,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-02252eb4-6b6d-498c-ae80-3487f1745df5,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-5db76a48-7e6d-450f-b78d-45c79980b453,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-4014d37e-6764-4d94-ab85-c8f6410d4dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-b0bfb185-58f2-442c-a3be-5d6d185ed0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34491,DS-f151452b-c1de-4097-9041-41f7892e0488,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: DataNode
v1: 1048576
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-537854859-172.17.0.21-1590300517527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38153,DS-e28884df-41e2-4216-b5b5-1a2f4002371e,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-a419ed60-1489-48c9-ba76-e08a0dca39f5,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-8b2cd931-d0d9-4de0-a0e7-64d7f64699ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-a36ed714-f83e-481b-a1b6-4384f462dda1,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-f04fd12f-033e-4468-a032-ee9a6adfb05b,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-84982ac1-42ed-48f5-963d-b89e70672329,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-91e5109b-bf97-43a1-ae77-cf609ee673c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-ab28a16b-0781-4323-b105-1520cad02cf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-537854859-172.17.0.21-1590300517527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38153,DS-e28884df-41e2-4216-b5b5-1a2f4002371e,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-a419ed60-1489-48c9-ba76-e08a0dca39f5,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-8b2cd931-d0d9-4de0-a0e7-64d7f64699ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-a36ed714-f83e-481b-a1b6-4384f462dda1,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-f04fd12f-033e-4468-a032-ee9a6adfb05b,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-84982ac1-42ed-48f5-963d-b89e70672329,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-91e5109b-bf97-43a1-ae77-cf609ee673c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-ab28a16b-0781-4323-b105-1520cad02cf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: DataNode
v1: 1048576
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-817538103-172.17.0.21-1590301574522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36470,DS-a19c1d96-5308-4a03-8c7e-1a260b826270,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-2883b9d3-c006-4026-b493-26acacc0ac6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45831,DS-6d90156d-b252-4b8f-9e0b-271642106849,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-5375c778-0edc-4fb0-939b-bcce918c5aff,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-c06373da-1b9f-4c46-860a-56fe35e925bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-da5bfb85-3539-423b-a97f-8fcae1b4c4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-821a7ebe-49ba-49be-9d04-13467a30e8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41905,DS-7c14e811-ca55-4973-9c89-1c76c74eed27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-817538103-172.17.0.21-1590301574522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36470,DS-a19c1d96-5308-4a03-8c7e-1a260b826270,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-2883b9d3-c006-4026-b493-26acacc0ac6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45831,DS-6d90156d-b252-4b8f-9e0b-271642106849,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-5375c778-0edc-4fb0-939b-bcce918c5aff,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-c06373da-1b9f-4c46-860a-56fe35e925bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-da5bfb85-3539-423b-a97f-8fcae1b4c4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-821a7ebe-49ba-49be-9d04-13467a30e8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41905,DS-7c14e811-ca55-4973-9c89-1c76c74eed27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: DataNode
v1: 1048576
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1258297110-172.17.0.21-1590302318384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46747,DS-21abd702-059e-48c0-8e0a-89126feec6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-b975121f-7967-4c28-a4c4-d5ffe0da1a20,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-adb57605-84b7-45c8-b7c0-64321ace2781,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-60257dae-41f2-4d1e-a903-1dec4cf30b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-eeead0e1-90ac-4671-90d5-3f1151c5f6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-292e0f10-e1dc-43a4-b96b-a498fd32ecee,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-d6dd8535-68cb-4191-a13b-7b65850a55ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-a755a7b7-7a9d-4973-8ca7-d9452fe3df65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1258297110-172.17.0.21-1590302318384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46747,DS-21abd702-059e-48c0-8e0a-89126feec6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-b975121f-7967-4c28-a4c4-d5ffe0da1a20,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-adb57605-84b7-45c8-b7c0-64321ace2781,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-60257dae-41f2-4d1e-a903-1dec4cf30b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-eeead0e1-90ac-4671-90d5-3f1151c5f6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-292e0f10-e1dc-43a4-b96b-a498fd32ecee,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-d6dd8535-68cb-4191-a13b-7b65850a55ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-a755a7b7-7a9d-4973-8ca7-d9452fe3df65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: DataNode
v1: 1048576
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1772052916-172.17.0.21-1590302434812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35060,DS-53466795-f048-4a6a-a3bf-1766be4c1781,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-af8daffd-0dec-483d-af4b-aa67d228516d,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-db9c7307-fec9-4a36-957d-f7d283324045,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-edbc2e67-a876-4b9a-a247-c1b5a8f7f676,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-be07082b-458e-4698-b679-4b8b76320a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-26e5438a-1fa4-4445-9bbe-8b7d6009ab6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-57db7485-e3aa-46f8-9b2e-f9c2b911abe4,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-99361e10-2f3d-4884-ae54-f249e1b8f738,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1772052916-172.17.0.21-1590302434812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35060,DS-53466795-f048-4a6a-a3bf-1766be4c1781,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-af8daffd-0dec-483d-af4b-aa67d228516d,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-db9c7307-fec9-4a36-957d-f7d283324045,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-edbc2e67-a876-4b9a-a247-c1b5a8f7f676,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-be07082b-458e-4698-b679-4b8b76320a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-26e5438a-1fa4-4445-9bbe-8b7d6009ab6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-57db7485-e3aa-46f8-9b2e-f9c2b911abe4,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-99361e10-2f3d-4884-ae54-f249e1b8f738,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: DataNode
v1: 1048576
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-335643322-172.17.0.21-1590302535888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37089,DS-04561e9c-5e6f-4ffb-b692-c3484ffdeb7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-86da561e-e423-4071-a2b2-6919ee23a722,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-70a88318-b07f-4a0d-88c7-d4ba771e28d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-92e4a6fa-e1cc-43b4-adf1-4e48718f4ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-6b43ca3b-1e0d-45ea-8749-41d354b1c12a,DISK], DatanodeInfoWithStorage[127.0.0.1:46235,DS-d87d6665-eb60-4504-bd80-4fe87d182d30,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-0dfd45e3-d7cd-4c37-ba6c-7dc3f4d18b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-abcb2518-cd6f-46fe-b36e-2fa63e61b6b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-335643322-172.17.0.21-1590302535888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37089,DS-04561e9c-5e6f-4ffb-b692-c3484ffdeb7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-86da561e-e423-4071-a2b2-6919ee23a722,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-70a88318-b07f-4a0d-88c7-d4ba771e28d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-92e4a6fa-e1cc-43b4-adf1-4e48718f4ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-6b43ca3b-1e0d-45ea-8749-41d354b1c12a,DISK], DatanodeInfoWithStorage[127.0.0.1:46235,DS-d87d6665-eb60-4504-bd80-4fe87d182d30,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-0dfd45e3-d7cd-4c37-ba6c-7dc3f4d18b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-abcb2518-cd6f-46fe-b36e-2fa63e61b6b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 5481
