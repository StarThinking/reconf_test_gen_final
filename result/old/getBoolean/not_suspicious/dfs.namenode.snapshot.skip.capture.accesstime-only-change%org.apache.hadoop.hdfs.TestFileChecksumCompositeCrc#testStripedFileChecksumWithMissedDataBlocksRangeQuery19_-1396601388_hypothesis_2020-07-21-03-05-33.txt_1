reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-631695089-172.17.0.6-1595301225830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37048,DS-984bf094-1c8f-4e0b-9f10-fe551234a9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-09d4ace6-ad29-445c-bb08-7e9338e7f6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-ebc5eade-cf86-4bcf-a7b5-68761a486319,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-9ae918e1-5db2-4ad7-8930-3853cb8082d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-ceb9612b-8fe5-4d65-b13e-f1ca32e8ebde,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-a5a9262b-0543-4277-8118-bb598256318a,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-15e9091e-4c11-41dd-8374-fe202da5b812,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-9ac454e4-b7cb-440e-861e-82fec99debd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-631695089-172.17.0.6-1595301225830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37048,DS-984bf094-1c8f-4e0b-9f10-fe551234a9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-09d4ace6-ad29-445c-bb08-7e9338e7f6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-ebc5eade-cf86-4bcf-a7b5-68761a486319,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-9ae918e1-5db2-4ad7-8930-3853cb8082d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-ceb9612b-8fe5-4d65-b13e-f1ca32e8ebde,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-a5a9262b-0543-4277-8118-bb598256318a,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-15e9091e-4c11-41dd-8374-fe202da5b812,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-9ac454e4-b7cb-440e-861e-82fec99debd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-287805274-172.17.0.6-1595301360538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38216,DS-14c11f78-8630-4481-a3d2-f92d4e97a422,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-1f656f8e-a416-4181-96ec-3df1f107ea37,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-acd78170-ce03-4156-b527-b88bf8acb8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-6a89d99b-21be-4012-a1fa-bcd9eb5afc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-bbf66235-5548-45d5-8b0e-4b7a7dd96e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-66b8d03e-1360-46e9-a898-91c295403d33,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-a74e6c02-4654-4e65-8152-82950c12b04e,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-19be20e1-ddf1-4edf-9ed3-e9185b587991,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-287805274-172.17.0.6-1595301360538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38216,DS-14c11f78-8630-4481-a3d2-f92d4e97a422,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-1f656f8e-a416-4181-96ec-3df1f107ea37,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-acd78170-ce03-4156-b527-b88bf8acb8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-6a89d99b-21be-4012-a1fa-bcd9eb5afc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-bbf66235-5548-45d5-8b0e-4b7a7dd96e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-66b8d03e-1360-46e9-a898-91c295403d33,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-a74e6c02-4654-4e65-8152-82950c12b04e,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-19be20e1-ddf1-4edf-9ed3-e9185b587991,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-146044478-172.17.0.6-1595301476051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45070,DS-53d6f241-c4cc-41ff-b9fc-a1eb4f01d2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-d5c90a1b-287f-402c-8274-d622da132854,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-f72a1c35-449a-4190-8172-82151305fb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35877,DS-afee4728-1815-4b91-b812-1fe1323a7389,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-c753b8ce-9f0d-45af-8fdb-d81caa4c37f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-d0586174-daef-4e2a-a7cb-7776072fa242,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-610708ca-7d08-41b2-8583-8974bbe6e14a,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-99aecc39-bf79-4ef4-b035-19608cb1e0da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-146044478-172.17.0.6-1595301476051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45070,DS-53d6f241-c4cc-41ff-b9fc-a1eb4f01d2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-d5c90a1b-287f-402c-8274-d622da132854,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-f72a1c35-449a-4190-8172-82151305fb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35877,DS-afee4728-1815-4b91-b812-1fe1323a7389,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-c753b8ce-9f0d-45af-8fdb-d81caa4c37f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-d0586174-daef-4e2a-a7cb-7776072fa242,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-610708ca-7d08-41b2-8583-8974bbe6e14a,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-99aecc39-bf79-4ef4-b035-19608cb1e0da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1272075891-172.17.0.6-1595302516314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37310,DS-7d50852f-e11f-4da1-82bd-a82578fe0d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-6a6a59ae-da99-4771-8e55-41c48b8e4bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-82d4264c-9e99-40a3-a3b9-7a54b8ed9d47,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-1e7f86a0-9b45-4f8d-b1f6-004408381352,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-ea838bd5-a19c-4aa8-8a51-f3e373a2c02c,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-0fc5e5d1-55ae-4309-b41b-e0a665140540,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-8d3b19d9-58fa-4db0-bb84-a1ccd6630924,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-38225ba2-1bab-45b3-88fa-27943be24f8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1272075891-172.17.0.6-1595302516314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37310,DS-7d50852f-e11f-4da1-82bd-a82578fe0d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-6a6a59ae-da99-4771-8e55-41c48b8e4bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-82d4264c-9e99-40a3-a3b9-7a54b8ed9d47,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-1e7f86a0-9b45-4f8d-b1f6-004408381352,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-ea838bd5-a19c-4aa8-8a51-f3e373a2c02c,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-0fc5e5d1-55ae-4309-b41b-e0a665140540,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-8d3b19d9-58fa-4db0-bb84-a1ccd6630924,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-38225ba2-1bab-45b3-88fa-27943be24f8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-931657192-172.17.0.6-1595302612918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39187,DS-5e0a68b5-a85c-4f1a-95ee-27bc758e8f00,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-7077ee04-792b-43f6-bcff-de0da909d351,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-62d1653d-fea3-49a3-b259-ac04ef3c3ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-ffbb0b27-c507-40d9-9e15-8ef5871f9e70,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-c8bc9d6f-f53e-4dfd-940a-5e5ded88f672,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-6e4cfe74-f836-4073-b01e-ebf9a13f3afa,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-7876e97d-563e-429a-9402-3a939ccf017e,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-5c6f38ba-2b38-4af9-a95c-d8935e3eed22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-931657192-172.17.0.6-1595302612918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39187,DS-5e0a68b5-a85c-4f1a-95ee-27bc758e8f00,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-7077ee04-792b-43f6-bcff-de0da909d351,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-62d1653d-fea3-49a3-b259-ac04ef3c3ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-ffbb0b27-c507-40d9-9e15-8ef5871f9e70,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-c8bc9d6f-f53e-4dfd-940a-5e5ded88f672,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-6e4cfe74-f836-4073-b01e-ebf9a13f3afa,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-7876e97d-563e-429a-9402-3a939ccf017e,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-5c6f38ba-2b38-4af9-a95c-d8935e3eed22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-448952324-172.17.0.6-1595302940212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33985,DS-56cb3095-e25d-48ee-b4ac-eb3d89f62cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-0f889290-b01a-4aec-96c8-6133f1cdadbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-6b070bd9-29c9-4b0c-8c56-f8151523e868,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-028eda65-b57b-452d-adfe-40ccdd96f09a,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-992ecf8d-f5bd-483e-8ef0-7357f78f20c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-d1921004-1e19-4600-b5d9-f156525d648a,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-f02b2b35-3e18-429a-b9be-ca30d192c301,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-06994532-9f02-4003-b568-4e56156f9322,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-448952324-172.17.0.6-1595302940212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33985,DS-56cb3095-e25d-48ee-b4ac-eb3d89f62cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-0f889290-b01a-4aec-96c8-6133f1cdadbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-6b070bd9-29c9-4b0c-8c56-f8151523e868,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-028eda65-b57b-452d-adfe-40ccdd96f09a,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-992ecf8d-f5bd-483e-8ef0-7357f78f20c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-d1921004-1e19-4600-b5d9-f156525d648a,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-f02b2b35-3e18-429a-b9be-ca30d192c301,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-06994532-9f02-4003-b568-4e56156f9322,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1398464836-172.17.0.6-1595303108812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34031,DS-34e198f0-b2a4-4775-b280-1c81481fa374,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-b64c798d-1cf7-489a-9f9f-59394b365f14,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-0e883bb9-f48a-49c8-bc48-0e61f88737bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-2ce1e7b3-e977-4218-90a4-014bbcf5c33c,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-5fa06a32-7e45-471a-8e87-8e2a0b0c3d20,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-d01aef33-9ae6-4ff8-8d5d-34c40343c315,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-22cec1ee-cc1e-4b7e-a001-584f89c6141a,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-f0e4b374-6289-42fd-bb40-750abe587f51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1398464836-172.17.0.6-1595303108812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34031,DS-34e198f0-b2a4-4775-b280-1c81481fa374,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-b64c798d-1cf7-489a-9f9f-59394b365f14,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-0e883bb9-f48a-49c8-bc48-0e61f88737bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-2ce1e7b3-e977-4218-90a4-014bbcf5c33c,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-5fa06a32-7e45-471a-8e87-8e2a0b0c3d20,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-d01aef33-9ae6-4ff8-8d5d-34c40343c315,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-22cec1ee-cc1e-4b7e-a001-584f89c6141a,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-f0e4b374-6289-42fd-bb40-750abe587f51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-136033490-172.17.0.6-1595303402733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36032,DS-e9851f76-e82a-488b-97d4-639912ce6be9,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-120c7e83-4b53-47f8-abea-e09c7c444035,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-58778778-29db-42b6-b2dd-81c93d8414b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-df5f97aa-48aa-4975-bb25-1f65d9b4f0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-b722e1fe-0776-4bd7-b22e-d4959e1bec2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-5d5e48de-f311-4a33-8345-fc9f56270313,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-42b78564-2ae6-48b1-8ebc-c611dbf2b2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-6623699e-c896-4c81-98ca-97843155fe92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-136033490-172.17.0.6-1595303402733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36032,DS-e9851f76-e82a-488b-97d4-639912ce6be9,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-120c7e83-4b53-47f8-abea-e09c7c444035,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-58778778-29db-42b6-b2dd-81c93d8414b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-df5f97aa-48aa-4975-bb25-1f65d9b4f0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-b722e1fe-0776-4bd7-b22e-d4959e1bec2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-5d5e48de-f311-4a33-8345-fc9f56270313,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-42b78564-2ae6-48b1-8ebc-c611dbf2b2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-6623699e-c896-4c81-98ca-97843155fe92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1372577614-172.17.0.6-1595303506436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43636,DS-bbf56954-90a1-4a9f-9194-a5e942fe60d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-117c0267-f862-4d74-91a7-c186721819bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-00a854af-134f-4d25-b57b-e96fd8e7e293,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-815c5065-8cf7-4fed-b3a3-209d4f9d0f88,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-b5c1d790-27b1-4ec5-864e-7aded1ee68b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-1312ef46-5c62-45c9-a3f8-d99522660e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-bc9cb125-e0d2-4a80-9fb9-000bc3de93eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-ce4df8fb-129b-4da6-81fb-9a1da85e91d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1372577614-172.17.0.6-1595303506436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43636,DS-bbf56954-90a1-4a9f-9194-a5e942fe60d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-117c0267-f862-4d74-91a7-c186721819bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-00a854af-134f-4d25-b57b-e96fd8e7e293,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-815c5065-8cf7-4fed-b3a3-209d4f9d0f88,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-b5c1d790-27b1-4ec5-864e-7aded1ee68b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-1312ef46-5c62-45c9-a3f8-d99522660e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-bc9cb125-e0d2-4a80-9fb9-000bc3de93eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-ce4df8fb-129b-4da6-81fb-9a1da85e91d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-931412418-172.17.0.6-1595303658792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38521,DS-29aa173b-86f8-4358-b93f-7276586e302a,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-0e5f82e7-ae03-46be-bbb4-0a3142b92b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-9c188bb7-ff3f-4188-bcfc-6001d22ed778,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-6ed0c81a-a6c9-46f8-8954-13a8d99a8922,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-855425bc-36d6-4281-a460-9ec810a5507d,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-5fb37d9e-03a0-411b-ae8a-d72c6e08b34e,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-be92db54-220a-4a76-a015-1367d0df414c,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-c073b028-8614-41b7-b5a7-6cd906952ef5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-931412418-172.17.0.6-1595303658792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38521,DS-29aa173b-86f8-4358-b93f-7276586e302a,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-0e5f82e7-ae03-46be-bbb4-0a3142b92b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-9c188bb7-ff3f-4188-bcfc-6001d22ed778,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-6ed0c81a-a6c9-46f8-8954-13a8d99a8922,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-855425bc-36d6-4281-a460-9ec810a5507d,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-5fb37d9e-03a0-411b-ae8a-d72c6e08b34e,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-be92db54-220a-4a76-a015-1367d0df414c,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-c073b028-8614-41b7-b5a7-6cd906952ef5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-836326552-172.17.0.6-1595304263865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44298,DS-d8e2a4a9-0491-4986-ba57-0a5ecffac640,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-f27e2151-294b-4688-bb46-e50f28f6b6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-3d7818a6-b65c-4bb1-a0cc-80985b2cf5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-ce3601f6-5695-4806-a18b-2908d140a724,DISK], DatanodeInfoWithStorage[127.0.0.1:39174,DS-7ba0a604-0547-4e3c-b420-1f9e1ba424b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-3730299e-ef47-46f0-86c7-5c55c6dfacb0,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-62d3c91b-8c81-4b19-85ca-b59abe1e8b03,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-cffb9b88-1fe7-463a-ac77-ec21789cb05d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-836326552-172.17.0.6-1595304263865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44298,DS-d8e2a4a9-0491-4986-ba57-0a5ecffac640,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-f27e2151-294b-4688-bb46-e50f28f6b6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-3d7818a6-b65c-4bb1-a0cc-80985b2cf5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-ce3601f6-5695-4806-a18b-2908d140a724,DISK], DatanodeInfoWithStorage[127.0.0.1:39174,DS-7ba0a604-0547-4e3c-b420-1f9e1ba424b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-3730299e-ef47-46f0-86c7-5c55c6dfacb0,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-62d3c91b-8c81-4b19-85ca-b59abe1e8b03,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-cffb9b88-1fe7-463a-ac77-ec21789cb05d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1213154068-172.17.0.6-1595304646085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36160,DS-a444c661-e8bf-4c65-8aef-983218fc6f34,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-3f97ac84-5d40-4b56-870d-929233a46ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-bdabb7ee-6e85-4cd3-a80c-83c334610ade,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-de457230-f13b-465e-8eda-bf5234bf5178,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-afabfb0c-abaf-432d-83d7-0fe050e14b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-137f7135-62c1-481e-a24a-fcec3860310d,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-df185039-081d-471b-acda-cc86a6782f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-758561da-22fa-4e37-9e47-759a267976cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1213154068-172.17.0.6-1595304646085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36160,DS-a444c661-e8bf-4c65-8aef-983218fc6f34,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-3f97ac84-5d40-4b56-870d-929233a46ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-bdabb7ee-6e85-4cd3-a80c-83c334610ade,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-de457230-f13b-465e-8eda-bf5234bf5178,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-afabfb0c-abaf-432d-83d7-0fe050e14b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-137f7135-62c1-481e-a24a-fcec3860310d,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-df185039-081d-471b-acda-cc86a6782f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-758561da-22fa-4e37-9e47-759a267976cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1348894457-172.17.0.6-1595304941110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38605,DS-5d9c1476-751e-442d-96e4-f34a79ee18e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-7d33fc0a-f0da-408e-9b40-cfe72fbd85ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-f0c045ca-9fe8-41d4-8f9a-b9addabdea83,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-c5aed28f-24db-4c97-b163-e60b9ba3f60f,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-03268c33-13ad-409b-b45b-3087bc2ef5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-86c40a2c-953d-464c-ac08-8ed6526e6351,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-b08c4a8a-c260-4dcb-aecf-8784cb5231b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-2e11d3a5-7fa1-42ea-9ea5-52901de24639,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1348894457-172.17.0.6-1595304941110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38605,DS-5d9c1476-751e-442d-96e4-f34a79ee18e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-7d33fc0a-f0da-408e-9b40-cfe72fbd85ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-f0c045ca-9fe8-41d4-8f9a-b9addabdea83,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-c5aed28f-24db-4c97-b163-e60b9ba3f60f,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-03268c33-13ad-409b-b45b-3087bc2ef5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-86c40a2c-953d-464c-ac08-8ed6526e6351,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-b08c4a8a-c260-4dcb-aecf-8784cb5231b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-2e11d3a5-7fa1-42ea-9ea5-52901de24639,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1691197530-172.17.0.6-1595305183752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42099,DS-01121521-c235-47af-94aa-55c5962d8861,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-0a09256d-4bed-484c-a664-c3e66b6c8d68,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-529820fd-7386-4df9-8e55-06599366e414,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-e5fb534a-fa0b-44a8-9fee-ad00597a28b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-70cf6279-cf85-4502-a91f-6f89351e390d,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-b7f6a98c-7012-4582-a7b1-4bb3d114edaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-9a615b81-1cb6-4dba-b976-461f5faf20a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-51633a90-107b-466b-b800-c6c758d4f464,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1691197530-172.17.0.6-1595305183752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42099,DS-01121521-c235-47af-94aa-55c5962d8861,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-0a09256d-4bed-484c-a664-c3e66b6c8d68,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-529820fd-7386-4df9-8e55-06599366e414,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-e5fb534a-fa0b-44a8-9fee-ad00597a28b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-70cf6279-cf85-4502-a91f-6f89351e390d,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-b7f6a98c-7012-4582-a7b1-4bb3d114edaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-9a615b81-1cb6-4dba-b976-461f5faf20a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-51633a90-107b-466b-b800-c6c758d4f464,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-909454022-172.17.0.6-1595305513183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38036,DS-becfc019-40cd-4284-91e1-ef92e493cd62,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-47f1ce51-6482-456c-8345-c612e0cdccdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-1312b231-81de-47f6-98ca-0150ad4f8a62,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-41476ee4-b76e-466c-a6bf-d6fb65d7bda4,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-b1d0f954-0aca-4d96-b845-d8a8903ba06f,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-328e0002-24f5-447f-8bd4-573d3fa34456,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-9991e586-5b39-4faf-84a1-a09b12b98ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-f5533489-bbc3-4983-a54e-da8896ffdcec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-909454022-172.17.0.6-1595305513183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38036,DS-becfc019-40cd-4284-91e1-ef92e493cd62,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-47f1ce51-6482-456c-8345-c612e0cdccdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34409,DS-1312b231-81de-47f6-98ca-0150ad4f8a62,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-41476ee4-b76e-466c-a6bf-d6fb65d7bda4,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-b1d0f954-0aca-4d96-b845-d8a8903ba06f,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-328e0002-24f5-447f-8bd4-573d3fa34456,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-9991e586-5b39-4faf-84a1-a09b12b98ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-f5533489-bbc3-4983-a54e-da8896ffdcec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-76304903-172.17.0.6-1595305546780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40694,DS-a62ad898-0f3b-4ea0-a39e-35ba37cdc188,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-a1d11c27-96a4-4359-ad33-04eaeedf93a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-8fc951b0-c967-491a-83e1-98d0f7297ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-71a564b5-6bb1-44bd-ab40-39a60be12332,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-f02372d7-1a77-4578-8777-c09471d4ef57,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-d6070549-b9a2-4e4c-82ac-2911bc56e999,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-cd1945e4-8049-4471-8265-6ce5cedfb1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-0ebe71f7-4a2a-4378-967c-d799dd6c3192,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-76304903-172.17.0.6-1595305546780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40694,DS-a62ad898-0f3b-4ea0-a39e-35ba37cdc188,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-a1d11c27-96a4-4359-ad33-04eaeedf93a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-8fc951b0-c967-491a-83e1-98d0f7297ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-71a564b5-6bb1-44bd-ab40-39a60be12332,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-f02372d7-1a77-4578-8777-c09471d4ef57,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-d6070549-b9a2-4e4c-82ac-2911bc56e999,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-cd1945e4-8049-4471-8265-6ce5cedfb1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-0ebe71f7-4a2a-4378-967c-d799dd6c3192,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1389347444-172.17.0.6-1595305866982:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40699,DS-aac8b81e-0d92-4e3f-9698-2de817cc5d42,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-7da35bb0-3436-4bf7-8ce6-8208738bacf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-fa4c17a4-68e0-4324-b06a-2d02f9788720,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-2a73e36d-d2fc-403c-88c1-af5b36e89f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-239d5a50-64a1-4cab-94ca-3cf1a8d99679,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-32c9ff3f-1ccf-476f-b591-2fa251ec54e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-6c6269c4-df86-448f-871b-1acfa2025e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-588c0402-82f7-4daa-9081-18398f73439a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1389347444-172.17.0.6-1595305866982:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40699,DS-aac8b81e-0d92-4e3f-9698-2de817cc5d42,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-7da35bb0-3436-4bf7-8ce6-8208738bacf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-fa4c17a4-68e0-4324-b06a-2d02f9788720,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-2a73e36d-d2fc-403c-88c1-af5b36e89f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-239d5a50-64a1-4cab-94ca-3cf1a8d99679,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-32c9ff3f-1ccf-476f-b591-2fa251ec54e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-6c6269c4-df86-448f-871b-1acfa2025e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-588c0402-82f7-4daa-9081-18398f73439a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-569076756-172.17.0.6-1595306016455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39073,DS-c5a288f3-a538-422d-92ff-4ecee5392df6,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-7cb5c459-1820-4c83-bb29-bb3f0138aad9,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-5815fd4f-6485-4f9b-b88a-2d0db5434973,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-abd2973d-9f08-4c84-b815-58cb838c21d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-a6ced9e4-476b-47da-9b1e-41cd4866203b,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-b4e3452b-e8cb-4a63-900b-f3e3267d60c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-44a342cb-711c-48d7-bbb7-059cb8dc50ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-46c4188f-2fdf-4519-b70a-83cd5aed5843,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-569076756-172.17.0.6-1595306016455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39073,DS-c5a288f3-a538-422d-92ff-4ecee5392df6,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-7cb5c459-1820-4c83-bb29-bb3f0138aad9,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-5815fd4f-6485-4f9b-b88a-2d0db5434973,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-abd2973d-9f08-4c84-b815-58cb838c21d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-a6ced9e4-476b-47da-9b1e-41cd4866203b,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-b4e3452b-e8cb-4a63-900b-f3e3267d60c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-44a342cb-711c-48d7-bbb7-059cb8dc50ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-46c4188f-2fdf-4519-b70a-83cd5aed5843,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1302444522-172.17.0.6-1595306051543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38096,DS-3f505322-8622-4df1-a463-cb330430ca56,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-25a89af1-b5af-41b8-9727-3c232dda9249,DISK], DatanodeInfoWithStorage[127.0.0.1:34447,DS-669a817f-849f-41e1-90ee-4d1ee539f4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-9b6e72d6-6e05-4ee7-b9a8-813c1df99ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-7a22a10d-bfdb-4544-9b7b-36b009ac868f,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-5debb1c5-9949-4b23-9e4f-9b1046b12373,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-138d4609-afe4-4b82-a31a-171348e46f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-ddad0a1a-8212-4fb7-aa82-dc59e037377e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1302444522-172.17.0.6-1595306051543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38096,DS-3f505322-8622-4df1-a463-cb330430ca56,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-25a89af1-b5af-41b8-9727-3c232dda9249,DISK], DatanodeInfoWithStorage[127.0.0.1:34447,DS-669a817f-849f-41e1-90ee-4d1ee539f4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-9b6e72d6-6e05-4ee7-b9a8-813c1df99ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-7a22a10d-bfdb-4544-9b7b-36b009ac868f,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-5debb1c5-9949-4b23-9e4f-9b1046b12373,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-138d4609-afe4-4b82-a31a-171348e46f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-ddad0a1a-8212-4fb7-aa82-dc59e037377e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5385
