reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1266717422-172.17.0.7-1595340394382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35528,DS-4aba14fb-6c32-49b4-b1ce-06d1c6299d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-fdc6dd3a-d459-4610-837a-8433e0e2c579,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-9e7a8c6f-3b06-4ff3-af12-14df976a7fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-8960584e-b036-402a-882f-3a6283dc078e,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-6ea62bdc-cb44-4de8-a082-18d0e705f978,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-44fb535d-5b17-442e-acd2-e9cd05d2b91e,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-3089b7bc-cfae-4b0b-ba5f-f24d2ec1fe9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-c96e6f3e-2295-45c3-a023-028502963dec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1266717422-172.17.0.7-1595340394382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35528,DS-4aba14fb-6c32-49b4-b1ce-06d1c6299d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-fdc6dd3a-d459-4610-837a-8433e0e2c579,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-9e7a8c6f-3b06-4ff3-af12-14df976a7fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-8960584e-b036-402a-882f-3a6283dc078e,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-6ea62bdc-cb44-4de8-a082-18d0e705f978,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-44fb535d-5b17-442e-acd2-e9cd05d2b91e,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-3089b7bc-cfae-4b0b-ba5f-f24d2ec1fe9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-c96e6f3e-2295-45c3-a023-028502963dec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-558020351-172.17.0.7-1595340497249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44124,DS-fbfc179a-fc44-4345-baa3-646ac4779fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-26ce3465-55a4-4e54-b877-935eeb289523,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-6b033b64-aed1-41d4-8e7c-cf4841df7337,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-96f4ef31-b0b3-40e8-a206-9253927d4e31,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-5cbec715-ba80-4f0e-b1ee-39713b6eeef3,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-e703a341-c9dc-4fa6-afcc-012a7f43d067,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-c97c45b0-0fb2-4393-a04e-cf0d5a13d547,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-6d395f96-0751-4cce-8dbc-ef3294bb3740,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-558020351-172.17.0.7-1595340497249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44124,DS-fbfc179a-fc44-4345-baa3-646ac4779fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-26ce3465-55a4-4e54-b877-935eeb289523,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-6b033b64-aed1-41d4-8e7c-cf4841df7337,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-96f4ef31-b0b3-40e8-a206-9253927d4e31,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-5cbec715-ba80-4f0e-b1ee-39713b6eeef3,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-e703a341-c9dc-4fa6-afcc-012a7f43d067,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-c97c45b0-0fb2-4393-a04e-cf0d5a13d547,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-6d395f96-0751-4cce-8dbc-ef3294bb3740,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1732233723-172.17.0.7-1595340880556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40644,DS-ba1a7a56-6ad7-4f6c-8426-f6e902d19343,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-112a5218-2665-4446-8e50-e74f1062f3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-20bbc8be-1e7f-407a-9fb5-5c804804e646,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-a89a0093-1519-4097-861e-34612ea57afe,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-9225456c-6894-463a-9e55-b210c7caa97e,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-7882b766-bb17-4093-84c8-dd99debfd6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-508e5dc2-c2e7-46a9-963c-f66dab71d1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-082317c9-cb91-4003-bf02-74f30f3b8664,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1732233723-172.17.0.7-1595340880556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40644,DS-ba1a7a56-6ad7-4f6c-8426-f6e902d19343,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-112a5218-2665-4446-8e50-e74f1062f3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-20bbc8be-1e7f-407a-9fb5-5c804804e646,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-a89a0093-1519-4097-861e-34612ea57afe,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-9225456c-6894-463a-9e55-b210c7caa97e,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-7882b766-bb17-4093-84c8-dd99debfd6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-508e5dc2-c2e7-46a9-963c-f66dab71d1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-082317c9-cb91-4003-bf02-74f30f3b8664,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274817482-172.17.0.7-1595341600440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41522,DS-e692b816-1faf-4636-b382-6d73d98cab61,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-a53ed5a1-f9d2-4663-b347-aab45dae15bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-7b1d9dbb-4953-4a2e-aa64-14c01e062d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-f9b4c83b-5294-43ce-88fd-d8dcb0ed8791,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-2d3fc8f6-c79b-4bd0-b6af-add6b7250954,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-1f0cc0c0-6d5c-4e3f-8c97-882e2beb2cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-2d9b2851-a25a-4cc6-92b1-cac44b01dadb,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-80fbf4ce-1f0e-4644-8255-2633d4d27dd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274817482-172.17.0.7-1595341600440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41522,DS-e692b816-1faf-4636-b382-6d73d98cab61,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-a53ed5a1-f9d2-4663-b347-aab45dae15bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-7b1d9dbb-4953-4a2e-aa64-14c01e062d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-f9b4c83b-5294-43ce-88fd-d8dcb0ed8791,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-2d3fc8f6-c79b-4bd0-b6af-add6b7250954,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-1f0cc0c0-6d5c-4e3f-8c97-882e2beb2cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-2d9b2851-a25a-4cc6-92b1-cac44b01dadb,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-80fbf4ce-1f0e-4644-8255-2633d4d27dd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1353477966-172.17.0.7-1595341732751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43361,DS-d7e3334e-ba50-4d8d-90f3-d8cdc2da1447,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-4183a751-ffb8-4d09-abf2-e82b0ae2740b,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-120cbe3d-1ae4-48b7-b923-061d9123b372,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-ae9e2ada-1510-4ffa-a37e-ee537767fa34,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-5f02ac73-bd00-4838-a6de-097a59f2f297,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-4aba0902-f9a2-4a4e-8311-bd3a9af11dce,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-b98f2450-18d0-4323-8d9f-c24dd6237d25,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-61c1bd7e-7a4c-456c-b080-5afec5845a24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1353477966-172.17.0.7-1595341732751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43361,DS-d7e3334e-ba50-4d8d-90f3-d8cdc2da1447,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-4183a751-ffb8-4d09-abf2-e82b0ae2740b,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-120cbe3d-1ae4-48b7-b923-061d9123b372,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-ae9e2ada-1510-4ffa-a37e-ee537767fa34,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-5f02ac73-bd00-4838-a6de-097a59f2f297,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-4aba0902-f9a2-4a4e-8311-bd3a9af11dce,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-b98f2450-18d0-4323-8d9f-c24dd6237d25,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-61c1bd7e-7a4c-456c-b080-5afec5845a24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-51094640-172.17.0.7-1595343288392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41622,DS-d436bd6b-cfc2-4739-b799-fd2476836713,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-81367eb1-631e-4c8c-9cf9-82ea4f1b8a10,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-e9662e98-5f9e-4ad9-9085-64a3abc046ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-fe893285-60bb-405c-aa83-e1d7fbf959dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-f8a96d84-c502-44c3-9b23-a6ac29cc0241,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-cae8d754-fbf4-4669-8827-093967c605a3,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-0fab6856-fdff-4114-aa26-91eb8205a0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-8e71a5e0-4c17-4f67-94f1-cae661bce203,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-51094640-172.17.0.7-1595343288392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41622,DS-d436bd6b-cfc2-4739-b799-fd2476836713,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-81367eb1-631e-4c8c-9cf9-82ea4f1b8a10,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-e9662e98-5f9e-4ad9-9085-64a3abc046ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-fe893285-60bb-405c-aa83-e1d7fbf959dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-f8a96d84-c502-44c3-9b23-a6ac29cc0241,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-cae8d754-fbf4-4669-8827-093967c605a3,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-0fab6856-fdff-4114-aa26-91eb8205a0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-8e71a5e0-4c17-4f67-94f1-cae661bce203,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-431066557-172.17.0.7-1595344081199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38358,DS-f205bc23-404c-4133-a494-789ef965284c,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-d311b474-f6a3-4f75-8f56-c14cf5ce5812,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-c372f660-0164-4b3d-b785-1116baaffaa3,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-f399a3d8-0572-49d3-827c-c9da1a5e4e94,DISK], DatanodeInfoWithStorage[127.0.0.1:40094,DS-8ecf0a96-8b0d-430c-bc1d-3c118a6ace15,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-ca2e38e0-0d75-4ec8-bae8-a3bb371bd475,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-898e6834-0b43-437a-9ed3-90b80cd24ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-69c40a20-98eb-4e11-b0fb-c6853f0b08ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-431066557-172.17.0.7-1595344081199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38358,DS-f205bc23-404c-4133-a494-789ef965284c,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-d311b474-f6a3-4f75-8f56-c14cf5ce5812,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-c372f660-0164-4b3d-b785-1116baaffaa3,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-f399a3d8-0572-49d3-827c-c9da1a5e4e94,DISK], DatanodeInfoWithStorage[127.0.0.1:40094,DS-8ecf0a96-8b0d-430c-bc1d-3c118a6ace15,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-ca2e38e0-0d75-4ec8-bae8-a3bb371bd475,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-898e6834-0b43-437a-9ed3-90b80cd24ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-69c40a20-98eb-4e11-b0fb-c6853f0b08ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1010295125-172.17.0.7-1595344241796:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46587,DS-9cdf9dd1-cc69-47a2-b2c8-ca73dec364f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-7b47a134-26db-4666-8d9e-7ca311b428b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-f2f1279f-d60d-4a46-95d6-cfda5b93db4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-08e1724d-7a9b-4fef-b590-9ad208a61666,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-96b77d44-c944-43e1-81ad-4dd4204c3019,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-e7c5515d-d1df-4ad9-8cbd-45d9ffe00c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-15043860-0a0a-452c-9c87-3dbd34d9a740,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-e3a79ad0-343d-44a0-be00-cf58e7a1033e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1010295125-172.17.0.7-1595344241796:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46587,DS-9cdf9dd1-cc69-47a2-b2c8-ca73dec364f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-7b47a134-26db-4666-8d9e-7ca311b428b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-f2f1279f-d60d-4a46-95d6-cfda5b93db4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-08e1724d-7a9b-4fef-b590-9ad208a61666,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-96b77d44-c944-43e1-81ad-4dd4204c3019,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-e7c5515d-d1df-4ad9-8cbd-45d9ffe00c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-15043860-0a0a-452c-9c87-3dbd34d9a740,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-e3a79ad0-343d-44a0-be00-cf58e7a1033e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2030284248-172.17.0.7-1595344434994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37819,DS-dfa3272b-3fae-4516-a525-a44d7eef20ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-ecb889a6-60ab-4f5f-940a-5ecb51f7ff33,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-011851cc-8a0c-4afd-a17f-f1986eab61d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-a820bb50-e481-4bca-9b1e-a3e890186b61,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-81cc8777-daa7-45a9-adac-629053ea7b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-38d94fd2-989c-4b3e-9fdd-1a526fc50f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-9f4d3c49-a992-4da9-afaf-1b57e66f1929,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-e6c027b3-4656-4296-b6ac-d6d86ee050a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2030284248-172.17.0.7-1595344434994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37819,DS-dfa3272b-3fae-4516-a525-a44d7eef20ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-ecb889a6-60ab-4f5f-940a-5ecb51f7ff33,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-011851cc-8a0c-4afd-a17f-f1986eab61d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-a820bb50-e481-4bca-9b1e-a3e890186b61,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-81cc8777-daa7-45a9-adac-629053ea7b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-38d94fd2-989c-4b3e-9fdd-1a526fc50f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-9f4d3c49-a992-4da9-afaf-1b57e66f1929,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-e6c027b3-4656-4296-b6ac-d6d86ee050a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-250113429-172.17.0.7-1595344575885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39227,DS-5c919a23-2a71-4b82-8a0d-f57b000bd4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-6c4d19a0-8d2c-4f0e-a182-54ed9cb414a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-6790cd4b-85e3-48a0-a127-8eb5aa553c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-d12ef9a5-5561-4450-9012-fc1bc9854557,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-c655c679-512f-4e14-99b7-3c066f0f452e,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-f9850b2d-6a0f-43df-9e2c-2fb2c8d19ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-2fef786a-3342-4728-accb-c09b7f439c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-0a420e56-5765-45a9-94d9-d7784dbfde11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-250113429-172.17.0.7-1595344575885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39227,DS-5c919a23-2a71-4b82-8a0d-f57b000bd4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-6c4d19a0-8d2c-4f0e-a182-54ed9cb414a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-6790cd4b-85e3-48a0-a127-8eb5aa553c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-d12ef9a5-5561-4450-9012-fc1bc9854557,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-c655c679-512f-4e14-99b7-3c066f0f452e,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-f9850b2d-6a0f-43df-9e2c-2fb2c8d19ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-2fef786a-3342-4728-accb-c09b7f439c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-0a420e56-5765-45a9-94d9-d7784dbfde11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1134904328-172.17.0.7-1595345269296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40805,DS-ebd67286-4b35-492d-a249-3ad1f7fc804b,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-055943dd-86c4-4402-8c52-bd0719109bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-e4e313b9-0ae3-4022-9af8-741cf6afbc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-7ef9ca87-a5af-4547-989e-0ffd8554b132,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-f444a455-63c2-47b7-8190-25d478b0a32a,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-d203ba6a-845f-41bc-b3d5-38930ebb1622,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-5b6e2337-e3a0-41fb-8e48-f9b5b11309cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-a9ae534c-5c76-4fdb-8d9c-fe6bbfc03601,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1134904328-172.17.0.7-1595345269296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40805,DS-ebd67286-4b35-492d-a249-3ad1f7fc804b,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-055943dd-86c4-4402-8c52-bd0719109bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-e4e313b9-0ae3-4022-9af8-741cf6afbc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-7ef9ca87-a5af-4547-989e-0ffd8554b132,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-f444a455-63c2-47b7-8190-25d478b0a32a,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-d203ba6a-845f-41bc-b3d5-38930ebb1622,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-5b6e2337-e3a0-41fb-8e48-f9b5b11309cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-a9ae534c-5c76-4fdb-8d9c-fe6bbfc03601,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1294860832-172.17.0.7-1595345552421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34188,DS-287ede41-eb9d-4602-b1bb-c13f1784d123,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-2471c9ed-8e7f-4711-8b0e-3c889c9851a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-93cad660-6f50-46dd-a9d0-bebfe31de964,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-f881728c-7c35-4d5c-8071-f769fc4101eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-b4735db0-6e4d-4f29-9d36-1e10a32f76cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-02f4236e-ea14-48ad-b897-48a1fd6a106c,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-b81a6752-33ae-46da-95b7-ed11aee2c416,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-040b6c91-b5cf-42e2-9c0b-922735fad738,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1294860832-172.17.0.7-1595345552421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34188,DS-287ede41-eb9d-4602-b1bb-c13f1784d123,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-2471c9ed-8e7f-4711-8b0e-3c889c9851a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-93cad660-6f50-46dd-a9d0-bebfe31de964,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-f881728c-7c35-4d5c-8071-f769fc4101eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-b4735db0-6e4d-4f29-9d36-1e10a32f76cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-02f4236e-ea14-48ad-b897-48a1fd6a106c,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-b81a6752-33ae-46da-95b7-ed11aee2c416,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-040b6c91-b5cf-42e2-9c0b-922735fad738,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5346
