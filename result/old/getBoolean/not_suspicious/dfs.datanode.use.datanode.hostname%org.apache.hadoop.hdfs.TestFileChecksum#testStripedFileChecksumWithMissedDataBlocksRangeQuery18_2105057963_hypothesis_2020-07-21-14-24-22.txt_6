reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1888729483-172.17.0.4-1595342439488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36799,DS-f844c23b-fbcd-455e-bf00-89285b9b4136,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-4bd17867-23ad-4e51-9272-7bb8787aa4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-c908272d-19f0-4388-8fda-e4e303e8141a,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-ed775a83-064c-4803-bc41-4007e006646a,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-49412f43-0a99-4e47-a114-a79edf64df04,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-fe2f6d5a-b5f5-4afa-b7d5-6a513dfb6c55,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-4b1b0db0-ec0f-45df-aa68-f70587e868e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-94eba22e-a1f5-4ce5-9ed4-6dff7fa28c7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1888729483-172.17.0.4-1595342439488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36799,DS-f844c23b-fbcd-455e-bf00-89285b9b4136,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-4bd17867-23ad-4e51-9272-7bb8787aa4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-c908272d-19f0-4388-8fda-e4e303e8141a,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-ed775a83-064c-4803-bc41-4007e006646a,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-49412f43-0a99-4e47-a114-a79edf64df04,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-fe2f6d5a-b5f5-4afa-b7d5-6a513dfb6c55,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-4b1b0db0-ec0f-45df-aa68-f70587e868e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-94eba22e-a1f5-4ce5-9ed4-6dff7fa28c7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1312391580-172.17.0.4-1595342485257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46768,DS-51f0fd27-01dd-4f04-95f2-107caa29beec,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-c920c212-ec92-4b27-9ea1-14b843b5e485,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-7941d0f8-23f7-4280-80a1-fbbec24ce27d,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-1998fef9-d1ae-49d3-a620-8e9bb76ee06d,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-03f452ab-85f7-47a5-b07e-6573a32f902a,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-05fb92f9-619d-48e0-89c4-5f381476ff30,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-2623f5b8-a9b0-47b1-b1d3-db8c2800946d,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-f6c93e96-ee9b-4ebf-82cc-a3309194b56e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1312391580-172.17.0.4-1595342485257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46768,DS-51f0fd27-01dd-4f04-95f2-107caa29beec,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-c920c212-ec92-4b27-9ea1-14b843b5e485,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-7941d0f8-23f7-4280-80a1-fbbec24ce27d,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-1998fef9-d1ae-49d3-a620-8e9bb76ee06d,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-03f452ab-85f7-47a5-b07e-6573a32f902a,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-05fb92f9-619d-48e0-89c4-5f381476ff30,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-2623f5b8-a9b0-47b1-b1d3-db8c2800946d,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-f6c93e96-ee9b-4ebf-82cc-a3309194b56e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1340264227-172.17.0.4-1595342876610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33423,DS-b1548db1-2d3f-40c9-a1c7-8ddda1a57879,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-4d1b3932-45ee-47d4-a0ae-11f09473911e,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-dfbb88be-eb11-4855-906e-856ebaaf8405,DISK], DatanodeInfoWithStorage[127.0.0.1:34771,DS-3b67b3c9-4b46-46e1-8386-2b69e2edc4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-3927416e-8a82-44d9-9b9e-f06b69ea102c,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-e0372328-4352-4cd2-99ca-77c8252ccb97,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-0eaddf80-b7ae-4cfa-9718-33380607ffcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-7dfdcb76-5c76-4ce4-afaf-67a291a256ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1340264227-172.17.0.4-1595342876610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33423,DS-b1548db1-2d3f-40c9-a1c7-8ddda1a57879,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-4d1b3932-45ee-47d4-a0ae-11f09473911e,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-dfbb88be-eb11-4855-906e-856ebaaf8405,DISK], DatanodeInfoWithStorage[127.0.0.1:34771,DS-3b67b3c9-4b46-46e1-8386-2b69e2edc4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-3927416e-8a82-44d9-9b9e-f06b69ea102c,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-e0372328-4352-4cd2-99ca-77c8252ccb97,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-0eaddf80-b7ae-4cfa-9718-33380607ffcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-7dfdcb76-5c76-4ce4-afaf-67a291a256ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1044550826-172.17.0.4-1595343361477:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39658,DS-85d521f4-c0ff-45ef-bf0b-6c1fbdfb7ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-32657154-593b-4f9a-b22f-d2207e707648,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-32c6844f-cba0-4de6-b7af-69b0a4055ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-3dd74b19-ef03-4dcc-ac12-b059a2b095b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-df6ce690-e471-44d4-a968-53048bfb8177,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-d4f2c333-4f72-4c1f-8b24-b52acd7da076,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-912da1dc-2e9c-40b9-b4d1-8e21cc9226a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-a09f205a-93f7-4fbf-adbc-d1794e77da51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1044550826-172.17.0.4-1595343361477:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39658,DS-85d521f4-c0ff-45ef-bf0b-6c1fbdfb7ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-32657154-593b-4f9a-b22f-d2207e707648,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-32c6844f-cba0-4de6-b7af-69b0a4055ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-3dd74b19-ef03-4dcc-ac12-b059a2b095b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-df6ce690-e471-44d4-a968-53048bfb8177,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-d4f2c333-4f72-4c1f-8b24-b52acd7da076,DISK], DatanodeInfoWithStorage[127.0.0.1:39867,DS-912da1dc-2e9c-40b9-b4d1-8e21cc9226a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-a09f205a-93f7-4fbf-adbc-d1794e77da51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-704876674-172.17.0.4-1595343588899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40723,DS-74dcef3c-008f-4161-b72c-61695ae95d67,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-52fc885f-da05-4e33-989a-16d03f85b792,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-c2bc3487-ed06-4186-84e9-84d43f9abe61,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-374b1e54-dd55-4173-abf7-2e1ad1c2ffe2,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-daf35a1a-82ce-4e12-b185-89f9aa05331c,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-eee9310b-49c0-4531-bcd7-3159da28991b,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-a93875e8-0c7c-4b4d-887d-0544131745e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-45f71980-6b16-4aa9-98df-ae9e14f1acbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-704876674-172.17.0.4-1595343588899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40723,DS-74dcef3c-008f-4161-b72c-61695ae95d67,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-52fc885f-da05-4e33-989a-16d03f85b792,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-c2bc3487-ed06-4186-84e9-84d43f9abe61,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-374b1e54-dd55-4173-abf7-2e1ad1c2ffe2,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-daf35a1a-82ce-4e12-b185-89f9aa05331c,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-eee9310b-49c0-4531-bcd7-3159da28991b,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-a93875e8-0c7c-4b4d-887d-0544131745e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-45f71980-6b16-4aa9-98df-ae9e14f1acbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-665944808-172.17.0.4-1595343712159:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44059,DS-12d8a7ff-d624-4580-b876-47b818010acf,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-282e3c1b-27be-41fc-be6a-3b149c9d85a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-54a32884-d22c-4b5e-9677-02372db6de82,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-0ee765f2-2e01-4100-9d76-d27ebe0a277c,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-b189726f-9dc6-41d2-b6b8-b1f4060d2cef,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-0c4dda73-9249-43c7-a7e6-dbc860578c92,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-f28c1aa5-f15c-4581-9666-1308ab5fbf93,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-e84d3b66-2c51-4154-a312-80f0a9b3f72e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-665944808-172.17.0.4-1595343712159:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44059,DS-12d8a7ff-d624-4580-b876-47b818010acf,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-282e3c1b-27be-41fc-be6a-3b149c9d85a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-54a32884-d22c-4b5e-9677-02372db6de82,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-0ee765f2-2e01-4100-9d76-d27ebe0a277c,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-b189726f-9dc6-41d2-b6b8-b1f4060d2cef,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-0c4dda73-9249-43c7-a7e6-dbc860578c92,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-f28c1aa5-f15c-4581-9666-1308ab5fbf93,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-e84d3b66-2c51-4154-a312-80f0a9b3f72e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2034393573-172.17.0.4-1595343760196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38021,DS-b7b2bd99-d9ef-4219-af50-eda1d8af6c76,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-c178816d-786b-4472-8921-f2439d94e5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-80a652c6-ab75-4d51-9dfd-b0817afa65cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-c33adb6f-7885-4c42-bcca-2d7199e914d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40722,DS-8bb276f1-abf4-47db-8cf7-47000f5abb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-2c7e5105-876b-4515-b5f6-04a07ac48b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-2f1c689e-4bcc-4d64-93db-58bb7b0400b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-48312be3-71bf-4d10-b4b3-fa63d3408406,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2034393573-172.17.0.4-1595343760196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38021,DS-b7b2bd99-d9ef-4219-af50-eda1d8af6c76,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-c178816d-786b-4472-8921-f2439d94e5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-80a652c6-ab75-4d51-9dfd-b0817afa65cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-c33adb6f-7885-4c42-bcca-2d7199e914d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40722,DS-8bb276f1-abf4-47db-8cf7-47000f5abb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-2c7e5105-876b-4515-b5f6-04a07ac48b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-2f1c689e-4bcc-4d64-93db-58bb7b0400b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-48312be3-71bf-4d10-b4b3-fa63d3408406,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-302271114-172.17.0.4-1595345247398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33018,DS-d1e5527e-0316-426c-9a2e-4cb7564d5c24,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-f1143810-c20b-482b-adf4-5cc84b30371b,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-4e01c28c-a7b7-4988-a45f-fa1b2960776d,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-9e41ed46-a782-4ce8-960a-febf22e48fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-ee80423a-2b56-4b75-a74c-843a932ba372,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-85e3b09e-38ba-4e4e-a0ed-0757029261bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-6d3c0471-1f3b-4bcb-b94b-cc130cc8e827,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-8ba2c299-358e-45ee-8075-e7ff05916d90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-302271114-172.17.0.4-1595345247398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33018,DS-d1e5527e-0316-426c-9a2e-4cb7564d5c24,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-f1143810-c20b-482b-adf4-5cc84b30371b,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-4e01c28c-a7b7-4988-a45f-fa1b2960776d,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-9e41ed46-a782-4ce8-960a-febf22e48fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-ee80423a-2b56-4b75-a74c-843a932ba372,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-85e3b09e-38ba-4e4e-a0ed-0757029261bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-6d3c0471-1f3b-4bcb-b94b-cc130cc8e827,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-8ba2c299-358e-45ee-8075-e7ff05916d90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1080770202-172.17.0.4-1595345585143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45882,DS-d13bda55-62be-4199-b722-f4c97bc4ea23,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-77fb3ba4-3e09-4f85-8638-6d564b9c9a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-716b74ad-0c8e-4c51-9ebe-2cdbed4676d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-e0244dd2-dfb9-4222-b471-b95e1a332488,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-a361359e-8cd2-4af5-8686-8a7e226b1994,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-ca9ff8fa-4ecc-431f-86f1-3b425acc47a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-e92f5b81-99e7-497c-bb31-4ff8e8b5ef4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37382,DS-34cfe46b-22fc-41d2-9049-9df12893f903,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1080770202-172.17.0.4-1595345585143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45882,DS-d13bda55-62be-4199-b722-f4c97bc4ea23,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-77fb3ba4-3e09-4f85-8638-6d564b9c9a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-716b74ad-0c8e-4c51-9ebe-2cdbed4676d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-e0244dd2-dfb9-4222-b471-b95e1a332488,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-a361359e-8cd2-4af5-8686-8a7e226b1994,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-ca9ff8fa-4ecc-431f-86f1-3b425acc47a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-e92f5b81-99e7-497c-bb31-4ff8e8b5ef4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37382,DS-34cfe46b-22fc-41d2-9049-9df12893f903,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1043375717-172.17.0.4-1595345635190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42305,DS-8b4633c6-6023-495f-8e3e-11b7440804b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-e64c4c12-cd98-4b11-9c95-280430f3bcfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-b479c570-d120-44a7-8d06-da29d5373513,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-5962f706-66e0-40af-8bb1-d9fd471a5b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-8a7a246f-d8b5-48a2-9863-71b137089a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-16b76012-f30f-4569-a0e7-913b8ea0e835,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-db802fb0-e6f5-403e-aca7-e8e66b9a0f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-cf945e72-db11-4cf1-89d4-78ac6df8d516,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1043375717-172.17.0.4-1595345635190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42305,DS-8b4633c6-6023-495f-8e3e-11b7440804b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-e64c4c12-cd98-4b11-9c95-280430f3bcfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-b479c570-d120-44a7-8d06-da29d5373513,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-5962f706-66e0-40af-8bb1-d9fd471a5b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-8a7a246f-d8b5-48a2-9863-71b137089a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-16b76012-f30f-4569-a0e7-913b8ea0e835,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-db802fb0-e6f5-403e-aca7-e8e66b9a0f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-cf945e72-db11-4cf1-89d4-78ac6df8d516,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1082546477-172.17.0.4-1595345960288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43985,DS-eb9c748d-1165-4481-a1b7-ff5b486ee6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-1a11f903-f18c-47f7-901e-ad22d9b8f337,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-694c6a75-0861-417d-bae8-0b8e9a164ada,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-5dc87731-cd8e-4a84-a2cf-ab28bcaed25d,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-2c715372-1326-4491-b4d5-5608253444c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-2d95858b-9be6-4cd3-ae4a-e33a95292e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-23086119-26d3-4d3a-976f-b8d0c78d0c96,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-4221a1fa-8a2c-43bc-a6c7-5fe0d58e0050,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1082546477-172.17.0.4-1595345960288:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43985,DS-eb9c748d-1165-4481-a1b7-ff5b486ee6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-1a11f903-f18c-47f7-901e-ad22d9b8f337,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-694c6a75-0861-417d-bae8-0b8e9a164ada,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-5dc87731-cd8e-4a84-a2cf-ab28bcaed25d,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-2c715372-1326-4491-b4d5-5608253444c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-2d95858b-9be6-4cd3-ae4a-e33a95292e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-23086119-26d3-4d3a-976f-b8d0c78d0c96,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-4221a1fa-8a2c-43bc-a6c7-5fe0d58e0050,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1369146976-172.17.0.4-1595346343163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36308,DS-5c534e9a-b6da-4c6d-a853-c5b1754b72fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-54e7e390-0b32-4a34-80c3-5d0809995d26,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-2e2a4542-c798-4b5b-94e7-de4ed496eacd,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-01940a90-ae7e-4e76-b78d-b6a70d114a90,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-06dda641-cf71-4183-b136-2236ac0fcaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-11e13123-e1ca-4c91-a7fc-28b6fbd470e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-df5d7f8b-2526-4632-9a59-b185e8de5991,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-e95468cd-8ebc-4978-9b51-53a0285d432f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1369146976-172.17.0.4-1595346343163:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36308,DS-5c534e9a-b6da-4c6d-a853-c5b1754b72fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-54e7e390-0b32-4a34-80c3-5d0809995d26,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-2e2a4542-c798-4b5b-94e7-de4ed496eacd,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-01940a90-ae7e-4e76-b78d-b6a70d114a90,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-06dda641-cf71-4183-b136-2236ac0fcaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-11e13123-e1ca-4c91-a7fc-28b6fbd470e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-df5d7f8b-2526-4632-9a59-b185e8de5991,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-e95468cd-8ebc-4978-9b51-53a0285d432f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-151694692-172.17.0.4-1595346469226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39614,DS-b436aedb-82af-419e-b570-c8c284a22689,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-c20c146c-28a5-470f-832e-bf4c04967f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-aa2a9f65-0a8c-47fe-bde3-d390222c03a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-b2ea3b8e-2bca-4d06-bbf1-7872b61bee2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-a25f15ae-4460-4386-8148-8dee0d496ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-13c59736-e25a-4183-ad8d-05cd4b553115,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-bdbf7cf0-0ff0-40fa-878d-99192fe4545a,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-30ecb49e-99c3-48ec-8329-62004314e690,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-151694692-172.17.0.4-1595346469226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39614,DS-b436aedb-82af-419e-b570-c8c284a22689,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-c20c146c-28a5-470f-832e-bf4c04967f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-aa2a9f65-0a8c-47fe-bde3-d390222c03a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-b2ea3b8e-2bca-4d06-bbf1-7872b61bee2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-a25f15ae-4460-4386-8148-8dee0d496ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-13c59736-e25a-4183-ad8d-05cd4b553115,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-bdbf7cf0-0ff0-40fa-878d-99192fe4545a,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-30ecb49e-99c3-48ec-8329-62004314e690,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-504457879-172.17.0.4-1595346586942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41093,DS-a49b10d2-bfa7-4dee-af27-9e4d2fc5e0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-030faa9a-b973-4701-83c5-10524d49204e,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-2a869ccb-35c7-49bb-baba-b12c001e02e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-bd0637db-8a64-48b9-b97f-caac2ac106a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-38d1c61d-f36a-4d95-88aa-757fea0ee61e,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-d01072a8-42d0-4759-a39d-2c2b223e3572,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-ad4fcfd4-ae69-4abb-a21b-cbc33487d203,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-0166d0ed-c559-4229-92f1-c914d5eef527,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-504457879-172.17.0.4-1595346586942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41093,DS-a49b10d2-bfa7-4dee-af27-9e4d2fc5e0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-030faa9a-b973-4701-83c5-10524d49204e,DISK], DatanodeInfoWithStorage[127.0.0.1:34817,DS-2a869ccb-35c7-49bb-baba-b12c001e02e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-bd0637db-8a64-48b9-b97f-caac2ac106a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-38d1c61d-f36a-4d95-88aa-757fea0ee61e,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-d01072a8-42d0-4759-a39d-2c2b223e3572,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-ad4fcfd4-ae69-4abb-a21b-cbc33487d203,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-0166d0ed-c559-4229-92f1-c914d5eef527,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1874357640-172.17.0.4-1595347361348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39443,DS-5875f826-80fd-48e8-a0e7-cf0f46d77b68,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-811827d7-7733-472e-b1c3-88b6a4bd98b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-bf345a18-ec0d-4ecd-9ec4-1f9ee76a15be,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-288a9a3c-dc57-40e2-a9e9-71b0da1a04ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-c8718902-1952-404e-9a96-67a409f1a31f,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-60bd10d9-fbe4-4530-aa69-382a1cc38a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-e9e145db-6c7c-48df-9208-3afdf72fd777,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-fb5b66b5-1ea5-4bc4-8ff2-6b2d76880293,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1874357640-172.17.0.4-1595347361348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39443,DS-5875f826-80fd-48e8-a0e7-cf0f46d77b68,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-811827d7-7733-472e-b1c3-88b6a4bd98b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-bf345a18-ec0d-4ecd-9ec4-1f9ee76a15be,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-288a9a3c-dc57-40e2-a9e9-71b0da1a04ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-c8718902-1952-404e-9a96-67a409f1a31f,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-60bd10d9-fbe4-4530-aa69-382a1cc38a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-e9e145db-6c7c-48df-9208-3afdf72fd777,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-fb5b66b5-1ea5-4bc4-8ff2-6b2d76880293,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6711
