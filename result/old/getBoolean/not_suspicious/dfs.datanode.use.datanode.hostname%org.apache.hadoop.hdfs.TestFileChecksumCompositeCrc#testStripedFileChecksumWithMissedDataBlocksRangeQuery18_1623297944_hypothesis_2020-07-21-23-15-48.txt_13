reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1711796976-172.17.0.9-1595373618496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33978,DS-828d6236-1c32-40df-9858-555c6abeeca1,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-c1b361a4-6cb7-4dcd-8a00-89aa5b7d5ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-790966c6-442d-46b1-9319-fbd6c407b9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-54d906e9-e6a0-4d0f-a8ba-08d95745cc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-886e1668-79c0-407d-acfb-cd426b3264f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-c20af938-291c-4c91-8895-49a0de0dd4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-e9222b9f-1780-4c27-ae65-c49eaf89332a,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-d5a80b0c-21f1-40dc-93a5-8da1f65acdde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1711796976-172.17.0.9-1595373618496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33978,DS-828d6236-1c32-40df-9858-555c6abeeca1,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-c1b361a4-6cb7-4dcd-8a00-89aa5b7d5ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-790966c6-442d-46b1-9319-fbd6c407b9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-54d906e9-e6a0-4d0f-a8ba-08d95745cc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-886e1668-79c0-407d-acfb-cd426b3264f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-c20af938-291c-4c91-8895-49a0de0dd4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38162,DS-e9222b9f-1780-4c27-ae65-c49eaf89332a,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-d5a80b0c-21f1-40dc-93a5-8da1f65acdde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1870220173-172.17.0.9-1595373906963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42867,DS-e3a64346-518c-41d3-b6aa-16928bf7d21a,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-a9eab338-22dd-422d-9649-3cdaad2c44fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-dc9af98d-9465-4312-9d24-2296346a2f52,DISK], DatanodeInfoWithStorage[127.0.0.1:33263,DS-6256d297-d0b0-402f-9c92-13a925001cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-b88c3f82-45c5-4f59-abbf-f88d20f4a0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-98d17d6d-6925-4452-8b7a-8044f556a26b,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-adce4906-9024-4f24-b352-09fa6560e75c,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-49c96534-f3f9-4849-893f-376afdd8cb1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1870220173-172.17.0.9-1595373906963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42867,DS-e3a64346-518c-41d3-b6aa-16928bf7d21a,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-a9eab338-22dd-422d-9649-3cdaad2c44fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-dc9af98d-9465-4312-9d24-2296346a2f52,DISK], DatanodeInfoWithStorage[127.0.0.1:33263,DS-6256d297-d0b0-402f-9c92-13a925001cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-b88c3f82-45c5-4f59-abbf-f88d20f4a0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-98d17d6d-6925-4452-8b7a-8044f556a26b,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-adce4906-9024-4f24-b352-09fa6560e75c,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-49c96534-f3f9-4849-893f-376afdd8cb1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-103587035-172.17.0.9-1595374193165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42972,DS-ca5cc020-6a7f-4af0-9ebc-a1522cd517ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-c0af95fc-df0b-49b4-a00c-f37cac4f3c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-9ecf8106-590f-4150-9cf7-9a0238352fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-b9036c38-042d-4290-af32-fd74f569c2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-e3ed2bea-7e2f-461d-8922-6d3b847d6ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-d5632dae-2174-4728-9066-2dcdbd54bd40,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-34dfff9d-b95e-4e58-b13a-c86b039e0cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-f08aa0fa-389f-4330-86be-295c9e25b5ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-103587035-172.17.0.9-1595374193165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42972,DS-ca5cc020-6a7f-4af0-9ebc-a1522cd517ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-c0af95fc-df0b-49b4-a00c-f37cac4f3c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-9ecf8106-590f-4150-9cf7-9a0238352fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-b9036c38-042d-4290-af32-fd74f569c2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-e3ed2bea-7e2f-461d-8922-6d3b847d6ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-d5632dae-2174-4728-9066-2dcdbd54bd40,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-34dfff9d-b95e-4e58-b13a-c86b039e0cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-f08aa0fa-389f-4330-86be-295c9e25b5ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-687975456-172.17.0.9-1595374386334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37268,DS-9179bebc-24d6-4662-8f71-dd43f93e1df8,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-2396f0de-979f-402b-857e-8f0462ae0ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-82964b62-5632-4d80-838c-cdd38973bef5,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-582b254d-eef0-489c-ad78-d54f1c736635,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-f9adcc3d-2cf8-4874-9097-b4a3467050fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-bd136be7-b76e-4c6f-8c50-6b1adc6a1724,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-5ce67914-cdc0-42fd-8223-c3e91329e267,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-eb81bd7a-6e68-43ea-89f8-8b9768e70b4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-687975456-172.17.0.9-1595374386334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37268,DS-9179bebc-24d6-4662-8f71-dd43f93e1df8,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-2396f0de-979f-402b-857e-8f0462ae0ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-82964b62-5632-4d80-838c-cdd38973bef5,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-582b254d-eef0-489c-ad78-d54f1c736635,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-f9adcc3d-2cf8-4874-9097-b4a3467050fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-bd136be7-b76e-4c6f-8c50-6b1adc6a1724,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-5ce67914-cdc0-42fd-8223-c3e91329e267,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-eb81bd7a-6e68-43ea-89f8-8b9768e70b4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969009057-172.17.0.9-1595374942310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42535,DS-9e60a780-6089-4172-9b3d-ad0385734222,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-0de05d8a-da38-416c-a79a-83b81e9322cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-654de055-3cf6-4da4-916c-401f944fcc11,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-e3f69f17-a746-4c9a-9e00-53b95f297c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-be17ba08-a63d-4100-a1e4-bc89f65e270d,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-53325bd3-8b39-4e0a-9099-a58b809cdb82,DISK], DatanodeInfoWithStorage[127.0.0.1:39710,DS-09ad25de-f772-4740-8ba7-fd658dce0286,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-3f70f789-ddc5-4091-b5ba-5604c6b6f910,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969009057-172.17.0.9-1595374942310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42535,DS-9e60a780-6089-4172-9b3d-ad0385734222,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-0de05d8a-da38-416c-a79a-83b81e9322cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-654de055-3cf6-4da4-916c-401f944fcc11,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-e3f69f17-a746-4c9a-9e00-53b95f297c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-be17ba08-a63d-4100-a1e4-bc89f65e270d,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-53325bd3-8b39-4e0a-9099-a58b809cdb82,DISK], DatanodeInfoWithStorage[127.0.0.1:39710,DS-09ad25de-f772-4740-8ba7-fd658dce0286,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-3f70f789-ddc5-4091-b5ba-5604c6b6f910,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-705784414-172.17.0.9-1595375013610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34467,DS-2d665d49-5960-44f8-a061-e7f914f912d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-05c39d85-8a1d-4c99-a3b1-b6a44fa0a5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-5d6272ae-fa31-466f-b7d2-d67077398e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-816c4416-a892-4b1c-8f48-b744f06f9b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-eee7da36-856d-425e-b83f-c46011609b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-3fc58981-4154-4378-9bee-8237476bae25,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-08e1cb74-a3c8-41e7-8d35-1773a41ca1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-1076fbd1-ccbc-4649-a58a-a883d3de8d68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-705784414-172.17.0.9-1595375013610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34467,DS-2d665d49-5960-44f8-a061-e7f914f912d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-05c39d85-8a1d-4c99-a3b1-b6a44fa0a5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-5d6272ae-fa31-466f-b7d2-d67077398e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-816c4416-a892-4b1c-8f48-b744f06f9b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-eee7da36-856d-425e-b83f-c46011609b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-3fc58981-4154-4378-9bee-8237476bae25,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-08e1cb74-a3c8-41e7-8d35-1773a41ca1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-1076fbd1-ccbc-4649-a58a-a883d3de8d68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1483711298-172.17.0.9-1595375089567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42795,DS-3aa53a9a-8eb6-46e1-bae2-370d539d7ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-9af64f5f-3e31-4a89-aded-2e24977a107c,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-d28b48e4-b678-4b8a-800d-cc8e9021dd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-e3ec05cc-85e4-4d94-a1d8-6031b478e1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-1e850e03-7cb2-42fc-8fdb-0c10c69f4342,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-cda7959a-7589-4700-a72d-e6d1c9135545,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-f077e6f4-a48b-499e-9cbe-669d8b4f62cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-ed01db6a-b610-4864-87e4-23412ceac4e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1483711298-172.17.0.9-1595375089567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42795,DS-3aa53a9a-8eb6-46e1-bae2-370d539d7ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-9af64f5f-3e31-4a89-aded-2e24977a107c,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-d28b48e4-b678-4b8a-800d-cc8e9021dd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-e3ec05cc-85e4-4d94-a1d8-6031b478e1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-1e850e03-7cb2-42fc-8fdb-0c10c69f4342,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-cda7959a-7589-4700-a72d-e6d1c9135545,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-f077e6f4-a48b-499e-9cbe-669d8b4f62cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-ed01db6a-b610-4864-87e4-23412ceac4e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1875804070-172.17.0.9-1595375586146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44406,DS-36ac8853-5f9e-4c33-82b3-86f208e17470,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-cb13f01b-dc5a-4a3b-96e9-301235c38c29,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-e554d069-860b-435d-a537-db63cb7a1cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-65feaecf-a188-452f-89ba-5e24fa24eb91,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-de14e192-260b-41ba-a8b5-cdd1eb51b576,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-e8e8acfc-2dd2-48dd-851a-6851533de549,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-49540552-9b81-46ca-a2d0-6558bc3225c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-c736dd4d-e973-41a1-8742-1d4e0a17ed2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1875804070-172.17.0.9-1595375586146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44406,DS-36ac8853-5f9e-4c33-82b3-86f208e17470,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-cb13f01b-dc5a-4a3b-96e9-301235c38c29,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-e554d069-860b-435d-a537-db63cb7a1cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-65feaecf-a188-452f-89ba-5e24fa24eb91,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-de14e192-260b-41ba-a8b5-cdd1eb51b576,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-e8e8acfc-2dd2-48dd-851a-6851533de549,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-49540552-9b81-46ca-a2d0-6558bc3225c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-c736dd4d-e973-41a1-8742-1d4e0a17ed2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888676998-172.17.0.9-1595375743700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32888,DS-6ee1002e-a839-4b62-986c-7562ac890069,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-1b963076-abf2-4b05-8cff-c610ce87cbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-e8e1e47b-e46d-4eb1-9539-86d83288a54a,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-6f38d215-5462-4b30-a042-b70d3378d145,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-be9999f8-2c29-4200-80fc-eb2113c2f821,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-5227b9f5-81d9-4b9a-8437-d79578d22c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-faf15d47-e506-4bb8-890a-10f76d9c4af2,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-154b8067-dc4c-4ce9-a631-68bbb8be3d7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888676998-172.17.0.9-1595375743700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32888,DS-6ee1002e-a839-4b62-986c-7562ac890069,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-1b963076-abf2-4b05-8cff-c610ce87cbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-e8e1e47b-e46d-4eb1-9539-86d83288a54a,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-6f38d215-5462-4b30-a042-b70d3378d145,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-be9999f8-2c29-4200-80fc-eb2113c2f821,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-5227b9f5-81d9-4b9a-8437-d79578d22c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-faf15d47-e506-4bb8-890a-10f76d9c4af2,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-154b8067-dc4c-4ce9-a631-68bbb8be3d7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1891760818-172.17.0.9-1595375823234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41918,DS-62721a8f-af51-448e-8277-bc3aa8a2c412,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-b9d2dd8f-1f6d-462e-9bf9-57230415c635,DISK], DatanodeInfoWithStorage[127.0.0.1:38359,DS-a1295579-8690-4c17-ae7a-929de84d0317,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-a1fef3c0-6712-4d90-998c-908728bc511f,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-19801e3b-2e23-4be6-893b-af0d2b79ac78,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-28121f14-949d-4a58-90cf-9d020ea932d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-aa984901-1271-4e1f-a814-b363eeca8ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-6333b79c-c86a-47e7-b7af-14578953e9d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1891760818-172.17.0.9-1595375823234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41918,DS-62721a8f-af51-448e-8277-bc3aa8a2c412,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-b9d2dd8f-1f6d-462e-9bf9-57230415c635,DISK], DatanodeInfoWithStorage[127.0.0.1:38359,DS-a1295579-8690-4c17-ae7a-929de84d0317,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-a1fef3c0-6712-4d90-998c-908728bc511f,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-19801e3b-2e23-4be6-893b-af0d2b79ac78,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-28121f14-949d-4a58-90cf-9d020ea932d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-aa984901-1271-4e1f-a814-b363eeca8ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-6333b79c-c86a-47e7-b7af-14578953e9d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-841285595-172.17.0.9-1595375922578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45879,DS-db95f9d4-3387-4fa0-99d7-71b16f5c9df7,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-5a873eb2-014e-4bcb-93c8-9952983a7fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-caf0dfa2-e102-4a1e-863a-299dbea3d857,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-39960576-5cd0-416c-a2aa-bdb9c5a6e819,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-06be19b8-7494-4553-8e8e-a52b87c014d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-bd5a5e4a-5c19-4e01-8089-62ce8c174f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-6cd83782-0ea5-4508-825e-eaf4c804f3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-1d62136b-747b-47f2-b711-9ece94340aa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-841285595-172.17.0.9-1595375922578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45879,DS-db95f9d4-3387-4fa0-99d7-71b16f5c9df7,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-5a873eb2-014e-4bcb-93c8-9952983a7fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-caf0dfa2-e102-4a1e-863a-299dbea3d857,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-39960576-5cd0-416c-a2aa-bdb9c5a6e819,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-06be19b8-7494-4553-8e8e-a52b87c014d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-bd5a5e4a-5c19-4e01-8089-62ce8c174f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-6cd83782-0ea5-4508-825e-eaf4c804f3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-1d62136b-747b-47f2-b711-9ece94340aa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1255057776-172.17.0.9-1595376211798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42886,DS-195a65ac-06e6-439b-97b5-a46a8128ce36,DISK], DatanodeInfoWithStorage[127.0.0.1:42723,DS-df138e11-22fe-445a-b50f-2922ea6edf32,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-c571768e-b095-4036-8dd3-becc3c3849b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-346d2a66-e65a-4cbf-9e4f-861993280811,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-4c8b917e-8f94-4046-8075-455465c1f08a,DISK], DatanodeInfoWithStorage[127.0.0.1:39807,DS-8dd379c4-dee8-4d70-8f50-2408ef4742bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-e9de6cc3-7978-4238-a42a-3784101612a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-3a29fd9d-2283-4d88-9be3-26d9a3deb6a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1255057776-172.17.0.9-1595376211798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42886,DS-195a65ac-06e6-439b-97b5-a46a8128ce36,DISK], DatanodeInfoWithStorage[127.0.0.1:42723,DS-df138e11-22fe-445a-b50f-2922ea6edf32,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-c571768e-b095-4036-8dd3-becc3c3849b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-346d2a66-e65a-4cbf-9e4f-861993280811,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-4c8b917e-8f94-4046-8075-455465c1f08a,DISK], DatanodeInfoWithStorage[127.0.0.1:39807,DS-8dd379c4-dee8-4d70-8f50-2408ef4742bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-e9de6cc3-7978-4238-a42a-3784101612a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-3a29fd9d-2283-4d88-9be3-26d9a3deb6a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-13232012-172.17.0.9-1595376368491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37768,DS-d21211f5-69fb-4409-a22d-bbf531d35d26,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-ea4ec74b-b4d3-4241-b75f-c8d6d989fe22,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-7b469178-73c5-4efb-b8ef-952017981b43,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-ae7620a4-70bf-480a-bf48-8b233dca805e,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-e06a05a1-a596-427a-bd53-5fa1351ed06a,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-28901ab3-495c-4bb9-8828-33d7254c3d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-df6f2804-9249-4a54-a07c-9a3ce4cb0a19,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-332904dc-e70f-4aba-9ebe-a06115024882,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-13232012-172.17.0.9-1595376368491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37768,DS-d21211f5-69fb-4409-a22d-bbf531d35d26,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-ea4ec74b-b4d3-4241-b75f-c8d6d989fe22,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-7b469178-73c5-4efb-b8ef-952017981b43,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-ae7620a4-70bf-480a-bf48-8b233dca805e,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-e06a05a1-a596-427a-bd53-5fa1351ed06a,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-28901ab3-495c-4bb9-8828-33d7254c3d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-df6f2804-9249-4a54-a07c-9a3ce4cb0a19,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-332904dc-e70f-4aba-9ebe-a06115024882,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-218416285-172.17.0.9-1595376848624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45606,DS-3ce7d1b7-0af8-4b62-bcb4-cfd1a227f287,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-d03dc7f7-94c8-480b-a69a-721683eb3f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-e2a156d3-0f1a-4fed-84b6-2718af6b74b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-c7108f10-8baa-4edc-aebb-898d72255e02,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-39e4d396-7653-4c80-9302-73696637da4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-9e96f2ae-19fa-41f4-a8ee-b6cc5bdce3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-cf6922c4-6ae6-4f17-97f9-a5e2f45fd7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-78b81e9c-21e3-4402-a919-5b05cc911474,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-218416285-172.17.0.9-1595376848624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45606,DS-3ce7d1b7-0af8-4b62-bcb4-cfd1a227f287,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-d03dc7f7-94c8-480b-a69a-721683eb3f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-e2a156d3-0f1a-4fed-84b6-2718af6b74b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-c7108f10-8baa-4edc-aebb-898d72255e02,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-39e4d396-7653-4c80-9302-73696637da4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-9e96f2ae-19fa-41f4-a8ee-b6cc5bdce3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-cf6922c4-6ae6-4f17-97f9-a5e2f45fd7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-78b81e9c-21e3-4402-a919-5b05cc911474,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-98570817-172.17.0.9-1595377309665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46878,DS-05342fcd-61de-4291-ba29-b9500d1b9a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-f9f2df7c-9274-42c1-8cb0-81e18e9e8e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-a455469f-b0ac-40ed-8582-1e4a1e394156,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-edab549a-d622-404d-b6dd-76395f91f2af,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-0b3e6d86-1de2-46b3-94ab-5c35e593e0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-a951bce0-ab47-4064-b997-ae992ed38432,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-d61502c2-4602-4ce1-9400-79678a52ca54,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-458c7285-7aea-48de-b488-955ca0953169,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-98570817-172.17.0.9-1595377309665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46878,DS-05342fcd-61de-4291-ba29-b9500d1b9a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-f9f2df7c-9274-42c1-8cb0-81e18e9e8e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-a455469f-b0ac-40ed-8582-1e4a1e394156,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-edab549a-d622-404d-b6dd-76395f91f2af,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-0b3e6d86-1de2-46b3-94ab-5c35e593e0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-a951bce0-ab47-4064-b997-ae992ed38432,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-d61502c2-4602-4ce1-9400-79678a52ca54,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-458c7285-7aea-48de-b488-955ca0953169,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1350530536-172.17.0.9-1595377436335:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46846,DS-b1672e00-3b64-4004-86d2-c6d32274913b,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-763db78b-9ced-4818-af6d-2c967fc82530,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-44c66248-7bcc-49a6-af68-9f0b2b072e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-021c047a-d8e5-4ae8-8173-4d26d7b22509,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-f4a4c482-0c62-41c8-bb4b-728dee10aeed,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-1f92ae2e-70c3-411f-ae35-2952112a4186,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-77923531-2530-4193-8aed-705e825690e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-b501b30f-a7fd-483e-a8a8-3b37dacfd751,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1350530536-172.17.0.9-1595377436335:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46846,DS-b1672e00-3b64-4004-86d2-c6d32274913b,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-763db78b-9ced-4818-af6d-2c967fc82530,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-44c66248-7bcc-49a6-af68-9f0b2b072e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-021c047a-d8e5-4ae8-8173-4d26d7b22509,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-f4a4c482-0c62-41c8-bb4b-728dee10aeed,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-1f92ae2e-70c3-411f-ae35-2952112a4186,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-77923531-2530-4193-8aed-705e825690e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-b501b30f-a7fd-483e-a8a8-3b37dacfd751,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 4818
