reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-844633793-172.17.0.9-1595425360831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46780,DS-8efc1f3d-cead-465f-b5e9-3cd7c3543261,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-d9eb8265-6d69-4ac2-81f8-41bdd9fb2fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-c0bc6af2-90e1-402e-afdb-f0d5031a1b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-51729f4d-77b7-4cfe-8d73-420b3494df9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-681b15ff-535d-4337-9edf-fcba8b2feb28,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-9a0e5ec5-6cb4-438c-8d1b-58fa9de0fcae,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-51699227-ae44-41af-b25a-35c5b4eacd07,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-5acdbbc8-a30d-4546-8908-a5299221ec6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-844633793-172.17.0.9-1595425360831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46780,DS-8efc1f3d-cead-465f-b5e9-3cd7c3543261,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-d9eb8265-6d69-4ac2-81f8-41bdd9fb2fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-c0bc6af2-90e1-402e-afdb-f0d5031a1b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-51729f4d-77b7-4cfe-8d73-420b3494df9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-681b15ff-535d-4337-9edf-fcba8b2feb28,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-9a0e5ec5-6cb4-438c-8d1b-58fa9de0fcae,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-51699227-ae44-41af-b25a-35c5b4eacd07,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-5acdbbc8-a30d-4546-8908-a5299221ec6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1799880583-172.17.0.9-1595425600994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39650,DS-c62e495d-1924-4cfc-96f6-0a9bb7cfcb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-7653c863-574f-4995-a62e-8f6351e188da,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-697c9989-3ca1-48b1-9425-32c780616eed,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-4450795e-3d0a-4bfc-8c3e-296dab75c639,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-29bc337c-882a-4218-9c3c-dbd8435e36b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-2978942a-d5fe-4cc8-afa4-b59382d6c779,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-dbf148e3-c62a-4b64-9c8e-826b574dc44a,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-86fee63f-e057-4e2e-8dab-ec124f431821,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1799880583-172.17.0.9-1595425600994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39650,DS-c62e495d-1924-4cfc-96f6-0a9bb7cfcb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-7653c863-574f-4995-a62e-8f6351e188da,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-697c9989-3ca1-48b1-9425-32c780616eed,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-4450795e-3d0a-4bfc-8c3e-296dab75c639,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-29bc337c-882a-4218-9c3c-dbd8435e36b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-2978942a-d5fe-4cc8-afa4-b59382d6c779,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-dbf148e3-c62a-4b64-9c8e-826b574dc44a,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-86fee63f-e057-4e2e-8dab-ec124f431821,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772610313-172.17.0.9-1595426038254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46197,DS-3a69b330-92ce-4561-acb2-2d27af16f94f,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-d992da5b-9045-4e00-b3e7-0111a30c247f,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-45e429df-fd5e-4a06-a42a-f6f92199f7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-fe1bd860-52e0-4694-a7c8-e634399ab0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-25a00109-20a3-4e88-ba36-32ef0dc4d2de,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-918fe338-53a1-4a52-ac88-c85393de256a,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-b993ffc0-62e1-4336-8012-ef1902bdcd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-8598d257-f2ba-4c67-94c8-25dc10406b1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772610313-172.17.0.9-1595426038254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46197,DS-3a69b330-92ce-4561-acb2-2d27af16f94f,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-d992da5b-9045-4e00-b3e7-0111a30c247f,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-45e429df-fd5e-4a06-a42a-f6f92199f7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-fe1bd860-52e0-4694-a7c8-e634399ab0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-25a00109-20a3-4e88-ba36-32ef0dc4d2de,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-918fe338-53a1-4a52-ac88-c85393de256a,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-b993ffc0-62e1-4336-8012-ef1902bdcd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-8598d257-f2ba-4c67-94c8-25dc10406b1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-605961753-172.17.0.9-1595426095382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39974,DS-867b1374-4eea-41e1-bd3a-f62f29ba9254,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-354239a6-6454-4d0a-9fe5-f3e76d821e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-987e5d05-5b0e-43ff-9f84-11ad434983f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-ac5d19df-098e-43de-9e5f-11890b42044d,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-9d80c87b-e184-4b50-b84a-a03d3a700290,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-1ce8abe6-7ce4-4f16-b3a5-ed66c2d5f691,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-5b0dcec2-7c00-4f0d-89e7-0a6e8b992b68,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-5ca3d343-059b-4cad-9029-9c60c2249c3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-605961753-172.17.0.9-1595426095382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39974,DS-867b1374-4eea-41e1-bd3a-f62f29ba9254,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-354239a6-6454-4d0a-9fe5-f3e76d821e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-987e5d05-5b0e-43ff-9f84-11ad434983f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-ac5d19df-098e-43de-9e5f-11890b42044d,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-9d80c87b-e184-4b50-b84a-a03d3a700290,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-1ce8abe6-7ce4-4f16-b3a5-ed66c2d5f691,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-5b0dcec2-7c00-4f0d-89e7-0a6e8b992b68,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-5ca3d343-059b-4cad-9029-9c60c2249c3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-460455543-172.17.0.9-1595426225877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41425,DS-4ef20ea3-03f8-4f8e-b43f-030167cc713a,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-388e7170-225e-4571-b785-6ebdfde068ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-099dcf77-706d-4be3-9b2d-4060de004abb,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-75b2b4ed-a269-4800-bf5e-e1bd1bf39bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-2ccd6df8-b154-4c11-8ae6-087e45e82032,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-15bdbdee-0334-4f53-b2bd-326e67c5b529,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-2a570a14-2dce-421c-8f6e-b2e8d25c2f13,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-e3d79a02-c44c-4779-b165-67767f42a4fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-460455543-172.17.0.9-1595426225877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41425,DS-4ef20ea3-03f8-4f8e-b43f-030167cc713a,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-388e7170-225e-4571-b785-6ebdfde068ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-099dcf77-706d-4be3-9b2d-4060de004abb,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-75b2b4ed-a269-4800-bf5e-e1bd1bf39bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-2ccd6df8-b154-4c11-8ae6-087e45e82032,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-15bdbdee-0334-4f53-b2bd-326e67c5b529,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-2a570a14-2dce-421c-8f6e-b2e8d25c2f13,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-e3d79a02-c44c-4779-b165-67767f42a4fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-820366918-172.17.0.9-1595426414622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38421,DS-8e6ecb54-84fc-4ffb-bc05-b753a1d59594,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-36b633b5-1d36-41bb-a203-63a6825af228,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-78980cc4-99d7-4112-ac56-ef1725099281,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-7ab423ee-9006-48f3-be10-952b91aea7ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-7c5e1d54-ed00-4cec-a9fb-5616fad4680c,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-e0dd3467-2309-407b-a04b-811bb8864783,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-83794e6a-6855-4157-bc10-f15884904961,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-6d29fe7f-c652-48a1-8bac-fdceb50c5821,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-820366918-172.17.0.9-1595426414622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38421,DS-8e6ecb54-84fc-4ffb-bc05-b753a1d59594,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-36b633b5-1d36-41bb-a203-63a6825af228,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-78980cc4-99d7-4112-ac56-ef1725099281,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-7ab423ee-9006-48f3-be10-952b91aea7ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-7c5e1d54-ed00-4cec-a9fb-5616fad4680c,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-e0dd3467-2309-407b-a04b-811bb8864783,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-83794e6a-6855-4157-bc10-f15884904961,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-6d29fe7f-c652-48a1-8bac-fdceb50c5821,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-542553196-172.17.0.9-1595426835130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46687,DS-9d669d55-988f-4d37-b03a-5860e7794a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-8084ec29-b8d3-4342-8e93-106c4b2f3d38,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-0d038db8-d242-4c73-89e5-15c07ff40cca,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-959dd3cb-3850-4e53-a422-4e00a24105b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-e2c2774e-1f56-45aa-bc88-a1d5b84ab65b,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-7730fed3-5432-4831-95b2-a9e6040517b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-a4bf3452-085b-4a28-9e0e-41c344e0e9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-4399a784-e238-4c43-a61e-780bdeea9f94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-542553196-172.17.0.9-1595426835130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46687,DS-9d669d55-988f-4d37-b03a-5860e7794a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-8084ec29-b8d3-4342-8e93-106c4b2f3d38,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-0d038db8-d242-4c73-89e5-15c07ff40cca,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-959dd3cb-3850-4e53-a422-4e00a24105b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-e2c2774e-1f56-45aa-bc88-a1d5b84ab65b,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-7730fed3-5432-4831-95b2-a9e6040517b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-a4bf3452-085b-4a28-9e0e-41c344e0e9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-4399a784-e238-4c43-a61e-780bdeea9f94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1382857876-172.17.0.9-1595426930741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39119,DS-1f349573-5dc3-40e7-85d7-557bbae68a02,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-7af35a63-8151-43bf-8347-644e0f116c34,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-09bfbe01-82eb-4e8c-98c8-b21f7ff6c5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-03c39af7-1d6f-40be-8eb6-803f13f3f98d,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-03ac7b72-b7a1-476b-8e4d-ce9b1eb01070,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-6d03dd63-7f04-4707-ace7-d7932753a913,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-8a666a8e-8f7d-4d5b-a356-fb79433484ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-c15c21fd-dbe5-4c5e-92fd-02de6d19fb49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1382857876-172.17.0.9-1595426930741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39119,DS-1f349573-5dc3-40e7-85d7-557bbae68a02,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-7af35a63-8151-43bf-8347-644e0f116c34,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-09bfbe01-82eb-4e8c-98c8-b21f7ff6c5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-03c39af7-1d6f-40be-8eb6-803f13f3f98d,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-03ac7b72-b7a1-476b-8e4d-ce9b1eb01070,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-6d03dd63-7f04-4707-ace7-d7932753a913,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-8a666a8e-8f7d-4d5b-a356-fb79433484ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-c15c21fd-dbe5-4c5e-92fd-02de6d19fb49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599653508-172.17.0.9-1595427017845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44436,DS-36a4ffb0-0ce8-419b-b909-59be6162571f,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-14437691-d732-4ee8-be4b-468631b5805a,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-e522733b-f4d8-4a97-b06e-74ce46153624,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-a404cfb0-053a-4b10-85a9-b844327edf53,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-b2ccfdcb-6ecf-43f6-9587-36416c8b4b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-3faf92f5-9fd8-44de-b9a0-e8f46e26732d,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-d487a251-56bf-4225-b7a1-2ff738f4bec3,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-f406d6a5-9df7-4486-9e40-dcc35f62eca0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599653508-172.17.0.9-1595427017845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44436,DS-36a4ffb0-0ce8-419b-b909-59be6162571f,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-14437691-d732-4ee8-be4b-468631b5805a,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-e522733b-f4d8-4a97-b06e-74ce46153624,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-a404cfb0-053a-4b10-85a9-b844327edf53,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-b2ccfdcb-6ecf-43f6-9587-36416c8b4b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-3faf92f5-9fd8-44de-b9a0-e8f46e26732d,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-d487a251-56bf-4225-b7a1-2ff738f4bec3,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-f406d6a5-9df7-4486-9e40-dcc35f62eca0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1562577934-172.17.0.9-1595427191431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38844,DS-bd804235-8cb7-4efb-9227-ef27d5084a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-85a232c3-6b58-457a-a2a9-37402d85f054,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-e3935911-8157-41f4-8ff9-cf14046d3851,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-e091eb10-50cb-418e-b688-3318e930336a,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-fc1137ef-ee54-44cf-8304-5745ffe85631,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-19c5d7ec-0235-421f-a48c-636a0b2578a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-c28696d4-dfc3-481a-8ba0-4101fec2d79a,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-0dbaa2bb-b3df-41f5-8db5-9e933bdc6ad6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1562577934-172.17.0.9-1595427191431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38844,DS-bd804235-8cb7-4efb-9227-ef27d5084a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-85a232c3-6b58-457a-a2a9-37402d85f054,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-e3935911-8157-41f4-8ff9-cf14046d3851,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-e091eb10-50cb-418e-b688-3318e930336a,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-fc1137ef-ee54-44cf-8304-5745ffe85631,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-19c5d7ec-0235-421f-a48c-636a0b2578a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-c28696d4-dfc3-481a-8ba0-4101fec2d79a,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-0dbaa2bb-b3df-41f5-8db5-9e933bdc6ad6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707205152-172.17.0.9-1595427758460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34338,DS-4ce9f379-ae41-4ead-86f7-8f585349bdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-d050ef1c-2ee4-4fa2-aeb3-d3f01cc38ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-ee89e711-b6c1-4ccc-9b42-7a27be57d6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-e85ef0d0-c11e-47a3-9cb1-2546ca4be8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-5bb1168e-2022-4d81-93c3-2e487dc1748e,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-946a27a7-d499-45fd-baf2-880d97aa063b,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-dab7cab7-b7b2-498c-9b87-3f366cefb11a,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-e1aed18b-11d9-4e67-8410-c7e4e7d4d0b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707205152-172.17.0.9-1595427758460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34338,DS-4ce9f379-ae41-4ead-86f7-8f585349bdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-d050ef1c-2ee4-4fa2-aeb3-d3f01cc38ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-ee89e711-b6c1-4ccc-9b42-7a27be57d6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-e85ef0d0-c11e-47a3-9cb1-2546ca4be8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-5bb1168e-2022-4d81-93c3-2e487dc1748e,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-946a27a7-d499-45fd-baf2-880d97aa063b,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-dab7cab7-b7b2-498c-9b87-3f366cefb11a,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-e1aed18b-11d9-4e67-8410-c7e4e7d4d0b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1868892894-172.17.0.9-1595427879091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36656,DS-30a9ee32-7d56-4056-afe1-0b5e22f00814,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-7869be6f-4477-4358-8db8-fd795a369c55,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-9f597b25-f3c1-48ea-b73a-5e147b8f23f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-8e8d1292-bdf7-42f5-8c0b-794f487b2055,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-e0115edc-eb20-4077-b43b-1586abe5cbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-af7cb92c-b4a2-4f07-9602-d2bc29bf0bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-86c103d6-cbf1-46c3-9cc9-03819b7fb5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-63300cc0-41f2-48b1-a5e7-936797c83d0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1868892894-172.17.0.9-1595427879091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36656,DS-30a9ee32-7d56-4056-afe1-0b5e22f00814,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-7869be6f-4477-4358-8db8-fd795a369c55,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-9f597b25-f3c1-48ea-b73a-5e147b8f23f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-8e8d1292-bdf7-42f5-8c0b-794f487b2055,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-e0115edc-eb20-4077-b43b-1586abe5cbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-af7cb92c-b4a2-4f07-9602-d2bc29bf0bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-86c103d6-cbf1-46c3-9cc9-03819b7fb5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-63300cc0-41f2-48b1-a5e7-936797c83d0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1658298798-172.17.0.9-1595428005094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41854,DS-9d39dcf6-c38e-4323-a88a-657d48ce8982,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-8154b007-7b5d-4d5c-83eb-5321b44552f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-ba9a1465-eedc-4dd0-90ea-b2a71b43ea56,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-8285b521-7ef6-4d51-9ba3-26d2ca36fc06,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-0de402e3-5141-4dce-a97c-122b79dca8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-e59dc016-6546-4809-94c5-b30206d37fad,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-d5d5fde0-746d-4d98-8abc-4a84b0dd6340,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-644e44ed-774c-45c7-857d-a76a327bba46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1658298798-172.17.0.9-1595428005094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41854,DS-9d39dcf6-c38e-4323-a88a-657d48ce8982,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-8154b007-7b5d-4d5c-83eb-5321b44552f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-ba9a1465-eedc-4dd0-90ea-b2a71b43ea56,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-8285b521-7ef6-4d51-9ba3-26d2ca36fc06,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-0de402e3-5141-4dce-a97c-122b79dca8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-e59dc016-6546-4809-94c5-b30206d37fad,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-d5d5fde0-746d-4d98-8abc-4a84b0dd6340,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-644e44ed-774c-45c7-857d-a76a327bba46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483807022-172.17.0.9-1595428724953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41373,DS-379f500c-a1b7-410c-a547-5226e89c24b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-6ff264a5-dbc3-4ec6-ade1-8cd517f08f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-3ec95d05-ad8d-4c80-b398-822df8394055,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-ef0a907f-5c95-4a18-9097-795d2d1c9c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-1f622023-3044-43c8-b3ea-d4434221fe6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-647b96a5-da98-4011-8db3-510977658a55,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-27eadc55-e5b8-4c05-9807-d0517df71dca,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-9daf8ac7-89c3-4d94-b6aa-1a7cdb0449bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483807022-172.17.0.9-1595428724953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41373,DS-379f500c-a1b7-410c-a547-5226e89c24b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-6ff264a5-dbc3-4ec6-ade1-8cd517f08f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-3ec95d05-ad8d-4c80-b398-822df8394055,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-ef0a907f-5c95-4a18-9097-795d2d1c9c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-1f622023-3044-43c8-b3ea-d4434221fe6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-647b96a5-da98-4011-8db3-510977658a55,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-27eadc55-e5b8-4c05-9807-d0517df71dca,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-9daf8ac7-89c3-4d94-b6aa-1a7cdb0449bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-639640801-172.17.0.9-1595429106413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44765,DS-114f446e-ef86-44aa-ac8f-b508472d9b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-869eeb23-934e-4472-9972-30115a86204c,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-ff83e7ca-8dee-4db1-93b3-3a11da37bbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-427ca3eb-fb43-4659-ac7c-f5a1ecf88aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-53847551-42df-440c-89f9-0ffd970e8c35,DISK], DatanodeInfoWithStorage[127.0.0.1:33541,DS-432c0110-2620-448a-b5f8-cdcf7d92cee9,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-670db09e-62b9-42f1-936c-53bcce568a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-89a691a8-2425-4493-bf7d-6c323e4c0e8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-639640801-172.17.0.9-1595429106413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44765,DS-114f446e-ef86-44aa-ac8f-b508472d9b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-869eeb23-934e-4472-9972-30115a86204c,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-ff83e7ca-8dee-4db1-93b3-3a11da37bbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-427ca3eb-fb43-4659-ac7c-f5a1ecf88aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-53847551-42df-440c-89f9-0ffd970e8c35,DISK], DatanodeInfoWithStorage[127.0.0.1:33541,DS-432c0110-2620-448a-b5f8-cdcf7d92cee9,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-670db09e-62b9-42f1-936c-53bcce568a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-89a691a8-2425-4493-bf7d-6c323e4c0e8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1576982766-172.17.0.9-1595429780692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46311,DS-ef2547cf-dee7-49e9-8177-6d9c0380aefa,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-f1219164-867a-4e4a-8412-50c98a9958d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-ebb20a73-b17a-48cf-bab6-8246cd40793e,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-7b3e0bd3-843c-4ca7-be5d-23c3d3a9da66,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-bc7ecc05-a6e9-4a73-b64d-5142204bd0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-0cce7701-e38a-4b7e-a378-f32bafa2c59d,DISK], DatanodeInfoWithStorage[127.0.0.1:32999,DS-c0b7ddb1-f2fd-48ae-93d6-f03651f632af,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-49a3c576-750e-4201-b67d-52298cd5fbac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1576982766-172.17.0.9-1595429780692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46311,DS-ef2547cf-dee7-49e9-8177-6d9c0380aefa,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-f1219164-867a-4e4a-8412-50c98a9958d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-ebb20a73-b17a-48cf-bab6-8246cd40793e,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-7b3e0bd3-843c-4ca7-be5d-23c3d3a9da66,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-bc7ecc05-a6e9-4a73-b64d-5142204bd0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-0cce7701-e38a-4b7e-a378-f32bafa2c59d,DISK], DatanodeInfoWithStorage[127.0.0.1:32999,DS-c0b7ddb1-f2fd-48ae-93d6-f03651f632af,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-49a3c576-750e-4201-b67d-52298cd5fbac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-366977784-172.17.0.9-1595430437995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44841,DS-b10558f0-ade2-4288-9193-a4959046e7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-e90dd977-4dc1-40d5-a63e-101c5aa61118,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-7305ef1b-9068-4641-b2c9-912a66cf16e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-f6cdd7a8-1b37-4354-8e77-40207df7f2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-6d671c17-b3d8-4820-9a5a-adcad2575206,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-e59b513e-dc6e-4b62-b84d-ddf837b168b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-b8b89e22-422e-4a3e-bb47-27db93a9bc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-64896197-0a0c-4c02-ad9f-acafb9e81a6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-366977784-172.17.0.9-1595430437995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44841,DS-b10558f0-ade2-4288-9193-a4959046e7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-e90dd977-4dc1-40d5-a63e-101c5aa61118,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-7305ef1b-9068-4641-b2c9-912a66cf16e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-f6cdd7a8-1b37-4354-8e77-40207df7f2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-6d671c17-b3d8-4820-9a5a-adcad2575206,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-e59b513e-dc6e-4b62-b84d-ddf837b168b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-b8b89e22-422e-4a3e-bb47-27db93a9bc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-64896197-0a0c-4c02-ad9f-acafb9e81a6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418589529-172.17.0.9-1595430876301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34700,DS-727323d2-4ac4-4320-bcbd-8f1799768229,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-dee03731-fef6-48f1-a77a-e58014718577,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-b7e2a53e-fe23-4ed4-b0ee-f0984216405a,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-6df3b5c8-279a-4dde-9bae-4d1678d5a9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-52f94186-39bc-47e9-a579-2013ca6f14a6,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-55c600d6-b776-404e-8e0b-674351c37e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-fb983552-624c-4134-9b12-2b38a2aee350,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-c791d327-dc88-4370-af04-923b07c6973b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418589529-172.17.0.9-1595430876301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34700,DS-727323d2-4ac4-4320-bcbd-8f1799768229,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-dee03731-fef6-48f1-a77a-e58014718577,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-b7e2a53e-fe23-4ed4-b0ee-f0984216405a,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-6df3b5c8-279a-4dde-9bae-4d1678d5a9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-52f94186-39bc-47e9-a579-2013ca6f14a6,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-55c600d6-b776-404e-8e0b-674351c37e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-fb983552-624c-4134-9b12-2b38a2aee350,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-c791d327-dc88-4370-af04-923b07c6973b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2119835484-172.17.0.9-1595431236620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35696,DS-5e386a25-67ec-4b3f-b312-ecb020790423,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-9047ba1e-c532-45bd-96d2-d1eaf49dc2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-f23b714d-966f-4aa1-a95a-674f7e6effdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-f58614af-895a-45e0-996c-7501d22d99cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-53df93e4-d3f7-4214-8b17-f8e5d0cb48ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-8d2e98d3-d8c3-43a6-bba7-7331c496842d,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-70d387bc-7a59-4adb-ab97-205cd0b39849,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-7a71eef8-6e48-4b15-b9ff-9f209992e9b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2119835484-172.17.0.9-1595431236620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35696,DS-5e386a25-67ec-4b3f-b312-ecb020790423,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-9047ba1e-c532-45bd-96d2-d1eaf49dc2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-f23b714d-966f-4aa1-a95a-674f7e6effdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-f58614af-895a-45e0-996c-7501d22d99cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-53df93e4-d3f7-4214-8b17-f8e5d0cb48ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-8d2e98d3-d8c3-43a6-bba7-7331c496842d,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-70d387bc-7a59-4adb-ab97-205cd0b39849,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-7a71eef8-6e48-4b15-b9ff-9f209992e9b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1205906952-172.17.0.9-1595431431002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40030,DS-dec5b61e-cb6d-45d5-877a-56f3532d225f,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-50c9a1c1-a0e6-4a80-804b-311188a56247,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-92dd2fe1-8990-46b2-bd5f-5e811f4591e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-2e0fb571-d68d-4c2e-9817-a10cacf782fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-12321d71-57a8-4b1c-b113-3941ede8911d,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-450ebabe-30e3-4976-9030-574b25c2c09c,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-1e20cda0-4a5f-4631-a7ca-a63cab5ee8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34784,DS-1dd0e684-398f-40d8-ac76-8e1b9523d0b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1205906952-172.17.0.9-1595431431002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40030,DS-dec5b61e-cb6d-45d5-877a-56f3532d225f,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-50c9a1c1-a0e6-4a80-804b-311188a56247,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-92dd2fe1-8990-46b2-bd5f-5e811f4591e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-2e0fb571-d68d-4c2e-9817-a10cacf782fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-12321d71-57a8-4b1c-b113-3941ede8911d,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-450ebabe-30e3-4976-9030-574b25c2c09c,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-1e20cda0-4a5f-4631-a7ca-a63cab5ee8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34784,DS-1dd0e684-398f-40d8-ac76-8e1b9523d0b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2080625680-172.17.0.9-1595431472216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39104,DS-e5179e29-cbdf-42b9-8159-b2f121ae2810,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-c8c39a5e-1ee3-4d3f-9b9b-828a0dd92138,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-0102760c-c33b-4ab6-9172-05535a338cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-e2d31c47-a40b-4322-a278-5b2decc7cf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-6e87492c-cd51-45e7-9589-810cd354507c,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-26c9fbb5-8b34-416b-ba69-42f3178d2712,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-435e9913-3e22-4e36-9d27-a40e62cf9b82,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-73a2cba7-dcb8-4a89-83c4-5212f42df920,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2080625680-172.17.0.9-1595431472216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39104,DS-e5179e29-cbdf-42b9-8159-b2f121ae2810,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-c8c39a5e-1ee3-4d3f-9b9b-828a0dd92138,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-0102760c-c33b-4ab6-9172-05535a338cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-e2d31c47-a40b-4322-a278-5b2decc7cf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-6e87492c-cd51-45e7-9589-810cd354507c,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-26c9fbb5-8b34-416b-ba69-42f3178d2712,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-435e9913-3e22-4e36-9d27-a40e62cf9b82,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-73a2cba7-dcb8-4a89-83c4-5212f42df920,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 6777
