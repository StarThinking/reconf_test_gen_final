reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-643744333-172.17.0.7-1595329018982:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35279,DS-03402a96-6b3f-4a7c-aa86-6143c9ba9e59,DISK], DatanodeInfoWithStorage[127.0.0.1:43506,DS-097c923e-09dc-460e-9f45-7e2c1ad1b0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-1c22cdf7-da34-41a0-8ed0-51be3e137114,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-c818a0d9-ef35-4bf0-9de6-29277f29da90,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-2cd12a38-f770-4c98-a3d5-72d2b8abec04,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-0ad98e51-f0da-4040-9736-9cae6437f994,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-07c73a56-379f-45bb-8578-54d33693d8da,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-bad20b7b-9f72-4203-9caf-acdc2d5b8237,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-643744333-172.17.0.7-1595329018982:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35279,DS-03402a96-6b3f-4a7c-aa86-6143c9ba9e59,DISK], DatanodeInfoWithStorage[127.0.0.1:43506,DS-097c923e-09dc-460e-9f45-7e2c1ad1b0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-1c22cdf7-da34-41a0-8ed0-51be3e137114,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-c818a0d9-ef35-4bf0-9de6-29277f29da90,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-2cd12a38-f770-4c98-a3d5-72d2b8abec04,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-0ad98e51-f0da-4040-9736-9cae6437f994,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-07c73a56-379f-45bb-8578-54d33693d8da,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-bad20b7b-9f72-4203-9caf-acdc2d5b8237,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1142049520-172.17.0.7-1595329167039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37666,DS-9a151686-0bcc-4898-92c9-6cc3097aa7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-0df20cb4-fb45-4c9f-bb8f-988e5d5b90ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-417adf9c-6072-4142-8cee-1490fea49181,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-7518a21b-4232-44de-b047-65ed9f9709b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-85176d02-ac9e-4b6f-93bb-8b825ffaeff1,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-e2bf3030-eb1e-4b45-bd13-1c33341fb246,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-ffdd267f-4752-4894-a6e5-e2d9f1d03fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-510f51be-c3cf-43c2-bf7a-6cc005604810,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1142049520-172.17.0.7-1595329167039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37666,DS-9a151686-0bcc-4898-92c9-6cc3097aa7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-0df20cb4-fb45-4c9f-bb8f-988e5d5b90ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-417adf9c-6072-4142-8cee-1490fea49181,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-7518a21b-4232-44de-b047-65ed9f9709b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-85176d02-ac9e-4b6f-93bb-8b825ffaeff1,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-e2bf3030-eb1e-4b45-bd13-1c33341fb246,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-ffdd267f-4752-4894-a6e5-e2d9f1d03fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-510f51be-c3cf-43c2-bf7a-6cc005604810,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1660533578-172.17.0.7-1595329236607:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38922,DS-04620dd2-5f87-41db-bbc6-1d017ecfd87f,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-216bdc5f-21bf-4944-9e7c-80ee7edf6439,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-74703e67-8250-4603-9842-4e30b547ae3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-7348fd90-3c16-4253-aa8a-611193490762,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-524b486f-00f1-47c0-8f9e-df7e26d39446,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-e31d0a51-c7a8-466b-a168-af2a218bbbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-b9a564bd-9112-4bfe-810d-5ded5489de35,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-58669bd1-29b8-42f5-a1db-958c5a57dcd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1660533578-172.17.0.7-1595329236607:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38922,DS-04620dd2-5f87-41db-bbc6-1d017ecfd87f,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-216bdc5f-21bf-4944-9e7c-80ee7edf6439,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-74703e67-8250-4603-9842-4e30b547ae3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-7348fd90-3c16-4253-aa8a-611193490762,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-524b486f-00f1-47c0-8f9e-df7e26d39446,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-e31d0a51-c7a8-466b-a168-af2a218bbbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-b9a564bd-9112-4bfe-810d-5ded5489de35,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-58669bd1-29b8-42f5-a1db-958c5a57dcd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1879289562-172.17.0.7-1595329535829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34502,DS-c03d4a42-e25f-4468-a69d-9e1b7a91ccc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-d034f420-f99b-4458-8d47-2655e8e039b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41627,DS-596ea8e2-079f-4056-bd9c-0d9ee0cbf6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-12d8761f-bbcc-4df9-907c-e70c51988236,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-772cc13d-152a-4ede-8304-85781b6efcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-30ad8831-fa8f-44bf-bfa6-e1500ddd2b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-77857c25-95ff-4a27-b72e-6019c61791c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-5c599bd5-41fb-4f43-bd47-0542f833f79f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1879289562-172.17.0.7-1595329535829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34502,DS-c03d4a42-e25f-4468-a69d-9e1b7a91ccc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-d034f420-f99b-4458-8d47-2655e8e039b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41627,DS-596ea8e2-079f-4056-bd9c-0d9ee0cbf6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-12d8761f-bbcc-4df9-907c-e70c51988236,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-772cc13d-152a-4ede-8304-85781b6efcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-30ad8831-fa8f-44bf-bfa6-e1500ddd2b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-77857c25-95ff-4a27-b72e-6019c61791c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-5c599bd5-41fb-4f43-bd47-0542f833f79f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-893662811-172.17.0.7-1595329653426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46200,DS-f759ef4c-115a-4fdc-b485-aaadbcc3512a,DISK], DatanodeInfoWithStorage[127.0.0.1:45198,DS-4323b66d-ee2e-42d4-bd53-0a9758e86989,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-3db33d4b-49e7-474e-be7a-bf51c1ecb0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33776,DS-c40cf7d6-1ca0-48f2-ab30-39a3dbefd636,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-67543200-ed2e-4575-b54f-47629eacb679,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-9aa59bb1-361e-486a-8b85-1d91758eb933,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-45b62005-2232-4230-a575-743f13bd0ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-72c511df-29d1-4fcc-be68-0f12bc7d1882,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-893662811-172.17.0.7-1595329653426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46200,DS-f759ef4c-115a-4fdc-b485-aaadbcc3512a,DISK], DatanodeInfoWithStorage[127.0.0.1:45198,DS-4323b66d-ee2e-42d4-bd53-0a9758e86989,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-3db33d4b-49e7-474e-be7a-bf51c1ecb0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33776,DS-c40cf7d6-1ca0-48f2-ab30-39a3dbefd636,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-67543200-ed2e-4575-b54f-47629eacb679,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-9aa59bb1-361e-486a-8b85-1d91758eb933,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-45b62005-2232-4230-a575-743f13bd0ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-72c511df-29d1-4fcc-be68-0f12bc7d1882,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1300631649-172.17.0.7-1595330362931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39044,DS-d5392861-5ee6-4977-b713-51cc004d2d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-4f365dd1-a04f-489c-9f37-8fc39ad6af83,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-4aed4549-ca38-4d6c-9b7f-b9760b1bf2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-bc954033-3727-48a7-b27b-5706a3710061,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-64c8e221-3014-4527-b7b9-e283e2a5ebb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-0fc08061-3085-4a2e-a908-21832d919742,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-95681855-6f58-41ef-b283-9ca42c7c34f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-4688163a-e49d-48dc-9c18-5ca5db4498f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1300631649-172.17.0.7-1595330362931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39044,DS-d5392861-5ee6-4977-b713-51cc004d2d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-4f365dd1-a04f-489c-9f37-8fc39ad6af83,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-4aed4549-ca38-4d6c-9b7f-b9760b1bf2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-bc954033-3727-48a7-b27b-5706a3710061,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-64c8e221-3014-4527-b7b9-e283e2a5ebb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-0fc08061-3085-4a2e-a908-21832d919742,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-95681855-6f58-41ef-b283-9ca42c7c34f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-4688163a-e49d-48dc-9c18-5ca5db4498f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-650907710-172.17.0.7-1595330407627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40197,DS-6b83a037-d23e-47be-9518-cebdd1493ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-0ebed1e4-2400-482c-aded-4f8c924cdf04,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-cbb10f71-9560-4881-8764-a3ff64d9c842,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-7dc43f39-4b0b-4422-a01e-f8908e6960d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-d91ba748-a316-4363-b145-be7fd821245f,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-8e3d9f45-8a69-438d-8462-dd2a6de06b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-b5156335-72bd-45ab-945b-1a60c7dd97e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-c8394cde-ebcf-48c2-8311-c9c4c106ef95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-650907710-172.17.0.7-1595330407627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40197,DS-6b83a037-d23e-47be-9518-cebdd1493ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-0ebed1e4-2400-482c-aded-4f8c924cdf04,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-cbb10f71-9560-4881-8764-a3ff64d9c842,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-7dc43f39-4b0b-4422-a01e-f8908e6960d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-d91ba748-a316-4363-b145-be7fd821245f,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-8e3d9f45-8a69-438d-8462-dd2a6de06b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-b5156335-72bd-45ab-945b-1a60c7dd97e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-c8394cde-ebcf-48c2-8311-c9c4c106ef95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2106645014-172.17.0.7-1595330550505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35847,DS-89831a6c-0f92-4780-95be-5454ed7f70be,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-47748512-fafe-4762-a9a9-1d68055094d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-3baded49-db75-47b6-b405-c1d61dc4ba4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-eaf36d70-8da3-47fe-a5b4-7631ed19bc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-3a31f85e-4b7c-45b1-8b85-84c62d42bc33,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-32faa246-5513-4a7f-aaf7-7e7a84437eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-28220633-396b-4e5c-8624-bd0f1c88b05f,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-d682ecb6-4d6c-44da-905a-9dc266b3097f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2106645014-172.17.0.7-1595330550505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35847,DS-89831a6c-0f92-4780-95be-5454ed7f70be,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-47748512-fafe-4762-a9a9-1d68055094d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-3baded49-db75-47b6-b405-c1d61dc4ba4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-eaf36d70-8da3-47fe-a5b4-7631ed19bc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-3a31f85e-4b7c-45b1-8b85-84c62d42bc33,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-32faa246-5513-4a7f-aaf7-7e7a84437eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-28220633-396b-4e5c-8624-bd0f1c88b05f,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-d682ecb6-4d6c-44da-905a-9dc266b3097f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-216832103-172.17.0.7-1595331197518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36920,DS-22c42c26-d4b7-404e-8485-c839fa8be594,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-15d26c85-dd27-429a-b846-819baa198f89,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-0a20ebc0-65b6-4d96-9bae-3f8a0f51a660,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-60de0a72-f928-456d-be09-617889ebf780,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-6466509d-4d2c-4b62-93dd-42c64105f8be,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-4f7e715c-fde7-47ce-bc5a-60947e463dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-c34ce1ae-953e-45be-8494-c6230e7d3b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-3854b167-8968-4b01-b8e8-33a19828ec3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-216832103-172.17.0.7-1595331197518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36920,DS-22c42c26-d4b7-404e-8485-c839fa8be594,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-15d26c85-dd27-429a-b846-819baa198f89,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-0a20ebc0-65b6-4d96-9bae-3f8a0f51a660,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-60de0a72-f928-456d-be09-617889ebf780,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-6466509d-4d2c-4b62-93dd-42c64105f8be,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-4f7e715c-fde7-47ce-bc5a-60947e463dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-c34ce1ae-953e-45be-8494-c6230e7d3b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-3854b167-8968-4b01-b8e8-33a19828ec3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-941741028-172.17.0.7-1595331341236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38858,DS-88b7bad7-f3a1-4353-8199-0279e455529c,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-b02a8881-7724-477d-9732-a82560d587a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-e0b6356d-d996-4ade-bc2a-d9b834db4675,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-4c0d252f-3acd-4627-b2ac-b4f571f362a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-668a0abf-16d9-492d-aa0b-cdb95e1ffb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-98425f05-1ab8-4a65-8556-11c3d4743184,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-cf7b310a-7bb1-4488-bd8b-d2e8a8443a39,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-385f1db6-ed7f-43b3-aed1-2b9c88b49567,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-941741028-172.17.0.7-1595331341236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38858,DS-88b7bad7-f3a1-4353-8199-0279e455529c,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-b02a8881-7724-477d-9732-a82560d587a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-e0b6356d-d996-4ade-bc2a-d9b834db4675,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-4c0d252f-3acd-4627-b2ac-b4f571f362a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-668a0abf-16d9-492d-aa0b-cdb95e1ffb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-98425f05-1ab8-4a65-8556-11c3d4743184,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-cf7b310a-7bb1-4488-bd8b-d2e8a8443a39,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-385f1db6-ed7f-43b3-aed1-2b9c88b49567,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1925991203-172.17.0.7-1595333049734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37265,DS-148f5682-ee22-48c8-8771-d5fa231fd369,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-33f42357-9fd4-4b55-b708-ad9cea342e60,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-8ebbfd7a-6193-46d2-b904-9d6031c87666,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-e9300994-3b11-4c18-b781-784a96706783,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-1fc8c862-2685-48ae-a628-adfcd0428a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-07314343-0a47-4299-a634-488eefad33ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-f3a8864c-fb54-41cc-bfda-924d661380f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-8c3f72ad-7d83-405f-a0b9-9b8032a773f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1925991203-172.17.0.7-1595333049734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37265,DS-148f5682-ee22-48c8-8771-d5fa231fd369,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-33f42357-9fd4-4b55-b708-ad9cea342e60,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-8ebbfd7a-6193-46d2-b904-9d6031c87666,DISK], DatanodeInfoWithStorage[127.0.0.1:43701,DS-e9300994-3b11-4c18-b781-784a96706783,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-1fc8c862-2685-48ae-a628-adfcd0428a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-07314343-0a47-4299-a634-488eefad33ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-f3a8864c-fb54-41cc-bfda-924d661380f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-8c3f72ad-7d83-405f-a0b9-9b8032a773f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-173481188-172.17.0.7-1595333296438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45707,DS-500b3fc5-c08b-482f-a449-452f891fe64b,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-e11a239c-a6ee-44e0-98dd-3ebd514ab3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-a4389f96-e6df-4f30-8d27-032a256c6da4,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-ea120eb8-406a-406c-859d-75e32db0b87c,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-338699a9-ebcc-40bd-805e-7dccf121c458,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-727c526b-afb1-41dc-83b7-95a3f660a53f,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-6f9ea16c-06d0-457a-b1f5-7403ff5ef447,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-94c63f10-07f8-441e-8ec0-7baecfff1b1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-173481188-172.17.0.7-1595333296438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45707,DS-500b3fc5-c08b-482f-a449-452f891fe64b,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-e11a239c-a6ee-44e0-98dd-3ebd514ab3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-a4389f96-e6df-4f30-8d27-032a256c6da4,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-ea120eb8-406a-406c-859d-75e32db0b87c,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-338699a9-ebcc-40bd-805e-7dccf121c458,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-727c526b-afb1-41dc-83b7-95a3f660a53f,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-6f9ea16c-06d0-457a-b1f5-7403ff5ef447,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-94c63f10-07f8-441e-8ec0-7baecfff1b1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-378718578-172.17.0.7-1595333371626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36239,DS-7cdeda11-631a-4950-badb-2034e908b0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-9363be55-9f44-43d7-adc0-c4b277a110a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-ffc857d3-f904-4192-8898-bffe3c796c58,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-b5308287-dd50-44c4-9aa3-d4452a9c015a,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-d4274082-e4e9-472b-ad4f-60634ff15bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-9d7b56a0-e03e-4b2a-8f29-24fb89ad3b33,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-eeb1addb-b78e-47d9-9f2c-7d927afe6cee,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-229793a6-0a25-4023-b28d-ec3122473933,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-378718578-172.17.0.7-1595333371626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36239,DS-7cdeda11-631a-4950-badb-2034e908b0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-9363be55-9f44-43d7-adc0-c4b277a110a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-ffc857d3-f904-4192-8898-bffe3c796c58,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-b5308287-dd50-44c4-9aa3-d4452a9c015a,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-d4274082-e4e9-472b-ad4f-60634ff15bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-9d7b56a0-e03e-4b2a-8f29-24fb89ad3b33,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-eeb1addb-b78e-47d9-9f2c-7d927afe6cee,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-229793a6-0a25-4023-b28d-ec3122473933,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-827539163-172.17.0.7-1595333557375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45509,DS-29e1e0ea-d72f-4b76-8361-e586a819592d,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-c8f62487-0fe6-45e7-8a15-9183f96da9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-fb01ae66-aaea-4c74-a610-9c62eb81b7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-773466f9-63fb-464d-a784-f9c49386b64d,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-60a176a1-1941-49ff-b9e4-0755fe2aa401,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-fa00b1bb-cab6-436b-b2b0-1e56da20e03f,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-43812843-c882-4c06-8a14-b877f0d6b7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-1bbb3614-c601-4e2a-937a-fa7fed3946bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-827539163-172.17.0.7-1595333557375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45509,DS-29e1e0ea-d72f-4b76-8361-e586a819592d,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-c8f62487-0fe6-45e7-8a15-9183f96da9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-fb01ae66-aaea-4c74-a610-9c62eb81b7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-773466f9-63fb-464d-a784-f9c49386b64d,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-60a176a1-1941-49ff-b9e4-0755fe2aa401,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-fa00b1bb-cab6-436b-b2b0-1e56da20e03f,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-43812843-c882-4c06-8a14-b877f0d6b7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-1bbb3614-c601-4e2a-937a-fa7fed3946bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1774074777-172.17.0.7-1595333847534:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41295,DS-0350bca2-a39d-4b61-973d-0842fa1f825b,DISK], DatanodeInfoWithStorage[127.0.0.1:32970,DS-100d347d-e960-4a1a-b456-a53fe0a08f30,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-d532e1b1-08b9-44a9-a105-14ea63d2bc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-b1118e42-f04f-4ccd-b801-08296931287b,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-30547f18-8890-4b99-aa41-7da244edd783,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-4f3b9319-ac5b-4055-ae3c-19172d779364,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-1cd27d01-3141-4305-ae0b-16a30ce41e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-5c0f6a7d-de9e-4ad2-92a4-043dd2a06236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1774074777-172.17.0.7-1595333847534:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41295,DS-0350bca2-a39d-4b61-973d-0842fa1f825b,DISK], DatanodeInfoWithStorage[127.0.0.1:32970,DS-100d347d-e960-4a1a-b456-a53fe0a08f30,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-d532e1b1-08b9-44a9-a105-14ea63d2bc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39017,DS-b1118e42-f04f-4ccd-b801-08296931287b,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-30547f18-8890-4b99-aa41-7da244edd783,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-4f3b9319-ac5b-4055-ae3c-19172d779364,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-1cd27d01-3141-4305-ae0b-16a30ce41e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-5c0f6a7d-de9e-4ad2-92a4-043dd2a06236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1635876045-172.17.0.7-1595334026896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38415,DS-0b7e58e8-ac0a-48aa-a202-d6eb8d87fcfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-f26a3325-7438-4aad-a53f-33730398529e,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-5ece9d9b-048d-42ee-a646-8fcdc129c09d,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-ba64bb22-18f6-45d7-a7ae-91601ea456a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-6cc144a4-782e-4a12-b235-03bf82e243e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-6a12a1a7-89be-40f6-a8b6-0aa2549d9d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-e61bd99b-7cf4-498b-b0e4-c5d054913a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-cad7fb06-5eb3-47a3-b40b-59b8ada97441,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1635876045-172.17.0.7-1595334026896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38415,DS-0b7e58e8-ac0a-48aa-a202-d6eb8d87fcfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-f26a3325-7438-4aad-a53f-33730398529e,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-5ece9d9b-048d-42ee-a646-8fcdc129c09d,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-ba64bb22-18f6-45d7-a7ae-91601ea456a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-6cc144a4-782e-4a12-b235-03bf82e243e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-6a12a1a7-89be-40f6-a8b6-0aa2549d9d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-e61bd99b-7cf4-498b-b0e4-c5d054913a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-cad7fb06-5eb3-47a3-b40b-59b8ada97441,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5422
