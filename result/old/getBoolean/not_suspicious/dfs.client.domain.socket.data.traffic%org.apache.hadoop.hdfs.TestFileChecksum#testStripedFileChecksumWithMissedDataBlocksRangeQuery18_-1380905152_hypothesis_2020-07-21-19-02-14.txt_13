reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-405331605-172.17.0.10-1595358346630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33911,DS-e8a197ec-635e-46fe-aa73-066da7d8766e,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-b83cac28-300a-44fa-9ce3-ffc1345ea864,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-e398c7d1-1c6c-495f-bfc1-ce3872584157,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-ab3228e6-6f39-4c6e-9430-843c13d922a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-243419db-3cc8-4168-b03d-0afc71b5922d,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-0c77913d-924f-4248-b1e3-d327706def30,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-f389eaf9-d281-4b6c-a59a-61930386dc79,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-067018e7-b162-477f-9e5d-b1e497aab09a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-405331605-172.17.0.10-1595358346630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33911,DS-e8a197ec-635e-46fe-aa73-066da7d8766e,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-b83cac28-300a-44fa-9ce3-ffc1345ea864,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-e398c7d1-1c6c-495f-bfc1-ce3872584157,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-ab3228e6-6f39-4c6e-9430-843c13d922a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-243419db-3cc8-4168-b03d-0afc71b5922d,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-0c77913d-924f-4248-b1e3-d327706def30,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-f389eaf9-d281-4b6c-a59a-61930386dc79,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-067018e7-b162-477f-9e5d-b1e497aab09a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-331044280-172.17.0.10-1595358752102:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42871,DS-106aa360-cbaa-41ba-bbfa-9c5759d462ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-1789f4bc-0826-4d3b-ba4c-a3495f612680,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-23c62dac-4df8-4178-9003-d0deaaaa8c23,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-70f5c270-574e-40ef-beaa-fd8a8a2dc78b,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-7b219f34-7293-447a-85ca-b9b80228f4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43749,DS-8866e01d-37da-4703-8cef-dc78024c0bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-588f22ca-5390-4eaf-bf34-b3d002231593,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-36e7a104-5bb4-41cd-b706-2ce84f25876c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-331044280-172.17.0.10-1595358752102:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42871,DS-106aa360-cbaa-41ba-bbfa-9c5759d462ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-1789f4bc-0826-4d3b-ba4c-a3495f612680,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-23c62dac-4df8-4178-9003-d0deaaaa8c23,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-70f5c270-574e-40ef-beaa-fd8a8a2dc78b,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-7b219f34-7293-447a-85ca-b9b80228f4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43749,DS-8866e01d-37da-4703-8cef-dc78024c0bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-588f22ca-5390-4eaf-bf34-b3d002231593,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-36e7a104-5bb4-41cd-b706-2ce84f25876c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-461904534-172.17.0.10-1595358809600:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34798,DS-cad47922-f27b-4c36-85a1-b40561526b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-8239f420-4b2b-4294-8d0b-5b00d6fd4332,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-5644540e-6614-4199-9c76-59b61ce64c26,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-e53e32c5-7ad6-4935-9109-1fc93e2a6809,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-ec477a90-e259-4cc6-94d1-9621cbd6d376,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-61c1f8a8-dedd-458f-b3cd-80abedc240bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-a20fa211-357a-446d-b3a8-d07921fcf952,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-4fe70ec6-98bb-4fea-937a-c2f23f0c0916,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-461904534-172.17.0.10-1595358809600:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34798,DS-cad47922-f27b-4c36-85a1-b40561526b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-8239f420-4b2b-4294-8d0b-5b00d6fd4332,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-5644540e-6614-4199-9c76-59b61ce64c26,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-e53e32c5-7ad6-4935-9109-1fc93e2a6809,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-ec477a90-e259-4cc6-94d1-9621cbd6d376,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-61c1f8a8-dedd-458f-b3cd-80abedc240bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-a20fa211-357a-446d-b3a8-d07921fcf952,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-4fe70ec6-98bb-4fea-937a-c2f23f0c0916,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-516095224-172.17.0.10-1595358838206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39034,DS-5cb6e5ea-16ef-4bb9-ae66-0cade0938cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-ba5ce949-c6c1-4812-85be-f529749a3366,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-6e52a694-fcaf-4ebd-a923-0fe12de5ac1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-148c7c11-4303-4ec8-a47c-4bcbd5e923bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-7e68f275-25f2-4d01-ad58-dec1cf59881e,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-55c50e89-4b02-40a0-92b0-7c3432b58873,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-e18ec6a4-478d-4702-82fe-ae227d316282,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-07a25a98-959f-4b13-9ed5-1a840518e269,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-516095224-172.17.0.10-1595358838206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39034,DS-5cb6e5ea-16ef-4bb9-ae66-0cade0938cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-ba5ce949-c6c1-4812-85be-f529749a3366,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-6e52a694-fcaf-4ebd-a923-0fe12de5ac1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-148c7c11-4303-4ec8-a47c-4bcbd5e923bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-7e68f275-25f2-4d01-ad58-dec1cf59881e,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-55c50e89-4b02-40a0-92b0-7c3432b58873,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-e18ec6a4-478d-4702-82fe-ae227d316282,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-07a25a98-959f-4b13-9ed5-1a840518e269,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-246704736-172.17.0.10-1595359068556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39415,DS-be4c002e-bd7d-478d-b654-a3f8418e5bed,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-78beabcb-a5b5-4413-ac9f-3483835ba602,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-6f589e2e-b1fc-4510-a49f-38a18aa55e73,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-979b939a-2493-42b9-bb09-e8d1bb094d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-f39aa9ba-b87c-47ff-b947-985f671a8b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-74332f3c-3267-4d56-b233-b581324ff695,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-031bd496-25c0-44e9-b63d-fd4173cefcee,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-04376f27-dac4-4692-8908-3a3f3a4749ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-246704736-172.17.0.10-1595359068556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39415,DS-be4c002e-bd7d-478d-b654-a3f8418e5bed,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-78beabcb-a5b5-4413-ac9f-3483835ba602,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-6f589e2e-b1fc-4510-a49f-38a18aa55e73,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-979b939a-2493-42b9-bb09-e8d1bb094d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-f39aa9ba-b87c-47ff-b947-985f671a8b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-74332f3c-3267-4d56-b233-b581324ff695,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-031bd496-25c0-44e9-b63d-fd4173cefcee,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-04376f27-dac4-4692-8908-3a3f3a4749ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1396177533-172.17.0.10-1595359426376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34931,DS-93d5f291-f39f-4a9e-bcbe-279d7810acd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-3650ad0d-3524-4a72-8918-df90ee82ad09,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-30ef9a6c-bb16-45f2-9d13-69e3466cf793,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-4a17d58f-43f1-40ce-bb36-c458411d0d37,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-15e514f9-8913-4012-b6f4-40af4133de92,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-93234e0c-7805-4ba6-8a01-2358334ec42f,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-7c5a7aa2-3e62-46de-a660-0e46102aa405,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-aaf61abc-8fb6-43be-96e7-f480bd6112c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1396177533-172.17.0.10-1595359426376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34931,DS-93d5f291-f39f-4a9e-bcbe-279d7810acd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-3650ad0d-3524-4a72-8918-df90ee82ad09,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-30ef9a6c-bb16-45f2-9d13-69e3466cf793,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-4a17d58f-43f1-40ce-bb36-c458411d0d37,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-15e514f9-8913-4012-b6f4-40af4133de92,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-93234e0c-7805-4ba6-8a01-2358334ec42f,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-7c5a7aa2-3e62-46de-a660-0e46102aa405,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-aaf61abc-8fb6-43be-96e7-f480bd6112c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1987346177-172.17.0.10-1595359730066:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36389,DS-e30d1e22-5cf8-4bfc-8ee2-b527af75a141,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-1a30aba3-d939-4f75-ba73-74e9690b8a19,DISK], DatanodeInfoWithStorage[127.0.0.1:44180,DS-480661d6-e9d6-4713-a6c9-dd339f7941d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-f9fefbc2-a297-4d0d-89c7-41dbe2099762,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-d014da3a-d2c3-4e04-8c8e-318e58275d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-7e2faada-f367-4ef0-8ce0-62781ca2ded7,DISK], DatanodeInfoWithStorage[127.0.0.1:46058,DS-0d72bdff-095c-4715-80b7-37ed9a769aca,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-80d8c67a-20ac-4811-8719-00eaf1b7f41f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1987346177-172.17.0.10-1595359730066:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36389,DS-e30d1e22-5cf8-4bfc-8ee2-b527af75a141,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-1a30aba3-d939-4f75-ba73-74e9690b8a19,DISK], DatanodeInfoWithStorage[127.0.0.1:44180,DS-480661d6-e9d6-4713-a6c9-dd339f7941d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-f9fefbc2-a297-4d0d-89c7-41dbe2099762,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-d014da3a-d2c3-4e04-8c8e-318e58275d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-7e2faada-f367-4ef0-8ce0-62781ca2ded7,DISK], DatanodeInfoWithStorage[127.0.0.1:46058,DS-0d72bdff-095c-4715-80b7-37ed9a769aca,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-80d8c67a-20ac-4811-8719-00eaf1b7f41f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308257772-172.17.0.10-1595359881988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38062,DS-9e6c5ede-ccbf-4a0f-995c-37dd14974b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-b2f102cf-8742-4034-894d-a245df0eb54d,DISK], DatanodeInfoWithStorage[127.0.0.1:39041,DS-c24c0ee2-e670-4ad2-bc50-abf7fdc05a02,DISK], DatanodeInfoWithStorage[127.0.0.1:44663,DS-57c56591-1f63-4a4f-a4e2-157879257ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-b192f018-6e41-41e4-982e-638aa9d9fb86,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-e956ba0e-6a34-4a77-a66d-6f1a16451506,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-d64446f5-aa59-4af6-9c8b-f546daa5aa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-3b3bc115-e0da-4f06-b1e4-d2b8029941d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308257772-172.17.0.10-1595359881988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38062,DS-9e6c5ede-ccbf-4a0f-995c-37dd14974b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-b2f102cf-8742-4034-894d-a245df0eb54d,DISK], DatanodeInfoWithStorage[127.0.0.1:39041,DS-c24c0ee2-e670-4ad2-bc50-abf7fdc05a02,DISK], DatanodeInfoWithStorage[127.0.0.1:44663,DS-57c56591-1f63-4a4f-a4e2-157879257ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-b192f018-6e41-41e4-982e-638aa9d9fb86,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-e956ba0e-6a34-4a77-a66d-6f1a16451506,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-d64446f5-aa59-4af6-9c8b-f546daa5aa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-3b3bc115-e0da-4f06-b1e4-d2b8029941d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-78611367-172.17.0.10-1595360105824:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46405,DS-7863e066-a03b-4a36-a63b-10511482ef19,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-937c72c4-52a5-425d-85f6-6c10989baab0,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-bec190f4-2d17-4f5e-8c06-ed0e689741d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-73c90b6d-0822-4141-8ac3-dddced502fea,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-ceaf8ef9-5fff-46bc-9306-19abfddc4207,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-1135f238-a117-41d5-89ce-76f917845f78,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-7541e7b3-b64d-4b89-bf73-6b136545f7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-941de4fb-62ad-4a8b-9bd5-dcde79490e1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-78611367-172.17.0.10-1595360105824:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46405,DS-7863e066-a03b-4a36-a63b-10511482ef19,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-937c72c4-52a5-425d-85f6-6c10989baab0,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-bec190f4-2d17-4f5e-8c06-ed0e689741d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-73c90b6d-0822-4141-8ac3-dddced502fea,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-ceaf8ef9-5fff-46bc-9306-19abfddc4207,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-1135f238-a117-41d5-89ce-76f917845f78,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-7541e7b3-b64d-4b89-bf73-6b136545f7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-941de4fb-62ad-4a8b-9bd5-dcde79490e1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1200160064-172.17.0.10-1595360666739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36577,DS-fac15122-d49f-4b87-8504-c6f56c8149a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-55e43a7b-2a2e-4d89-a8e5-009824f2a82e,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-18d4e27f-b76d-4ea1-9831-b7a645769e92,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-941d911d-12fb-499c-83ec-f2ed717be366,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-42274c23-3fe4-4f6e-9b1c-9b2ffc63e7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-f858bdd2-1dfb-4990-ae50-1f85ed382150,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-18f73d0c-fc2e-41f2-b841-b042e8800107,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-97071479-0093-41ac-afd6-434c5ed16c4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1200160064-172.17.0.10-1595360666739:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36577,DS-fac15122-d49f-4b87-8504-c6f56c8149a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-55e43a7b-2a2e-4d89-a8e5-009824f2a82e,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-18d4e27f-b76d-4ea1-9831-b7a645769e92,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-941d911d-12fb-499c-83ec-f2ed717be366,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-42274c23-3fe4-4f6e-9b1c-9b2ffc63e7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-f858bdd2-1dfb-4990-ae50-1f85ed382150,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-18f73d0c-fc2e-41f2-b841-b042e8800107,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-97071479-0093-41ac-afd6-434c5ed16c4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1226061871-172.17.0.10-1595360989818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34728,DS-67b79b30-5c2b-4862-b0e0-a3952549024a,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-7370d4aa-bdb1-4e54-927d-8977bdb4ede8,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-779592eb-4151-4b17-8f86-a2a76f58790b,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-32b8e4c3-584d-403a-8dca-8038aec9bfbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-43bfb598-6aad-4fef-bea0-fbb6c2a662a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-a56c6a4b-5e7e-4bd4-88f4-7ce1387205b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-820baec1-9217-456e-b28a-dd77af5a3b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-ec5407c4-ffc7-4fc9-bb0e-5951638952de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1226061871-172.17.0.10-1595360989818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34728,DS-67b79b30-5c2b-4862-b0e0-a3952549024a,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-7370d4aa-bdb1-4e54-927d-8977bdb4ede8,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-779592eb-4151-4b17-8f86-a2a76f58790b,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-32b8e4c3-584d-403a-8dca-8038aec9bfbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-43bfb598-6aad-4fef-bea0-fbb6c2a662a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-a56c6a4b-5e7e-4bd4-88f4-7ce1387205b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-820baec1-9217-456e-b28a-dd77af5a3b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-ec5407c4-ffc7-4fc9-bb0e-5951638952de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-537720425-172.17.0.10-1595361046897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38825,DS-f5bba277-890d-4c57-a720-f1c481994761,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-6a74eb6f-474a-47ae-8175-a646183643a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-e1dbbf14-8a19-4612-9923-fb55689b90af,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-563ee65e-1a1a-459c-a419-472d4e6a8fec,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-b1593c5a-ce6c-4782-9aec-12a911995605,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-2d00b0b1-973c-49bd-a5ed-3099ad6dd806,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-2ff50e29-2062-4604-af2b-45d9960cdb69,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-3cdd2bc9-991d-46a8-bfa5-e4e82fb5296d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-537720425-172.17.0.10-1595361046897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38825,DS-f5bba277-890d-4c57-a720-f1c481994761,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-6a74eb6f-474a-47ae-8175-a646183643a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-e1dbbf14-8a19-4612-9923-fb55689b90af,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-563ee65e-1a1a-459c-a419-472d4e6a8fec,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-b1593c5a-ce6c-4782-9aec-12a911995605,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-2d00b0b1-973c-49bd-a5ed-3099ad6dd806,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-2ff50e29-2062-4604-af2b-45d9960cdb69,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-3cdd2bc9-991d-46a8-bfa5-e4e82fb5296d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1139865229-172.17.0.10-1595361318590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44083,DS-bf2239cd-d3ca-43e0-a84b-243e13fd351e,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-9ecb6181-061b-40eb-97fd-9ef676728979,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-a1abe1b1-0d1a-48b6-bec0-e6b06c6e0fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-08ba3a9e-d991-454d-97f7-73f19e98a6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-7ceea737-764d-4e5a-8b3a-81b073dfafaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-5322e2ce-7855-4d61-9b2f-fdb0a2be46f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-fb3d27a9-813f-45d7-8211-c199b27fae7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-75051cf9-6b73-4e52-b634-3d7c4cc7d7e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1139865229-172.17.0.10-1595361318590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44083,DS-bf2239cd-d3ca-43e0-a84b-243e13fd351e,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-9ecb6181-061b-40eb-97fd-9ef676728979,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-a1abe1b1-0d1a-48b6-bec0-e6b06c6e0fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-08ba3a9e-d991-454d-97f7-73f19e98a6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-7ceea737-764d-4e5a-8b3a-81b073dfafaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-5322e2ce-7855-4d61-9b2f-fdb0a2be46f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-fb3d27a9-813f-45d7-8211-c199b27fae7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-75051cf9-6b73-4e52-b634-3d7c4cc7d7e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1944397480-172.17.0.10-1595361375266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46006,DS-8414dfea-1e1c-47ff-a0a9-e9fec6f6c225,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-a5235268-cc79-4978-92af-22f5f9072df3,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-7fe87550-8e70-487f-9318-1998581ee3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-947e5a75-a1c2-44e2-a1fa-306298498df3,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-fdeba772-9681-4d89-acd0-4b8436c2834c,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-b91302ec-ddc0-4652-95e1-310e26e05c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-009349d6-e661-4ac6-b21b-d6f1eb87e35f,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-d3c4d257-70ef-47b5-8d26-8229afada39f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1944397480-172.17.0.10-1595361375266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46006,DS-8414dfea-1e1c-47ff-a0a9-e9fec6f6c225,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-a5235268-cc79-4978-92af-22f5f9072df3,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-7fe87550-8e70-487f-9318-1998581ee3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-947e5a75-a1c2-44e2-a1fa-306298498df3,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-fdeba772-9681-4d89-acd0-4b8436c2834c,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-b91302ec-ddc0-4652-95e1-310e26e05c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-009349d6-e661-4ac6-b21b-d6f1eb87e35f,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-d3c4d257-70ef-47b5-8d26-8229afada39f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-152456382-172.17.0.10-1595361703108:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43381,DS-83d16b80-2c73-4890-b0be-aa79f11fb260,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-83da9151-e726-4d01-a28a-87d08755c73e,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-4cb292ac-d6d6-4e64-a58a-64d53dc2678a,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-67765c45-150f-4b3b-843e-1a6866c1ba13,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-2cfbe82b-708c-4608-a3a7-567e08a0cf2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-bdd2d44c-cb56-49f2-a602-6181022cd52b,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-238d7aab-9650-4174-9f2d-6d4187ae6c22,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-f88658c5-fd8b-43a1-a1f4-30a856d38b64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-152456382-172.17.0.10-1595361703108:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43381,DS-83d16b80-2c73-4890-b0be-aa79f11fb260,DISK], DatanodeInfoWithStorage[127.0.0.1:43804,DS-83da9151-e726-4d01-a28a-87d08755c73e,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-4cb292ac-d6d6-4e64-a58a-64d53dc2678a,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-67765c45-150f-4b3b-843e-1a6866c1ba13,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-2cfbe82b-708c-4608-a3a7-567e08a0cf2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-bdd2d44c-cb56-49f2-a602-6181022cd52b,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-238d7aab-9650-4174-9f2d-6d4187ae6c22,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-f88658c5-fd8b-43a1-a1f4-30a856d38b64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.domain.socket.data.traffic
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-15125197-172.17.0.10-1595362425828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41690,DS-c320aed8-5a94-4f0e-97ed-22124dc9dc40,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-15894ad6-2cc0-4ad2-8b5a-489b925c074c,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-3761bf13-4f3f-4fe3-a05a-584ae9830e34,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-cfe1ddc0-f49e-42b6-8e38-96cb708e065f,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-10537539-5fd4-4a1d-8f99-27d1fc1efefc,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-7a6bef8c-f7a7-4cda-879f-d059939c0cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-269335a7-0e23-4421-97d1-2eb7a2e114c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-07aa439e-5838-4f2e-aa18-8ea639dd7391,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-15125197-172.17.0.10-1595362425828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41690,DS-c320aed8-5a94-4f0e-97ed-22124dc9dc40,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-15894ad6-2cc0-4ad2-8b5a-489b925c074c,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-3761bf13-4f3f-4fe3-a05a-584ae9830e34,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-cfe1ddc0-f49e-42b6-8e38-96cb708e065f,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-10537539-5fd4-4a1d-8f99-27d1fc1efefc,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-7a6bef8c-f7a7-4cda-879f-d059939c0cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-269335a7-0e23-4421-97d1-2eb7a2e114c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-07aa439e-5838-4f2e-aa18-8ea639dd7391,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 4816
