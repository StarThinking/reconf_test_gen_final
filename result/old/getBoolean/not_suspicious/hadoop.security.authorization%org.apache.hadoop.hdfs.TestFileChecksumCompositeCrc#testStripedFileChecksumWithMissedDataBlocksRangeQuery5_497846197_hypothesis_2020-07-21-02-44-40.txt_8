reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851117010-172.17.0.20-1595299909554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44327,DS-ed6b4964-8b75-42a7-a799-4282e69f55a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-fa824b3c-a812-46fc-adde-8f72cda1edd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-2ddcccfa-0897-46bf-a3e4-d96430ef114d,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-b2bb1ccd-238f-4b32-9d9c-e75f0b7f60b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-28945c0d-e54f-46f7-95dc-6977088ec1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-2e0ed010-2507-4184-b9fb-64e8f4c7f471,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-bf7abed2-c776-49d4-b973-b0e291065688,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-579d7fd9-cc9d-44ca-b60f-8e2e112629b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851117010-172.17.0.20-1595299909554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44327,DS-ed6b4964-8b75-42a7-a799-4282e69f55a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-fa824b3c-a812-46fc-adde-8f72cda1edd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-2ddcccfa-0897-46bf-a3e4-d96430ef114d,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-b2bb1ccd-238f-4b32-9d9c-e75f0b7f60b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-28945c0d-e54f-46f7-95dc-6977088ec1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-2e0ed010-2507-4184-b9fb-64e8f4c7f471,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-bf7abed2-c776-49d4-b973-b0e291065688,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-579d7fd9-cc9d-44ca-b60f-8e2e112629b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-511313185-172.17.0.20-1595299999565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34638,DS-1d48a13a-6be6-451b-9ce0-5ffde26422d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-14923d29-a8b3-437d-a47b-37d39fe0eff4,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-247bae6e-fb37-47b9-8e94-7f366186d4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-68175dcd-093b-4a31-b1fd-48d0cdbe1e26,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-3aabb96e-2dd9-416b-a51f-9645bd8e3f94,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-96ac9f47-bd7d-4671-90d7-079e9aabfb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-dc86f252-65d5-4466-b1bb-d8dc9afae493,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-cbd8411a-6c58-41ae-bafb-ec0ac1a5fba8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-511313185-172.17.0.20-1595299999565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34638,DS-1d48a13a-6be6-451b-9ce0-5ffde26422d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-14923d29-a8b3-437d-a47b-37d39fe0eff4,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-247bae6e-fb37-47b9-8e94-7f366186d4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-68175dcd-093b-4a31-b1fd-48d0cdbe1e26,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-3aabb96e-2dd9-416b-a51f-9645bd8e3f94,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-96ac9f47-bd7d-4671-90d7-079e9aabfb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-dc86f252-65d5-4466-b1bb-d8dc9afae493,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-cbd8411a-6c58-41ae-bafb-ec0ac1a5fba8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-865626604-172.17.0.20-1595300729500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35591,DS-4e1075e5-98cf-4774-9c01-2692a56a9d81,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-41241425-3ab6-450c-9662-b38d6a122b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-608a8d2b-30a6-4728-88f9-6468ac5f356a,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-e73af4dc-d6f0-40cb-94c8-5b4a8b2fe38a,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-4172fa36-9afc-4985-a07e-6c2aa2105f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-81ec28e9-e272-4f5e-9402-dd99fc92761f,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-aa3de6d8-51fe-4324-83b1-c629bcd30be8,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-017dd839-f583-4ef8-9fa3-9526cf625e30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-865626604-172.17.0.20-1595300729500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35591,DS-4e1075e5-98cf-4774-9c01-2692a56a9d81,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-41241425-3ab6-450c-9662-b38d6a122b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-608a8d2b-30a6-4728-88f9-6468ac5f356a,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-e73af4dc-d6f0-40cb-94c8-5b4a8b2fe38a,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-4172fa36-9afc-4985-a07e-6c2aa2105f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-81ec28e9-e272-4f5e-9402-dd99fc92761f,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-aa3de6d8-51fe-4324-83b1-c629bcd30be8,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-017dd839-f583-4ef8-9fa3-9526cf625e30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-299105346-172.17.0.20-1595301090983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43245,DS-15dc18eb-16f9-4d1f-aa8c-617f775c1fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-1b610153-ad9a-4e1d-a085-3260ff814c40,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-e9885340-8958-44eb-a01f-f2181c3018ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-cb68eccf-0d37-4ba3-ad78-349b9119e96d,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-5b425631-4500-48c1-9cf0-5d2f7746bd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-15d045b4-3962-499d-92a9-07925bb503d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-7d5ebc27-80d3-4895-a789-14715acb4405,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-4b63f78a-89cc-43b0-af95-d6bb9f9d8a66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-299105346-172.17.0.20-1595301090983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43245,DS-15dc18eb-16f9-4d1f-aa8c-617f775c1fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-1b610153-ad9a-4e1d-a085-3260ff814c40,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-e9885340-8958-44eb-a01f-f2181c3018ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-cb68eccf-0d37-4ba3-ad78-349b9119e96d,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-5b425631-4500-48c1-9cf0-5d2f7746bd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-15d045b4-3962-499d-92a9-07925bb503d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-7d5ebc27-80d3-4895-a789-14715acb4405,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-4b63f78a-89cc-43b0-af95-d6bb9f9d8a66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-83825287-172.17.0.20-1595301496845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34888,DS-8ad4ded3-9311-4ffb-8ff7-177017b8feac,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-462d5040-1bee-467f-8cff-510e8d7efac7,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-e7bea568-3fee-4892-9dd3-d9f72a400623,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-7209b12c-cafb-44df-bf86-6ebab6af9d39,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-6b0b1089-58f8-4e63-ac08-753d072e5307,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-21009943-3680-4ba5-9bd5-042654e9c7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-7f1837fc-f70c-47bf-ada6-bd0772109c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-9217e3f0-15d3-4d3a-b523-bc76dd473722,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-83825287-172.17.0.20-1595301496845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34888,DS-8ad4ded3-9311-4ffb-8ff7-177017b8feac,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-462d5040-1bee-467f-8cff-510e8d7efac7,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-e7bea568-3fee-4892-9dd3-d9f72a400623,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-7209b12c-cafb-44df-bf86-6ebab6af9d39,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-6b0b1089-58f8-4e63-ac08-753d072e5307,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-21009943-3680-4ba5-9bd5-042654e9c7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-7f1837fc-f70c-47bf-ada6-bd0772109c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-9217e3f0-15d3-4d3a-b523-bc76dd473722,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488340678-172.17.0.20-1595302009725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36968,DS-62c8a6ba-ed11-4848-8ce6-d43ceed7adb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-afbeddb7-f4c8-4880-b614-932e2659869f,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-4dee2a91-55bb-4084-bba1-d48ac374efb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-83f60d96-75bf-4dd8-bc08-33c503213d18,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-c089f777-aa8e-44db-8009-3d60ed42aa7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-830e1e7f-335a-4a03-9e9c-2f141f019150,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-37d9c316-4d78-43b0-b29b-eb8055450648,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-f8428cc1-e23d-4fbe-a31c-fd3a8ee7debe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488340678-172.17.0.20-1595302009725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36968,DS-62c8a6ba-ed11-4848-8ce6-d43ceed7adb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-afbeddb7-f4c8-4880-b614-932e2659869f,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-4dee2a91-55bb-4084-bba1-d48ac374efb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-83f60d96-75bf-4dd8-bc08-33c503213d18,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-c089f777-aa8e-44db-8009-3d60ed42aa7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-830e1e7f-335a-4a03-9e9c-2f141f019150,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-37d9c316-4d78-43b0-b29b-eb8055450648,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-f8428cc1-e23d-4fbe-a31c-fd3a8ee7debe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-565985773-172.17.0.20-1595302308286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35439,DS-b4a6022f-2808-48f2-ba6b-69b4966c044d,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-d62325c9-8324-49f7-ac00-73d050e5bd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-07ce628b-4505-4829-b7c7-6c3fbd68ecac,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-ab99f3d6-a912-46e9-bdcf-03aa54399f43,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-6eee82ba-640c-4229-9bd2-23693b37e86e,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-651f4629-6324-4033-9578-2f9de7f35c15,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-c8ca12b7-6d85-478a-bb24-6b25f5d18c67,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-ee736315-0be2-40b1-907c-db76a415c0a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-565985773-172.17.0.20-1595302308286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35439,DS-b4a6022f-2808-48f2-ba6b-69b4966c044d,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-d62325c9-8324-49f7-ac00-73d050e5bd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-07ce628b-4505-4829-b7c7-6c3fbd68ecac,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-ab99f3d6-a912-46e9-bdcf-03aa54399f43,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-6eee82ba-640c-4229-9bd2-23693b37e86e,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-651f4629-6324-4033-9578-2f9de7f35c15,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-c8ca12b7-6d85-478a-bb24-6b25f5d18c67,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-ee736315-0be2-40b1-907c-db76a415c0a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-467671994-172.17.0.20-1595302569986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37024,DS-8683d444-152c-419d-b512-c05631f8ff0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-94f2b50f-9f1d-45d9-a02c-17775e52739f,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-11fe1710-bf65-42ab-a6a5-e997d8690b07,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-a231e9f5-d020-47fd-93d7-583df7a6df09,DISK], DatanodeInfoWithStorage[127.0.0.1:36616,DS-ef1f2ec9-e53f-4dcd-8143-246b18aca6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-85049739-1f33-43bb-9768-878daf14ad8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-68b922b0-b29b-410d-8b1f-c5b53b3b676a,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-906762c9-db2a-4df0-b7fa-438e0cc6568e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-467671994-172.17.0.20-1595302569986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37024,DS-8683d444-152c-419d-b512-c05631f8ff0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-94f2b50f-9f1d-45d9-a02c-17775e52739f,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-11fe1710-bf65-42ab-a6a5-e997d8690b07,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-a231e9f5-d020-47fd-93d7-583df7a6df09,DISK], DatanodeInfoWithStorage[127.0.0.1:36616,DS-ef1f2ec9-e53f-4dcd-8143-246b18aca6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-85049739-1f33-43bb-9768-878daf14ad8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-68b922b0-b29b-410d-8b1f-c5b53b3b676a,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-906762c9-db2a-4df0-b7fa-438e0cc6568e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-350920655-172.17.0.20-1595303078019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35137,DS-9f7342e9-1d2f-4a60-ab28-7e47b341223a,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-31a3042d-dacb-4213-bfd6-fb8758aa30a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-d018337a-afcc-4104-9ea2-6e583bb6aced,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-82ed6d70-657c-40f2-9e8e-87571651ef68,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-682aeb13-77c3-4459-8243-8c63e4830dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-d9d7f1a6-5728-4b80-855c-439aec2af4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46730,DS-0c2a5d06-93b6-41f0-9ab3-c6b07ab5ce92,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-7aba97d8-7b3a-4cf7-aaf1-ea1a6b74ee5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-350920655-172.17.0.20-1595303078019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35137,DS-9f7342e9-1d2f-4a60-ab28-7e47b341223a,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-31a3042d-dacb-4213-bfd6-fb8758aa30a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-d018337a-afcc-4104-9ea2-6e583bb6aced,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-82ed6d70-657c-40f2-9e8e-87571651ef68,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-682aeb13-77c3-4459-8243-8c63e4830dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-d9d7f1a6-5728-4b80-855c-439aec2af4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46730,DS-0c2a5d06-93b6-41f0-9ab3-c6b07ab5ce92,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-7aba97d8-7b3a-4cf7-aaf1-ea1a6b74ee5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877903018-172.17.0.20-1595304179519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41297,DS-4e0d7b62-9e7e-4cc2-a95a-aa7af6ee2ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-ac681a4d-c1da-47ae-9e4b-a713b55a6d70,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-a26d3812-2d48-4a63-952d-ddccfb9e39c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-d9ef21e8-fbb8-469f-9de8-335ba2779007,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-8529fd7b-0a6e-4029-b356-d704f4472dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-7df7ddd0-2b18-48a7-aa52-55ca5746228a,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-b664d90d-78bf-4393-aefd-964d622b2f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-8cd85b9f-f6de-4962-9a53-f055fa4b8eab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877903018-172.17.0.20-1595304179519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41297,DS-4e0d7b62-9e7e-4cc2-a95a-aa7af6ee2ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-ac681a4d-c1da-47ae-9e4b-a713b55a6d70,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-a26d3812-2d48-4a63-952d-ddccfb9e39c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-d9ef21e8-fbb8-469f-9de8-335ba2779007,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-8529fd7b-0a6e-4029-b356-d704f4472dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-7df7ddd0-2b18-48a7-aa52-55ca5746228a,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-b664d90d-78bf-4393-aefd-964d622b2f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-8cd85b9f-f6de-4962-9a53-f055fa4b8eab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-357761982-172.17.0.20-1595304895429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34331,DS-6e8bf962-6f5e-4792-b4da-553726ac16b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-776b4135-ebe5-4d38-aca5-61efddbe0972,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-d007229a-8ccc-4b7e-b4a1-db813441bb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-c68e34ea-559b-4d05-8283-a287b63cf0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-94f090be-fa3a-455e-9cf9-f91e64436b92,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-55e9d44c-9a2c-4bed-b4b3-e9d548ae56ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-164515e3-3c63-4664-9c19-0c2a4d31198d,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-d890f628-5b83-496a-9717-ef941c36f169,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-357761982-172.17.0.20-1595304895429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34331,DS-6e8bf962-6f5e-4792-b4da-553726ac16b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-776b4135-ebe5-4d38-aca5-61efddbe0972,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-d007229a-8ccc-4b7e-b4a1-db813441bb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-c68e34ea-559b-4d05-8283-a287b63cf0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-94f090be-fa3a-455e-9cf9-f91e64436b92,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-55e9d44c-9a2c-4bed-b4b3-e9d548ae56ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-164515e3-3c63-4664-9c19-0c2a4d31198d,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-d890f628-5b83-496a-9717-ef941c36f169,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1809518586-172.17.0.20-1595304986234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46377,DS-6e6d332d-0f0a-4da6-a16f-528095800eba,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-3d2bb5a2-fe21-4037-84a1-8423d31d496d,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-7d381dc1-3988-472d-a976-2647d42af229,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-aeb3a1b3-af69-4520-8c56-44c6f4546844,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-8c6e3fd9-7fa4-4492-aa89-326824b7d680,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-9ea92bb1-4444-4c07-93f7-223efc73aad7,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-07d20f27-a511-4ba4-8324-60ae21ea658e,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-505793e8-053a-4451-87d4-161e2e75e050,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1809518586-172.17.0.20-1595304986234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46377,DS-6e6d332d-0f0a-4da6-a16f-528095800eba,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-3d2bb5a2-fe21-4037-84a1-8423d31d496d,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-7d381dc1-3988-472d-a976-2647d42af229,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-aeb3a1b3-af69-4520-8c56-44c6f4546844,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-8c6e3fd9-7fa4-4492-aa89-326824b7d680,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-9ea92bb1-4444-4c07-93f7-223efc73aad7,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-07d20f27-a511-4ba4-8324-60ae21ea658e,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-505793e8-053a-4451-87d4-161e2e75e050,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1689941819-172.17.0.20-1595305484036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35589,DS-254b0c4d-becf-4ba5-addc-1826039847ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-67d3cb9c-858f-457f-b0c6-3bdc7dbeaaad,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-33d8d81c-aeb3-448a-b2a3-595b7cfda93f,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-75aa75c9-290e-434a-94ee-020f54b84f39,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-ce3d852c-d1ce-4183-a3b9-72fcd68b4445,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-d4f0362f-0f24-451a-b751-a8e2ec00cbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-8f28cce0-80af-4d01-a661-f100d8956ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-43b66db6-0ff8-4d42-9e0c-bfb86022aec0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1689941819-172.17.0.20-1595305484036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35589,DS-254b0c4d-becf-4ba5-addc-1826039847ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-67d3cb9c-858f-457f-b0c6-3bdc7dbeaaad,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-33d8d81c-aeb3-448a-b2a3-595b7cfda93f,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-75aa75c9-290e-434a-94ee-020f54b84f39,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-ce3d852c-d1ce-4183-a3b9-72fcd68b4445,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-d4f0362f-0f24-451a-b751-a8e2ec00cbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-8f28cce0-80af-4d01-a661-f100d8956ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-43b66db6-0ff8-4d42-9e0c-bfb86022aec0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-746044765-172.17.0.20-1595305678519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32946,DS-cf2eebe2-ceb7-4f3e-98ba-7898171376aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-7be7dffc-1969-4234-aab2-c90d8f918260,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-e86e251d-1c64-48e1-abda-9d0b7bcd2e67,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-121262d2-f1d4-4a7c-832a-31435969b7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-6f397b1a-b241-49c7-bd44-3b531ea4592b,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-41d7272b-ea08-498b-8016-d22d163d9547,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-6886db98-3ea1-42a6-b925-b72255e0f9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-28955c96-9227-4bd4-ada8-b468a02ddd87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-746044765-172.17.0.20-1595305678519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32946,DS-cf2eebe2-ceb7-4f3e-98ba-7898171376aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-7be7dffc-1969-4234-aab2-c90d8f918260,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-e86e251d-1c64-48e1-abda-9d0b7bcd2e67,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-121262d2-f1d4-4a7c-832a-31435969b7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-6f397b1a-b241-49c7-bd44-3b531ea4592b,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-41d7272b-ea08-498b-8016-d22d163d9547,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-6886db98-3ea1-42a6-b925-b72255e0f9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-28955c96-9227-4bd4-ada8-b468a02ddd87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 6735
