reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283832943-172.17.0.8-1595409444286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43235,DS-067ddecd-be44-44a5-b9e5-addcdcd2eb92,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-59f2f92e-6657-4a18-b1ae-aa2b4d9c38f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-32486aa6-6644-45ad-acd8-1d50edb3de30,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-d064c831-8da4-4b87-95dd-e89600bd6d69,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-7be29655-af38-4755-9a95-9666c6d6d455,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-4eb083a2-e40e-44a1-b68d-89e74a158e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-4e2e4d91-33a0-4651-8929-892663c83e22,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-8f45d2cd-119f-4f13-b874-29e77e6febef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283832943-172.17.0.8-1595409444286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43235,DS-067ddecd-be44-44a5-b9e5-addcdcd2eb92,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-59f2f92e-6657-4a18-b1ae-aa2b4d9c38f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-32486aa6-6644-45ad-acd8-1d50edb3de30,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-d064c831-8da4-4b87-95dd-e89600bd6d69,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-7be29655-af38-4755-9a95-9666c6d6d455,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-4eb083a2-e40e-44a1-b68d-89e74a158e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-4e2e4d91-33a0-4651-8929-892663c83e22,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-8f45d2cd-119f-4f13-b874-29e77e6febef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-175255032-172.17.0.8-1595409696324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33299,DS-04b91f59-bf2b-497e-a925-436e0b247945,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-44edc49b-ffed-4b16-a8d2-023dde80e1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-6dd70a3c-b30d-4564-aa7d-994506cb2fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-d54ed16d-38ba-4004-8a7b-88584cb522c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-f215313c-d4bb-4d30-a6fb-d32b994393a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-950e5ed5-3450-458d-b524-861697ef2dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-dc3f76ef-d883-4782-95f9-6d288e715cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-b4ad6d37-e52b-4723-bf2e-6808c204b6f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-175255032-172.17.0.8-1595409696324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33299,DS-04b91f59-bf2b-497e-a925-436e0b247945,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-44edc49b-ffed-4b16-a8d2-023dde80e1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-6dd70a3c-b30d-4564-aa7d-994506cb2fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-d54ed16d-38ba-4004-8a7b-88584cb522c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-f215313c-d4bb-4d30-a6fb-d32b994393a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-950e5ed5-3450-458d-b524-861697ef2dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-dc3f76ef-d883-4782-95f9-6d288e715cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-b4ad6d37-e52b-4723-bf2e-6808c204b6f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1004699630-172.17.0.8-1595409812192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35472,DS-6a3a463b-664d-4a0c-b885-42da1c7fc27a,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-bbaf164a-e5d6-475e-964c-adc065c7f9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-22ef90bc-73ad-41cd-b564-5960cb54a2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-65eeb21c-d9fa-4a97-bda9-509e096166ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-b67ff16c-6984-4b3f-8fb1-b232ec0c4e55,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-23bb3fb1-b5ad-47ce-91fb-43b849dbcbec,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-44e7ebdb-6f26-4f4a-895b-d595bd7529bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-2ddee679-e706-4d7b-a16c-8a2555256c18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1004699630-172.17.0.8-1595409812192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35472,DS-6a3a463b-664d-4a0c-b885-42da1c7fc27a,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-bbaf164a-e5d6-475e-964c-adc065c7f9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-22ef90bc-73ad-41cd-b564-5960cb54a2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-65eeb21c-d9fa-4a97-bda9-509e096166ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-b67ff16c-6984-4b3f-8fb1-b232ec0c4e55,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-23bb3fb1-b5ad-47ce-91fb-43b849dbcbec,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-44e7ebdb-6f26-4f4a-895b-d595bd7529bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-2ddee679-e706-4d7b-a16c-8a2555256c18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114168109-172.17.0.8-1595410484332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37573,DS-5280f5ef-3bbd-40ce-8040-c6d67f3581e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-9c4bc1d9-df07-4e85-b9af-e2e1d4563d52,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-d0970d15-9cf8-440b-9446-9ccde32820fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-98fc0390-05c1-4f41-ba17-dafc6a5e09c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-cddc76a7-bf65-4293-8713-c90ee33f9b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41774,DS-3a4eb426-dc22-49b8-90eb-ab9da728b7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-e37c2b72-7d06-4ad5-a419-dde44d8caf8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-05547b89-181d-4304-993c-b3f0cb980ea5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114168109-172.17.0.8-1595410484332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37573,DS-5280f5ef-3bbd-40ce-8040-c6d67f3581e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-9c4bc1d9-df07-4e85-b9af-e2e1d4563d52,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-d0970d15-9cf8-440b-9446-9ccde32820fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-98fc0390-05c1-4f41-ba17-dafc6a5e09c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-cddc76a7-bf65-4293-8713-c90ee33f9b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41774,DS-3a4eb426-dc22-49b8-90eb-ab9da728b7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-e37c2b72-7d06-4ad5-a419-dde44d8caf8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-05547b89-181d-4304-993c-b3f0cb980ea5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2028317651-172.17.0.8-1595410939606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42745,DS-ae31216f-f549-4371-9e7b-1767886f864b,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-8e5a0355-5230-4f1e-a9a3-69336e0add37,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-3119b785-bde1-4ad4-91e2-3060d1512477,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-f6ec1ec5-9129-4f31-8313-55ba93e8dba4,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-cec35bc6-2fa1-4961-8950-a559f1e3d9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-a7e85666-ff39-4500-ba8f-da303b8dee81,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-5e90a101-c1c2-481d-b24a-7ad2995b4400,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-01de1455-1948-44c0-a725-e272329351b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2028317651-172.17.0.8-1595410939606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42745,DS-ae31216f-f549-4371-9e7b-1767886f864b,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-8e5a0355-5230-4f1e-a9a3-69336e0add37,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-3119b785-bde1-4ad4-91e2-3060d1512477,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-f6ec1ec5-9129-4f31-8313-55ba93e8dba4,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-cec35bc6-2fa1-4961-8950-a559f1e3d9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-a7e85666-ff39-4500-ba8f-da303b8dee81,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-5e90a101-c1c2-481d-b24a-7ad2995b4400,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-01de1455-1948-44c0-a725-e272329351b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-545196760-172.17.0.8-1595411161423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44103,DS-3e807391-f713-4847-a62b-362e033817b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-6789ec07-a670-4261-8985-e1715e941474,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-99945717-a5d2-41f7-a524-8cfafc1b3ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-11680e7b-8935-474b-9e1b-644bdc1c5035,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-897d3ad4-0643-45f4-950d-3e61883d997e,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-949e8860-f4e5-46e0-b703-48b9d9670342,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-c7eabdf0-b54a-46a1-8132-f05efe96b28c,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-ae9b99ec-ece4-40de-bb39-a230afb543ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-545196760-172.17.0.8-1595411161423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44103,DS-3e807391-f713-4847-a62b-362e033817b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-6789ec07-a670-4261-8985-e1715e941474,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-99945717-a5d2-41f7-a524-8cfafc1b3ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-11680e7b-8935-474b-9e1b-644bdc1c5035,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-897d3ad4-0643-45f4-950d-3e61883d997e,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-949e8860-f4e5-46e0-b703-48b9d9670342,DISK], DatanodeInfoWithStorage[127.0.0.1:37131,DS-c7eabdf0-b54a-46a1-8132-f05efe96b28c,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-ae9b99ec-ece4-40de-bb39-a230afb543ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-112860567-172.17.0.8-1595411230231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36353,DS-c1a23356-2da1-4558-933c-85bc708db2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-1b60235d-4690-4228-ae5a-2b38c894cc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-00d80ba6-ea0b-4113-9139-66bfd32e062e,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-005f0181-86a8-4203-bebb-6b9d0c4dcedf,DISK], DatanodeInfoWithStorage[127.0.0.1:38180,DS-ef52698f-81d6-4a40-8185-9d57cff8f643,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-0ce3d05f-36d5-4575-9260-c20515559a04,DISK], DatanodeInfoWithStorage[127.0.0.1:40746,DS-f4ae234b-9b91-4a74-9c7f-d9b62634a770,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-f0a9d40b-6875-46ad-9bb1-1115a90de628,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-112860567-172.17.0.8-1595411230231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36353,DS-c1a23356-2da1-4558-933c-85bc708db2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-1b60235d-4690-4228-ae5a-2b38c894cc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-00d80ba6-ea0b-4113-9139-66bfd32e062e,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-005f0181-86a8-4203-bebb-6b9d0c4dcedf,DISK], DatanodeInfoWithStorage[127.0.0.1:38180,DS-ef52698f-81d6-4a40-8185-9d57cff8f643,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-0ce3d05f-36d5-4575-9260-c20515559a04,DISK], DatanodeInfoWithStorage[127.0.0.1:40746,DS-f4ae234b-9b91-4a74-9c7f-d9b62634a770,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-f0a9d40b-6875-46ad-9bb1-1115a90de628,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1700088405-172.17.0.8-1595411445088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38675,DS-55ccaec4-668f-4a03-9c92-e890aca2ef61,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-798ce40a-2fc3-46d9-89a5-e7691b825447,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-f5ad84a2-4cd9-4577-9be0-92b130f9ae94,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-06f7f6b7-d490-424a-93f7-da0894f553de,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-4f1a482f-9d51-46ed-8530-1dfab80b2053,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-8c33cfd9-87a7-4950-89b9-b76e85a541ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-0186ccc4-1e21-42de-a251-5350baa0fa46,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-6f68031b-d637-4777-bb8e-24b69bd418ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1700088405-172.17.0.8-1595411445088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38675,DS-55ccaec4-668f-4a03-9c92-e890aca2ef61,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-798ce40a-2fc3-46d9-89a5-e7691b825447,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-f5ad84a2-4cd9-4577-9be0-92b130f9ae94,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-06f7f6b7-d490-424a-93f7-da0894f553de,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-4f1a482f-9d51-46ed-8530-1dfab80b2053,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-8c33cfd9-87a7-4950-89b9-b76e85a541ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-0186ccc4-1e21-42de-a251-5350baa0fa46,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-6f68031b-d637-4777-bb8e-24b69bd418ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-524152674-172.17.0.8-1595411553601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36469,DS-296cc91b-85a7-4e4b-a4bc-adba1e64ce6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-272b2130-dc3d-4340-82d1-1fbfea1ac91e,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-4808d4c4-01a5-416b-ad26-f3b252de2ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-ca0b0a65-910b-4767-909a-058bc93a8257,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-7ac402b2-cc6b-4835-b673-40746d66a25c,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-a2d81d73-604c-462a-946b-bc31093c1b34,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-eb4f8526-77bb-401a-9012-21ba52b07c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-bb2c4797-566f-47ae-a7c7-5de49afed11f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-524152674-172.17.0.8-1595411553601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36469,DS-296cc91b-85a7-4e4b-a4bc-adba1e64ce6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-272b2130-dc3d-4340-82d1-1fbfea1ac91e,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-4808d4c4-01a5-416b-ad26-f3b252de2ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-ca0b0a65-910b-4767-909a-058bc93a8257,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-7ac402b2-cc6b-4835-b673-40746d66a25c,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-a2d81d73-604c-462a-946b-bc31093c1b34,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-eb4f8526-77bb-401a-9012-21ba52b07c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-bb2c4797-566f-47ae-a7c7-5de49afed11f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1706960931-172.17.0.8-1595411872451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43832,DS-83291455-cbb6-461b-a0cd-1bc83fc7900e,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-855271be-ef82-4591-bbdd-e8c9d2a7fbae,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-c3835bab-ae52-4d53-8164-14751cde3702,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-df24d36f-acd6-4089-8369-66301bec0476,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-a9156811-9ee1-4cd1-9dfb-73997f12e837,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-1e8e6d93-12ee-4633-a2ce-431fcce9425c,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-d50194e3-dc4a-499a-a547-b64e192c8b38,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-9facde5c-f1b5-484b-8247-3266799a435d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1706960931-172.17.0.8-1595411872451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43832,DS-83291455-cbb6-461b-a0cd-1bc83fc7900e,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-855271be-ef82-4591-bbdd-e8c9d2a7fbae,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-c3835bab-ae52-4d53-8164-14751cde3702,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-df24d36f-acd6-4089-8369-66301bec0476,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-a9156811-9ee1-4cd1-9dfb-73997f12e837,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-1e8e6d93-12ee-4633-a2ce-431fcce9425c,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-d50194e3-dc4a-499a-a547-b64e192c8b38,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-9facde5c-f1b5-484b-8247-3266799a435d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1209772154-172.17.0.8-1595412242579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43592,DS-d7485737-d96e-4137-b77b-8fc335b8c5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-2416c2df-bcb9-4612-9022-5ec657a1d41b,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-d0061669-1e78-4d18-a9c3-fd5b33913e13,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-b682a690-ce00-4fe4-bd0b-f4e4673beedb,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-f3f33269-7b80-4dff-818c-d2d86d41c396,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-f8ed9892-2feb-4101-a1b3-c6b448d916cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-3ce27ca2-4d2a-432d-8940-8a73685aba01,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-ce8962b3-4d35-457e-a0b5-732ae0feb878,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1209772154-172.17.0.8-1595412242579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43592,DS-d7485737-d96e-4137-b77b-8fc335b8c5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-2416c2df-bcb9-4612-9022-5ec657a1d41b,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-d0061669-1e78-4d18-a9c3-fd5b33913e13,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-b682a690-ce00-4fe4-bd0b-f4e4673beedb,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-f3f33269-7b80-4dff-818c-d2d86d41c396,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-f8ed9892-2feb-4101-a1b3-c6b448d916cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-3ce27ca2-4d2a-432d-8940-8a73685aba01,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-ce8962b3-4d35-457e-a0b5-732ae0feb878,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347328487-172.17.0.8-1595412952876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43314,DS-2d662d3b-921f-483d-a7f6-80da77272bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-da299daf-2ce1-4268-bedf-1b7e66bc3a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-028c55e4-c79e-4037-808c-599ffa3304ba,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-08718495-02c5-4705-a574-d9acd60f3ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-260e40b2-a1ab-4985-9a55-54e0867b0486,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-69e617d5-40ab-4f79-a4ea-e84c86b45287,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-ff87e27a-b641-46b5-bbcb-f74ada506c69,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-fac4009b-f05e-4a16-98e0-49b26cedf7e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347328487-172.17.0.8-1595412952876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43314,DS-2d662d3b-921f-483d-a7f6-80da77272bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-da299daf-2ce1-4268-bedf-1b7e66bc3a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-028c55e4-c79e-4037-808c-599ffa3304ba,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-08718495-02c5-4705-a574-d9acd60f3ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-260e40b2-a1ab-4985-9a55-54e0867b0486,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-69e617d5-40ab-4f79-a4ea-e84c86b45287,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-ff87e27a-b641-46b5-bbcb-f74ada506c69,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-fac4009b-f05e-4a16-98e0-49b26cedf7e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1120419151-172.17.0.8-1595413124843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41709,DS-e57e2800-739a-4f20-a39a-a0d03778237d,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-474ab2ee-c587-435b-a085-9cef6b9ac32c,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-432e4e20-7dab-4bc8-b3c0-4bde65a1b160,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-40130e8a-7172-4493-8351-0d3b4a0a9d73,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-c7deaa8c-8d5f-4010-9cd2-6cb997eac931,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-2418c820-4fc9-4820-93c7-3a5d74d565ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-2df924dd-39ee-4fa9-9985-de57594cde1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-621dd4d7-27d4-4742-8710-eb36e5898de0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1120419151-172.17.0.8-1595413124843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41709,DS-e57e2800-739a-4f20-a39a-a0d03778237d,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-474ab2ee-c587-435b-a085-9cef6b9ac32c,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-432e4e20-7dab-4bc8-b3c0-4bde65a1b160,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-40130e8a-7172-4493-8351-0d3b4a0a9d73,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-c7deaa8c-8d5f-4010-9cd2-6cb997eac931,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-2418c820-4fc9-4820-93c7-3a5d74d565ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-2df924dd-39ee-4fa9-9985-de57594cde1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-621dd4d7-27d4-4742-8710-eb36e5898de0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2039289132-172.17.0.8-1595413166757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36939,DS-fa6862c0-16d2-4935-b23d-9d93cdb74d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-5e4f83ad-378b-4e01-a111-cdc372a34ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-bfc1e5ef-4937-439a-8353-54f26b73c4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-39e172a3-33c4-4ed4-8269-091d58a20e13,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-fc84266c-993b-4517-a502-3cd79091c914,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-0a16ab57-6d61-4baf-942c-996c519d4f22,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-eb09a7d9-d465-444a-8111-96a0fb473ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-1192c6ec-a8a2-464a-9daf-56a8b7e807bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2039289132-172.17.0.8-1595413166757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36939,DS-fa6862c0-16d2-4935-b23d-9d93cdb74d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-5e4f83ad-378b-4e01-a111-cdc372a34ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-bfc1e5ef-4937-439a-8353-54f26b73c4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-39e172a3-33c4-4ed4-8269-091d58a20e13,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-fc84266c-993b-4517-a502-3cd79091c914,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-0a16ab57-6d61-4baf-942c-996c519d4f22,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-eb09a7d9-d465-444a-8111-96a0fb473ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-1192c6ec-a8a2-464a-9daf-56a8b7e807bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-746282054-172.17.0.8-1595413661122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37621,DS-c91db48e-9015-4db5-8637-8d2224c96a00,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-a3542d92-566d-4c17-bf21-28d00e9a865a,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-ba323d87-dc64-49e7-90b2-d6ce07d3ce98,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-3f27b69e-d81b-4acd-aa9a-9bc48b5bdfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-faa6da4f-233e-4b08-b09a-37ebe4f98ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-dca73343-49bd-4284-b713-d7104ada2f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-7912a6c9-7873-40ce-a169-484a4326061c,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-c3f1d846-3d3a-4861-8e59-accf00b9e245,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-746282054-172.17.0.8-1595413661122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37621,DS-c91db48e-9015-4db5-8637-8d2224c96a00,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-a3542d92-566d-4c17-bf21-28d00e9a865a,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-ba323d87-dc64-49e7-90b2-d6ce07d3ce98,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-3f27b69e-d81b-4acd-aa9a-9bc48b5bdfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-faa6da4f-233e-4b08-b09a-37ebe4f98ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-dca73343-49bd-4284-b713-d7104ada2f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-7912a6c9-7873-40ce-a169-484a4326061c,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-c3f1d846-3d3a-4861-8e59-accf00b9e245,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211943839-172.17.0.8-1595414727517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43339,DS-6bf3a469-d274-4725-8d07-8987e2ac7cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-46d818b9-2dab-4c34-99b9-a6ebd8d19e89,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-a0c5a06a-2493-455e-b299-ee99498e8369,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-a6c0b463-81b7-4418-89a8-d34b457e27d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-7b436baf-e662-46f9-9021-784a91f65d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-8bf1c3be-6631-47e2-80b6-eb96ef8759e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-5703c340-c236-473f-8940-46dd8bea62ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-2408b0a4-69ca-4681-a0d7-073b800058a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211943839-172.17.0.8-1595414727517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43339,DS-6bf3a469-d274-4725-8d07-8987e2ac7cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-46d818b9-2dab-4c34-99b9-a6ebd8d19e89,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-a0c5a06a-2493-455e-b299-ee99498e8369,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-a6c0b463-81b7-4418-89a8-d34b457e27d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-7b436baf-e662-46f9-9021-784a91f65d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-8bf1c3be-6631-47e2-80b6-eb96ef8759e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-5703c340-c236-473f-8940-46dd8bea62ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-2408b0a4-69ca-4681-a0d7-073b800058a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5416
