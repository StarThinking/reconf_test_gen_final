reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1182108483-172.17.0.14-1595355812129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38444,DS-ef3746c0-5ad0-48e4-86af-e5045c164e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-dea0c304-6456-4cba-a1a6-854957efd7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-601b14d6-1c30-4849-8a12-4968a20b8b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-b2038862-8609-4333-bcf5-ca182a0bb788,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-0a4315af-ab04-49da-ae5f-3c04c4ec5989,DISK], DatanodeInfoWithStorage[127.0.0.1:39997,DS-8a6c30d5-7894-4b5a-93ca-a22456f2bc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-1ab4b255-ca84-4048-b5c5-b5df02c14f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-69ad748f-ada9-4349-83b0-49fedfbe0b59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1182108483-172.17.0.14-1595355812129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38444,DS-ef3746c0-5ad0-48e4-86af-e5045c164e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-dea0c304-6456-4cba-a1a6-854957efd7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-601b14d6-1c30-4849-8a12-4968a20b8b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-b2038862-8609-4333-bcf5-ca182a0bb788,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-0a4315af-ab04-49da-ae5f-3c04c4ec5989,DISK], DatanodeInfoWithStorage[127.0.0.1:39997,DS-8a6c30d5-7894-4b5a-93ca-a22456f2bc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-1ab4b255-ca84-4048-b5c5-b5df02c14f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-69ad748f-ada9-4349-83b0-49fedfbe0b59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2044009231-172.17.0.14-1595356053147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34403,DS-761333f6-d317-4237-8f6e-103b29c63b44,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-f9a6bc28-94b8-44f6-b3ce-295deea11c38,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-db2253e0-9d07-45ed-bf19-67f7b9b7c947,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-a84da6f0-69af-4a0f-81b6-93277fe96cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-7859ce79-6ea9-4b2c-9e7a-7379f0a1d9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-2f1ba6a0-99a6-4011-bf34-6dedb51d6404,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-eacc5cbd-4532-452f-a5b7-d15276365223,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-3201dddf-54bd-4919-b3a8-c84bb982455e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2044009231-172.17.0.14-1595356053147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34403,DS-761333f6-d317-4237-8f6e-103b29c63b44,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-f9a6bc28-94b8-44f6-b3ce-295deea11c38,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-db2253e0-9d07-45ed-bf19-67f7b9b7c947,DISK], DatanodeInfoWithStorage[127.0.0.1:41616,DS-a84da6f0-69af-4a0f-81b6-93277fe96cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-7859ce79-6ea9-4b2c-9e7a-7379f0a1d9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-2f1ba6a0-99a6-4011-bf34-6dedb51d6404,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-eacc5cbd-4532-452f-a5b7-d15276365223,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-3201dddf-54bd-4919-b3a8-c84bb982455e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-261849198-172.17.0.14-1595356261521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36625,DS-2bbf19ce-443b-4117-8937-d30a34d54887,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-9574e45c-0b15-4f56-a0f0-96822a00e09f,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-153cec64-73be-47d4-bbaf-df0a6ba762c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-cee9ca68-1f51-458f-829a-a36107760889,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-ab41a299-2df5-477d-a138-e257fb875a49,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-f135456a-7f72-40c6-9368-b22bae942a68,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-d184eca1-1935-4d52-b684-f2e7bf8795a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-22d66ae7-5f0b-489b-88b6-775863e599ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-261849198-172.17.0.14-1595356261521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36625,DS-2bbf19ce-443b-4117-8937-d30a34d54887,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-9574e45c-0b15-4f56-a0f0-96822a00e09f,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-153cec64-73be-47d4-bbaf-df0a6ba762c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-cee9ca68-1f51-458f-829a-a36107760889,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-ab41a299-2df5-477d-a138-e257fb875a49,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-f135456a-7f72-40c6-9368-b22bae942a68,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-d184eca1-1935-4d52-b684-f2e7bf8795a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-22d66ae7-5f0b-489b-88b6-775863e599ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1778441952-172.17.0.14-1595356366372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33793,DS-ea9357ba-3d7a-423f-a8fb-fb5d5839f477,DISK], DatanodeInfoWithStorage[127.0.0.1:40407,DS-5b20de1a-4634-46ac-badc-52cae156ea74,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-78071d09-dc34-4f6f-8fe0-4e13cd03ebb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-dd140d71-da10-4f06-9b13-a3d4686a9880,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-b73719f9-edd5-4af6-b9ca-21a7f700ba76,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-af8d6378-10e9-4193-9231-438e3916fbde,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-05effd57-45fa-4e5c-b633-23dac1b8b0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-5d196829-c388-4c93-b3e5-8ea0de926992,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1778441952-172.17.0.14-1595356366372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33793,DS-ea9357ba-3d7a-423f-a8fb-fb5d5839f477,DISK], DatanodeInfoWithStorage[127.0.0.1:40407,DS-5b20de1a-4634-46ac-badc-52cae156ea74,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-78071d09-dc34-4f6f-8fe0-4e13cd03ebb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-dd140d71-da10-4f06-9b13-a3d4686a9880,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-b73719f9-edd5-4af6-b9ca-21a7f700ba76,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-af8d6378-10e9-4193-9231-438e3916fbde,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-05effd57-45fa-4e5c-b633-23dac1b8b0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-5d196829-c388-4c93-b3e5-8ea0de926992,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-463824983-172.17.0.14-1595356481775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39934,DS-7819e76a-3d8e-461a-845d-19a840e55dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-ac6b5645-f902-4c55-999c-676f1253095d,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-f5e4fe7b-5367-4931-abac-6929bd9b866d,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-287eab50-6ff9-4022-9147-1325d304c94d,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-ce59b7f3-fac5-4ffa-aa30-e21c220d257a,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-9118008c-dfd9-4133-9ea2-47f280afc86a,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-67750ceb-8d78-4546-aa84-cd934b487ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-8285f87c-c7f9-4b5a-93f1-3c28eb47ab4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-463824983-172.17.0.14-1595356481775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39934,DS-7819e76a-3d8e-461a-845d-19a840e55dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-ac6b5645-f902-4c55-999c-676f1253095d,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-f5e4fe7b-5367-4931-abac-6929bd9b866d,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-287eab50-6ff9-4022-9147-1325d304c94d,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-ce59b7f3-fac5-4ffa-aa30-e21c220d257a,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-9118008c-dfd9-4133-9ea2-47f280afc86a,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-67750ceb-8d78-4546-aa84-cd934b487ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-8285f87c-c7f9-4b5a-93f1-3c28eb47ab4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-372778338-172.17.0.14-1595356982620:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38743,DS-12a019fb-9f62-459d-9ca7-47fa00b5cbed,DISK], DatanodeInfoWithStorage[127.0.0.1:42591,DS-007e3162-9da6-462d-bdb9-b5c3fc147c25,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-d1484c03-c847-4174-9962-0354f98d9f20,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-bd098205-8924-4c62-b7e6-c11d34926f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-0d2f8bbf-320a-412e-a0ff-5d2faa0a14bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-99d37487-3196-476c-8d76-678b47d28de6,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-b2fcf4d3-9ff4-4022-852f-0b1f6eadbb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-323f9205-a6e4-4b29-866b-415d30bcea16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-372778338-172.17.0.14-1595356982620:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38743,DS-12a019fb-9f62-459d-9ca7-47fa00b5cbed,DISK], DatanodeInfoWithStorage[127.0.0.1:42591,DS-007e3162-9da6-462d-bdb9-b5c3fc147c25,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-d1484c03-c847-4174-9962-0354f98d9f20,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-bd098205-8924-4c62-b7e6-c11d34926f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-0d2f8bbf-320a-412e-a0ff-5d2faa0a14bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-99d37487-3196-476c-8d76-678b47d28de6,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-b2fcf4d3-9ff4-4022-852f-0b1f6eadbb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-323f9205-a6e4-4b29-866b-415d30bcea16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-23779166-172.17.0.14-1595357078521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38527,DS-26432ee4-2478-4062-a7b4-0d3b9eae663c,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-d46674bd-714c-4bec-a1b9-a33bb90ecb46,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-a4b52074-ac73-4abf-91b7-334edbac778f,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-c930089c-6e8f-4a38-a30d-eb2063e7e058,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-16e6ee0c-9cdf-4fd0-9d69-9c7c157a9a92,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-c1f2b6d5-95cb-4f39-8c60-7f4a1bb83372,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-0272504b-46d8-4e04-9773-7aab6411bf51,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-3ceb1623-9bd1-479a-b41d-069307ea567c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-23779166-172.17.0.14-1595357078521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38527,DS-26432ee4-2478-4062-a7b4-0d3b9eae663c,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-d46674bd-714c-4bec-a1b9-a33bb90ecb46,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-a4b52074-ac73-4abf-91b7-334edbac778f,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-c930089c-6e8f-4a38-a30d-eb2063e7e058,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-16e6ee0c-9cdf-4fd0-9d69-9c7c157a9a92,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-c1f2b6d5-95cb-4f39-8c60-7f4a1bb83372,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-0272504b-46d8-4e04-9773-7aab6411bf51,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-3ceb1623-9bd1-479a-b41d-069307ea567c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-685302828-172.17.0.14-1595357106022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36868,DS-a5d0ae5e-82e4-4118-9d73-fd10c1a66c15,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-3e7c938c-2e84-4e3d-81a7-a4ef262c48f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-08e1c99f-2418-4190-9dfe-543ea65902d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46117,DS-f28fd290-6c5e-4c2a-bebb-93f89c319be3,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-3db75724-276c-4ae0-8f51-34e415bf2f45,DISK], DatanodeInfoWithStorage[127.0.0.1:34291,DS-651024e5-483b-4ffe-8186-a82e5def1018,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-2dcb6c1e-5c63-44b1-a0cd-c90ee505e17a,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-d6580472-2127-4ff2-9b3c-ac1edfa73f9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-685302828-172.17.0.14-1595357106022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36868,DS-a5d0ae5e-82e4-4118-9d73-fd10c1a66c15,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-3e7c938c-2e84-4e3d-81a7-a4ef262c48f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-08e1c99f-2418-4190-9dfe-543ea65902d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46117,DS-f28fd290-6c5e-4c2a-bebb-93f89c319be3,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-3db75724-276c-4ae0-8f51-34e415bf2f45,DISK], DatanodeInfoWithStorage[127.0.0.1:34291,DS-651024e5-483b-4ffe-8186-a82e5def1018,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-2dcb6c1e-5c63-44b1-a0cd-c90ee505e17a,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-d6580472-2127-4ff2-9b3c-ac1edfa73f9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-23996082-172.17.0.14-1595357204646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34722,DS-25a0ba8d-402e-432b-8e45-8b140cef8df5,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-115a8696-0544-4659-998f-10593f8c7a27,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-fbd41303-979c-45bc-bf4f-b635e6d03d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-76ba80c0-2357-43f4-9a72-88843a4989d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-dfed6e4b-273e-448d-b8bb-776b7fd8b1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-6f98cb5d-fcad-4a5a-9bb0-96def93471d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-f88289ce-34f5-4e4a-9761-4e8561ef1b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-1a68be56-6684-42d0-9905-fb719fe0b15f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-23996082-172.17.0.14-1595357204646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34722,DS-25a0ba8d-402e-432b-8e45-8b140cef8df5,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-115a8696-0544-4659-998f-10593f8c7a27,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-fbd41303-979c-45bc-bf4f-b635e6d03d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40225,DS-76ba80c0-2357-43f4-9a72-88843a4989d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-dfed6e4b-273e-448d-b8bb-776b7fd8b1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-6f98cb5d-fcad-4a5a-9bb0-96def93471d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-f88289ce-34f5-4e4a-9761-4e8561ef1b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-1a68be56-6684-42d0-9905-fb719fe0b15f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-874269900-172.17.0.14-1595358183056:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38242,DS-7e8a755a-fe3a-4727-ae59-dd3f70c62de9,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-29dc646c-ce0b-4683-8e23-66f4e7d90da9,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-cac181f4-5743-4f65-ba87-cc906dfd4438,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-1f4156ea-d538-4967-a982-0c98fc4abc10,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-4af40911-80a6-4cfc-8230-b4944b4315b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-7dc52a04-5e41-4663-93c1-2d743563b451,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-1a677fad-b73c-4ed4-8c1e-2169807f0cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-1c8769d1-d509-40c7-9914-55a0d640f8d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-874269900-172.17.0.14-1595358183056:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38242,DS-7e8a755a-fe3a-4727-ae59-dd3f70c62de9,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-29dc646c-ce0b-4683-8e23-66f4e7d90da9,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-cac181f4-5743-4f65-ba87-cc906dfd4438,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-1f4156ea-d538-4967-a982-0c98fc4abc10,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-4af40911-80a6-4cfc-8230-b4944b4315b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-7dc52a04-5e41-4663-93c1-2d743563b451,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-1a677fad-b73c-4ed4-8c1e-2169807f0cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-1c8769d1-d509-40c7-9914-55a0d640f8d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864408430-172.17.0.14-1595358797417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40841,DS-55bc02d9-5d89-4205-aa61-68162b84c63a,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-26889a62-b2d6-447a-9cbc-6c5f387c9a02,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-1e70f406-aa14-415f-84d6-16138af3c55c,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-b43ca169-a0b8-40a9-917b-1a594a306531,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-a0be2a1c-bffe-4b11-acb1-3b66a0daf20f,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-023fd49a-9312-4ff2-b05e-7bdc4b96fd85,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-75f66b37-149e-4076-957a-7707a2f68857,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-fd23f4c1-1c4b-4b76-8be5-95145e296131,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864408430-172.17.0.14-1595358797417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40841,DS-55bc02d9-5d89-4205-aa61-68162b84c63a,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-26889a62-b2d6-447a-9cbc-6c5f387c9a02,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-1e70f406-aa14-415f-84d6-16138af3c55c,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-b43ca169-a0b8-40a9-917b-1a594a306531,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-a0be2a1c-bffe-4b11-acb1-3b66a0daf20f,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-023fd49a-9312-4ff2-b05e-7bdc4b96fd85,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-75f66b37-149e-4076-957a-7707a2f68857,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-fd23f4c1-1c4b-4b76-8be5-95145e296131,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-75734633-172.17.0.14-1595358904172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46252,DS-140c1aa8-c318-43fc-9a2d-8a407317b732,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-b9dbd06d-1f95-4ccc-b672-f04a4dccae09,DISK], DatanodeInfoWithStorage[127.0.0.1:39337,DS-54d36f09-86be-4763-a27b-96dec471b398,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-aaccaab4-92f3-4654-b81b-d56b0b17bb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-2cf7e9a5-2b73-47c2-b169-ed0e22d11813,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-42f78aac-162b-4dfe-8d9d-6f1a82403632,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-21895315-166a-475a-8bd5-71fee8c64f85,DISK], DatanodeInfoWithStorage[127.0.0.1:33531,DS-ea03c860-fb18-404a-a5f5-5efed3e45b40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-75734633-172.17.0.14-1595358904172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46252,DS-140c1aa8-c318-43fc-9a2d-8a407317b732,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-b9dbd06d-1f95-4ccc-b672-f04a4dccae09,DISK], DatanodeInfoWithStorage[127.0.0.1:39337,DS-54d36f09-86be-4763-a27b-96dec471b398,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-aaccaab4-92f3-4654-b81b-d56b0b17bb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-2cf7e9a5-2b73-47c2-b169-ed0e22d11813,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-42f78aac-162b-4dfe-8d9d-6f1a82403632,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-21895315-166a-475a-8bd5-71fee8c64f85,DISK], DatanodeInfoWithStorage[127.0.0.1:33531,DS-ea03c860-fb18-404a-a5f5-5efed3e45b40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-796748320-172.17.0.14-1595359048116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41192,DS-97490f4c-8b09-4350-bf16-dc1716efd995,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-5edb76ca-8019-41c4-ac1b-e9233b3823a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-9e1b1d60-ae92-4352-b0dc-556ee9aacc13,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-65fa39bf-861a-4dc9-b629-37939aafff8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-f562eb50-e990-4ccf-943e-799b1b2cc209,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-a0695d2d-212f-4818-9e1b-5e9d4c04c491,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-7916fa38-c055-44ff-89cc-5e9d627e7fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-4998345f-9b6e-4f8d-b387-acc2b8795f29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-796748320-172.17.0.14-1595359048116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41192,DS-97490f4c-8b09-4350-bf16-dc1716efd995,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-5edb76ca-8019-41c4-ac1b-e9233b3823a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-9e1b1d60-ae92-4352-b0dc-556ee9aacc13,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-65fa39bf-861a-4dc9-b629-37939aafff8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-f562eb50-e990-4ccf-943e-799b1b2cc209,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-a0695d2d-212f-4818-9e1b-5e9d4c04c491,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-7916fa38-c055-44ff-89cc-5e9d627e7fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-4998345f-9b6e-4f8d-b387-acc2b8795f29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-290912744-172.17.0.14-1595359697270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39023,DS-38681ce5-f24f-4204-81af-4a11693ee48e,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-1d721cab-4e69-4ff6-9bdd-3f843b95a2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-579fa826-327b-449e-aeff-59dbaaf74f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-98ce01dd-404d-4106-9ca7-b2de97749774,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-abfd7547-c9c8-40af-b7f9-cdb9148dc1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-4d3547dd-41f6-450a-bc77-8f1c4444d8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-ac2245f1-d62b-4f8d-b3a3-cba244ded2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-1454e19a-8fc6-4d5d-8a2b-80cdcfbb7773,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-290912744-172.17.0.14-1595359697270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39023,DS-38681ce5-f24f-4204-81af-4a11693ee48e,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-1d721cab-4e69-4ff6-9bdd-3f843b95a2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-579fa826-327b-449e-aeff-59dbaaf74f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-98ce01dd-404d-4106-9ca7-b2de97749774,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-abfd7547-c9c8-40af-b7f9-cdb9148dc1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-4d3547dd-41f6-450a-bc77-8f1c4444d8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-ac2245f1-d62b-4f8d-b3a3-cba244ded2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-1454e19a-8fc6-4d5d-8a2b-80cdcfbb7773,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1124781458-172.17.0.14-1595359849435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36887,DS-369bb3f0-652d-40de-9f14-c2d2de922607,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-48baab32-bb95-457c-95df-b550f88a705f,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-a98da794-ddb5-41cc-b9c9-5b89ca2de477,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-c8be28ae-96b7-4c00-8381-79ab3d8355aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-6c69ad4a-9825-4017-983f-8309c369a97c,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-68b991a7-4447-432b-955f-1170d62228b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-6d6deca7-1bca-4676-9826-6697dd5844ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-50315d8b-42fb-41e7-aa59-562c40d3f3cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1124781458-172.17.0.14-1595359849435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36887,DS-369bb3f0-652d-40de-9f14-c2d2de922607,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-48baab32-bb95-457c-95df-b550f88a705f,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-a98da794-ddb5-41cc-b9c9-5b89ca2de477,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-c8be28ae-96b7-4c00-8381-79ab3d8355aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-6c69ad4a-9825-4017-983f-8309c369a97c,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-68b991a7-4447-432b-955f-1170d62228b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-6d6deca7-1bca-4676-9826-6697dd5844ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-50315d8b-42fb-41e7-aa59-562c40d3f3cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1991060646-172.17.0.14-1595359952541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40752,DS-8cc935f2-a931-4264-ac5c-3872a1b3b7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-247e015a-597a-4cab-a9f5-7ba2cf512056,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-5400a8d7-3a10-44d5-8fc5-6d7d9a24cb39,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-0b4a83a5-8308-49dc-9b9b-c94262761823,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-bf134ac0-805f-4660-90e2-b2c42d5f0df9,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-6d3536a4-f825-49f4-b440-0e6d7bd73962,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-dcbc5d7a-3837-40bd-86bf-6b48fe42f1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-87bac2c6-a56d-4d07-b851-d3e4c1e0f401,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1991060646-172.17.0.14-1595359952541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40752,DS-8cc935f2-a931-4264-ac5c-3872a1b3b7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-247e015a-597a-4cab-a9f5-7ba2cf512056,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-5400a8d7-3a10-44d5-8fc5-6d7d9a24cb39,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-0b4a83a5-8308-49dc-9b9b-c94262761823,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-bf134ac0-805f-4660-90e2-b2c42d5f0df9,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-6d3536a4-f825-49f4-b440-0e6d7bd73962,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-dcbc5d7a-3837-40bd-86bf-6b48fe42f1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-87bac2c6-a56d-4d07-b851-d3e4c1e0f401,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1562866454-172.17.0.14-1595360168151:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35809,DS-e22f7fb1-91c3-4e52-9c01-65c59af2bca1,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-461abc6f-f9f0-4bb8-a4d1-3a05b27df575,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-cae613c2-b78e-435c-9332-e03ce984e285,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-86574763-843f-4054-baac-10f6f5243489,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-ddc42a68-99eb-4654-95b7-dace8d7bd8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-dd79be93-3514-414e-a6ce-5e2e8eed5ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-f89b1534-f3d3-4970-a0ae-57a0ca1a65e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-9898a2ac-97a4-46c1-8547-6b1f974e7503,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1562866454-172.17.0.14-1595360168151:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35809,DS-e22f7fb1-91c3-4e52-9c01-65c59af2bca1,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-461abc6f-f9f0-4bb8-a4d1-3a05b27df575,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-cae613c2-b78e-435c-9332-e03ce984e285,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-86574763-843f-4054-baac-10f6f5243489,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-ddc42a68-99eb-4654-95b7-dace8d7bd8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-dd79be93-3514-414e-a6ce-5e2e8eed5ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-f89b1534-f3d3-4970-a0ae-57a0ca1a65e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-9898a2ac-97a4-46c1-8547-6b1f974e7503,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-555537075-172.17.0.14-1595360749440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38635,DS-252648e4-eb06-4d05-88e8-fd31731c8d92,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-c367803e-9989-473b-b216-b57f38aadbfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-3a5b54fe-41ff-4308-a610-97c773f938da,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-d60ae20d-862e-4da0-83e6-05b08a1fff26,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-adea9db3-a335-4074-b5d1-57108406bc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-ddd025ee-9f4f-4a53-94ba-2378477c2613,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-51e4690c-1ab9-4271-8eb5-f16be6fb8914,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-63bf812d-b16f-49ec-a61e-e10a03f04438,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-555537075-172.17.0.14-1595360749440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38635,DS-252648e4-eb06-4d05-88e8-fd31731c8d92,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-c367803e-9989-473b-b216-b57f38aadbfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-3a5b54fe-41ff-4308-a610-97c773f938da,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-d60ae20d-862e-4da0-83e6-05b08a1fff26,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-adea9db3-a335-4074-b5d1-57108406bc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-ddd025ee-9f4f-4a53-94ba-2378477c2613,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-51e4690c-1ab9-4271-8eb5-f16be6fb8914,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-63bf812d-b16f-49ec-a61e-e10a03f04438,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1006110399-172.17.0.14-1595360781367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41105,DS-0f0f2421-7224-4f3a-9907-47a0af6e8312,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-5c3e306a-1043-487b-9eee-88f3078765a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-bdad28c0-8f6e-4eda-b6ba-25ab48921ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-d9ad6925-c6c0-432d-a09e-c6c595370c58,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-fdac6864-11b5-4038-afa6-f93df18ab37b,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-25edd8c2-64e2-487e-b2fb-60977ed12db8,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-19a0c23a-b548-4d98-b227-7cc735c42c37,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-23a1b358-eb8f-4761-bda7-1275b8d56a56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1006110399-172.17.0.14-1595360781367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41105,DS-0f0f2421-7224-4f3a-9907-47a0af6e8312,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-5c3e306a-1043-487b-9eee-88f3078765a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-bdad28c0-8f6e-4eda-b6ba-25ab48921ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-d9ad6925-c6c0-432d-a09e-c6c595370c58,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-fdac6864-11b5-4038-afa6-f93df18ab37b,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-25edd8c2-64e2-487e-b2fb-60977ed12db8,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-19a0c23a-b548-4d98-b227-7cc735c42c37,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-23a1b358-eb8f-4761-bda7-1275b8d56a56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1851621247-172.17.0.14-1595360878250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39728,DS-5ff96932-24e3-45eb-b268-3aa8182903de,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-218cdede-10bf-4a96-87f3-a7ce4c3cc859,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-33be4fc4-4b33-4926-bccd-6d58eca13676,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-e6c8f4cb-17b6-4398-8188-dfbc9982f0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-618cfc93-9e4d-4075-96bf-fe781c2788b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-3d639900-e925-4571-b82d-c62c43e7ec1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-b9816525-1fd1-4078-877d-4a54afe084c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-f291b96a-9645-4e30-ac91-21b89994f818,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1851621247-172.17.0.14-1595360878250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39728,DS-5ff96932-24e3-45eb-b268-3aa8182903de,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-218cdede-10bf-4a96-87f3-a7ce4c3cc859,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-33be4fc4-4b33-4926-bccd-6d58eca13676,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-e6c8f4cb-17b6-4398-8188-dfbc9982f0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-618cfc93-9e4d-4075-96bf-fe781c2788b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-3d639900-e925-4571-b82d-c62c43e7ec1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-b9816525-1fd1-4078-877d-4a54afe084c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-f291b96a-9645-4e30-ac91-21b89994f818,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5155
