reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1139461130-172.17.0.19-1595324346514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40471,DS-c6e136d9-a997-4d2d-b39e-d5ade6312ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-d61c89eb-808c-4d04-aa21-3a79d6b584df,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-e39ddcc8-e88d-4d48-a0ad-e331ed7c6843,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-c82435c7-5841-4f28-92ce-ec73ba1e2b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-2ea247d4-f5e8-48bf-a873-f5c2a737b364,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-e1fa24a4-ce2d-46a9-a29d-c2b34dd0abb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-d669cce3-e9b4-4de2-b217-9f1baa3cd89b,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-2a22f38f-51b4-4347-8a04-d7728b400fb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1139461130-172.17.0.19-1595324346514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40471,DS-c6e136d9-a997-4d2d-b39e-d5ade6312ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-d61c89eb-808c-4d04-aa21-3a79d6b584df,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-e39ddcc8-e88d-4d48-a0ad-e331ed7c6843,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-c82435c7-5841-4f28-92ce-ec73ba1e2b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-2ea247d4-f5e8-48bf-a873-f5c2a737b364,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-e1fa24a4-ce2d-46a9-a29d-c2b34dd0abb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-d669cce3-e9b4-4de2-b217-9f1baa3cd89b,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-2a22f38f-51b4-4347-8a04-d7728b400fb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-494980990-172.17.0.19-1595324906455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43992,DS-29e1a60c-eb96-4bfb-b31b-344ec9392044,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-d983aa58-24c1-4f00-9290-1e6710feb705,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-75fe9926-d509-49db-9a68-c44d06dc98d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-160540af-2e84-4603-8bb2-7b687ec790eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-6360e4ea-408e-4312-8558-b06c14a8a90e,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-58467f9f-268d-4a3d-9a4a-d21221c53f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-7ad84871-1f54-4dcb-ba39-64fc3a7c3d27,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-f4b7a9c4-62d4-4917-88d8-5e9fbe71e92d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-494980990-172.17.0.19-1595324906455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43992,DS-29e1a60c-eb96-4bfb-b31b-344ec9392044,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-d983aa58-24c1-4f00-9290-1e6710feb705,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-75fe9926-d509-49db-9a68-c44d06dc98d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-160540af-2e84-4603-8bb2-7b687ec790eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-6360e4ea-408e-4312-8558-b06c14a8a90e,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-58467f9f-268d-4a3d-9a4a-d21221c53f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-7ad84871-1f54-4dcb-ba39-64fc3a7c3d27,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-f4b7a9c4-62d4-4917-88d8-5e9fbe71e92d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053904411-172.17.0.19-1595325176802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42990,DS-c5a7a4a2-fe0f-4c4f-812a-2e52c06d1887,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-f49037af-e269-4a72-a3fc-f3ebc3af43c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42693,DS-e208801e-29e6-4089-aebf-a8067e1caab5,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-3da7f233-d935-4dab-86cd-6c143aea59b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-acb0d2a5-f61f-4aed-8017-7d81e7d948ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-b96c7e0f-c735-4b11-8922-e7feaa2b2d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-d8e48b9a-a413-4992-b2ff-1cf18dc43a35,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-be65a45c-ee5d-4083-90ec-bef307c53053,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053904411-172.17.0.19-1595325176802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42990,DS-c5a7a4a2-fe0f-4c4f-812a-2e52c06d1887,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-f49037af-e269-4a72-a3fc-f3ebc3af43c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42693,DS-e208801e-29e6-4089-aebf-a8067e1caab5,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-3da7f233-d935-4dab-86cd-6c143aea59b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-acb0d2a5-f61f-4aed-8017-7d81e7d948ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-b96c7e0f-c735-4b11-8922-e7feaa2b2d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-d8e48b9a-a413-4992-b2ff-1cf18dc43a35,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-be65a45c-ee5d-4083-90ec-bef307c53053,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525583741-172.17.0.19-1595325251358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36782,DS-ae7177f6-37a8-42a3-a289-57915e6dfc11,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-a6107309-f105-43fd-8e89-536723066cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-d48433c6-4901-4a19-979c-478c5bb82a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-60f23d1e-26ef-4908-8faa-ae50f9d294f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-17e1ad7b-f1c4-4897-af0e-2c385980dafa,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-c25e8c9a-1839-467c-bca7-4c687cbd9a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-b3c1f613-8eba-4227-afde-85c6079a2878,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-c031b6e0-49ad-4601-9923-1f1993859689,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525583741-172.17.0.19-1595325251358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36782,DS-ae7177f6-37a8-42a3-a289-57915e6dfc11,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-a6107309-f105-43fd-8e89-536723066cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-d48433c6-4901-4a19-979c-478c5bb82a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-60f23d1e-26ef-4908-8faa-ae50f9d294f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-17e1ad7b-f1c4-4897-af0e-2c385980dafa,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-c25e8c9a-1839-467c-bca7-4c687cbd9a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-b3c1f613-8eba-4227-afde-85c6079a2878,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-c031b6e0-49ad-4601-9923-1f1993859689,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188443179-172.17.0.19-1595325367621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39507,DS-aa4bedcb-7097-4236-b510-9075bea4abb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-55150978-1373-4916-97e1-14fe4b9be294,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-ef2e821b-b5ca-421f-9046-1831ae5e948d,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-9c975be0-df7d-407b-9742-f5927462af97,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-f09d533a-ad13-4924-8343-cc9d5884de5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-03649775-cb1f-45a8-8f52-e0ac20314fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-e181ff76-3449-48b5-b672-1b96dc6ac91e,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-eda10334-98ad-4946-8d59-0fc9d8c980a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188443179-172.17.0.19-1595325367621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39507,DS-aa4bedcb-7097-4236-b510-9075bea4abb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-55150978-1373-4916-97e1-14fe4b9be294,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-ef2e821b-b5ca-421f-9046-1831ae5e948d,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-9c975be0-df7d-407b-9742-f5927462af97,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-f09d533a-ad13-4924-8343-cc9d5884de5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-03649775-cb1f-45a8-8f52-e0ac20314fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-e181ff76-3449-48b5-b672-1b96dc6ac91e,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-eda10334-98ad-4946-8d59-0fc9d8c980a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058501053-172.17.0.19-1595325846127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45927,DS-2bef5e03-9fd2-4d31-b697-af81f57c08da,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-59b45b36-111b-42ef-b73c-06a0284d479c,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-682b924d-041e-4811-85f7-8ae734982a84,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-e96ee353-19fb-40e1-aa6e-c9e1fa80bcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-fc9a9eb2-1f7d-4d96-bfc2-71fab1595a81,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-13f0c7e5-5acc-4410-b0e3-bfb23c5ff7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-f8767fd5-d76d-48f5-9b46-31ad6afcfc07,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-dcc5b19c-65da-40d0-a026-6f246d60ee70,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058501053-172.17.0.19-1595325846127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45927,DS-2bef5e03-9fd2-4d31-b697-af81f57c08da,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-59b45b36-111b-42ef-b73c-06a0284d479c,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-682b924d-041e-4811-85f7-8ae734982a84,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-e96ee353-19fb-40e1-aa6e-c9e1fa80bcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-fc9a9eb2-1f7d-4d96-bfc2-71fab1595a81,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-13f0c7e5-5acc-4410-b0e3-bfb23c5ff7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-f8767fd5-d76d-48f5-9b46-31ad6afcfc07,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-dcc5b19c-65da-40d0-a026-6f246d60ee70,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-384822868-172.17.0.19-1595326085463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46475,DS-470db15b-0e21-49fc-be41-598e312ce721,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-a24206a9-9c27-47d0-8899-46d91dde3e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-2f187a9b-d292-425e-b8b0-c5b9d50d1c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-b5432f7b-e6ed-4061-98f3-2768431ff0da,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-fb7cd8db-2cd3-4857-a4cb-b179454077a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-5dcd577b-1d87-4444-b5e5-009204561383,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-eb2006c6-6293-4e37-8d9a-a8c9d6d4a5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-7e4442cd-9c88-40fe-8627-4381d20f66f5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-384822868-172.17.0.19-1595326085463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46475,DS-470db15b-0e21-49fc-be41-598e312ce721,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-a24206a9-9c27-47d0-8899-46d91dde3e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-2f187a9b-d292-425e-b8b0-c5b9d50d1c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-b5432f7b-e6ed-4061-98f3-2768431ff0da,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-fb7cd8db-2cd3-4857-a4cb-b179454077a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-5dcd577b-1d87-4444-b5e5-009204561383,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-eb2006c6-6293-4e37-8d9a-a8c9d6d4a5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-7e4442cd-9c88-40fe-8627-4381d20f66f5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950436950-172.17.0.19-1595326165718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44433,DS-03dda6ac-1608-49c0-8f15-75be0ba9a40a,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-2dc09847-88bd-44be-b74e-2dcd02b71dea,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-0acaa9a0-a23a-4021-a74c-fb08c4afe93c,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-128c75a5-da01-4f79-9c53-b437b12478fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-db07abc1-8c00-4b31-949a-fce876cdab9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-8d567e0e-957f-40f0-b377-cc3e4dd1013b,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-357fc19e-acf7-4199-bd6e-4d256f126661,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-5934d89e-5ada-4257-bfe6-9c5f3ebd38d8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950436950-172.17.0.19-1595326165718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44433,DS-03dda6ac-1608-49c0-8f15-75be0ba9a40a,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-2dc09847-88bd-44be-b74e-2dcd02b71dea,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-0acaa9a0-a23a-4021-a74c-fb08c4afe93c,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-128c75a5-da01-4f79-9c53-b437b12478fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-db07abc1-8c00-4b31-949a-fce876cdab9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-8d567e0e-957f-40f0-b377-cc3e4dd1013b,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-357fc19e-acf7-4199-bd6e-4d256f126661,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-5934d89e-5ada-4257-bfe6-9c5f3ebd38d8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1533449952-172.17.0.19-1595326232757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41505,DS-e672c43d-c561-4709-a795-084490449695,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-794ba758-5425-4bd1-806d-58df2a3f00b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-0882718b-c62c-4415-b908-3da2d52236e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-ceb0b9d3-4df5-4137-9cc5-47b0e45ab52b,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-f14c4515-ee3d-49d0-8377-97065240fc58,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-54b4f674-9b25-4240-9867-100e7e718140,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-fc74bf37-a226-4e03-8869-0c157fc1a2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-6a199d51-05ef-4c30-b239-8e79ebacdb68,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1533449952-172.17.0.19-1595326232757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41505,DS-e672c43d-c561-4709-a795-084490449695,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-794ba758-5425-4bd1-806d-58df2a3f00b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-0882718b-c62c-4415-b908-3da2d52236e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-ceb0b9d3-4df5-4137-9cc5-47b0e45ab52b,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-f14c4515-ee3d-49d0-8377-97065240fc58,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-54b4f674-9b25-4240-9867-100e7e718140,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-fc74bf37-a226-4e03-8869-0c157fc1a2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-6a199d51-05ef-4c30-b239-8e79ebacdb68,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1103076391-172.17.0.19-1595326266186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39152,DS-d87958d7-3e33-4df2-86f8-c879e71db60d,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-98c4c579-b62d-4a92-94e0-dea1844f9300,DISK], DatanodeInfoWithStorage[127.0.0.1:41017,DS-e8103b2b-3bba-4e29-a26c-d83eb7b56846,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-576d3487-11d4-4d32-b9a0-c994ba6289b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-dc272c5a-6f8c-4944-8b4c-26e0db5bd065,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-75ff7e24-964a-4145-9bb7-590d5eecb99e,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-2bfb39cd-6f9c-4261-b514-bc8378b3d5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-02eb9b9e-bb00-480b-9e6e-4bfe72559b19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1103076391-172.17.0.19-1595326266186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39152,DS-d87958d7-3e33-4df2-86f8-c879e71db60d,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-98c4c579-b62d-4a92-94e0-dea1844f9300,DISK], DatanodeInfoWithStorage[127.0.0.1:41017,DS-e8103b2b-3bba-4e29-a26c-d83eb7b56846,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-576d3487-11d4-4d32-b9a0-c994ba6289b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-dc272c5a-6f8c-4944-8b4c-26e0db5bd065,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-75ff7e24-964a-4145-9bb7-590d5eecb99e,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-2bfb39cd-6f9c-4261-b514-bc8378b3d5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-02eb9b9e-bb00-480b-9e6e-4bfe72559b19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2122626563-172.17.0.19-1595326491105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38000,DS-94c5f99b-7aa8-480c-8d36-55c513787e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-93002fee-b9f8-4194-a7ed-cb07d558f515,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-5cb062de-a3ac-451e-9d87-c3502c4c2187,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-c28795b5-a256-4368-9de5-e86968aa37d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-040cab91-6590-42e2-a8c0-0bb3fbdc5a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-262581b4-d26f-4510-9cf9-55d946078747,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-1cc4b1b4-ffd4-43df-b4ca-8e399d4d13ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-c4d1ddb9-a998-4eb3-b77e-ff6f8e61e472,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2122626563-172.17.0.19-1595326491105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38000,DS-94c5f99b-7aa8-480c-8d36-55c513787e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-93002fee-b9f8-4194-a7ed-cb07d558f515,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-5cb062de-a3ac-451e-9d87-c3502c4c2187,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-c28795b5-a256-4368-9de5-e86968aa37d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-040cab91-6590-42e2-a8c0-0bb3fbdc5a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-262581b4-d26f-4510-9cf9-55d946078747,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-1cc4b1b4-ffd4-43df-b4ca-8e399d4d13ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-c4d1ddb9-a998-4eb3-b77e-ff6f8e61e472,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1761163630-172.17.0.19-1595326599401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45834,DS-7b33ddd3-9cfc-4b5f-9de0-ad7f145fb2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-deda17d9-f0e2-4768-8ec0-5b713e07ad1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-f912d43d-4c8a-4cac-8b28-249807f405a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-56477e29-af6c-420b-b0bf-a1c5877efd25,DISK], DatanodeInfoWithStorage[127.0.0.1:41427,DS-255eb0c4-2c84-4f24-9417-c69dc205575f,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-fe54debf-195b-4b2a-906a-bfe3fa8b6e34,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-2b89f56a-bb20-4d88-82e8-e14f783d78cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-38276276-ac83-44ad-bb17-8d9a4806e347,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1761163630-172.17.0.19-1595326599401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45834,DS-7b33ddd3-9cfc-4b5f-9de0-ad7f145fb2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-deda17d9-f0e2-4768-8ec0-5b713e07ad1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-f912d43d-4c8a-4cac-8b28-249807f405a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-56477e29-af6c-420b-b0bf-a1c5877efd25,DISK], DatanodeInfoWithStorage[127.0.0.1:41427,DS-255eb0c4-2c84-4f24-9417-c69dc205575f,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-fe54debf-195b-4b2a-906a-bfe3fa8b6e34,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-2b89f56a-bb20-4d88-82e8-e14f783d78cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-38276276-ac83-44ad-bb17-8d9a4806e347,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-633049446-172.17.0.19-1595326634405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34304,DS-96829084-7a06-47cd-9c26-3210b362a70c,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-4070128b-fc9a-4e00-98c4-7a2cb3f8ea65,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-7e6049bb-2663-4654-896b-a1a28272557a,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-fa3dc3bc-00ae-444c-8787-08b0b31cabcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-7c8e0bba-c153-436c-a84a-613d4369cce6,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-20fb3913-a081-45f3-a219-1084660988d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-7bdbdfcc-9503-4d7f-8e84-c2bd1eff819f,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-99681744-b1ca-42b1-81f4-07ee21b97fa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-633049446-172.17.0.19-1595326634405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34304,DS-96829084-7a06-47cd-9c26-3210b362a70c,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-4070128b-fc9a-4e00-98c4-7a2cb3f8ea65,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-7e6049bb-2663-4654-896b-a1a28272557a,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-fa3dc3bc-00ae-444c-8787-08b0b31cabcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-7c8e0bba-c153-436c-a84a-613d4369cce6,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-20fb3913-a081-45f3-a219-1084660988d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-7bdbdfcc-9503-4d7f-8e84-c2bd1eff819f,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-99681744-b1ca-42b1-81f4-07ee21b97fa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1362214500-172.17.0.19-1595326702316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38341,DS-5fdd57b5-aebc-4e49-bb87-53788f8f28c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-8b74302b-6d68-48a7-b2cf-8be381225590,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-031e81e6-ff0a-4071-b8dc-59f0e6ea5cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-4b9ebaa2-bed7-468c-81f2-20283406198f,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-33ffaa4b-1db0-49a2-b847-c2321218a4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-7235bad8-f140-482a-9246-d7873e98e231,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-106d1e8b-7442-4b5d-8ec6-805d091bba0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-5b24d1b7-203d-4ee4-b918-1b08a1dfd9cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1362214500-172.17.0.19-1595326702316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38341,DS-5fdd57b5-aebc-4e49-bb87-53788f8f28c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-8b74302b-6d68-48a7-b2cf-8be381225590,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-031e81e6-ff0a-4071-b8dc-59f0e6ea5cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-4b9ebaa2-bed7-468c-81f2-20283406198f,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-33ffaa4b-1db0-49a2-b847-c2321218a4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-7235bad8-f140-482a-9246-d7873e98e231,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-106d1e8b-7442-4b5d-8ec6-805d091bba0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-5b24d1b7-203d-4ee4-b918-1b08a1dfd9cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885124048-172.17.0.19-1595326818551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46134,DS-9ccf39e1-530a-49aa-9ab0-74b2676a5737,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-afc46b79-a76d-4b0c-9a84-f2da79a3e1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-ca783b40-790c-4f54-99b6-7c96b67ff797,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-00b8d7ec-4c7f-42a7-9fa5-50c50460ac8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-6c961685-2733-4266-b721-6ed06049357e,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-dcee236a-212e-4642-ba8f-7577cc0985d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-76f075ce-1aec-4b27-9ea6-feeea45ac587,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-d90729f9-1fc4-4bb3-90d4-c4355db3ec96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885124048-172.17.0.19-1595326818551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46134,DS-9ccf39e1-530a-49aa-9ab0-74b2676a5737,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-afc46b79-a76d-4b0c-9a84-f2da79a3e1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-ca783b40-790c-4f54-99b6-7c96b67ff797,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-00b8d7ec-4c7f-42a7-9fa5-50c50460ac8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-6c961685-2733-4266-b721-6ed06049357e,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-dcee236a-212e-4642-ba8f-7577cc0985d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-76f075ce-1aec-4b27-9ea6-feeea45ac587,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-d90729f9-1fc4-4bb3-90d4-c4355db3ec96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2104269865-172.17.0.19-1595326924744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44317,DS-b2d4d460-e7bf-4b9a-a965-86257c1bd8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-41fc7bbb-08d2-458c-a294-fb02ef83c94d,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-b69f2ed5-94c6-48b5-a080-906ca7ba1326,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-3a40a2bd-c9cb-436f-ae9a-5c7e57193586,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-65755f8b-cfd0-40e1-9358-4863a02d4acd,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-126e79e6-7e72-4520-aaa0-7b45efee2e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-09f40d93-a8e3-4921-8531-6bb46141f8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-0a7a6805-0d70-4c33-b3f9-5ba9b013cacc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2104269865-172.17.0.19-1595326924744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44317,DS-b2d4d460-e7bf-4b9a-a965-86257c1bd8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-41fc7bbb-08d2-458c-a294-fb02ef83c94d,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-b69f2ed5-94c6-48b5-a080-906ca7ba1326,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-3a40a2bd-c9cb-436f-ae9a-5c7e57193586,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-65755f8b-cfd0-40e1-9358-4863a02d4acd,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-126e79e6-7e72-4520-aaa0-7b45efee2e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-09f40d93-a8e3-4921-8531-6bb46141f8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-0a7a6805-0d70-4c33-b3f9-5ba9b013cacc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-516057611-172.17.0.19-1595326959851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45129,DS-b1cbcb85-612b-42b2-819c-af9ec51f5cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-c38be642-1924-424b-bcd0-6e05af0e0d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-d33635c8-2ff4-48f0-86f3-87baae56fe71,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-261a800a-aab9-47bd-a926-bf39e8cc2bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-c9b02fb5-c30a-4afb-8d9e-3986e3a4f01f,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-4511e199-8628-4196-881b-40f3ad88142b,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-4d816e24-87ea-4e2b-b441-d830c7412ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-03f2374c-3612-4583-bbbc-fe3b88600f9c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-516057611-172.17.0.19-1595326959851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45129,DS-b1cbcb85-612b-42b2-819c-af9ec51f5cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-c38be642-1924-424b-bcd0-6e05af0e0d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-d33635c8-2ff4-48f0-86f3-87baae56fe71,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-261a800a-aab9-47bd-a926-bf39e8cc2bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-c9b02fb5-c30a-4afb-8d9e-3986e3a4f01f,DISK], DatanodeInfoWithStorage[127.0.0.1:37103,DS-4511e199-8628-4196-881b-40f3ad88142b,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-4d816e24-87ea-4e2b-b441-d830c7412ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-03f2374c-3612-4583-bbbc-fe3b88600f9c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-709197029-172.17.0.19-1595327046737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40503,DS-559b35d6-631d-4a20-b84a-828581d62c43,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-0e23afe2-2a28-4e63-9eb8-6c668915f241,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-daeabade-f97c-4a05-aa14-5f61c8df1cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-287a6914-e7a1-458a-abd5-2d2287cffdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-642be5c5-ce43-4f1b-9fe1-7573d9c504f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-82f70558-e6ba-45bf-9559-c2ddf4b36f09,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-b5741322-5bf6-4859-9bb2-020e90ea76bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-cbe16147-6d09-4d67-8d2c-808baabe7e36,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-709197029-172.17.0.19-1595327046737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40503,DS-559b35d6-631d-4a20-b84a-828581d62c43,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-0e23afe2-2a28-4e63-9eb8-6c668915f241,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-daeabade-f97c-4a05-aa14-5f61c8df1cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-287a6914-e7a1-458a-abd5-2d2287cffdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-642be5c5-ce43-4f1b-9fe1-7573d9c504f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-82f70558-e6ba-45bf-9559-c2ddf4b36f09,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-b5741322-5bf6-4859-9bb2-020e90ea76bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-cbe16147-6d09-4d67-8d2c-808baabe7e36,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144915455-172.17.0.19-1595327121238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42458,DS-e82fea47-436f-441f-8308-33df7ddab5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-158ecb65-327e-432a-a1f8-38b285afb669,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-2c3b479f-c83c-4eaf-97ec-c07661b0dca6,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-ea01cc98-dd36-46fb-bf34-c9853a038ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-7ae61240-0c25-4144-92ba-d04764a3a81b,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-38ca0084-cb11-4464-b7d2-fdd5a2142c61,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-2ff27048-e4af-48b7-b3fc-3058d58f1dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-179f6602-908c-42fa-b041-8e1af3c17de2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144915455-172.17.0.19-1595327121238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42458,DS-e82fea47-436f-441f-8308-33df7ddab5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-158ecb65-327e-432a-a1f8-38b285afb669,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-2c3b479f-c83c-4eaf-97ec-c07661b0dca6,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-ea01cc98-dd36-46fb-bf34-c9853a038ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-7ae61240-0c25-4144-92ba-d04764a3a81b,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-38ca0084-cb11-4464-b7d2-fdd5a2142c61,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-2ff27048-e4af-48b7-b3fc-3058d58f1dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-179f6602-908c-42fa-b041-8e1af3c17de2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885862303-172.17.0.19-1595327188499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46322,DS-14a37ab9-eebc-45a6-a109-14bd4fde2740,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-06261f5a-58e3-4668-8b36-e4124741bbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-263966e9-da9e-40be-9c87-7b7ee9893108,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-822ed0c6-8c11-45e8-8789-0cc7026069a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-14cee9b0-8ed8-4eaf-8ffb-b287d7e87599,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-064a8177-a1d6-40b7-9a57-a119a889d288,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-c6edef8c-2016-4811-b684-f7fd9ca0a9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-0a33cae8-079f-4bb7-a919-cbcc905d305e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885862303-172.17.0.19-1595327188499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46322,DS-14a37ab9-eebc-45a6-a109-14bd4fde2740,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-06261f5a-58e3-4668-8b36-e4124741bbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-263966e9-da9e-40be-9c87-7b7ee9893108,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-822ed0c6-8c11-45e8-8789-0cc7026069a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-14cee9b0-8ed8-4eaf-8ffb-b287d7e87599,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-064a8177-a1d6-40b7-9a57-a119a889d288,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-c6edef8c-2016-4811-b684-f7fd9ca0a9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-0a33cae8-079f-4bb7-a919-cbcc905d305e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572379214-172.17.0.19-1595327364351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34756,DS-733768fe-b9f2-4916-862a-bdea4afd48bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-635c3167-66be-4971-96f8-6fd63a986335,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-6fd9d444-8d7b-4715-843e-685f5337d6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-77d0fa75-0442-4f66-b84c-32e8a5103eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-73a68399-05d1-42fb-a4a3-ce47c1054e74,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-b79c09b1-7f70-4b04-a2e9-e7c6dd2a1120,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-83010939-75b8-43f0-9c43-e21cbf41df3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-5ddb6203-0375-4678-9175-817d6f80bc42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572379214-172.17.0.19-1595327364351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34756,DS-733768fe-b9f2-4916-862a-bdea4afd48bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-635c3167-66be-4971-96f8-6fd63a986335,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-6fd9d444-8d7b-4715-843e-685f5337d6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-77d0fa75-0442-4f66-b84c-32e8a5103eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-73a68399-05d1-42fb-a4a3-ce47c1054e74,DISK], DatanodeInfoWithStorage[127.0.0.1:34216,DS-b79c09b1-7f70-4b04-a2e9-e7c6dd2a1120,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-83010939-75b8-43f0-9c43-e21cbf41df3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-5ddb6203-0375-4678-9175-817d6f80bc42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-992643751-172.17.0.19-1595327392689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34214,DS-8957f530-9309-4c12-963b-85b398b97f76,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-28f1eff2-73f8-43a2-9257-f1d1cb4b07af,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-b135833b-a663-40c6-b92c-087709e0b9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-0617e168-780f-47aa-9ad7-d43c230fdd80,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-6e6d15fa-f22e-417e-9a7a-cc3c29907f04,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-1e842499-d2f3-44c2-a735-23399e96db08,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-82ce76c9-4119-48df-b9e1-a486436b79a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43860,DS-609b1046-0c34-402a-a9ea-fb368f95fea5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-992643751-172.17.0.19-1595327392689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34214,DS-8957f530-9309-4c12-963b-85b398b97f76,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-28f1eff2-73f8-43a2-9257-f1d1cb4b07af,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-b135833b-a663-40c6-b92c-087709e0b9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-0617e168-780f-47aa-9ad7-d43c230fdd80,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-6e6d15fa-f22e-417e-9a7a-cc3c29907f04,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-1e842499-d2f3-44c2-a735-23399e96db08,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-82ce76c9-4119-48df-b9e1-a486436b79a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43860,DS-609b1046-0c34-402a-a9ea-fb368f95fea5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-477064181-172.17.0.19-1595327516028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33828,DS-9c15bf89-0a50-4726-bccd-4c1cedc6ef3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-a3c21480-49f7-4397-8404-abb001a79434,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-a85b479a-0a63-4b7a-9320-8c6b0f59550e,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-972d8f66-5f27-41d8-bd7f-04ebf75b8f61,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-eb1b3458-7625-4455-8e49-0508919ad90a,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-86621051-fa9d-49ea-b218-5753d20388bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-b0ab8a41-0696-4bd8-a10d-089e6464fb39,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-fa4be8ac-18c1-4192-9439-a3cb73b16a0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-477064181-172.17.0.19-1595327516028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33828,DS-9c15bf89-0a50-4726-bccd-4c1cedc6ef3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-a3c21480-49f7-4397-8404-abb001a79434,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-a85b479a-0a63-4b7a-9320-8c6b0f59550e,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-972d8f66-5f27-41d8-bd7f-04ebf75b8f61,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-eb1b3458-7625-4455-8e49-0508919ad90a,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-86621051-fa9d-49ea-b218-5753d20388bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-b0ab8a41-0696-4bd8-a10d-089e6464fb39,DISK], DatanodeInfoWithStorage[127.0.0.1:41482,DS-fa4be8ac-18c1-4192-9439-a3cb73b16a0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045409613-172.17.0.19-1595327708170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41338,DS-0b594bc1-0c45-480a-beeb-9bc39feaa96c,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-8b40922d-b307-4887-963b-044e7af6c996,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-a5b6e724-7bdf-492d-bdf4-b58693ac9d09,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-2f9cb8cb-d771-4902-a743-21a426e8e1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-39c2c990-ad66-4ba0-80d7-c47a314ee4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-318422b1-29d1-48a7-8d38-0520d8242562,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-90531b0c-9d68-4b85-85be-12a4b5836df5,DISK], DatanodeInfoWithStorage[127.0.0.1:33171,DS-efb53d6d-8478-43e4-903c-4fe919b0bf14,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045409613-172.17.0.19-1595327708170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41338,DS-0b594bc1-0c45-480a-beeb-9bc39feaa96c,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-8b40922d-b307-4887-963b-044e7af6c996,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-a5b6e724-7bdf-492d-bdf4-b58693ac9d09,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-2f9cb8cb-d771-4902-a743-21a426e8e1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-39c2c990-ad66-4ba0-80d7-c47a314ee4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-318422b1-29d1-48a7-8d38-0520d8242562,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-90531b0c-9d68-4b85-85be-12a4b5836df5,DISK], DatanodeInfoWithStorage[127.0.0.1:33171,DS-efb53d6d-8478-43e4-903c-4fe919b0bf14,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781006943-172.17.0.19-1595327772747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37095,DS-86da2267-300d-41e7-864e-d044b4b75547,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-96acb50f-07c2-42ec-94a7-efdc22bda0de,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-1df2a61e-5203-4c41-90eb-513fcefeb309,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-f5469f23-18c3-4494-b14c-67d6e6b05629,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-89561ede-c787-4d9c-9fa6-95ad743f9aae,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-dcf5a6b8-a678-4782-a244-c75da2eb94dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-6577d3d7-8d84-4247-9572-3262a497f172,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-77a38bc0-08ac-4eea-abc4-41777bbfd3a0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781006943-172.17.0.19-1595327772747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37095,DS-86da2267-300d-41e7-864e-d044b4b75547,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-96acb50f-07c2-42ec-94a7-efdc22bda0de,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-1df2a61e-5203-4c41-90eb-513fcefeb309,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-f5469f23-18c3-4494-b14c-67d6e6b05629,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-89561ede-c787-4d9c-9fa6-95ad743f9aae,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-dcf5a6b8-a678-4782-a244-c75da2eb94dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-6577d3d7-8d84-4247-9572-3262a497f172,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-77a38bc0-08ac-4eea-abc4-41777bbfd3a0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2013472284-172.17.0.19-1595327800946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41649,DS-f58fa78f-7f73-4c3e-842a-11091aeffd03,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-c1171737-c73f-47fa-bbf0-e9a7aadb80df,DISK], DatanodeInfoWithStorage[127.0.0.1:33667,DS-2ead8cd6-1349-4df2-838c-73cfdeab6ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-0ebaf4a9-50ed-4b9c-88bd-7ed858a99dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-2158e913-3026-47c3-a534-21457e051816,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-29c5485f-9252-4682-b97b-9328466b21e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-f52ab91d-bccb-4c0a-9b35-b29d7b642777,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-07d22321-3325-42a0-871c-af0d971e4f13,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2013472284-172.17.0.19-1595327800946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41649,DS-f58fa78f-7f73-4c3e-842a-11091aeffd03,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-c1171737-c73f-47fa-bbf0-e9a7aadb80df,DISK], DatanodeInfoWithStorage[127.0.0.1:33667,DS-2ead8cd6-1349-4df2-838c-73cfdeab6ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-0ebaf4a9-50ed-4b9c-88bd-7ed858a99dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-2158e913-3026-47c3-a534-21457e051816,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-29c5485f-9252-4682-b97b-9328466b21e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-f52ab91d-bccb-4c0a-9b35-b29d7b642777,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-07d22321-3325-42a0-871c-af0d971e4f13,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2022313380-172.17.0.19-1595327836107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33381,DS-2e5409eb-fcb8-46dc-b97b-f3074020abea,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-721025a0-665a-49b8-9f90-ab90276b1fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-36b7de81-a4c0-4834-aec7-4e1643f714ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-8f112cde-e6a2-4fbd-a540-80a9c5613d01,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-efe5390d-34b4-48bd-8dfb-4250dc007dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-9512fd00-5447-4e5b-aff8-c8581999f220,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-41b3d263-b8a2-48a6-ac43-8e39ac66b640,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-1a7bfac3-e42b-473c-94c6-edba6dc08feb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2022313380-172.17.0.19-1595327836107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33381,DS-2e5409eb-fcb8-46dc-b97b-f3074020abea,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-721025a0-665a-49b8-9f90-ab90276b1fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-36b7de81-a4c0-4834-aec7-4e1643f714ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-8f112cde-e6a2-4fbd-a540-80a9c5613d01,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-efe5390d-34b4-48bd-8dfb-4250dc007dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-9512fd00-5447-4e5b-aff8-c8581999f220,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-41b3d263-b8a2-48a6-ac43-8e39ac66b640,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-1a7bfac3-e42b-473c-94c6-edba6dc08feb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1727745867-172.17.0.19-1595327869233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40948,DS-8c3f5d77-e90c-4091-9096-608bf05a69c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-ce6a4b0f-f80e-4bb3-8ad3-106695a1921f,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-428051ad-2db2-4191-8f6c-a079cf449bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-fa584d25-7047-4d43-a97f-de9920d38131,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-4fa794f3-5bfd-49ee-8f70-3b4192f6ed6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-701d0753-8b20-4274-99c7-de1781c45744,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-4b0ef100-76e4-42a8-be8d-6c2fc2c74ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-f910b324-576b-4d16-95d1-1cd642e89a11,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1727745867-172.17.0.19-1595327869233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40948,DS-8c3f5d77-e90c-4091-9096-608bf05a69c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-ce6a4b0f-f80e-4bb3-8ad3-106695a1921f,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-428051ad-2db2-4191-8f6c-a079cf449bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-fa584d25-7047-4d43-a97f-de9920d38131,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-4fa794f3-5bfd-49ee-8f70-3b4192f6ed6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-701d0753-8b20-4274-99c7-de1781c45744,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-4b0ef100-76e4-42a8-be8d-6c2fc2c74ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-f910b324-576b-4d16-95d1-1cd642e89a11,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-298322653-172.17.0.19-1595327938826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39742,DS-1af60a88-a4e2-4206-a33c-d8fff27e3d88,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-09dbdd8c-6467-4a4a-9658-2086b7383cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-e80baa41-030c-4239-a902-490310dbdcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-73c9971f-a3de-48f2-b275-8c2f1e64ac00,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-a552573e-a799-4598-9deb-a44bcc54efbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-0635df93-a64d-4760-b673-9546f082c0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-35464175-98de-4275-a4a4-8218d7f5d1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-623d1bc7-8f7e-44f0-8634-fea924ce9652,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-298322653-172.17.0.19-1595327938826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39742,DS-1af60a88-a4e2-4206-a33c-d8fff27e3d88,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-09dbdd8c-6467-4a4a-9658-2086b7383cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-e80baa41-030c-4239-a902-490310dbdcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-73c9971f-a3de-48f2-b275-8c2f1e64ac00,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-a552573e-a799-4598-9deb-a44bcc54efbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-0635df93-a64d-4760-b673-9546f082c0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-35464175-98de-4275-a4a4-8218d7f5d1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-623d1bc7-8f7e-44f0-8634-fea924ce9652,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417029637-172.17.0.19-1595327972530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39724,DS-defb5517-1791-457b-aebb-4f34d7f74a41,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-0c2e08d5-1dff-40a5-94c5-3d78aab3edfd,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-03bc7d8e-2ee4-4be7-900f-2a246887da0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-feee6835-2f36-4037-a167-89f78c411817,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-28cf22ca-dac9-4a26-981e-8835b821c5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-ce888ecc-052b-40c4-8e84-f59d252b137d,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-62db07d6-0574-490a-9d81-8f6d6b4d7755,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-e44eccea-e15c-4715-8de8-4f4603562951,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417029637-172.17.0.19-1595327972530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39724,DS-defb5517-1791-457b-aebb-4f34d7f74a41,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-0c2e08d5-1dff-40a5-94c5-3d78aab3edfd,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-03bc7d8e-2ee4-4be7-900f-2a246887da0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-feee6835-2f36-4037-a167-89f78c411817,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-28cf22ca-dac9-4a26-981e-8835b821c5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-ce888ecc-052b-40c4-8e84-f59d252b137d,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-62db07d6-0574-490a-9d81-8f6d6b4d7755,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-e44eccea-e15c-4715-8de8-4f4603562951,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1415998330-172.17.0.19-1595328006713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45765,DS-4b8481e8-318a-444f-b9bc-44391fe50158,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-f4bcf3ed-204a-4b06-a913-b8420f70a7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-2a056109-124c-4567-bebe-7528f5fc07e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-d7ac7c76-c261-45b2-a5c6-ee036cd8b285,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-78b87579-5409-42a1-bce7-9365417efd94,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-cf728a5f-dfb8-4dc7-ac69-3b8553908b58,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-5aa5360b-dce5-4eeb-a809-881fc5b903c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-81768a35-b847-462a-8518-946079b3de03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1415998330-172.17.0.19-1595328006713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45765,DS-4b8481e8-318a-444f-b9bc-44391fe50158,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-f4bcf3ed-204a-4b06-a913-b8420f70a7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-2a056109-124c-4567-bebe-7528f5fc07e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-d7ac7c76-c261-45b2-a5c6-ee036cd8b285,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-78b87579-5409-42a1-bce7-9365417efd94,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-cf728a5f-dfb8-4dc7-ac69-3b8553908b58,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-5aa5360b-dce5-4eeb-a809-881fc5b903c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-81768a35-b847-462a-8518-946079b3de03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1477782843-172.17.0.19-1595328088878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45315,DS-ee9b8e0b-0ddb-4ab0-a5f8-4669ff27828d,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-0fd73f1e-79b8-44ad-ac7e-3a632c79ea2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-6fa8d78b-9ef6-461d-b6c5-d54c95b49bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-76df0291-fe67-4dea-940f-5cfb0f91eaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-76866178-c8d8-443d-92c4-bb5a77d831a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-fb0639f8-90b5-4599-b8d7-bad5f061e7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-4d59cc03-dd30-41fb-90c3-cce66e660bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-c1ba7a6e-b0ff-4b9f-b663-95764ba8c864,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1477782843-172.17.0.19-1595328088878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45315,DS-ee9b8e0b-0ddb-4ab0-a5f8-4669ff27828d,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-0fd73f1e-79b8-44ad-ac7e-3a632c79ea2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-6fa8d78b-9ef6-461d-b6c5-d54c95b49bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-76df0291-fe67-4dea-940f-5cfb0f91eaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-76866178-c8d8-443d-92c4-bb5a77d831a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-fb0639f8-90b5-4599-b8d7-bad5f061e7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-4d59cc03-dd30-41fb-90c3-cce66e660bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-c1ba7a6e-b0ff-4b9f-b663-95764ba8c864,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1057158154-172.17.0.19-1595328158643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46437,DS-38bee2bd-184e-4e25-83b2-080c54019cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-1f558d35-754f-49a2-be0b-b3af79f08b20,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-e99ad27f-ad5d-4dd9-ba5a-b0847a66594c,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-40e63f87-27e1-4db1-b7b1-40896b98ecc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-ef1379a8-32d7-4f99-92fd-c96c8ce5f29c,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-9734fc1b-7b32-4b62-bdea-80fa4b22ebc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-110197e6-982b-4af2-bcba-7ea5083f2fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-a8899100-b833-4d06-8648-ff62e3b05e6d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1057158154-172.17.0.19-1595328158643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46437,DS-38bee2bd-184e-4e25-83b2-080c54019cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-1f558d35-754f-49a2-be0b-b3af79f08b20,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-e99ad27f-ad5d-4dd9-ba5a-b0847a66594c,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-40e63f87-27e1-4db1-b7b1-40896b98ecc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-ef1379a8-32d7-4f99-92fd-c96c8ce5f29c,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-9734fc1b-7b32-4b62-bdea-80fa4b22ebc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-110197e6-982b-4af2-bcba-7ea5083f2fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-a8899100-b833-4d06-8648-ff62e3b05e6d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-996763980-172.17.0.19-1595328192872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46135,DS-59f909a3-d969-4b83-b41d-eb0002a0f39b,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-de7b94f8-c6d9-4d73-b64a-3920f26fd8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-ac65fe9d-7e65-4314-8972-3f2c45f94e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-cb88e7d2-9a8d-4751-94bb-d8b7694f9630,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-ec0bc3cf-3cd9-4f1d-bbaa-f5802a116caf,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-46c2ca30-cc66-4763-a269-057ec9d1c39a,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-29c30183-4427-4b1f-9616-527134bf25c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-1ce8cf0b-c30f-4081-b16a-b8cf4d01c2e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-996763980-172.17.0.19-1595328192872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46135,DS-59f909a3-d969-4b83-b41d-eb0002a0f39b,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-de7b94f8-c6d9-4d73-b64a-3920f26fd8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-ac65fe9d-7e65-4314-8972-3f2c45f94e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-cb88e7d2-9a8d-4751-94bb-d8b7694f9630,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-ec0bc3cf-3cd9-4f1d-bbaa-f5802a116caf,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-46c2ca30-cc66-4763-a269-057ec9d1c39a,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-29c30183-4427-4b1f-9616-527134bf25c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-1ce8cf0b-c30f-4081-b16a-b8cf4d01c2e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1808768437-172.17.0.19-1595328222534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37267,DS-eeb61fe9-a537-4503-9146-a15ae887d9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-d15d2d01-4851-4f5a-ac8d-cd81dcb2b111,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-2e1b258d-de43-44a9-946d-651812980ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-b445b949-f5d3-48a6-893c-313a47ccab90,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-29fc8bdc-5915-43d0-a572-e23861433ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-708b27e2-3b65-48e1-834d-d73e09251221,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-b1acda35-18a7-4d6a-90b8-76dc42cbfab4,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-30bb17b2-55fa-4e14-a53d-e9d498f7e08a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1808768437-172.17.0.19-1595328222534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37267,DS-eeb61fe9-a537-4503-9146-a15ae887d9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-d15d2d01-4851-4f5a-ac8d-cd81dcb2b111,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-2e1b258d-de43-44a9-946d-651812980ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-b445b949-f5d3-48a6-893c-313a47ccab90,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-29fc8bdc-5915-43d0-a572-e23861433ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-708b27e2-3b65-48e1-834d-d73e09251221,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-b1acda35-18a7-4d6a-90b8-76dc42cbfab4,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-30bb17b2-55fa-4e14-a53d-e9d498f7e08a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-622290842-172.17.0.19-1595328391200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38816,DS-7efbdd24-5d1f-4479-95cc-805318b90cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-1de01e60-dee9-4b00-81c5-66f2747b6587,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-1fcc4522-1ec5-46d6-8d22-0497e2b5ba34,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-e6da02d9-9d71-4d66-9584-ef6eaf809bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-fc49801d-ede8-40c3-9322-f35ffe1100cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-25ed46cd-caf3-453c-9889-606dcc934c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-4c700d0d-1c16-4e1e-8827-7a878ee15f86,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-9bfdae51-8f1f-4360-bb04-9334cd18e4a0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-622290842-172.17.0.19-1595328391200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38816,DS-7efbdd24-5d1f-4479-95cc-805318b90cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-1de01e60-dee9-4b00-81c5-66f2747b6587,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-1fcc4522-1ec5-46d6-8d22-0497e2b5ba34,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-e6da02d9-9d71-4d66-9584-ef6eaf809bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-fc49801d-ede8-40c3-9322-f35ffe1100cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-25ed46cd-caf3-453c-9889-606dcc934c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-4c700d0d-1c16-4e1e-8827-7a878ee15f86,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-9bfdae51-8f1f-4360-bb04-9334cd18e4a0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914900502-172.17.0.19-1595328604685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36404,DS-440f8ec0-90cc-4ae9-9767-07a2fd9e2329,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-85f4729b-2b4d-46e4-b926-b48fcaa9e536,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-954382cb-f7ce-4467-9937-68bebd1f32c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-8c0ce19e-f927-40dc-bc65-0fdb1ea5f013,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-cc56a8fd-89ea-49c2-9130-2c350c2c4b23,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-46d43053-6798-4299-be78-034d1e0f7fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-aa7b9551-7181-401f-9003-4bbd0ef6b184,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-3206e5af-c8e6-4919-b87a-6de8904910d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914900502-172.17.0.19-1595328604685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36404,DS-440f8ec0-90cc-4ae9-9767-07a2fd9e2329,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-85f4729b-2b4d-46e4-b926-b48fcaa9e536,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-954382cb-f7ce-4467-9937-68bebd1f32c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-8c0ce19e-f927-40dc-bc65-0fdb1ea5f013,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-cc56a8fd-89ea-49c2-9130-2c350c2c4b23,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-46d43053-6798-4299-be78-034d1e0f7fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-aa7b9551-7181-401f-9003-4bbd0ef6b184,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-3206e5af-c8e6-4919-b87a-6de8904910d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-176208541-172.17.0.19-1595328815861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33932,DS-a90b1451-ea8c-4752-86b8-5361fbf18a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-c5950783-b300-49ee-bc5b-2cb0190b2081,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-bbbc5e73-97e8-4224-9eb3-6aa0207b67b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-4d9f5e37-52af-4b2e-a5bd-143e20844697,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-6d848cbb-6d31-4f66-8901-dbbbf2194697,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-de754bd5-62aa-4ab0-bfca-ccd80e492fac,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-40d52fcb-bfab-4a8b-b1f0-849d739ef4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-a79ffc6b-ef86-4c50-9305-55947ae2cc2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-176208541-172.17.0.19-1595328815861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33932,DS-a90b1451-ea8c-4752-86b8-5361fbf18a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-c5950783-b300-49ee-bc5b-2cb0190b2081,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-bbbc5e73-97e8-4224-9eb3-6aa0207b67b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-4d9f5e37-52af-4b2e-a5bd-143e20844697,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-6d848cbb-6d31-4f66-8901-dbbbf2194697,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-de754bd5-62aa-4ab0-bfca-ccd80e492fac,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-40d52fcb-bfab-4a8b-b1f0-849d739ef4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-a79ffc6b-ef86-4c50-9305-55947ae2cc2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-925117376-172.17.0.19-1595328891929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34624,DS-78f3bc60-4577-4e8b-b3f9-09e80fba4544,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-3c1ae3ff-19b7-4941-92c3-ca9450c38e63,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-64239fe3-d8f4-4db1-93ed-53f04e7bc0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-7250f3e7-91f1-42f3-a318-4c2cfc3f5c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-4bde05ea-215d-4a11-b52a-4f20376401ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-a2c7488d-d630-4f9e-a060-e329f2e58a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-64f0be2c-6322-44a0-b6fa-70d3a676744d,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-384b7606-875f-4dd5-a7ae-5914a527c157,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-925117376-172.17.0.19-1595328891929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34624,DS-78f3bc60-4577-4e8b-b3f9-09e80fba4544,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-3c1ae3ff-19b7-4941-92c3-ca9450c38e63,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-64239fe3-d8f4-4db1-93ed-53f04e7bc0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-7250f3e7-91f1-42f3-a318-4c2cfc3f5c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-4bde05ea-215d-4a11-b52a-4f20376401ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-a2c7488d-d630-4f9e-a060-e329f2e58a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-64f0be2c-6322-44a0-b6fa-70d3a676744d,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-384b7606-875f-4dd5-a7ae-5914a527c157,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2055725043-172.17.0.19-1595329113924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39581,DS-1ffd11b0-ce04-4bcc-9277-3ce5e8b381c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-a1ea682a-57c5-40c1-86d9-65e62c11e3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-2d9d26b9-ceae-48a7-8723-41467882bf90,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-57e782c4-cb9a-454c-94a5-5057368bfe90,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-2c4e921a-b959-41db-9d19-5937fbffcdb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-29d768d2-ac7f-49a9-a409-37d07882a7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-de8b1317-26c0-4742-b77a-cf3f680d7cae,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-e0498e58-d6f4-430f-8890-a17357532551,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2055725043-172.17.0.19-1595329113924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39581,DS-1ffd11b0-ce04-4bcc-9277-3ce5e8b381c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-a1ea682a-57c5-40c1-86d9-65e62c11e3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-2d9d26b9-ceae-48a7-8723-41467882bf90,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-57e782c4-cb9a-454c-94a5-5057368bfe90,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-2c4e921a-b959-41db-9d19-5937fbffcdb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-29d768d2-ac7f-49a9-a409-37d07882a7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-de8b1317-26c0-4742-b77a-cf3f680d7cae,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-e0498e58-d6f4-430f-8890-a17357532551,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548435875-172.17.0.19-1595329304630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45561,DS-c15e266b-dc42-4aae-86e5-fbfe32461b04,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-30058d94-c844-4858-a650-cc23847c08fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-bbe13895-c134-4636-ad35-14250ecbc62c,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-310d0a68-6f8b-4b4f-82de-8960471c2122,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-142ec8c7-991f-48ad-a392-4c352e335676,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-29d8f655-f1f6-41a8-98e7-237263d4977c,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-5e05e435-3ead-449d-9ce6-4790e521cd89,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-a280fef4-f601-494c-a24f-91eff3c2a1db,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548435875-172.17.0.19-1595329304630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45561,DS-c15e266b-dc42-4aae-86e5-fbfe32461b04,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-30058d94-c844-4858-a650-cc23847c08fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-bbe13895-c134-4636-ad35-14250ecbc62c,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-310d0a68-6f8b-4b4f-82de-8960471c2122,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-142ec8c7-991f-48ad-a392-4c352e335676,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-29d8f655-f1f6-41a8-98e7-237263d4977c,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-5e05e435-3ead-449d-9ce6-4790e521cd89,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-a280fef4-f601-494c-a24f-91eff3c2a1db,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994229149-172.17.0.19-1595329457853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37011,DS-73c0fd37-a436-40e4-bae4-e6a370780266,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-eea75290-9184-4af3-aeb1-4d64fc3b83b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-baf12719-b62e-41ec-a0dd-5ee784354b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-33e58499-4ea8-4cce-8877-f9666edf01ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-062ef339-d83d-4ea3-af2b-525ad3f3498e,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-d260ece6-af49-4c0b-8930-9dc973db2f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-5b99454f-f086-4ac4-a0b7-188fd486b9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-c9d27c59-591a-47fa-ae07-bf1a57283c4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994229149-172.17.0.19-1595329457853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37011,DS-73c0fd37-a436-40e4-bae4-e6a370780266,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-eea75290-9184-4af3-aeb1-4d64fc3b83b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-baf12719-b62e-41ec-a0dd-5ee784354b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-33e58499-4ea8-4cce-8877-f9666edf01ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-062ef339-d83d-4ea3-af2b-525ad3f3498e,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-d260ece6-af49-4c0b-8930-9dc973db2f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-5b99454f-f086-4ac4-a0b7-188fd486b9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-c9d27c59-591a-47fa-ae07-bf1a57283c4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 13 out of 50
v1v1v2v2 failed with probability 25 out of 50
result: false positive !!!
Total execution time in seconds : 5360
